{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'FI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 13:49:34,245]\u001b[0m Using an existing study with name 'FI_2018' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:49:46,082]\u001b[0m Trial 1500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:49:51,851]\u001b[0m Trial 1501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:49:57,047]\u001b[0m Trial 1502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:01,144]\u001b[0m Trial 1503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:04,734]\u001b[0m Trial 1504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:08,617]\u001b[0m Trial 1505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:12,785]\u001b[0m Trial 1506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:16,710]\u001b[0m Trial 1507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:20,426]\u001b[0m Trial 1508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:26,361]\u001b[0m Trial 1509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:29,982]\u001b[0m Trial 1510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:33,716]\u001b[0m Trial 1511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:50:37,799]\u001b[0m Trial 1512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:51:31,848]\u001b[0m Trial 1513 finished with value: 3.809931212728028 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005070370515387451, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2046922451012514, 'dropout_rate_Layer_2': 0.38378544845400986, 'dropout_rate_Layer_3': 0.1231929623626108, 'dropout_rate_Layer_4': 0.010863318463298065, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.010427229598441612, 'l1_Layer_2': 4.90623858251807e-05, 'l1_Layer_3': 0.00024925894886370037, 'l1_Layer_4': 0.0006183974111780895, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130, 'n_units_Layer_4': 170}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 14.16% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 13:51:37,877]\u001b[0m Trial 1514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:51:41,591]\u001b[0m Trial 1515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:51:45,235]\u001b[0m Trial 1516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:51:49,245]\u001b[0m Trial 1517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:51:52,903]\u001b[0m Trial 1518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:51:58,717]\u001b[0m Trial 1519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:52:04,646]\u001b[0m Trial 1520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:52:08,497]\u001b[0m Trial 1521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:52:12,416]\u001b[0m Trial 1522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:53:00,884]\u001b[0m Trial 1523 finished with value: 3.731178986981817 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005843069298587432, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19814422216257738, 'dropout_rate_Layer_2': 0.39607777120798443, 'dropout_rate_Layer_3': 0.10908241364578158, 'dropout_rate_Layer_4': 0.0024683452789682966, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01078080779226309, 'l1_Layer_2': 4.015729989029349e-05, 'l1_Layer_3': 0.0003181271925252739, 'l1_Layer_4': 0.0005426684510304428, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 125, 'n_units_Layer_4': 175}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 15.17% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 13:53:51,386]\u001b[0m Trial 1524 finished with value: 3.860692010929243 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005186248717588815, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19511926910577923, 'dropout_rate_Layer_2': 0.39853555828830484, 'dropout_rate_Layer_3': 0.11438629421761806, 'dropout_rate_Layer_4': 0.0014341337960501845, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.02281654398352708, 'l1_Layer_2': 2.6305562466697228e-05, 'l1_Layer_3': 0.00024245371720573274, 'l1_Layer_4': 0.0006998397301668363, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 180}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 20.48% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 13:53:56,648]\u001b[0m Trial 1525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:54:47,353]\u001b[0m Trial 1526 finished with value: 4.022656040093974 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005204496200522006, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1810824729520288, 'dropout_rate_Layer_2': 0.39840014772028687, 'dropout_rate_Layer_3': 0.12078044400661928, 'dropout_rate_Layer_4': 0.2706823583737886, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.022429892185797808, 'l1_Layer_2': 3.412950013484523e-05, 'l1_Layer_3': 0.00027565520805297614, 'l1_Layer_4': 0.019207081652963805, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 105, 'n_units_Layer_4': 230}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.02 | sMAPE for Validation Set is: 11.76% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 16.77% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 13:55:25,458]\u001b[0m Trial 1527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:33,493]\u001b[0m Trial 1528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:38,860]\u001b[0m Trial 1529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:42,586]\u001b[0m Trial 1530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:46,444]\u001b[0m Trial 1531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:50,282]\u001b[0m Trial 1532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:54,091]\u001b[0m Trial 1533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:55:57,934]\u001b[0m Trial 1534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:04,167]\u001b[0m Trial 1535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:13,705]\u001b[0m Trial 1536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:19,175]\u001b[0m Trial 1537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:23,258]\u001b[0m Trial 1538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:26,819]\u001b[0m Trial 1539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:35,004]\u001b[0m Trial 1540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:40,780]\u001b[0m Trial 1541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:44,646]\u001b[0m Trial 1542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:48,613]\u001b[0m Trial 1543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:52,384]\u001b[0m Trial 1544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:56:57,095]\u001b[0m Trial 1545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:57:02,750]\u001b[0m Trial 1546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:57:59,573]\u001b[0m Trial 1547 finished with value: 3.8585463442615957 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005383427248930998, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19198017079940763, 'dropout_rate_Layer_2': 0.3858067265893843, 'dropout_rate_Layer_3': 0.12583797408387187, 'dropout_rate_Layer_4': 0.27310987037249507, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.021305056769440573, 'l1_Layer_2': 3.153763802287295e-05, 'l1_Layer_3': 0.00019578942127743287, 'l1_Layer_4': 0.05157920624490032, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 90, 'n_units_Layer_4': 215}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 13:58:04,967]\u001b[0m Trial 1548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:58:09,102]\u001b[0m Trial 1549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:58:14,806]\u001b[0m Trial 1550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:58:49,547]\u001b[0m Trial 1551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:58:53,208]\u001b[0m Trial 1552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:58:58,002]\u001b[0m Trial 1553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:02,142]\u001b[0m Trial 1554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:07,338]\u001b[0m Trial 1555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:12,454]\u001b[0m Trial 1556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:16,634]\u001b[0m Trial 1557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:20,581]\u001b[0m Trial 1558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:24,240]\u001b[0m Trial 1559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:29,923]\u001b[0m Trial 1560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:34,222]\u001b[0m Trial 1561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:38,202]\u001b[0m Trial 1562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:42,200]\u001b[0m Trial 1563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 13:59:49,507]\u001b[0m Trial 1564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:20,516]\u001b[0m Trial 1565 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:23,950]\u001b[0m Trial 1566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:27,927]\u001b[0m Trial 1567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:31,940]\u001b[0m Trial 1568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:35,577]\u001b[0m Trial 1569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:41,248]\u001b[0m Trial 1570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:45,275]\u001b[0m Trial 1571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:49,891]\u001b[0m Trial 1572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:00:56,782]\u001b[0m Trial 1573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:01,293]\u001b[0m Trial 1574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:04,904]\u001b[0m Trial 1575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:10,276]\u001b[0m Trial 1576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:14,219]\u001b[0m Trial 1577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:18,095]\u001b[0m Trial 1578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:21,765]\u001b[0m Trial 1579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:28,423]\u001b[0m Trial 1580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:01:34,402]\u001b[0m Trial 1581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:08,771]\u001b[0m Trial 1582 finished with value: 3.9386213847556366 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013832818905504462, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1620334510764387, 'dropout_rate_Layer_2': 0.3979926109941138, 'dropout_rate_Layer_3': 0.01359812646133346, 'dropout_rate_Layer_4': 0.0015614532878036602, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.9414388562855912e-05, 'l1_Layer_2': 0.0005604958335820695, 'l1_Layer_3': 1.717913270983974e-05, 'l1_Layer_4': 1.0703818093249681e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135, 'n_units_Layer_4': 60}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.94 | sMAPE for Validation Set is: 11.52% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 22.13% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:02:12,862]\u001b[0m Trial 1583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:16,882]\u001b[0m Trial 1584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:21,195]\u001b[0m Trial 1585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:26,279]\u001b[0m Trial 1586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:38,267]\u001b[0m Trial 1587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:42,331]\u001b[0m Trial 1588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:46,131]\u001b[0m Trial 1589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:49,948]\u001b[0m Trial 1590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:02:54,023]\u001b[0m Trial 1591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:03:02,143]\u001b[0m Trial 1592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:03:07,337]\u001b[0m Trial 1593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:03:13,071]\u001b[0m Trial 1594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:03:16,972]\u001b[0m Trial 1595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:03:20,828]\u001b[0m Trial 1596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:03:26,653]\u001b[0m Trial 1597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:04:20,434]\u001b[0m Trial 1598 finished with value: 3.8344364908376445 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005104994989538756, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17901757850287522, 'dropout_rate_Layer_2': 0.3740973727853559, 'dropout_rate_Layer_3': 0.1313219795405491, 'dropout_rate_Layer_4': 0.0037925279428929447, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0714670633752999, 'l1_Layer_2': 2.2057126758892386e-05, 'l1_Layer_3': 0.0001299635106274578, 'l1_Layer_4': 0.09513293186370592, 'n_units_Layer_1': 140, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80, 'n_units_Layer_4': 220}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 21.78% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:04:24,532]\u001b[0m Trial 1599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:04:29,741]\u001b[0m Trial 1600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:05:10,147]\u001b[0m Trial 1601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:05:14,170]\u001b[0m Trial 1602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:05:19,306]\u001b[0m Trial 1603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:05:23,417]\u001b[0m Trial 1604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:06:50,348]\u001b[0m Trial 1605 finished with value: 3.8092273467168685 and parameters: {'n_hidden': 4, 'learning_rate': 0.00151172205295149, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.098264764311524, 'dropout_rate_Layer_2': 0.39694958744363107, 'dropout_rate_Layer_3': 0.13029227695601303, 'dropout_rate_Layer_4': 0.1922048075340316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003241775434069352, 'l1_Layer_2': 0.000903720877008921, 'l1_Layer_3': 0.00020486733159732478, 'l1_Layer_4': 2.259462501523397e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135, 'n_units_Layer_4': 230}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.40 | sMAPE for Test Set is: 20.80% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:08:14,839]\u001b[0m Trial 1606 finished with value: 3.878928347137832 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015079442968131038, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1413045719991274, 'dropout_rate_Layer_2': 0.3950240367120338, 'dropout_rate_Layer_3': 0.13526554027845847, 'dropout_rate_Layer_4': 0.17651981030207398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003099580487666151, 'l1_Layer_2': 0.0015848510908170375, 'l1_Layer_3': 0.0001750307286721772, 'l1_Layer_4': 2.337027793327273e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125, 'n_units_Layer_4': 225}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:08:18,748]\u001b[0m Trial 1607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:08:22,605]\u001b[0m Trial 1608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:08:35,045]\u001b[0m Trial 1609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:09:38,689]\u001b[0m Trial 1610 finished with value: 3.6427777208163086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009661719109542038, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19692245708746992, 'dropout_rate_Layer_2': 0.13172171628703394, 'dropout_rate_Layer_3': 0.1663510736403244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001875394692639127, 'l1_Layer_2': 0.002574384668869953, 'l1_Layer_3': 0.0004731648637813925, 'n_units_Layer_1': 150, 'n_units_Layer_2': 130, 'n_units_Layer_3': 90}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.69 | sMAPE for Test Set is: 16.87% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:09:42,723]\u001b[0m Trial 1611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:18,841]\u001b[0m Trial 1612 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:24,029]\u001b[0m Trial 1613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:27,908]\u001b[0m Trial 1614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:31,698]\u001b[0m Trial 1615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:35,782]\u001b[0m Trial 1616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:40,993]\u001b[0m Trial 1617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:48,094]\u001b[0m Trial 1618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:10:58,761]\u001b[0m Trial 1619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:14,146]\u001b[0m Trial 1620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:17,951]\u001b[0m Trial 1621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:21,691]\u001b[0m Trial 1622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:25,810]\u001b[0m Trial 1623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:29,319]\u001b[0m Trial 1624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:33,132]\u001b[0m Trial 1625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:38,711]\u001b[0m Trial 1626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:42,562]\u001b[0m Trial 1627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:50,465]\u001b[0m Trial 1628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:11:54,132]\u001b[0m Trial 1629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:12:06,077]\u001b[0m Trial 1630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:12:22,399]\u001b[0m Trial 1631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:12:27,394]\u001b[0m Trial 1632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:12:34,512]\u001b[0m Trial 1633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:13:35,133]\u001b[0m Trial 1634 finished with value: 3.918041563913143 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015738746428851419, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14133093559880225, 'dropout_rate_Layer_2': 0.39999404888025064, 'dropout_rate_Layer_3': 0.1337351790222471, 'dropout_rate_Layer_4': 0.19106522150457925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0003317399122226825, 'l1_Layer_2': 0.0013827801600204232, 'l1_Layer_3': 0.0002233986587599783, 'l1_Layer_4': 2.2684819460948176e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 245, 'n_units_Layer_3': 135, 'n_units_Layer_4': 230}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.56 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:13:39,018]\u001b[0m Trial 1635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:14:44,864]\u001b[0m Trial 1636 finished with value: 3.9232003124110975 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007415170557279592, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09097513980828782, 'dropout_rate_Layer_2': 0.3997010694467514, 'dropout_rate_Layer_3': 0.11965621230646767, 'dropout_rate_Layer_4': 0.2507091267434192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002065732236639413, 'l1_Layer_2': 0.0017070841739368174, 'l1_Layer_3': 0.0008612917911697367, 'l1_Layer_4': 2.914148662496764e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125, 'n_units_Layer_4': 245}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.92 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.15 | sMAPE for Test Set is: 20.49% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:14:48,793]\u001b[0m Trial 1637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:14:52,726]\u001b[0m Trial 1638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:14:56,297]\u001b[0m Trial 1639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:15:00,048]\u001b[0m Trial 1640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:15:08,253]\u001b[0m Trial 1641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:15:12,384]\u001b[0m Trial 1642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:15:17,113]\u001b[0m Trial 1643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:15:24,309]\u001b[0m Trial 1644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:16:44,567]\u001b[0m Trial 1645 finished with value: 3.8836683539172125 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014229035296597662, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15561142028630714, 'dropout_rate_Layer_2': 0.37708653118267255, 'dropout_rate_Layer_3': 0.13889551419946142, 'dropout_rate_Layer_4': 0.1382453405672157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00044942478846977756, 'l1_Layer_2': 0.0010447554073293789, 'l1_Layer_3': 0.0005267994712185043, 'l1_Layer_4': 1.1293297484889084e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 255, 'n_units_Layer_3': 100, 'n_units_Layer_4': 190}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.03 | sMAPE for Test Set is: 22.41% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:16:48,521]\u001b[0m Trial 1646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:17:16,023]\u001b[0m Trial 1647 finished with value: 3.992177681048267 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016243040249238978, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15626956487148674, 'dropout_rate_Layer_2': 0.3898437281767078, 'dropout_rate_Layer_3': 0.029234147012348673, 'dropout_rate_Layer_4': 0.005437935807570092, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.224635529061077e-05, 'l1_Layer_2': 0.0006230710870295921, 'l1_Layer_3': 1.6933365348824665e-05, 'l1_Layer_4': 1.0568472259218376e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110, 'n_units_Layer_4': 55}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.22 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:18:04,663]\u001b[0m Trial 1648 finished with value: 3.809809188079124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007746337831400264, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004392793494725102, 'dropout_rate_Layer_2': 0.12954060140437118, 'dropout_rate_Layer_3': 0.16353000194142184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002446153378578317, 'l1_Layer_2': 5.417765021799403e-05, 'l1_Layer_3': 0.0006928954808746384, 'n_units_Layer_1': 155, 'n_units_Layer_2': 130, 'n_units_Layer_3': 120}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 24.34% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:18:12,360]\u001b[0m Trial 1649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:16,526]\u001b[0m Trial 1650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:20,185]\u001b[0m Trial 1651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:25,443]\u001b[0m Trial 1652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:30,845]\u001b[0m Trial 1653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:39,294]\u001b[0m Trial 1654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:46,726]\u001b[0m Trial 1655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:50,356]\u001b[0m Trial 1656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:55,741]\u001b[0m Trial 1657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:18:59,604]\u001b[0m Trial 1658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:19:03,034]\u001b[0m Trial 1659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:19:06,034]\u001b[0m Trial 1660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:19:55,972]\u001b[0m Trial 1661 finished with value: 4.120625935422198 and parameters: {'n_hidden': 4, 'learning_rate': 0.000619710011156712, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23492393965988062, 'dropout_rate_Layer_2': 0.3362265428304193, 'dropout_rate_Layer_3': 0.1449277422910317, 'dropout_rate_Layer_4': 0.34157109801320884, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08602457209757725, 'l1_Layer_2': 1.1876462683844608e-05, 'l1_Layer_3': 0.00012527863243326062, 'l1_Layer_4': 0.08858539523566367, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70, 'n_units_Layer_4': 240}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.12 | sMAPE for Validation Set is: 11.93% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 24.82% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:19:59,809]\u001b[0m Trial 1662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:07,220]\u001b[0m Trial 1663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:11,091]\u001b[0m Trial 1664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:16,521]\u001b[0m Trial 1665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:44,141]\u001b[0m Trial 1666 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:51,660]\u001b[0m Trial 1667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:55,297]\u001b[0m Trial 1668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:20:59,560]\u001b[0m Trial 1669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:21:03,755]\u001b[0m Trial 1670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:21:08,722]\u001b[0m Trial 1671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:21:18,502]\u001b[0m Trial 1672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:21:25,710]\u001b[0m Trial 1673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:22:30,973]\u001b[0m Trial 1674 finished with value: 3.931389005423924 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012384809071602377, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15470238065727177, 'dropout_rate_Layer_2': 0.37953691269938494, 'dropout_rate_Layer_3': 0.13852783712119657, 'dropout_rate_Layer_4': 0.1318428492850903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00031369851590123184, 'l1_Layer_2': 0.001057209864490234, 'l1_Layer_3': 0.0005178968721651215, 'l1_Layer_4': 1.0765877803254671e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 260, 'n_units_Layer_3': 95, 'n_units_Layer_4': 190}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 20.55% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:22:34,639]\u001b[0m Trial 1675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:22:38,142]\u001b[0m Trial 1676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:22:41,895]\u001b[0m Trial 1677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:22:47,465]\u001b[0m Trial 1678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:23:10,471]\u001b[0m Trial 1679 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:23:17,529]\u001b[0m Trial 1680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:23:24,007]\u001b[0m Trial 1681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:23:27,523]\u001b[0m Trial 1682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:23:31,610]\u001b[0m Trial 1683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:23:35,412]\u001b[0m Trial 1684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:00,708]\u001b[0m Trial 1685 finished with value: 4.008056350575702 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019725674761532676, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15741636070575407, 'dropout_rate_Layer_2': 0.38269437362572495, 'dropout_rate_Layer_3': 0.0028538318820188688, 'dropout_rate_Layer_4': 0.008427629247028482, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.096931591903545e-05, 'l1_Layer_2': 0.0005860953837887021, 'l1_Layer_3': 1.1250338380258545e-05, 'l1_Layer_4': 1.0555534518761153e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 250, 'n_units_Layer_3': 115, 'n_units_Layer_4': 55}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 24.22% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:24:08,599]\u001b[0m Trial 1686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:14,308]\u001b[0m Trial 1687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:17,871]\u001b[0m Trial 1688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:21,474]\u001b[0m Trial 1689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:28,356]\u001b[0m Trial 1690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:36,195]\u001b[0m Trial 1691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:40,353]\u001b[0m Trial 1692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:24:45,704]\u001b[0m Trial 1693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:25:37,614]\u001b[0m Trial 1694 finished with value: 4.006412679469785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014352445498176819, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16736936519395307, 'dropout_rate_Layer_2': 0.3660812899156408, 'dropout_rate_Layer_3': 0.14634870341823014, 'dropout_rate_Layer_4': 0.17219986037382157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00044414572004473435, 'l1_Layer_2': 0.000910193303439595, 'l1_Layer_3': 0.001198374616037214, 'l1_Layer_4': 3.0737818082146975e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150, 'n_units_Layer_4': 200}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 21.15% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:25:53,695]\u001b[0m Trial 1695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:25:56,913]\u001b[0m Trial 1696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:26:00,564]\u001b[0m Trial 1697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:26:07,368]\u001b[0m Trial 1698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:26:12,011]\u001b[0m Trial 1699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:26:17,156]\u001b[0m Trial 1700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:26:47,979]\u001b[0m Trial 1701 finished with value: 4.005068089495823 and parameters: {'n_hidden': 4, 'learning_rate': 0.001774646470980156, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14833139249185529, 'dropout_rate_Layer_2': 0.3939140497964981, 'dropout_rate_Layer_3': 0.0004413741817427281, 'dropout_rate_Layer_4': 0.006175023237812711, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.964022628643432e-05, 'l1_Layer_2': 0.000746499989317432, 'l1_Layer_3': 1.8964238828453013e-05, 'l1_Layer_4': 1.2577866006703228e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100, 'n_units_Layer_4': 50}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.01 | sMAPE for Validation Set is: 11.71% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 24.28% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:26:51,631]\u001b[0m Trial 1702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:26:55,710]\u001b[0m Trial 1703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:27:03,343]\u001b[0m Trial 1704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:27:06,647]\u001b[0m Trial 1705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:27:13,611]\u001b[0m Trial 1706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:27:23,665]\u001b[0m Trial 1707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:27:27,387]\u001b[0m Trial 1708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:29:08,774]\u001b[0m Trial 1709 finished with value: 3.8392788076667146 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014922636668512962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19061905798935713, 'dropout_rate_Layer_2': 0.3571391965351172, 'dropout_rate_Layer_3': 0.10860468658156788, 'dropout_rate_Layer_4': 0.09259816009272982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005240745562731668, 'l1_Layer_2': 0.000580774392167934, 'l1_Layer_3': 0.0008479568132490714, 'l1_Layer_4': 3.0120104105092053e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125, 'n_units_Layer_4': 155}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 11.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.57 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:29:18,833]\u001b[0m Trial 1710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:29:22,365]\u001b[0m Trial 1711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:29:27,693]\u001b[0m Trial 1712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:29:42,860]\u001b[0m Trial 1713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:29:51,297]\u001b[0m Trial 1714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:30:02,400]\u001b[0m Trial 1715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:30:06,104]\u001b[0m Trial 1716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:31:03,023]\u001b[0m Trial 1717 finished with value: 3.9312793929528027 and parameters: {'n_hidden': 4, 'learning_rate': 0.001636487668721364, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17787294161213577, 'dropout_rate_Layer_2': 0.3582272935430066, 'dropout_rate_Layer_3': 0.11129461632905448, 'dropout_rate_Layer_4': 0.07688332046398827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0007014665778736855, 'l1_Layer_2': 0.0005820970311249201, 'l1_Layer_3': 0.0009875411703514263, 'l1_Layer_4': 2.975385959296922e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125, 'n_units_Layer_4': 160}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.16 | sMAPE for Test Set is: 20.54% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:31:28,251]\u001b[0m Trial 1718 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:31:31,907]\u001b[0m Trial 1719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:31:41,892]\u001b[0m Trial 1720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:32:07,711]\u001b[0m Trial 1721 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:32:13,115]\u001b[0m Trial 1722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:32:16,909]\u001b[0m Trial 1723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:32:20,679]\u001b[0m Trial 1724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:33:45,321]\u001b[0m Trial 1725 finished with value: 3.7913556160873543 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018845328338521622, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16292457372234492, 'dropout_rate_Layer_2': 0.3357621249564543, 'dropout_rate_Layer_3': 0.06916015537305448, 'dropout_rate_Layer_4': 0.05451720283623658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001774811324839429, 'l1_Layer_2': 0.0002578844926087929, 'l1_Layer_3': 0.0003943077983299083, 'l1_Layer_4': 3.59697315737731e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150, 'n_units_Layer_4': 250}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 21.85% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:33:53,285]\u001b[0m Trial 1726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:33:57,884]\u001b[0m Trial 1727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:37:29,255]\u001b[0m Trial 1728 finished with value: 4.001225822335959 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017780495643853578, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1590755176302567, 'dropout_rate_Layer_2': 0.33121447959155326, 'dropout_rate_Layer_3': 0.06781621124156015, 'dropout_rate_Layer_4': 0.053151353575209836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00016609526109162862, 'l1_Layer_2': 0.000352380984980454, 'l1_Layer_3': 0.0003885177006654983, 'l1_Layer_4': 4.74231012629698e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235, 'n_units_Layer_4': 250}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 20.58% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:37:34,595]\u001b[0m Trial 1729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:37:38,332]\u001b[0m Trial 1730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:37:41,965]\u001b[0m Trial 1731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:37:51,429]\u001b[0m Trial 1732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:37:58,957]\u001b[0m Trial 1733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:10,736]\u001b[0m Trial 1734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:14,672]\u001b[0m Trial 1735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:18,859]\u001b[0m Trial 1736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:22,296]\u001b[0m Trial 1737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:30,840]\u001b[0m Trial 1738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:34,433]\u001b[0m Trial 1739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:38,620]\u001b[0m Trial 1740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:45,431]\u001b[0m Trial 1741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:50,648]\u001b[0m Trial 1742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:38:57,218]\u001b[0m Trial 1743 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:39:01,701]\u001b[0m Trial 1744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:39:10,904]\u001b[0m Trial 1745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:39:14,037]\u001b[0m Trial 1746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:39:38,940]\u001b[0m Trial 1747 finished with value: 3.7418953716910313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012169842385042144, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19728090659259248, 'dropout_rate_Layer_2': 0.008823590117052572, 'dropout_rate_Layer_3': 0.18356906053274202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047271150377051717, 'l1_Layer_2': 0.00134389012535888, 'l1_Layer_3': 0.000330053864453888, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 19.43% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:39:46,289]\u001b[0m Trial 1748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:39:50,990]\u001b[0m Trial 1749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:39:57,172]\u001b[0m Trial 1750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:40:03,853]\u001b[0m Trial 1751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:40:07,976]\u001b[0m Trial 1752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:41:01,933]\u001b[0m Trial 1753 finished with value: 3.8719654794867027 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005003734712107377, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1430107980573422, 'dropout_rate_Layer_2': 0.39192243401547716, 'dropout_rate_Layer_3': 0.031200009226597707, 'dropout_rate_Layer_4': 0.007105574574022984, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.166739598267862e-05, 'l1_Layer_2': 0.00014390210231442297, 'l1_Layer_3': 1.0845254405774906e-05, 'l1_Layer_4': 1.0097000122055037e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 245, 'n_units_Layer_3': 115, 'n_units_Layer_4': 50}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 17.32% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:41:06,653]\u001b[0m Trial 1754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:41:10,190]\u001b[0m Trial 1755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:41:14,630]\u001b[0m Trial 1756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:41:52,291]\u001b[0m Trial 1757 finished with value: 3.9735178113028105 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006840885757645094, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19040848536460803, 'dropout_rate_Layer_2': 0.37487441701877117, 'dropout_rate_Layer_3': 0.1382936741169558, 'dropout_rate_Layer_4': 0.1677205654651834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.014289974031251143, 'l1_Layer_2': 2.1657824945954087e-05, 'l1_Layer_3': 0.00010725026186721645, 'l1_Layer_4': 0.05514542312321346, 'n_units_Layer_1': 80, 'n_units_Layer_2': 140, 'n_units_Layer_3': 85, 'n_units_Layer_4': 205}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 25.02% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:41:56,915]\u001b[0m Trial 1758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:42:01,102]\u001b[0m Trial 1759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:42:04,818]\u001b[0m Trial 1760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:42:27,116]\u001b[0m Trial 1761 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:24,986]\u001b[0m Trial 1762 finished with value: 3.868466974459102 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005181586650449189, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09784667251560326, 'dropout_rate_Layer_2': 0.3987041095077526, 'dropout_rate_Layer_3': 0.00020346268894625395, 'dropout_rate_Layer_4': 0.0009814786515805621, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.419846334391485e-05, 'l1_Layer_2': 0.00012072924245662113, 'l1_Layer_3': 1.0562513546357472e-05, 'l1_Layer_4': 1.0176756989058692e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130, 'n_units_Layer_4': 50}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.87 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 18.38% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:43:29,150]\u001b[0m Trial 1763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:36,160]\u001b[0m Trial 1764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:40,175]\u001b[0m Trial 1765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:44,303]\u001b[0m Trial 1766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:47,989]\u001b[0m Trial 1767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:53,691]\u001b[0m Trial 1768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:43:57,675]\u001b[0m Trial 1769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:02,970]\u001b[0m Trial 1770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:07,234]\u001b[0m Trial 1771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:13,212]\u001b[0m Trial 1772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:18,378]\u001b[0m Trial 1773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:22,049]\u001b[0m Trial 1774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:29,934]\u001b[0m Trial 1775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:35,371]\u001b[0m Trial 1776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:44:40,251]\u001b[0m Trial 1777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:45:41,431]\u001b[0m Trial 1778 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:45:56,008]\u001b[0m Trial 1779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:46:03,251]\u001b[0m Trial 1780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:46:08,999]\u001b[0m Trial 1781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:46:12,959]\u001b[0m Trial 1782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:46:16,572]\u001b[0m Trial 1783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:47:15,736]\u001b[0m Trial 1784 finished with value: 3.746127509822171 and parameters: {'n_hidden': 4, 'learning_rate': 0.001100593602205035, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17101210520896815, 'dropout_rate_Layer_2': 0.33959529782959563, 'dropout_rate_Layer_3': 0.07846485513976209, 'dropout_rate_Layer_4': 0.045669159890411384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00025341542014834407, 'l1_Layer_2': 0.0002734706768946227, 'l1_Layer_3': 0.0003808923448972874, 'l1_Layer_4': 0.00012237396229680526, 'n_units_Layer_1': 110, 'n_units_Layer_2': 235, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.65 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:47:23,667]\u001b[0m Trial 1785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:47:27,160]\u001b[0m Trial 1786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:47:31,465]\u001b[0m Trial 1787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:47:51,662]\u001b[0m Trial 1788 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:49:22,945]\u001b[0m Trial 1789 finished with value: 3.8220942858788334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005004686659984222, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13079245887107008, 'dropout_rate_Layer_2': 0.3389917383547005, 'dropout_rate_Layer_3': 0.07601334646407606, 'dropout_rate_Layer_4': 0.03186386493445736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00020417362788755037, 'l1_Layer_2': 0.00030576762481648965, 'l1_Layer_3': 0.00041104735946308435, 'l1_Layer_4': 0.00014631474542845646, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 150, 'n_units_Layer_4': 205}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:49:26,853]\u001b[0m Trial 1790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:49:30,205]\u001b[0m Trial 1791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:49:37,899]\u001b[0m Trial 1792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:49:43,703]\u001b[0m Trial 1793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:49:47,219]\u001b[0m Trial 1794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:49:51,285]\u001b[0m Trial 1795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:10,111]\u001b[0m Trial 1796 finished with value: 3.8864722081136436 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005928901276420982, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16088897976261646, 'dropout_rate_Layer_2': 0.3375930180562741, 'dropout_rate_Layer_3': 0.08139011221923043, 'dropout_rate_Layer_4': 0.003412543265721754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003454198342956403, 'l1_Layer_2': 0.00024597801283361893, 'l1_Layer_3': 0.0003707861098699137, 'l1_Layer_4': 0.00013812731940644648, 'n_units_Layer_1': 110, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145, 'n_units_Layer_4': 295}. Best is trial 1073 with value: 3.5376371337270824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 22.28% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:51:13,632]\u001b[0m Trial 1797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:29,071]\u001b[0m Trial 1798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:32,934]\u001b[0m Trial 1799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:41,240]\u001b[0m Trial 1800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:44,462]\u001b[0m Trial 1801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:48,573]\u001b[0m Trial 1802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:54,795]\u001b[0m Trial 1803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:51:59,103]\u001b[0m Trial 1804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:04,957]\u001b[0m Trial 1805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:10,238]\u001b[0m Trial 1806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:15,312]\u001b[0m Trial 1807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:19,565]\u001b[0m Trial 1808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:24,550]\u001b[0m Trial 1809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:28,058]\u001b[0m Trial 1810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:33,253]\u001b[0m Trial 1811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:39,001]\u001b[0m Trial 1812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:42,842]\u001b[0m Trial 1813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:46,626]\u001b[0m Trial 1814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:52:54,761]\u001b[0m Trial 1815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:53:01,712]\u001b[0m Trial 1816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:53:05,526]\u001b[0m Trial 1817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:53:32,634]\u001b[0m Trial 1818 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:54:08,304]\u001b[0m Trial 1819 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:54:16,640]\u001b[0m Trial 1820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:54:20,382]\u001b[0m Trial 1821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:56:14,784]\u001b[0m Trial 1822 finished with value: 3.4636481611555516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007453890629793506, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034607006657077284, 'dropout_rate_Layer_2': 0.17289071539851658, 'dropout_rate_Layer_3': 0.0025110046700910493, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005161499777069233, 'l1_Layer_2': 0.0019643777085280928, 'l1_Layer_3': 4.7368500419730676e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 10.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 10.49% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:56:18,998]\u001b[0m Trial 1823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:56:24,335]\u001b[0m Trial 1824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:02,389]\u001b[0m Trial 1825 finished with value: 4.031789288480855 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011741685713020803, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13545724316024094, 'dropout_rate_Layer_2': 0.3302806392533206, 'dropout_rate_Layer_3': 0.07505077886371275, 'dropout_rate_Layer_4': 0.051439361384111426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00023326615699454086, 'l1_Layer_2': 0.0002629332341901734, 'l1_Layer_3': 0.0002824344662223533, 'l1_Layer_4': 7.774145340877729e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 95, 'n_units_Layer_3': 155, 'n_units_Layer_4': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 11.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 22.10% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:57:13,440]\u001b[0m Trial 1826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:17,655]\u001b[0m Trial 1827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:22,198]\u001b[0m Trial 1828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:25,858]\u001b[0m Trial 1829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:29,544]\u001b[0m Trial 1830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:36,353]\u001b[0m Trial 1831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:41,371]\u001b[0m Trial 1832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:57:45,382]\u001b[0m Trial 1833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:58:50,254]\u001b[0m Trial 1834 finished with value: 3.8526272259788588 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006874673201731005, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16967308239591666, 'dropout_rate_Layer_2': 0.34296402439002655, 'dropout_rate_Layer_3': 0.0635445353329043, 'dropout_rate_Layer_4': 0.035155997924559826, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014179748121943822, 'l1_Layer_2': 0.0002781697783538548, 'l1_Layer_3': 0.0006295885555860832, 'l1_Layer_4': 5.8631459175752544e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135, 'n_units_Layer_4': 240}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.61 | sMAPE for Test Set is: 24.55% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 14:59:14,549]\u001b[0m Trial 1835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 14:59:18,370]\u001b[0m Trial 1836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:10,359]\u001b[0m Trial 1837 finished with value: 3.643635036612357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009692159683193979, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12737339933199338, 'dropout_rate_Layer_2': 0.030017420124934142, 'dropout_rate_Layer_3': 0.08219547264968155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007842619166944613, 'l1_Layer_2': 0.0007409088969501437, 'l1_Layer_3': 0.000607664587817218, 'n_units_Layer_1': 250, 'n_units_Layer_2': 145, 'n_units_Layer_3': 125}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.15 | sMAPE for Test Set is: 25.47% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:00:14,341]\u001b[0m Trial 1838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:21,669]\u001b[0m Trial 1839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:29,541]\u001b[0m Trial 1840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:33,851]\u001b[0m Trial 1841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:37,324]\u001b[0m Trial 1842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:41,716]\u001b[0m Trial 1843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:45,246]\u001b[0m Trial 1844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:51,151]\u001b[0m Trial 1845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:00:56,517]\u001b[0m Trial 1846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:07,360]\u001b[0m Trial 1847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:12,086]\u001b[0m Trial 1848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:15,529]\u001b[0m Trial 1849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:26,667]\u001b[0m Trial 1850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:30,818]\u001b[0m Trial 1851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:36,258]\u001b[0m Trial 1852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:40,681]\u001b[0m Trial 1853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:45,050]\u001b[0m Trial 1854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:50,666]\u001b[0m Trial 1855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:01:54,120]\u001b[0m Trial 1856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:02:03,268]\u001b[0m Trial 1857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:02:06,791]\u001b[0m Trial 1858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:02:10,902]\u001b[0m Trial 1859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:02:14,770]\u001b[0m Trial 1860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:02:19,334]\u001b[0m Trial 1861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:02:24,165]\u001b[0m Trial 1862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:03:18,058]\u001b[0m Trial 1863 finished with value: 3.7456525827253326 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005047335389071877, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09493115036467202, 'dropout_rate_Layer_2': 0.39586182859226937, 'dropout_rate_Layer_3': 0.013640811302236633, 'dropout_rate_Layer_4': 0.09016312276754061, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.5329881328252583e-05, 'l1_Layer_2': 1.3134275669770196e-05, 'l1_Layer_3': 1.006652829365467e-05, 'l1_Layer_4': 6.273114294376245e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 21.06% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:03:27,319]\u001b[0m Trial 1864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:03:31,957]\u001b[0m Trial 1865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:03:35,610]\u001b[0m Trial 1866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:03:39,711]\u001b[0m Trial 1867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:04:40,725]\u001b[0m Trial 1868 finished with value: 3.6918797612501035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012056610061568893, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03896719337374406, 'dropout_rate_Layer_2': 0.12813971084734285, 'dropout_rate_Layer_3': 0.0623181087758449, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000332141213381537, 'l1_Layer_2': 0.0007304314886981609, 'l1_Layer_3': 0.0008293433470605934, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 90}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 10.81% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:04:48,145]\u001b[0m Trial 1869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:04:51,802]\u001b[0m Trial 1870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:04:58,794]\u001b[0m Trial 1871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:05:09,645]\u001b[0m Trial 1872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:05:44,744]\u001b[0m Trial 1873 finished with value: 3.8944656579143735 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005281761362973872, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18557957248710774, 'dropout_rate_Layer_2': 0.38310737363758907, 'dropout_rate_Layer_3': 0.10855082800902129, 'dropout_rate_Layer_4': 0.0016086705020527305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03775804525419109, 'l1_Layer_2': 2.5444233587536316e-05, 'l1_Layer_3': 0.00025902249920716744, 'l1_Layer_4': 0.0010502997041090122, 'n_units_Layer_1': 85, 'n_units_Layer_2': 80, 'n_units_Layer_3': 100, 'n_units_Layer_4': 185}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 24.69% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:05:50,807]\u001b[0m Trial 1874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:05:56,047]\u001b[0m Trial 1875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:16,968]\u001b[0m Trial 1876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:20,641]\u001b[0m Trial 1877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:24,480]\u001b[0m Trial 1878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:30,172]\u001b[0m Trial 1879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:34,345]\u001b[0m Trial 1880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:37,839]\u001b[0m Trial 1881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:06:42,304]\u001b[0m Trial 1882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:07:03,075]\u001b[0m Trial 1883 finished with value: 3.9926882073266547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016465047756637954, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03798034429323879, 'dropout_rate_Layer_2': 0.11000840427687608, 'dropout_rate_Layer_3': 0.08146164261587685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002488876592427713, 'l1_Layer_2': 0.000744193106270258, 'l1_Layer_3': 1.89323052204058e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 12.60% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:07:41,697]\u001b[0m Trial 1884 finished with value: 3.7090060204766977 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005282430650884198, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004276060184918343, 'dropout_rate_Layer_2': 0.31919377438782853, 'dropout_rate_Layer_3': 0.13116008334937712, 'dropout_rate_Layer_4': 0.10933289530693882, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.368453450179753e-05, 'l1_Layer_2': 1.1006005704967482e-05, 'l1_Layer_3': 1.0269453678129269e-05, 'l1_Layer_4': 8.650873119369509e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 125}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.83 | sMAPE for Test Set is: 17.29% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:07:49,888]\u001b[0m Trial 1885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:14,626]\u001b[0m Trial 1886 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:18,281]\u001b[0m Trial 1887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:22,737]\u001b[0m Trial 1888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:26,014]\u001b[0m Trial 1889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:36,600]\u001b[0m Trial 1890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:41,095]\u001b[0m Trial 1891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:08:50,584]\u001b[0m Trial 1892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:17,181]\u001b[0m Trial 1893 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:21,444]\u001b[0m Trial 1894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:26,970]\u001b[0m Trial 1895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:31,567]\u001b[0m Trial 1896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:36,880]\u001b[0m Trial 1897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:40,709]\u001b[0m Trial 1898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:45,812]\u001b[0m Trial 1899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:49,410]\u001b[0m Trial 1900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:09:52,945]\u001b[0m Trial 1901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:10:00,120]\u001b[0m Trial 1902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:10:03,984]\u001b[0m Trial 1903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:10:09,783]\u001b[0m Trial 1904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:10:38,792]\u001b[0m Trial 1905 finished with value: 3.9292787274013463 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008553834584386926, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13032717445025943, 'dropout_rate_Layer_2': 0.36735782303772835, 'dropout_rate_Layer_3': 0.09527675061054233, 'dropout_rate_Layer_4': 0.028397946835170256, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002600071122190477, 'l1_Layer_2': 0.00016769735560954516, 'l1_Layer_3': 0.0012528209738108973, 'l1_Layer_4': 0.00010401979381037912, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 105, 'n_units_Layer_4': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 27.61% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:10:48,288]\u001b[0m Trial 1906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:10:52,595]\u001b[0m Trial 1907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:10:57,593]\u001b[0m Trial 1908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:12:56,422]\u001b[0m Trial 1909 finished with value: 3.6324589255357806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015115077422612339, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024424859742369055, 'dropout_rate_Layer_2': 0.3725508044103341, 'dropout_rate_Layer_3': 0.11573807318359644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001816538948465201, 'l1_Layer_2': 0.0008600305251559243, 'l1_Layer_3': 0.00034926801335514676, 'n_units_Layer_1': 245, 'n_units_Layer_2': 135, 'n_units_Layer_3': 125}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.19 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:13:00,944]\u001b[0m Trial 1910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:13:05,454]\u001b[0m Trial 1911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:14:39,179]\u001b[0m Trial 1912 finished with value: 3.7426905585001307 and parameters: {'n_hidden': 3, 'learning_rate': 0.002045510922114145, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1451823780424169, 'dropout_rate_Layer_2': 0.3777701715658745, 'dropout_rate_Layer_3': 0.08427463683169112, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018615088130501554, 'l1_Layer_2': 0.0008067469277948124, 'l1_Layer_3': 0.0003149138648903749, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 11.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 12.71% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:14:42,565]\u001b[0m Trial 1913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:16:54,248]\u001b[0m Trial 1914 finished with value: 3.688413263694757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020340673238218986, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08938486874065735, 'dropout_rate_Layer_2': 0.36930306102684585, 'dropout_rate_Layer_3': 0.12785750104322977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015180673488008622, 'l1_Layer_2': 0.0008201884495881099, 'l1_Layer_3': 0.0003705763214420684, 'n_units_Layer_1': 260, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:17:57,517]\u001b[0m Trial 1915 finished with value: 3.7564323382093483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008131768576017104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02636574047325536, 'dropout_rate_Layer_2': 0.007077800737157683, 'dropout_rate_Layer_3': 0.1412009833804866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019014088429477696, 'l1_Layer_2': 2.4010334033057842e-05, 'l1_Layer_3': 0.002744535641396494, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 265}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 11.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:18:02,029]\u001b[0m Trial 1916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:18:12,540]\u001b[0m Trial 1917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:18:16,030]\u001b[0m Trial 1918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:18:55,911]\u001b[0m Trial 1919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:01,796]\u001b[0m Trial 1920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:09,913]\u001b[0m Trial 1921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:13,798]\u001b[0m Trial 1922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:19,067]\u001b[0m Trial 1923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:24,768]\u001b[0m Trial 1924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:39,070]\u001b[0m Trial 1925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:43,612]\u001b[0m Trial 1926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:47,534]\u001b[0m Trial 1927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:56,085]\u001b[0m Trial 1928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:19:59,768]\u001b[0m Trial 1929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:20:07,292]\u001b[0m Trial 1930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:20:36,124]\u001b[0m Trial 1931 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:22:16,502]\u001b[0m Trial 1932 finished with value: 3.712898003983986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030006487462763596, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14377049894066643, 'dropout_rate_Layer_2': 0.3652571288536111, 'dropout_rate_Layer_3': 0.08865589719246292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019121422201347797, 'l1_Layer_2': 0.0009615314650693792, 'l1_Layer_3': 0.0004151238988936237, 'n_units_Layer_1': 240, 'n_units_Layer_2': 125, 'n_units_Layer_3': 100}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 11.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:24:01,852]\u001b[0m Trial 1933 finished with value: 3.7069550980535966 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005038661211407085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17087389637943876, 'dropout_rate_Layer_2': 0.34938844956026044, 'dropout_rate_Layer_3': 0.07803326023094424, 'dropout_rate_Layer_4': 0.07466087643452028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00019161193584295855, 'l1_Layer_2': 0.0004683205088939491, 'l1_Layer_3': 0.00043380506418054266, 'l1_Layer_4': 0.0001336076577247519, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 260}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 10.95% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:24:05,857]\u001b[0m Trial 1934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:24:13,310]\u001b[0m Trial 1935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:24:19,481]\u001b[0m Trial 1936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:24:23,504]\u001b[0m Trial 1937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:24:27,575]\u001b[0m Trial 1938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:24:32,561]\u001b[0m Trial 1939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:24:40,079]\u001b[0m Trial 1940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:25:17,012]\u001b[0m Trial 1941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:26:56,446]\u001b[0m Trial 1942 finished with value: 3.893848547051961 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006433233195430768, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029136826812188935, 'dropout_rate_Layer_2': 0.1344856568065546, 'dropout_rate_Layer_3': 0.16599427975168915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017187000569697807, 'l1_Layer_2': 2.1812141721699603e-05, 'l1_Layer_3': 0.0019949303360777045, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 12.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:27:38,584]\u001b[0m Trial 1943 finished with value: 3.9584127855966873 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005261400063440285, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1860108677699764, 'dropout_rate_Layer_2': 0.3973406702352188, 'dropout_rate_Layer_3': 0.09874112140251559, 'dropout_rate_Layer_4': 0.06272741680730157, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.045508824156625056, 'l1_Layer_2': 1.101161478738079e-05, 'l1_Layer_3': 0.00021052679076980873, 'l1_Layer_4': 0.00031546792448152426, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120, 'n_units_Layer_4': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.42 | sMAPE for Test Set is: 21.10% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:27:42,511]\u001b[0m Trial 1944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:27:47,824]\u001b[0m Trial 1945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:28:26,671]\u001b[0m Trial 1946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:28:34,183]\u001b[0m Trial 1947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:28:38,774]\u001b[0m Trial 1948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:28:43,018]\u001b[0m Trial 1949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:28:47,459]\u001b[0m Trial 1950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:30:19,001]\u001b[0m Trial 1951 finished with value: 3.8409625760536623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006341865636305812, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03451940707783678, 'dropout_rate_Layer_2': 0.12925253928761696, 'dropout_rate_Layer_3': 0.13781640146185098, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017414189780400177, 'l1_Layer_2': 1.8393446597917313e-05, 'l1_Layer_3': 0.0018660111001510985, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 12.64% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:30:22,654]\u001b[0m Trial 1952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:30:36,577]\u001b[0m Trial 1953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:30:40,620]\u001b[0m Trial 1954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:31:15,267]\u001b[0m Trial 1955 finished with value: 3.742479298660875 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005194922138409288, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013815907378732147, 'dropout_rate_Layer_2': 0.3208841751826529, 'dropout_rate_Layer_3': 0.13960207284460563, 'dropout_rate_Layer_4': 0.11463584293327289, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.972288852920084e-05, 'l1_Layer_2': 1.4242075705567237e-05, 'l1_Layer_3': 1.0856922337088452e-05, 'l1_Layer_4': 0.00010576148601164547, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60, 'n_units_Layer_4': 135}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.68 | sMAPE for Test Set is: 21.62% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:31:22,500]\u001b[0m Trial 1956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:31:28,355]\u001b[0m Trial 1957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:32:51,148]\u001b[0m Trial 1958 finished with value: 3.5830776402581783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016963008036538646, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14556552593390792, 'dropout_rate_Layer_2': 0.1127631734397802, 'dropout_rate_Layer_3': 0.07521150744024971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015190765886337642, 'l1_Layer_2': 0.0011723158067073753, 'l1_Layer_3': 0.0002279926713259272, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:32:54,600]\u001b[0m Trial 1959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:33:02,188]\u001b[0m Trial 1960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:34:43,081]\u001b[0m Trial 1961 finished with value: 3.7850370246871226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006559578741866792, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04728332166465114, 'dropout_rate_Layer_2': 0.11949311996737551, 'dropout_rate_Layer_3': 0.1487856224461658, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012852691460158775, 'l1_Layer_2': 1.6439395731380248e-05, 'l1_Layer_3': 0.0018415428206925123, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 12.81% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:34:53,142]\u001b[0m Trial 1962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:34:56,569]\u001b[0m Trial 1963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:35:01,161]\u001b[0m Trial 1964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:35:59,470]\u001b[0m Trial 1965 finished with value: 3.99561214130906 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011552720000541448, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16463338369600383, 'dropout_rate_Layer_2': 0.3713864185096901, 'dropout_rate_Layer_3': 0.15463076305779233, 'dropout_rate_Layer_4': 0.2100653937316009, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.016076707899661768, 'l1_Layer_2': 5.350448740183567e-05, 'l1_Layer_3': 0.00015843045155351684, 'l1_Layer_4': 0.00018348941950300927, 'n_units_Layer_1': 165, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145, 'n_units_Layer_4': 295}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 11.66% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 25.72% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:36:03,006]\u001b[0m Trial 1966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:37:43,356]\u001b[0m Trial 1967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:37:48,276]\u001b[0m Trial 1968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:37:52,142]\u001b[0m Trial 1969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:37:57,272]\u001b[0m Trial 1970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:38:01,755]\u001b[0m Trial 1971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:38:18,465]\u001b[0m Trial 1972 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:38:23,848]\u001b[0m Trial 1973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:38:27,791]\u001b[0m Trial 1974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:39:03,570]\u001b[0m Trial 1975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:39:07,591]\u001b[0m Trial 1976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:39:13,032]\u001b[0m Trial 1977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:39:18,276]\u001b[0m Trial 1978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:39:22,517]\u001b[0m Trial 1979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:39:26,320]\u001b[0m Trial 1980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:40:07,677]\u001b[0m Trial 1981 finished with value: 3.830894695522621 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007671285242151782, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22257076594466932, 'dropout_rate_Layer_2': 0.32606400687528697, 'dropout_rate_Layer_3': 0.12178353161303351, 'dropout_rate_Layer_4': 0.04892787267571074, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006915998565558153, 'l1_Layer_2': 3.165556059570378e-05, 'l1_Layer_3': 0.00034616886482467834, 'l1_Layer_4': 0.0035228504494264306, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95, 'n_units_Layer_4': 130}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.10% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.05 | sMAPE for Test Set is: 22.61% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:40:14,014]\u001b[0m Trial 1982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:40:56,987]\u001b[0m Trial 1983 finished with value: 3.914911323339579 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007744392453438274, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22331471342119083, 'dropout_rate_Layer_2': 0.3312065553065542, 'dropout_rate_Layer_3': 0.13138264686095144, 'dropout_rate_Layer_4': 0.043776217561439665, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007365156899454253, 'l1_Layer_2': 5.152009774627062e-05, 'l1_Layer_3': 0.00010636409225592507, 'l1_Layer_4': 0.003982186764419452, 'n_units_Layer_1': 90, 'n_units_Layer_2': 70, 'n_units_Layer_3': 95, 'n_units_Layer_4': 125}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 11.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 23.49% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:41:05,234]\u001b[0m Trial 1984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:41:09,021]\u001b[0m Trial 1985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:41:13,309]\u001b[0m Trial 1986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:43:42,513]\u001b[0m Trial 1987 finished with value: 3.503120590255248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018230663673740703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12053794020883903, 'dropout_rate_Layer_2': 0.11565934234920053, 'dropout_rate_Layer_3': 0.07745381108418668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001451107365649448, 'l1_Layer_2': 0.0010475782399712245, 'l1_Layer_3': 0.00039348662163908707, 'n_units_Layer_1': 250, 'n_units_Layer_2': 100, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.50 | sMAPE for Validation Set is: 10.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 11.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:43:47,363]\u001b[0m Trial 1988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:43:53,100]\u001b[0m Trial 1989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:43:56,975]\u001b[0m Trial 1990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:44:04,348]\u001b[0m Trial 1991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:45:55,247]\u001b[0m Trial 1992 finished with value: 3.6016179077807315 and parameters: {'n_hidden': 3, 'learning_rate': 0.001927440571895425, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1459115342995642, 'dropout_rate_Layer_2': 0.10943577531908286, 'dropout_rate_Layer_3': 0.07863834772613273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001382412348347548, 'l1_Layer_2': 0.0009802010655536033, 'l1_Layer_3': 0.00024167630465515955, 'n_units_Layer_1': 240, 'n_units_Layer_2': 100, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:46:30,071]\u001b[0m Trial 1993 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:46:33,973]\u001b[0m Trial 1994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:46:37,439]\u001b[0m Trial 1995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:46:45,501]\u001b[0m Trial 1996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:51:15,170]\u001b[0m Trial 1997 finished with value: 3.674098659587306 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005035999512778776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18708732815753243, 'dropout_rate_Layer_2': 0.34971846064349, 'dropout_rate_Layer_3': 0.07892621189937271, 'dropout_rate_Layer_4': 0.026152300462549998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017637921469735804, 'l1_Layer_2': 0.00044987436017742967, 'l1_Layer_3': 0.00044940875758097624, 'l1_Layer_4': 0.00040672542510208996, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 270}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.78 | sMAPE for Test Set is: 10.61% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:51:30,563]\u001b[0m Trial 1998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:52:06,473]\u001b[0m Trial 1999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:52:10,462]\u001b[0m Trial 2000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:52:18,021]\u001b[0m Trial 2001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:52:22,658]\u001b[0m Trial 2002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:52:58,649]\u001b[0m Trial 2003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:53:35,314]\u001b[0m Trial 2004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:53:38,717]\u001b[0m Trial 2005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:53:51,865]\u001b[0m Trial 2006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:53:56,644]\u001b[0m Trial 2007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:54:00,296]\u001b[0m Trial 2008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:54:05,175]\u001b[0m Trial 2009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:54:09,106]\u001b[0m Trial 2010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:54:47,614]\u001b[0m Trial 2011 finished with value: 3.8910887634332396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007295978257663125, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09042830801637812, 'dropout_rate_Layer_2': 0.1378790252376184, 'dropout_rate_Layer_3': 0.141350411619758, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020642728754617274, 'l1_Layer_2': 1.8175822413942e-05, 'l1_Layer_3': 1.0054468585318241e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 13.68% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 15:54:51,839]\u001b[0m Trial 2012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:54:59,570]\u001b[0m Trial 2013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:55:03,586]\u001b[0m Trial 2014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:55:09,454]\u001b[0m Trial 2015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:55:24,792]\u001b[0m Trial 2016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:55:36,100]\u001b[0m Trial 2017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:55:41,532]\u001b[0m Trial 2018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:55:55,938]\u001b[0m Trial 2019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 15:58:20,135]\u001b[0m Trial 2020 finished with value: 3.5818267303161337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016789713587394555, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13868002580439054, 'dropout_rate_Layer_2': 0.09996823028107284, 'dropout_rate_Layer_3': 0.09363068371954107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018141384757806931, 'l1_Layer_2': 0.0006466404501490982, 'l1_Layer_3': 0.000333567040999103, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 85}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 10.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 11.52% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:00:10,640]\u001b[0m Trial 2021 finished with value: 3.6426817500613473 and parameters: {'n_hidden': 3, 'learning_rate': 0.001494095985305915, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13606008307986753, 'dropout_rate_Layer_2': 0.3676982660735161, 'dropout_rate_Layer_3': 0.09566591527560914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019491178809096913, 'l1_Layer_2': 0.0009703468208532809, 'l1_Layer_3': 0.0003699690009685836, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 80}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 11.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:03:14,662]\u001b[0m Trial 2022 finished with value: 3.6675864426872136 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005840852129517983, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19138053799892263, 'dropout_rate_Layer_2': 0.3527333922333471, 'dropout_rate_Layer_3': 0.09034900161544629, 'dropout_rate_Layer_4': 9.690082418498114e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.026176090832297e-05, 'l1_Layer_2': 0.0004493206811161052, 'l1_Layer_3': 0.00021792790698238598, 'l1_Layer_4': 0.00035177269228471803, 'n_units_Layer_1': 55, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145, 'n_units_Layer_4': 270}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 10.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:03:19,244]\u001b[0m Trial 2023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:03:26,648]\u001b[0m Trial 2024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:03:32,281]\u001b[0m Trial 2025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:03:37,179]\u001b[0m Trial 2026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:03:41,133]\u001b[0m Trial 2027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:04:17,809]\u001b[0m Trial 2028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:06:02,576]\u001b[0m Trial 2029 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:06:07,517]\u001b[0m Trial 2030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:06:11,542]\u001b[0m Trial 2031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:06:17,021]\u001b[0m Trial 2032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:06:31,444]\u001b[0m Trial 2033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:06:36,363]\u001b[0m Trial 2034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:07:13,353]\u001b[0m Trial 2035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:07:18,004]\u001b[0m Trial 2036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:07:21,933]\u001b[0m Trial 2037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:08:02,637]\u001b[0m Trial 2038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:08:08,505]\u001b[0m Trial 2039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:08:24,197]\u001b[0m Trial 2040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:09:31,031]\u001b[0m Trial 2041 finished with value: 3.889384112822055 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007502553156973422, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24483554763360693, 'dropout_rate_Layer_2': 0.36021190862527624, 'dropout_rate_Layer_3': 0.1679818056892226, 'dropout_rate_Layer_4': 0.11025561644805877, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006111606843455416, 'l1_Layer_2': 1.6736728352274896e-05, 'l1_Layer_3': 0.0006405237788709874, 'l1_Layer_4': 0.03444428936736181, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65, 'n_units_Layer_4': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.89 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.83 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:09:38,994]\u001b[0m Trial 2042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:11:00,152]\u001b[0m Trial 2043 finished with value: 3.824911819774123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006432066601822821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04453529760371171, 'dropout_rate_Layer_2': 0.10712211866656558, 'dropout_rate_Layer_3': 0.013117272884334057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1420031957195883e-05, 'l1_Layer_2': 1.3366958950591064e-05, 'l1_Layer_3': 1.0304233259136902e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.82 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.83 | sMAPE for Test Set is: 12.92% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:11:03,820]\u001b[0m Trial 2044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:11:18,515]\u001b[0m Trial 2045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:11:23,261]\u001b[0m Trial 2046 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:11:59,792]\u001b[0m Trial 2047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:12:04,294]\u001b[0m Trial 2048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:12:08,497]\u001b[0m Trial 2049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:12:13,884]\u001b[0m Trial 2050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:12:17,711]\u001b[0m Trial 2051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:12:21,963]\u001b[0m Trial 2052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:14:04,540]\u001b[0m Trial 2053 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:14:14,326]\u001b[0m Trial 2054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:14:36,110]\u001b[0m Trial 2055 finished with value: 4.6659428266528815 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010516242072415114, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21247031647558076, 'dropout_rate_Layer_2': 0.318307428498686, 'dropout_rate_Layer_3': 0.0922964950305763, 'dropout_rate_Layer_4': 0.04956178977490093, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012930111853907396, 'l1_Layer_2': 0.00010684948530635576, 'l1_Layer_3': 0.0004026036067687197, 'l1_Layer_4': 0.016445532123119715, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 90, 'n_units_Layer_4': 135}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.67 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.62 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:14:40,188]\u001b[0m Trial 2056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:14:45,433]\u001b[0m Trial 2057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:14:49,151]\u001b[0m Trial 2058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:14:57,888]\u001b[0m Trial 2059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:15:13,718]\u001b[0m Trial 2060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:15:30,649]\u001b[0m Trial 2061 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:15:34,335]\u001b[0m Trial 2062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:15:40,904]\u001b[0m Trial 2063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:15:45,091]\u001b[0m Trial 2064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:15:49,000]\u001b[0m Trial 2065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:16:25,204]\u001b[0m Trial 2066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:16:55,280]\u001b[0m Trial 2067 finished with value: 4.3611117548116765 and parameters: {'n_hidden': 4, 'learning_rate': 0.000942114474078267, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17746906513186497, 'dropout_rate_Layer_2': 0.37888391906602165, 'dropout_rate_Layer_3': 0.14976081277050413, 'dropout_rate_Layer_4': 0.0406276515114937, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.009575633860872092, 'l1_Layer_2': 3.288826304600978e-05, 'l1_Layer_3': 0.00031008147917281333, 'l1_Layer_4': 0.005592047423181933, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 110, 'n_units_Layer_4': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.36 | sMAPE for Validation Set is: 12.90% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:17:33,077]\u001b[0m Trial 2068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:17:37,748]\u001b[0m Trial 2069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:18:13,925]\u001b[0m Trial 2070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:18:19,465]\u001b[0m Trial 2071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:18:23,515]\u001b[0m Trial 2072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:18:38,075]\u001b[0m Trial 2073 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:19:15,153]\u001b[0m Trial 2074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:20:45,374]\u001b[0m Trial 2075 finished with value: 3.587141407548382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008766649255566183, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1426121938073817, 'dropout_rate_Layer_2': 0.14834826888692665, 'dropout_rate_Layer_3': 0.009001241672158225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009928236373144807, 'l1_Layer_2': 1.6265426132186504e-05, 'l1_Layer_3': 0.001948181544460594, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 235}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 10.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:20:53,708]\u001b[0m Trial 2076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:20:58,106]\u001b[0m Trial 2077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:21:12,983]\u001b[0m Trial 2078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:21:27,552]\u001b[0m Trial 2079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:21:35,593]\u001b[0m Trial 2080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:21:39,695]\u001b[0m Trial 2081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:23:23,104]\u001b[0m Trial 2082 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:25:05,351]\u001b[0m Trial 2083 finished with value: 3.7306744612883818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005548648511475289, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13982568932704495, 'dropout_rate_Layer_2': 5.9415898992109595e-05, 'dropout_rate_Layer_3': 0.01257597530995972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.978660133720233e-05, 'l1_Layer_2': 2.6515251532029257e-05, 'l1_Layer_3': 0.0024847354166534293, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 12.59% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:25:09,473]\u001b[0m Trial 2084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:26:05,837]\u001b[0m Trial 2085 finished with value: 3.748057507127801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005004379081275018, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13694088991183795, 'dropout_rate_Layer_2': 0.0008441142772715928, 'dropout_rate_Layer_3': 0.0006076273844800757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.847955709296893e-05, 'l1_Layer_2': 1.2225700012215869e-05, 'l1_Layer_3': 1.0268186715072015e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 12.21% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:26:09,767]\u001b[0m Trial 2086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:26:13,878]\u001b[0m Trial 2087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:27:14,473]\u001b[0m Trial 2088 finished with value: 3.756073550924908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005641510608869821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14752213101988543, 'dropout_rate_Layer_2': 0.0031230162448920534, 'dropout_rate_Layer_3': 0.001516906959608962, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.815974015437199e-05, 'l1_Layer_2': 1.0408654098688332e-05, 'l1_Layer_3': 7.381947543032946e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 14.82% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:28:36,024]\u001b[0m Trial 2089 finished with value: 3.6660038709240923 and parameters: {'n_hidden': 3, 'learning_rate': 0.002084761017390908, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14124915530498, 'dropout_rate_Layer_2': 0.39234191244073346, 'dropout_rate_Layer_3': 0.12179279179466132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020096283691638473, 'l1_Layer_2': 0.0013705908127674205, 'l1_Layer_3': 0.00037262534543455365, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 75}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 10.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.97 | sMAPE for Test Set is: 11.07% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:28:40,387]\u001b[0m Trial 2090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:28:48,025]\u001b[0m Trial 2091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:28:52,246]\u001b[0m Trial 2092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:28:57,702]\u001b[0m Trial 2093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:29:02,395]\u001b[0m Trial 2094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:29:08,197]\u001b[0m Trial 2095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:30:33,311]\u001b[0m Trial 2096 finished with value: 3.759748653868279 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005390488756390889, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13925475039737892, 'dropout_rate_Layer_2': 0.0054541841157502895, 'dropout_rate_Layer_3': 0.010648536992734206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.797993010970076e-05, 'l1_Layer_2': 1.093845302796652e-05, 'l1_Layer_3': 9.169435452597415e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.27 | sMAPE for Test Set is: 11.74% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:30:38,024]\u001b[0m Trial 2097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:30:41,684]\u001b[0m Trial 2098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:31:24,642]\u001b[0m Trial 2099 finished with value: 3.8083831564008186 and parameters: {'n_hidden': 4, 'learning_rate': 0.000616797912898237, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19513435438300977, 'dropout_rate_Layer_2': 0.3502348021026868, 'dropout_rate_Layer_3': 0.12315565675300075, 'dropout_rate_Layer_4': 0.0009946346252119407, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.025619526088597955, 'l1_Layer_2': 2.5346834347735928e-05, 'l1_Layer_3': 0.00019778456762737637, 'l1_Layer_4': 0.0009016078445038805, 'n_units_Layer_1': 115, 'n_units_Layer_2': 90, 'n_units_Layer_3': 80, 'n_units_Layer_4': 180}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 24.04% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:32:04,263]\u001b[0m Trial 2100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:08,717]\u001b[0m Trial 2101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:22,919]\u001b[0m Trial 2102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:28,475]\u001b[0m Trial 2103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:32,273]\u001b[0m Trial 2104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:37,119]\u001b[0m Trial 2105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:51,705]\u001b[0m Trial 2106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:32:55,554]\u001b[0m Trial 2107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:33:35,273]\u001b[0m Trial 2108 finished with value: 3.8491208464739715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005213785061104848, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1553732579604716, 'dropout_rate_Layer_2': 0.007697242873491898, 'dropout_rate_Layer_3': 0.019071059385673442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.754184860090013e-05, 'l1_Layer_2': 1.1163586400814996e-05, 'l1_Layer_3': 0.00015649861453359722, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 12.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:34:27,820]\u001b[0m Trial 2109 finished with value: 4.042394497745309 and parameters: {'n_hidden': 4, 'learning_rate': 0.000724096238644648, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19755752928161557, 'dropout_rate_Layer_2': 0.3470303235769726, 'dropout_rate_Layer_3': 0.12859687176704718, 'dropout_rate_Layer_4': 0.03968735161653071, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0446502161940636, 'l1_Layer_2': 6.080811070296636e-05, 'l1_Layer_3': 0.0001699471758499173, 'l1_Layer_4': 0.0022719060297771007, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80, 'n_units_Layer_4': 185}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.04 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:34:32,300]\u001b[0m Trial 2110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:34:39,565]\u001b[0m Trial 2111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:34:43,883]\u001b[0m Trial 2112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:34:49,785]\u001b[0m Trial 2113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:35:18,730]\u001b[0m Trial 2114 finished with value: 3.7651930171950565 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011783492820466909, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006211172569652494, 'dropout_rate_Layer_2': 0.3091476497213105, 'dropout_rate_Layer_3': 0.13526878637643147, 'dropout_rate_Layer_4': 0.11907985943030255, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.686490260154078e-05, 'l1_Layer_2': 1.0799834794082537e-05, 'l1_Layer_3': 0.00012285139108835522, 'l1_Layer_4': 0.00012179282220822216, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 140}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.71 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:35:23,171]\u001b[0m Trial 2115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:35:26,880]\u001b[0m Trial 2116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:35:41,985]\u001b[0m Trial 2117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:35:45,545]\u001b[0m Trial 2118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:35:54,182]\u001b[0m Trial 2119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:37:36,660]\u001b[0m Trial 2120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:38:52,776]\u001b[0m Trial 2121 finished with value: 3.83002547926077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005484084000732483, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14193785407296827, 'dropout_rate_Layer_2': 0.014181460474467816, 'dropout_rate_Layer_3': 0.0010496932513758914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.756333674449457e-05, 'l1_Layer_2': 1.0061862061761206e-05, 'l1_Layer_3': 9.029316896164614e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 12.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:40:12,524]\u001b[0m Trial 2122 finished with value: 3.690642616335906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018566384950537331, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12614303455185416, 'dropout_rate_Layer_2': 0.1227511448442437, 'dropout_rate_Layer_3': 0.13468570984285186, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009793938134807906, 'l1_Layer_2': 0.002234224069577174, 'l1_Layer_3': 0.00031288613853160493, 'n_units_Layer_1': 240, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.78% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 11.71% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:41:23,160]\u001b[0m Trial 2123 finished with value: 3.7636328282569367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005487519853801995, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14656519750110772, 'dropout_rate_Layer_2': 0.014390665112755191, 'dropout_rate_Layer_3': 0.0028701919325082935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.229467900322857e-05, 'l1_Layer_2': 1.0880858650786968e-05, 'l1_Layer_3': 8.625984866475977e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 11.07% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 13.22% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:41:27,062]\u001b[0m Trial 2124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:41:32,048]\u001b[0m Trial 2125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:45:11,759]\u001b[0m Trial 2126 finished with value: 3.677546924044078 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005903691263708075, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18710638885228792, 'dropout_rate_Layer_2': 0.3275953104583563, 'dropout_rate_Layer_3': 0.06284991387195776, 'dropout_rate_Layer_4': 0.0066173312315442046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.01364151031802e-05, 'l1_Layer_2': 0.0004481119313658625, 'l1_Layer_3': 0.00034221632051859046, 'l1_Layer_4': 0.00035659869469460866, 'n_units_Layer_1': 50, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145, 'n_units_Layer_4': 275}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:45:16,224]\u001b[0m Trial 2127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:46:43,719]\u001b[0m Trial 2128 finished with value: 3.7503826451789952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005495832953065756, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13226640033454598, 'dropout_rate_Layer_2': 0.00042364248629272745, 'dropout_rate_Layer_3': 0.010343279791304418, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.991145989313092e-05, 'l1_Layer_2': 1.2334552895541107e-05, 'l1_Layer_3': 0.00010958041718320988, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 12.65% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:46:47,737]\u001b[0m Trial 2129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:46:52,034]\u001b[0m Trial 2130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:47:29,615]\u001b[0m Trial 2131 finished with value: 4.004035344869731 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006522346492874741, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22186588154103196, 'dropout_rate_Layer_2': 0.35730575421022887, 'dropout_rate_Layer_3': 0.10279242881395985, 'dropout_rate_Layer_4': 0.03649082118723543, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.021161567784097817, 'l1_Layer_2': 4.2716396692271766e-05, 'l1_Layer_3': 9.427104422424053e-05, 'l1_Layer_4': 0.0296338502788653, 'n_units_Layer_1': 140, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60, 'n_units_Layer_4': 165}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.00 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 25.08% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:47:35,699]\u001b[0m Trial 2132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:49:10,599]\u001b[0m Trial 2133 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:49:42,104]\u001b[0m Trial 2134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:49:46,542]\u001b[0m Trial 2135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:50:17,085]\u001b[0m Trial 2136 finished with value: 4.082078303140857 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012422394780667522, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15259487870378868, 'dropout_rate_Layer_2': 0.3813995680505015, 'dropout_rate_Layer_3': 0.12072998504439489, 'dropout_rate_Layer_4': 0.031477269665773695, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05713117164882871, 'l1_Layer_2': 1.781862408844291e-05, 'l1_Layer_3': 0.0003662048473330578, 'l1_Layer_4': 0.0012623120785178379, 'n_units_Layer_1': 95, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.08 | sMAPE for Validation Set is: 11.81% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 22.43% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:50:21,447]\u001b[0m Trial 2137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:50:47,438]\u001b[0m Trial 2138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:50:51,792]\u001b[0m Trial 2139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:50:55,189]\u001b[0m Trial 2140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:53:07,073]\u001b[0m Trial 2141 finished with value: 3.6634044964020482 and parameters: {'n_hidden': 3, 'learning_rate': 0.001845669824479248, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10375194008029037, 'dropout_rate_Layer_2': 0.398300837448398, 'dropout_rate_Layer_3': 0.12364744481527888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009565260922377342, 'l1_Layer_2': 0.0022569970065674247, 'l1_Layer_3': 0.00028678283741327384, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 10.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 11.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:54:37,080]\u001b[0m Trial 2142 finished with value: 3.623581108638472 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019281187972112182, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1086430782624936, 'dropout_rate_Layer_2': 0.3981426720040903, 'dropout_rate_Layer_3': 0.13453557977914393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001105391042073047, 'l1_Layer_2': 0.002150878295901658, 'l1_Layer_3': 0.0002852468781694957, 'n_units_Layer_1': 240, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:54:40,998]\u001b[0m Trial 2143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:16,340]\u001b[0m Trial 2144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:21,931]\u001b[0m Trial 2145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:26,595]\u001b[0m Trial 2146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:31,020]\u001b[0m Trial 2147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:35,613]\u001b[0m Trial 2148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:39,886]\u001b[0m Trial 2149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:48,110]\u001b[0m Trial 2150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:52,392]\u001b[0m Trial 2151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:55:57,429]\u001b[0m Trial 2152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:56:59,518]\u001b[0m Trial 2153 finished with value: 3.7750482980321465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005832079656740448, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13308087654769005, 'dropout_rate_Layer_2': 0.007008673934478222, 'dropout_rate_Layer_3': 0.0130455629412582, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.66387798874186e-05, 'l1_Layer_2': 1.136749989800361e-05, 'l1_Layer_3': 7.910942441648505e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.56 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:57:04,490]\u001b[0m Trial 2154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:57:08,994]\u001b[0m Trial 2155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:57:45,874]\u001b[0m Trial 2156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:57:52,034]\u001b[0m Trial 2157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:57:56,187]\u001b[0m Trial 2158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 16:59:24,054]\u001b[0m Trial 2159 finished with value: 3.702907393409331 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005073619792572466, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13390320154975321, 'dropout_rate_Layer_2': 0.018054403874338487, 'dropout_rate_Layer_3': 0.0007814182509975898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.2431602608773835e-05, 'l1_Layer_2': 1.364906133924403e-05, 'l1_Layer_3': 9.963471024248933e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 10.81% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 16:59:28,409]\u001b[0m Trial 2160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:00:10,888]\u001b[0m Trial 2161 finished with value: 3.966773131346569 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006080652617295543, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2040768290041099, 'dropout_rate_Layer_2': 0.3478672327205696, 'dropout_rate_Layer_3': 0.08824245898466887, 'dropout_rate_Layer_4': 0.026409577460763667, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017008762203332275, 'l1_Layer_2': 8.729132202658192e-05, 'l1_Layer_3': 0.0005343370835435209, 'l1_Layer_4': 0.008315734986922285, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 80}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.55 | sMAPE for Test Set is: 23.96% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:00:48,158]\u001b[0m Trial 2162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:02:32,192]\u001b[0m Trial 2163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:02:35,807]\u001b[0m Trial 2164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:02:40,291]\u001b[0m Trial 2165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:03:18,590]\u001b[0m Trial 2166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:03:22,945]\u001b[0m Trial 2167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:03:28,401]\u001b[0m Trial 2168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:03:32,432]\u001b[0m Trial 2169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:03:36,597]\u001b[0m Trial 2170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:04:16,054]\u001b[0m Trial 2171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:05:50,150]\u001b[0m Trial 2172 finished with value: 3.81297970000592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005072024543568153, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.136331567280546, 'dropout_rate_Layer_2': 0.02124370831650307, 'dropout_rate_Layer_3': 0.01084141232915309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.820282376166011e-05, 'l1_Layer_2': 1.4363585561117562e-05, 'l1_Layer_3': 0.00014084248195247502, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 11.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:05:54,605]\u001b[0m Trial 2173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:07:24,084]\u001b[0m Trial 2174 finished with value: 3.7714297659792266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005703340530329137, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1633020086768964, 'dropout_rate_Layer_2': 0.0113042411244276, 'dropout_rate_Layer_3': 0.0004499761617618067, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.107354124839855e-05, 'l1_Layer_2': 1.2179183465637815e-05, 'l1_Layer_3': 8.767263740037303e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 225}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:07:40,383]\u001b[0m Trial 2175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:17,054]\u001b[0m Trial 2176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:21,405]\u001b[0m Trial 2177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:25,316]\u001b[0m Trial 2178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:31,031]\u001b[0m Trial 2179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:45,486]\u001b[0m Trial 2180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:49,761]\u001b[0m Trial 2181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:55,348]\u001b[0m Trial 2182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:08:59,342]\u001b[0m Trial 2183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:09:05,365]\u001b[0m Trial 2184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:09:20,941]\u001b[0m Trial 2185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:09:36,642]\u001b[0m Trial 2186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:10:49,601]\u001b[0m Trial 2187 finished with value: 3.7559029873212175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005901045800280744, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1450225912272575, 'dropout_rate_Layer_2': 0.013141955549073842, 'dropout_rate_Layer_3': 0.01747643386937604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010152482317073752, 'l1_Layer_2': 5.918727648401777e-05, 'l1_Layer_3': 0.00010155611791012791, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.34 | sMAPE for Test Set is: 11.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:10:53,559]\u001b[0m Trial 2188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:10:59,136]\u001b[0m Trial 2189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:11:03,281]\u001b[0m Trial 2190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:12:14,598]\u001b[0m Trial 2191 finished with value: 3.699544524733581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023610376793972705, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11072116246120609, 'dropout_rate_Layer_2': 0.3981503598288622, 'dropout_rate_Layer_3': 0.13863667669742993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011631499932421786, 'l1_Layer_2': 0.0022580367680590865, 'l1_Layer_3': 0.00019996992156848242, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 100}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 10.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 11.12% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:12:19,253]\u001b[0m Trial 2192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:12:26,427]\u001b[0m Trial 2193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:12:31,798]\u001b[0m Trial 2194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:12:35,971]\u001b[0m Trial 2195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:13:46,899]\u001b[0m Trial 2196 finished with value: 3.75796906813119 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012764074636383, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14410368988094135, 'dropout_rate_Layer_2': 0.012700411633546226, 'dropout_rate_Layer_3': 0.015326033699676674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.435364561563472e-05, 'l1_Layer_2': 3.5642488020535674e-05, 'l1_Layer_3': 0.00010112584515251722, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.28 | sMAPE for Test Set is: 11.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:13:51,028]\u001b[0m Trial 2197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:14:32,187]\u001b[0m Trial 2198 finished with value: 3.7714789237101427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005268556483653784, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0046883390322284505, 'dropout_rate_Layer_2': 0.32210081946318037, 'dropout_rate_Layer_3': 0.10686077565016616, 'dropout_rate_Layer_4': 0.12427594786394139, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7429821167187913e-05, 'l1_Layer_2': 1.0923533159299377e-05, 'l1_Layer_3': 2.9648229239394728e-05, 'l1_Layer_4': 0.00010429593097440059, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55, 'n_units_Layer_4': 130}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:15:32,123]\u001b[0m Trial 2199 finished with value: 3.7549277494695157 and parameters: {'n_hidden': 3, 'learning_rate': 0.000502556855935667, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14726848397657336, 'dropout_rate_Layer_2': 0.012546173981455537, 'dropout_rate_Layer_3': 0.02683530765711435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001024460856166029, 'l1_Layer_2': 3.557016905794943e-05, 'l1_Layer_3': 9.597958417054116e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 215}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.95% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 11.42% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:16:36,934]\u001b[0m Trial 2200 finished with value: 3.71334326404433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029604436245999, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15319385037405323, 'dropout_rate_Layer_2': 0.007399347425433984, 'dropout_rate_Layer_3': 0.02239763727066385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011361378570131545, 'l1_Layer_2': 3.3113870409549435e-05, 'l1_Layer_3': 0.00014131972131288458, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 11.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:16:51,159]\u001b[0m Trial 2201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:16:55,750]\u001b[0m Trial 2202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:17:01,596]\u001b[0m Trial 2203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:17:16,753]\u001b[0m Trial 2204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:17:20,851]\u001b[0m Trial 2205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:17:25,695]\u001b[0m Trial 2206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:17:30,482]\u001b[0m Trial 2207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:18:51,962]\u001b[0m Trial 2208 finished with value: 3.7581955139685825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005104583143260659, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15628741264037796, 'dropout_rate_Layer_2': 0.01129113325186072, 'dropout_rate_Layer_3': 0.027808805679931544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010571169890138267, 'l1_Layer_2': 3.0349710106607674e-05, 'l1_Layer_3': 0.0001495951148044958, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.22 | sMAPE for Test Set is: 11.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:18:57,417]\u001b[0m Trial 2209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:19:01,949]\u001b[0m Trial 2210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:19:06,283]\u001b[0m Trial 2211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:19:10,041]\u001b[0m Trial 2212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:20:41,039]\u001b[0m Trial 2213 finished with value: 3.73501644450193 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005900106914932181, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15438133933436202, 'dropout_rate_Layer_2': 0.017835846513200658, 'dropout_rate_Layer_3': 0.024295121224031636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.918553602711925e-05, 'l1_Layer_2': 3.0060935519845524e-05, 'l1_Layer_3': 0.00015309171526823814, 'n_units_Layer_1': 135, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 11.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:21:58,530]\u001b[0m Trial 2214 finished with value: 3.7115568704800452 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005996414716613098, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.159249860574774, 'dropout_rate_Layer_2': 0.03120721003317272, 'dropout_rate_Layer_3': 0.029534430423264965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010951447786567328, 'l1_Layer_2': 5.161033924190329e-05, 'l1_Layer_3': 0.00016396886082702244, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.02 | sMAPE for Test Set is: 11.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:22:03,079]\u001b[0m Trial 2215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:22:10,777]\u001b[0m Trial 2216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:23:18,599]\u001b[0m Trial 2217 finished with value: 3.7502160184876216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005891290079967279, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15311570536858563, 'dropout_rate_Layer_2': 0.024795441347457592, 'dropout_rate_Layer_3': 0.024753988588361486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.389846465484482e-05, 'l1_Layer_2': 4.0933418742232914e-05, 'l1_Layer_3': 0.0001854511326364826, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 11.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:23:49,372]\u001b[0m Trial 2218 finished with value: 4.06328974795741 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010259939537659347, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24436568593237268, 'dropout_rate_Layer_2': 0.36591276802854833, 'dropout_rate_Layer_3': 0.14449415179799663, 'dropout_rate_Layer_4': 0.0004395189328610513, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09913655453456055, 'l1_Layer_2': 4.092851579331674e-05, 'l1_Layer_3': 0.0001481666823837739, 'l1_Layer_4': 0.00020085682190743866, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 60, 'n_units_Layer_4': 145}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:24:48,112]\u001b[0m Trial 2219 finished with value: 3.731443867421461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005745615654391956, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16365740730131217, 'dropout_rate_Layer_2': 0.024458733967482077, 'dropout_rate_Layer_3': 0.021292087039396352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.4611520526041185e-05, 'l1_Layer_2': 3.9816660828492614e-05, 'l1_Layer_3': 0.00018135099764296687, 'n_units_Layer_1': 140, 'n_units_Layer_2': 140, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.25 | sMAPE for Test Set is: 11.67% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:27:50,714]\u001b[0m Trial 2220 finished with value: 3.6334850873139093 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005851874058370389, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1896908242697142, 'dropout_rate_Layer_2': 0.350853902759952, 'dropout_rate_Layer_3': 0.08766236652590953, 'dropout_rate_Layer_4': 0.005348927125201111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.176408674387722e-05, 'l1_Layer_2': 0.0004269289626173263, 'l1_Layer_3': 0.0003266528180164767, 'l1_Layer_4': 0.00036513270820520135, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 275}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.63 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.16 | sMAPE for Test Set is: 11.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:27:55,092]\u001b[0m Trial 2221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:28:00,567]\u001b[0m Trial 2222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:28:05,129]\u001b[0m Trial 2223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:28:09,354]\u001b[0m Trial 2224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:29:14,759]\u001b[0m Trial 2225 finished with value: 3.751971317194472 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006043949159233306, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16040035305382688, 'dropout_rate_Layer_2': 0.07231986877694907, 'dropout_rate_Layer_3': 0.02926060292188683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001159194968536205, 'l1_Layer_2': 4.365478968517582e-05, 'l1_Layer_3': 0.00015225102180118694, 'n_units_Layer_1': 140, 'n_units_Layer_2': 140, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.15 | sMAPE for Test Set is: 11.54% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:29:52,401]\u001b[0m Trial 2226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:31:09,279]\u001b[0m Trial 2227 finished with value: 3.7676810965946483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006012843229915596, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17360905696209208, 'dropout_rate_Layer_2': 0.0308812441297949, 'dropout_rate_Layer_3': 0.030766074562431685, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.103113428391246e-05, 'l1_Layer_2': 4.4173376334978045e-05, 'l1_Layer_3': 0.00014324455875476216, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:31:23,653]\u001b[0m Trial 2228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:31:28,031]\u001b[0m Trial 2229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:33:07,023]\u001b[0m Trial 2230 finished with value: 3.7928443298171133 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008024876619559532, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21772954086515228, 'dropout_rate_Layer_2': 0.3837590233420926, 'dropout_rate_Layer_3': 0.10636413657831781, 'dropout_rate_Layer_4': 0.0673285773876009, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.056551132245532126, 'l1_Layer_2': 1.018566652284279e-05, 'l1_Layer_3': 0.00019691177600465306, 'l1_Layer_4': 0.0007885412370776517, 'n_units_Layer_1': 180, 'n_units_Layer_2': 120, 'n_units_Layer_3': 100, 'n_units_Layer_4': 175}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 21.55% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:33:11,179]\u001b[0m Trial 2231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:33:15,049]\u001b[0m Trial 2232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:34:15,699]\u001b[0m Trial 2233 finished with value: 3.753006641052289 and parameters: {'n_hidden': 3, 'learning_rate': 0.00064631510521589, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16074233965954277, 'dropout_rate_Layer_2': 0.023960293917390296, 'dropout_rate_Layer_3': 0.033418223085030244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.323593264628417e-05, 'l1_Layer_2': 5.3076098438479595e-05, 'l1_Layer_3': 0.0001868567270042308, 'n_units_Layer_1': 140, 'n_units_Layer_2': 140, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:34:21,424]\u001b[0m Trial 2234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:34:26,169]\u001b[0m Trial 2235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:34:30,249]\u001b[0m Trial 2236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:35:03,842]\u001b[0m Trial 2237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:35:07,666]\u001b[0m Trial 2238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:36:41,075]\u001b[0m Trial 2239 finished with value: 3.73910475958659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006146440458701352, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16451659230475774, 'dropout_rate_Layer_2': 0.024828011911301184, 'dropout_rate_Layer_3': 0.025327800960345426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5352663972244924e-05, 'l1_Layer_2': 5.5887589188486054e-05, 'l1_Layer_3': 0.00019218328797340374, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 10.88% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 11.13% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:37:55,282]\u001b[0m Trial 2240 finished with value: 3.644261666392037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005978966448058619, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1704083863422071, 'dropout_rate_Layer_2': 0.036668989988413676, 'dropout_rate_Layer_3': 0.024345513785336916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.899924126718617e-05, 'l1_Layer_2': 3.899014568611222e-05, 'l1_Layer_3': 0.00022070599204534466, 'n_units_Layer_1': 135, 'n_units_Layer_2': 145, 'n_units_Layer_3': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.81 | sMAPE for Test Set is: 10.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:37:59,202]\u001b[0m Trial 2241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:38:03,956]\u001b[0m Trial 2242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:38:09,162]\u001b[0m Trial 2243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:39:43,368]\u001b[0m Trial 2244 finished with value: 3.6225172420142973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023895346342013755, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1287633527112119, 'dropout_rate_Layer_2': 0.10278641230689252, 'dropout_rate_Layer_3': 0.13229737474045894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020024822966613737, 'l1_Layer_2': 0.003446029243786819, 'l1_Layer_3': 0.0003603539379738058, 'n_units_Layer_1': 230, 'n_units_Layer_2': 85, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:39:52,204]\u001b[0m Trial 2245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:40:00,338]\u001b[0m Trial 2246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:40:04,735]\u001b[0m Trial 2247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:40:08,823]\u001b[0m Trial 2248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:40:12,545]\u001b[0m Trial 2249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:41:31,864]\u001b[0m Trial 2250 finished with value: 3.69781895238372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025244794011610623, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12641816608266693, 'dropout_rate_Layer_2': 0.11812161735549594, 'dropout_rate_Layer_3': 0.13254021249214445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014050069195636018, 'l1_Layer_2': 0.003028725937131618, 'l1_Layer_3': 0.00036943884728437936, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 11.50% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:41:38,145]\u001b[0m Trial 2251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:41:44,042]\u001b[0m Trial 2252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:41:48,832]\u001b[0m Trial 2253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:41:52,616]\u001b[0m Trial 2254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:43:05,514]\u001b[0m Trial 2255 finished with value: 3.66595932688349 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006027738416679268, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1676384844893953, 'dropout_rate_Layer_2': 0.02463809267070675, 'dropout_rate_Layer_3': 0.020655052093071526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.8313576144936674e-05, 'l1_Layer_2': 5.866019065385524e-05, 'l1_Layer_3': 0.000189956686540115, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 10.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:43:42,175]\u001b[0m Trial 2256 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:44:53,558]\u001b[0m Trial 2257 finished with value: 3.6983486502175005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006871906483348723, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17392162099330105, 'dropout_rate_Layer_2': 0.024523770239629934, 'dropout_rate_Layer_3': 0.02205547770895941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.066509445659919e-05, 'l1_Layer_2': 5.935367314962379e-05, 'l1_Layer_3': 0.00017934052751299195, 'n_units_Layer_1': 135, 'n_units_Layer_2': 145, 'n_units_Layer_3': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.70 | sMAPE for Validation Set is: 10.84% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 11.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:45:01,662]\u001b[0m Trial 2258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:07,557]\u001b[0m Trial 2259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:15,930]\u001b[0m Trial 2260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:20,283]\u001b[0m Trial 2261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:24,513]\u001b[0m Trial 2262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:28,268]\u001b[0m Trial 2263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:32,595]\u001b[0m Trial 2264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:38,159]\u001b[0m Trial 2265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:42,335]\u001b[0m Trial 2266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:50,320]\u001b[0m Trial 2267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:54,503]\u001b[0m Trial 2268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:45:58,792]\u001b[0m Trial 2269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:46:57,361]\u001b[0m Trial 2270 finished with value: 3.7182153611520596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006861387259177814, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17065758783946502, 'dropout_rate_Layer_2': 0.023067387026686606, 'dropout_rate_Layer_3': 0.037386624122056164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.0438332239705136e-05, 'l1_Layer_2': 7.67950060259827e-05, 'l1_Layer_3': 0.00024365980299760113, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 10.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 11.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:47:05,238]\u001b[0m Trial 2271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:48:31,877]\u001b[0m Trial 2272 finished with value: 3.7331020605408725 and parameters: {'n_hidden': 3, 'learning_rate': 0.000694532297998097, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17005000922318272, 'dropout_rate_Layer_2': 0.02792075718407449, 'dropout_rate_Layer_3': 0.037517588518617695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.536382973785691e-05, 'l1_Layer_2': 7.526617954038273e-05, 'l1_Layer_3': 0.000205532143087433, 'n_units_Layer_1': 145, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.87% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 10.88% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:48:36,008]\u001b[0m Trial 2273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:48:40,127]\u001b[0m Trial 2274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:49:24,826]\u001b[0m Trial 2275 finished with value: 3.723904992277618 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012051094220514513, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2120382298324341, 'dropout_rate_Layer_2': 0.35034930953971627, 'dropout_rate_Layer_3': 0.15859673698593116, 'dropout_rate_Layer_4': 0.06224315379362329, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03414461824889054, 'l1_Layer_2': 1.4111989142936998e-05, 'l1_Layer_3': 0.00043800457784877526, 'l1_Layer_4': 0.0005811609711970587, 'n_units_Layer_1': 125, 'n_units_Layer_2': 125, 'n_units_Layer_3': 120, 'n_units_Layer_4': 130}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 20.76% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:49:39,886]\u001b[0m Trial 2276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:50:07,891]\u001b[0m Trial 2277 finished with value: 3.734514609257824 and parameters: {'n_hidden': 4, 'learning_rate': 0.001134232196865807, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011422420191386988, 'dropout_rate_Layer_2': 0.3197385158344985, 'dropout_rate_Layer_3': 0.13740697166436153, 'dropout_rate_Layer_4': 0.12125374411599056, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.6454215411404e-05, 'l1_Layer_2': 1.173892942312345e-05, 'l1_Layer_3': 0.00015760067805781978, 'l1_Layer_4': 9.417761564717345e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 140}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.92% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.95 | sMAPE for Test Set is: 22.32% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:50:14,269]\u001b[0m Trial 2278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:50:18,558]\u001b[0m Trial 2279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:51:10,885]\u001b[0m Trial 2280 finished with value: 3.734761883200214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006864240412563674, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17984925016466616, 'dropout_rate_Layer_2': 0.04510144932930572, 'dropout_rate_Layer_3': 0.038564432461080614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.72417772643035e-05, 'l1_Layer_2': 8.504619089173453e-05, 'l1_Layer_3': 0.00022723118836891462, 'n_units_Layer_1': 140, 'n_units_Layer_2': 145, 'n_units_Layer_3': 200}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.82% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 13.20% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:51:14,935]\u001b[0m Trial 2281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:51:20,091]\u001b[0m Trial 2282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:51:51,733]\u001b[0m Trial 2283 finished with value: 3.7495666966535968 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011386614032392096, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03028908617194316, 'dropout_rate_Layer_2': 0.24238394557431914, 'dropout_rate_Layer_3': 0.147125039987208, 'dropout_rate_Layer_4': 0.11868136267986445, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.290708782751344e-05, 'l1_Layer_2': 2.0462023340394702e-05, 'l1_Layer_3': 3.163915363397963e-05, 'l1_Layer_4': 6.770118573978311e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 75, 'n_units_Layer_4': 170}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.04 | sMAPE for Test Set is: 22.75% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:52:00,075]\u001b[0m Trial 2284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:52:07,969]\u001b[0m Trial 2285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:53:40,340]\u001b[0m Trial 2286 finished with value: 3.5703768664498567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023706667687835715, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12687258671766835, 'dropout_rate_Layer_2': 0.10248743981745125, 'dropout_rate_Layer_3': 0.1322324296330869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001383838425581632, 'l1_Layer_2': 0.0031415456153042385, 'l1_Layer_3': 0.0003700533565533476, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.05 | sMAPE for Test Set is: 11.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:53:45,252]\u001b[0m Trial 2287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:53:49,518]\u001b[0m Trial 2288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:54:45,593]\u001b[0m Trial 2289 finished with value: 3.7327533856716903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007152922188252331, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17897429573668147, 'dropout_rate_Layer_2': 0.03713597364325928, 'dropout_rate_Layer_3': 0.037553720648253464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.7835783335530365e-05, 'l1_Layer_2': 7.994494994992298e-05, 'l1_Layer_3': 0.0002449810967598482, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 200}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.29 | sMAPE for Test Set is: 11.83% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:54:49,966]\u001b[0m Trial 2290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:54:56,011]\u001b[0m Trial 2291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:55:01,192]\u001b[0m Trial 2292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:55:05,209]\u001b[0m Trial 2293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:56:26,804]\u001b[0m Trial 2294 finished with value: 3.8287853163935837 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006080793951134706, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19156562723006001, 'dropout_rate_Layer_2': 0.3496066739644279, 'dropout_rate_Layer_3': 0.08732059023174397, 'dropout_rate_Layer_4': 0.0016620072417540162, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010593539072641595, 'l1_Layer_2': 0.0004454151822663443, 'l1_Layer_3': 0.00032220239706269577, 'l1_Layer_4': 0.0003708588293099347, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140, 'n_units_Layer_4': 275}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 14.05% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:56:37,110]\u001b[0m Trial 2295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:56:41,704]\u001b[0m Trial 2296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 17:59:00,935]\u001b[0m Trial 2297 finished with value: 3.615118542827485 and parameters: {'n_hidden': 3, 'learning_rate': 0.002400255106710353, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12580249705934388, 'dropout_rate_Layer_2': 0.10245658928266467, 'dropout_rate_Layer_3': 0.13158781658398844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011700250962147745, 'l1_Layer_2': 0.00336041286368063, 'l1_Layer_3': 0.0002121030672477473, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.40% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 11.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 17:59:04,674]\u001b[0m Trial 2298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:00:02,783]\u001b[0m Trial 2299 finished with value: 3.7685607246935255 and parameters: {'n_hidden': 3, 'learning_rate': 0.000699229896843893, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17784489432683706, 'dropout_rate_Layer_2': 0.04915033917619709, 'dropout_rate_Layer_3': 0.03892339771978677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.409887669097304e-05, 'l1_Layer_2': 8.137193195165352e-05, 'l1_Layer_3': 0.00025717982460238986, 'n_units_Layer_1': 145, 'n_units_Layer_2': 150, 'n_units_Layer_3': 200}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 11.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:00:09,389]\u001b[0m Trial 2300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:00:13,706]\u001b[0m Trial 2301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:02:28,269]\u001b[0m Trial 2302 finished with value: 3.5668553224711004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018588226506197534, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12553277382952838, 'dropout_rate_Layer_2': 0.11890295633923642, 'dropout_rate_Layer_3': 0.12789037462833097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014330082598295322, 'l1_Layer_2': 0.0026597886057675665, 'l1_Layer_3': 0.0005237823406120877, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.57 | sMAPE for Validation Set is: 10.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.82 | sMAPE for Test Set is: 10.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:02:32,463]\u001b[0m Trial 2303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:03:08,659]\u001b[0m Trial 2304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:03:12,691]\u001b[0m Trial 2305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:03:16,985]\u001b[0m Trial 2306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:03:22,483]\u001b[0m Trial 2307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:03:26,466]\u001b[0m Trial 2308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:05:02,771]\u001b[0m Trial 2309 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:05:31,892]\u001b[0m Trial 2310 finished with value: 4.108250076357879 and parameters: {'n_hidden': 4, 'learning_rate': 0.001236629652852989, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2125783958631945, 'dropout_rate_Layer_2': 0.35256681484505076, 'dropout_rate_Layer_3': 0.15613755777037608, 'dropout_rate_Layer_4': 0.07924291382330509, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05599817020952957, 'l1_Layer_2': 1.451046997234632e-05, 'l1_Layer_3': 0.0004347580266968885, 'l1_Layer_4': 0.000481102192404495, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 120, 'n_units_Layer_4': 120}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.50 | sMAPE for Test Set is: 21.28% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:06:08,944]\u001b[0m Trial 2311 finished with value: 3.6835344460512225 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005143715581669229, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0556014963095417, 'dropout_rate_Layer_2': 0.325569766786437, 'dropout_rate_Layer_3': 0.10527728742875689, 'dropout_rate_Layer_4': 0.083045363990538, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0323395450275636e-05, 'l1_Layer_2': 2.0340152794607917e-05, 'l1_Layer_3': 0.00016311485869344302, 'l1_Layer_4': 0.00043668489449462714, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 100}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 10.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 15.42% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:06:12,984]\u001b[0m Trial 2312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:06:17,576]\u001b[0m Trial 2313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:06:32,910]\u001b[0m Trial 2314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:06:36,962]\u001b[0m Trial 2315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:06:41,581]\u001b[0m Trial 2316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:06:56,904]\u001b[0m Trial 2317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:07:00,857]\u001b[0m Trial 2318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:07:06,501]\u001b[0m Trial 2319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:07:10,774]\u001b[0m Trial 2320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:08:57,343]\u001b[0m Trial 2321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:09:01,600]\u001b[0m Trial 2322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:09:05,921]\u001b[0m Trial 2323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:10:22,108]\u001b[0m Trial 2324 finished with value: 3.75110586567742 and parameters: {'n_hidden': 3, 'learning_rate': 0.000740953489766658, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18272000908687272, 'dropout_rate_Layer_2': 0.024069939999310338, 'dropout_rate_Layer_3': 0.03644739907530831, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.849839682774675e-05, 'l1_Layer_2': 9.802572242156297e-05, 'l1_Layer_3': 0.000316448544128446, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 195}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 11.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:10:30,666]\u001b[0m Trial 2325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:10:34,410]\u001b[0m Trial 2326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:10:39,088]\u001b[0m Trial 2327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:11:30,227]\u001b[0m Trial 2328 finished with value: 3.7806470933883993 and parameters: {'n_hidden': 3, 'learning_rate': 0.000682371792131544, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16855460451800883, 'dropout_rate_Layer_2': 0.04135999151482814, 'dropout_rate_Layer_3': 0.045446835932066436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.915545975605535e-05, 'l1_Layer_2': 7.709030130115083e-05, 'l1_Layer_3': 0.00019873619656935048, 'n_units_Layer_1': 145, 'n_units_Layer_2': 140, 'n_units_Layer_3': 200}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 10.99% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.51 | sMAPE for Test Set is: 12.23% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:11:33,913]\u001b[0m Trial 2329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:13:44,811]\u001b[0m Trial 2330 finished with value: 3.539858012918654 and parameters: {'n_hidden': 3, 'learning_rate': 0.001725999853469484, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12935273851101683, 'dropout_rate_Layer_2': 0.12148371893667921, 'dropout_rate_Layer_3': 0.1238535020199203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00149727882843011, 'l1_Layer_2': 0.003253714632214283, 'l1_Layer_3': 0.00038616994123482793, 'n_units_Layer_1': 230, 'n_units_Layer_2': 75, 'n_units_Layer_3': 110}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.54 | sMAPE for Validation Set is: 10.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 4.90 | sMAPE for Test Set is: 10.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:13:49,923]\u001b[0m Trial 2331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:13:55,541]\u001b[0m Trial 2332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:13:59,756]\u001b[0m Trial 2333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:14:35,629]\u001b[0m Trial 2334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:14:39,726]\u001b[0m Trial 2335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:14:43,831]\u001b[0m Trial 2336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:14:48,526]\u001b[0m Trial 2337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:14:56,046]\u001b[0m Trial 2338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:00,674]\u001b[0m Trial 2339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:05,350]\u001b[0m Trial 2340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:09,931]\u001b[0m Trial 2341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:15,698]\u001b[0m Trial 2342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:21,317]\u001b[0m Trial 2343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:26,814]\u001b[0m Trial 2344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:15:30,488]\u001b[0m Trial 2345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:18:27,284]\u001b[0m Trial 2346 finished with value: 3.662979761581848 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006801547155766228, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20927562647395648, 'dropout_rate_Layer_2': 0.3243696991996203, 'dropout_rate_Layer_3': 0.10318419302174081, 'dropout_rate_Layer_4': 0.023340449575766916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.302512159980488e-05, 'l1_Layer_2': 0.00043746025034830787, 'l1_Layer_3': 0.0002661776245230242, 'l1_Layer_4': 0.00044034583462557316, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130, 'n_units_Layer_4': 280}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 10.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 10.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:18:31,866]\u001b[0m Trial 2347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:18:47,000]\u001b[0m Trial 2348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:18:51,982]\u001b[0m Trial 2349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:15,905]\u001b[0m Trial 2350 finished with value: 3.5982852679080364 and parameters: {'n_hidden': 3, 'learning_rate': 0.001684677294097452, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13263219390118608, 'dropout_rate_Layer_2': 0.12037317365587893, 'dropout_rate_Layer_3': 0.12108746090895713, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010214402968773762, 'l1_Layer_2': 0.003752302734941758, 'l1_Layer_3': 0.0002683685818605708, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 10.42% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:21:19,508]\u001b[0m Trial 2351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:27,233]\u001b[0m Trial 2352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:31,538]\u001b[0m Trial 2353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:35,735]\u001b[0m Trial 2354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:40,314]\u001b[0m Trial 2355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:45,680]\u001b[0m Trial 2356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:49,887]\u001b[0m Trial 2357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:21:54,742]\u001b[0m Trial 2358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:22:33,632]\u001b[0m Trial 2359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:23:08,659]\u001b[0m Trial 2360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:23:47,408]\u001b[0m Trial 2361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:23:55,432]\u001b[0m Trial 2362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:24:03,401]\u001b[0m Trial 2363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:24:07,212]\u001b[0m Trial 2364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:24:13,690]\u001b[0m Trial 2365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:24:17,527]\u001b[0m Trial 2366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:26:43,123]\u001b[0m Trial 2367 finished with value: 3.6122165091965677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015382411610671471, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1347642964260102, 'dropout_rate_Layer_2': 0.12218899262118776, 'dropout_rate_Layer_3': 0.11653863808298362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012700862980578203, 'l1_Layer_2': 0.0028473073706039107, 'l1_Layer_3': 0.00021997133541448103, 'n_units_Layer_1': 230, 'n_units_Layer_2': 85, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 10.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:26:47,985]\u001b[0m Trial 2368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:29:16,236]\u001b[0m Trial 2369 finished with value: 3.649875572837709 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005554123711266923, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2050700377811288, 'dropout_rate_Layer_2': 0.348857071712231, 'dropout_rate_Layer_3': 0.09304986964395867, 'dropout_rate_Layer_4': 0.025840619401329704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.479649377962494e-05, 'l1_Layer_2': 0.0004202085884218317, 'l1_Layer_3': 0.00026294549187147497, 'l1_Layer_4': 0.0004084413517092747, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130, 'n_units_Layer_4': 285}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 10.55% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.92 | sMAPE for Test Set is: 10.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:29:21,689]\u001b[0m Trial 2370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:31:03,846]\u001b[0m Trial 2371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:31:09,015]\u001b[0m Trial 2372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:31:12,870]\u001b[0m Trial 2373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:31:17,361]\u001b[0m Trial 2374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:31:22,859]\u001b[0m Trial 2375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:31:30,974]\u001b[0m Trial 2376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:32:41,741]\u001b[0m Trial 2377 finished with value: 3.6436053788950544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006377359964201965, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1606084780459474, 'dropout_rate_Layer_2': 0.029899595941489693, 'dropout_rate_Layer_3': 0.02859972181994315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.319355287736658e-05, 'l1_Layer_2': 5.472586364299587e-05, 'l1_Layer_3': 0.0002115967927953233, 'n_units_Layer_1': 135, 'n_units_Layer_2': 145, 'n_units_Layer_3': 195}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 10.95% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:32:45,598]\u001b[0m Trial 2378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:33:36,732]\u001b[0m Trial 2379 finished with value: 3.9746290368740786 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006496189459073439, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17832977391014498, 'dropout_rate_Layer_2': 0.3647334506283129, 'dropout_rate_Layer_3': 0.08498773904953943, 'dropout_rate_Layer_4': 0.028267687765632904, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.038975857627819105, 'l1_Layer_2': 1.925696251252956e-05, 'l1_Layer_3': 0.00030951541078226157, 'l1_Layer_4': 0.0007236646186274733, 'n_units_Layer_1': 210, 'n_units_Layer_2': 120, 'n_units_Layer_3': 135, 'n_units_Layer_4': 95}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.97 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 21.24% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:33:41,815]\u001b[0m Trial 2380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:33:45,738]\u001b[0m Trial 2381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:34:22,123]\u001b[0m Trial 2382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:34:31,214]\u001b[0m Trial 2383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:34:34,785]\u001b[0m Trial 2384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:34:50,201]\u001b[0m Trial 2385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:37:27,036]\u001b[0m Trial 2386 finished with value: 3.6803457244503655 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005608861190106002, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21148349064505526, 'dropout_rate_Layer_2': 0.32499242945873424, 'dropout_rate_Layer_3': 0.09345670544986152, 'dropout_rate_Layer_4': 0.020242962804163888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.766534021757012e-05, 'l1_Layer_2': 0.00045585783968558376, 'l1_Layer_3': 0.00024759162940497754, 'l1_Layer_4': 0.00047906994135152835, 'n_units_Layer_1': 60, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115, 'n_units_Layer_4': 285}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.68 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 11.33% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:37:31,779]\u001b[0m Trial 2387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:37:46,663]\u001b[0m Trial 2388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:37:51,003]\u001b[0m Trial 2389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:37:55,156]\u001b[0m Trial 2390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:39:40,317]\u001b[0m Trial 2391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:39:48,059]\u001b[0m Trial 2392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:23,398]\u001b[0m Trial 2393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:31,276]\u001b[0m Trial 2394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:36,311]\u001b[0m Trial 2395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:40,693]\u001b[0m Trial 2396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:45,489]\u001b[0m Trial 2397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:54,065]\u001b[0m Trial 2398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:40:58,047]\u001b[0m Trial 2399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:41:03,255]\u001b[0m Trial 2400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:41:39,748]\u001b[0m Trial 2401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:41:47,680]\u001b[0m Trial 2402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:41:52,882]\u001b[0m Trial 2403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:41:57,566]\u001b[0m Trial 2404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:42:01,711]\u001b[0m Trial 2405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:42:06,355]\u001b[0m Trial 2406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:42:10,536]\u001b[0m Trial 2407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:42:18,665]\u001b[0m Trial 2408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:42:32,036]\u001b[0m Trial 2409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:43:09,236]\u001b[0m Trial 2410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:43:16,892]\u001b[0m Trial 2411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:43:21,085]\u001b[0m Trial 2412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:43:53,901]\u001b[0m Trial 2413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:43:57,897]\u001b[0m Trial 2414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:44:02,845]\u001b[0m Trial 2415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:44:10,467]\u001b[0m Trial 2416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:44:18,227]\u001b[0m Trial 2417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:44:24,090]\u001b[0m Trial 2418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:46:33,522]\u001b[0m Trial 2419 finished with value: 3.6747578466848734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019320751421692598, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1298796534345048, 'dropout_rate_Layer_2': 0.1251606163257209, 'dropout_rate_Layer_3': 0.12116192123882485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000802615957749838, 'l1_Layer_2': 0.0035318052258444576, 'l1_Layer_3': 0.00023539513507455422, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 10.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:46:41,239]\u001b[0m Trial 2420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:46:48,623]\u001b[0m Trial 2421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:46:56,162]\u001b[0m Trial 2422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:47:02,008]\u001b[0m Trial 2423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:47:34,897]\u001b[0m Trial 2424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:47:39,256]\u001b[0m Trial 2425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:48:13,782]\u001b[0m Trial 2426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:48:17,369]\u001b[0m Trial 2427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:50:55,497]\u001b[0m Trial 2428 finished with value: 3.6408658586267655 and parameters: {'n_hidden': 4, 'learning_rate': 0.000684530896930279, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2074042790614593, 'dropout_rate_Layer_2': 0.3232146452502698, 'dropout_rate_Layer_3': 0.09230899959801417, 'dropout_rate_Layer_4': 0.00021704199921175268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.7601812536378045e-05, 'l1_Layer_2': 0.0006863225453770125, 'l1_Layer_3': 0.00026562991243039586, 'l1_Layer_4': 0.00036958855987178485, 'n_units_Layer_1': 55, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130, 'n_units_Layer_4': 300}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:51:01,928]\u001b[0m Trial 2429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:17,103]\u001b[0m Trial 2430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:20,962]\u001b[0m Trial 2431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:29,104]\u001b[0m Trial 2432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:33,635]\u001b[0m Trial 2433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:48,009]\u001b[0m Trial 2434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:55,675]\u001b[0m Trial 2435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:51:59,913]\u001b[0m Trial 2436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:52:14,744]\u001b[0m Trial 2437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:52:19,959]\u001b[0m Trial 2438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:52:24,898]\u001b[0m Trial 2439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:52:31,400]\u001b[0m Trial 2440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:52:35,647]\u001b[0m Trial 2441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:52:40,118]\u001b[0m Trial 2442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:53:19,483]\u001b[0m Trial 2443 finished with value: 3.7501916830455344 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007099256228265651, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048829025758966506, 'dropout_rate_Layer_2': 0.32050923497100586, 'dropout_rate_Layer_3': 0.16511234573786915, 'dropout_rate_Layer_4': 0.16720858184741205, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5987519604058688e-05, 'l1_Layer_2': 3.223528173091827e-05, 'l1_Layer_3': 0.00014130121452980306, 'l1_Layer_4': 0.0004436742635296657, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 75, 'n_units_Layer_4': 165}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 16.17% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:53:24,174]\u001b[0m Trial 2444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:53:38,932]\u001b[0m Trial 2445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:53:44,945]\u001b[0m Trial 2446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:53:48,487]\u001b[0m Trial 2447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:53:53,097]\u001b[0m Trial 2448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:53:58,595]\u001b[0m Trial 2449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:02,834]\u001b[0m Trial 2450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:06,909]\u001b[0m Trial 2451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:11,364]\u001b[0m Trial 2452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:26,923]\u001b[0m Trial 2453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:30,980]\u001b[0m Trial 2454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:35,267]\u001b[0m Trial 2455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:41,068]\u001b[0m Trial 2456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:54:49,451]\u001b[0m Trial 2457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:55:04,569]\u001b[0m Trial 2458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 18:56:30,287]\u001b[0m Trial 2459 finished with value: 3.7426882247152276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019845487883527386, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13664444516076837, 'dropout_rate_Layer_2': 0.07925092675699985, 'dropout_rate_Layer_3': 0.11821242420700546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025803647692114315, 'l1_Layer_2': 0.004490923179508946, 'l1_Layer_3': 0.00047505869732120966, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 13.48% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 18:56:35,073]\u001b[0m Trial 2460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:00:09,737]\u001b[0m Trial 2461 finished with value: 3.6237019468330582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005718266235973475, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15246623824733013, 'dropout_rate_Layer_2': 0.17481142361749255, 'dropout_rate_Layer_3': 0.32762274449721596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022581604533619625, 'l1_Layer_2': 4.659043767129126e-05, 'l1_Layer_3': 0.00019041592105584155, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 10.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:00:14,349]\u001b[0m Trial 2462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:00:19,451]\u001b[0m Trial 2463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:00:34,783]\u001b[0m Trial 2464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:00:39,902]\u001b[0m Trial 2465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:00:44,297]\u001b[0m Trial 2466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:02:24,816]\u001b[0m Trial 2467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:02:31,996]\u001b[0m Trial 2468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:04:18,292]\u001b[0m Trial 2469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:04:22,544]\u001b[0m Trial 2470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:04:27,485]\u001b[0m Trial 2471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:04:34,593]\u001b[0m Trial 2472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:06:21,081]\u001b[0m Trial 2473 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:06:28,582]\u001b[0m Trial 2474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:06:32,582]\u001b[0m Trial 2475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:06:37,016]\u001b[0m Trial 2476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:06:52,517]\u001b[0m Trial 2477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:06:56,022]\u001b[0m Trial 2478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:07:01,468]\u001b[0m Trial 2479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:07:17,296]\u001b[0m Trial 2480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:07:21,413]\u001b[0m Trial 2481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:07:27,576]\u001b[0m Trial 2482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:07:31,969]\u001b[0m Trial 2483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:09:16,059]\u001b[0m Trial 2484 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:09:20,193]\u001b[0m Trial 2485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:09:26,344]\u001b[0m Trial 2486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:09:31,773]\u001b[0m Trial 2487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:11:09,131]\u001b[0m Trial 2488 finished with value: 3.6432690331611775 and parameters: {'n_hidden': 3, 'learning_rate': 0.001640648737358009, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13156567842090067, 'dropout_rate_Layer_2': 0.10115495406215458, 'dropout_rate_Layer_3': 0.12352882717294937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00210032734429551, 'l1_Layer_2': 0.003269595884590826, 'l1_Layer_3': 0.00022306447307993433, 'n_units_Layer_1': 230, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.99 | sMAPE for Test Set is: 11.07% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:11:13,135]\u001b[0m Trial 2489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:11:50,095]\u001b[0m Trial 2490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:12:27,312]\u001b[0m Trial 2491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:12:31,681]\u001b[0m Trial 2492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:12:39,733]\u001b[0m Trial 2493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:12:47,257]\u001b[0m Trial 2494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:13:03,206]\u001b[0m Trial 2495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:13:08,109]\u001b[0m Trial 2496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:13:38,505]\u001b[0m Trial 2497 finished with value: 3.7557773971868404 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010189739972471345, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02060088657920406, 'dropout_rate_Layer_2': 0.266522778812451, 'dropout_rate_Layer_3': 0.1132061299795478, 'dropout_rate_Layer_4': 0.0691705108464252, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.8648598962172285e-05, 'l1_Layer_2': 1.7613173927873957e-05, 'l1_Layer_3': 0.00014215127000569784, 'l1_Layer_4': 0.0003102668004441881, 'n_units_Layer_1': 115, 'n_units_Layer_2': 225, 'n_units_Layer_3': 65, 'n_units_Layer_4': 95}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 10.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 14.38% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:13:43,285]\u001b[0m Trial 2498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:13:47,420]\u001b[0m Trial 2499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:13:53,671]\u001b[0m Trial 2500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:13:57,805]\u001b[0m Trial 2501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:14:01,705]\u001b[0m Trial 2502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:14:06,514]\u001b[0m Trial 2503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:14:21,863]\u001b[0m Trial 2504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:15:53,814]\u001b[0m Trial 2505 finished with value: 3.666759906068195 and parameters: {'n_hidden': 3, 'learning_rate': 0.001661738495118467, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11944429598649434, 'dropout_rate_Layer_2': 0.1156198664009012, 'dropout_rate_Layer_3': 0.10643419424577526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022023979084657146, 'l1_Layer_2': 0.0033361805908047066, 'l1_Layer_3': 0.0002362787847560436, 'n_units_Layer_1': 225, 'n_units_Layer_2': 90, 'n_units_Layer_3': 100}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 10.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.26 | sMAPE for Test Set is: 11.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:17:21,712]\u001b[0m Trial 2506 finished with value: 3.5853823079121625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014190006594510512, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1160382958780266, 'dropout_rate_Layer_2': 0.09136267359929359, 'dropout_rate_Layer_3': 0.10306183992235984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021129805782132524, 'l1_Layer_2': 0.004603215007971458, 'l1_Layer_3': 0.00020482607033550093, 'n_units_Layer_1': 225, 'n_units_Layer_2': 65, 'n_units_Layer_3': 100}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 10.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.98 | sMAPE for Test Set is: 11.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:17:26,773]\u001b[0m Trial 2507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:17:32,499]\u001b[0m Trial 2508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:17:47,858]\u001b[0m Trial 2509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:06,751]\u001b[0m Trial 2510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:10,687]\u001b[0m Trial 2511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:15,633]\u001b[0m Trial 2512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:21,849]\u001b[0m Trial 2513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:26,043]\u001b[0m Trial 2514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:34,598]\u001b[0m Trial 2515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:38,998]\u001b[0m Trial 2516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:44,223]\u001b[0m Trial 2517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:20:50,217]\u001b[0m Trial 2518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:22:50,074]\u001b[0m Trial 2519 finished with value: 3.6588127823648513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014553322501246197, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11385244523710054, 'dropout_rate_Layer_2': 0.09212552485060461, 'dropout_rate_Layer_3': 0.11381775763581548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0026148216363767523, 'l1_Layer_2': 0.004786916796184963, 'l1_Layer_3': 0.00013683267164988258, 'n_units_Layer_1': 105, 'n_units_Layer_2': 85, 'n_units_Layer_3': 60}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.94 | sMAPE for Test Set is: 10.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:22:55,138]\u001b[0m Trial 2520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:23:04,513]\u001b[0m Trial 2521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:23:08,946]\u001b[0m Trial 2522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:24:35,229]\u001b[0m Trial 2523 finished with value: 3.64020329167723 and parameters: {'n_hidden': 3, 'learning_rate': 0.001446424872978914, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1151887162351698, 'dropout_rate_Layer_2': 0.09431629892447457, 'dropout_rate_Layer_3': 0.10828928102735247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027065796343210824, 'l1_Layer_2': 0.005147151532315236, 'l1_Layer_3': 0.00011589490095550567, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 10.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:25:21,781]\u001b[0m Trial 2524 finished with value: 3.7766561243032393 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008885778092307433, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20893108928315704, 'dropout_rate_Layer_2': 0.38596759046571505, 'dropout_rate_Layer_3': 0.11027276396804608, 'dropout_rate_Layer_4': 0.06029895396886416, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.03146021324637202, 'l1_Layer_2': 1.2286758417656806e-05, 'l1_Layer_3': 0.0007440502499828516, 'l1_Layer_4': 0.0017804356203000283, 'n_units_Layer_1': 125, 'n_units_Layer_2': 135, 'n_units_Layer_3': 115, 'n_units_Layer_4': 140}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.78 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:25:26,697]\u001b[0m Trial 2525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:11,199]\u001b[0m Trial 2526 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:16,723]\u001b[0m Trial 2527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:21,466]\u001b[0m Trial 2528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:25,728]\u001b[0m Trial 2529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:30,778]\u001b[0m Trial 2530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:39,131]\u001b[0m Trial 2531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:43,604]\u001b[0m Trial 2532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:47,786]\u001b[0m Trial 2533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:27:52,226]\u001b[0m Trial 2534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:28:00,227]\u001b[0m Trial 2535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:28:08,201]\u001b[0m Trial 2536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:28:15,830]\u001b[0m Trial 2537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:28:23,977]\u001b[0m Trial 2538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:29:18,245]\u001b[0m Trial 2539 finished with value: 3.9897462990164096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007622387860702501, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2030081845110064, 'dropout_rate_Layer_2': 0.37205343350295184, 'dropout_rate_Layer_3': 0.09266676584828892, 'dropout_rate_Layer_4': 0.024603973376006553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 8.613169012872185e-05, 'l1_Layer_2': 0.00034956222974955547, 'l1_Layer_3': 0.00014335264766961113, 'l1_Layer_4': 0.0007266052513484129, 'n_units_Layer_1': 70, 'n_units_Layer_2': 285, 'n_units_Layer_3': 160, 'n_units_Layer_4': 280}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:29:22,469]\u001b[0m Trial 2540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:29:38,884]\u001b[0m Trial 2541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:29:43,483]\u001b[0m Trial 2542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:29:48,935]\u001b[0m Trial 2543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:29:52,922]\u001b[0m Trial 2544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:31:26,941]\u001b[0m Trial 2545 finished with value: 3.6536236048588324 and parameters: {'n_hidden': 3, 'learning_rate': 0.001334850017330605, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12116776672007898, 'dropout_rate_Layer_2': 0.10225461216333923, 'dropout_rate_Layer_3': 0.1120389270494734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032144545635804283, 'l1_Layer_2': 0.005430857728845552, 'l1_Layer_3': 0.00015311965548721017, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 60}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 10.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.08 | sMAPE for Test Set is: 11.20% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:31:32,516]\u001b[0m Trial 2546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:31:47,681]\u001b[0m Trial 2547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:34:33,006]\u001b[0m Trial 2548 finished with value: 3.6893736936970574 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006640001735880917, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22724499663488282, 'dropout_rate_Layer_2': 0.38436074808714527, 'dropout_rate_Layer_3': 0.12115514491988864, 'dropout_rate_Layer_4': 0.008828858736817631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 7.473286950597632e-05, 'l1_Layer_2': 0.0006146309444286441, 'l1_Layer_3': 0.00024334580142648492, 'l1_Layer_4': 0.0002463066917302443, 'n_units_Layer_1': 65, 'n_units_Layer_2': 265, 'n_units_Layer_3': 105, 'n_units_Layer_4': 260}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 11.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:34:40,792]\u001b[0m Trial 2549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:34:46,758]\u001b[0m Trial 2550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:38:04,886]\u001b[0m Trial 2551 finished with value: 3.5466234724659276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015856624691077488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12290946955804094, 'dropout_rate_Layer_2': 0.10394155923380126, 'dropout_rate_Layer_3': 0.10102541067199429, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022759198635482177, 'l1_Layer_2': 0.006330613935708084, 'l1_Layer_3': 0.0002273438862222701, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 65}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.13 | sMAPE for Test Set is: 11.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:40:15,739]\u001b[0m Trial 2552 finished with value: 3.6882900377492 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005923179996454778, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18732249914697363, 'dropout_rate_Layer_2': 0.36712414872299776, 'dropout_rate_Layer_3': 0.10638284985144593, 'dropout_rate_Layer_4': 0.035223118554314085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.567568868676567e-05, 'l1_Layer_2': 0.0007065256338458066, 'l1_Layer_3': 0.0005864905404547081, 'l1_Layer_4': 0.0012868554526212547, 'n_units_Layer_1': 50, 'n_units_Layer_2': 285, 'n_units_Layer_3': 90, 'n_units_Layer_4': 300}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:40:20,284]\u001b[0m Trial 2553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:40:28,510]\u001b[0m Trial 2554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:40:32,942]\u001b[0m Trial 2555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:40:37,114]\u001b[0m Trial 2556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:40:45,744]\u001b[0m Trial 2557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:40:51,389]\u001b[0m Trial 2558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:40:56,508]\u001b[0m Trial 2559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:41:00,565]\u001b[0m Trial 2560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:41:09,163]\u001b[0m Trial 2561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:41:17,156]\u001b[0m Trial 2562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:42:39,792]\u001b[0m Trial 2563 finished with value: 3.7682906564254335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015873636505626355, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12868486353717473, 'dropout_rate_Layer_2': 0.07345384605213187, 'dropout_rate_Layer_3': 0.09750834041258356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002200437930556728, 'l1_Layer_2': 0.0028454645872360153, 'l1_Layer_3': 0.00021864309100523663, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 70}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.10 | sMAPE for Test Set is: 11.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:42:44,059]\u001b[0m Trial 2564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:44:20,984]\u001b[0m Trial 2565 finished with value: 3.7128056587009683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016538226630337686, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15284853419075056, 'dropout_rate_Layer_2': 0.10619349147733609, 'dropout_rate_Layer_3': 0.1019729001906056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017445554750731564, 'l1_Layer_2': 0.006222891468625484, 'l1_Layer_3': 0.00012239258996386986, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.73% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:44:24,901]\u001b[0m Trial 2566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:44:29,026]\u001b[0m Trial 2567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:44:34,434]\u001b[0m Trial 2568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:44:42,604]\u001b[0m Trial 2569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:45:24,551]\u001b[0m Trial 2570 finished with value: 3.7594254985024365 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006661540234470913, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06641275325974452, 'dropout_rate_Layer_2': 0.27473306426675537, 'dropout_rate_Layer_3': 0.09201948129513249, 'dropout_rate_Layer_4': 0.16519255789972845, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0700503755554018e-05, 'l1_Layer_2': 4.35346762100007e-05, 'l1_Layer_3': 0.000653105002132389, 'l1_Layer_4': 0.0004931917467285049, 'n_units_Layer_1': 155, 'n_units_Layer_2': 70, 'n_units_Layer_3': 90, 'n_units_Layer_4': 90}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.76 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:45:33,194]\u001b[0m Trial 2571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:47:19,356]\u001b[0m Trial 2572 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:47:25,037]\u001b[0m Trial 2573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:47:30,950]\u001b[0m Trial 2574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:49:07,587]\u001b[0m Trial 2575 finished with value: 3.6895783669544553 and parameters: {'n_hidden': 4, 'learning_rate': 0.000871361246278832, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2055023153451815, 'dropout_rate_Layer_2': 0.32732612629829216, 'dropout_rate_Layer_3': 0.11357212905213596, 'dropout_rate_Layer_4': 0.06563118855480225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012014456911608452, 'l1_Layer_2': 0.0012331380825907586, 'l1_Layer_3': 0.0002016594369662557, 'l1_Layer_4': 0.00021386995536652737, 'n_units_Layer_1': 55, 'n_units_Layer_2': 295, 'n_units_Layer_3': 130, 'n_units_Layer_4': 285}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.21 | sMAPE for Test Set is: 11.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:49:12,365]\u001b[0m Trial 2576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:49:15,815]\u001b[0m Trial 2577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:49:19,564]\u001b[0m Trial 2578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:49:28,276]\u001b[0m Trial 2579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:49:32,557]\u001b[0m Trial 2580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:50:06,196]\u001b[0m Trial 2581 finished with value: 3.6056627724956525 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009777796478441304, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0030423395167314864, 'dropout_rate_Layer_2': 0.3254640179925256, 'dropout_rate_Layer_3': 0.13153882487067653, 'dropout_rate_Layer_4': 0.05879711934309945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011855525564194492, 'l1_Layer_2': 2.0036284714669304e-05, 'l1_Layer_3': 5.2491738594148125e-05, 'l1_Layer_4': 4.213677216708599e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 145}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:50:14,702]\u001b[0m Trial 2582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:50:18,701]\u001b[0m Trial 2583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:50:22,964]\u001b[0m Trial 2584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:50:35,931]\u001b[0m Trial 2585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:50:52,079]\u001b[0m Trial 2586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:50:59,330]\u001b[0m Trial 2587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:51:03,962]\u001b[0m Trial 2588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:51:08,331]\u001b[0m Trial 2589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:51:25,090]\u001b[0m Trial 2590 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:51:31,229]\u001b[0m Trial 2591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:51:40,420]\u001b[0m Trial 2592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:52:22,861]\u001b[0m Trial 2593 finished with value: 3.656678399320422 and parameters: {'n_hidden': 4, 'learning_rate': 0.002464012678426499, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0010029309921204131, 'dropout_rate_Layer_2': 0.23560719257805485, 'dropout_rate_Layer_3': 0.16798636703828396, 'dropout_rate_Layer_4': 0.05594189209789547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001550537373016756, 'l1_Layer_2': 2.4928841257957558e-05, 'l1_Layer_3': 7.983046944044058e-05, 'l1_Layer_4': 4.163285680855725e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 285, 'n_units_Layer_3': 90, 'n_units_Layer_4': 185}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 10.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.30 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:52:38,610]\u001b[0m Trial 2594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:11,885]\u001b[0m Trial 2595 finished with value: 3.641767703962948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014493230929424495, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07740310517175608, 'dropout_rate_Layer_2': 0.11336594856398599, 'dropout_rate_Layer_3': 0.14334991644489337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017176238027935434, 'l1_Layer_2': 0.006440497595738835, 'l1_Layer_3': 0.0005889909051748954, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.60% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:54:16,315]\u001b[0m Trial 2596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:22,124]\u001b[0m Trial 2597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:25,961]\u001b[0m Trial 2598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:31,053]\u001b[0m Trial 2599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:37,424]\u001b[0m Trial 2600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:41,942]\u001b[0m Trial 2601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:49,732]\u001b[0m Trial 2602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:54,370]\u001b[0m Trial 2603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:54:59,776]\u001b[0m Trial 2604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:04,753]\u001b[0m Trial 2605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:08,837]\u001b[0m Trial 2606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:13,144]\u001b[0m Trial 2607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:29,109]\u001b[0m Trial 2608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:32,691]\u001b[0m Trial 2609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:37,611]\u001b[0m Trial 2610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:42,882]\u001b[0m Trial 2611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:49,167]\u001b[0m Trial 2612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:53,808]\u001b[0m Trial 2613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:55:58,717]\u001b[0m Trial 2614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:56:04,545]\u001b[0m Trial 2615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:57:43,344]\u001b[0m Trial 2616 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:57:58,145]\u001b[0m Trial 2617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:58:02,075]\u001b[0m Trial 2618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:58:08,449]\u001b[0m Trial 2619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:58:12,592]\u001b[0m Trial 2620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:59:44,792]\u001b[0m Trial 2621 finished with value: 3.6116510889383666 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009617793368063269, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007814710732711892, 'dropout_rate_Layer_2': 0.019366701857177496, 'dropout_rate_Layer_3': 0.2808575084015023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.489071877537236e-05, 'l1_Layer_2': 0.00011549352845678707, 'l1_Layer_3': 0.0031201397713182485, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 10.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.85 | sMAPE for Test Set is: 10.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 19:59:50,869]\u001b[0m Trial 2622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 19:59:58,671]\u001b[0m Trial 2623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:01:33,512]\u001b[0m Trial 2624 finished with value: 3.636816477642379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014769691961593607, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07545907302794774, 'dropout_rate_Layer_2': 0.10246530156614476, 'dropout_rate_Layer_3': 0.13021310459156288, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002497689648246297, 'l1_Layer_2': 0.006294987717371857, 'l1_Layer_3': 0.0004535294241074588, 'n_units_Layer_1': 110, 'n_units_Layer_2': 70, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.14 | sMAPE for Test Set is: 11.47% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:01:40,945]\u001b[0m Trial 2625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:01:46,367]\u001b[0m Trial 2626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:01:52,507]\u001b[0m Trial 2627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:03:54,550]\u001b[0m Trial 2628 finished with value: 3.6072275152419535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015130138731199476, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08333458210146097, 'dropout_rate_Layer_2': 0.11074658122008836, 'dropout_rate_Layer_3': 0.14771773495989635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031865231416264637, 'l1_Layer_2': 0.007215318581252842, 'l1_Layer_3': 0.0004569969353321463, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 65}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.61 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.01 | sMAPE for Test Set is: 11.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:04:00,273]\u001b[0m Trial 2629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:05,705]\u001b[0m Trial 2630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:09,904]\u001b[0m Trial 2631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:14,217]\u001b[0m Trial 2632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:19,273]\u001b[0m Trial 2633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:24,486]\u001b[0m Trial 2634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:29,436]\u001b[0m Trial 2635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:34,188]\u001b[0m Trial 2636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:38,706]\u001b[0m Trial 2637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:04:43,227]\u001b[0m Trial 2638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:05:22,609]\u001b[0m Trial 2639 finished with value: 3.691954255334936 and parameters: {'n_hidden': 4, 'learning_rate': 0.002195432030007926, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04108295937127259, 'dropout_rate_Layer_2': 0.23619477247286513, 'dropout_rate_Layer_3': 0.18714252092844866, 'dropout_rate_Layer_4': 0.05571181199895833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001552493007493902, 'l1_Layer_2': 5.3762087258543596e-05, 'l1_Layer_3': 8.376364517292479e-05, 'l1_Layer_4': 2.8775051045735115e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 285, 'n_units_Layer_3': 95, 'n_units_Layer_4': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.09 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:05:54,244]\u001b[0m Trial 2640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:05:59,461]\u001b[0m Trial 2641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:05,520]\u001b[0m Trial 2642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:13,251]\u001b[0m Trial 2643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:17,446]\u001b[0m Trial 2644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:21,469]\u001b[0m Trial 2645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:27,300]\u001b[0m Trial 2646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:32,134]\u001b[0m Trial 2647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:38,030]\u001b[0m Trial 2648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:42,671]\u001b[0m Trial 2649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:47,343]\u001b[0m Trial 2650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:52,414]\u001b[0m Trial 2651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:06:57,490]\u001b[0m Trial 2652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:08:38,113]\u001b[0m Trial 2653 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:08:42,054]\u001b[0m Trial 2654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:08:46,604]\u001b[0m Trial 2655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:08:55,019]\u001b[0m Trial 2656 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:00,254]\u001b[0m Trial 2657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:05,255]\u001b[0m Trial 2658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:09,766]\u001b[0m Trial 2659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:14,730]\u001b[0m Trial 2660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:20,934]\u001b[0m Trial 2661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:38,029]\u001b[0m Trial 2662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:42,030]\u001b[0m Trial 2663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:47,101]\u001b[0m Trial 2664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:52,069]\u001b[0m Trial 2665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:09:59,472]\u001b[0m Trial 2666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:02,913]\u001b[0m Trial 2667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:07,885]\u001b[0m Trial 2668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:13,350]\u001b[0m Trial 2669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:21,222]\u001b[0m Trial 2670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:25,755]\u001b[0m Trial 2671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:44,263]\u001b[0m Trial 2672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:49,948]\u001b[0m Trial 2673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:54,616]\u001b[0m Trial 2674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:10:59,874]\u001b[0m Trial 2675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:05,257]\u001b[0m Trial 2676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:20,507]\u001b[0m Trial 2677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:24,670]\u001b[0m Trial 2678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:33,171]\u001b[0m Trial 2679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:38,548]\u001b[0m Trial 2680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:42,539]\u001b[0m Trial 2681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:47,160]\u001b[0m Trial 2682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:11:51,616]\u001b[0m Trial 2683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:00,839]\u001b[0m Trial 2684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:05,206]\u001b[0m Trial 2685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:10,200]\u001b[0m Trial 2686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:41,019]\u001b[0m Trial 2687 finished with value: 3.8046394125309733 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009651663937870958, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2530370051187252, 'dropout_rate_Layer_2': 0.3050431977498751, 'dropout_rate_Layer_3': 0.1090615277945814, 'dropout_rate_Layer_4': 0.06722579870319557, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.031048534494676403, 'l1_Layer_2': 1.395755011732259e-05, 'l1_Layer_3': 0.0008076143069750586, 'l1_Layer_4': 0.0017451554125321506, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155, 'n_units_Layer_4': 140}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.27 | sMAPE for Test Set is: 22.96% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:12:46,028]\u001b[0m Trial 2688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:50,079]\u001b[0m Trial 2689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:54,597]\u001b[0m Trial 2690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:12:59,005]\u001b[0m Trial 2691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:14:42,277]\u001b[0m Trial 2692 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:14:47,145]\u001b[0m Trial 2693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:14:57,567]\u001b[0m Trial 2694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:05,937]\u001b[0m Trial 2695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:12,984]\u001b[0m Trial 2696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:17,409]\u001b[0m Trial 2697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:21,355]\u001b[0m Trial 2698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:31,326]\u001b[0m Trial 2699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:36,081]\u001b[0m Trial 2700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:44,439]\u001b[0m Trial 2701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:49,698]\u001b[0m Trial 2702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:15:58,515]\u001b[0m Trial 2703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:02,542]\u001b[0m Trial 2704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:10,546]\u001b[0m Trial 2705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:25,276]\u001b[0m Trial 2706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:29,978]\u001b[0m Trial 2707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:34,133]\u001b[0m Trial 2708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:38,742]\u001b[0m Trial 2709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:47,723]\u001b[0m Trial 2710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:51,527]\u001b[0m Trial 2711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:16:57,215]\u001b[0m Trial 2712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:17:11,878]\u001b[0m Trial 2713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:18:45,184]\u001b[0m Trial 2714 finished with value: 3.964511036664192 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016892470974284315, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11065092570180592, 'dropout_rate_Layer_2': 0.1014822799300202, 'dropout_rate_Layer_3': 0.1319347097835601, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002883068775798393, 'l1_Layer_2': 0.0072276898421669645, 'l1_Layer_3': 3.8856583853997554e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 50, 'n_units_Layer_3': 55}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.96 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 15.91% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:18:49,258]\u001b[0m Trial 2715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:18:53,923]\u001b[0m Trial 2716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:18:58,580]\u001b[0m Trial 2717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:02,828]\u001b[0m Trial 2718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:25,583]\u001b[0m Trial 2719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:32,949]\u001b[0m Trial 2720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:37,006]\u001b[0m Trial 2721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:42,551]\u001b[0m Trial 2722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:47,708]\u001b[0m Trial 2723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:19:53,705]\u001b[0m Trial 2724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:20:00,038]\u001b[0m Trial 2725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:20:08,371]\u001b[0m Trial 2726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:20:12,281]\u001b[0m Trial 2727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:20:16,901]\u001b[0m Trial 2728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:20:22,105]\u001b[0m Trial 2729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:20:55,369]\u001b[0m Trial 2730 finished with value: 3.9343271599490772 and parameters: {'n_hidden': 4, 'learning_rate': 0.002297818125580849, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04043729987389374, 'dropout_rate_Layer_2': 0.2252015409104977, 'dropout_rate_Layer_3': 0.1912128888934752, 'dropout_rate_Layer_4': 0.055396511118779516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0002075693488660079, 'l1_Layer_2': 5.017235707634048e-05, 'l1_Layer_3': 8.500500855862037e-05, 'l1_Layer_4': 3.417521200567769e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 155, 'n_units_Layer_4': 205}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.93 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.99 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:21:09,825]\u001b[0m Trial 2731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:21:17,456]\u001b[0m Trial 2732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:21:22,002]\u001b[0m Trial 2733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:22:51,932]\u001b[0m Trial 2734 finished with value: 3.6201686170602865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015142093430082014, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06874824694397773, 'dropout_rate_Layer_2': 0.08615795081339805, 'dropout_rate_Layer_3': 0.15293747879905362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001175489340107006, 'l1_Layer_2': 0.008274480359081866, 'l1_Layer_3': 0.0004042535378585469, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 70}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.52% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.45 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:23:06,692]\u001b[0m Trial 2735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:23:13,143]\u001b[0m Trial 2736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:23:17,075]\u001b[0m Trial 2737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:23:23,108]\u001b[0m Trial 2738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:23:27,799]\u001b[0m Trial 2739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:23:32,001]\u001b[0m Trial 2740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:23:36,190]\u001b[0m Trial 2741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:24:32,552]\u001b[0m Trial 2742 finished with value: 3.8010742197178824 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009918718182297, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2529202771353702, 'dropout_rate_Layer_2': 0.30585792615725693, 'dropout_rate_Layer_3': 0.10639836504805968, 'dropout_rate_Layer_4': 0.07351919539338302, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0537089364779514, 'l1_Layer_2': 1.3258147371054082e-05, 'l1_Layer_3': 0.0007697795446006603, 'l1_Layer_4': 0.0017600001618381725, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 155, 'n_units_Layer_4': 150}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.80 | sMAPE for Validation Set is: 11.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:24:39,569]\u001b[0m Trial 2743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:24:43,568]\u001b[0m Trial 2744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:24:50,331]\u001b[0m Trial 2745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:24:55,932]\u001b[0m Trial 2746 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:25:00,666]\u001b[0m Trial 2747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:25:05,089]\u001b[0m Trial 2748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:25:09,374]\u001b[0m Trial 2749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:25:44,668]\u001b[0m Trial 2750 finished with value: 3.7263333731967427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027290217220820754, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027387974228380314, 'dropout_rate_Layer_2': 0.24663788395049968, 'dropout_rate_Layer_3': 0.17049324599791688, 'dropout_rate_Layer_4': 0.048027404188850036, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014427589746612659, 'l1_Layer_2': 2.3352310928036498e-05, 'l1_Layer_3': 4.8442847915401616e-05, 'l1_Layer_4': 3.2398629048167976e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 285, 'n_units_Layer_3': 90, 'n_units_Layer_4': 210}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.73 | sMAPE for Validation Set is: 10.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 14.39% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:25:48,526]\u001b[0m Trial 2751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:26:33,723]\u001b[0m Trial 2752 finished with value: 3.8608708809696317 and parameters: {'n_hidden': 4, 'learning_rate': 0.000979169032871047, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25628789187052214, 'dropout_rate_Layer_2': 0.30975942606064294, 'dropout_rate_Layer_3': 0.07010209722651115, 'dropout_rate_Layer_4': 0.09686418936085475, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03073834443799758, 'l1_Layer_2': 1.2615771846986878e-05, 'l1_Layer_3': 0.0008872731556241222, 'l1_Layer_4': 0.0013666378814706918, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155, 'n_units_Layer_4': 150}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.86 | sMAPE for Test Set is: 21.96% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:26:39,983]\u001b[0m Trial 2753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:26:43,904]\u001b[0m Trial 2754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:26:49,720]\u001b[0m Trial 2755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:26:53,944]\u001b[0m Trial 2756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:26:58,595]\u001b[0m Trial 2757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:12,286]\u001b[0m Trial 2758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:19,919]\u001b[0m Trial 2759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:27,717]\u001b[0m Trial 2760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:33,152]\u001b[0m Trial 2761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:37,421]\u001b[0m Trial 2762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:41,489]\u001b[0m Trial 2763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:27:45,921]\u001b[0m Trial 2764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:28:23,318]\u001b[0m Trial 2765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:28:29,327]\u001b[0m Trial 2766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:31:25,507]\u001b[0m Trial 2767 finished with value: 3.7101566278601497 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006410013688147527, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19891393468646382, 'dropout_rate_Layer_2': 0.3615574172441164, 'dropout_rate_Layer_3': 0.06279620797227331, 'dropout_rate_Layer_4': 0.02057272991434045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.512011986309895e-05, 'l1_Layer_2': 0.0008551123099007834, 'l1_Layer_3': 0.00047556146936063054, 'l1_Layer_4': 0.00034139393534829757, 'n_units_Layer_1': 55, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145, 'n_units_Layer_4': 95}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 10.72% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 10.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:31:30,948]\u001b[0m Trial 2768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:31:46,525]\u001b[0m Trial 2769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:31:51,639]\u001b[0m Trial 2770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:00,069]\u001b[0m Trial 2771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:09,455]\u001b[0m Trial 2772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:15,325]\u001b[0m Trial 2773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:20,208]\u001b[0m Trial 2774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:26,695]\u001b[0m Trial 2775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:30,892]\u001b[0m Trial 2776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:35,144]\u001b[0m Trial 2777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:40,090]\u001b[0m Trial 2778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:44,567]\u001b[0m Trial 2779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:52,473]\u001b[0m Trial 2780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:32:56,890]\u001b[0m Trial 2781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:33:01,915]\u001b[0m Trial 2782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:34:56,041]\u001b[0m Trial 2783 finished with value: 3.772532827574448 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005035989377900059, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.178728404217024, 'dropout_rate_Layer_2': 0.3218259221490082, 'dropout_rate_Layer_3': 0.09318286972915588, 'dropout_rate_Layer_4': 0.04312607402859012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.2211082373087896e-05, 'l1_Layer_2': 0.00039933215828796614, 'l1_Layer_3': 0.00019114465957573577, 'l1_Layer_4': 0.0009405939030298257, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 120, 'n_units_Layer_4': 290}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 10.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 4.91 | sMAPE for Test Set is: 10.88% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:35:58,256]\u001b[0m Trial 2784 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:03,414]\u001b[0m Trial 2785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:11,793]\u001b[0m Trial 2786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:16,985]\u001b[0m Trial 2787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:21,232]\u001b[0m Trial 2788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:25,890]\u001b[0m Trial 2789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:30,686]\u001b[0m Trial 2790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:38,875]\u001b[0m Trial 2791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:36:54,005]\u001b[0m Trial 2792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:02,249]\u001b[0m Trial 2793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:08,476]\u001b[0m Trial 2794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:12,358]\u001b[0m Trial 2795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:22,622]\u001b[0m Trial 2796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:30,834]\u001b[0m Trial 2797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:35,696]\u001b[0m Trial 2798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:42,163]\u001b[0m Trial 2799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:37:56,771]\u001b[0m Trial 2800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:02,436]\u001b[0m Trial 2801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:07,355]\u001b[0m Trial 2802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:11,787]\u001b[0m Trial 2803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:16,718]\u001b[0m Trial 2804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:22,344]\u001b[0m Trial 2805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:28,087]\u001b[0m Trial 2806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:34,126]\u001b[0m Trial 2807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:38:38,823]\u001b[0m Trial 2808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:39:25,404]\u001b[0m Trial 2809 finished with value: 3.8459282403063284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012834545730345415, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2879946501687725, 'dropout_rate_Layer_2': 0.3096289989269497, 'dropout_rate_Layer_3': 0.10927292422440339, 'dropout_rate_Layer_4': 0.07349336276007401, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05446992321119161, 'l1_Layer_2': 1.4436867053408672e-05, 'l1_Layer_3': 0.0006483829627786491, 'l1_Layer_4': 0.0019086141519934687, 'n_units_Layer_1': 110, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160, 'n_units_Layer_4': 160}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.13 | sMAPE for Test Set is: 22.66% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:39:30,150]\u001b[0m Trial 2810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:39:43,319]\u001b[0m Trial 2811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:39:49,659]\u001b[0m Trial 2812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:39:54,372]\u001b[0m Trial 2813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:39:58,790]\u001b[0m Trial 2814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:40:03,018]\u001b[0m Trial 2815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:40:09,417]\u001b[0m Trial 2816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:42:58,890]\u001b[0m Trial 2817 finished with value: 3.6933941354565114 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005513880222413781, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1858742080444919, 'dropout_rate_Layer_2': 0.29823835430392287, 'dropout_rate_Layer_3': 0.09717494359034512, 'dropout_rate_Layer_4': 0.0014011899517644396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.598674547172848e-05, 'l1_Layer_2': 0.0008218008026541022, 'l1_Layer_3': 0.0003341047870567679, 'l1_Layer_4': 0.0007315778445752539, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 100, 'n_units_Layer_4': 265}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.69 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 14.62% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:43:07,029]\u001b[0m Trial 2818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:11,474]\u001b[0m Trial 2819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:27,171]\u001b[0m Trial 2820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:33,572]\u001b[0m Trial 2821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:38,572]\u001b[0m Trial 2822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:43,332]\u001b[0m Trial 2823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:47,288]\u001b[0m Trial 2824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:52,234]\u001b[0m Trial 2825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:43:59,096]\u001b[0m Trial 2826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:06,700]\u001b[0m Trial 2827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:10,951]\u001b[0m Trial 2828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:16,535]\u001b[0m Trial 2829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:24,739]\u001b[0m Trial 2830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:29,743]\u001b[0m Trial 2831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:44,727]\u001b[0m Trial 2832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:49,508]\u001b[0m Trial 2833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:44:55,276]\u001b[0m Trial 2834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:45:01,959]\u001b[0m Trial 2835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:45:15,848]\u001b[0m Trial 2836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:45:20,398]\u001b[0m Trial 2837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:47:31,753]\u001b[0m Trial 2838 finished with value: 3.7880971292854464 and parameters: {'n_hidden': 4, 'learning_rate': 0.000629200666956655, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2084560125140592, 'dropout_rate_Layer_2': 0.3479131716532049, 'dropout_rate_Layer_3': 0.10949217693297962, 'dropout_rate_Layer_4': 0.035969800283995275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.170697927877848e-05, 'l1_Layer_2': 0.0011837546560389683, 'l1_Layer_3': 0.00011832010214316826, 'l1_Layer_4': 0.00018826411217680262, 'n_units_Layer_1': 75, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145, 'n_units_Layer_4': 285}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:47:36,302]\u001b[0m Trial 2839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:47:40,344]\u001b[0m Trial 2840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:47:45,357]\u001b[0m Trial 2841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:47:49,622]\u001b[0m Trial 2842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:47:54,628]\u001b[0m Trial 2843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:48:36,009]\u001b[0m Trial 2844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:48:40,008]\u001b[0m Trial 2845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:48:46,292]\u001b[0m Trial 2846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:48:51,749]\u001b[0m Trial 2847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:50:27,530]\u001b[0m Trial 2848 finished with value: 3.6411828594500797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005909817471927137, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13146566142811858, 'dropout_rate_Layer_2': 0.021297733109523966, 'dropout_rate_Layer_3': 0.009461159142867385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.4030918380880226e-05, 'l1_Layer_2': 0.0014159771287143902, 'l1_Layer_3': 0.00017527513348432143, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.64 | sMAPE for Validation Set is: 10.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.87 | sMAPE for Test Set is: 10.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:50:31,762]\u001b[0m Trial 2849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:50:36,170]\u001b[0m Trial 2850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:50:40,589]\u001b[0m Trial 2851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:50:49,450]\u001b[0m Trial 2852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:50:54,824]\u001b[0m Trial 2853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:00,106]\u001b[0m Trial 2854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:04,896]\u001b[0m Trial 2855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:09,871]\u001b[0m Trial 2856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:25,017]\u001b[0m Trial 2857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:32,405]\u001b[0m Trial 2858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:37,258]\u001b[0m Trial 2859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:41,613]\u001b[0m Trial 2860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:46,063]\u001b[0m Trial 2861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:51:52,476]\u001b[0m Trial 2862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:15,020]\u001b[0m Trial 2863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:19,397]\u001b[0m Trial 2864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:24,362]\u001b[0m Trial 2865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:32,416]\u001b[0m Trial 2866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:42,134]\u001b[0m Trial 2867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:48,470]\u001b[0m Trial 2868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:52,904]\u001b[0m Trial 2869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:52:57,356]\u001b[0m Trial 2870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:55:15,958]\u001b[0m Trial 2871 finished with value: 3.5497631686537403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011522881199913613, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0816957401594763, 'dropout_rate_Layer_2': 0.08996945510192261, 'dropout_rate_Layer_3': 0.11497813923720654, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010904157047147399, 'l1_Layer_2': 0.009647794825716035, 'l1_Layer_3': 0.0007400184806915818, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 10.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.88 | sMAPE for Test Set is: 10.81% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:55:20,776]\u001b[0m Trial 2872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:56:50,646]\u001b[0m Trial 2873 finished with value: 3.621138748305692 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011838201811445535, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11049689872294866, 'dropout_rate_Layer_2': 0.0902428035140475, 'dropout_rate_Layer_3': 0.1164286628166508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010957143620652246, 'l1_Layer_2': 0.008828479523125566, 'l1_Layer_3': 0.0003250524668805301, 'n_units_Layer_1': 110, 'n_units_Layer_2': 85, 'n_units_Layer_3': 105}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.04 | sMAPE for Test Set is: 11.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:57:05,724]\u001b[0m Trial 2874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:57:13,723]\u001b[0m Trial 2875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:57:17,583]\u001b[0m Trial 2876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:57:56,916]\u001b[0m Trial 2877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:58:00,976]\u001b[0m Trial 2878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:58:09,444]\u001b[0m Trial 2879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:58:14,668]\u001b[0m Trial 2880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:58:19,761]\u001b[0m Trial 2881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:58:36,704]\u001b[0m Trial 2882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:58:57,644]\u001b[0m Trial 2883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:59:39,613]\u001b[0m Trial 2884 finished with value: 3.7539207314823373 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014801093652172996, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06787284455363067, 'dropout_rate_Layer_2': 0.275281184230097, 'dropout_rate_Layer_3': 0.12411395877023193, 'dropout_rate_Layer_4': 0.04439298043355225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001011361629699766, 'l1_Layer_2': 2.9023011555134203e-05, 'l1_Layer_3': 9.497001211587703e-05, 'l1_Layer_4': 3.7023128036758944e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 285, 'n_units_Layer_3': 85, 'n_units_Layer_4': 215}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.75 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 14.33% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 20:59:44,714]\u001b[0m Trial 2885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:59:49,482]\u001b[0m Trial 2886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:59:53,295]\u001b[0m Trial 2887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 20:59:59,925]\u001b[0m Trial 2888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:00:04,337]\u001b[0m Trial 2889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:00:11,346]\u001b[0m Trial 2890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:00:15,715]\u001b[0m Trial 2891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:00:22,944]\u001b[0m Trial 2892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:02:11,791]\u001b[0m Trial 2893 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:02:48,985]\u001b[0m Trial 2894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:02:54,538]\u001b[0m Trial 2895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:03:00,180]\u001b[0m Trial 2896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:03:04,521]\u001b[0m Trial 2897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:03:10,735]\u001b[0m Trial 2898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:03:18,538]\u001b[0m Trial 2899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:03:53,655]\u001b[0m Trial 2900 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:03:58,422]\u001b[0m Trial 2901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:04:02,472]\u001b[0m Trial 2902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:04:06,847]\u001b[0m Trial 2903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:04:30,282]\u001b[0m Trial 2904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:04:39,016]\u001b[0m Trial 2905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:04:54,313]\u001b[0m Trial 2906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:04:59,075]\u001b[0m Trial 2907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:03,878]\u001b[0m Trial 2908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:09,674]\u001b[0m Trial 2909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:14,128]\u001b[0m Trial 2910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:18,291]\u001b[0m Trial 2911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:26,853]\u001b[0m Trial 2912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:31,443]\u001b[0m Trial 2913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:05:36,006]\u001b[0m Trial 2914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:16,065]\u001b[0m Trial 2915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:34,677]\u001b[0m Trial 2916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:39,381]\u001b[0m Trial 2917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:43,897]\u001b[0m Trial 2918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:47,922]\u001b[0m Trial 2919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:52,548]\u001b[0m Trial 2920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:06:58,458]\u001b[0m Trial 2921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:07:03,319]\u001b[0m Trial 2922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:09:00,571]\u001b[0m Trial 2923 finished with value: 3.6026793519611466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010604002923606715, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06566012724636935, 'dropout_rate_Layer_2': 0.10084762671800135, 'dropout_rate_Layer_3': 0.06863715719305064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008768770991192722, 'l1_Layer_2': 0.011787501230010777, 'l1_Layer_3': 3.0480678261152995e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.60 | sMAPE for Validation Set is: 10.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 4.96 | sMAPE for Test Set is: 11.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:09:05,693]\u001b[0m Trial 2924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:09:14,742]\u001b[0m Trial 2925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:09:19,843]\u001b[0m Trial 2926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:09:26,225]\u001b[0m Trial 2927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:09:30,176]\u001b[0m Trial 2928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:10:08,325]\u001b[0m Trial 2929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:10:14,554]\u001b[0m Trial 2930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:10:20,017]\u001b[0m Trial 2931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:10:23,835]\u001b[0m Trial 2932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:11:09,800]\u001b[0m Trial 2933 finished with value: 3.6493952152005344 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008976834890452347, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04766058873905165, 'dropout_rate_Layer_2': 0.21848380246430157, 'dropout_rate_Layer_3': 0.202884704017553, 'dropout_rate_Layer_4': 0.04985647598060906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000266011139051766, 'l1_Layer_2': 5.7672391162863317e-05, 'l1_Layer_3': 0.00023441320279426334, 'l1_Layer_4': 2.8469618067634116e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 105, 'n_units_Layer_4': 185}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.65 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 11.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:11:44,971]\u001b[0m Trial 2934 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:11:50,784]\u001b[0m Trial 2935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:12:01,108]\u001b[0m Trial 2936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:12:05,132]\u001b[0m Trial 2937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:12:11,216]\u001b[0m Trial 2938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:14:58,510]\u001b[0m Trial 2939 finished with value: 3.7175004741288653 and parameters: {'n_hidden': 4, 'learning_rate': 0.00058398439206969, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2005704834083244, 'dropout_rate_Layer_2': 0.33889829666782345, 'dropout_rate_Layer_3': 0.11644169823856343, 'dropout_rate_Layer_4': 0.06779889496491748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.732130361506953e-05, 'l1_Layer_2': 0.0006260628121017518, 'l1_Layer_3': 0.000945127405673081, 'l1_Layer_4': 0.0006618911415428278, 'n_units_Layer_1': 85, 'n_units_Layer_2': 300, 'n_units_Layer_3': 105, 'n_units_Layer_4': 280}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 10.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.63 | sMAPE for Test Set is: 12.41% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:15:03,131]\u001b[0m Trial 2940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:15:42,113]\u001b[0m Trial 2941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:15:50,289]\u001b[0m Trial 2942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:15:55,396]\u001b[0m Trial 2943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:16:01,733]\u001b[0m Trial 2944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:16:10,243]\u001b[0m Trial 2945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:16:41,974]\u001b[0m Trial 2946 finished with value: 3.8339997163165216 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011209175704518378, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2839950727097876, 'dropout_rate_Layer_2': 0.32921685166976045, 'dropout_rate_Layer_3': 0.08020313538939647, 'dropout_rate_Layer_4': 0.06272700773742039, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02739870338878737, 'l1_Layer_2': 1.8304066780636183e-05, 'l1_Layer_3': 0.0005198209122011454, 'l1_Layer_4': 0.001752570419358142, 'n_units_Layer_1': 105, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140, 'n_units_Layer_4': 160}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.83 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:16:46,696]\u001b[0m Trial 2947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:17:27,601]\u001b[0m Trial 2948 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:17:43,209]\u001b[0m Trial 2949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:17:47,834]\u001b[0m Trial 2950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:17:52,925]\u001b[0m Trial 2951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:21:31,358]\u001b[0m Trial 2952 finished with value: 3.5190037742584557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008686080805047835, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1497626848995628, 'dropout_rate_Layer_2': 0.1205582118758546, 'dropout_rate_Layer_3': 0.06819599455995845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011276435791226845, 'l1_Layer_2': 0.01185645115955874, 'l1_Layer_3': 9.415731242485254e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 85, 'n_units_Layer_3': 115}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 10.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 11.14% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:21:35,768]\u001b[0m Trial 2953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:21:41,040]\u001b[0m Trial 2954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:21:56,856]\u001b[0m Trial 2955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:01,369]\u001b[0m Trial 2956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:06,354]\u001b[0m Trial 2957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:15,289]\u001b[0m Trial 2958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:19,060]\u001b[0m Trial 2959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:24,092]\u001b[0m Trial 2960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:29,460]\u001b[0m Trial 2961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:47,454]\u001b[0m Trial 2962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:22:56,194]\u001b[0m Trial 2963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:23:11,212]\u001b[0m Trial 2964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:23:39,718]\u001b[0m Trial 2965 finished with value: 3.6208747493621356 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018781944748736694, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05339253669173639, 'dropout_rate_Layer_2': 0.22026045628461174, 'dropout_rate_Layer_3': 0.21024911241587274, 'dropout_rate_Layer_4': 0.04779850040485813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00024364325591887253, 'l1_Layer_2': 6.16149152554205e-05, 'l1_Layer_3': 0.00023254835644754247, 'l1_Layer_4': 2.5974296201327225e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 100, 'n_units_Layer_4': 240}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.47 | sMAPE for Test Set is: 12.15% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:23:43,616]\u001b[0m Trial 2966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:23:52,495]\u001b[0m Trial 2967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:23:58,479]\u001b[0m Trial 2968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:24:03,523]\u001b[0m Trial 2969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:24:07,849]\u001b[0m Trial 2970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:24:35,978]\u001b[0m Trial 2971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:24:44,482]\u001b[0m Trial 2972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:24:49,775]\u001b[0m Trial 2973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:24:54,019]\u001b[0m Trial 2974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:25:18,508]\u001b[0m Trial 2975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:25:31,358]\u001b[0m Trial 2976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:25:35,563]\u001b[0m Trial 2977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:25:40,801]\u001b[0m Trial 2978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:25:55,506]\u001b[0m Trial 2979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:26:10,484]\u001b[0m Trial 2980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:26:46,246]\u001b[0m Trial 2981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:26:51,285]\u001b[0m Trial 2982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:26:57,360]\u001b[0m Trial 2983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:27:01,891]\u001b[0m Trial 2984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:27:06,758]\u001b[0m Trial 2985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:27:22,290]\u001b[0m Trial 2986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:27:27,278]\u001b[0m Trial 2987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:27:33,572]\u001b[0m Trial 2988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:27:37,949]\u001b[0m Trial 2989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:28:00,260]\u001b[0m Trial 2990 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:30:12,022]\u001b[0m Trial 2991 finished with value: 3.6204273626480243 and parameters: {'n_hidden': 4, 'learning_rate': 0.000571590830304669, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.208319353375731, 'dropout_rate_Layer_2': 0.30366778038946307, 'dropout_rate_Layer_3': 0.10927774478848458, 'dropout_rate_Layer_4': 0.04596436551750259, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010031673833781385, 'l1_Layer_2': 0.0014341167447507075, 'l1_Layer_3': 0.00017563565987869888, 'l1_Layer_4': 0.0005878685900350856, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 135, 'n_units_Layer_4': 300}. Best is trial 1822 with value: 3.4636481611555516.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.62 | sMAPE for Validation Set is: 10.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 4.93 | sMAPE for Test Set is: 11.04% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-25 21:30:19,909]\u001b[0m Trial 2992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:30:35,255]\u001b[0m Trial 2993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:30:40,769]\u001b[0m Trial 2994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:31:13,216]\u001b[0m Trial 2995 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:31:54,281]\u001b[0m Trial 2996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:32:03,737]\u001b[0m Trial 2997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:32:09,063]\u001b[0m Trial 2998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-25 21:32:17,059]\u001b[0m Trial 2999 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-01-01, MAE is:1.92 & sMAPE is:8.39% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :1.92 & 8.39% & 1.02\n",
      "for 2018-01-02, MAE is:3.78 & sMAPE is:12.32% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.85 & 10.36% & 0.81\n",
      "for 2018-01-03, MAE is:2.99 & sMAPE is:9.74% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.90 & 10.15% & 0.76\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E5CD22E9E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:2.74 & sMAPE is:8.64% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 9.77% & 0.79\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001E5C8C6C9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:1.53 & sMAPE is:4.77% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.59 & 8.77% & 0.79\n",
      "for 2018-01-06, MAE is:3.02 & sMAPE is:10.14% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 9.00% & 0.77\n",
      "for 2018-01-07, MAE is:0.96 & sMAPE is:3.34% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 8.19% & 0.74\n",
      "for 2018-01-08, MAE is:4.46 & sMAPE is:12.06% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.67 & 8.68% & 0.72\n",
      "for 2018-01-09, MAE is:4.20 & sMAPE is:12.36% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.84 & 9.09% & 0.80\n",
      "for 2018-01-10, MAE is:7.54 & sMAPE is:19.48% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 10.12% & 0.78\n",
      "for 2018-01-11, MAE is:7.26 & sMAPE is:16.54% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :3.67 & 10.71% & 0.77\n",
      "for 2018-01-12, MAE is:2.57 & sMAPE is:6.55% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 10.36% & 0.74\n",
      "for 2018-01-13, MAE is:3.31 & sMAPE is:10.25% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 10.35% & 0.84\n",
      "for 2018-01-14, MAE is:1.21 & sMAPE is:4.17% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 9.91% & 0.84\n",
      "for 2018-01-15, MAE is:4.75 & sMAPE is:14.14% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.48 & 10.19% & 0.89\n",
      "for 2018-01-16, MAE is:2.52 & sMAPE is:8.39% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 10.08% & 0.88\n",
      "for 2018-01-17, MAE is:5.89 & sMAPE is:13.70% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.57 & 10.29% & 0.91\n",
      "for 2018-01-18, MAE is:6.46 & sMAPE is:15.16% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 10.56% & 0.97\n",
      "for 2018-01-19, MAE is:14.03 & sMAPE is:23.88% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 11.27% & 0.96\n",
      "for 2018-01-20, MAE is:2.28 & sMAPE is:6.46% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 11.03% & 0.97\n",
      "for 2018-01-21, MAE is:2.70 & sMAPE is:7.55% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 10.86% & 0.95\n",
      "for 2018-01-22, MAE is:15.50 & sMAPE is:24.64% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 11.49% & 0.93\n",
      "for 2018-01-23, MAE is:36.18 & sMAPE is:41.43% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 12.79% & 0.93\n",
      "for 2018-01-24, MAE is:10.03 & sMAPE is:25.50% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 13.32% & 0.95\n",
      "for 2018-01-25, MAE is:6.37 & sMAPE is:20.22% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 13.59% & 0.94\n",
      "for 2018-01-26, MAE is:7.23 & sMAPE is:18.28% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 13.77% & 0.93\n",
      "for 2018-01-27, MAE is:1.66 & sMAPE is:5.17% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 13.46% & 0.91\n",
      "for 2018-01-28, MAE is:1.11 & sMAPE is:3.80% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 13.11% & 0.89\n",
      "for 2018-01-29, MAE is:3.18 & sMAPE is:8.58% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 12.95% & 0.86\n",
      "for 2018-01-30, MAE is:4.96 & sMAPE is:11.76% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 12.91% & 0.84\n",
      "for 2018-01-31, MAE is:11.20 & sMAPE is:19.95% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 13.14% & 0.84\n",
      "for 2018-02-01, MAE is:2.69 & sMAPE is:7.39% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 12.96% & 0.83\n",
      "for 2018-02-02, MAE is:3.89 & sMAPE is:10.70% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 12.89% & 0.82\n",
      "for 2018-02-03, MAE is:1.58 & sMAPE is:4.57% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 12.65% & 0.82\n",
      "for 2018-02-04, MAE is:1.47 & sMAPE is:4.30% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 12.41% & 0.80\n",
      "for 2018-02-05, MAE is:11.28 & sMAPE is:20.04% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 12.62% & 0.80\n",
      "for 2018-02-06, MAE is:3.36 & sMAPE is:7.26% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 12.48% & 0.79\n",
      "for 2018-02-07, MAE is:3.52 & sMAPE is:7.21% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 12.34% & 0.77\n",
      "for 2018-02-08, MAE is:5.31 & sMAPE is:11.82% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 12.33% & 0.77\n",
      "for 2018-02-09, MAE is:3.24 & sMAPE is:8.39% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 12.23% & 0.78\n",
      "for 2018-02-10, MAE is:1.95 & sMAPE is:5.76% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.07% & 0.79\n",
      "for 2018-02-11, MAE is:1.51 & sMAPE is:4.87% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 11.90% & 0.78\n",
      "for 2018-02-12, MAE is:3.56 & sMAPE is:8.50% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 11.82% & 0.77\n",
      "for 2018-02-13, MAE is:3.32 & sMAPE is:8.67% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 11.75% & 0.76\n",
      "for 2018-02-14, MAE is:4.69 & sMAPE is:11.71% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 11.75% & 0.75\n",
      "for 2018-02-15, MAE is:3.51 & sMAPE is:9.01% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 11.69% & 0.75\n",
      "for 2018-02-16, MAE is:2.57 & sMAPE is:6.36% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 11.57% & 0.75\n",
      "for 2018-02-17, MAE is:4.09 & sMAPE is:10.86% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 11.56% & 0.75\n",
      "for 2018-02-18, MAE is:1.98 & sMAPE is:5.28% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 11.43% & 0.74\n",
      "for 2018-02-19, MAE is:5.28 & sMAPE is:10.61% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 11.41% & 0.74\n",
      "for 2018-02-20, MAE is:6.20 & sMAPE is:10.92% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 11.40% & 0.73\n",
      "for 2018-02-21, MAE is:5.82 & sMAPE is:10.14% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 11.38% & 0.72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-22, MAE is:5.17 & sMAPE is:9.21% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 11.34% & 0.72\n",
      "for 2018-02-23, MAE is:6.73 & sMAPE is:13.35% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 11.38% & 0.73\n",
      "for 2018-02-24, MAE is:2.55 & sMAPE is:6.30% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 11.28% & 0.73\n",
      "for 2018-02-25, MAE is:1.36 & sMAPE is:3.60% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 11.15% & 0.73\n",
      "for 2018-02-26, MAE is:5.08 & sMAPE is:9.74% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 11.12% & 0.73\n",
      "for 2018-02-27, MAE is:4.99 & sMAPE is:9.26% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 11.09% & 0.74\n",
      "for 2018-02-28, MAE is:40.97 & sMAPE is:34.12% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 11.48% & 0.75\n",
      "for 2018-03-01, MAE is:46.29 & sMAPE is:46.05% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 12.06% & 0.75\n",
      "for 2018-03-02, MAE is:18.46 & sMAPE is:21.20% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 12.21% & 0.75\n",
      "for 2018-03-03, MAE is:5.69 & sMAPE is:12.44% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 12.21% & 0.76\n",
      "for 2018-03-04, MAE is:1.83 & sMAPE is:4.52% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 12.09% & 0.76\n",
      "for 2018-03-05, MAE is:9.28 & sMAPE is:16.36% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 12.16% & 0.76\n",
      "for 2018-03-06, MAE is:3.08 & sMAPE is:6.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 12.06% & 0.77\n",
      "for 2018-03-07, MAE is:4.37 & sMAPE is:9.60% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 12.03% & 0.76\n",
      "for 2018-03-08, MAE is:3.05 & sMAPE is:7.81% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 11.96% & 0.74\n",
      "for 2018-03-09, MAE is:5.70 & sMAPE is:12.87% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 11.98% & 0.74\n",
      "for 2018-03-10, MAE is:1.41 & sMAPE is:3.74% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 11.86% & 0.73\n",
      "for 2018-03-11, MAE is:1.03 & sMAPE is:2.87% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 11.73% & 0.72\n",
      "for 2018-03-12, MAE is:2.47 & sMAPE is:5.69% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 11.65% & 0.71\n",
      "for 2018-03-13, MAE is:2.79 & sMAPE is:6.84% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 11.58% & 0.71\n",
      "for 2018-03-14, MAE is:4.57 & sMAPE is:8.92% & rMAE is:3.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 11.54% & 0.75\n",
      "for 2018-03-15, MAE is:3.30 & sMAPE is:6.68% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 11.48% & 0.74\n",
      "for 2018-03-16, MAE is:4.95 & sMAPE is:10.57% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 11.46% & 0.76\n",
      "for 2018-03-17, MAE is:2.67 & sMAPE is:6.70% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 11.40% & 0.78\n",
      "for 2018-03-18, MAE is:1.31 & sMAPE is:3.50% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 11.30% & 0.78\n",
      "for 2018-03-19, MAE is:3.06 & sMAPE is:6.93% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 11.24% & 0.79\n",
      "for 2018-03-20, MAE is:4.28 & sMAPE is:9.48% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 11.22% & 0.80\n",
      "for 2018-03-21, MAE is:5.21 & sMAPE is:11.17% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 11.22% & 0.80\n",
      "for 2018-03-22, MAE is:2.68 & sMAPE is:6.27% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 11.16% & 0.80\n",
      "for 2018-03-23, MAE is:5.06 & sMAPE is:10.16% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 11.15% & 0.80\n",
      "for 2018-03-24, MAE is:1.76 & sMAPE is:4.44% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 11.07% & 0.80\n",
      "for 2018-03-25, MAE is:1.88 & sMAPE is:4.85% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 10.99% & 0.80\n",
      "for 2018-03-26, MAE is:3.29 & sMAPE is:6.95% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 10.94% & 0.80\n",
      "for 2018-03-27, MAE is:2.73 & sMAPE is:5.73% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 10.88% & 0.79\n",
      "for 2018-03-28, MAE is:2.98 & sMAPE is:6.29% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 10.83% & 0.79\n",
      "for 2018-03-29, MAE is:4.42 & sMAPE is:9.88% & rMAE is:2.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 10.82% & 0.81\n",
      "for 2018-03-30, MAE is:1.65 & sMAPE is:3.99% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 10.74% & 0.80\n",
      "for 2018-03-31, MAE is:1.59 & sMAPE is:4.03% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 10.67% & 0.81\n",
      "for 2018-04-01, MAE is:1.31 & sMAPE is:3.40% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 10.59% & 0.81\n",
      "for 2018-04-02, MAE is:1.34 & sMAPE is:3.47% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 10.51% & 0.80\n",
      "for 2018-04-03, MAE is:3.22 & sMAPE is:7.57% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 10.48% & 0.81\n",
      "for 2018-04-04, MAE is:1.99 & sMAPE is:4.60% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 10.42% & 0.80\n",
      "for 2018-04-05, MAE is:2.57 & sMAPE is:5.88% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 10.37% & 0.81\n",
      "for 2018-04-06, MAE is:2.45 & sMAPE is:5.85% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 10.32% & 0.81\n",
      "for 2018-04-07, MAE is:2.56 & sMAPE is:6.79% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 10.29% & 0.83\n",
      "for 2018-04-08, MAE is:2.19 & sMAPE is:5.77% & rMAE is:3.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 10.24% & 0.86\n",
      "for 2018-04-09, MAE is:2.72 & sMAPE is:6.20% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 10.20% & 0.86\n",
      "for 2018-04-10, MAE is:1.99 & sMAPE is:4.64% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 10.14% & 0.86\n",
      "for 2018-04-11, MAE is:2.43 & sMAPE is:6.22% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 10.10% & 0.86\n",
      "for 2018-04-12, MAE is:2.33 & sMAPE is:5.72% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.11 & 10.06% & 0.86\n",
      "for 2018-04-13, MAE is:2.33 & sMAPE is:5.92% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 10.02% & 0.86\n",
      "for 2018-04-14, MAE is:3.14 & sMAPE is:8.69% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.06 & 10.01% & 0.87\n",
      "for 2018-04-15, MAE is:3.15 & sMAPE is:8.33% & rMAE is:8.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 9.99% & 0.94\n",
      "for 2018-04-16, MAE is:4.83 & sMAPE is:10.37% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 10.00% & 0.94\n",
      "for 2018-04-17, MAE is:3.25 & sMAPE is:7.21% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 9.97% & 0.95\n",
      "for 2018-04-18, MAE is:1.87 & sMAPE is:4.16% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 9.92% & 0.94\n",
      "for 2018-04-19, MAE is:2.73 & sMAPE is:6.57% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 9.89% & 0.95\n",
      "for 2018-04-20, MAE is:2.80 & sMAPE is:7.15% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 9.86% & 0.94\n",
      "for 2018-04-21, MAE is:2.67 & sMAPE is:8.61% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 9.85% & 0.94\n",
      "for 2018-04-22, MAE is:2.86 & sMAPE is:8.47% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 9.84% & 0.94\n",
      "for 2018-04-23, MAE is:10.16 & sMAPE is:22.18% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 9.95% & 0.94\n",
      "for 2018-04-24, MAE is:2.92 & sMAPE is:8.74% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 9.94% & 0.93\n",
      "for 2018-04-25, MAE is:9.24 & sMAPE is:24.33% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 10.06% & 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-26, MAE is:5.52 & sMAPE is:13.13% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 10.09% & 0.95\n",
      "for 2018-04-27, MAE is:12.60 & sMAPE is:23.78% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 10.20% & 0.95\n",
      "for 2018-04-28, MAE is:5.09 & sMAPE is:13.52% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 10.23% & 0.95\n",
      "for 2018-04-29, MAE is:1.55 & sMAPE is:4.56% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 10.19% & 0.95\n",
      "for 2018-04-30, MAE is:3.90 & sMAPE is:11.49% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 10.20% & 0.95\n",
      "for 2018-05-01, MAE is:8.25 & sMAPE is:43.33% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.04 & 10.47% & 0.94\n",
      "for 2018-05-02, MAE is:6.13 & sMAPE is:19.86% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 10.55% & 0.94\n",
      "for 2018-05-03, MAE is:22.33 & sMAPE is:28.28% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 10.69% & 0.95\n",
      "for 2018-05-04, MAE is:6.17 & sMAPE is:16.16% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 10.74% & 0.94\n",
      "for 2018-05-05, MAE is:1.73 & sMAPE is:5.78% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.17 & 10.70% & 0.94\n",
      "for 2018-05-06, MAE is:7.86 & sMAPE is:42.61% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 10.95% & 0.93\n",
      "for 2018-05-07, MAE is:8.91 & sMAPE is:48.83% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 11.25% & 0.93\n",
      "for 2018-05-08, MAE is:26.05 & sMAPE is:86.34% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 11.83% & 0.94\n",
      "for 2018-05-09, MAE is:9.74 & sMAPE is:73.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.31% & 0.93\n",
      "for 2018-05-10, MAE is:10.16 & sMAPE is:86.15% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.88% & 0.93\n",
      "for 2018-05-11, MAE is:14.65 & sMAPE is:75.77% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 13.36% & 0.93\n",
      "for 2018-05-12, MAE is:10.64 & sMAPE is:41.91% & rMAE is:5.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 13.57% & 0.97\n",
      "for 2018-05-13, MAE is:4.74 & sMAPE is:25.70% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 13.67% & 0.97\n",
      "for 2018-05-14, MAE is:20.19 & sMAPE is:38.90% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 13.85% & 0.96\n",
      "for 2018-05-15, MAE is:15.58 & sMAPE is:37.19% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 14.03% & 0.97\n",
      "for 2018-05-16, MAE is:36.31 & sMAPE is:43.64% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.24% & 0.96\n",
      "for 2018-05-17, MAE is:9.37 & sMAPE is:38.58% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 14.42% & 0.96\n",
      "for 2018-05-18, MAE is:9.09 & sMAPE is:30.71% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 14.54% & 0.96\n",
      "for 2018-05-19, MAE is:6.24 & sMAPE is:20.12% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 14.58% & 0.96\n",
      "for 2018-05-20, MAE is:5.32 & sMAPE is:20.54% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 14.62% & 0.96\n",
      "for 2018-05-21, MAE is:20.29 & sMAPE is:77.74% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.11 & 15.07% & 0.97\n",
      "for 2018-05-22, MAE is:26.43 & sMAPE is:56.80% & rMAE is:3.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.36% & 0.98\n",
      "for 2018-05-23, MAE is:15.71 & sMAPE is:32.38% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 15.48% & 0.98\n",
      "for 2018-05-24, MAE is:9.76 & sMAPE is:18.45% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 15.50% & 0.98\n",
      "for 2018-05-25, MAE is:7.12 & sMAPE is:15.29% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 15.50% & 0.98\n",
      "for 2018-05-26, MAE is:3.70 & sMAPE is:10.01% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 15.46% & 0.98\n",
      "for 2018-05-27, MAE is:2.79 & sMAPE is:7.63% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 15.41% & 0.97\n",
      "for 2018-05-28, MAE is:5.30 & sMAPE is:11.34% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.38% & 0.97\n",
      "for 2018-05-29, MAE is:4.90 & sMAPE is:11.81% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 15.36% & 0.96\n",
      "for 2018-05-30, MAE is:8.34 & sMAPE is:18.60% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.38% & 0.96\n",
      "for 2018-05-31, MAE is:6.19 & sMAPE is:11.47% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.36% & 0.96\n",
      "for 2018-06-01, MAE is:6.26 & sMAPE is:12.40% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 15.34% & 0.96\n",
      "for 2018-06-02, MAE is:1.93 & sMAPE is:4.63% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 15.27% & 0.96\n",
      "for 2018-06-03, MAE is:2.64 & sMAPE is:6.48% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 15.21% & 0.96\n",
      "for 2018-06-04, MAE is:3.97 & sMAPE is:8.56% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.17% & 0.96\n",
      "for 2018-06-05, MAE is:4.08 & sMAPE is:8.43% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 15.12% & 0.95\n",
      "for 2018-06-06, MAE is:8.62 & sMAPE is:15.89% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.13% & 0.95\n",
      "for 2018-06-07, MAE is:6.80 & sMAPE is:12.40% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.11% & 0.96\n",
      "for 2018-06-08, MAE is:6.57 & sMAPE is:11.17% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.09% & 0.95\n",
      "for 2018-06-09, MAE is:5.52 & sMAPE is:9.80% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 15.05% & 0.95\n",
      "for 2018-06-10, MAE is:2.36 & sMAPE is:5.38% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 14.99% & 0.95\n",
      "for 2018-06-11, MAE is:3.32 & sMAPE is:6.36% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 14.94% & 0.95\n",
      "for 2018-06-12, MAE is:3.18 & sMAPE is:6.42% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 14.89% & 0.95\n",
      "for 2018-06-13, MAE is:5.89 & sMAPE is:10.26% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 14.86% & 0.95\n",
      "for 2018-06-14, MAE is:4.69 & sMAPE is:8.54% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 14.82% & 0.96\n",
      "for 2018-06-15, MAE is:3.80 & sMAPE is:7.69% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 14.78% & 0.95\n",
      "for 2018-06-16, MAE is:1.01 & sMAPE is:2.28% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 14.70% & 0.95\n",
      "for 2018-06-17, MAE is:1.24 & sMAPE is:2.91% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 14.63% & 0.94\n",
      "for 2018-06-18, MAE is:4.25 & sMAPE is:8.62% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 14.60% & 0.95\n",
      "for 2018-06-19, MAE is:3.62 & sMAPE is:8.85% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 14.56% & 0.95\n",
      "for 2018-06-20, MAE is:3.03 & sMAPE is:6.75% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 14.52% & 0.94\n",
      "for 2018-06-21, MAE is:7.39 & sMAPE is:15.86% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 14.53% & 0.94\n",
      "for 2018-06-22, MAE is:6.98 & sMAPE is:30.54% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 14.62% & 0.94\n",
      "for 2018-06-23, MAE is:11.08 & sMAPE is:36.70% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 14.74% & 0.94\n",
      "for 2018-06-24, MAE is:7.81 & sMAPE is:20.62% & rMAE is:4.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 14.78% & 0.96\n",
      "for 2018-06-25, MAE is:2.87 & sMAPE is:5.69% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 14.73% & 0.97\n",
      "for 2018-06-26, MAE is:3.26 & sMAPE is:6.73% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 14.68% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-27, MAE is:4.27 & sMAPE is:8.45% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 14.65% & 0.96\n",
      "for 2018-06-28, MAE is:3.53 & sMAPE is:7.12% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 14.60% & 0.96\n",
      "for 2018-06-29, MAE is:4.30 & sMAPE is:8.66% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 14.57% & 0.96\n",
      "for 2018-06-30, MAE is:5.62 & sMAPE is:13.34% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 14.56% & 0.96\n",
      "for 2018-07-01, MAE is:2.26 & sMAPE is:5.15% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.01 & 14.51% & 0.95\n",
      "for 2018-07-02, MAE is:3.96 & sMAPE is:7.54% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 14.47% & 0.95\n",
      "for 2018-07-03, MAE is:2.40 & sMAPE is:4.74% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 14.42% & 0.95\n",
      "for 2018-07-04, MAE is:2.52 & sMAPE is:4.74% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 14.37% & 0.95\n",
      "for 2018-07-05, MAE is:3.09 & sMAPE is:5.81% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 14.32% & 0.94\n",
      "for 2018-07-06, MAE is:4.11 & sMAPE is:7.53% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 14.29% & 0.94\n",
      "for 2018-07-07, MAE is:1.86 & sMAPE is:4.06% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 14.23% & 0.94\n",
      "for 2018-07-08, MAE is:3.06 & sMAPE is:6.63% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 14.19% & 0.94\n",
      "for 2018-07-09, MAE is:2.92 & sMAPE is:5.45% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 14.15% & 0.95\n",
      "for 2018-07-10, MAE is:3.16 & sMAPE is:6.07% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 14.10% & 0.95\n",
      "for 2018-07-11, MAE is:2.21 & sMAPE is:4.12% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 14.05% & 0.95\n",
      "for 2018-07-12, MAE is:2.39 & sMAPE is:4.21% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 14.00% & 0.95\n",
      "for 2018-07-13, MAE is:2.62 & sMAPE is:4.78% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 13.95% & 0.95\n",
      "for 2018-07-14, MAE is:2.50 & sMAPE is:5.00% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 13.91% & 0.95\n",
      "for 2018-07-15, MAE is:1.77 & sMAPE is:3.40% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 13.85% & 0.95\n",
      "for 2018-07-16, MAE is:1.68 & sMAPE is:3.01% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 13.80% & 0.94\n",
      "for 2018-07-17, MAE is:1.76 & sMAPE is:3.21% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.74 & 13.75% & 0.94\n",
      "for 2018-07-18, MAE is:3.43 & sMAPE is:6.19% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.73 & 13.71% & 0.95\n",
      "for 2018-07-19, MAE is:2.97 & sMAPE is:5.66% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.71 & 13.67% & 0.95\n",
      "for 2018-07-20, MAE is:2.94 & sMAPE is:5.18% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 13.63% & 0.95\n",
      "for 2018-07-21, MAE is:1.43 & sMAPE is:2.76% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 13.57% & 0.95\n",
      "for 2018-07-22, MAE is:1.69 & sMAPE is:3.27% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 13.52% & 0.95\n",
      "for 2018-07-23, MAE is:1.76 & sMAPE is:3.10% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 13.47% & 0.96\n",
      "for 2018-07-24, MAE is:2.43 & sMAPE is:4.15% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 13.42% & 0.96\n",
      "for 2018-07-25, MAE is:2.72 & sMAPE is:4.76% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 13.38% & 0.96\n",
      "for 2018-07-26, MAE is:2.24 & sMAPE is:3.92% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 13.34% & 0.95\n",
      "for 2018-07-27, MAE is:2.87 & sMAPE is:4.99% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 13.30% & 0.96\n",
      "for 2018-07-28, MAE is:1.13 & sMAPE is:2.32% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 13.24% & 0.96\n",
      "for 2018-07-29, MAE is:1.86 & sMAPE is:3.65% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 13.20% & 0.95\n",
      "for 2018-07-30, MAE is:7.41 & sMAPE is:11.70% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 13.19% & 0.95\n",
      "for 2018-07-31, MAE is:6.39 & sMAPE is:9.38% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 13.17% & 0.95\n",
      "for 2018-08-01, MAE is:7.00 & sMAPE is:10.46% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 13.16% & 0.95\n",
      "for 2018-08-02, MAE is:3.72 & sMAPE is:6.50% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 13.13% & 0.96\n",
      "for 2018-08-03, MAE is:7.03 & sMAPE is:11.18% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 13.12% & 0.96\n",
      "for 2018-08-04, MAE is:2.08 & sMAPE is:4.05% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 13.08% & 0.96\n",
      "for 2018-08-05, MAE is:1.94 & sMAPE is:3.82% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.52 & 13.04% & 0.96\n",
      "for 2018-08-06, MAE is:2.12 & sMAPE is:3.82% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.51 & 12.99% & 0.95\n",
      "for 2018-08-07, MAE is:2.96 & sMAPE is:5.13% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.50 & 12.96% & 0.95\n",
      "for 2018-08-08, MAE is:3.83 & sMAPE is:6.56% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 12.93% & 0.95\n",
      "for 2018-08-09, MAE is:3.63 & sMAPE is:6.61% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 12.90% & 0.95\n",
      "for 2018-08-10, MAE is:6.24 & sMAPE is:11.23% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 12.89% & 0.95\n",
      "for 2018-08-11, MAE is:1.71 & sMAPE is:3.62% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 12.85% & 0.94\n",
      "for 2018-08-12, MAE is:2.65 & sMAPE is:5.74% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 12.82% & 0.94\n",
      "for 2018-08-13, MAE is:2.88 & sMAPE is:5.11% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.78% & 0.94\n",
      "for 2018-08-14, MAE is:3.84 & sMAPE is:6.57% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.76% & 0.95\n",
      "for 2018-08-15, MAE is:1.33 & sMAPE is:2.38% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.71% & 0.94\n",
      "for 2018-08-16, MAE is:2.87 & sMAPE is:5.42% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.68% & 0.94\n",
      "for 2018-08-17, MAE is:2.11 & sMAPE is:4.12% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.64% & 0.94\n",
      "for 2018-08-18, MAE is:2.46 & sMAPE is:5.15% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.61% & 0.94\n",
      "for 2018-08-19, MAE is:2.53 & sMAPE is:5.72% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.58% & 0.94\n",
      "for 2018-08-20, MAE is:2.04 & sMAPE is:4.07% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.54% & 0.94\n",
      "for 2018-08-21, MAE is:6.29 & sMAPE is:11.12% & rMAE is:4.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.54% & 0.96\n",
      "for 2018-08-22, MAE is:3.66 & sMAPE is:6.26% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.51% & 0.96\n",
      "for 2018-08-23, MAE is:7.50 & sMAPE is:12.65% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.51% & 0.96\n",
      "for 2018-08-24, MAE is:6.01 & sMAPE is:10.70% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.50% & 0.96\n",
      "for 2018-08-25, MAE is:4.23 & sMAPE is:8.59% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.49% & 0.96\n",
      "for 2018-08-26, MAE is:3.53 & sMAPE is:6.92% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.46% & 0.96\n",
      "for 2018-08-27, MAE is:2.11 & sMAPE is:3.67% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 12.43% & 0.96\n",
      "for 2018-08-28, MAE is:10.98 & sMAPE is:17.87% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.45% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-29, MAE is:3.24 & sMAPE is:5.08% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.42% & 0.96\n",
      "for 2018-08-30, MAE is:7.16 & sMAPE is:11.38% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.41% & 0.96\n",
      "for 2018-08-31, MAE is:5.26 & sMAPE is:8.67% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.40% & 0.96\n",
      "for 2018-09-01, MAE is:2.04 & sMAPE is:3.50% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 12.36% & 0.95\n",
      "for 2018-09-02, MAE is:2.32 & sMAPE is:4.28% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 12.33% & 0.95\n",
      "for 2018-09-03, MAE is:4.65 & sMAPE is:7.47% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 12.31% & 0.95\n",
      "for 2018-09-04, MAE is:5.05 & sMAPE is:7.90% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 12.29% & 0.96\n",
      "for 2018-09-05, MAE is:3.18 & sMAPE is:4.93% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 12.26% & 0.96\n",
      "for 2018-09-06, MAE is:3.63 & sMAPE is:5.78% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 12.24% & 0.96\n",
      "for 2018-09-07, MAE is:3.52 & sMAPE is:5.88% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.31 & 12.21% & 0.96\n",
      "for 2018-09-08, MAE is:1.49 & sMAPE is:2.76% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 12.17% & 0.96\n",
      "for 2018-09-09, MAE is:1.34 & sMAPE is:2.50% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 12.13% & 0.96\n",
      "for 2018-09-10, MAE is:3.68 & sMAPE is:6.17% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 12.11% & 0.95\n",
      "for 2018-09-11, MAE is:2.36 & sMAPE is:4.09% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 12.08% & 0.95\n",
      "for 2018-09-12, MAE is:2.91 & sMAPE is:5.29% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 12.05% & 0.95\n",
      "for 2018-09-13, MAE is:4.28 & sMAPE is:7.90% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :5.24 & 12.04% & 0.95\n",
      "for 2018-09-14, MAE is:2.68 & sMAPE is:4.68% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 12.01% & 0.95\n",
      "for 2018-09-15, MAE is:1.98 & sMAPE is:3.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.22 & 11.98% & 0.95\n",
      "for 2018-09-16, MAE is:3.03 & sMAPE is:5.98% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 11.95% & 0.95\n",
      "for 2018-09-17, MAE is:5.26 & sMAPE is:9.03% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 11.94% & 0.95\n",
      "for 2018-09-18, MAE is:5.24 & sMAPE is:9.02% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 11.93% & 0.95\n",
      "for 2018-09-19, MAE is:3.24 & sMAPE is:6.59% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 11.91% & 0.95\n",
      "for 2018-09-20, MAE is:3.75 & sMAPE is:8.97% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 11.90% & 0.94\n",
      "for 2018-09-21, MAE is:8.55 & sMAPE is:25.34% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 11.95% & 0.94\n",
      "for 2018-09-22, MAE is:8.82 & sMAPE is:52.75% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 12.10% & 0.94\n",
      "for 2018-09-23, MAE is:15.35 & sMAPE is:49.08% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 12.24% & 0.94\n",
      "for 2018-09-24, MAE is:12.02 & sMAPE is:34.73% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 12.33% & 0.94\n",
      "for 2018-09-25, MAE is:7.05 & sMAPE is:14.55% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 12.34% & 0.94\n",
      "for 2018-09-26, MAE is:10.30 & sMAPE is:36.80% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 12.43% & 0.94\n",
      "for 2018-09-27, MAE is:11.67 & sMAPE is:30.43% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 12.49% & 0.94\n",
      "for 2018-09-28, MAE is:10.99 & sMAPE is:21.14% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.53% & 0.94\n",
      "for 2018-09-29, MAE is:8.02 & sMAPE is:20.49% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.55% & 0.94\n",
      "for 2018-09-30, MAE is:8.04 & sMAPE is:24.13% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.60% & 0.94\n",
      "for 2018-10-01, MAE is:5.95 & sMAPE is:14.37% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.60% & 0.94\n",
      "for 2018-10-02, MAE is:6.33 & sMAPE is:12.63% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.60% & 0.94\n",
      "for 2018-10-03, MAE is:5.15 & sMAPE is:10.48% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.60% & 0.94\n",
      "for 2018-10-04, MAE is:12.48 & sMAPE is:22.76% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.63% & 0.94\n",
      "for 2018-10-05, MAE is:3.79 & sMAPE is:7.31% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.61% & 0.93\n",
      "for 2018-10-06, MAE is:2.07 & sMAPE is:4.59% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.58% & 0.93\n",
      "for 2018-10-07, MAE is:5.91 & sMAPE is:12.63% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.58% & 0.93\n",
      "for 2018-10-08, MAE is:3.26 & sMAPE is:6.49% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.56% & 0.93\n",
      "for 2018-10-09, MAE is:1.84 & sMAPE is:4.06% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.53% & 0.93\n",
      "for 2018-10-10, MAE is:3.09 & sMAPE is:6.16% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.51% & 0.93\n",
      "for 2018-10-11, MAE is:5.11 & sMAPE is:11.06% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.51% & 0.93\n",
      "for 2018-10-12, MAE is:4.83 & sMAPE is:9.74% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.50% & 0.93\n",
      "for 2018-10-13, MAE is:7.21 & sMAPE is:21.03% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.53% & 0.93\n",
      "for 2018-10-14, MAE is:11.32 & sMAPE is:67.32% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.72% & 0.93\n",
      "for 2018-10-15, MAE is:21.54 & sMAPE is:72.17% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.92% & 0.93\n",
      "for 2018-10-16, MAE is:6.34 & sMAPE is:14.56% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.93% & 0.93\n",
      "for 2018-10-17, MAE is:3.19 & sMAPE is:6.54% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.91% & 0.93\n",
      "for 2018-10-18, MAE is:8.99 & sMAPE is:17.21% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.92% & 0.93\n",
      "for 2018-10-19, MAE is:4.78 & sMAPE is:9.88% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.91% & 0.93\n",
      "for 2018-10-20, MAE is:3.21 & sMAPE is:7.77% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.89% & 0.93\n",
      "for 2018-10-21, MAE is:5.35 & sMAPE is:14.28% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.90% & 0.93\n",
      "for 2018-10-22, MAE is:5.83 & sMAPE is:16.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.91% & 0.93\n",
      "for 2018-10-23, MAE is:9.50 & sMAPE is:26.32% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 12.95% & 0.93\n",
      "for 2018-10-24, MAE is:6.88 & sMAPE is:15.37% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 12.96% & 0.93\n",
      "for 2018-10-25, MAE is:5.80 & sMAPE is:12.06% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 12.96% & 0.93\n",
      "for 2018-10-26, MAE is:10.58 & sMAPE is:19.82% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 12.98% & 0.93\n",
      "for 2018-10-27, MAE is:0.88 & sMAPE is:2.00% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 12.95% & 0.93\n",
      "for 2018-10-28, MAE is:1.05 & sMAPE is:2.34% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.91% & 0.93\n",
      "for 2018-10-29, MAE is:4.98 & sMAPE is:9.97% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.90% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-30, MAE is:4.65 & sMAPE is:10.26% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.89% & 0.93\n",
      "for 2018-10-31, MAE is:6.15 & sMAPE is:13.71% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 12.89% & 0.93\n",
      "for 2018-11-01, MAE is:2.60 & sMAPE is:5.81% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 12.87% & 0.93\n",
      "for 2018-11-02, MAE is:2.65 & sMAPE is:5.94% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 12.85% & 0.92\n",
      "for 2018-11-03, MAE is:1.39 & sMAPE is:3.29% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.82% & 0.92\n",
      "for 2018-11-04, MAE is:2.25 & sMAPE is:5.42% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.79% & 0.93\n",
      "for 2018-11-05, MAE is:3.02 & sMAPE is:6.61% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.77% & 0.93\n",
      "for 2018-11-06, MAE is:5.58 & sMAPE is:10.58% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.77% & 0.93\n",
      "for 2018-11-07, MAE is:7.27 & sMAPE is:13.92% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.77% & 0.93\n",
      "for 2018-11-08, MAE is:9.60 & sMAPE is:16.58% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.78% & 0.93\n",
      "for 2018-11-09, MAE is:3.30 & sMAPE is:6.74% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.76% & 0.93\n",
      "for 2018-11-10, MAE is:2.60 & sMAPE is:5.83% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.74% & 0.93\n",
      "for 2018-11-11, MAE is:3.17 & sMAPE is:8.02% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.73% & 0.93\n",
      "for 2018-11-12, MAE is:2.79 & sMAPE is:6.10% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.70% & 0.93\n",
      "for 2018-11-13, MAE is:4.16 & sMAPE is:9.25% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.69% & 0.93\n",
      "for 2018-11-14, MAE is:7.61 & sMAPE is:14.30% & rMAE is:3.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.70% & 0.94\n",
      "for 2018-11-15, MAE is:2.46 & sMAPE is:5.13% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.68% & 0.94\n",
      "for 2018-11-16, MAE is:2.12 & sMAPE is:4.51% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.65% & 0.94\n",
      "for 2018-11-17, MAE is:2.91 & sMAPE is:6.52% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.63% & 0.94\n",
      "for 2018-11-18, MAE is:3.50 & sMAPE is:7.74% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 12.62% & 0.94\n",
      "for 2018-11-19, MAE is:3.19 & sMAPE is:6.23% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.60% & 0.94\n",
      "for 2018-11-20, MAE is:2.54 & sMAPE is:5.52% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 12.57% & 0.94\n",
      "for 2018-11-21, MAE is:4.54 & sMAPE is:7.95% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 12.56% & 0.94\n",
      "for 2018-11-22, MAE is:16.12 & sMAPE is:23.34% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.59% & 0.94\n",
      "for 2018-11-23, MAE is:5.91 & sMAPE is:10.20% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :5.38 & 12.59% & 0.94\n",
      "for 2018-11-24, MAE is:2.26 & sMAPE is:4.82% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.56% & 0.94\n",
      "for 2018-11-25, MAE is:1.19 & sMAPE is:2.42% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.53% & 0.94\n",
      "for 2018-11-26, MAE is:12.43 & sMAPE is:17.19% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 12.54% & 0.94\n",
      "for 2018-11-27, MAE is:20.08 & sMAPE is:28.17% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.59% & 0.94\n",
      "for 2018-11-28, MAE is:8.57 & sMAPE is:14.84% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 12.60% & 0.94\n",
      "for 2018-11-29, MAE is:3.65 & sMAPE is:7.83% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.58% & 0.94\n",
      "for 2018-11-30, MAE is:2.26 & sMAPE is:5.08% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.56% & 0.93\n",
      "for 2018-12-01, MAE is:1.76 & sMAPE is:3.93% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.54% & 0.93\n",
      "for 2018-12-02, MAE is:2.88 & sMAPE is:6.68% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.52% & 0.93\n",
      "for 2018-12-03, MAE is:3.10 & sMAPE is:6.56% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.50% & 0.93\n",
      "for 2018-12-04, MAE is:4.20 & sMAPE is:8.92% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.49% & 0.93\n",
      "for 2018-12-05, MAE is:9.43 & sMAPE is:17.68% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.51% & 0.93\n",
      "for 2018-12-06, MAE is:7.75 & sMAPE is:14.52% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.51% & 0.93\n",
      "for 2018-12-07, MAE is:4.46 & sMAPE is:8.11% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.50% & 0.93\n",
      "for 2018-12-08, MAE is:1.38 & sMAPE is:3.20% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.47% & 0.93\n",
      "for 2018-12-09, MAE is:4.64 & sMAPE is:12.06% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :5.39 & 12.47% & 0.93\n",
      "for 2018-12-10, MAE is:9.43 & sMAPE is:19.21% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.49% & 0.93\n",
      "for 2018-12-11, MAE is:7.07 & sMAPE is:12.80% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.49% & 0.93\n",
      "for 2018-12-12, MAE is:8.11 & sMAPE is:13.22% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.49% & 0.93\n",
      "for 2018-12-13, MAE is:6.81 & sMAPE is:11.48% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.49% & 0.94\n",
      "for 2018-12-14, MAE is:6.21 & sMAPE is:10.26% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.48% & 0.94\n",
      "for 2018-12-15, MAE is:2.96 & sMAPE is:5.83% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.46% & 0.93\n",
      "for 2018-12-16, MAE is:2.11 & sMAPE is:4.29% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.44% & 0.93\n",
      "for 2018-12-17, MAE is:11.71 & sMAPE is:17.88% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.46% & 0.93\n",
      "for 2018-12-18, MAE is:7.28 & sMAPE is:11.89% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.46% & 0.93\n",
      "for 2018-12-19, MAE is:5.12 & sMAPE is:8.51% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.44% & 0.93\n",
      "for 2018-12-20, MAE is:5.57 & sMAPE is:9.21% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.44% & 0.94\n",
      "for 2018-12-21, MAE is:4.66 & sMAPE is:7.85% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.42% & 0.94\n",
      "for 2018-12-22, MAE is:1.38 & sMAPE is:2.70% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.39% & 0.94\n",
      "for 2018-12-23, MAE is:3.10 & sMAPE is:6.00% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.38% & 0.94\n",
      "for 2018-12-24, MAE is:3.78 & sMAPE is:7.10% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.36% & 0.93\n",
      "for 2018-12-25, MAE is:5.26 & sMAPE is:12.22% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.36% & 0.93\n",
      "for 2018-12-26, MAE is:10.79 & sMAPE is:27.23% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.40% & 0.93\n",
      "for 2018-12-27, MAE is:4.82 & sMAPE is:9.54% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 12.40% & 0.93\n",
      "for 2018-12-28, MAE is:6.28 & sMAPE is:11.76% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 12.39% & 0.93\n",
      "for 2018-12-29, MAE is:1.49 & sMAPE is:3.02% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.37% & 0.93\n",
      "for 2018-12-30, MAE is:4.08 & sMAPE is:8.35% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.36% & 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:04:08,176]\u001b[0m Using an existing study with name 'FI_2019' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-31, MAE is:5.41 & sMAPE is:11.41% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 12.35% & 0.94\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:04:28,416]\u001b[0m Trial 135 finished with value: 5.666228996681767 and parameters: {'n_hidden': 3, 'learning_rate': 0.005440109504587367, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021891340073731516, 'dropout_rate_Layer_2': 0.20965149173197634, 'dropout_rate_Layer_3': 0.03310226574261897, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7407338456947372e-05, 'l1_Layer_2': 1.43198475306803e-05, 'l1_Layer_3': 0.037994191149336484, 'n_units_Layer_1': 285, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 98 with value: 5.281086055597558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 12.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:04:32,766]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:04:40,191]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:06:00,215]\u001b[0m Trial 138 finished with value: 5.24869559007428 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035211549618156617, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06341009838430145, 'dropout_rate_Layer_2': 0.20334153795154591, 'dropout_rate_Layer_3': 0.05045629288983397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.538716025694064e-05, 'l1_Layer_2': 3.8752360353563e-05, 'l1_Layer_3': 0.005341730925027741, 'n_units_Layer_1': 90, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 14.89% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:06:09,554]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:06:16,579]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:06:47,218]\u001b[0m Trial 141 finished with value: 5.551896512956813 and parameters: {'n_hidden': 3, 'learning_rate': 0.003765329426338053, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05007048391047389, 'dropout_rate_Layer_2': 0.2088131071701768, 'dropout_rate_Layer_3': 0.05560673520456888, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7069799755763942e-05, 'l1_Layer_2': 3.522527036528361e-05, 'l1_Layer_3': 0.005714104933585643, 'n_units_Layer_1': 90, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:06:58,135]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:08:18,512]\u001b[0m Trial 143 finished with value: 5.4357052792206355 and parameters: {'n_hidden': 3, 'learning_rate': 0.004809130498659921, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0694589090937123, 'dropout_rate_Layer_2': 0.1911312714077533, 'dropout_rate_Layer_3': 0.05429933436173848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5829738675577652e-05, 'l1_Layer_2': 3.6134288586205093e-05, 'l1_Layer_3': 0.013742709497224668, 'n_units_Layer_1': 75, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:08:28,481]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:08:32,470]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:08:52,646]\u001b[0m Trial 146 finished with value: 5.432569438549836 and parameters: {'n_hidden': 3, 'learning_rate': 0.009338707740366223, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010608251472404191, 'dropout_rate_Layer_2': 0.3668532761179705, 'dropout_rate_Layer_3': 0.3483439777998254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004527732437542993, 'l1_Layer_2': 0.00038977562935243494, 'l1_Layer_3': 1.1326307465437211e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 80, 'n_units_Layer_3': 250}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 12.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 15.82% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:08:56,712]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:09:49,731]\u001b[0m Trial 148 finished with value: 5.32435675132652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030106240328116774, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013630473039551082, 'dropout_rate_Layer_2': 0.17600845003078314, 'dropout_rate_Layer_3': 0.05374326217724268, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.046194480065322e-05, 'l1_Layer_2': 3.9128648083170715e-05, 'l1_Layer_3': 0.014002219340073492, 'n_units_Layer_1': 50, 'n_units_Layer_2': 80, 'n_units_Layer_3': 190}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 11.94% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:09:53,356]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:09,908]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:14,182]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:19,512]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:23,681]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:28,481]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:32,251]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:41,270]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:10:57,491]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:11:03,175]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:11:28,375]\u001b[0m Trial 159 finished with value: 7.732847319350785 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 18.32% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:11:33,973]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:11:41,966]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:11:47,817]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:12:04,122]\u001b[0m Trial 163 finished with value: 9.914977245961266 and parameters: {'n_hidden': 3, 'learning_rate': 0.02043439289550321, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1669226097601424, 'dropout_rate_Layer_2': 0.2883681312389442, 'dropout_rate_Layer_3': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019638194370642372, 'l1_Layer_2': 0.0009449992203604101, 'l1_Layer_3': 1.7508089836152578e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 138 with value: 5.24869559007428.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.91 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 22.77% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:12:34,476]\u001b[0m Trial 164 finished with value: 5.055736733801537 and parameters: {'n_hidden': 3, 'learning_rate': 0.003793660930434398, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05827730977782626, 'dropout_rate_Layer_2': 0.1805899140529457, 'dropout_rate_Layer_3': 0.006400972245295206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.840557667706276e-05, 'l1_Layer_2': 3.945309211804828e-05, 'l1_Layer_3': 0.005092138217537802, 'n_units_Layer_1': 90, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:12:40,020]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:13:18,057]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:13:22,022]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:13:25,572]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:13:34,061]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:14:03,389]\u001b[0m Trial 170 finished with value: 5.5050903206031405 and parameters: {'n_hidden': 3, 'learning_rate': 0.007054110853376935, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07779354453771786, 'dropout_rate_Layer_2': 0.12197308505087792, 'dropout_rate_Layer_3': 0.00690046203241973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2718205166964228e-05, 'l1_Layer_2': 2.181681438863097e-05, 'l1_Layer_3': 0.0019122638997368577, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 12.05% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 15.13% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:14:09,438]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:14:13,411]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:14:27,613]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:14:31,972]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:15:24,104]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:15:55,509]\u001b[0m Trial 176 finished with value: 5.40307322104772 and parameters: {'n_hidden': 3, 'learning_rate': 0.006766216165559864, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07570055858266106, 'dropout_rate_Layer_2': 0.1570447575482241, 'dropout_rate_Layer_3': 0.0021567180329748912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2484632310685625e-05, 'l1_Layer_2': 1.7314746551608148e-05, 'l1_Layer_3': 0.0021925290985545035, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:16:09,697]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:13,459]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:22,562]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:27,545]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:36,235]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:42,649]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:49,987]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:16:54,172]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:17:02,036]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:17:10,017]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:17:31,942]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:18:06,463]\u001b[0m Trial 188 finished with value: 8.810622520540013 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007149284812719697, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12608447112948556, 'dropout_rate_Layer_2': 0.3696527011867759, 'dropout_rate_Layer_3': 0.07280864135905066, 'dropout_rate_Layer_4': 0.11190531815242527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 8.264392365524795e-05, 'l1_Layer_2': 1.9345671280203125e-05, 'l1_Layer_3': 0.0007290800848895018, 'l1_Layer_4': 0.0009435505099533775, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 7.46 | sMAPE for Test Set is: 18.09% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:18:28,666]\u001b[0m Trial 189 finished with value: 5.930080005784052 and parameters: {'n_hidden': 3, 'learning_rate': 0.09552863950955486, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38822091191716623, 'dropout_rate_Layer_2': 0.19453154272118953, 'dropout_rate_Layer_3': 0.30867919320760523, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.460001730073588e-05, 'l1_Layer_2': 0.0005949364596097605, 'l1_Layer_3': 0.09380924843729435, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 13.19% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.71% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:18:38,090]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:18:42,357]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:18:50,795]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:18:55,827]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:19:02,105]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:19:07,637]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:19:11,516]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:19:15,280]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:19:19,480]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:20:40,100]\u001b[0m Trial 199 finished with value: 6.385234575897621 and parameters: {'n_hidden': 4, 'learning_rate': 0.0044768196495760726, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01813082704135005, 'dropout_rate_Layer_2': 0.3956950463695265, 'dropout_rate_Layer_3': 0.2827276319967715, 'dropout_rate_Layer_4': 0.36034107667384696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017941955197833077, 'l1_Layer_2': 7.691587829351679e-05, 'l1_Layer_3': 0.0005540614709872965, 'l1_Layer_4': 5.644504058283056e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 280, 'n_units_Layer_3': 100, 'n_units_Layer_4': 230}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 16.72% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:20:55,144]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:21:04,577]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:21:22,240]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:21:30,965]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:21:38,949]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:21:47,802]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:21:52,531]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:06,694]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:12,535]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:17,020]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:23,030]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:29,367]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:33,311]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:38,822]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:43,796]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:48,712]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:52,851]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:22:56,641]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:01,574]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:06,708]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:12,608]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:16,059]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:22,727]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:37,692]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:43,963]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:47,184]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:23:51,292]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:24:02,838]\u001b[0m Trial 227 finished with value: 9.982408867157593 and parameters: {'n_hidden': 3, 'learning_rate': 0.055253663196854146, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3727669795240734, 'dropout_rate_Layer_2': 0.34544090184346715, 'dropout_rate_Layer_3': 0.3458689286003118, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01999031829135244, 'l1_Layer_2': 0.05841049604887016, 'l1_Layer_3': 0.003971599824250398, 'n_units_Layer_1': 115, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.98 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 21.03% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:24:13,265]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:24:17,584]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:24:36,669]\u001b[0m Trial 230 finished with value: 6.145567792008042 and parameters: {'n_hidden': 3, 'learning_rate': 0.004131547011612929, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3932468379428143, 'dropout_rate_Layer_2': 0.1844866916273114, 'dropout_rate_Layer_3': 0.2819473374017195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018425616787673133, 'l1_Layer_2': 0.0005356822605634538, 'l1_Layer_3': 0.0002638524858924727, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 13.45% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:24:45,342]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:25:27,889]\u001b[0m Trial 232 finished with value: 5.208286046005049 and parameters: {'n_hidden': 3, 'learning_rate': 0.011037388615060609, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07771388691562123, 'dropout_rate_Layer_2': 0.15133648528801416, 'dropout_rate_Layer_3': 0.018962899396940174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.916493514175971e-05, 'l1_Layer_2': 5.231437640760429e-05, 'l1_Layer_3': 0.007015635657256303, 'n_units_Layer_1': 95, 'n_units_Layer_2': 60, 'n_units_Layer_3': 160}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 14.68% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:25:37,302]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:25:41,258]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:25:45,926]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:25:52,347]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:25:58,038]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:26:22,753]\u001b[0m Trial 238 finished with value: 5.355254547409505 and parameters: {'n_hidden': 4, 'learning_rate': 0.008535928868256723, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04432873141500096, 'dropout_rate_Layer_2': 0.2081745537240819, 'dropout_rate_Layer_3': 0.19149816775461756, 'dropout_rate_Layer_4': 0.008855953931346916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.035945870241862715, 'l1_Layer_2': 0.0001380757033313408, 'l1_Layer_3': 0.00038871447968530707, 'l1_Layer_4': 1.1056398397277305e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 130, 'n_units_Layer_3': 180, 'n_units_Layer_4': 50}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:26:30,268]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:26:42,236]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:26:48,771]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:26:56,707]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:27:27,776]\u001b[0m Trial 243 finished with value: 5.323917728584792 and parameters: {'n_hidden': 4, 'learning_rate': 0.00932415864055084, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0011029998536157774, 'dropout_rate_Layer_2': 0.29454392804994994, 'dropout_rate_Layer_3': 0.3070616328502629, 'dropout_rate_Layer_4': 0.11304681390730059, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00886579377757601, 'l1_Layer_2': 0.0003156441614801989, 'l1_Layer_3': 0.000145440927411102, 'l1_Layer_4': 1.1637706474671143e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 120, 'n_units_Layer_3': 175, 'n_units_Layer_4': 115}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 14.75% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:27:36,179]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:27:56,776]\u001b[0m Trial 245 finished with value: 5.711479611290233 and parameters: {'n_hidden': 3, 'learning_rate': 0.011503546922593005, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0009994159737821166, 'dropout_rate_Layer_2': 0.06818827629207178, 'dropout_rate_Layer_3': 0.1274748959829865, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2335114401413426e-05, 'l1_Layer_2': 0.0006255033186848523, 'l1_Layer_3': 0.000142008401175623, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 100}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:28:00,791]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:09,465]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:16,423]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:27,490]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:33,911]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:39,497]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:42,849]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:47,328]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:52,320]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:28:56,183]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:29:10,912]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:29:14,901]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:29:45,913]\u001b[0m Trial 258 finished with value: 7.352449972358719 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.35 | sMAPE for Validation Set is: 16.22% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 17.95% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:29:57,643]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:10,200]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:13,939]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:19,845]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:24,138]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:28,266]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:32,518]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:44,448]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:53,405]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:30:57,105]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:01,458]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:05,859]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:09,670]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:13,595]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:17,388]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:26,315]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:36,885]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:40,778]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:48,101]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:31:52,548]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:14,780]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:18,791]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:22,978]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:29,909]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:33,722]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:38,571]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:47,602]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:53,411]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:32:59,713]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:03,179]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:07,468]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:18,866]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:27,552]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:31,932]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:37,080]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:40,539]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:46,612]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:33:52,435]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:34:08,065]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:01,564]\u001b[0m Trial 298 finished with value: 5.299831628417613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036448672133099556, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04539279658832278, 'dropout_rate_Layer_2': 0.215297608869445, 'dropout_rate_Layer_3': 0.05306284062108654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.614300381660926e-05, 'l1_Layer_2': 3.959860058217993e-05, 'l1_Layer_3': 0.009873094930066995, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.52 | sMAPE for Test Set is: 14.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:35:05,215]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:10,344]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:14,044]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:34,502]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:38,525]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:42,637]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:35:48,871]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:36:28,514]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:36:33,050]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:36:47,630]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:37:27,920]\u001b[0m Trial 309 finished with value: 5.334341158933479 and parameters: {'n_hidden': 3, 'learning_rate': 0.003317505453777511, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01175430077633384, 'dropout_rate_Layer_2': 0.2612645113805632, 'dropout_rate_Layer_3': 0.037918555028434955, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2829733683987649e-05, 'l1_Layer_2': 2.8082495416188003e-05, 'l1_Layer_3': 0.012475902872973423, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 215}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 11.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 14.85% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:37:36,427]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:37:43,378]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:37:49,596]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:38:20,443]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:38:24,825]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:38:33,725]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:38:37,677]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:38:43,243]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:38:59,133]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:39:04,667]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:39:11,760]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:39:40,230]\u001b[0m Trial 321 finished with value: 10.265379137238087 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013878420558099073, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3750512572232201, 'dropout_rate_Layer_2': 0.0972247107702501, 'dropout_rate_Layer_3': 0.2871549569339343, 'dropout_rate_Layer_4': 0.11611594516575559, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00591468720976618, 'l1_Layer_2': 0.00258532431426045, 'l1_Layer_3': 3.943169225185429e-05, 'l1_Layer_4': 0.00443349752716847, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 205, 'n_units_Layer_4': 215}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.27 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 1.30\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 21.71% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:40:04,365]\u001b[0m Trial 322 finished with value: 6.55683045108447 and parameters: {'n_hidden': 3, 'learning_rate': 0.09379569356567374, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3377664130771256, 'dropout_rate_Layer_2': 0.1485982049581919, 'dropout_rate_Layer_3': 0.19238881315003456, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0039148675586577605, 'l1_Layer_2': 0.001114619340334869, 'l1_Layer_3': 0.0005948657412919942, 'n_units_Layer_1': 50, 'n_units_Layer_2': 140, 'n_units_Layer_3': 55}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 17.89% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:40:32,780]\u001b[0m Trial 323 finished with value: 7.576853382818303 and parameters: {'n_hidden': 3, 'learning_rate': 0.03287577865472878, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3543006450642185, 'dropout_rate_Layer_2': 0.2218595958571739, 'dropout_rate_Layer_3': 0.32687055377277197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.911268695886246e-05, 'l1_Layer_2': 0.00026938398928504705, 'l1_Layer_3': 0.0007978268741299222, 'n_units_Layer_1': 135, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.58 | sMAPE for Validation Set is: 16.68% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:40:39,090]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:40:49,271]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:40:52,724]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:41:08,109]\u001b[0m Trial 327 finished with value: 8.240815909685812 and parameters: {'n_hidden': 3, 'learning_rate': 0.00933250880832266, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3604783340437895, 'dropout_rate_Layer_2': 0.17161236391776488, 'dropout_rate_Layer_3': 0.196934933813728, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.745280594442716e-05, 'l1_Layer_2': 0.0014822823970290927, 'l1_Layer_3': 0.022201348116214707, 'n_units_Layer_1': 170, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 18.78% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 7.87 | sMAPE for Test Set is: 19.65% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:41:25,675]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:41:29,617]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:41:34,588]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:41:39,719]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:41:46,091]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:42:08,329]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:42:37,311]\u001b[0m Trial 334 finished with value: 5.059101515007196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034102214544970517, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05659468201687101, 'dropout_rate_Layer_2': 0.15313879106938516, 'dropout_rate_Layer_3': 0.03673039853259483, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1500641838303107e-05, 'l1_Layer_2': 1.2034834959729575e-05, 'l1_Layer_3': 0.013575800080269365, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 225}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.70 | sMAPE for Test Set is: 14.58% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:42:41,924]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:43:01,846]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:43:05,407]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:43:09,632]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:43:18,267]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:43:45,941]\u001b[0m Trial 340 finished with value: 6.153919505549098 and parameters: {'n_hidden': 3, 'learning_rate': 0.013523430078187487, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011135781628051546, 'dropout_rate_Layer_2': 0.056409058815920905, 'dropout_rate_Layer_3': 0.32650708100266157, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.161245565878536e-05, 'l1_Layer_2': 0.000766049344912331, 'l1_Layer_3': 0.0002521416334324769, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 125}. Best is trial 164 with value: 5.055736733801537.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 13.54% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:43:50,536]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:43:55,380]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:44:00,345]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:44:06,553]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:44:15,007]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:44:24,211]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:44:49,055]\u001b[0m Trial 347 finished with value: 5.022441019674474 and parameters: {'n_hidden': 3, 'learning_rate': 0.008725410457255858, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012901141786571292, 'dropout_rate_Layer_2': 0.3416507485381881, 'dropout_rate_Layer_3': 0.20641694387104478, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006229192058806023, 'l1_Layer_2': 7.240096564030407e-05, 'l1_Layer_3': 3.264338802323287e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 347 with value: 5.022441019674474.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:44:53,491]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:45:02,261]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:45:05,910]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:45:47,234]\u001b[0m Trial 351 finished with value: 4.987662499195147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015980698338572267, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059045043751557086, 'dropout_rate_Layer_2': 0.16173604282200654, 'dropout_rate_Layer_3': 0.07523562479911118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.710431565459289e-05, 'l1_Layer_2': 3.8189562307669655e-05, 'l1_Layer_3': 0.031460433557619925, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 14.61% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:45:51,009]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:45:55,657]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:00,392]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:04,460]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:28,695]\u001b[0m Trial 356 finished with value: 9.837939476198768 and parameters: {'n_hidden': 4, 'learning_rate': 0.004173660796937017, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12502254715619876, 'dropout_rate_Layer_2': 0.3507047191569168, 'dropout_rate_Layer_3': 0.0742395847728644, 'dropout_rate_Layer_4': 0.1555727965869839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004149825295680265, 'l1_Layer_2': 5.7743772398847734e-05, 'l1_Layer_3': 0.000124010863661017, 'l1_Layer_4': 0.00027108563561846754, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.84 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 21.56% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:46:32,914]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:37,570]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:41,701]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:46,645]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:46:51,504]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:47:00,244]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:47:30,899]\u001b[0m Trial 363 finished with value: 5.142363221860687 and parameters: {'n_hidden': 3, 'learning_rate': 0.007165114393350436, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01972761270361678, 'dropout_rate_Layer_2': 0.34248009395460394, 'dropout_rate_Layer_3': 0.21124539193800132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028776002567132208, 'l1_Layer_2': 6.015207654829922e-05, 'l1_Layer_3': 6.06897969726022e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 220}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 14.40% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:47:44,254]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:47:47,596]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:50:22,829]\u001b[0m Trial 366 finished with value: 6.6072840216528315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005337467130078826, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011092794421635044, 'dropout_rate_Layer_2': 0.205218602268399, 'dropout_rate_Layer_3': 0.1967077359584341, 'dropout_rate_Layer_4': 0.39387624431754936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0769710075473707e-05, 'l1_Layer_2': 1.7652325424141376e-05, 'l1_Layer_3': 0.01915544547816285, 'l1_Layer_4': 0.07764279568071372, 'n_units_Layer_1': 70, 'n_units_Layer_2': 270, 'n_units_Layer_3': 50, 'n_units_Layer_4': 300}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 14.82% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 16.90% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:50:28,490]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:50:47,867]\u001b[0m Trial 368 finished with value: 6.303880043811193 and parameters: {'n_hidden': 3, 'learning_rate': 0.00651512431868221, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15644322262892524, 'dropout_rate_Layer_2': 0.28558957112021055, 'dropout_rate_Layer_3': 0.25733878570935953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.181574935044205e-05, 'l1_Layer_2': 0.002090303979050236, 'l1_Layer_3': 0.0003994874123144068, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:50:51,825]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:50:57,093]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:51:00,746]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:51:07,726]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:51:11,739]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:51:22,580]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:51:43,296]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:51:47,095]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:52:04,338]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:52:12,389]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:52:19,022]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:52:22,707]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:53:44,671]\u001b[0m Trial 381 finished with value: 5.0304105742550425 and parameters: {'n_hidden': 3, 'learning_rate': 0.011240137088491338, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06763254567354093, 'dropout_rate_Layer_2': 0.29491198660613444, 'dropout_rate_Layer_3': 0.2028860763761599, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003064987469148652, 'l1_Layer_2': 1.0423839981080765e-05, 'l1_Layer_3': 6.821302073955012e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 11.10% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:53:48,665]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:53:53,485]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:53:57,584]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:54:02,443]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:54:09,042]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:54:15,462]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:55:03,865]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:55:08,690]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:55:20,034]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:55:31,787]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:55:37,270]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:55:41,661]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:15,233]\u001b[0m Trial 394 finished with value: 5.66111043313806 and parameters: {'n_hidden': 3, 'learning_rate': 0.01163413854816632, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019306948931395937, 'dropout_rate_Layer_2': 0.07678656789233301, 'dropout_rate_Layer_3': 0.1382794316863478, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3377089808121006e-05, 'l1_Layer_2': 1.9534924500148446e-05, 'l1_Layer_3': 0.00030724015595974357, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 95}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 12.56% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:56:20,395]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:29,834]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:38,315]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:44,143]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:49,933]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:54,584]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:56:57,789]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:57:03,077]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:57:07,385]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:57:31,641]\u001b[0m Trial 404 finished with value: 5.193191718176089 and parameters: {'n_hidden': 3, 'learning_rate': 0.002752419131901528, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03031625875716637, 'dropout_rate_Layer_2': 0.17210380705420553, 'dropout_rate_Layer_3': 0.06138972970440007, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5517724143397505e-05, 'l1_Layer_2': 3.168063517540583e-05, 'l1_Layer_3': 0.00555857726566876, 'n_units_Layer_1': 85, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.19 | sMAPE for Validation Set is: 11.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:57:43,310]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:58:12,471]\u001b[0m Trial 406 finished with value: 5.063487587312523 and parameters: {'n_hidden': 3, 'learning_rate': 0.00194352600635539, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0293435354724548, 'dropout_rate_Layer_2': 0.17250029955741303, 'dropout_rate_Layer_3': 0.08924325667224427, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.406777439767729e-05, 'l1_Layer_2': 2.9752916196752914e-05, 'l1_Layer_3': 0.005574662667728545, 'n_units_Layer_1': 90, 'n_units_Layer_2': 230, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 14.61% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:58:18,140]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:58:22,214]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:58:31,196]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:58:36,071]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:58:41,583]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:58:59,790]\u001b[0m Trial 412 finished with value: 6.076879265228463 and parameters: {'n_hidden': 3, 'learning_rate': 0.03166214283907858, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3556544331146468, 'dropout_rate_Layer_2': 0.31810469291286586, 'dropout_rate_Layer_3': 0.2245106297007373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.257069053677527e-05, 'l1_Layer_2': 0.000557844116934787, 'l1_Layer_3': 0.001502160982826759, 'n_units_Layer_1': 90, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 15.28% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 03:59:04,277]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:09,949]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:24,827]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:28,798]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:33,057]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:40,949]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:44,846]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:48,724]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:53,678]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 03:59:58,146]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:00:03,119]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:00:26,916]\u001b[0m Trial 424 finished with value: 5.931719714143423 and parameters: {'n_hidden': 3, 'learning_rate': 0.04014476219701467, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3582402707676212, 'dropout_rate_Layer_2': 0.39952757879304596, 'dropout_rate_Layer_3': 0.2153554618616747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5365902791434686e-05, 'l1_Layer_2': 0.0004101673917573927, 'l1_Layer_3': 0.0008435130562627553, 'n_units_Layer_1': 95, 'n_units_Layer_2': 210, 'n_units_Layer_3': 185}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 15.34% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:02:32,887]\u001b[0m Trial 425 finished with value: 6.440625073270425 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005264786847264253, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0031557618404880385, 'dropout_rate_Layer_2': 0.23266830070403022, 'dropout_rate_Layer_3': 0.18855758068654294, 'dropout_rate_Layer_4': 0.39516887397471967, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0269841090487405e-05, 'l1_Layer_2': 1.2321823510345666e-05, 'l1_Layer_3': 0.09528674155914083, 'l1_Layer_4': 0.07981100748105069, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 285}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 15.31% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:02:42,198]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:02:50,871]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:03:15,431]\u001b[0m Trial 428 finished with value: 5.863934960578406 and parameters: {'n_hidden': 3, 'learning_rate': 0.011700118640972798, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1553980937856724, 'dropout_rate_Layer_2': 0.07146367736731399, 'dropout_rate_Layer_3': 0.13597893727177074, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5371102848826313e-05, 'l1_Layer_2': 1.072823169368322e-05, 'l1_Layer_3': 0.0003667584374075703, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 100}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:03:20,954]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:03:25,719]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:03:34,428]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:03:42,452]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:03:46,882]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:03:52,329]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:01,236]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:05,775]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:13,301]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:16,767]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:21,170]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:25,441]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:29,407]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:35,226]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:04:39,815]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:05:40,832]\u001b[0m Trial 444 finished with value: 5.364547211304722 and parameters: {'n_hidden': 3, 'learning_rate': 0.010869285341691988, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01412967885089832, 'dropout_rate_Layer_2': 0.30573439348551124, 'dropout_rate_Layer_3': 0.2677046246359494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023918149832962914, 'l1_Layer_2': 4.166255066844634e-05, 'l1_Layer_3': 2.0868016653878296e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 235}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 15.50% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:05:44,252]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:05:48,329]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:05:52,102]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:05:56,653]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:02,271]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:09,183]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:25,072]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:29,620]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:33,323]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:39,948]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:44,748]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:50,797]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:06:55,344]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:09:19,817]\u001b[0m Trial 458 finished with value: 6.524419820468519 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031093438014950436, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004198157474513924, 'dropout_rate_Layer_2': 0.21881737534527346, 'dropout_rate_Layer_3': 0.19938742691606784, 'dropout_rate_Layer_4': 0.3863681852229391, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0473996172597373e-05, 'l1_Layer_2': 1.0758597313570637e-05, 'l1_Layer_3': 0.08219568865488623, 'l1_Layer_4': 1.1711620438314293e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 275}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:09:28,608]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:09:57,018]\u001b[0m Trial 460 finished with value: 5.95881605538576 and parameters: {'n_hidden': 3, 'learning_rate': 0.03970377087860826, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3569939754137878, 'dropout_rate_Layer_2': 0.3971384283260884, 'dropout_rate_Layer_3': 0.21573168321462016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.452621471270363e-05, 'l1_Layer_2': 0.00017783126564355624, 'l1_Layer_3': 0.0013634924152604976, 'n_units_Layer_1': 100, 'n_units_Layer_2': 220, 'n_units_Layer_3': 180}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.30 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:10:01,551]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:10,146]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:16,370]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:21,207]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:25,542]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:28,985]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:37,919]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:43,593]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:48,282]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:51,752]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:10:56,654]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:00,958]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:04,985]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:10,221]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:14,410]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:17,898]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:25,833]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:42,332]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:46,472]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:11:57,798]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:02,463]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:07,979]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:13,161]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:26,141]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:32,196]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:36,659]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:40,522]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:46,060]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:49,736]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:12:55,492]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:13:01,992]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:13:28,813]\u001b[0m Trial 492 finished with value: 5.220822740373664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047906914862440595, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026702060180068404, 'dropout_rate_Layer_2': 0.1523130201042562, 'dropout_rate_Layer_3': 0.01009354741458399, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3182535464700323e-05, 'l1_Layer_2': 3.495476894354102e-05, 'l1_Layer_3': 0.003600441239991043, 'n_units_Layer_1': 125, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.22 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 15.08% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:13:32,705]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:07,055]\u001b[0m Trial 494 finished with value: 7.343615075969162 and parameters: {'n_hidden': 4, 'learning_rate': 0.0071236480560144585, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06188930008834445, 'dropout_rate_Layer_2': 0.2624388738228616, 'dropout_rate_Layer_3': 0.25043388185875337, 'dropout_rate_Layer_4': 0.2896194136510601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00033810410190772324, 'l1_Layer_2': 5.9599819961814053e-05, 'l1_Layer_3': 0.002748498736765347, 'l1_Layer_4': 0.06394201201399735, 'n_units_Layer_1': 95, 'n_units_Layer_2': 260, 'n_units_Layer_3': 95, 'n_units_Layer_4': 230}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 16.34% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 17.44% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:14:11,369]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:18,577]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:23,165]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:31,248]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:36,227]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:41,584]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:45,872]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:51,075]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:14:56,001]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:15:01,629]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:15:07,194]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:15:23,393]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:16:59,114]\u001b[0m Trial 507 finished with value: 6.649728414781488 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005091019489241255, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07184044385234561, 'dropout_rate_Layer_2': 0.390248881713647, 'dropout_rate_Layer_3': 0.1638590046132025, 'dropout_rate_Layer_4': 0.2837004352185785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 3.890287815904606e-05, 'l1_Layer_2': 7.848571195631997e-05, 'l1_Layer_3': 0.07857096738016461, 'l1_Layer_4': 0.010675724996663517, 'n_units_Layer_1': 210, 'n_units_Layer_2': 265, 'n_units_Layer_3': 100, 'n_units_Layer_4': 240}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:17:05,014]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:08,358]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:25,159]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:31,033]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:37,699]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:43,701]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:47,654]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:52,125]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:17:57,718]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:02,362]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:05,961]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:14,830]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:18,599]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:23,417]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:27,317]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:18:50,298]\u001b[0m Trial 523 finished with value: 7.417755838674762 and parameters: {'n_hidden': 3, 'learning_rate': 0.047402924628874556, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3644467244568981, 'dropout_rate_Layer_2': 0.39624127910765305, 'dropout_rate_Layer_3': 0.16950559794005748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0535641497172534e-05, 'l1_Layer_2': 0.00016513959243510482, 'l1_Layer_3': 0.007904585504655757, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.42 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 7.19 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:18:54,971]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:03,703]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:10,154]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:15,732]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:21,968]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:26,733]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:40,891]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:50,247]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:19:56,579]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:20:04,634]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:20:08,414]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:20:12,793]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:20:16,530]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:20:22,725]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:20:25,763]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:21:52,800]\u001b[0m Trial 539 finished with value: 5.054568052553819 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019987907833344783, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05281929740728381, 'dropout_rate_Layer_2': 0.15787866826172794, 'dropout_rate_Layer_3': 0.265998051238627, 'dropout_rate_Layer_4': 0.3216872820690202, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006753804700465532, 'l1_Layer_2': 0.00012354821454081078, 'l1_Layer_3': 0.0019281164187672586, 'l1_Layer_4': 0.000179920389002907, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 95, 'n_units_Layer_4': 190}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 15.33% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:22:07,807]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:22:15,535]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:22:20,922]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:22:31,396]\u001b[0m Trial 543 finished with value: 7.2278159277310365 and parameters: {'n_hidden': 3, 'learning_rate': 0.04607654847564702, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3386997540767217, 'dropout_rate_Layer_2': 0.3986676037308423, 'dropout_rate_Layer_3': 0.16101026255520287, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.528616909491487e-05, 'l1_Layer_2': 0.00025270128297553106, 'l1_Layer_3': 0.000832177874169749, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 15.84% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:22:35,417]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:22:44,326]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:22:52,931]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:22:57,770]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:01,938]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:06,045]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:09,747]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:14,287]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:17,730]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:22,943]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:27,079]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:23:35,239]\u001b[0m Trial 555 finished with value: 13.933296632962076 and parameters: {'n_hidden': 4, 'learning_rate': 0.026432427003435024, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3434373534015887, 'dropout_rate_Layer_2': 0.32467327589249123, 'dropout_rate_Layer_3': 0.19772018400609556, 'dropout_rate_Layer_4': 0.027432628952963528, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.6162214069553236e-05, 'l1_Layer_2': 5.11305056180848e-05, 'l1_Layer_3': 0.003549287484382151, 'l1_Layer_4': 1.0824343421712497e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210, 'n_units_Layer_4': 115}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.93 | sMAPE for Validation Set is: 33.69% | rMAE for Validation Set is: 1.76\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:23:54,580]\u001b[0m Trial 556 finished with value: 5.851501819519133 and parameters: {'n_hidden': 3, 'learning_rate': 0.04962647610920382, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37561353381938134, 'dropout_rate_Layer_2': 0.3686134276163273, 'dropout_rate_Layer_3': 0.008456911758420699, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9240520756995826e-05, 'l1_Layer_2': 0.0009959862946843103, 'l1_Layer_3': 0.011050163144663866, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 12.93% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 16.06% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:23:59,509]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:24:04,518]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:24:35,645]\u001b[0m Trial 559 finished with value: 5.577460515534632 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024600008499818977, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06821827569460084, 'dropout_rate_Layer_2': 0.15203389637356923, 'dropout_rate_Layer_3': 0.24896616049803993, 'dropout_rate_Layer_4': 0.27001776074746464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0009494472224721375, 'l1_Layer_2': 0.0002108856243162733, 'l1_Layer_3': 0.000399017554497459, 'l1_Layer_4': 0.00012238930580824557, 'n_units_Layer_1': 95, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110, 'n_units_Layer_4': 185}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:24:39,031]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:24:42,951]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:24:47,563]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:24:54,094]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:04,564]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:15,847]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:20,330]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:25,856]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:34,181]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:44,038]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:49,313]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:25:58,498]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:26:08,687]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:26:14,459]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:26:21,394]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:26:24,616]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:11,816]\u001b[0m Trial 576 finished with value: 5.370622505919672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013610062834573545, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06508616567395523, 'dropout_rate_Layer_2': 0.23165569650911844, 'dropout_rate_Layer_3': 0.034106906774701184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4405094958763517e-05, 'l1_Layer_2': 2.2017668107126e-05, 'l1_Layer_3': 0.009582450440473591, 'n_units_Layer_1': 90, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:27:16,415]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:22,538]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:28,933]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:33,383]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:37,362]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:42,727]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:46,200]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:51,780]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:27:56,250]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:00,763]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:19,814]\u001b[0m Trial 587 finished with value: 5.84269703789574 and parameters: {'n_hidden': 3, 'learning_rate': 0.04397029001464014, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36576259964974117, 'dropout_rate_Layer_2': 0.368802777877719, 'dropout_rate_Layer_3': 0.05322059036883235, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.879463423286084e-05, 'l1_Layer_2': 0.0010006578876988318, 'l1_Layer_3': 0.012881331258817722, 'n_units_Layer_1': 195, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 14.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:28:25,066]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:29,242]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:33,281]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:41,025]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:45,194]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:50,022]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:28:54,247]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:29:04,958]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:29:32,926]\u001b[0m Trial 596 finished with value: 8.485390720784775 and parameters: {'n_hidden': 4, 'learning_rate': 0.002427472323236813, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20019787684925466, 'dropout_rate_Layer_2': 0.1674309921060751, 'dropout_rate_Layer_3': 0.2413935839644248, 'dropout_rate_Layer_4': 0.2376234938572196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0005910674455520429, 'l1_Layer_2': 0.0003204785835859935, 'l1_Layer_3': 0.00027186267948423195, 'l1_Layer_4': 0.00017849110249302844, 'n_units_Layer_1': 95, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125, 'n_units_Layer_4': 185}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 18.92% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 18.82% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:29:41,009]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:29:44,913]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:29:54,833]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:00,461]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:04,486]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:08,792]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:16,264]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:21,255]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:27,379]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:32,962]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:37,535]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:41,454]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:52,423]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:30:56,340]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:00,710]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:08,666]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:12,704]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:22,983]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:29,797]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:34,542]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:31:39,599]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:00,478]\u001b[0m Trial 618 finished with value: 5.7735005732754745 and parameters: {'n_hidden': 3, 'learning_rate': 0.05384927348778592, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3753019236772316, 'dropout_rate_Layer_2': 0.36220579086209426, 'dropout_rate_Layer_3': 0.016890536120031184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6568399836508796e-05, 'l1_Layer_2': 0.0011570838749186462, 'l1_Layer_3': 0.018572731272399955, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 135}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 15.82% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:32:05,203]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:09,032]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:13,552]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:18,378]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:23,939]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:28,847]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:34,271]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:38,423]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:46,029]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:49,966]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:53,719]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:32:58,207]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:03,291]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:18,005]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:22,639]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:28,589]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:32,013]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:41,202]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:52,369]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:33:56,263]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:02,449]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:06,748]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:14,659]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:20,927]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:25,235]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:28,924]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:33,492]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:37,511]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:47,509]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:53,882]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:34:57,495]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:04,577]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:09,248]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:12,470]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:16,811]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:21,545]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:25,890]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:30,151]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:38,686]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:42,038]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:46,453]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:50,858]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:35:59,209]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:05,920]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:12,595]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:18,371]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:26,650]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:31,149]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:37,050]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:41,247]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:45,812]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:36:52,998]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:37:26,325]\u001b[0m Trial 671 finished with value: 6.092327375698354 and parameters: {'n_hidden': 3, 'learning_rate': 0.061650526008055616, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37595791287661484, 'dropout_rate_Layer_2': 0.35970145259277303, 'dropout_rate_Layer_3': 0.015333465550418484, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.6681132817958636e-05, 'l1_Layer_2': 0.0010701084247019318, 'l1_Layer_3': 0.013711233754752047, 'n_units_Layer_1': 195, 'n_units_Layer_2': 285, 'n_units_Layer_3': 140}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:37:30,819]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:37:34,888]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:06,407]\u001b[0m Trial 674 finished with value: 5.448288188824218 and parameters: {'n_hidden': 4, 'learning_rate': 0.001068546619134102, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0605351353680828, 'dropout_rate_Layer_2': 0.1459175659554836, 'dropout_rate_Layer_3': 0.3401302372216403, 'dropout_rate_Layer_4': 0.009309432541320828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0011763745325127782, 'l1_Layer_2': 0.000221796511397825, 'l1_Layer_3': 0.002041533741827337, 'l1_Layer_4': 0.00035681464250384397, 'n_units_Layer_1': 90, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80, 'n_units_Layer_4': 110}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 16.05% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:38:11,786]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:22,694]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:31,772]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:36,101]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:47,425]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:51,982]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:38:58,371]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:03,329]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:06,990]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:13,734]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:17,879]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:21,308]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:29,533]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:34,554]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:39,962]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:39:44,116]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:40:41,370]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:40:45,945]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:40:50,781]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:22,443]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:26,342]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:30,542]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:35,266]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:40,689]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:46,146]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:50,417]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:54,313]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:41:59,003]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:05,807]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:11,622]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:17,365]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:21,680]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:25,080]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:29,436]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:39,720]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:44,007]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:49,107]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:42:55,102]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:43:19,711]\u001b[0m Trial 713 finished with value: 6.054700580113869 and parameters: {'n_hidden': 3, 'learning_rate': 0.09743382748518005, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30953988675897376, 'dropout_rate_Layer_2': 0.3001317235408805, 'dropout_rate_Layer_3': 0.04019252007610175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0644455973789754e-05, 'l1_Layer_2': 0.004712147729759642, 'l1_Layer_3': 0.020844979500137743, 'n_units_Layer_1': 205, 'n_units_Layer_2': 255, 'n_units_Layer_3': 165}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 15.97% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:43:24,045]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:43:33,568]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:43:41,446]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:43:46,027]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:43:55,009]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:44:09,091]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:44:14,374]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:44:24,419]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:44:30,537]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:44:34,859]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:44:39,219]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:08,821]\u001b[0m Trial 725 finished with value: 5.267498629759143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027391523460111667, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.060031495194357354, 'dropout_rate_Layer_2': 0.19266833826061075, 'dropout_rate_Layer_3': 0.052955684405335594, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3467793039930567e-05, 'l1_Layer_2': 3.7519827018267926e-05, 'l1_Layer_3': 0.009021374244446033, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 15.19% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:45:16,171]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:21,752]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:31,294]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:38,883]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:43,530]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:52,498]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:45:57,243]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:46:23,922]\u001b[0m Trial 733 finished with value: 5.119065235544626 and parameters: {'n_hidden': 3, 'learning_rate': 0.005528768397934999, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04854391025301083, 'dropout_rate_Layer_2': 0.35545190544463484, 'dropout_rate_Layer_3': 0.3255739862372044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004448967977687392, 'l1_Layer_2': 7.787793677754087e-05, 'l1_Layer_3': 2.5698331479996477e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:46:27,586]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:46:40,730]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:47:31,867]\u001b[0m Trial 736 finished with value: 6.161607505848953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012315286623133853, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19031618118316193, 'dropout_rate_Layer_2': 0.17427745131902841, 'dropout_rate_Layer_3': 0.32813285179582546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0019503412113452982, 'l1_Layer_2': 0.0001466341566027773, 'l1_Layer_3': 0.0014710238525758373, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 80}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 13.57% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:48:15,942]\u001b[0m Trial 737 finished with value: 5.038182318126244 and parameters: {'n_hidden': 3, 'learning_rate': 0.002119938080377474, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017570421189608422, 'dropout_rate_Layer_2': 0.1773843031859689, 'dropout_rate_Layer_3': 0.03327891414477223, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3101193982381568e-05, 'l1_Layer_2': 5.454190317461186e-05, 'l1_Layer_3': 0.011378267778187274, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 11.39% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:48:20,202]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:48:24,444]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:48:33,153]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:48:43,439]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:48:48,886]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:49:09,240]\u001b[0m Trial 743 finished with value: 5.69572972052146 and parameters: {'n_hidden': 3, 'learning_rate': 0.053400903867667486, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3785131424065849, 'dropout_rate_Layer_2': 0.291433177425851, 'dropout_rate_Layer_3': 0.040417773485402694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.799301658840214e-05, 'l1_Layer_2': 0.0006510593629311139, 'l1_Layer_3': 0.051385816659093295, 'n_units_Layer_1': 185, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 15.61% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:49:46,776]\u001b[0m Trial 744 finished with value: 5.568605331564304 and parameters: {'n_hidden': 4, 'learning_rate': 0.001965866687628632, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07794026365793291, 'dropout_rate_Layer_2': 0.15436052317963112, 'dropout_rate_Layer_3': 0.32261426602159454, 'dropout_rate_Layer_4': 0.20212927575757145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001033856153215944, 'l1_Layer_2': 0.000347516020380851, 'l1_Layer_3': 0.004758506600939244, 'l1_Layer_4': 0.00022387391255816226, 'n_units_Layer_1': 90, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120, 'n_units_Layer_4': 175}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 12.28% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:49:50,887]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:50:40,534]\u001b[0m Trial 746 finished with value: 4.998304589718191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019745466704390803, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017782659010690094, 'dropout_rate_Layer_2': 0.15941606691767207, 'dropout_rate_Layer_3': 0.030264312347138653, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0590462599699345e-05, 'l1_Layer_2': 4.855079187501192e-05, 'l1_Layer_3': 0.010209291981563753, 'n_units_Layer_1': 120, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:50:44,259]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:51:01,916]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:51:07,777]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:51:53,114]\u001b[0m Trial 750 finished with value: 5.162945366385261 and parameters: {'n_hidden': 3, 'learning_rate': 0.00592140130487692, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02563063278892765, 'dropout_rate_Layer_2': 0.35556079247111416, 'dropout_rate_Layer_3': 0.31409968897346263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005890826356503675, 'l1_Layer_2': 7.481772268872515e-05, 'l1_Layer_3': 2.7308832403198934e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 215}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 15.02% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:52:02,066]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:52:08,992]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:52:48,259]\u001b[0m Trial 753 finished with value: 5.0569215338278966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018305748745205976, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.033404879332834786, 'dropout_rate_Layer_2': 0.1472402898103204, 'dropout_rate_Layer_3': 0.01774937874574043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0366452573660894e-05, 'l1_Layer_2': 5.9085910607815234e-05, 'l1_Layer_3': 0.00929750911323324, 'n_units_Layer_1': 130, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:52:55,534]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:00,265]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:06,639]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:10,699]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:15,853]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:20,529]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:29,194]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:53:35,170]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 14.88% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:54:07,705]\u001b[0m Trial 762 finished with value: 5.1326435407047155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020528735755576876, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017821133328135518, 'dropout_rate_Layer_2': 0.15327548188416026, 'dropout_rate_Layer_3': 0.03251585270218364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.768355202340097e-05, 'l1_Layer_2': 5.6126286025662855e-05, 'l1_Layer_3': 0.009238111732589666, 'n_units_Layer_1': 135, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:54:41,534]\u001b[0m Trial 763 finished with value: 5.108529031378818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020846076260734258, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017538628812661026, 'dropout_rate_Layer_2': 0.15571499708525222, 'dropout_rate_Layer_3': 0.03143074732095946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.771399719222838e-05, 'l1_Layer_2': 5.9520623759620255e-05, 'l1_Layer_3': 0.00861720639829968, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 11.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 15.43% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:54:47,628]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:54:51,032]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:55:22,073]\u001b[0m Trial 766 finished with value: 5.057833656074836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022006669101948245, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017555788928423164, 'dropout_rate_Layer_2': 0.14758319260210043, 'dropout_rate_Layer_3': 0.03197166940632369, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.11757973418456e-05, 'l1_Layer_2': 7.392019462539375e-05, 'l1_Layer_3': 0.008993414541651123, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 15.44% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:55:27,641]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:55:32,989]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:55:37,923]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:56:25,595]\u001b[0m Trial 770 finished with value: 5.673303415164821 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009219159108456148, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09591985745521496, 'dropout_rate_Layer_2': 0.1407345336691761, 'dropout_rate_Layer_3': 0.39782890267469917, 'dropout_rate_Layer_4': 0.1921036066515633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001012445251562537, 'l1_Layer_2': 0.00044508769537691104, 'l1_Layer_3': 0.0051668192740539284, 'l1_Layer_4': 0.0003959791316497238, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70, 'n_units_Layer_4': 90}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 12.70% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 16.11% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:57:08,064]\u001b[0m Trial 771 finished with value: 5.3138318408667695 and parameters: {'n_hidden': 3, 'learning_rate': 0.05560824389441615, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37853263202345705, 'dropout_rate_Layer_2': 0.34929776120699646, 'dropout_rate_Layer_3': 0.05289282564335007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.1066721907455964e-05, 'l1_Layer_2': 0.0007424193759128329, 'l1_Layer_3': 0.05735765597393259, 'n_units_Layer_1': 200, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 11.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 14.37% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:57:12,980]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:57:20,236]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:58:10,145]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:59:06,065]\u001b[0m Trial 775 finished with value: 5.03798837840224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020376432081213305, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006769866781406474, 'dropout_rate_Layer_2': 0.15275440567193818, 'dropout_rate_Layer_3': 0.0332449905402038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.2911570028239795e-05, 'l1_Layer_2': 8.055682858178294e-05, 'l1_Layer_3': 0.009312369060407576, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 15.62% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:59:49,616]\u001b[0m Trial 776 finished with value: 5.101011324386134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021264258668512994, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004985299521265672, 'dropout_rate_Layer_2': 0.15235342566645507, 'dropout_rate_Layer_3': 0.0411845518511441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.9281544721740435e-05, 'l1_Layer_2': 8.206970709272332e-05, 'l1_Layer_3': 0.008276948453585967, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.10 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.78 | sMAPE for Test Set is: 14.58% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 04:59:54,155]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 04:59:59,702]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:00:03,833]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:00:08,754]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:00:15,499]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:00:53,687]\u001b[0m Trial 782 finished with value: 5.0756860746662475 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021728956086813018, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0015236281811624348, 'dropout_rate_Layer_2': 0.15227450176960414, 'dropout_rate_Layer_3': 0.027483299149109887, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.3525862679607356e-05, 'l1_Layer_2': 8.30450816293418e-05, 'l1_Layer_3': 0.008186937764672579, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 14.71% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:01:25,048]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:01:30,337]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:01:54,942]\u001b[0m Trial 785 finished with value: 5.236547843912681 and parameters: {'n_hidden': 3, 'learning_rate': 0.05608286451528475, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3703874901248292, 'dropout_rate_Layer_2': 0.349742346936019, 'dropout_rate_Layer_3': 0.042353053724158284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.8066638716985556e-05, 'l1_Layer_2': 0.0008557326262097709, 'l1_Layer_3': 0.048362764933521006, 'n_units_Layer_1': 205, 'n_units_Layer_2': 115, 'n_units_Layer_3': 70}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:02:21,822]\u001b[0m Trial 786 finished with value: 5.478452859146857 and parameters: {'n_hidden': 3, 'learning_rate': 0.013082784685344519, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19428824521382948, 'dropout_rate_Layer_2': 0.08751500541615939, 'dropout_rate_Layer_3': 0.19837947923671898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.676407027587112e-05, 'l1_Layer_2': 0.014107227862700626, 'l1_Layer_3': 0.00019434725366202613, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205}. Best is trial 351 with value: 4.987662499195147.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 14.78% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:02:40,537]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:02:44,876]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:02:50,834]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:02:57,630]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:03,273]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:07,822]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:14,922]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:20,670]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:26,761]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:32,428]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:36,461]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:03:54,953]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:04:09,706]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:04:14,585]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:04:48,172]\u001b[0m Trial 801 finished with value: 4.952444976135338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019590641663869836, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01656115952080786, 'dropout_rate_Layer_2': 0.14773369174622786, 'dropout_rate_Layer_3': 0.04376616611217308, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.838189733692984e-05, 'l1_Layer_2': 6.087627435988552e-05, 'l1_Layer_3': 0.009302515993937343, 'n_units_Layer_1': 135, 'n_units_Layer_2': 260, 'n_units_Layer_3': 205}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:04:53,229]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:04:58,222]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:05:02,989]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:05:07,996]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:05:14,121]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:05:19,158]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:05:25,508]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:05:34,256]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:06:14,212]\u001b[0m Trial 810 finished with value: 5.061685376278292 and parameters: {'n_hidden': 3, 'learning_rate': 0.001985236931131258, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01817813580687424, 'dropout_rate_Layer_2': 0.14796569020114778, 'dropout_rate_Layer_3': 0.04441217652973982, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.025975927903626e-05, 'l1_Layer_2': 6.209417745189174e-05, 'l1_Layer_3': 0.009428351518935002, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.61 | sMAPE for Test Set is: 14.27% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:06:31,897]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:06:36,681]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:06:59,363]\u001b[0m Trial 813 finished with value: 5.8925143693590085 and parameters: {'n_hidden': 3, 'learning_rate': 0.011744310711880158, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01046813860090764, 'dropout_rate_Layer_2': 0.3466442199093977, 'dropout_rate_Layer_3': 0.20920684708969395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022805054023613717, 'l1_Layer_2': 6.571125280575607e-05, 'l1_Layer_3': 4.01243139413184e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 60, 'n_units_Layer_3': 255}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 12.89% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.08 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:07:04,462]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:07:09,209]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:07:55,403]\u001b[0m Trial 816 finished with value: 5.072105314855912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018586503051155345, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017542282778282008, 'dropout_rate_Layer_2': 0.1475408055325086, 'dropout_rate_Layer_3': 0.04435172092442771, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.246772920710427e-05, 'l1_Layer_2': 9.532791418907239e-05, 'l1_Layer_3': 0.008924552724377475, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 11.42% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 15.63% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:08:02,261]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:08:08,828]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:08:13,997]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:08:18,549]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:08:26,206]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:08:31,922]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:09:02,998]\u001b[0m Trial 823 finished with value: 5.005550263456347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018652149164387892, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018297827803955852, 'dropout_rate_Layer_2': 0.14698507131199584, 'dropout_rate_Layer_3': 0.04153305071492199, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.495293734063203e-05, 'l1_Layer_2': 9.602070885530095e-05, 'l1_Layer_3': 0.006706893723455896, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:09:08,002]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:09:11,749]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:09:39,662]\u001b[0m Trial 826 finished with value: 4.996393904632694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018647800764568926, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015575830294874882, 'dropout_rate_Layer_2': 0.1469884627943649, 'dropout_rate_Layer_3': 0.04314731618818386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.769594011230743e-05, 'l1_Layer_2': 0.00010253768131902695, 'l1_Layer_3': 0.006761119766780608, 'n_units_Layer_1': 135, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 15.33% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:09:43,815]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:09:49,349]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:10:07,864]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:10:13,905]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:10:19,229]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:10:25,193]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:11:03,521]\u001b[0m Trial 833 finished with value: 5.049090094677339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016414079332535518, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01286408346629463, 'dropout_rate_Layer_2': 0.13905039583209822, 'dropout_rate_Layer_3': 0.04318730473679059, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.498087385539648e-05, 'l1_Layer_2': 8.388346374747962e-05, 'l1_Layer_3': 0.010897159501158321, 'n_units_Layer_1': 155, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.64 | sMAPE for Test Set is: 14.35% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:11:07,738]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:12:02,896]\u001b[0m Trial 835 finished with value: 5.279997659417725 and parameters: {'n_hidden': 3, 'learning_rate': 0.009031687026348113, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05962536801345646, 'dropout_rate_Layer_2': 0.3138386474808923, 'dropout_rate_Layer_3': 0.28848715950201265, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005352198361678814, 'l1_Layer_2': 3.775661217848643e-05, 'l1_Layer_3': 1.2974633288571441e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 205}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 14.83% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:12:07,336]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:12:12,228]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:12:18,804]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:12:49,138]\u001b[0m Trial 839 finished with value: 5.5124914588031375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0704898745814997, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34329737094459295, 'dropout_rate_Layer_2': 0.34210384311210734, 'dropout_rate_Layer_3': 0.05141247446376461, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.424048021640591e-05, 'l1_Layer_2': 0.0028198214491954223, 'l1_Layer_3': 0.042614719348725426, 'n_units_Layer_1': 210, 'n_units_Layer_2': 125, 'n_units_Layer_3': 70}. Best is trial 801 with value: 4.952444976135338.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 12.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 15.07% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:12:55,576]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:13:30,565]\u001b[0m Trial 841 finished with value: 4.9516658084352585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017296987928973682, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012478223692364893, 'dropout_rate_Layer_2': 0.13416176771347413, 'dropout_rate_Layer_3': 0.04187937040096185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.207373137255678e-05, 'l1_Layer_2': 9.409365663464828e-05, 'l1_Layer_3': 0.010691928664646978, 'n_units_Layer_1': 150, 'n_units_Layer_2': 270, 'n_units_Layer_3': 195}. Best is trial 841 with value: 4.9516658084352585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.95 | sMAPE for Validation Set is: 11.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 14.85% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:13:35,631]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:14:20,490]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:14:24,516]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:14:52,591]\u001b[0m Trial 845 finished with value: 5.848041981895986 and parameters: {'n_hidden': 3, 'learning_rate': 0.06271904713466926, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3351830542760551, 'dropout_rate_Layer_2': 0.3435237750174137, 'dropout_rate_Layer_3': 0.03698534291004661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.993799431213458e-05, 'l1_Layer_2': 0.0049686863257687505, 'l1_Layer_3': 0.0496553236129351, 'n_units_Layer_1': 215, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70}. Best is trial 841 with value: 4.9516658084352585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 12.97% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 16.09% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:14:58,793]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:15:45,606]\u001b[0m Trial 847 finished with value: 5.846163091428674 and parameters: {'n_hidden': 3, 'learning_rate': 0.07456030098100498, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3781344600866293, 'dropout_rate_Layer_2': 0.3117119166471562, 'dropout_rate_Layer_3': 0.07017287372078106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.342387432980932e-05, 'l1_Layer_2': 0.0023928049506200806, 'l1_Layer_3': 0.061224862903048, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 65}. Best is trial 841 with value: 4.9516658084352585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 12.91% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 15.59% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:16:22,293]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:01,294]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:06,174]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:10,538]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:14,856]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:20,876]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:28,316]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:32,769]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:38,065]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:48,736]\u001b[0m Trial 857 finished with value: 15.906868798586244 and parameters: {'n_hidden': 3, 'learning_rate': 0.05461600032190601, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28707564683769965, 'dropout_rate_Layer_2': 0.33209335871716955, 'dropout_rate_Layer_3': 0.025071845238872188, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 3.611515093709209e-05, 'l1_Layer_2': 0.007789527119102113, 'l1_Layer_3': 0.02991449593675365, 'n_units_Layer_1': 215, 'n_units_Layer_2': 115, 'n_units_Layer_3': 85}. Best is trial 841 with value: 4.9516658084352585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.91 | sMAPE for Validation Set is: 38.78% | rMAE for Validation Set is: 2.01\n",
      "MAE for Test Set is: 14.05 | sMAPE for Test Set is: 35.99% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:17:52,912]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:17:56,831]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:18:02,642]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:18:06,986]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:18:11,207]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:18:15,314]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:18:56,531]\u001b[0m Trial 864 finished with value: 5.046942520572263 and parameters: {'n_hidden': 3, 'learning_rate': 0.002105266227026054, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007985669126531009, 'dropout_rate_Layer_2': 0.1556065389937297, 'dropout_rate_Layer_3': 0.04536406044238037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.280943779226499e-05, 'l1_Layer_2': 0.00010374933438073215, 'l1_Layer_3': 0.008269728586373622, 'n_units_Layer_1': 135, 'n_units_Layer_2': 265, 'n_units_Layer_3': 205}. Best is trial 841 with value: 4.9516658084352585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 14.67% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:19:18,165]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:19:22,752]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:19:41,458]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:19:46,976]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:19:52,650]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:20:15,080]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:20:19,807]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:20:25,310]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:20:39,924]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:20:45,558]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:20:49,890]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:21:22,669]\u001b[0m Trial 876 finished with value: 5.16710852945317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019263661494693812, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015286093599958311, 'dropout_rate_Layer_2': 0.15609823399072623, 'dropout_rate_Layer_3': 0.037123345261281304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.513811522350447e-05, 'l1_Layer_2': 6.784323375793637e-05, 'l1_Layer_3': 0.008000183590313972, 'n_units_Layer_1': 150, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195}. Best is trial 841 with value: 4.9516658084352585.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.17 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 14.80% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:21:27,390]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:21:32,319]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:22:10,334]\u001b[0m Trial 879 finished with value: 4.90057905158073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021313068844245903, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02163221773220256, 'dropout_rate_Layer_2': 0.16082935723583652, 'dropout_rate_Layer_3': 0.03354128459773508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010221494852108909, 'l1_Layer_2': 0.000108273726678256, 'l1_Layer_3': 0.009870058449320146, 'n_units_Layer_1': 155, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 879 with value: 4.90057905158073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 11.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 14.53% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:22:26,833]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:23:01,954]\u001b[0m Trial 881 finished with value: 5.2510357827891605 and parameters: {'n_hidden': 3, 'learning_rate': 0.009723221311093237, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0914152275874791, 'dropout_rate_Layer_2': 0.3973231313642739, 'dropout_rate_Layer_3': 0.19235573480418053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002649916876346732, 'l1_Layer_2': 5.354300606177516e-05, 'l1_Layer_3': 5.273016745436652e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 120, 'n_units_Layer_3': 165}. Best is trial 879 with value: 4.90057905158073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 11.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 14.78% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:23:37,510]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:23:42,309]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:23:46,653]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:23:53,772]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:24:26,639]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:24:31,681]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:25:07,030]\u001b[0m Trial 888 finished with value: 5.927204155162726 and parameters: {'n_hidden': 4, 'learning_rate': 0.08119856256454062, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3452010826726447, 'dropout_rate_Layer_2': 0.34640358000986454, 'dropout_rate_Layer_3': 0.06574238780276717, 'dropout_rate_Layer_4': 0.38322384498105583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.777570331748331e-05, 'l1_Layer_2': 0.0016137810116212713, 'l1_Layer_3': 0.03079579001373376, 'l1_Layer_4': 7.296018085772099e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 60, 'n_units_Layer_3': 50, 'n_units_Layer_4': 125}. Best is trial 879 with value: 4.90057905158073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 13.07% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:25:11,037]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:26:01,672]\u001b[0m Trial 890 finished with value: 4.988291878274032 and parameters: {'n_hidden': 3, 'learning_rate': 0.001813381223761566, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008169899264459466, 'dropout_rate_Layer_2': 0.13760101485885504, 'dropout_rate_Layer_3': 0.0260924060093578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.859241202123937e-05, 'l1_Layer_2': 9.55827698497363e-05, 'l1_Layer_3': 0.006682264730214109, 'n_units_Layer_1': 135, 'n_units_Layer_2': 250, 'n_units_Layer_3': 205}. Best is trial 879 with value: 4.90057905158073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 11.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 15.35% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:26:29,667]\u001b[0m Trial 891 finished with value: 4.859052543458103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017476313768094013, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006971237401983534, 'dropout_rate_Layer_2': 0.13727199077965527, 'dropout_rate_Layer_3': 0.023721887958140963, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.387826675535344e-05, 'l1_Layer_2': 9.417184636523521e-05, 'l1_Layer_3': 0.006401532725517947, 'n_units_Layer_1': 145, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.82 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:26:35,762]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:26:40,012]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:14,172]\u001b[0m Trial 894 finished with value: 5.143444363857781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017009831989491602, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0070497412247305605, 'dropout_rate_Layer_2': 0.13695973657302818, 'dropout_rate_Layer_3': 0.021334948653116803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001027248038918047, 'l1_Layer_2': 0.0001073862733644722, 'l1_Layer_3': 0.00654903018712517, 'n_units_Layer_1': 160, 'n_units_Layer_2': 255, 'n_units_Layer_3': 195}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.14 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.32 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:27:19,494]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:24,381]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:28,486]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:32,861]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:38,802]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:43,353]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:48,135]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:27:52,997]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:01,450]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:05,521]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:10,381]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:28,737]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:33,918]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:38,051]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:43,777]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:49,010]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:53,511]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:28:57,044]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:29:03,524]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:29:07,706]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:29:12,198]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:29:26,555]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:30:04,762]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:30:08,950]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:30:13,288]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:30:18,498]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:30:22,841]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:30:46,273]\u001b[0m Trial 922 finished with value: 5.120096308008473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0067807538149434994, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17649294292356674, 'dropout_rate_Layer_2': 0.09887722053772624, 'dropout_rate_Layer_3': 0.26251554539037186, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0062968166254606375, 'l1_Layer_2': 0.0005723772503881313, 'l1_Layer_3': 0.0003851107321397654, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.12 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.05 | sMAPE for Test Set is: 15.14% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:30:55,018]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:19,350]\u001b[0m Trial 924 finished with value: 5.125699795167094 and parameters: {'n_hidden': 3, 'learning_rate': 0.007075253515182004, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17473888221428188, 'dropout_rate_Layer_2': 0.09549505069171452, 'dropout_rate_Layer_3': 0.2952568614947991, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003391744226072766, 'l1_Layer_2': 0.0005785332904601603, 'l1_Layer_3': 0.00040842503626249737, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.11 | sMAPE for Test Set is: 15.25% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:31:23,580]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:28,637]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:33,604]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:38,781]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:43,183]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:53,115]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:31:57,135]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:01,716]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:09,281]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:13,586]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:18,053]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:32,653]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:37,065]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:42,332]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:48,601]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:32:52,845]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:33:16,426]\u001b[0m Trial 941 finished with value: 5.12556398558661 and parameters: {'n_hidden': 3, 'learning_rate': 0.009914336898450277, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07052905743251606, 'dropout_rate_Layer_2': 0.06956564584792488, 'dropout_rate_Layer_3': 0.31112630088560084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005028996433993581, 'l1_Layer_2': 2.493865359504142e-05, 'l1_Layer_3': 0.0014067489961232759, 'n_units_Layer_1': 295, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 15.39% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:33:30,272]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:33:35,592]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:34:20,873]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:34:35,705]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:34:42,136]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:34:51,352]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:34:56,656]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:35:34,847]\u001b[0m Trial 949 finished with value: 5.062359495216241 and parameters: {'n_hidden': 3, 'learning_rate': 0.002099642723767612, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030767012021466388, 'dropout_rate_Layer_2': 0.1372111358409246, 'dropout_rate_Layer_3': 0.025804533387330672, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.0963806153964425e-05, 'l1_Layer_2': 7.172311936370528e-05, 'l1_Layer_3': 0.009705486252590047, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 205}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 15.34% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:35:39,617]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:35:47,244]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:35:52,268]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:35:56,991]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:01,886]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:06,415]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:11,283]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:31,305]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:35,773]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:49,789]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:36:54,292]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:37:14,098]\u001b[0m Trial 961 finished with value: 5.6016178769283895 and parameters: {'n_hidden': 3, 'learning_rate': 0.029287055048540848, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39617307663383083, 'dropout_rate_Layer_2': 0.2929193274853693, 'dropout_rate_Layer_3': 0.04387427582709144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.549925771914462e-05, 'l1_Layer_2': 0.00035297885607139253, 'l1_Layer_3': 0.017980209688403314, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 16.32% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:37:30,680]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:37:36,488]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:37:43,751]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:37:48,320]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:37:52,380]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:11,563]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:16,809]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:22,724]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:27,753]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:32,999]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:38,307]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:44,994]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:49,884]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:53,956]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:38:59,830]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:39:04,470]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:39:09,703]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:39:14,193]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:39:43,132]\u001b[0m Trial 980 finished with value: 4.961549677156202 and parameters: {'n_hidden': 3, 'learning_rate': 0.004669987147171729, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06787091454851873, 'dropout_rate_Layer_2': 0.18332462928079613, 'dropout_rate_Layer_3': 0.17709080585042666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001701414267463989, 'l1_Layer_2': 0.00010432004917421841, 'l1_Layer_3': 0.013400363025396071, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.67 | sMAPE for Test Set is: 14.41% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:39:48,403]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:40:07,664]\u001b[0m Trial 982 finished with value: 6.008940624409326 and parameters: {'n_hidden': 3, 'learning_rate': 0.07739532809207408, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39757328432497435, 'dropout_rate_Layer_2': 0.3000508220365129, 'dropout_rate_Layer_3': 0.0398828042595382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3196436287978616e-05, 'l1_Layer_2': 0.00039358821152737624, 'l1_Layer_3': 0.043827036806488515, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 80}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 13.05% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:40:53,225]\u001b[0m Trial 983 finished with value: 5.988178631065055 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017522868569652763, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10493918257632184, 'dropout_rate_Layer_2': 0.08182811468564652, 'dropout_rate_Layer_3': 0.31686823291993627, 'dropout_rate_Layer_4': 0.22752771559277138, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0006355597716656918, 'l1_Layer_2': 0.00015702751793831988, 'l1_Layer_3': 0.001218720536615786, 'l1_Layer_4': 0.0021126999428455182, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 75, 'n_units_Layer_4': 195}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 13.29% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:40:58,469]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:41:06,924]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:41:14,963]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:41:55,393]\u001b[0m Trial 987 finished with value: 5.004148501470767 and parameters: {'n_hidden': 3, 'learning_rate': 0.004863231948729283, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09051264065611729, 'dropout_rate_Layer_2': 0.18665915823294266, 'dropout_rate_Layer_3': 0.19700493136242925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001708304261184537, 'l1_Layer_2': 0.0001951607470945269, 'l1_Layer_3': 0.013404636225456207, 'n_units_Layer_1': 295, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.69 | sMAPE for Test Set is: 14.48% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:42:08,316]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:42:53,715]\u001b[0m Trial 989 finished with value: 4.98269210199626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018446159038136246, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021475462209027102, 'dropout_rate_Layer_2': 0.12146192582202593, 'dropout_rate_Layer_3': 0.02663894342985629, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.680630922817638e-05, 'l1_Layer_2': 0.00018307911653324312, 'l1_Layer_3': 0.005355270524475875, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 190}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 11.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 15.13% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:42:58,251]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:43:25,778]\u001b[0m Trial 991 finished with value: 5.087286925315856 and parameters: {'n_hidden': 3, 'learning_rate': 0.001818961203812595, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021528655095966152, 'dropout_rate_Layer_2': 0.12522350135451626, 'dropout_rate_Layer_3': 0.02699824010436088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7225835160415564e-05, 'l1_Layer_2': 0.00012376137028753475, 'l1_Layer_3': 0.005171368373617558, 'n_units_Layer_1': 130, 'n_units_Layer_2': 265, 'n_units_Layer_3': 190}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 11.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.04 | sMAPE for Test Set is: 15.15% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:44:13,640]\u001b[0m Trial 992 finished with value: 4.863389470404085 and parameters: {'n_hidden': 3, 'learning_rate': 0.004238544251428811, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06068857791337742, 'dropout_rate_Layer_2': 0.18934253222771574, 'dropout_rate_Layer_3': 0.1891710833104169, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015084437541419745, 'l1_Layer_2': 0.00011968033557427181, 'l1_Layer_3': 0.00459438062871245, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.86 | sMAPE for Validation Set is: 10.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 14.90% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:44:54,009]\u001b[0m Trial 993 finished with value: 6.1694588712607015 and parameters: {'n_hidden': 3, 'learning_rate': 0.02824813907060781, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3667247025959126, 'dropout_rate_Layer_2': 0.35231823517103955, 'dropout_rate_Layer_3': 0.05400569236751791, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.999199175404802e-05, 'l1_Layer_2': 0.000759160278577339, 'l1_Layer_3': 0.08168416121329086, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:45:02,018]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:45:17,017]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:45:22,314]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:45:31,075]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:46:09,734]\u001b[0m Trial 998 finished with value: 4.984454361056037 and parameters: {'n_hidden': 3, 'learning_rate': 0.004764885649645142, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05733896931200816, 'dropout_rate_Layer_2': 0.18397815767445772, 'dropout_rate_Layer_3': 0.21068184933727577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018470449679546122, 'l1_Layer_2': 0.00027865688438571983, 'l1_Layer_3': 0.010274491389621412, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.73 | sMAPE for Test Set is: 14.43% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:46:14,909]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:46:22,181]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:46:29,764]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:46:55,326]\u001b[0m Trial 1002 finished with value: 5.344613493319108 and parameters: {'n_hidden': 3, 'learning_rate': 0.06126187329852001, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39964501260918384, 'dropout_rate_Layer_2': 0.26655256112062914, 'dropout_rate_Layer_3': 0.0015339384220158306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.749691560705078e-05, 'l1_Layer_2': 0.0014203940321734336, 'l1_Layer_3': 0.01868245170151633, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 90}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 14.96% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:47:00,275]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:47:06,326]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:47:11,252]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:47:16,363]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:47:21,501]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:47:57,342]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:48:04,727]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:48:21,249]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:48:26,972]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:48:48,439]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:48:53,153]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:48:57,880]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:49:02,813]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:49:40,504]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:50:25,720]\u001b[0m Trial 1017 finished with value: 5.498170291960128 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007866667435249162, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03651505804069931, 'dropout_rate_Layer_2': 0.17051016474445335, 'dropout_rate_Layer_3': 0.3694442861292169, 'dropout_rate_Layer_4': 0.3263146906958827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019019850699932101, 'l1_Layer_2': 3.6573838347506816e-05, 'l1_Layer_3': 0.007734780184386132, 'l1_Layer_4': 0.00023839410505740124, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 150, 'n_units_Layer_4': 70}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 12.18% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 15.67% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:51:00,707]\u001b[0m Trial 1018 finished with value: 5.17635376746872 and parameters: {'n_hidden': 3, 'learning_rate': 0.03247736950987289, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38515529236114715, 'dropout_rate_Layer_2': 0.28235054976374097, 'dropout_rate_Layer_3': 0.02770801824106819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.0243570093060054e-05, 'l1_Layer_2': 0.00030507096039910454, 'l1_Layer_3': 0.029060474628773886, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 110}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 11.40% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.62 | sMAPE for Test Set is: 14.56% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:51:08,257]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:51:42,378]\u001b[0m Trial 1020 finished with value: 5.81451771633141 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008183653918050484, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02927647522020318, 'dropout_rate_Layer_2': 0.18763508965266046, 'dropout_rate_Layer_3': 0.37343756993160665, 'dropout_rate_Layer_4': 0.3274352868419056, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017582765501045288, 'l1_Layer_2': 2.86890945512655e-05, 'l1_Layer_3': 0.010883250306095448, 'l1_Layer_4': 0.0015250522398033196, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 150, 'n_units_Layer_4': 50}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:52:11,241]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:52:16,411]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:52:57,051]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:53:29,185]\u001b[0m Trial 1024 finished with value: 5.00740151663732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035013900167810857, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0671726680598108, 'dropout_rate_Layer_2': 0.19838573086582578, 'dropout_rate_Layer_3': 0.20311129924148572, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014073629580781415, 'l1_Layer_2': 0.0001649526340412996, 'l1_Layer_3': 0.021903825933714104, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 285}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.01 | sMAPE for Validation Set is: 11.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 14.81% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:53:43,684]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:53:49,452]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:53:55,316]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:54:32,439]\u001b[0m Trial 1028 finished with value: 5.044343411220962 and parameters: {'n_hidden': 3, 'learning_rate': 0.002009195029514233, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00811425546024602, 'dropout_rate_Layer_2': 0.1512279577224297, 'dropout_rate_Layer_3': 0.04360076679983684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.8553073967538684e-05, 'l1_Layer_2': 8.367593593029355e-05, 'l1_Layer_3': 0.007985724436379219, 'n_units_Layer_1': 145, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 11.29% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.66 | sMAPE for Test Set is: 14.45% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:54:37,572]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:54:42,441]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:54:56,258]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:55:03,611]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:55:12,031]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:55:17,009]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:55:22,058]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:55:54,012]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:56:31,714]\u001b[0m Trial 1037 finished with value: 5.035831098232411 and parameters: {'n_hidden': 3, 'learning_rate': 0.001122495378729888, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0870876925655436, 'dropout_rate_Layer_2': 0.0714167968886759, 'dropout_rate_Layer_3': 0.3637003098723312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021479584239586604, 'l1_Layer_2': 2.864728774610657e-05, 'l1_Layer_3': 0.0008282501492036176, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.04 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 14.71% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:56:45,791]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:56:51,462]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:56:57,633]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:57:31,631]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:58:26,390]\u001b[0m Trial 1042 finished with value: 4.9582027796438055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030188479715810325, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05623803793985744, 'dropout_rate_Layer_2': 0.2083570421165372, 'dropout_rate_Layer_3': 0.21666658813425865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002034413326267039, 'l1_Layer_2': 0.00020559945645138333, 'l1_Layer_3': 0.008111427648511907, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 300}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 14.48% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 05:58:34,713]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:58:50,089]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:58:55,206]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:00,678]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:09,509]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:14,789]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:34,647]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:39,607]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:44,700]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:49,886]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 05:59:55,148]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:00:01,005]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:00:09,510]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:00:45,822]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:01:01,644]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:01:34,947]\u001b[0m Trial 1058 finished with value: 4.971437666305172 and parameters: {'n_hidden': 3, 'learning_rate': 0.035240832999390515, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3481015907517526, 'dropout_rate_Layer_2': 0.27655118499822373, 'dropout_rate_Layer_3': 0.025645048118088185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.916011493425334e-05, 'l1_Layer_2': 0.0003261380527298066, 'l1_Layer_3': 0.028660250650235922, 'n_units_Layer_1': 290, 'n_units_Layer_2': 70, 'n_units_Layer_3': 110}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.77 | sMAPE for Test Set is: 14.57% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:01:39,768]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:02:18,530]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:03:04,698]\u001b[0m Trial 1061 finished with value: 4.933121637072642 and parameters: {'n_hidden': 3, 'learning_rate': 0.002551759971858493, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04664496702816514, 'dropout_rate_Layer_2': 0.22051069212129926, 'dropout_rate_Layer_3': 0.22581620109539824, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014527175122039848, 'l1_Layer_2': 0.00029256006925229046, 'l1_Layer_3': 0.005152915803231161, 'n_units_Layer_1': 285, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 14.75% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:03:15,097]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:03:19,884]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:03:28,663]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:04:04,621]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:04:12,957]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:04:21,941]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:04:27,441]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:04:32,619]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:04:40,940]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:05:13,722]\u001b[0m Trial 1071 finished with value: 5.064132173412116 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025678137883074588, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054364266135790824, 'dropout_rate_Layer_2': 0.20761335104564868, 'dropout_rate_Layer_3': 0.2298100497268995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014635292833527218, 'l1_Layer_2': 0.0003588026416993514, 'l1_Layer_3': 0.0048143616487021125, 'n_units_Layer_1': 275, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:05:29,891]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:05:46,560]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:06:01,666]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:06:06,393]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:06:12,197]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:06:20,089]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:06:57,138]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:07:14,822]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:07:20,747]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:07:26,132]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:01,742]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:06,828]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:22,744]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:28,549]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:34,773]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:40,161]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:48,471]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:08:54,529]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:09:09,068]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:09:13,928]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:09:22,955]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:09:28,012]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:09:33,075]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:09:40,302]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:10:17,497]\u001b[0m Trial 1096 finished with value: 4.968822154932181 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010449010637370948, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08359258843380335, 'dropout_rate_Layer_2': 0.06046536684554017, 'dropout_rate_Layer_3': 0.36810905860390924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022402906348425408, 'l1_Layer_2': 2.9371325118872766e-05, 'l1_Layer_3': 0.002337236225454293, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 260}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 11.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:10:22,565]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:10:58,328]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:04,646]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:16,680]\u001b[0m Trial 1100 finished with value: 11.763877192866646 and parameters: {'n_hidden': 3, 'learning_rate': 0.03702622842711373, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3477774491241994, 'dropout_rate_Layer_2': 0.24845339772750852, 'dropout_rate_Layer_3': 5.4377617743975315e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 7.698831507397487e-05, 'l1_Layer_2': 0.0007015394356677113, 'l1_Layer_3': 0.030667163567609165, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.76 | sMAPE for Validation Set is: 27.45% | rMAE for Validation Set is: 1.49\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 26.81% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:11:21,916]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:26,774]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:33,034]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:38,238]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:46,189]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:11:51,266]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:12:06,673]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:12:12,559]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:12:21,694]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:12:53,922]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:13:22,306]\u001b[0m Trial 1111 finished with value: 5.254500570656865 and parameters: {'n_hidden': 3, 'learning_rate': 0.022502259254624162, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32812570029091825, 'dropout_rate_Layer_2': 0.2727195634451988, 'dropout_rate_Layer_3': 0.02435745310144708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.609591754233179e-05, 'l1_Layer_2': 0.0015716059577441535, 'l1_Layer_3': 0.03089552605314026, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 95}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 11.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 15.32% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:13:28,536]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:14:08,091]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:14:23,933]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:14:29,949]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:14:35,457]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:14:40,502]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:14:55,043]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:10,854]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:16,143]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:22,307]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:37,031]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:42,035]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:49,403]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:15:54,518]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:16:37,380]\u001b[0m Trial 1126 finished with value: 4.9994482993102825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015590282343782992, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14223381901473942, 'dropout_rate_Layer_2': 0.13044283647951732, 'dropout_rate_Layer_3': 0.035520845681485246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.919871091189005e-05, 'l1_Layer_2': 0.00012044507937381686, 'l1_Layer_3': 0.00436352852680179, 'n_units_Layer_1': 135, 'n_units_Layer_2': 240, 'n_units_Layer_3': 200}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.27% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:16:42,186]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:16:55,307]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:17:49,664]\u001b[0m Trial 1129 finished with value: 4.909573206857151 and parameters: {'n_hidden': 3, 'learning_rate': 0.002552725130678328, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16223866144056967, 'dropout_rate_Layer_2': 0.18325393712569904, 'dropout_rate_Layer_3': 0.22285235726732003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006778103128084636, 'l1_Layer_2': 0.0003457989695102442, 'l1_Layer_3': 0.009261727214673285, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.91 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.85 | sMAPE for Test Set is: 14.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:18:07,537]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:18:13,000]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:18:28,812]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:18:33,940]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:18:47,157]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:18:55,927]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:19:04,784]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:19:10,569]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:19:39,197]\u001b[0m Trial 1138 finished with value: 5.134360803865187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013628574978676506, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008385682631050323, 'dropout_rate_Layer_2': 0.14605461626280847, 'dropout_rate_Layer_3': 0.019769685870793353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.585018485361388e-05, 'l1_Layer_2': 0.00018036188764158264, 'l1_Layer_3': 2.8959975934678583e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.59% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 15.56% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:19:44,599]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:19:49,703]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:19:54,572]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:00,444]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:08,671]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:14,823]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:19,852]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:24,979]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:32,177]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:37,563]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:42,453]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:47,530]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:20:53,237]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:21:26,319]\u001b[0m Trial 1152 finished with value: 4.8884266960598675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033679749739666275, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.114582112535482, 'dropout_rate_Layer_2': 0.2029337050622609, 'dropout_rate_Layer_3': 0.23503049530076814, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007038007118201716, 'l1_Layer_2': 0.00032689228662239836, 'l1_Layer_3': 0.01609203621317108, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 290}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.89 | sMAPE for Validation Set is: 10.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 14.62% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:21:31,796]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:21:37,383]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:21:42,229]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:21:46,655]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:21:51,331]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:21:56,487]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:22:05,132]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:22:11,107]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:22:16,098]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:22:52,691]\u001b[0m Trial 1162 finished with value: 5.047497533348907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012924428342960049, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08101130701276037, 'dropout_rate_Layer_2': 0.017710776436120595, 'dropout_rate_Layer_3': 0.3796880622110258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002756087957046763, 'l1_Layer_2': 4.561728410858445e-05, 'l1_Layer_3': 0.0009999759273061528, 'n_units_Layer_1': 170, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:23:08,429]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:23:14,136]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:23:18,945]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:23:23,723]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:23:29,002]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:23:33,728]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:23:49,679]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:24:18,201]\u001b[0m Trial 1170 finished with value: 6.57068419555934 and parameters: {'n_hidden': 3, 'learning_rate': 0.02075666180138429, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3238170114908491, 'dropout_rate_Layer_2': 0.26713845609644193, 'dropout_rate_Layer_3': 0.02539072807759888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013325642880623612, 'l1_Layer_2': 0.0017961873150820588, 'l1_Layer_3': 0.02871894667692218, 'n_units_Layer_1': 300, 'n_units_Layer_2': 70, 'n_units_Layer_3': 95}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 14.65% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:24:45,141]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:24:50,671]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:24:55,600]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:00,348]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:05,151]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:21,730]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:27,407]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:35,178]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:40,015]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:44,885]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:51,060]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:25:55,917]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:26:13,414]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:26:38,325]\u001b[0m Trial 1184 finished with value: 5.062856051890765 and parameters: {'n_hidden': 3, 'learning_rate': 0.00275049377679664, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013302611955962756, 'dropout_rate_Layer_2': 0.1159187453787502, 'dropout_rate_Layer_3': 0.05244392360080169, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.760043989715482e-05, 'l1_Layer_2': 5.521240668989139e-05, 'l1_Layer_3': 0.0051679502761478174, 'n_units_Layer_1': 155, 'n_units_Layer_2': 260, 'n_units_Layer_3': 205}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.28% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 14.90% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:26:43,248]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:26:47,913]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:27:10,451]\u001b[0m Trial 1187 finished with value: 5.287295337007476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032345344369178394, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10168231789711198, 'dropout_rate_Layer_2': 0.006778359703757661, 'dropout_rate_Layer_3': 0.3793543930626889, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027275731071399203, 'l1_Layer_2': 3.597664385256051e-05, 'l1_Layer_3': 0.00033422424168674564, 'n_units_Layer_1': 170, 'n_units_Layer_2': 225, 'n_units_Layer_3': 265}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 11.61% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 5.99 | sMAPE for Test Set is: 14.97% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:27:17,262]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:27:57,305]\u001b[0m Trial 1189 finished with value: 5.426029684570248 and parameters: {'n_hidden': 3, 'learning_rate': 0.03148417546893455, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3419847898198325, 'dropout_rate_Layer_2': 0.31237235705715716, 'dropout_rate_Layer_3': 0.05794506599057015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7653361756617986e-05, 'l1_Layer_2': 0.001246385144072, 'l1_Layer_3': 0.043567799819133335, 'n_units_Layer_1': 290, 'n_units_Layer_2': 65, 'n_units_Layer_3': 60}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.59 | sMAPE for Test Set is: 14.47% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:28:02,375]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:28:11,438]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:28:19,835]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:28:25,433]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:29:04,023]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:29:08,876]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:29:39,222]\u001b[0m Trial 1196 finished with value: 5.2261066749508815 and parameters: {'n_hidden': 3, 'learning_rate': 0.035036026701386565, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3862681606506743, 'dropout_rate_Layer_2': 0.3103805140055672, 'dropout_rate_Layer_3': 0.030307647681768277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5686920302828066e-05, 'l1_Layer_2': 0.0004912469163298814, 'l1_Layer_3': 0.017426513911322286, 'n_units_Layer_1': 270, 'n_units_Layer_2': 70, 'n_units_Layer_3': 55}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 11.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 15.00% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:29:46,561]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:29:51,429]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:29:57,451]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:30:11,369]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:30:16,243]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:30:44,990]\u001b[0m Trial 1202 finished with value: 5.111628631835098 and parameters: {'n_hidden': 3, 'learning_rate': 0.006129079537586322, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06560362992787479, 'dropout_rate_Layer_2': 0.1671722513462724, 'dropout_rate_Layer_3': 0.18910271388305688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006979200109097066, 'l1_Layer_2': 3.0015126150843555e-05, 'l1_Layer_3': 3.3345796447793e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.11 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 5.55 | sMAPE for Test Set is: 14.17% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:30:50,267]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:30:54,913]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:31:02,762]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:31:27,680]\u001b[0m Trial 1206 finished with value: 5.362191681142626 and parameters: {'n_hidden': 3, 'learning_rate': 0.009070320801599132, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011114949798176246, 'dropout_rate_Layer_2': 0.33552371372978196, 'dropout_rate_Layer_3': 0.20272322564629142, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01800680385963994, 'l1_Layer_2': 4.400685954425891e-05, 'l1_Layer_3': 5.352884365079484e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 255}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 11.80% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 5.68 | sMAPE for Test Set is: 14.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:31:51,455]\u001b[0m Trial 1207 finished with value: 5.062202938917184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016586528385220177, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026808326948374372, 'dropout_rate_Layer_2': 0.1042182042835982, 'dropout_rate_Layer_3': 0.04210363885979434, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001231733656351126, 'l1_Layer_2': 4.474188471532315e-05, 'l1_Layer_3': 0.003960754249936141, 'n_units_Layer_1': 155, 'n_units_Layer_2': 260, 'n_units_Layer_3': 205}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 15.15% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:31:59,419]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:32:13,961]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:32:21,662]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:32:26,641]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:32:31,653]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:32:36,344]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:00,522]\u001b[0m Trial 1214 finished with value: 5.609684623761772 and parameters: {'n_hidden': 3, 'learning_rate': 0.03592037344472483, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38571042652670756, 'dropout_rate_Layer_2': 0.2811363246653934, 'dropout_rate_Layer_3': 0.023850301869016342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1529790621666416e-05, 'l1_Layer_2': 0.0002631949920986081, 'l1_Layer_3': 0.019214672176054395, 'n_units_Layer_1': 270, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 12.48% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 14.82% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:33:05,374]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:10,484]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:17,190]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:30,611]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:35,387]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:43,137]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:48,392]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:33:53,417]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:34:01,804]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:34:06,910]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:34:21,636]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:34:26,826]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:34:59,140]\u001b[0m Trial 1227 finished with value: 5.473314382719148 and parameters: {'n_hidden': 3, 'learning_rate': 0.004264497310986619, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05217322489834902, 'dropout_rate_Layer_2': 0.2798360011811421, 'dropout_rate_Layer_3': 0.06527236150626373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010624329677440563, 'l1_Layer_2': 2.1516834384739085e-05, 'l1_Layer_3': 1.4804684743372607e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 15.03% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:35:24,434]\u001b[0m Trial 1228 finished with value: 5.132857257529565 and parameters: {'n_hidden': 3, 'learning_rate': 0.008431303952389248, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06510523965372722, 'dropout_rate_Layer_2': 0.3633043873989573, 'dropout_rate_Layer_3': 0.01905436451009475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002929568054435719, 'l1_Layer_2': 9.928783251525011e-05, 'l1_Layer_3': 5.6159403249498154e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 235}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.42% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.02 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:35:57,523]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:04,189]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:09,874]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:14,838]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:23,340]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:28,227]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:33,388]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:41,844]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:46,645]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:36:51,817]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:05,464]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:12,512]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:17,218]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:24,684]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:38,724]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:54,226]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:37:59,314]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:04,262]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:08,932]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:13,678]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:24,065]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:29,594]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:34,687]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:41,856]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:47,436]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:38:56,109]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:39:21,921]\u001b[0m Trial 1255 finished with value: 5.360058367347807 and parameters: {'n_hidden': 3, 'learning_rate': 0.026551051156997886, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3667559898574945, 'dropout_rate_Layer_2': 0.23920481937701596, 'dropout_rate_Layer_3': 0.08000996447368974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2749780062873327e-05, 'l1_Layer_2': 0.0007765589997654373, 'l1_Layer_3': 0.008418888690894556, 'n_units_Layer_1': 270, 'n_units_Layer_2': 55, 'n_units_Layer_3': 55}. Best is trial 891 with value: 4.859052543458103.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 11.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.12 | sMAPE for Test Set is: 15.24% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:39:29,420]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:39:34,471]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:39:39,221]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:39:43,779]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:39:48,462]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:40:41,583]\u001b[0m Trial 1261 finished with value: 4.74254153932273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013893975166651242, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14638933970934018, 'dropout_rate_Layer_2': 0.04842477645263471, 'dropout_rate_Layer_3': 0.39687427015960763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006035246042865329, 'l1_Layer_2': 1.6619915883387907e-05, 'l1_Layer_3': 0.0009294133335557423, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.74 | sMAPE for Validation Set is: 10.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.58 | sMAPE for Test Set is: 14.08% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:40:46,866]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:40:52,260]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:40:58,409]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:04,342]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:08,973]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:13,713]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:20,104]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:25,621]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:30,929]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:35,843]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:41,412]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:47,161]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:52,727]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:41:58,510]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:03,185]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:08,460]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:14,124]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:19,109]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:24,754]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:29,764]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:35,001]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:39,838]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:43,643]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:42:58,673]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:04,747]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:09,279]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:26,855]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:32,453]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:37,272]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:42,218]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:49,393]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:54,220]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:43:58,753]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:44:13,743]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:44:19,101]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:44:25,151]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:44:29,945]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:44:44,313]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:45:24,614]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:45:29,737]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:45:54,770]\u001b[0m Trial 1302 finished with value: 5.059358661330167 and parameters: {'n_hidden': 3, 'learning_rate': 0.004200347928947081, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1479435603951288, 'dropout_rate_Layer_2': 0.0009715039930804584, 'dropout_rate_Layer_3': 0.08493411621027454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017268722399644992, 'l1_Layer_2': 0.00018803977223784147, 'l1_Layer_3': 2.1902163488530637e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.06 | sMAPE for Validation Set is: 11.18% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:46:00,260]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:46:05,603]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:46:23,472]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:46:28,863]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:46:33,522]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:46:38,780]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:01,129]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:06,357]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:11,650]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:17,656]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:23,636]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:28,597]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:33,934]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:38,334]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:43,077]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:47:58,407]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:03,934]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:09,921]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:18,183]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:23,192]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:28,489]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:33,149]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:38,050]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:43,677]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:48,772]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:48:55,683]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:49:04,951]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:49:09,602]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:49:44,573]\u001b[0m Trial 1331 finished with value: 5.0157712189711665 and parameters: {'n_hidden': 3, 'learning_rate': 0.004011155730301174, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04646960801587062, 'dropout_rate_Layer_2': 0.399708733784157, 'dropout_rate_Layer_3': 0.2846641665533491, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002617989921675185, 'l1_Layer_2': 3.621873535049797e-05, 'l1_Layer_3': 2.9506206444451352e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 165}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 11.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.91 | sMAPE for Test Set is: 14.84% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:49:50,524]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:49:55,003]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:50:26,303]\u001b[0m Trial 1334 finished with value: 5.049976022603126 and parameters: {'n_hidden': 3, 'learning_rate': 0.00417971961266941, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061480199906034316, 'dropout_rate_Layer_2': 0.3997335242323507, 'dropout_rate_Layer_3': 0.28483677409145486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015063948628052, 'l1_Layer_2': 2.5258478333279623e-05, 'l1_Layer_3': 5.303822491689907e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 150}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.05 | sMAPE for Validation Set is: 11.24% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 15.52% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:50:51,141]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:13,432]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:27,642]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:32,312]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:37,353]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:44,715]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:51,426]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:51:55,807]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:52:00,348]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:52:04,809]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:52:09,792]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:52:38,732]\u001b[0m Trial 1346 finished with value: 5.161165441605409 and parameters: {'n_hidden': 3, 'learning_rate': 0.004123014308123979, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18964716457070563, 'dropout_rate_Layer_2': 0.3348589119018793, 'dropout_rate_Layer_3': 0.072059348847333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001486973777223037, 'l1_Layer_2': 0.0020274647508770564, 'l1_Layer_3': 0.00019470137695708637, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.16 | sMAPE for Validation Set is: 11.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.10 | sMAPE for Test Set is: 15.27% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:52:53,606]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:53:01,389]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:53:14,532]\u001b[0m Trial 1349 finished with value: 5.63277075997944 and parameters: {'n_hidden': 3, 'learning_rate': 0.005969568923937654, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15964285359754696, 'dropout_rate_Layer_2': 0.011099095293581902, 'dropout_rate_Layer_3': 0.37358470016022505, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003027607314082891, 'l1_Layer_2': 2.2715400439517484e-05, 'l1_Layer_3': 0.0002384660822173767, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 16.74% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:53:18,850]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:53:27,117]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:53:32,767]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:53:37,334]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:54:05,041]\u001b[0m Trial 1354 finished with value: 5.086778077426569 and parameters: {'n_hidden': 3, 'learning_rate': 0.001521629124749919, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20233184272709925, 'dropout_rate_Layer_2': 0.3485202146618399, 'dropout_rate_Layer_3': 0.08046145224606657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011928537250657483, 'l1_Layer_2': 0.0032208227949840026, 'l1_Layer_3': 0.00018881454287412655, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 15.13% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:54:11,083]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:54:19,295]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:54:30,125]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:54:51,463]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:54:56,395]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:55:03,725]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:55:17,455]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:55:38,699]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:55:44,304]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:55:49,533]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:24,751]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:31,935]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:37,175]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:42,674]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:47,670]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:52,828]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:56:57,411]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:57:25,592]\u001b[0m Trial 1372 finished with value: 5.252118999456337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028379660565653413, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2512078584058872, 'dropout_rate_Layer_2': 0.05230530322884901, 'dropout_rate_Layer_3': 0.06994986365384373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.312858188091773e-05, 'l1_Layer_2': 0.0003897789165241581, 'l1_Layer_3': 0.0001581611276434145, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 11.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 14.66% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:57:31,019]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:57:36,281]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:57:41,447]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:57:49,098]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:57:54,434]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:58:07,761]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:58:13,567]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:58:19,626]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:58:48,476]\u001b[0m Trial 1381 finished with value: 4.97777895728525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019294407541562738, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023808671758625232, 'dropout_rate_Layer_2': 0.12608335206433297, 'dropout_rate_Layer_3': 0.10463455190659526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013544298863100648, 'l1_Layer_2': 0.0001365390482450211, 'l1_Layer_3': 0.005394775502101386, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 11.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.84 | sMAPE for Test Set is: 14.79% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:59:10,822]\u001b[0m Trial 1382 finished with value: 6.6651655601522775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006396042937931154, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08587720129755692, 'dropout_rate_Layer_2': 0.06555808841370882, 'dropout_rate_Layer_3': 0.38472550611245815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0044860357003368, 'l1_Layer_2': 1.727032732169635e-05, 'l1_Layer_3': 0.0009497073882703449, 'n_units_Layer_1': 150, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 14.83% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 06:59:15,796]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:59:21,340]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:59:29,395]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:59:35,017]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:59:39,926]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 06:59:48,263]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:00:05,260]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:00:39,689]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:00:44,551]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:00:50,456]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:00:55,862]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:01,581]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:07,307]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:13,368]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:18,039]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:27,187]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:39,663]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:44,816]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:50,690]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:01:56,403]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:04,158]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:09,865]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:14,883]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:20,956]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:37,298]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:43,505]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:50,879]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:02:59,983]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:03:38,950]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:04:15,343]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:04:23,800]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:04:41,528]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:04:47,429]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:04:52,218]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:05:06,062]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:05:24,152]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:05:29,241]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:05:34,207]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:06:17,376]\u001b[0m Trial 1421 finished with value: 5.029248079942812 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038809951741340773, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05562212444437565, 'dropout_rate_Layer_2': 0.19064441625808218, 'dropout_rate_Layer_3': 0.28456519120044443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011261905036357447, 'l1_Layer_2': 4.7351202131959575e-05, 'l1_Layer_3': 0.00040541516451754787, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 155}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.03 | sMAPE for Validation Set is: 11.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.94 | sMAPE for Test Set is: 14.91% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:06:39,227]\u001b[0m Trial 1422 finished with value: 5.131740600876301 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046558902364358876, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14277094353523712, 'dropout_rate_Layer_2': 0.1657590469337396, 'dropout_rate_Layer_3': 0.051988432037861965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006553506562100758, 'l1_Layer_2': 0.0013866785098232929, 'l1_Layer_3': 8.890241060980126e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 15.60% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:07:34,085]\u001b[0m Trial 1423 finished with value: 4.838880982665375 and parameters: {'n_hidden': 3, 'learning_rate': 0.001132761203625976, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13497037911791201, 'dropout_rate_Layer_2': 0.17515856282139688, 'dropout_rate_Layer_3': 0.04441067401272876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006309918259110667, 'l1_Layer_2': 0.0014596952811158118, 'l1_Layer_3': 8.305802099432783e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.84 | sMAPE for Validation Set is: 10.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.81 | sMAPE for Test Set is: 14.57% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:07:39,464]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:07:44,430]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:07:50,010]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:08:34,200]\u001b[0m Trial 1427 finished with value: 5.069984317154413 and parameters: {'n_hidden': 3, 'learning_rate': 0.003610549556158403, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05672776873689935, 'dropout_rate_Layer_2': 0.1846450082386492, 'dropout_rate_Layer_3': 0.20262385449195683, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00144401387673571, 'l1_Layer_2': 2.4662372859808433e-05, 'l1_Layer_3': 0.0003599237878988306, 'n_units_Layer_1': 250, 'n_units_Layer_2': 130, 'n_units_Layer_3': 150}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:08:40,196]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:09:57,848]\u001b[0m Trial 1429 finished with value: 4.921042565025208 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008744370838185149, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14254828209477918, 'dropout_rate_Layer_2': 0.17448470027870247, 'dropout_rate_Layer_3': 0.060174409814942764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007252465767020568, 'l1_Layer_2': 0.00035074139044932105, 'l1_Layer_3': 6.838418481023922e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.92 | sMAPE for Validation Set is: 10.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 14.44% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:10:03,166]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:10:08,552]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:10:21,729]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:10:36,155]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:11:05,816]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:11:11,092]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:11:16,508]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:11:54,341]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:12:28,150]\u001b[0m Trial 1438 finished with value: 4.98635872342289 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011001993001658363, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1187514625849467, 'dropout_rate_Layer_2': 0.17131433622570574, 'dropout_rate_Layer_3': 0.04818884555360004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006482984501507446, 'l1_Layer_2': 0.0012414499305096057, 'l1_Layer_3': 4.9620431227239534e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 11.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.48 | sMAPE for Test Set is: 14.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:12:42,643]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:13:14,050]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:13:18,796]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:13:26,076]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:13:30,676]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:13:36,340]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:13:41,905]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:14:37,275]\u001b[0m Trial 1446 finished with value: 5.069543690921208 and parameters: {'n_hidden': 3, 'learning_rate': 0.002957922308852183, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07325246053456369, 'dropout_rate_Layer_2': 0.1750035346372627, 'dropout_rate_Layer_3': 0.2838146967083446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001356823943375758, 'l1_Layer_2': 1.2262646690631923e-05, 'l1_Layer_3': 0.000579216311894449, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 155}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 15.55% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:14:52,816]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:15:27,371]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:15:32,627]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:16:01,103]\u001b[0m Trial 1450 finished with value: 5.665716755199255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0263388255887883, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3861003497156578, 'dropout_rate_Layer_2': 0.22472916587987124, 'dropout_rate_Layer_3': 0.06550803928714838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5678160721090815e-05, 'l1_Layer_2': 0.0007473543076685638, 'l1_Layer_3': 0.02302814373856943, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 75}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 12.63% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 5.87 | sMAPE for Test Set is: 14.83% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:16:09,143]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:16:23,831]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:16:31,301]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:16:36,536]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:16:43,341]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:17:05,685]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:17:40,857]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:17:46,422]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:18:04,586]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:18:09,663]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:18:43,827]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:18:49,487]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:18:53,976]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:18:58,531]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:19:02,985]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:19:36,171]\u001b[0m Trial 1466 finished with value: 5.473143281661376 and parameters: {'n_hidden': 3, 'learning_rate': 0.02434130897050211, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3674414549983665, 'dropout_rate_Layer_2': 0.23590210360985048, 'dropout_rate_Layer_3': 0.031929032949604724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.288099336298988e-05, 'l1_Layer_2': 0.00042804675687640195, 'l1_Layer_3': 0.01404702380517231, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 55}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 5.88 | sMAPE for Test Set is: 14.77% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:19:40,519]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:20:12,480]\u001b[0m Trial 1468 finished with value: 4.974827902570117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014320560588566198, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03150120722528029, 'dropout_rate_Layer_2': 0.14474840934531166, 'dropout_rate_Layer_3': 0.021205309035651196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015453413852073965, 'l1_Layer_2': 7.435232544957092e-05, 'l1_Layer_3': 0.003592513038935558, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 11.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 14.58% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:20:21,218]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:20:26,301]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:20:31,567]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:20:55,691]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:21:00,453]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:21:28,798]\u001b[0m Trial 1474 finished with value: 5.3279857533626265 and parameters: {'n_hidden': 3, 'learning_rate': 0.06053459357227061, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3353467486096184, 'dropout_rate_Layer_2': 0.2583957752591729, 'dropout_rate_Layer_3': 0.04978311291274086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.138402872742808e-05, 'l1_Layer_2': 0.0008376968492936989, 'l1_Layer_3': 0.09995248547703443, 'n_units_Layer_1': 280, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 15.80% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:21:34,215]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:21:40,659]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:21:44,971]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:21:50,045]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:21:58,279]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:22:06,000]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:22:39,088]\u001b[0m Trial 1481 finished with value: 5.081135627117902 and parameters: {'n_hidden': 3, 'learning_rate': 0.002918106574780452, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07706455142068751, 'dropout_rate_Layer_2': 0.19194628865097074, 'dropout_rate_Layer_3': 0.2819508192328394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011133505401605935, 'l1_Layer_2': 1.2009147908991473e-05, 'l1_Layer_3': 0.00033389647306049136, 'n_units_Layer_1': 245, 'n_units_Layer_2': 140, 'n_units_Layer_3': 150}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 11.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.17 | sMAPE for Test Set is: 15.51% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:22:43,729]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:23:02,655]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:23:37,409]\u001b[0m Trial 1484 finished with value: 5.07891093946258 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007946300531274996, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09705468739413091, 'dropout_rate_Layer_2': 0.21186854267559788, 'dropout_rate_Layer_3': 0.01972733618838705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011585805606037745, 'l1_Layer_2': 0.0004312700390835339, 'l1_Layer_3': 9.739528582727962e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 11.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.14 | sMAPE for Test Set is: 15.26% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:23:42,464]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:23:58,764]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:24:03,521]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:24:09,181]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:24:32,411]\u001b[0m Trial 1489 finished with value: 5.618487561266849 and parameters: {'n_hidden': 3, 'learning_rate': 0.08600380129109013, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35087421156817383, 'dropout_rate_Layer_2': 0.27795466855250806, 'dropout_rate_Layer_3': 0.019757332771357772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.083483260926619e-05, 'l1_Layer_2': 0.0019652781006647907, 'l1_Layer_3': 0.05629180149788017, 'n_units_Layer_1': 280, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 12.32% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 5.95 | sMAPE for Test Set is: 15.39% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:24:58,855]\u001b[0m Trial 1490 finished with value: 5.519459310556923 and parameters: {'n_hidden': 3, 'learning_rate': 0.062173697942562285, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3170511815491666, 'dropout_rate_Layer_2': 0.260490686129503, 'dropout_rate_Layer_3': 0.03437127434295602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011439543500069285, 'l1_Layer_2': 0.000899162726251968, 'l1_Layer_3': 0.07534700107848834, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 105}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 5.75 | sMAPE for Test Set is: 14.54% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:25:04,344]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:25:18,652]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:25:24,100]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:25:28,531]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:26:05,354]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:26:20,698]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:26:25,974]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:26:31,224]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:26:35,891]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:26:57,222]\u001b[0m Trial 1500 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:27:13,352]\u001b[0m Trial 1501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:27:23,874]\u001b[0m Trial 1502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:27:31,529]\u001b[0m Trial 1503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:27:36,085]\u001b[0m Trial 1504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:28:21,350]\u001b[0m Trial 1505 finished with value: 5.128494981480709 and parameters: {'n_hidden': 3, 'learning_rate': 0.003932001651361873, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07528855524167138, 'dropout_rate_Layer_2': 0.1721531414599085, 'dropout_rate_Layer_3': 0.2934181055909476, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001220690200653202, 'l1_Layer_2': 2.0296544046151788e-05, 'l1_Layer_3': 0.0004550705334667805, 'n_units_Layer_1': 265, 'n_units_Layer_2': 140, 'n_units_Layer_3': 145}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 11.35% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.22 | sMAPE for Test Set is: 15.46% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:28:29,494]\u001b[0m Trial 1506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:29:04,555]\u001b[0m Trial 1507 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:04,148]\u001b[0m Trial 1508 finished with value: 4.963965344437895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029184780748624556, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07160176610524292, 'dropout_rate_Layer_2': 0.19131582580899323, 'dropout_rate_Layer_3': 0.2863171534973482, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008728023039938382, 'l1_Layer_2': 1.8702090324305996e-05, 'l1_Layer_3': 0.0006718347942757404, 'n_units_Layer_1': 260, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.96 | sMAPE for Validation Set is: 11.01% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 15.47% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:30:08,951]\u001b[0m Trial 1509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:13,605]\u001b[0m Trial 1510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:18,826]\u001b[0m Trial 1511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:23,304]\u001b[0m Trial 1512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:27,771]\u001b[0m Trial 1513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:32,029]\u001b[0m Trial 1514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:39,788]\u001b[0m Trial 1515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:45,077]\u001b[0m Trial 1516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:49,329]\u001b[0m Trial 1517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:54,915]\u001b[0m Trial 1518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:30:59,216]\u001b[0m Trial 1519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:03,593]\u001b[0m Trial 1520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:11,774]\u001b[0m Trial 1521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:16,222]\u001b[0m Trial 1522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:21,382]\u001b[0m Trial 1523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:29,196]\u001b[0m Trial 1524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:36,728]\u001b[0m Trial 1525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:41,849]\u001b[0m Trial 1526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:46,354]\u001b[0m Trial 1527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:53,018]\u001b[0m Trial 1528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:31:57,685]\u001b[0m Trial 1529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:32:02,996]\u001b[0m Trial 1530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:32:08,414]\u001b[0m Trial 1531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:32:13,817]\u001b[0m Trial 1532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:32:18,285]\u001b[0m Trial 1533 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:32:23,751]\u001b[0m Trial 1534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:32:29,736]\u001b[0m Trial 1535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:34:05,994]\u001b[0m Trial 1536 finished with value: 5.147114335158682 and parameters: {'n_hidden': 3, 'learning_rate': 0.002842458190496662, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07421135188853166, 'dropout_rate_Layer_2': 0.16741638074109183, 'dropout_rate_Layer_3': 0.2858657819105619, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007955993870723322, 'l1_Layer_2': 1.6294431848650078e-05, 'l1_Layer_3': 0.00044430519431227713, 'n_units_Layer_1': 260, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.15 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.26 | sMAPE for Test Set is: 15.53% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:34:10,373]\u001b[0m Trial 1537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:34:17,621]\u001b[0m Trial 1538 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:34:40,071]\u001b[0m Trial 1539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:34:44,654]\u001b[0m Trial 1540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:34:49,015]\u001b[0m Trial 1541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:35:04,477]\u001b[0m Trial 1542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:35:09,942]\u001b[0m Trial 1543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:35:18,464]\u001b[0m Trial 1544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:35:54,857]\u001b[0m Trial 1545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:35:59,826]\u001b[0m Trial 1546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:36:04,945]\u001b[0m Trial 1547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:36:09,802]\u001b[0m Trial 1548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:36:18,075]\u001b[0m Trial 1549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:36:23,348]\u001b[0m Trial 1550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:36:30,907]\u001b[0m Trial 1551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:36:35,367]\u001b[0m Trial 1552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:37:12,946]\u001b[0m Trial 1553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:37:18,505]\u001b[0m Trial 1554 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:37:59,263]\u001b[0m Trial 1555 finished with value: 4.979744697513969 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010479482212047391, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03193108937054891, 'dropout_rate_Layer_2': 0.15750172546422347, 'dropout_rate_Layer_3': 0.18176247534006412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.170223765888443e-05, 'l1_Layer_2': 0.00012498941582253764, 'l1_Layer_3': 0.010706556719501225, 'n_units_Layer_1': 115, 'n_units_Layer_2': 250, 'n_units_Layer_3': 190}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.98 | sMAPE for Validation Set is: 11.14% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.92 | sMAPE for Test Set is: 14.91% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:38:03,638]\u001b[0m Trial 1556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:38:20,857]\u001b[0m Trial 1557 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:38:25,464]\u001b[0m Trial 1558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:38:32,038]\u001b[0m Trial 1559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:39:02,659]\u001b[0m Trial 1560 finished with value: 4.98983466563056 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060977397329100924, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08686714491930433, 'dropout_rate_Layer_2': 0.03802876413893464, 'dropout_rate_Layer_3': 0.05267363009868745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005682481144145495, 'l1_Layer_2': 0.003179043222727399, 'l1_Layer_3': 5.1934417353846545e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.99 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 14.73% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:39:17,855]\u001b[0m Trial 1561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:39:38,097]\u001b[0m Trial 1562 finished with value: 5.072870885615463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0065160710180895785, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09177566161182826, 'dropout_rate_Layer_2': 0.0371216965923577, 'dropout_rate_Layer_3': 0.055183628218499, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005766105834600271, 'l1_Layer_2': 0.0030369959840443233, 'l1_Layer_3': 5.0109485224583594e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.07 | sMAPE for Validation Set is: 11.30% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.00 | sMAPE for Test Set is: 15.06% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:39:52,454]\u001b[0m Trial 1563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:39:57,327]\u001b[0m Trial 1564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:40:03,518]\u001b[0m Trial 1565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:40:11,342]\u001b[0m Trial 1566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:40:17,900]\u001b[0m Trial 1567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:40:51,877]\u001b[0m Trial 1568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:41:05,587]\u001b[0m Trial 1569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:41:28,561]\u001b[0m Trial 1570 finished with value: 5.433265464949653 and parameters: {'n_hidden': 3, 'learning_rate': 0.033424824393542635, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3999447872122085, 'dropout_rate_Layer_2': 0.23872450534044626, 'dropout_rate_Layer_3': 0.061366016803517984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2286031895959428e-05, 'l1_Layer_2': 0.00028094319710584697, 'l1_Layer_3': 0.01020992253513962, 'n_units_Layer_1': 265, 'n_units_Layer_2': 55, 'n_units_Layer_3': 60}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 15.90% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:41:43,068]\u001b[0m Trial 1571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:41:53,028]\u001b[0m Trial 1572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:41:58,160]\u001b[0m Trial 1573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:42:08,286]\u001b[0m Trial 1574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:42:14,034]\u001b[0m Trial 1575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:42:21,511]\u001b[0m Trial 1576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:42:26,453]\u001b[0m Trial 1577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:42:32,208]\u001b[0m Trial 1578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:42:36,822]\u001b[0m Trial 1579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:43:21,112]\u001b[0m Trial 1580 finished with value: 5.080287196347611 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022304717739640755, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027614386343250363, 'dropout_rate_Layer_2': 0.05666565618089624, 'dropout_rate_Layer_3': 0.35165808430087947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019463402351770096, 'l1_Layer_2': 2.8075635397262537e-05, 'l1_Layer_3': 0.0004955329197658774, 'n_units_Layer_1': 160, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.08 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 15.49% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:44:07,383]\u001b[0m Trial 1581 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:44:13,088]\u001b[0m Trial 1582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:44:19,730]\u001b[0m Trial 1583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:45:13,132]\u001b[0m Trial 1584 finished with value: 4.92953949336455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015761086468056664, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08110898040557986, 'dropout_rate_Layer_2': 0.000456339900423805, 'dropout_rate_Layer_3': 0.37339409366605175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004032394076961926, 'l1_Layer_2': 5.4993657713096293e-05, 'l1_Layer_3': 0.0016333741931187464, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 280}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.93 | sMAPE for Validation Set is: 10.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 15.10% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:46:03,255]\u001b[0m Trial 1585 finished with value: 5.269649703755724 and parameters: {'n_hidden': 3, 'learning_rate': 0.004016274173943857, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08420773676358072, 'dropout_rate_Layer_2': 0.17017558424590745, 'dropout_rate_Layer_3': 0.2577313045872344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010582919031125776, 'l1_Layer_2': 1.2172986689930984e-05, 'l1_Layer_3': 0.0008418155738496942, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 11.63% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 16.61% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:46:10,249]\u001b[0m Trial 1586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:14,932]\u001b[0m Trial 1587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:29,731]\u001b[0m Trial 1588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:34,914]\u001b[0m Trial 1589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:39,401]\u001b[0m Trial 1590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:44,943]\u001b[0m Trial 1591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:50,354]\u001b[0m Trial 1592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:54,630]\u001b[0m Trial 1593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:46:59,050]\u001b[0m Trial 1594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:13,925]\u001b[0m Trial 1595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:19,410]\u001b[0m Trial 1596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:38,788]\u001b[0m Trial 1597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:43,062]\u001b[0m Trial 1598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:48,783]\u001b[0m Trial 1599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:53,758]\u001b[0m Trial 1600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:47:58,056]\u001b[0m Trial 1601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:48:03,407]\u001b[0m Trial 1602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:48:08,661]\u001b[0m Trial 1603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:48:13,818]\u001b[0m Trial 1604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:48:19,383]\u001b[0m Trial 1605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:48:49,878]\u001b[0m Trial 1606 finished with value: 4.999244375939254 and parameters: {'n_hidden': 3, 'learning_rate': 0.002296339616251467, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07429726020914591, 'dropout_rate_Layer_2': 0.17409899383283572, 'dropout_rate_Layer_3': 0.06699671100290655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017171172048134837, 'l1_Layer_2': 2.012139698982252e-05, 'l1_Layer_3': 0.0003649110534841468, 'n_units_Layer_1': 275, 'n_units_Layer_2': 135, 'n_units_Layer_3': 140}. Best is trial 1261 with value: 4.74254153932273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.00 | sMAPE for Validation Set is: 11.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.03 | sMAPE for Test Set is: 15.16% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 07:48:55,649]\u001b[0m Trial 1607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:49:01,096]\u001b[0m Trial 1608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:49:06,797]\u001b[0m Trial 1609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:49:24,335]\u001b[0m Trial 1610 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:49:30,827]\u001b[0m Trial 1611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:49:35,351]\u001b[0m Trial 1612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:49:40,605]\u001b[0m Trial 1613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:02,145]\u001b[0m Trial 1614 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:06,895]\u001b[0m Trial 1615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:12,756]\u001b[0m Trial 1616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:18,081]\u001b[0m Trial 1617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:22,571]\u001b[0m Trial 1618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:39,319]\u001b[0m Trial 1619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:44,223]\u001b[0m Trial 1620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:51,894]\u001b[0m Trial 1621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:50:57,084]\u001b[0m Trial 1622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:03,497]\u001b[0m Trial 1623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:08,910]\u001b[0m Trial 1624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:14,024]\u001b[0m Trial 1625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:27,497]\u001b[0m Trial 1626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:32,295]\u001b[0m Trial 1627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:36,720]\u001b[0m Trial 1628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:41,211]\u001b[0m Trial 1629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:46,244]\u001b[0m Trial 1630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:51:51,596]\u001b[0m Trial 1631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:52:06,487]\u001b[0m Trial 1632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:52:10,686]\u001b[0m Trial 1633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 07:52:19,226]\u001b[0m Trial 1634 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:11.87 & sMAPE is:52.46% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.87 & 52.46% & 0.60\n",
      "for 2019-01-02, MAE is:16.78 & sMAPE is:51.95% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :14.32 & 52.20% & 1.90\n",
      "for 2019-01-03, MAE is:3.98 & sMAPE is:6.93% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.88 & 37.11% & 1.52\n",
      "for 2019-01-04, MAE is:2.43 & sMAPE is:4.45% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 28.95% & 1.36\n",
      "for 2019-01-05, MAE is:2.29 & sMAPE is:4.22% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 24.00% & 1.23\n",
      "for 2019-01-06, MAE is:2.14 & sMAPE is:4.07% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 20.68% & 1.31\n",
      "for 2019-01-07, MAE is:2.63 & sMAPE is:5.14% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 18.46% & 1.20\n",
      "for 2019-01-08, MAE is:4.54 & sMAPE is:9.41% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 17.33% & 1.07\n",
      "for 2019-01-09, MAE is:10.04 & sMAPE is:18.48% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 17.46% & 1.02\n",
      "for 2019-01-10, MAE is:7.79 & sMAPE is:12.81% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 16.99% & 1.03\n",
      "for 2019-01-11, MAE is:2.64 & sMAPE is:5.11% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 15.91% & 1.01\n",
      "for 2019-01-12, MAE is:1.21 & sMAPE is:2.51% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.70 & 14.79% & 0.95\n",
      "for 2019-01-13, MAE is:2.64 & sMAPE is:5.53% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 14.08% & 0.94\n",
      "for 2019-01-14, MAE is:7.34 & sMAPE is:18.38% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 14.39% & 0.94\n",
      "for 2019-01-15, MAE is:7.51 & sMAPE is:14.64% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 14.41% & 0.99\n",
      "for 2019-01-16, MAE is:3.87 & sMAPE is:7.14% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :5.61 & 13.95% & 0.98\n",
      "for 2019-01-17, MAE is:2.62 & sMAPE is:5.01% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 13.43% & 0.94\n",
      "for 2019-01-18, MAE is:6.17 & sMAPE is:10.23% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.47 & 13.25% & 0.92\n",
      "for 2019-01-19, MAE is:3.20 & sMAPE is:5.61% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.35 & 12.85% & 0.90\n",
      "for 2019-01-20, MAE is:3.22 & sMAPE is:5.80% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 12.49% & 0.88\n",
      "for 2019-01-21, MAE is:7.29 & sMAPE is:10.80% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 12.41% & 0.85\n",
      "for 2019-01-22, MAE is:3.93 & sMAPE is:5.93% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.28 & 12.12% & 0.83\n",
      "for 2019-01-23, MAE is:9.33 & sMAPE is:13.13% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 12.16% & 0.83\n",
      "for 2019-01-24, MAE is:20.71 & sMAPE is:27.18% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 12.79% & 0.82\n",
      "for 2019-01-25, MAE is:6.98 & sMAPE is:10.18% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 12.68% & 0.84\n",
      "for 2019-01-26, MAE is:2.34 & sMAPE is:4.15% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 12.36% & 0.87\n",
      "for 2019-01-27, MAE is:3.70 & sMAPE is:6.61% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 12.14% & 0.90\n",
      "for 2019-01-28, MAE is:4.02 & sMAPE is:6.58% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 11.94% & 0.88\n",
      "for 2019-01-29, MAE is:6.26 & sMAPE is:10.33% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 11.89% & 0.91\n",
      "for 2019-01-30, MAE is:3.22 & sMAPE is:5.30% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 11.67% & 0.89\n",
      "for 2019-01-31, MAE is:6.83 & sMAPE is:11.50% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 11.66% & 0.88\n",
      "for 2019-02-01, MAE is:3.45 & sMAPE is:5.93% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 11.48% & 0.86\n",
      "for 2019-02-02, MAE is:1.40 & sMAPE is:2.77% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.59 & 11.22% & 0.85\n",
      "for 2019-02-03, MAE is:0.81 & sMAPE is:1.63% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 10.94% & 0.83\n",
      "for 2019-02-04, MAE is:2.72 & sMAPE is:4.95% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 10.77% & 0.82\n",
      "for 2019-02-05, MAE is:2.86 & sMAPE is:5.07% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.30 & 10.61% & 0.81\n",
      "for 2019-02-06, MAE is:4.25 & sMAPE is:7.53% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :5.27 & 10.53% & 0.83\n",
      "for 2019-02-07, MAE is:2.86 & sMAPE is:5.30% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.21 & 10.39% & 0.82\n",
      "for 2019-02-08, MAE is:2.41 & sMAPE is:4.84% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 10.25% & 0.80\n",
      "for 2019-02-09, MAE is:2.56 & sMAPE is:5.66% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.07 & 10.13% & 0.80\n",
      "for 2019-02-10, MAE is:1.10 & sMAPE is:2.45% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 9.94% & 0.79\n",
      "for 2019-02-11, MAE is:2.63 & sMAPE is:5.35% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 9.83% & 0.78\n",
      "for 2019-02-12, MAE is:2.33 & sMAPE is:4.82% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 9.72% & 0.77\n",
      "for 2019-02-13, MAE is:2.92 & sMAPE is:6.01% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 9.63% & 0.76\n",
      "for 2019-02-14, MAE is:2.94 & sMAPE is:6.01% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.77 & 9.55% & 0.76\n",
      "for 2019-02-15, MAE is:2.69 & sMAPE is:6.39% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 9.48% & 0.75\n",
      "for 2019-02-16, MAE is:1.46 & sMAPE is:3.68% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 9.36% & 0.74\n",
      "for 2019-02-17, MAE is:2.62 & sMAPE is:6.35% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 9.30% & 0.74\n",
      "for 2019-02-18, MAE is:4.06 & sMAPE is:8.60% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 9.28% & 0.73\n",
      "for 2019-02-19, MAE is:2.41 & sMAPE is:5.64% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.56 & 9.21% & 0.73\n",
      "for 2019-02-20, MAE is:2.33 & sMAPE is:5.67% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 9.14% & 0.72\n",
      "for 2019-02-21, MAE is:2.54 & sMAPE is:5.29% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 9.07% & 0.72\n",
      "for 2019-02-22, MAE is:3.48 & sMAPE is:7.45% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 9.04% & 0.73\n",
      "for 2019-02-23, MAE is:2.21 & sMAPE is:5.71% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.42 & 8.97% & 0.78\n",
      "for 2019-02-24, MAE is:1.10 & sMAPE is:2.94% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.36 & 8.86% & 0.77\n",
      "for 2019-02-25, MAE is:1.87 & sMAPE is:4.67% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.31 & 8.79% & 0.77\n",
      "for 2019-02-26, MAE is:4.56 & sMAPE is:9.93% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 8.81% & 0.78\n",
      "for 2019-02-27, MAE is:2.88 & sMAPE is:6.84% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 8.78% & 0.79\n",
      "for 2019-02-28, MAE is:3.52 & sMAPE is:9.08% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.28 & 8.78% & 0.78\n",
      "for 2019-03-01, MAE is:5.59 & sMAPE is:11.48% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 8.83% & 0.80\n",
      "for 2019-03-02, MAE is:2.06 & sMAPE is:4.93% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 8.76% & 0.80\n",
      "for 2019-03-03, MAE is:1.39 & sMAPE is:3.59% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.68% & 0.80\n",
      "for 2019-03-04, MAE is:5.17 & sMAPE is:11.25% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 8.72% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-05, MAE is:3.39 & sMAPE is:7.77% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.22 & 8.71% & 0.81\n",
      "for 2019-03-06, MAE is:3.25 & sMAPE is:7.22% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.21 & 8.68% & 0.80\n",
      "for 2019-03-07, MAE is:3.19 & sMAPE is:7.53% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.19 & 8.66% & 0.80\n",
      "for 2019-03-08, MAE is:2.95 & sMAPE is:7.43% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 8.65% & 0.79\n",
      "for 2019-03-09, MAE is:3.35 & sMAPE is:9.30% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 8.66% & 0.80\n",
      "for 2019-03-10, MAE is:3.49 & sMAPE is:9.18% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 8.66% & 0.82\n",
      "for 2019-03-11, MAE is:3.95 & sMAPE is:9.64% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.15 & 8.68% & 0.82\n",
      "for 2019-03-12, MAE is:2.90 & sMAPE is:6.30% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 8.64% & 0.82\n",
      "for 2019-03-13, MAE is:3.13 & sMAPE is:7.04% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.12 & 8.62% & 0.82\n",
      "for 2019-03-14, MAE is:1.76 & sMAPE is:4.40% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 8.56% & 0.82\n",
      "for 2019-03-15, MAE is:3.13 & sMAPE is:7.87% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.07 & 8.55% & 0.82\n",
      "for 2019-03-16, MAE is:1.68 & sMAPE is:4.18% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 8.50% & 0.81\n",
      "for 2019-03-17, MAE is:2.70 & sMAPE is:7.80% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 8.49% & 0.81\n",
      "for 2019-03-18, MAE is:8.92 & sMAPE is:23.68% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.09 & 8.68% & 0.83\n",
      "for 2019-03-19, MAE is:5.71 & sMAPE is:13.19% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :4.11 & 8.74% & 0.84\n",
      "for 2019-03-20, MAE is:3.64 & sMAPE is:8.27% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 8.74% & 0.85\n",
      "for 2019-03-21, MAE is:2.82 & sMAPE is:6.80% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 8.71% & 0.85\n",
      "for 2019-03-22, MAE is:2.34 & sMAPE is:5.96% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 8.68% & 0.85\n",
      "for 2019-03-23, MAE is:2.92 & sMAPE is:8.72% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 8.68% & 0.84\n",
      "for 2019-03-24, MAE is:4.11 & sMAPE is:12.79% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 8.73% & 0.85\n",
      "for 2019-03-25, MAE is:2.68 & sMAPE is:7.60% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 8.71% & 0.85\n",
      "for 2019-03-26, MAE is:2.46 & sMAPE is:6.26% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 8.69% & 0.84\n",
      "for 2019-03-27, MAE is:2.29 & sMAPE is:5.54% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 8.65% & 0.85\n",
      "for 2019-03-28, MAE is:2.28 & sMAPE is:6.53% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 8.62% & 0.84\n",
      "for 2019-03-29, MAE is:6.41 & sMAPE is:33.16% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 8.90% & 0.84\n",
      "for 2019-03-30, MAE is:4.56 & sMAPE is:15.12% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 8.97% & 0.86\n",
      "for 2019-03-31, MAE is:5.36 & sMAPE is:21.09% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.11% & 0.86\n",
      "for 2019-04-01, MAE is:3.27 & sMAPE is:8.26% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.10% & 0.86\n",
      "for 2019-04-02, MAE is:2.31 & sMAPE is:6.91% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.07% & 0.86\n",
      "for 2019-04-03, MAE is:7.94 & sMAPE is:22.23% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 9.22% & 0.89\n",
      "for 2019-04-04, MAE is:3.04 & sMAPE is:7.91% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.20% & 0.89\n",
      "for 2019-04-05, MAE is:6.53 & sMAPE is:16.44% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :4.06 & 9.28% & 0.88\n",
      "for 2019-04-06, MAE is:2.36 & sMAPE is:6.36% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 9.25% & 0.88\n",
      "for 2019-04-07, MAE is:3.88 & sMAPE is:10.46% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 9.26% & 0.87\n",
      "for 2019-04-08, MAE is:2.85 & sMAPE is:6.75% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :4.02 & 9.23% & 0.87\n",
      "for 2019-04-09, MAE is:2.42 & sMAPE is:5.80% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.20% & 0.87\n",
      "for 2019-04-10, MAE is:2.42 & sMAPE is:5.55% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 9.16% & 0.86\n",
      "for 2019-04-11, MAE is:4.11 & sMAPE is:9.06% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 9.16% & 0.86\n",
      "for 2019-04-12, MAE is:7.68 & sMAPE is:14.25% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.21% & 0.86\n",
      "for 2019-04-13, MAE is:2.07 & sMAPE is:4.81% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.17% & 0.85\n",
      "for 2019-04-14, MAE is:1.59 & sMAPE is:3.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 9.12% & 0.85\n",
      "for 2019-04-15, MAE is:5.06 & sMAPE is:10.99% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.14% & 0.85\n",
      "for 2019-04-16, MAE is:5.55 & sMAPE is:11.09% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.16% & 0.85\n",
      "for 2019-04-17, MAE is:3.24 & sMAPE is:7.10% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :4.00 & 9.14% & 0.85\n",
      "for 2019-04-18, MAE is:4.23 & sMAPE is:9.27% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 9.14% & 0.86\n",
      "for 2019-04-19, MAE is:2.43 & sMAPE is:6.01% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 9.11% & 0.85\n",
      "for 2019-04-20, MAE is:1.76 & sMAPE is:4.40% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :3.97 & 9.07% & 0.85\n",
      "for 2019-04-21, MAE is:1.82 & sMAPE is:4.87% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 9.03% & 0.85\n",
      "for 2019-04-22, MAE is:3.06 & sMAPE is:10.54% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.94 & 9.04% & 0.84\n",
      "for 2019-04-23, MAE is:8.71 & sMAPE is:30.36% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :3.99 & 9.23% & 0.84\n",
      "for 2019-04-24, MAE is:8.41 & sMAPE is:41.79% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 9.52% & 0.84\n",
      "for 2019-04-25, MAE is:5.37 & sMAPE is:13.99% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.04 & 9.55% & 0.84\n",
      "for 2019-04-26, MAE is:9.56 & sMAPE is:17.72% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 9.63% & 0.84\n",
      "for 2019-04-27, MAE is:5.62 & sMAPE is:16.32% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.10 & 9.68% & 0.84\n",
      "for 2019-04-28, MAE is:9.41 & sMAPE is:50.72% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 10.03% & 0.83\n",
      "for 2019-04-29, MAE is:10.63 & sMAPE is:24.69% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 10.15% & 0.83\n",
      "for 2019-04-30, MAE is:8.21 & sMAPE is:21.55% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.23 & 10.25% & 0.83\n",
      "for 2019-05-01, MAE is:10.85 & sMAPE is:65.62% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 10.71% & 0.83\n",
      "for 2019-05-02, MAE is:9.20 & sMAPE is:59.35% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 11.10% & 0.83\n",
      "for 2019-05-03, MAE is:3.77 & sMAPE is:10.74% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 11.10% & 0.83\n",
      "for 2019-05-04, MAE is:2.02 & sMAPE is:5.09% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.30 & 11.05% & 0.82\n",
      "for 2019-05-05, MAE is:2.49 & sMAPE is:6.85% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.29 & 11.02% & 0.82\n",
      "for 2019-05-06, MAE is:8.81 & sMAPE is:15.77% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.32 & 11.06% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-07, MAE is:5.17 & sMAPE is:10.03% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :4.33 & 11.05% & 0.82\n",
      "for 2019-05-08, MAE is:5.60 & sMAPE is:14.86% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 11.08% & 0.82\n",
      "for 2019-05-09, MAE is:10.11 & sMAPE is:29.52% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 11.22% & 0.82\n",
      "for 2019-05-10, MAE is:6.40 & sMAPE is:24.29% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.40 & 11.32% & 0.82\n",
      "for 2019-05-11, MAE is:2.41 & sMAPE is:6.67% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.39 & 11.29% & 0.82\n",
      "for 2019-05-12, MAE is:20.14 & sMAPE is:106.29% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 12.01% & 0.82\n",
      "for 2019-05-13, MAE is:33.97 & sMAPE is:59.10% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 12.36% & 0.83\n",
      "for 2019-05-14, MAE is:12.49 & sMAPE is:19.65% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 12.41% & 0.83\n",
      "for 2019-05-15, MAE is:5.42 & sMAPE is:10.96% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 12.40% & 0.83\n",
      "for 2019-05-16, MAE is:6.11 & sMAPE is:13.36% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.41% & 0.83\n",
      "for 2019-05-17, MAE is:5.99 & sMAPE is:14.24% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.42% & 0.83\n",
      "for 2019-05-18, MAE is:2.91 & sMAPE is:9.38% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 12.40% & 0.83\n",
      "for 2019-05-19, MAE is:7.94 & sMAPE is:24.10% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 12.49% & 0.83\n",
      "for 2019-05-20, MAE is:6.30 & sMAPE is:12.24% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 12.48% & 0.82\n",
      "for 2019-05-21, MAE is:10.55 & sMAPE is:18.27% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.87 & 12.53% & 0.82\n",
      "for 2019-05-22, MAE is:20.70 & sMAPE is:26.94% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 12.63% & 0.83\n",
      "for 2019-05-23, MAE is:6.37 & sMAPE is:12.95% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 12.63% & 0.83\n",
      "for 2019-05-24, MAE is:10.61 & sMAPE is:18.50% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.67% & 0.83\n",
      "for 2019-05-25, MAE is:5.10 & sMAPE is:13.03% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.67% & 0.84\n",
      "for 2019-05-26, MAE is:5.36 & sMAPE is:18.10% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.03 & 12.71% & 0.84\n",
      "for 2019-05-27, MAE is:11.77 & sMAPE is:30.01% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 12.83% & 0.84\n",
      "for 2019-05-28, MAE is:9.13 & sMAPE is:20.59% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 12.88% & 0.84\n",
      "for 2019-05-29, MAE is:9.71 & sMAPE is:32.59% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.13 & 13.01% & 0.84\n",
      "for 2019-05-30, MAE is:19.18 & sMAPE is:109.99% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 13.66% & 0.84\n",
      "for 2019-05-31, MAE is:10.17 & sMAPE is:57.60% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 13.95% & 0.84\n",
      "for 2019-06-01, MAE is:8.99 & sMAPE is:43.68% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 14.15% & 0.83\n",
      "for 2019-06-02, MAE is:10.23 & sMAPE is:58.87% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.32 & 14.44% & 0.84\n",
      "for 2019-06-03, MAE is:17.40 & sMAPE is:31.09% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 14.55% & 0.84\n",
      "for 2019-06-04, MAE is:10.55 & sMAPE is:48.39% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 14.76% & 0.84\n",
      "for 2019-06-05, MAE is:22.55 & sMAPE is:46.05% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.54 & 14.96% & 0.84\n",
      "for 2019-06-06, MAE is:17.51 & sMAPE is:67.82% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :5.62 & 15.30% & 0.84\n",
      "for 2019-06-07, MAE is:32.67 & sMAPE is:64.79% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :5.79 & 15.61% & 0.84\n",
      "for 2019-06-08, MAE is:12.76 & sMAPE is:67.61% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 15.94% & 0.84\n",
      "for 2019-06-09, MAE is:10.50 & sMAPE is:80.65% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 16.35% & 0.84\n",
      "for 2019-06-10, MAE is:9.91 & sMAPE is:58.90% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 16.61% & 0.84\n",
      "for 2019-06-11, MAE is:14.96 & sMAPE is:54.83% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 16.85% & 0.84\n",
      "for 2019-06-12, MAE is:10.94 & sMAPE is:53.47% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 17.07% & 0.84\n",
      "for 2019-06-13, MAE is:4.90 & sMAPE is:22.99% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.96 & 17.11% & 0.84\n",
      "for 2019-06-14, MAE is:3.14 & sMAPE is:9.15% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 17.06% & 0.83\n",
      "for 2019-06-15, MAE is:3.15 & sMAPE is:13.04% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 17.03% & 0.83\n",
      "for 2019-06-16, MAE is:3.14 & sMAPE is:13.44% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 17.01% & 0.82\n",
      "for 2019-06-17, MAE is:4.27 & sMAPE is:15.93% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 17.01% & 0.82\n",
      "for 2019-06-18, MAE is:3.61 & sMAPE is:14.67% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 16.99% & 0.82\n",
      "for 2019-06-19, MAE is:4.62 & sMAPE is:20.25% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.01% & 0.82\n",
      "for 2019-06-20, MAE is:4.59 & sMAPE is:14.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.00% & 0.82\n",
      "for 2019-06-21, MAE is:2.68 & sMAPE is:11.09% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 16.96% & 0.82\n",
      "for 2019-06-22, MAE is:3.52 & sMAPE is:25.95% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 17.02% & 0.82\n",
      "for 2019-06-23, MAE is:4.29 & sMAPE is:21.95% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :5.83 & 17.04% & 0.82\n",
      "for 2019-06-24, MAE is:3.07 & sMAPE is:8.56% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :5.82 & 17.00% & 0.82\n",
      "for 2019-06-25, MAE is:10.54 & sMAPE is:22.23% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 17.03% & 0.82\n",
      "for 2019-06-26, MAE is:13.76 & sMAPE is:28.80% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.09% & 0.82\n",
      "for 2019-06-27, MAE is:3.68 & sMAPE is:11.26% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.06% & 0.82\n",
      "for 2019-06-28, MAE is:7.25 & sMAPE is:18.33% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.07% & 0.82\n",
      "for 2019-06-29, MAE is:3.54 & sMAPE is:14.43% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 17.05% & 0.82\n",
      "for 2019-06-30, MAE is:6.44 & sMAPE is:31.77% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.13% & 0.82\n",
      "for 2019-07-01, MAE is:6.57 & sMAPE is:19.16% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.14% & 0.82\n",
      "for 2019-07-02, MAE is:9.11 & sMAPE is:21.20% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 17.17% & 0.82\n",
      "for 2019-07-03, MAE is:3.20 & sMAPE is:8.34% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.12% & 0.82\n",
      "for 2019-07-04, MAE is:11.82 & sMAPE is:26.85% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 17.17% & 0.82\n",
      "for 2019-07-05, MAE is:3.29 & sMAPE is:8.82% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 17.13% & 0.82\n",
      "for 2019-07-06, MAE is:2.92 & sMAPE is:10.01% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.09% & 0.82\n",
      "for 2019-07-07, MAE is:1.99 & sMAPE is:7.36% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 17.04% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-08, MAE is:3.05 & sMAPE is:9.32% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 17.00% & 0.81\n",
      "for 2019-07-09, MAE is:11.04 & sMAPE is:26.29% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.04% & 0.82\n",
      "for 2019-07-10, MAE is:4.33 & sMAPE is:11.64% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 17.02% & 0.82\n",
      "for 2019-07-11, MAE is:9.15 & sMAPE is:21.97% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.04% & 0.82\n",
      "for 2019-07-12, MAE is:6.42 & sMAPE is:15.95% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 17.04% & 0.82\n",
      "for 2019-07-13, MAE is:5.04 & sMAPE is:14.25% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :5.88 & 17.02% & 0.82\n",
      "for 2019-07-14, MAE is:1.31 & sMAPE is:3.70% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.86 & 16.95% & 0.82\n",
      "for 2019-07-15, MAE is:15.95 & sMAPE is:31.87% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 17.03% & 0.82\n",
      "for 2019-07-16, MAE is:3.62 & sMAPE is:8.06% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 16.98% & 0.82\n",
      "for 2019-07-17, MAE is:7.55 & sMAPE is:15.18% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :5.91 & 16.98% & 0.82\n",
      "for 2019-07-18, MAE is:10.05 & sMAPE is:18.33% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 16.98% & 0.82\n",
      "for 2019-07-19, MAE is:7.79 & sMAPE is:14.53% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 16.97% & 0.82\n",
      "for 2019-07-20, MAE is:4.65 & sMAPE is:10.38% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 16.94% & 0.82\n",
      "for 2019-07-21, MAE is:3.89 & sMAPE is:9.45% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.92 & 16.90% & 0.82\n",
      "for 2019-07-22, MAE is:10.66 & sMAPE is:19.92% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 16.91% & 0.83\n",
      "for 2019-07-23, MAE is:11.21 & sMAPE is:19.00% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 16.92% & 0.83\n",
      "for 2019-07-24, MAE is:11.02 & sMAPE is:17.67% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.93% & 0.83\n",
      "for 2019-07-25, MAE is:7.15 & sMAPE is:12.11% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.91% & 0.83\n",
      "for 2019-07-26, MAE is:9.02 & sMAPE is:15.71% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.90% & 0.84\n",
      "for 2019-07-27, MAE is:7.95 & sMAPE is:15.99% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.89% & 0.84\n",
      "for 2019-07-28, MAE is:6.88 & sMAPE is:16.00% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.89% & 0.84\n",
      "for 2019-07-29, MAE is:7.77 & sMAPE is:13.74% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.88% & 0.85\n",
      "for 2019-07-30, MAE is:4.35 & sMAPE is:9.07% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.84% & 0.85\n",
      "for 2019-07-31, MAE is:3.77 & sMAPE is:7.34% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.79% & 0.84\n",
      "for 2019-08-01, MAE is:8.94 & sMAPE is:16.33% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 16.79% & 0.85\n",
      "for 2019-08-02, MAE is:9.83 & sMAPE is:18.12% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 16.80% & 0.85\n",
      "for 2019-08-03, MAE is:3.77 & sMAPE is:9.05% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.76% & 0.85\n",
      "for 2019-08-04, MAE is:1.23 & sMAPE is:3.14% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 16.70% & 0.85\n",
      "for 2019-08-05, MAE is:11.89 & sMAPE is:21.06% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 16.72% & 0.85\n",
      "for 2019-08-06, MAE is:8.61 & sMAPE is:15.32% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 16.71% & 0.85\n",
      "for 2019-08-07, MAE is:11.67 & sMAPE is:20.67% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 16.73% & 0.86\n",
      "for 2019-08-08, MAE is:9.31 & sMAPE is:16.53% & rMAE is:2.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.73% & 0.87\n",
      "for 2019-08-09, MAE is:10.40 & sMAPE is:18.89% & rMAE is:3.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.74% & 0.88\n",
      "for 2019-08-10, MAE is:2.00 & sMAPE is:5.49% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.69% & 0.87\n",
      "for 2019-08-11, MAE is:5.53 & sMAPE is:22.51% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 16.71% & 0.87\n",
      "for 2019-08-12, MAE is:11.36 & sMAPE is:21.58% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 16.74% & 0.88\n",
      "for 2019-08-13, MAE is:13.13 & sMAPE is:23.57% & rMAE is:4.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 16.77% & 0.89\n",
      "for 2019-08-14, MAE is:12.82 & sMAPE is:23.35% & rMAE is:3.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 16.80% & 0.90\n",
      "for 2019-08-15, MAE is:8.30 & sMAPE is:16.85% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 16.80% & 0.91\n",
      "for 2019-08-16, MAE is:10.70 & sMAPE is:20.55% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 16.81% & 0.91\n",
      "for 2019-08-17, MAE is:6.01 & sMAPE is:20.30% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 16.83% & 0.91\n",
      "for 2019-08-18, MAE is:2.59 & sMAPE is:8.09% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 16.79% & 0.91\n",
      "for 2019-08-19, MAE is:7.26 & sMAPE is:15.71% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 16.79% & 0.91\n",
      "for 2019-08-20, MAE is:4.91 & sMAPE is:10.81% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 16.76% & 0.91\n",
      "for 2019-08-21, MAE is:12.76 & sMAPE is:22.88% & rMAE is:7.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 16.79% & 0.94\n",
      "for 2019-08-22, MAE is:9.00 & sMAPE is:16.92% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 16.79% & 0.95\n",
      "for 2019-08-23, MAE is:11.17 & sMAPE is:21.12% & rMAE is:3.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 16.80% & 0.96\n",
      "for 2019-08-24, MAE is:9.42 & sMAPE is:19.84% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 16.82% & 0.96\n",
      "for 2019-08-25, MAE is:4.64 & sMAPE is:12.27% & rMAE is:5.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 16.80% & 0.98\n",
      "for 2019-08-26, MAE is:14.07 & sMAPE is:26.30% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 16.84% & 0.98\n",
      "for 2019-08-27, MAE is:11.96 & sMAPE is:20.83% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.32 & 16.86% & 0.98\n",
      "for 2019-08-28, MAE is:9.51 & sMAPE is:16.45% & rMAE is:3.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 16.85% & 0.99\n",
      "for 2019-08-29, MAE is:6.60 & sMAPE is:12.07% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 16.83% & 1.00\n",
      "for 2019-08-30, MAE is:11.40 & sMAPE is:20.95% & rMAE is:4.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 16.85% & 1.01\n",
      "for 2019-08-31, MAE is:7.33 & sMAPE is:18.37% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 16.86% & 1.01\n",
      "for 2019-09-01, MAE is:6.08 & sMAPE is:16.33% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.35 & 16.85% & 1.01\n",
      "for 2019-09-02, MAE is:8.32 & sMAPE is:17.07% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.86% & 1.02\n",
      "for 2019-09-03, MAE is:7.95 & sMAPE is:14.82% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.85% & 1.02\n",
      "for 2019-09-04, MAE is:7.20 & sMAPE is:13.49% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.83% & 1.02\n",
      "for 2019-09-05, MAE is:6.77 & sMAPE is:14.96% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.83% & 1.02\n",
      "for 2019-09-06, MAE is:11.21 & sMAPE is:23.18% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.85% & 1.03\n",
      "for 2019-09-07, MAE is:7.73 & sMAPE is:16.92% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.85% & 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-08, MAE is:3.80 & sMAPE is:8.23% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.39 & 16.82% & 1.02\n",
      "for 2019-09-09, MAE is:11.92 & sMAPE is:19.78% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.83% & 1.02\n",
      "for 2019-09-10, MAE is:10.13 & sMAPE is:18.59% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 16.84% & 1.03\n",
      "for 2019-09-11, MAE is:7.15 & sMAPE is:15.72% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.83% & 1.02\n",
      "for 2019-09-12, MAE is:5.76 & sMAPE is:13.17% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 16.82% & 1.02\n",
      "for 2019-09-13, MAE is:8.60 & sMAPE is:18.52% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.82% & 1.02\n",
      "for 2019-09-14, MAE is:7.20 & sMAPE is:17.29% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 16.83% & 1.02\n",
      "for 2019-09-15, MAE is:12.44 & sMAPE is:42.53% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.93% & 1.02\n",
      "for 2019-09-16, MAE is:8.71 & sMAPE is:30.48% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.98% & 1.02\n",
      "for 2019-09-17, MAE is:7.87 & sMAPE is:16.50% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.98% & 1.02\n",
      "for 2019-09-18, MAE is:9.18 & sMAPE is:19.91% & rMAE is:3.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.99% & 1.03\n",
      "for 2019-09-19, MAE is:4.99 & sMAPE is:10.53% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.96% & 1.03\n",
      "for 2019-09-20, MAE is:11.64 & sMAPE is:21.01% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.98% & 1.03\n",
      "for 2019-09-21, MAE is:2.90 & sMAPE is:7.39% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.94% & 1.03\n",
      "for 2019-09-22, MAE is:1.61 & sMAPE is:4.41% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.89% & 1.03\n",
      "for 2019-09-23, MAE is:13.80 & sMAPE is:27.35% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.93% & 1.03\n",
      "for 2019-09-24, MAE is:9.97 & sMAPE is:18.47% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.94% & 1.03\n",
      "for 2019-09-25, MAE is:13.85 & sMAPE is:26.14% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.97% & 1.03\n",
      "for 2019-09-26, MAE is:45.01 & sMAPE is:49.80% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.10% & 1.03\n",
      "for 2019-09-27, MAE is:9.33 & sMAPE is:16.09% & rMAE is:4.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 17.09% & 1.05\n",
      "for 2019-09-28, MAE is:6.15 & sMAPE is:14.42% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.08% & 1.05\n",
      "for 2019-09-29, MAE is:5.57 & sMAPE is:14.78% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.07% & 1.05\n",
      "for 2019-09-30, MAE is:5.70 & sMAPE is:12.40% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.06% & 1.04\n",
      "for 2019-10-01, MAE is:5.03 & sMAPE is:11.07% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 17.04% & 1.04\n",
      "for 2019-10-02, MAE is:4.86 & sMAPE is:11.01% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 17.01% & 1.04\n",
      "for 2019-10-03, MAE is:9.08 & sMAPE is:18.60% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 17.02% & 1.04\n",
      "for 2019-10-04, MAE is:9.83 & sMAPE is:18.95% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 17.03% & 1.04\n",
      "for 2019-10-05, MAE is:3.27 & sMAPE is:8.18% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.99% & 1.04\n",
      "for 2019-10-06, MAE is:1.38 & sMAPE is:3.72% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.95% & 1.04\n",
      "for 2019-10-07, MAE is:15.34 & sMAPE is:29.28% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.99% & 1.04\n",
      "for 2019-10-08, MAE is:13.14 & sMAPE is:22.62% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 17.01% & 1.04\n",
      "for 2019-10-09, MAE is:12.00 & sMAPE is:22.30% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 17.03% & 1.04\n",
      "for 2019-10-10, MAE is:9.71 & sMAPE is:18.55% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.03% & 1.04\n",
      "for 2019-10-11, MAE is:11.29 & sMAPE is:24.00% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.06% & 1.05\n",
      "for 2019-10-12, MAE is:6.22 & sMAPE is:16.28% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.06% & 1.05\n",
      "for 2019-10-13, MAE is:3.10 & sMAPE is:8.73% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.03% & 1.05\n",
      "for 2019-10-14, MAE is:8.98 & sMAPE is:18.07% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.03% & 1.05\n",
      "for 2019-10-15, MAE is:6.19 & sMAPE is:12.41% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 17.02% & 1.05\n",
      "for 2019-10-16, MAE is:4.02 & sMAPE is:8.75% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.99% & 1.05\n",
      "for 2019-10-17, MAE is:12.27 & sMAPE is:22.93% & rMAE is:3.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 17.01% & 1.06\n",
      "for 2019-10-18, MAE is:13.70 & sMAPE is:25.46% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.04% & 1.06\n",
      "for 2019-10-19, MAE is:2.91 & sMAPE is:7.43% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.00% & 1.06\n",
      "for 2019-10-20, MAE is:5.82 & sMAPE is:15.41% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 17.00% & 1.06\n",
      "for 2019-10-21, MAE is:9.36 & sMAPE is:18.04% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 17.00% & 1.07\n",
      "for 2019-10-22, MAE is:5.50 & sMAPE is:17.45% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 17.00% & 1.06\n",
      "for 2019-10-23, MAE is:18.07 & sMAPE is:44.63% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.10% & 1.07\n",
      "for 2019-10-24, MAE is:8.02 & sMAPE is:16.52% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 17.09% & 1.07\n",
      "for 2019-10-25, MAE is:5.97 & sMAPE is:15.29% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.09% & 1.07\n",
      "for 2019-10-26, MAE is:6.18 & sMAPE is:24.30% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.11% & 1.07\n",
      "for 2019-10-27, MAE is:3.18 & sMAPE is:8.95% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.08% & 1.06\n",
      "for 2019-10-28, MAE is:7.65 & sMAPE is:14.97% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.08% & 1.07\n",
      "for 2019-10-29, MAE is:3.35 & sMAPE is:6.89% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.04% & 1.07\n",
      "for 2019-10-30, MAE is:8.03 & sMAPE is:15.87% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 17.04% & 1.07\n",
      "for 2019-10-31, MAE is:5.59 & sMAPE is:12.05% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.02% & 1.07\n",
      "for 2019-11-01, MAE is:6.47 & sMAPE is:14.14% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 17.01% & 1.07\n",
      "for 2019-11-02, MAE is:2.69 & sMAPE is:7.70% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.98% & 1.06\n",
      "for 2019-11-03, MAE is:2.80 & sMAPE is:7.48% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.95% & 1.07\n",
      "for 2019-11-04, MAE is:2.88 & sMAPE is:6.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.92% & 1.07\n",
      "for 2019-11-05, MAE is:7.81 & sMAPE is:14.74% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.91% & 1.07\n",
      "for 2019-11-06, MAE is:9.44 & sMAPE is:16.00% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.91% & 1.07\n",
      "for 2019-11-07, MAE is:7.93 & sMAPE is:13.99% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 16.90% & 1.07\n",
      "for 2019-11-08, MAE is:10.24 & sMAPE is:17.67% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 16.90% & 1.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-09, MAE is:1.57 & sMAPE is:3.75% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 16.86% & 1.07\n",
      "for 2019-11-10, MAE is:4.01 & sMAPE is:9.77% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.84% & 1.06\n",
      "for 2019-11-11, MAE is:6.49 & sMAPE is:12.60% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.82% & 1.06\n",
      "for 2019-11-12, MAE is:6.13 & sMAPE is:12.62% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.81% & 1.07\n",
      "for 2019-11-13, MAE is:5.55 & sMAPE is:11.32% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.79% & 1.06\n",
      "for 2019-11-14, MAE is:4.18 & sMAPE is:8.66% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.77% & 1.06\n",
      "for 2019-11-15, MAE is:6.29 & sMAPE is:12.98% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 16.76% & 1.06\n",
      "for 2019-11-16, MAE is:5.01 & sMAPE is:11.08% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 16.74% & 1.06\n",
      "for 2019-11-17, MAE is:1.56 & sMAPE is:3.98% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.70% & 1.06\n",
      "for 2019-11-18, MAE is:8.21 & sMAPE is:15.46% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 16.69% & 1.06\n",
      "for 2019-11-19, MAE is:3.48 & sMAPE is:7.93% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.67% & 1.06\n",
      "for 2019-11-20, MAE is:5.69 & sMAPE is:12.11% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.65% & 1.06\n",
      "for 2019-11-21, MAE is:3.94 & sMAPE is:8.53% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 16.63% & 1.06\n",
      "for 2019-11-22, MAE is:3.81 & sMAPE is:8.72% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 16.60% & 1.06\n",
      "for 2019-11-23, MAE is:0.96 & sMAPE is:2.48% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 16.56% & 1.06\n",
      "for 2019-11-24, MAE is:1.39 & sMAPE is:3.64% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.52% & 1.06\n",
      "for 2019-11-25, MAE is:4.76 & sMAPE is:9.79% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 16.50% & 1.06\n",
      "for 2019-11-26, MAE is:11.76 & sMAPE is:19.68% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 16.51% & 1.06\n",
      "for 2019-11-27, MAE is:11.74 & sMAPE is:20.47% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.52% & 1.06\n",
      "for 2019-11-28, MAE is:6.08 & sMAPE is:12.99% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.51% & 1.07\n",
      "for 2019-11-29, MAE is:5.47 & sMAPE is:12.19% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 16.50% & 1.07\n",
      "for 2019-11-30, MAE is:1.15 & sMAPE is:2.83% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 16.46% & 1.07\n",
      "for 2019-12-01, MAE is:1.79 & sMAPE is:4.45% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 16.42% & 1.07\n",
      "for 2019-12-02, MAE is:4.37 & sMAPE is:9.03% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.40% & 1.07\n",
      "for 2019-12-03, MAE is:7.36 & sMAPE is:14.16% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 16.39% & 1.07\n",
      "for 2019-12-04, MAE is:2.70 & sMAPE is:6.27% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.36% & 1.06\n",
      "for 2019-12-05, MAE is:3.41 & sMAPE is:8.93% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.34% & 1.06\n",
      "for 2019-12-06, MAE is:9.73 & sMAPE is:26.23% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.37% & 1.06\n",
      "for 2019-12-07, MAE is:2.15 & sMAPE is:6.90% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.34% & 1.06\n",
      "for 2019-12-08, MAE is:3.57 & sMAPE is:14.26% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.34% & 1.06\n",
      "for 2019-12-09, MAE is:9.14 & sMAPE is:42.66% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.41% & 1.06\n",
      "for 2019-12-10, MAE is:6.84 & sMAPE is:14.57% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.41% & 1.06\n",
      "for 2019-12-11, MAE is:7.45 & sMAPE is:27.58% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.44% & 1.06\n",
      "for 2019-12-12, MAE is:5.64 & sMAPE is:13.32% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.43% & 1.06\n",
      "for 2019-12-13, MAE is:4.96 & sMAPE is:11.61% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.42% & 1.06\n",
      "for 2019-12-14, MAE is:1.73 & sMAPE is:5.00% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 16.38% & 1.06\n",
      "for 2019-12-15, MAE is:4.16 & sMAPE is:13.33% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.38% & 1.06\n",
      "for 2019-12-16, MAE is:8.14 & sMAPE is:16.74% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.38% & 1.06\n",
      "for 2019-12-17, MAE is:6.79 & sMAPE is:14.15% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.37% & 1.06\n",
      "for 2019-12-18, MAE is:6.26 & sMAPE is:13.48% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.36% & 1.06\n",
      "for 2019-12-19, MAE is:6.98 & sMAPE is:15.13% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.36% & 1.06\n",
      "for 2019-12-20, MAE is:4.61 & sMAPE is:10.89% & rMAE is:3.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.34% & 1.07\n",
      "for 2019-12-21, MAE is:1.49 & sMAPE is:4.44% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 16.31% & 1.07\n",
      "for 2019-12-22, MAE is:1.45 & sMAPE is:3.96% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.28% & 1.06\n",
      "for 2019-12-23, MAE is:5.44 & sMAPE is:13.22% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 16.27% & 1.06\n",
      "for 2019-12-24, MAE is:3.23 & sMAPE is:8.64% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.25% & 1.06\n",
      "for 2019-12-25, MAE is:2.13 & sMAPE is:6.10% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 16.22% & 1.06\n",
      "for 2019-12-26, MAE is:3.59 & sMAPE is:10.40% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 16.20% & 1.06\n",
      "for 2019-12-27, MAE is:5.17 & sMAPE is:12.32% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.19% & 1.06\n",
      "for 2019-12-28, MAE is:4.53 & sMAPE is:12.36% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 16.18% & 1.07\n",
      "for 2019-12-29, MAE is:3.15 & sMAPE is:11.39% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.17% & 1.06\n",
      "for 2019-12-30, MAE is:5.13 & sMAPE is:29.70% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.20% & 1.06\n",
      "for 2019-12-31, MAE is:5.55 & sMAPE is:22.83% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.22% & 1.06\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 11:53:55,857]\u001b[0m A new study created in RDB with name: FI_2020\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:54:07,176]\u001b[0m Trial 0 finished with value: 7.697868640791327 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631298459593683, 'dropout_rate_Layer_2': 0.37217768275567337, 'dropout_rate_Layer_3': 0.23356429238410611, 'dropout_rate_Layer_4': 0.2895177235751562, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012792200211888852, 'l1_Layer_2': 0.012110013329057133, 'l1_Layer_3': 0.0032357461094841447, 'l1_Layer_4': 2.5278958822460455e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 195, 'n_units_Layer_4': 195}. Best is trial 0 with value: 7.697868640791327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.70 | sMAPE for Validation Set is: 19.00% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 15.40 | sMAPE for Test Set is: 59.84% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 11:54:36,389]\u001b[0m Trial 1 finished with value: 8.25926120449933 and parameters: {'n_hidden': 4, 'learning_rate': 0.06565668274609418, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04935183554893055, 'dropout_rate_Layer_2': 0.3489223544960258, 'dropout_rate_Layer_3': 0.3973398508480647, 'dropout_rate_Layer_4': 0.35895232416739825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.721154410662058e-05, 'l1_Layer_2': 0.011397007896641838, 'l1_Layer_3': 1.1482993363518403e-05, 'l1_Layer_4': 0.034348763313160335, 'n_units_Layer_1': 75, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270, 'n_units_Layer_4': 55}. Best is trial 0 with value: 7.697868640791327.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.26 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 13.03 | sMAPE for Test Set is: 54.32% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 11:54:41,906]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:56:34,794]\u001b[0m Trial 3 finished with value: 5.791594736092139 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007149284812719697, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12608447112948556, 'dropout_rate_Layer_2': 0.3696527011867759, 'dropout_rate_Layer_3': 0.07280864135905066, 'dropout_rate_Layer_4': 0.11190531815242527, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 8.264392365524795e-05, 'l1_Layer_2': 1.9345671280203125e-05, 'l1_Layer_3': 0.0007290800848895018, 'l1_Layer_4': 0.0009435505099533775, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 3 with value: 5.791594736092139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 14.87% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.60 | sMAPE for Test Set is: 50.34% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 11:56:42,576]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:56:45,411]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:57:25,076]\u001b[0m Trial 6 finished with value: 6.902488962161033 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018587276846634376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13438212346518613, 'dropout_rate_Layer_2': 0.34303608373935657, 'dropout_rate_Layer_3': 0.2869303017026118, 'dropout_rate_Layer_4': 0.07404787993368181, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032985313997028823, 'l1_Layer_2': 0.0006837745913772087, 'l1_Layer_3': 0.019025392329337712, 'l1_Layer_4': 3.733517467726048e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145, 'n_units_Layer_4': 60}. Best is trial 3 with value: 5.791594736092139.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 17.18% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 13.71 | sMAPE for Test Set is: 55.88% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 11:57:29,755]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:58:39,481]\u001b[0m Trial 8 finished with value: 5.605842551261575 and parameters: {'n_hidden': 4, 'learning_rate': 0.004173660796937017, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12502254715619876, 'dropout_rate_Layer_2': 0.3507047191569168, 'dropout_rate_Layer_3': 0.0742395847728644, 'dropout_rate_Layer_4': 0.1555727965869839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004149825295680265, 'l1_Layer_2': 5.7743772398847734e-05, 'l1_Layer_3': 0.000124010863661017, 'l1_Layer_4': 0.00027108563561846754, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 50.64% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 11:58:42,988]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:58:47,695]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:58:51,049]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:58:53,707]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:58:57,406]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:01,920]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:05,467]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:08,588]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:12,035]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:28,682]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:36,158]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:39,953]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:46,213]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:49,724]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 11:59:53,509]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:00:08,466]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:00:25,198]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:00:28,416]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:00:33,414]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:00:55,823]\u001b[0m Trial 28 finished with value: 7.3772912113892986 and parameters: {'n_hidden': 4, 'learning_rate': 0.029019516749402507, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15784971460777475, 'dropout_rate_Layer_2': 0.2526607747721198, 'dropout_rate_Layer_3': 0.3124996773625499, 'dropout_rate_Layer_4': 0.022428932327073173, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007011252782922107, 'l1_Layer_2': 0.0001393769705492429, 'l1_Layer_3': 0.0031945604910743027, 'l1_Layer_4': 0.002930452749697101, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50, 'n_units_Layer_4': 140}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 18.38% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 14.03 | sMAPE for Test Set is: 56.71% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:01:01,572]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:06,431]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:12,352]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:18,848]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:28,458]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:34,364]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:38,276]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:41,095]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:45,733]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:51,318]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:01:55,475]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:02:06,107]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:02:45,073]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:02:51,639]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:03,793]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:08,857]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:16,157]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:29,493]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:03:45,800]\u001b[0m Trial 47 finished with value: 6.657548104460235 and parameters: {'n_hidden': 4, 'learning_rate': 0.0074273722483823145, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11779252108909413, 'dropout_rate_Layer_2': 0.04017260546293327, 'dropout_rate_Layer_3': 0.23358613957734256, 'dropout_rate_Layer_4': 0.07096542962104198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0047358105669837135, 'l1_Layer_2': 0.00032114525864295363, 'l1_Layer_3': 0.024745105946765298, 'l1_Layer_4': 0.0006681638321674815, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295, 'n_units_Layer_4': 180}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 16.70% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 13.55 | sMAPE for Test Set is: 55.41% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:04:02,847]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:06,552]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:10,126]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:14,638]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:19,225]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:25,734]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:36,312]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:40,496]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:45,505]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:48,912]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:53,412]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:04:59,156]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:05:39,032]\u001b[0m Trial 60 finished with value: 7.110834808837992 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045129070142594764, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1952513755654459, 'dropout_rate_Layer_2': 0.3563976622885555, 'dropout_rate_Layer_3': 0.26956839011363903, 'dropout_rate_Layer_4': 0.055007408345232725, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004471902039770953, 'l1_Layer_2': 0.030775556781424573, 'l1_Layer_3': 0.024236499277276728, 'l1_Layer_4': 0.006807156320961155, 'n_units_Layer_1': 65, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150, 'n_units_Layer_4': 195}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 17.63% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 14.61 | sMAPE for Test Set is: 58.07% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:06:34,929]\u001b[0m Trial 61 finished with value: 7.099683289732127 and parameters: {'n_hidden': 4, 'learning_rate': 0.00275043037861949, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20084348515599182, 'dropout_rate_Layer_2': 0.31824584860995797, 'dropout_rate_Layer_3': 0.2168817766801419, 'dropout_rate_Layer_4': 0.05750705228410681, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005102423553962484, 'l1_Layer_2': 0.026752993953956097, 'l1_Layer_3': 0.02357762100365578, 'l1_Layer_4': 0.015135440616232253, 'n_units_Layer_1': 90, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160, 'n_units_Layer_4': 195}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 57.54% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:06:45,811]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:06:51,629]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:06:56,524]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:02,556]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:13,018]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:38,677]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:42,584]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:07:46,421]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:39,198]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:08:42,437]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:09:06,484]\u001b[0m Trial 72 finished with value: 6.807743568740079 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024696186431054316, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21759803689656892, 'dropout_rate_Layer_2': 0.08214503892600132, 'dropout_rate_Layer_3': 0.27474004070377034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0038378875937989053, 'l1_Layer_2': 0.00019278134234993903, 'l1_Layer_3': 0.024090718190112655, 'n_units_Layer_1': 195, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 13.91 | sMAPE for Test Set is: 56.36% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:09:14,692]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:23,760]\u001b[0m Trial 74 finished with value: 6.529415614049973 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016188432781604712, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2373086255988658, 'dropout_rate_Layer_2': 0.3802072790214623, 'dropout_rate_Layer_3': 0.215973342715516, 'dropout_rate_Layer_4': 0.13182206332989935, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.014296022155760583, 'l1_Layer_2': 0.008557170575668353, 'l1_Layer_3': 0.00013656933160956897, 'l1_Layer_4': 4.154039389616468e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80, 'n_units_Layer_4': 140}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 16.62% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.65 | sMAPE for Test Set is: 53.16% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:10:30,824]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:38,575]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:44,294]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:48,367]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:10:55,606]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:11:08,096]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:01,851]\u001b[0m Trial 81 finished with value: 7.198110324825879 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036607393224410366, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21145296797829152, 'dropout_rate_Layer_2': 0.36924746970810607, 'dropout_rate_Layer_3': 0.29962063602834466, 'dropout_rate_Layer_4': 0.07498851512216478, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005668005221276318, 'l1_Layer_2': 0.031796164505782536, 'l1_Layer_3': 0.009980903615045937, 'l1_Layer_4': 0.014124314622212676, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 120, 'n_units_Layer_4': 170}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 57.76% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:12:12,248]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:17,447]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:23,543]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:12:28,175]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:07,721]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:13,634]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:17,862]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:22,616]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:13:58,434]\u001b[0m Trial 90 finished with value: 6.603189276254821 and parameters: {'n_hidden': 4, 'learning_rate': 0.0045872146930430345, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1933475215197836, 'dropout_rate_Layer_2': 0.3965410660522955, 'dropout_rate_Layer_3': 0.3617288156318581, 'dropout_rate_Layer_4': 0.08065702229418281, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0059862348696275115, 'l1_Layer_2': 6.468547928123686e-05, 'l1_Layer_3': 0.0023386064143079755, 'l1_Layer_4': 0.0011924075333652724, 'n_units_Layer_1': 170, 'n_units_Layer_2': 50, 'n_units_Layer_3': 60, 'n_units_Layer_4': 155}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 13.04 | sMAPE for Test Set is: 54.19% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:14:07,349]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:21,739]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:25,281]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:29,210]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:33,799]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:39,238]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:14:44,844]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:20,549]\u001b[0m Trial 98 finished with value: 5.814148938844546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017976781100972007, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24883718296464666, 'dropout_rate_Layer_2': 0.3934698252798002, 'dropout_rate_Layer_3': 0.35347838897808936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005464111107306174, 'l1_Layer_2': 3.698813652496629e-05, 'l1_Layer_3': 0.0003907376572529464, 'n_units_Layer_1': 160, 'n_units_Layer_2': 230, 'n_units_Layer_3': 90}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 14.80% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.43 | sMAPE for Test Set is: 40.82% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:15:24,481]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:28,374]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:33,204]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:15:39,102]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:16:57,111]\u001b[0m Trial 103 finished with value: 5.676372559800939 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006255240478769322, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28024741086012467, 'dropout_rate_Layer_2': 0.32757388667081966, 'dropout_rate_Layer_3': 0.35928166438121006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013050515058776358, 'l1_Layer_2': 4.229425980985433e-05, 'l1_Layer_3': 0.00022999266841829913, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 80}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 14.55% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.27 | sMAPE for Test Set is: 40.61% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:17:01,336]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:39,791]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:44,545]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:48,093]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:54,050]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:17:58,566]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:07,360]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:17,015]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:18:52,836]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:03,558]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:19,558]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:23,695]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:28,320]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:31,731]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:44,103]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:19:50,083]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:01,760]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:12,030]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:20:19,314]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:33,589]\u001b[0m Trial 123 finished with value: 7.206890471900643 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034585538693111604, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16554627968896202, 'dropout_rate_Layer_2': 0.37721540626467837, 'dropout_rate_Layer_3': 0.2779296595917101, 'dropout_rate_Layer_4': 0.06387842695316032, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003157988179002021, 'l1_Layer_2': 0.08898553308455767, 'l1_Layer_3': 0.01693655239986885, 'l1_Layer_4': 0.0031289333028218453, 'n_units_Layer_1': 55, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160, 'n_units_Layer_4': 180}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.76% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 57.01% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:21:37,334]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:41,524]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:21:50,203]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:08,191]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:21,026]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:25,429]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:30,404]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:22:34,657]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:30,299]\u001b[0m Trial 132 finished with value: 6.771631355871702 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023991342532480252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17951418637015534, 'dropout_rate_Layer_2': 0.3359657990294555, 'dropout_rate_Layer_3': 0.2600995042334444, 'dropout_rate_Layer_4': 0.04844343428897984, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001342529821768719, 'l1_Layer_2': 0.07577788981910646, 'l1_Layer_3': 0.02360426194815182, 'l1_Layer_4': 4.607054691883073e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 245, 'n_units_Layer_3': 105, 'n_units_Layer_4': 120}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 16.83% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 13.15 | sMAPE for Test Set is: 54.58% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:23:36,200]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:23:52,178]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:24:26,031]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:16,468]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:20,848]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:37,134]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:25:42,726]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:26:32,618]\u001b[0m Trial 140 finished with value: 6.789860022827234 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029088261704570658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17818476330935615, 'dropout_rate_Layer_2': 0.3161061175001525, 'dropout_rate_Layer_3': 0.2542220280881718, 'dropout_rate_Layer_4': 0.07835736621361762, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020043750053197647, 'l1_Layer_2': 0.030467487856147595, 'l1_Layer_3': 0.025531530793602493, 'l1_Layer_4': 8.29285851869605e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85, 'n_units_Layer_4': 190}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 13.94 | sMAPE for Test Set is: 56.52% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:26:42,801]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:29:54,200]\u001b[0m Trial 142 finished with value: 6.810137061193669 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016996385021408964, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1907153503439748, 'dropout_rate_Layer_2': 0.34763908254264975, 'dropout_rate_Layer_3': 0.25980957807914856, 'dropout_rate_Layer_4': 0.10010236515662027, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023563174977920148, 'l1_Layer_2': 0.021623521747710088, 'l1_Layer_3': 0.03802808278867304, 'l1_Layer_4': 7.57064585226423e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130, 'n_units_Layer_4': 190}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 13.84 | sMAPE for Test Set is: 56.30% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:32:40,075]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:32:44,439]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:32:50,345]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:32:55,810]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:33:01,868]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:34:49,507]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:34:57,653]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:33,356]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:38,532]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:44,070]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:47,954]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:54,206]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:35:58,672]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:36:09,032]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:25,360]\u001b[0m Trial 157 finished with value: 5.97599442397638 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009188151048842981, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0171012959310936, 'dropout_rate_Layer_2': 0.39979998813855844, 'dropout_rate_Layer_3': 0.0003485931251694654, 'dropout_rate_Layer_4': 0.2973213763682097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00041019791983053065, 'l1_Layer_2': 0.00027276536446034613, 'l1_Layer_3': 0.00021251075245918026, 'l1_Layer_4': 1.1401171377307085e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50, 'n_units_Layer_4': 145}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 15.18% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 12.04 | sMAPE for Test Set is: 51.37% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:38:30,733]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:36,761]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:42,282]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:47,902]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:53,487]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:38:57,795]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:08,418]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:12,998]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:36,115]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:41,990]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:49,922]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:39:53,525]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:40:51,065]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:40:58,852]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:03,597]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:09,723]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:15,144]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:19,026]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:41:22,689]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:42:18,461]\u001b[0m Trial 177 finished with value: 5.874874983730707 and parameters: {'n_hidden': 4, 'learning_rate': 0.007104368165848743, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08144612591949851, 'dropout_rate_Layer_2': 0.33489256400816003, 'dropout_rate_Layer_3': 0.07021361806831719, 'dropout_rate_Layer_4': 0.34900253686150484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007948777304351413, 'l1_Layer_2': 1.152482948987314e-05, 'l1_Layer_3': 0.00012653350579365085, 'l1_Layer_4': 1.625858805639147e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50, 'n_units_Layer_4': 215}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 14.89% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.41 | sMAPE for Test Set is: 52.49% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:42:22,776]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:42:27,427]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:42:30,884]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:42:34,784]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:42:43,337]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:43:21,812]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:15,430]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:19,845]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:26,180]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:31,688]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:35,387]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:45:59,570]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:10,399]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:15,363]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:21,136]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:29,084]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:34,796]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:40,923]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:45,711]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:50,786]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:46:56,388]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 57.77% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:48:13,295]\u001b[0m Trial 199 finished with value: 6.853556336273251 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020320999520810224, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1862490660649108, 'dropout_rate_Layer_2': 0.31742369478120386, 'dropout_rate_Layer_3': 0.25400153800064196, 'dropout_rate_Layer_4': 0.10555047129973971, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002736964620863098, 'l1_Layer_2': 0.05974512018814129, 'l1_Layer_3': 0.0536374168644243, 'l1_Layer_4': 4.258921486649476e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 130, 'n_units_Layer_4': 215}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:16,620]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:24,846]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:30,913]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:35,450]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:40,479]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:52,516]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:48:57,725]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:05,502]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:08,908]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:17,220]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:25,461]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:49:44,986]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:09,579]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:25,052]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:32,078]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:47,766]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:50:56,680]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:07,380]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:13,241]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:19,474]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:24,706]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:30,079]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:36,459]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:51:57,011]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:52:00,841]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:19,683]\u001b[0m Trial 225 finished with value: 5.923313769423984 and parameters: {'n_hidden': 4, 'learning_rate': 0.001735880904191962, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1794227385678519, 'dropout_rate_Layer_2': 0.3104939646776825, 'dropout_rate_Layer_3': 0.03281447851247681, 'dropout_rate_Layer_4': 0.1256184395819526, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02310376772886496, 'l1_Layer_2': 0.00014327198801962146, 'l1_Layer_3': 0.00015112288757853306, 'l1_Layer_4': 0.0006207926120084398, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55, 'n_units_Layer_4': 135}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 50.75% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:53:24,833]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:30,812]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:38,563]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:53:42,971]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:05,225]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:15,148]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:21,272]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:25,858]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:31,506]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:39,806]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:54:44,324]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:55:49,414]\u001b[0m Trial 237 finished with value: 5.758739379131595 and parameters: {'n_hidden': 4, 'learning_rate': 0.001779549648399498, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18992400990656783, 'dropout_rate_Layer_2': 0.3266773120189041, 'dropout_rate_Layer_3': 0.03389168889505061, 'dropout_rate_Layer_4': 0.11831539267388286, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00557892114520386, 'l1_Layer_2': 0.00013788051840214318, 'l1_Layer_3': 0.00031352914759343845, 'l1_Layer_4': 0.0005393577197242929, 'n_units_Layer_1': 200, 'n_units_Layer_2': 145, 'n_units_Layer_3': 50, 'n_units_Layer_4': 145}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.95 | sMAPE for Test Set is: 51.40% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 12:55:53,866]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:24,545]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:30,756]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:38,633]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:46,327]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:51,215]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:55,874]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:56:59,840]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:04,909]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:09,423]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:15,522]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:21,169]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:34,918]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:39,782]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:43,590]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:49,092]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:57:53,249]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:32,037]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:37,199]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:52,892]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:58:58,250]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:01,600]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:10,954]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 12:59:29,538]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:01,441]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:09,068]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:13,891]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:17,412]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:24,213]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:30,068]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:37,173]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:43,184]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:50,640]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:00:56,329]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:04,806]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:18,158]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:01:34,551]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:02:41,400]\u001b[0m Trial 275 finished with value: 6.9119069445555015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019878726992796068, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17378714544657428, 'dropout_rate_Layer_2': 0.29119320035041174, 'dropout_rate_Layer_3': 0.2651229709687234, 'dropout_rate_Layer_4': 0.06350594586949626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0028851870182313322, 'l1_Layer_2': 0.0670984715274157, 'l1_Layer_3': 0.06665664860746179, 'l1_Layer_4': 4.966759831201357e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120, 'n_units_Layer_4': 200}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 15.37 | sMAPE for Test Set is: 59.80% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:02:52,897]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:00,000]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:08,887]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:13,471]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:18,838]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:23,261]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:03:26,735]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:04:54,734]\u001b[0m Trial 283 finished with value: 5.748026217481943 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011817896839141067, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034696467442219436, 'dropout_rate_Layer_2': 0.36436167481013965, 'dropout_rate_Layer_3': 0.0059107167999510905, 'dropout_rate_Layer_4': 0.3266122456237239, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00052863295691, 'l1_Layer_2': 0.0001310097417846341, 'l1_Layer_3': 0.00021572744140571586, 'l1_Layer_4': 1.4393973067811851e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 50, 'n_units_Layer_4': 165}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 49.71% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:05:00,933]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:05,871]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:11,806]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:25,320]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:40,063]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:44,350]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:05:50,073]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:11,868]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:17,461]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:22,884]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:34,277]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:39,878]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:45,656]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:50,534]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:06:55,466]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:00,725]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:05,407]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:11,102]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:07:16,941]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:08:23,235]\u001b[0m Trial 303 finished with value: 5.74841628983922 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011300560286184942, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05182731600431878, 'dropout_rate_Layer_2': 0.3565642068923696, 'dropout_rate_Layer_3': 0.04426096112632465, 'dropout_rate_Layer_4': 0.3401331579060048, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008303463056591202, 'l1_Layer_2': 0.00012095068098191928, 'l1_Layer_3': 0.00011599949651497403, 'l1_Layer_4': 1.0940373270140637e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 120, 'n_units_Layer_4': 175}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 14.74% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 49.27% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:08:52,432]\u001b[0m Trial 304 finished with value: 6.263693430292762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016193832886969121, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2689960314129893, 'dropout_rate_Layer_2': 0.36294093879507605, 'dropout_rate_Layer_3': 0.36478484091864705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005635404388948383, 'l1_Layer_2': 5.368430596259179e-05, 'l1_Layer_3': 0.00025469265359124725, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 8 with value: 5.605842551261575.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 15.65% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 44.74% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:09:01,204]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:09:06,320]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:09:12,702]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:10:55,330]\u001b[0m Trial 308 finished with value: 5.5141214875358004 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010916337702845534, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04207548369466236, 'dropout_rate_Layer_2': 0.36586045035271875, 'dropout_rate_Layer_3': 0.022257573631735854, 'dropout_rate_Layer_4': 0.22675215604611926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019180904986114243, 'l1_Layer_2': 9.895693740620723e-05, 'l1_Layer_3': 0.0004161114209393119, 'l1_Layer_4': 3.6110195018149936e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125, 'n_units_Layer_4': 170}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.27 | sMAPE for Test Set is: 49.14% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:11:00,624]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:11:05,332]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:11:13,547]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:11:38,780]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:11:44,122]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:11:50,821]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:11:56,147]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:23,486]\u001b[0m Trial 316 finished with value: 5.55111072798237 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005387643181136887, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04292297636016594, 'dropout_rate_Layer_2': 0.3646552166813491, 'dropout_rate_Layer_3': 0.04048193229579964, 'dropout_rate_Layer_4': 0.21156664560596494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015165583075475614, 'l1_Layer_2': 0.0005800123701569574, 'l1_Layer_3': 0.0006625008704753044, 'l1_Layer_4': 0.00012648768742282225, 'n_units_Layer_1': 80, 'n_units_Layer_2': 225, 'n_units_Layer_3': 120, 'n_units_Layer_4': 145}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 14.16% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 46.40% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:13:31,616]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:37,204]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:13:42,861]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:04,089]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:11,875]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:18,927]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:23,596]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:27,864]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:14:35,837]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:15:48,264]\u001b[0m Trial 326 finished with value: 5.737162917697009 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009610094070095636, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22472090196059005, 'dropout_rate_Layer_2': 0.3659277895063098, 'dropout_rate_Layer_3': 0.31428012994323246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008651132998214897, 'l1_Layer_2': 9.312560745850624e-05, 'l1_Layer_3': 1.1902579248536624e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 110}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 14.57% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.39 | sMAPE for Test Set is: 40.83% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:16:46,680]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:27,739]\u001b[0m Trial 328 finished with value: 5.732370836259712 and parameters: {'n_hidden': 3, 'learning_rate': 0.002641300305815235, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15969541013994853, 'dropout_rate_Layer_2': 0.29004610177523393, 'dropout_rate_Layer_3': 0.12512416773635737, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006209875406726724, 'l1_Layer_2': 3.445946377650499e-05, 'l1_Layer_3': 0.0001661093156132212, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 50.15% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:17:36,448]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:17:43,685]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:18:02,015]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:18:07,108]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:19:07,261]\u001b[0m Trial 333 finished with value: 5.864517128942622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009089511951658676, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15118459321141106, 'dropout_rate_Layer_2': 0.2891973114281971, 'dropout_rate_Layer_3': 0.1230974486419014, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011330276907640895, 'l1_Layer_2': 3.802167381509026e-05, 'l1_Layer_3': 0.00017490136407682876, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 14.88% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 48.48% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:19:31,675]\u001b[0m Trial 334 finished with value: 7.207806054307098 and parameters: {'n_hidden': 4, 'learning_rate': 0.01295511893035413, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09729904773879021, 'dropout_rate_Layer_2': 0.3450418299488889, 'dropout_rate_Layer_3': 0.2870123697728218, 'dropout_rate_Layer_4': 0.019503863023208293, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026883062806879092, 'l1_Layer_2': 0.0621583309079012, 'l1_Layer_3': 0.049615339919530134, 'l1_Layer_4': 0.006583209498625585, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 125, 'n_units_Layer_4': 190}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 17.97% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 15.17 | sMAPE for Test Set is: 59.25% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:20:32,903]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:20:37,816]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:21:14,846]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:00,887]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:09,368]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:22,414]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:23:27,137]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:24:14,782]\u001b[0m Trial 342 finished with value: 5.535710752254537 and parameters: {'n_hidden': 4, 'learning_rate': 0.001361977853218003, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10088081716650393, 'dropout_rate_Layer_2': 0.23138575448928778, 'dropout_rate_Layer_3': 0.03968795197473602, 'dropout_rate_Layer_4': 0.22252243595981838, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00028890334394250216, 'l1_Layer_2': 6.962658764519242e-05, 'l1_Layer_3': 3.281574419046346e-05, 'l1_Layer_4': 0.00010632498316284452, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145, 'n_units_Layer_4': 200}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.49% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:24:19,852]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:04,475]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:25,825]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:31,961]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:36,160]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:25:41,654]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:20,418]\u001b[0m Trial 349 finished with value: 5.670362655383915 and parameters: {'n_hidden': 4, 'learning_rate': 0.001511863786819192, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04003433562961996, 'dropout_rate_Layer_2': 0.22820871007785004, 'dropout_rate_Layer_3': 0.03705351792027819, 'dropout_rate_Layer_4': 0.2334350120370059, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002609478068544751, 'l1_Layer_2': 0.0010454458566396025, 'l1_Layer_3': 2.844600410455654e-05, 'l1_Layer_4': 8.091403100901078e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 275, 'n_units_Layer_3': 110, 'n_units_Layer_4': 195}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 50.10% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:26:25,842]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:29,500]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:26:58,896]\u001b[0m Trial 352 finished with value: 6.000692501609774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016279568343696806, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13658938998244907, 'dropout_rate_Layer_2': 0.3805523983372569, 'dropout_rate_Layer_3': 0.07760746561364895, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014607378054938827, 'l1_Layer_2': 5.79962433872995e-05, 'l1_Layer_3': 6.703756576873374e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 15.13% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 50.28% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:27:07,807]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:29:29,402]\u001b[0m Trial 354 finished with value: 5.872070499443254 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008042437410480831, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.098801890406873, 'dropout_rate_Layer_2': 0.20570974877138865, 'dropout_rate_Layer_3': 0.09621638437374411, 'dropout_rate_Layer_4': 0.2186751954017218, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.188514919312202e-05, 'l1_Layer_2': 9.363472435844889e-05, 'l1_Layer_3': 3.610509788198223e-05, 'l1_Layer_4': 3.1734675663767934e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 255, 'n_units_Layer_3': 140, 'n_units_Layer_4': 205}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 14.95% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.85 | sMAPE for Test Set is: 51.08% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:29:38,811]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:29:43,516]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:29:51,049]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:29:54,775]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:09,909]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:18,488]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:22,019]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:31,343]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:35,427]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:39,694]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:45,289]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:50,082]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:30:56,930]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:31:51,419]\u001b[0m Trial 368 finished with value: 5.875804845003664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019839855486609988, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09596665575969908, 'dropout_rate_Layer_2': 0.3337150993612607, 'dropout_rate_Layer_3': 0.045170117129596274, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009034410727263622, 'l1_Layer_2': 2.4613832059383426e-05, 'l1_Layer_3': 0.0001858289175700455, 'n_units_Layer_1': 300, 'n_units_Layer_2': 165, 'n_units_Layer_3': 165}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 14.86% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 11.78 | sMAPE for Test Set is: 50.75% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:31:55,949]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:13,192]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:17,179]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:22,892]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:28,969]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:35,816]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:39,436]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:32:43,795]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:07,591]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:17,391]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:39,513]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:49,531]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:33:54,796]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:34:01,096]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:34:06,933]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:34:12,544]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:34:50,866]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:35:30,159]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:37:03,701]\u001b[0m Trial 387 finished with value: 6.600306011649262 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019748938949302364, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14475644363085208, 'dropout_rate_Layer_2': 0.285953056740503, 'dropout_rate_Layer_3': 0.2642817219484149, 'dropout_rate_Layer_4': 0.2937074957108781, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002619935109822151, 'l1_Layer_2': 0.00014782856243753282, 'l1_Layer_3': 0.00910296561247993, 'l1_Layer_4': 7.26493382266919e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295, 'n_units_Layer_4': 200}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.78 | sMAPE for Test Set is: 53.42% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:37:43,480]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:37:54,115]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:37:59,298]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:38:31,677]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:39:48,371]\u001b[0m Trial 392 finished with value: 6.7857884550361005 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020331775068662765, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1339532604371365, 'dropout_rate_Layer_2': 0.27329394076786306, 'dropout_rate_Layer_3': 0.26017285769812065, 'dropout_rate_Layer_4': 0.2709964088561214, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000255090399759606, 'l1_Layer_2': 0.0001586163792732851, 'l1_Layer_3': 0.007973164008640414, 'l1_Layer_4': 7.98574414325722e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300, 'n_units_Layer_4': 200}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 16.91% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 54.12% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:39:53,115]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:01,394]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:09,575]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:12,777]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:21,112]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:28,660]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:35,990]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:41,359]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:49,899]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:40:55,410]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:41:36,386]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:41:44,355]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:41:51,857]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:00,407]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:42,179]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:47,778]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:42:56,342]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:43:00,926]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:44:27,477]\u001b[0m Trial 411 finished with value: 6.808607889598089 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016178116011021813, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11126823618695006, 'dropout_rate_Layer_2': 0.2642391797865143, 'dropout_rate_Layer_3': 0.2615551602544527, 'dropout_rate_Layer_4': 0.25625942518616707, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00022424985642211133, 'l1_Layer_2': 0.00044932086480639963, 'l1_Layer_3': 0.007478353280456451, 'l1_Layer_4': 0.0001377818701424341, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295, 'n_units_Layer_4': 195}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 16.98% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 12.89 | sMAPE for Test Set is: 53.76% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:44:34,780]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:44:39,218]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:46:01,345]\u001b[0m Trial 414 finished with value: 5.640988149491991 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005220499699776813, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16251312327487086, 'dropout_rate_Layer_2': 0.27445751958238657, 'dropout_rate_Layer_3': 0.09292896360177548, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024400692322834538, 'l1_Layer_2': 3.767113264199487e-05, 'l1_Layer_3': 0.0001899077750396084, 'n_units_Layer_1': 290, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 14.39% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 48.11% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:46:58,075]\u001b[0m Trial 415 finished with value: 5.628980227671079 and parameters: {'n_hidden': 4, 'learning_rate': 0.003293926889822434, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08749419394427656, 'dropout_rate_Layer_2': 0.26280598873228417, 'dropout_rate_Layer_3': 0.022733647660892184, 'dropout_rate_Layer_4': 0.17503668441612566, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001854227871070842, 'l1_Layer_2': 4.8372903134943015e-05, 'l1_Layer_3': 5.937105008368323e-05, 'l1_Layer_4': 0.00011631640562742271, 'n_units_Layer_1': 90, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160, 'n_units_Layer_4': 165}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.63 | sMAPE for Validation Set is: 14.49% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.44 | sMAPE for Test Set is: 50.04% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:47:15,616]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:49:20,100]\u001b[0m Trial 417 finished with value: 6.713046258459323 and parameters: {'n_hidden': 4, 'learning_rate': 0.001662348654147875, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1056734504153336, 'dropout_rate_Layer_2': 0.2604604227925423, 'dropout_rate_Layer_3': 0.2588344503468968, 'dropout_rate_Layer_4': 0.2794128767760613, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002754737479519447, 'l1_Layer_2': 0.0003860781668557721, 'l1_Layer_3': 0.012553835357992243, 'l1_Layer_4': 0.00014427701548445066, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295, 'n_units_Layer_4': 190}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 16.83% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 13.02 | sMAPE for Test Set is: 54.18% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:49:25,615]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:49:41,380]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:50:03,253]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:51:03,888]\u001b[0m Trial 421 finished with value: 6.797100136444335 and parameters: {'n_hidden': 4, 'learning_rate': 0.0016716172462165552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09863284120081811, 'dropout_rate_Layer_2': 0.2992503829401631, 'dropout_rate_Layer_3': 0.25981945343328544, 'dropout_rate_Layer_4': 0.27868526328884724, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002918226340136347, 'l1_Layer_2': 0.00040932266981722355, 'l1_Layer_3': 0.013625175514391729, 'l1_Layer_4': 0.00011616688626875768, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285, 'n_units_Layer_4': 195}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 53.15% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:52:21,853]\u001b[0m Trial 422 finished with value: 6.71542198545218 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015549790893692192, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0926824752457941, 'dropout_rate_Layer_2': 0.2577332401062787, 'dropout_rate_Layer_3': 0.2575213084619591, 'dropout_rate_Layer_4': 0.2799027370622466, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002971308134950792, 'l1_Layer_2': 0.00032821310737545965, 'l1_Layer_3': 0.013410711246734408, 'l1_Layer_4': 0.00015205909234046637, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285, 'n_units_Layer_4': 190}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 12.60 | sMAPE for Test Set is: 52.90% | rMAE for Test Set is: 1.00\n",
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 13.18 | sMAPE for Test Set is: 54.57% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:53:10,751]\u001b[0m Trial 423 finished with value: 6.758703531100099 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015007756038440648, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10551158255491232, 'dropout_rate_Layer_2': 0.2597314963549627, 'dropout_rate_Layer_3': 0.2583639981297134, 'dropout_rate_Layer_4': 0.24459848815071455, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00029138152134398047, 'l1_Layer_2': 0.0003782401892876268, 'l1_Layer_3': 0.014551025075105252, 'l1_Layer_4': 0.00015846283407053866, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285, 'n_units_Layer_4': 185}. Best is trial 308 with value: 5.5141214875358004.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:54:35,737]\u001b[0m Trial 424 finished with value: 5.475190877337252 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007711405668512451, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17539471882030447, 'dropout_rate_Layer_2': 0.2875071005486155, 'dropout_rate_Layer_3': 0.09622559698165076, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025539869848190838, 'l1_Layer_2': 4.137405901051049e-05, 'l1_Layer_3': 0.00020463977891668493, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 205}. Best is trial 424 with value: 5.475190877337252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 47.43% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:54:43,201]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:55:23,778]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:56:13,712]\u001b[0m Trial 427 finished with value: 6.843711092387721 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014751747573191018, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1052730677926229, 'dropout_rate_Layer_2': 0.24725721423678265, 'dropout_rate_Layer_3': 0.2482472726901875, 'dropout_rate_Layer_4': 0.2412239832132838, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00022356738376135517, 'l1_Layer_2': 0.0003956274941413574, 'l1_Layer_3': 0.012660382453652344, 'l1_Layer_4': 0.0001520511713129424, 'n_units_Layer_1': 80, 'n_units_Layer_2': 275, 'n_units_Layer_3': 280, 'n_units_Layer_4': 190}. Best is trial 424 with value: 5.475190877337252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 17.08% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 13.33 | sMAPE for Test Set is: 54.90% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 13:56:53,349]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:57:35,625]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:57:51,074]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:58:27,429]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 13:58:44,664]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:00:42,198]\u001b[0m Trial 433 finished with value: 5.992169513951023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006966018013288144, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24552394290967755, 'dropout_rate_Layer_2': 0.3610046684251933, 'dropout_rate_Layer_3': 0.2851765206283937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008096606216211385, 'l1_Layer_2': 0.00011166479411046932, 'l1_Layer_3': 1.730634208097966e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 255, 'n_units_Layer_3': 105}. Best is trial 424 with value: 5.475190877337252.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 15.06% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 49.50% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:01:24,346]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:02:05,044]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:03:29,351]\u001b[0m Trial 436 finished with value: 5.472460231834284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007395248715442818, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1425733961285962, 'dropout_rate_Layer_2': 0.2922536273568739, 'dropout_rate_Layer_3': 0.09911311094973742, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023911475421350948, 'l1_Layer_2': 1.024897952980574e-05, 'l1_Layer_3': 0.0001884483249409814, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 225}. Best is trial 436 with value: 5.472460231834284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 48.72% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:04:11,051]\u001b[0m Trial 437 finished with value: 5.5730769838389955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007423264933160286, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14445169225007087, 'dropout_rate_Layer_2': 0.2877166479239898, 'dropout_rate_Layer_3': 0.10267027307056846, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021661912631121497, 'l1_Layer_2': 1.079914950002889e-05, 'l1_Layer_3': 0.0001187154287250023, 'n_units_Layer_1': 275, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 436 with value: 5.472460231834284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 48.03% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:06:10,667]\u001b[0m Trial 438 finished with value: 5.759038168278487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008319928287349733, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17629305864273037, 'dropout_rate_Layer_2': 0.3425443436023774, 'dropout_rate_Layer_3': 0.28849979963795414, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0044559817789686, 'l1_Layer_2': 0.00013317040346124426, 'l1_Layer_3': 1.050505328072778e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110}. Best is trial 436 with value: 5.472460231834284.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 47.99% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:07:35,166]\u001b[0m Trial 439 finished with value: 5.3244954004678435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007180258812333178, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13882227446964887, 'dropout_rate_Layer_2': 0.257236868537843, 'dropout_rate_Layer_3': 0.09619315914082834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014677396732405371, 'l1_Layer_2': 1.0001759376768418e-05, 'l1_Layer_3': 0.00011183474387532931, 'n_units_Layer_1': 265, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 439 with value: 5.3244954004678435.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 13.64% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 47.22% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:08:11,344]\u001b[0m Trial 440 finished with value: 5.420557909726654 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014615860287576783, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06548833422232267, 'dropout_rate_Layer_2': 0.37377586569974736, 'dropout_rate_Layer_3': 0.0534094717386524, 'dropout_rate_Layer_4': 0.2593588852608588, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00024059793039955078, 'l1_Layer_2': 2.7373979516506737e-05, 'l1_Layer_3': 2.4394697111408757e-05, 'l1_Layer_4': 0.00022239804169596028, 'n_units_Layer_1': 65, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180, 'n_units_Layer_4': 150}. Best is trial 439 with value: 5.3244954004678435.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 50.79% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:08:54,407]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:01,027]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:09,068]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:09:44,338]\u001b[0m Trial 444 finished with value: 5.535003082126212 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014971067960224487, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06359976558822748, 'dropout_rate_Layer_2': 0.37627595475743253, 'dropout_rate_Layer_3': 0.05440729822065145, 'dropout_rate_Layer_4': 0.2454572170076026, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00025355860772391874, 'l1_Layer_2': 3.1170769803895225e-05, 'l1_Layer_3': 2.3436613465249212e-05, 'l1_Layer_4': 5.16928577235276e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180, 'n_units_Layer_4': 125}. Best is trial 439 with value: 5.3244954004678435.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 49.44% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:10:41,029]\u001b[0m Trial 445 finished with value: 6.689262221450025 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014898673696949135, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08721076249583695, 'dropout_rate_Layer_2': 0.2469117654800473, 'dropout_rate_Layer_3': 0.38332898498605084, 'dropout_rate_Layer_4': 0.22848531030647135, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00044561504092329455, 'l1_Layer_2': 0.0006120825645675595, 'l1_Layer_3': 0.002670488851846, 'l1_Layer_4': 0.0001437973447730837, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285, 'n_units_Layer_4': 195}. Best is trial 439 with value: 5.3244954004678435.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 16.85% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 12.94 | sMAPE for Test Set is: 53.98% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:11:15,413]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:12:58,153]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:06,902]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:13:13,476]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:14:50,520]\u001b[0m Trial 450 finished with value: 5.736025634673276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008848710590446258, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26696874915926866, 'dropout_rate_Layer_2': 0.38745680041785135, 'dropout_rate_Layer_3': 0.2936524011866942, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00397507422574248, 'l1_Layer_2': 0.00014444686951154234, 'l1_Layer_3': 1.3621874703728113e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 240, 'n_units_Layer_3': 130}. Best is trial 439 with value: 5.3244954004678435.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 14.59% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 48.98% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:16:29,408]\u001b[0m Trial 451 finished with value: 5.284134760471251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007495651560584628, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1416182763343205, 'dropout_rate_Layer_2': 0.26269553464189066, 'dropout_rate_Layer_3': 0.10038482871983824, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023226352514747017, 'l1_Layer_2': 1.1620432474478605e-05, 'l1_Layer_3': 0.00011268782252349563, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 235}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.94 | sMAPE for Test Set is: 48.43% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:16:42,104]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:19:14,133]\u001b[0m Trial 453 finished with value: 5.677996226289419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008699960492472961, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2695667137249549, 'dropout_rate_Layer_2': 0.3903016891292458, 'dropout_rate_Layer_3': 0.30144755913273363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034816537022971847, 'l1_Layer_2': 0.00021102913599107184, 'l1_Layer_3': 2.182055312927425e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 14.37% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 48.22% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:21:07,364]\u001b[0m Trial 454 finished with value: 5.447693973120366 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007107418298792967, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13802467864443635, 'dropout_rate_Layer_2': 0.2516888711039871, 'dropout_rate_Layer_3': 0.09943516810707759, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002236726809813476, 'l1_Layer_2': 1.1195174270589931e-05, 'l1_Layer_3': 0.00012080159192851403, 'n_units_Layer_1': 245, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.92% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 47.68% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:21:24,599]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:22:47,987]\u001b[0m Trial 456 finished with value: 6.80707424910597 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014427165628547506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10053337433518955, 'dropout_rate_Layer_2': 0.233407709037382, 'dropout_rate_Layer_3': 0.3723244359587727, 'dropout_rate_Layer_4': 0.2878536959410706, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005264950291837338, 'l1_Layer_2': 0.000557472796627321, 'l1_Layer_3': 0.004995977789536463, 'l1_Layer_4': 0.00010285566851827481, 'n_units_Layer_1': 85, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285, 'n_units_Layer_4': 195}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 17.06% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 53.80% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:25:18,213]\u001b[0m Trial 457 finished with value: 5.408177670082789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006103331409666251, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14053461281202004, 'dropout_rate_Layer_2': 0.25698547265413596, 'dropout_rate_Layer_3': 0.09964407472332226, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014133277266349148, 'l1_Layer_2': 1.094356813101573e-05, 'l1_Layer_3': 7.924560142676946e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 47.88% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:26:02,158]\u001b[0m Trial 458 finished with value: 5.609240097431275 and parameters: {'n_hidden': 4, 'learning_rate': 0.003104823641773386, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09901057347609374, 'dropout_rate_Layer_2': 0.37620101637281217, 'dropout_rate_Layer_3': 0.12888591092981005, 'dropout_rate_Layer_4': 0.2429344832570151, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.94129788428907e-05, 'l1_Layer_2': 3.422844623043584e-05, 'l1_Layer_3': 1.0090811972655613e-05, 'l1_Layer_4': 2.6382232113902862e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215, 'n_units_Layer_4': 160}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 50.15% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:27:46,704]\u001b[0m Trial 459 finished with value: 5.814647649662011 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008687975286438479, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26876396561178123, 'dropout_rate_Layer_2': 0.3866296565413127, 'dropout_rate_Layer_3': 0.2986333796974618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036503295680412945, 'l1_Layer_2': 0.0002369672058750195, 'l1_Layer_3': 1.2998977317355211e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 14.73% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 48.19% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:27:53,039]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:08,398]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:28:25,203]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:30:03,204]\u001b[0m Trial 463 finished with value: 5.777966883977254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008800327381429968, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27084120717323373, 'dropout_rate_Layer_2': 0.39048261386600597, 'dropout_rate_Layer_3': 0.2847188208081428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035807298640733324, 'l1_Layer_2': 0.00020559848497870312, 'l1_Layer_3': 1.3221210993744023e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 14.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 49.34% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:30:54,487]\u001b[0m Trial 464 finished with value: 5.550047838878808 and parameters: {'n_hidden': 4, 'learning_rate': 0.001460367612607967, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059432181188100244, 'dropout_rate_Layer_2': 0.37959332798536116, 'dropout_rate_Layer_3': 0.09327567041677982, 'dropout_rate_Layer_4': 0.2772329909199533, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.1787629765620883e-05, 'l1_Layer_2': 6.448417832609638e-05, 'l1_Layer_3': 2.758701002152754e-05, 'l1_Layer_4': 0.0002070832988790477, 'n_units_Layer_1': 115, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250, 'n_units_Layer_4': 245}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 48.26% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:31:00,744]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:32:38,249]\u001b[0m Trial 466 finished with value: 5.793943503533439 and parameters: {'n_hidden': 3, 'learning_rate': 0.000868561774853268, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27049205182036506, 'dropout_rate_Layer_2': 0.3923775801602231, 'dropout_rate_Layer_3': 0.3018110630406438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037573263100157193, 'l1_Layer_2': 0.00019153248990864515, 'l1_Layer_3': 1.1900283239673995e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.02 | sMAPE for Test Set is: 48.33% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:32:44,470]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:35:43,368]\u001b[0m Trial 468 finished with value: 5.581882362543316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008622703570283028, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28392996111260455, 'dropout_rate_Layer_2': 0.38786807564874953, 'dropout_rate_Layer_3': 0.2859161486940236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003299791637617855, 'l1_Layer_2': 0.00020122415679495103, 'l1_Layer_3': 1.27639112587087e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.58 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 48.33% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:37:10,822]\u001b[0m Trial 469 finished with value: 5.809584317651319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008254809303998489, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.287425942810135, 'dropout_rate_Layer_2': 0.3869002839924246, 'dropout_rate_Layer_3': 0.28615386093727074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00362578046069957, 'l1_Layer_2': 0.00020894031782224036, 'l1_Layer_3': 1.2847236216796424e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 14.71% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.26 | sMAPE for Test Set is: 49.23% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:39:38,118]\u001b[0m Trial 470 finished with value: 5.706396785181994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008409501124226197, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2818373116017679, 'dropout_rate_Layer_2': 0.3895616845696719, 'dropout_rate_Layer_3': 0.29917767938907375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034138384213484537, 'l1_Layer_2': 0.00021827788221469028, 'l1_Layer_3': 1.2800369427457771e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 49.39% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:41:16,155]\u001b[0m Trial 471 finished with value: 5.618385497151806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007421835648729761, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1329164010215395, 'dropout_rate_Layer_2': 0.24841368564322558, 'dropout_rate_Layer_3': 0.10362930795471333, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014676280065383973, 'l1_Layer_2': 1.0417267984983729e-05, 'l1_Layer_3': 0.00011296443970921335, 'n_units_Layer_1': 250, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 14.31% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.90 | sMAPE for Test Set is: 48.14% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:42:43,603]\u001b[0m Trial 472 finished with value: 5.766311004903284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010092403661439776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2818903134895839, 'dropout_rate_Layer_2': 0.39993309453023, 'dropout_rate_Layer_3': 0.30454151795057155, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027845795184602467, 'l1_Layer_2': 0.00036992333100721684, 'l1_Layer_3': 1.118211875435647e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 14.66% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 47.88% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:42:52,028]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:44:17,019]\u001b[0m Trial 474 finished with value: 5.759069353655065 and parameters: {'n_hidden': 3, 'learning_rate': 0.001018653081747006, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28380784506705115, 'dropout_rate_Layer_2': 0.3927609808247196, 'dropout_rate_Layer_3': 0.30498975101390763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002749011044091946, 'l1_Layer_2': 0.0003792875419538659, 'l1_Layer_3': 1.0234579507836479e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 47.88% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:45:26,229]\u001b[0m Trial 475 finished with value: 5.561536297780397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006863799342837115, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14050190123523096, 'dropout_rate_Layer_2': 0.21444613211839206, 'dropout_rate_Layer_3': 0.13636953902561644, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010269593455780681, 'l1_Layer_2': 1.0120598719251727e-05, 'l1_Layer_3': 8.358641079413263e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.31 | sMAPE for Test Set is: 49.49% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:45:34,927]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:46:13,712]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:46:19,955]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:46:26,325]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:47:05,261]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:49:07,370]\u001b[0m Trial 481 finished with value: 5.699808119431111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008928839969413894, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2998592672494964, 'dropout_rate_Layer_2': 0.3915237302707936, 'dropout_rate_Layer_3': 0.28124975940211533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003076243871254062, 'l1_Layer_2': 0.0002293243037191107, 'l1_Layer_3': 1.5605471468262394e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 14.41% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 48.97% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:49:13,079]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:50:56,258]\u001b[0m Trial 483 finished with value: 5.710577029862217 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007281348599515548, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2963556987664413, 'dropout_rate_Layer_2': 0.37193666132101105, 'dropout_rate_Layer_3': 0.2642109562057785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028770379970643237, 'l1_Layer_2': 0.0003880108948655466, 'l1_Layer_3': 1.4694024466967632e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.46% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 47.20% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:52:22,401]\u001b[0m Trial 484 finished with value: 5.456007114575563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007392778579579764, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14832081283873516, 'dropout_rate_Layer_2': 0.22322636502251442, 'dropout_rate_Layer_3': 0.13791347530003067, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008738095375942741, 'l1_Layer_2': 1.2208566913185613e-05, 'l1_Layer_3': 7.722791231875414e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 46.93% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:52:32,782]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:52:40,585]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:52:49,464]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:54:11,951]\u001b[0m Trial 488 finished with value: 5.8044172013227735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009497923512781386, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27827719237221293, 'dropout_rate_Layer_2': 0.3918475244915097, 'dropout_rate_Layer_3': 0.2802972832683184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029771651651889293, 'l1_Layer_2': 0.0002420344780778787, 'l1_Layer_3': 1.0218235005716377e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 47.90% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:55:33,443]\u001b[0m Trial 489 finished with value: 6.713511626795906 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010889337871867039, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3344361352706071, 'dropout_rate_Layer_2': 0.19875875311866378, 'dropout_rate_Layer_3': 0.2880672094564716, 'dropout_rate_Layer_4': 0.20439823360114714, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003809890686405764, 'l1_Layer_2': 0.0005175635035930363, 'l1_Layer_3': 0.02148453107857299, 'l1_Layer_4': 0.00014126864037739093, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285, 'n_units_Layer_4': 195}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 53.26% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:55:49,930]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:55:56,400]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:56:18,959]\u001b[0m Trial 492 finished with value: 5.610247461289667 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025628668241213987, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13365754573993827, 'dropout_rate_Layer_2': 0.34272401112766226, 'dropout_rate_Layer_3': 0.018828770171419533, 'dropout_rate_Layer_4': 0.24521432553144898, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00023657323308288523, 'l1_Layer_2': 2.2945122502328724e-05, 'l1_Layer_3': 1.7653241400911798e-05, 'l1_Layer_4': 5.904488753262398e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 175, 'n_units_Layer_4': 195}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.61 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 47.99% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:56:22,753]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 14:58:04,759]\u001b[0m Trial 494 finished with value: 5.525572972519659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006214797782428985, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12329058691140056, 'dropout_rate_Layer_2': 0.22631895946110075, 'dropout_rate_Layer_3': 0.13857427485425644, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010219037854059428, 'l1_Layer_2': 1.4048378831845832e-05, 'l1_Layer_3': 7.808668310374456e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 220}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.33 | sMAPE for Test Set is: 49.53% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 14:59:47,805]\u001b[0m Trial 495 finished with value: 5.474206064586533 and parameters: {'n_hidden': 3, 'learning_rate': 0.000603288634283966, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12122764304674638, 'dropout_rate_Layer_2': 0.25696568294334476, 'dropout_rate_Layer_3': 0.156493567481365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007770308801076476, 'l1_Layer_2': 1.4315210534147036e-05, 'l1_Layer_3': 4.200267430284399e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 220}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 49.09% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:01:23,077]\u001b[0m Trial 496 finished with value: 5.7262901009172475 and parameters: {'n_hidden': 3, 'learning_rate': 0.001003763281678588, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28376397129322584, 'dropout_rate_Layer_2': 0.382248173564376, 'dropout_rate_Layer_3': 0.29232741541336477, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021283262051061485, 'l1_Layer_2': 0.00027827690770089783, 'l1_Layer_3': 1.4295244217482452e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 47.77% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:02:25,038]\u001b[0m Trial 497 finished with value: 6.646426272916173 and parameters: {'n_hidden': 4, 'learning_rate': 0.000990143277335265, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3285400147499891, 'dropout_rate_Layer_2': 0.26101639911723945, 'dropout_rate_Layer_3': 0.3545194518066966, 'dropout_rate_Layer_4': 0.2318253146022377, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005055538221457356, 'l1_Layer_2': 0.0003207279702696787, 'l1_Layer_3': 0.021520333326825836, 'l1_Layer_4': 0.00016025747772226482, 'n_units_Layer_1': 160, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290, 'n_units_Layer_4': 195}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 16.70% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 13.16 | sMAPE for Test Set is: 54.44% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:02:46,622]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:03:10,435]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:03:18,451]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:03:21,987]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:03:28,108]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:05:56,744]\u001b[0m Trial 503 finished with value: 5.543873665230677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006061643168107495, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10793869838248484, 'dropout_rate_Layer_2': 0.25504719417424915, 'dropout_rate_Layer_3': 0.15766733240735822, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007013187207123071, 'l1_Layer_2': 1.655894715262553e-05, 'l1_Layer_3': 4.791103688195306e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 14.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 49.62% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:06:01,736]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:06:10,188]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:06:15,040]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:07:46,543]\u001b[0m Trial 507 finished with value: 5.707474768903225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010243663990872848, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3154841526838254, 'dropout_rate_Layer_2': 0.37204990109415303, 'dropout_rate_Layer_3': 0.290086783607147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001991976715389494, 'l1_Layer_2': 0.0001497039284132884, 'l1_Layer_3': 1.458266995214427e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 49.22% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:07:52,539]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:07:56,573]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:08:02,596]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:08:06,337]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:08:11,292]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:09:13,303]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:09:19,832]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:11:02,249]\u001b[0m Trial 515 finished with value: 5.3631963281968895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010230929733663298, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1264981494272871, 'dropout_rate_Layer_2': 0.23712362864837583, 'dropout_rate_Layer_3': 0.1440629287196787, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004936502880178255, 'l1_Layer_2': 1.721371075478995e-05, 'l1_Layer_3': 3.340638014886554e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 240}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 48.49% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:11:37,581]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:13:49,259]\u001b[0m Trial 517 finished with value: 5.525885060406264 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009402035350422117, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12443559346084376, 'dropout_rate_Layer_2': 0.23636982449555255, 'dropout_rate_Layer_3': 0.14818130860482406, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00043831074806672453, 'l1_Layer_2': 1.8520107868782244e-05, 'l1_Layer_3': 3.393550463397554e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 49.78% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:13:57,500]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:14:02,791]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:14:08,170]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:14:28,206]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:14:34,176]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:14:43,522]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:14:47,949]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:15:21,397]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:15:27,271]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:15:45,215]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:15:49,952]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:15:55,803]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:16:00,977]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:16:07,430]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:16:16,790]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:18:30,114]\u001b[0m Trial 533 finished with value: 5.656950038940103 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006195801697526473, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2939279671692499, 'dropout_rate_Layer_2': 0.37525048653686605, 'dropout_rate_Layer_3': 0.32114165739244827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018099373376694431, 'l1_Layer_2': 0.00017314916522605698, 'l1_Layer_3': 1.5200275034828168e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 14.29% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 48.31% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:21:00,853]\u001b[0m Trial 534 finished with value: 5.586826890655957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006271895809559984, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2959974108562146, 'dropout_rate_Layer_2': 0.3521081061259274, 'dropout_rate_Layer_3': 0.318786837428187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014348095049736855, 'l1_Layer_2': 0.00016889802006189725, 'l1_Layer_3': 1.4144138017522469e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 46.67% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:23:14,711]\u001b[0m Trial 535 finished with value: 5.505413971391248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005832932300677858, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.291698545260976, 'dropout_rate_Layer_2': 0.3537139529332481, 'dropout_rate_Layer_3': 0.3140452047594377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012892267745237384, 'l1_Layer_2': 0.00016068702826163879, 'l1_Layer_3': 1.4284888713174626e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.97 | sMAPE for Test Set is: 48.31% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:23:28,781]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:23:50,568]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:24:28,184]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:24:50,126]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:24:53,550]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:26:40,946]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:26:47,089]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:28:55,233]\u001b[0m Trial 543 finished with value: 5.678803314789714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005601625249483496, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3252403381978308, 'dropout_rate_Layer_2': 0.37402387908002316, 'dropout_rate_Layer_3': 0.3284024621114531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021600943147889007, 'l1_Layer_2': 0.0002316808689174039, 'l1_Layer_3': 2.7519834877088587e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.37% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:30:10,826]\u001b[0m Trial 544 finished with value: 5.707443590164185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005961495520620513, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08235768924600834, 'dropout_rate_Layer_2': 0.22592869079445127, 'dropout_rate_Layer_3': 0.1602953759759841, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012603446029961348, 'l1_Layer_2': 1.3056975540551184e-05, 'l1_Layer_3': 2.6496088277425136e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.45% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.57% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:30:16,695]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:30:24,164]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:32:14,962]\u001b[0m Trial 547 finished with value: 5.769070618299133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005555414326727318, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3415741288992656, 'dropout_rate_Layer_2': 0.3873211673991525, 'dropout_rate_Layer_3': 0.2663151919492339, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002362258676332003, 'l1_Layer_2': 0.0004407384529504461, 'l1_Layer_3': 2.1028630798083475e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 14.63% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 47.17% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:32:23,170]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:33:02,370]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:33:10,408]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:33:32,935]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:33:47,220]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:34:07,455]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:36:14,710]\u001b[0m Trial 554 finished with value: 5.597231987628191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009210609813772563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3017332744335307, 'dropout_rate_Layer_2': 0.3499928191151334, 'dropout_rate_Layer_3': 0.30031540856292793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002135252571277174, 'l1_Layer_2': 0.0002341269435587877, 'l1_Layer_3': 1.7471767445110573e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 14.32% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 49.02% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:36:54,060]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:37:00,265]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:37:10,459]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:37:14,680]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:37:53,198]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:38:44,097]\u001b[0m Trial 560 finished with value: 5.438536524865881 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014463575418673926, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05844769061922123, 'dropout_rate_Layer_2': 0.38103121847955435, 'dropout_rate_Layer_3': 0.08986345755685783, 'dropout_rate_Layer_4': 0.27972665043231065, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.1047572604707256e-05, 'l1_Layer_2': 5.868195356956279e-05, 'l1_Layer_3': 2.8791308637971618e-05, 'l1_Layer_4': 0.00018420965753361855, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255, 'n_units_Layer_4': 240}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 47.71% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:38:49,921]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:38:53,869]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:38:59,649]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:39:39,137]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:39:54,815]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:00,592]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:17,259]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:27,021]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:30,353]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:37,480]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:45,738]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:40:50,844]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:41:04,141]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:41:08,137]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:41:14,174]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:41:29,329]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:42:25,651]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:42:31,621]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:43:07,048]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:44:18,575]\u001b[0m Trial 580 finished with value: 5.456962285077327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007182131365322076, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1486666484696658, 'dropout_rate_Layer_2': 0.23774373020288878, 'dropout_rate_Layer_3': 0.0962669490391022, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008320269905632129, 'l1_Layer_2': 1.6862789761149756e-05, 'l1_Layer_3': 7.631388641555286e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 47.83% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:44:22,161]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:44:28,247]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:45:47,957]\u001b[0m Trial 583 finished with value: 5.622006144243912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011763023918586544, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3143407242071847, 'dropout_rate_Layer_2': 0.3540162649572772, 'dropout_rate_Layer_3': 0.3140127206376028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019851954223096668, 'l1_Layer_2': 9.657226960809239e-05, 'l1_Layer_3': 2.3302575789774168e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 48.15% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:45:52,664]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:46:09,763]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:46:18,246]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:46:23,996]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:46:59,690]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:47:03,763]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:49:16,336]\u001b[0m Trial 590 finished with value: 5.574594165097846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006741783397082553, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3352791875775982, 'dropout_rate_Layer_2': 0.3846279738802, 'dropout_rate_Layer_3': 0.300947012973358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014370455467289085, 'l1_Layer_2': 0.00025599695331338817, 'l1_Layer_3': 2.4820928866891497e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 14.27% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.36% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:51:22,699]\u001b[0m Trial 591 finished with value: 5.53739995143933 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006687058179801864, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.330929501189241, 'dropout_rate_Layer_2': 0.33111028669225295, 'dropout_rate_Layer_3': 0.30270810107504015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001407812895597498, 'l1_Layer_2': 0.00025784810780267475, 'l1_Layer_3': 2.6423426748925373e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.70 | sMAPE for Test Set is: 47.32% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:51:27,692]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:52:36,672]\u001b[0m Trial 593 finished with value: 5.4405885903484545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006583968904800607, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14673106181801465, 'dropout_rate_Layer_2': 0.23683422662215056, 'dropout_rate_Layer_3': 0.11670095394575522, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008367371612247147, 'l1_Layer_2': 1.699908162781372e-05, 'l1_Layer_3': 7.137522662902231e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 47.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:52:42,562]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:52:47,999]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:52:53,581]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:52:58,611]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:53:04,895]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:53:42,776]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:53:52,414]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:54:48,805]\u001b[0m Trial 601 finished with value: 5.617303114843104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009229107712676124, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14985145566140992, 'dropout_rate_Layer_2': 0.20956839891188156, 'dropout_rate_Layer_3': 0.07780119707511862, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012580098624754969, 'l1_Layer_2': 1.2148277769462096e-05, 'l1_Layer_3': 5.365356295410748e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.43 | sMAPE for Test Set is: 49.98% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:57:08,981]\u001b[0m Trial 602 finished with value: 5.416033059844758 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008379106483869747, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13731251091823443, 'dropout_rate_Layer_2': 0.2221730038557612, 'dropout_rate_Layer_3': 0.11796497058704002, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018696773661238217, 'l1_Layer_2': 1.711603710778264e-05, 'l1_Layer_3': 0.0001121159399827382, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 48.78% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 15:57:14,822]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:19,653]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:25,249]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:28,656]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:34,542]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:40,646]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:44,840]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 15:57:53,901]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:00:05,322]\u001b[0m Trial 611 finished with value: 5.601796097320329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007173140458875112, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3226047989286847, 'dropout_rate_Layer_2': 0.3256449972716613, 'dropout_rate_Layer_3': 0.3140086803444915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010017439628981382, 'l1_Layer_2': 0.00012333553289244452, 'l1_Layer_3': 2.9017323781939648e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 14.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 49.89% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:01:05,093]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:02:19,189]\u001b[0m Trial 613 finished with value: 5.410349749346686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008288946683463183, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1179867196841009, 'dropout_rate_Layer_2': 0.2287076691900598, 'dropout_rate_Layer_3': 0.14045497452405, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009112877204894537, 'l1_Layer_2': 1.7357915124074755e-05, 'l1_Layer_3': 7.148727373324903e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.41 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 47.81% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:02:25,126]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:03:01,912]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:03:34,781]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:03:40,451]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:03:56,006]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:04:10,709]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:04:27,095]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:07:20,923]\u001b[0m Trial 621 finished with value: 5.508434201885201 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005768011096812107, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3161463944677839, 'dropout_rate_Layer_2': 0.34225769345648044, 'dropout_rate_Layer_3': 0.3013669314607663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009673459613591658, 'l1_Layer_2': 0.0002578048240921367, 'l1_Layer_3': 2.7554850666795564e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.09 | sMAPE for Test Set is: 48.73% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:07:40,770]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:07:45,205]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:07:50,698]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:09:38,118]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:09:42,686]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:09:59,938]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:10:05,908]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:10:10,203]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:11:58,377]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:12:25,874]\u001b[0m Trial 631 finished with value: 5.526047572139476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018351954129637925, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1155805604562807, 'dropout_rate_Layer_2': 0.344718253633257, 'dropout_rate_Layer_3': 0.03446719870634238, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020495096959990923, 'l1_Layer_2': 2.9702969817876788e-05, 'l1_Layer_3': 4.134526258541418e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 250, 'n_units_Layer_3': 130}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.53 | sMAPE for Validation Set is: 14.20% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.54 | sMAPE for Test Set is: 50.16% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:12:41,650]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:12:46,326]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:12:50,394]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:12:55,612]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:13:02,062]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:13:10,412]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:13:17,867]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:03,170]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:09,245]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:17,737]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:23,342]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:28,395]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:34,177]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:43,079]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:48,988]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:15:53,985]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:17:04,148]\u001b[0m Trial 648 finished with value: 5.483489596990235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008338653060183164, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14788235536303596, 'dropout_rate_Layer_2': 0.24476715287894482, 'dropout_rate_Layer_3': 0.10744097704591583, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008926056333165448, 'l1_Layer_2': 1.8447456532558785e-05, 'l1_Layer_3': 8.21509605986301e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 47.87% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:17:09,908]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:17:26,153]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:17:29,562]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:17:45,366]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:17:51,755]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:18:00,379]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:18:04,615]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:18:08,162]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:18:15,059]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:18:27,778]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:20:20,006]\u001b[0m Trial 659 finished with value: 5.304717556466825 and parameters: {'n_hidden': 3, 'learning_rate': 0.00058043066119298, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10384766693096757, 'dropout_rate_Layer_2': 0.23337357759205987, 'dropout_rate_Layer_3': 0.09758517361459654, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008787299309288934, 'l1_Layer_2': 1.2728387869640524e-05, 'l1_Layer_3': 5.8209593547512414e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.72 | sMAPE for Test Set is: 47.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:20:27,687]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:20:36,905]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:20:41,979]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:20:47,107]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:20:51,992]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:20:57,432]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:21:01,694]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:21:10,422]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:21:24,772]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:21:39,296]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:23:28,971]\u001b[0m Trial 670 finished with value: 5.341532976183369 and parameters: {'n_hidden': 3, 'learning_rate': 0.000560871363115961, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10415541271567368, 'dropout_rate_Layer_2': 0.21950115153674146, 'dropout_rate_Layer_3': 0.08503977172190613, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010495719395249815, 'l1_Layer_2': 1.2687088577371416e-05, 'l1_Layer_3': 5.639547469052169e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 240}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.36 | sMAPE for Test Set is: 46.24% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:23:36,093]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:23:45,653]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:23:53,696]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:25:19,420]\u001b[0m Trial 674 finished with value: 5.37673153198853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005835423442262211, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11507318350637027, 'dropout_rate_Layer_2': 0.24449370593006353, 'dropout_rate_Layer_3': 0.0862731275892847, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006033063423338834, 'l1_Layer_2': 1.271811051504553e-05, 'l1_Layer_3': 3.5366024015597955e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.60% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:25:23,175]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:25:57,578]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:26:04,229]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:26:09,696]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:26:22,355]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:26:59,311]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:27:05,658]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:27:11,411]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:27:50,853]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:28:28,154]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:28:35,546]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:28:45,316]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:30:29,963]\u001b[0m Trial 687 finished with value: 5.3477759347148455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005920256965550363, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10792844084687546, 'dropout_rate_Layer_2': 0.2446554897173226, 'dropout_rate_Layer_3': 0.08666826819028918, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006243680938870625, 'l1_Layer_2': 1.3111979805582165e-05, 'l1_Layer_3': 5.0042377980947234e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 270}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 46.25% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:30:36,504]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:30:44,146]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:30:51,884]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:30:57,660]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:31:03,088]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:31:18,028]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:31:39,381]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:32:13,528]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:34:06,078]\u001b[0m Trial 696 finished with value: 5.622327958201119 and parameters: {'n_hidden': 3, 'learning_rate': 0.000844465314444028, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35615846968404496, 'dropout_rate_Layer_2': 0.3438122592108104, 'dropout_rate_Layer_3': 0.3087998794564277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005453900020698814, 'l1_Layer_2': 0.0004407283845847886, 'l1_Layer_3': 2.2711807693540586e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.62 | sMAPE for Validation Set is: 14.48% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 48.30% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:34:43,948]\u001b[0m Trial 697 finished with value: 5.432614368655384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012292812201936004, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08960300243137596, 'dropout_rate_Layer_2': 0.3846571489157393, 'dropout_rate_Layer_3': 0.041791129893720205, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042524029458848546, 'l1_Layer_2': 4.8662777735252985e-05, 'l1_Layer_3': 3.809829098921226e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.41 | sMAPE for Test Set is: 46.29% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:34:50,030]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:35:27,973]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:37:24,717]\u001b[0m Trial 700 finished with value: 5.596310875633354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008416177986077305, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3592238325482821, 'dropout_rate_Layer_2': 0.33311513645313756, 'dropout_rate_Layer_3': 0.3096835019366614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006284386089188569, 'l1_Layer_2': 0.00045440140398788313, 'l1_Layer_3': 2.117406811282885e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 451 with value: 5.284134760471251.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 14.42% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 48.39% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:37:32,725]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:06,775]\u001b[0m Trial 702 finished with value: 5.259211113133244 and parameters: {'n_hidden': 3, 'learning_rate': 0.000611858574489687, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.093158382864649, 'dropout_rate_Layer_2': 0.2655827229826857, 'dropout_rate_Layer_3': 0.05871152161538966, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015090867943328551, 'l1_Layer_2': 1.2503315739114077e-05, 'l1_Layer_3': 3.9704622146547114e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 270, 'n_units_Layer_3': 285}. Best is trial 702 with value: 5.259211113133244.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 13.52% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 46.66% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:39:11,281]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:19,364]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:23,350]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:31,371]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:36,714]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:52,707]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:39:58,040]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:40:13,065]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:40:17,486]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:00,689]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:06,409]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:12,834]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:16,884]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:22,247]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:33,415]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:42:40,248]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:43:19,521]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:43:26,987]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:45:22,770]\u001b[0m Trial 721 finished with value: 5.241306146167955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005649874108399499, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09114154763097757, 'dropout_rate_Layer_2': 0.27239909421324177, 'dropout_rate_Layer_3': 0.05920661208747553, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010569898397345728, 'l1_Layer_2': 1.2122343182460573e-05, 'l1_Layer_3': 3.977833389394012e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 46.58% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:45:28,567]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:45:43,435]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:45:51,793]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:45:57,143]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:46:02,398]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:46:09,955]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:47:14,884]\u001b[0m Trial 728 finished with value: 5.3601112665766 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005976823939279377, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08947412767499538, 'dropout_rate_Layer_2': 0.2709873523326826, 'dropout_rate_Layer_3': 0.06297659599184934, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010493868153819731, 'l1_Layer_2': 1.1763779004190612e-05, 'l1_Layer_3': 3.388727140356094e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 290}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 46.48% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:47:19,482]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:47:48,785]\u001b[0m Trial 730 finished with value: 5.523024580243359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011833416105568903, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03919808454228877, 'dropout_rate_Layer_2': 0.384391031799232, 'dropout_rate_Layer_3': 0.06365258317502595, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038901380855752476, 'l1_Layer_2': 2.6198497757565812e-05, 'l1_Layer_3': 4.996070923468492e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 14.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 49.46% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:47:52,955]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:48:31,929]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:49:07,279]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:49:13,575]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:50:17,480]\u001b[0m Trial 735 finished with value: 5.346695109887719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005880708397351625, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08899170242974182, 'dropout_rate_Layer_2': 0.2725501707510013, 'dropout_rate_Layer_3': 0.059068673503545686, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016457833380176285, 'l1_Layer_2': 1.2415788659260315e-05, 'l1_Layer_3': 2.0114296023828067e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.71% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 46.40% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:50:23,556]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:50:40,048]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:50:45,383]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:52:21,208]\u001b[0m Trial 739 finished with value: 5.6936904530329855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006666137491753165, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2869365407393187, 'dropout_rate_Layer_2': 0.231120747098988, 'dropout_rate_Layer_3': 0.20154780511049938, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015967620807965954, 'l1_Layer_2': 0.0004825559360327815, 'l1_Layer_3': 1.5240713553845915e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 14.44% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 47.27% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:52:27,458]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:54:38,907]\u001b[0m Trial 741 finished with value: 5.650292622834388 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006114394482421763, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35860200823899235, 'dropout_rate_Layer_2': 0.23318090721521229, 'dropout_rate_Layer_3': 0.13620922504965494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001543352082232175, 'l1_Layer_2': 0.000698837883358076, 'l1_Layer_3': 2.8196720916772228e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 130}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.65 | sMAPE for Validation Set is: 14.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 48.50% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:55:29,583]\u001b[0m Trial 742 finished with value: 5.390761115457759 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005826029588262015, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08905575133896208, 'dropout_rate_Layer_2': 0.271784774037082, 'dropout_rate_Layer_3': 0.058191047402863315, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011566980474456273, 'l1_Layer_2': 1.2942757274356462e-05, 'l1_Layer_3': 1.9004664923815484e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.58 | sMAPE for Test Set is: 47.08% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 16:56:55,560]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 16:58:21,430]\u001b[0m Trial 744 finished with value: 5.447223447812114 and parameters: {'n_hidden': 4, 'learning_rate': 0.001151088406608273, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22685793769386914, 'dropout_rate_Layer_2': 0.367810217864266, 'dropout_rate_Layer_3': 0.3993270423614673, 'dropout_rate_Layer_4': 0.016448994962575916, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012094514267805552, 'l1_Layer_2': 0.00024050055766387294, 'l1_Layer_3': 1.0163441948202961e-05, 'l1_Layer_4': 0.00016608919484291357, 'n_units_Layer_1': 85, 'n_units_Layer_2': 245, 'n_units_Layer_3': 260, 'n_units_Layer_4': 200}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.70 | sMAPE for Test Set is: 47.39% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:00:49,518]\u001b[0m Trial 745 finished with value: 5.656306417974014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005486008762549972, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3537396132089362, 'dropout_rate_Layer_2': 0.2333424575498517, 'dropout_rate_Layer_3': 0.14354426544688884, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010361733671132077, 'l1_Layer_2': 0.0007529171471889535, 'l1_Layer_3': 3.9119719571762225e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 130}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 14.28% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 10.96 | sMAPE for Test Set is: 48.29% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:00:58,280]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:01:06,420]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:02:52,691]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:03:00,302]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:03:07,387]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:03:17,215]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:03:32,634]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:04:11,662]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:04:26,684]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:06:53,675]\u001b[0m Trial 755 finished with value: 5.549959539283809 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005143541606524615, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35426254960386105, 'dropout_rate_Layer_2': 0.27737850986943047, 'dropout_rate_Layer_3': 0.11837115451571244, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008285547400892745, 'l1_Layer_2': 0.0005105689672482465, 'l1_Layer_3': 4.1254276825291695e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.19 | sMAPE for Test Set is: 49.13% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:06:58,848]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:07:17,517]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:07:23,572]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:07:31,180]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:07:35,054]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:07:41,073]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:08:17,271]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:08:27,944]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:08:42,449]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:03,818]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:13,424]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:22,232]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:33,360]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:38,860]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:44,643]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:51,070]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:09:57,196]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:10:03,215]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:10:08,478]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:10:14,735]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:10:22,867]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:10:38,627]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:10:45,922]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:12:34,257]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:12:51,451]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:12:58,315]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:13:14,174]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:13:20,315]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:13:28,567]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:13:41,868]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:14:18,440]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:14:29,403]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:14:36,898]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:14:43,294]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:14:49,195]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:16:12,843]\u001b[0m Trial 791 finished with value: 6.5987061772976965 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012574158679031088, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19689277425784318, 'dropout_rate_Layer_2': 0.21517803003737584, 'dropout_rate_Layer_3': 0.26014383907690586, 'dropout_rate_Layer_4': 0.28669598926883366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003077558120739338, 'l1_Layer_2': 0.0015806560669761663, 'l1_Layer_3': 0.038142231313350386, 'l1_Layer_4': 5.3908631540529887e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 210}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.58% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 53.49% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:17:23,609]\u001b[0m Trial 792 finished with value: 6.673743939888101 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012617557916715552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20101548360978475, 'dropout_rate_Layer_2': 0.24183197207658447, 'dropout_rate_Layer_3': 0.2601225453388633, 'dropout_rate_Layer_4': 0.19437762903565062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002968098978461648, 'l1_Layer_2': 0.005071904617592393, 'l1_Layer_3': 0.03533286780329327, 'l1_Layer_4': 5.9100131164365976e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 16.73% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 52.83% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:18:32,651]\u001b[0m Trial 793 finished with value: 6.695552254264804 and parameters: {'n_hidden': 4, 'learning_rate': 0.001293542876514992, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19779447410871917, 'dropout_rate_Layer_2': 0.21241142997160642, 'dropout_rate_Layer_3': 0.2603430920007572, 'dropout_rate_Layer_4': 0.18329919205195816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000309389037191576, 'l1_Layer_2': 0.0008170686147783673, 'l1_Layer_3': 0.032700547809993326, 'l1_Layer_4': 5.766053886643931e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 215}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 16.79% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 12.29 | sMAPE for Test Set is: 52.07% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:19:10,616]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:19:25,633]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:19:32,984]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:20:56,442]\u001b[0m Trial 797 finished with value: 6.6249019760526116 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012781705383529067, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20537529354552234, 'dropout_rate_Layer_2': 0.20970895005695372, 'dropout_rate_Layer_3': 0.26086075003545584, 'dropout_rate_Layer_4': 0.19872051623660897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00030421935104339975, 'l1_Layer_2': 0.0009007764286111459, 'l1_Layer_3': 0.03905429799352119, 'l1_Layer_4': 5.7273266301602425e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 225}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 16.59% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 52.38% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:21:34,967]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:22:12,379]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:22:52,168]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:23:31,437]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:24:26,774]\u001b[0m Trial 802 finished with value: 6.617133281102173 and parameters: {'n_hidden': 4, 'learning_rate': 0.001349182514482978, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1900355518058555, 'dropout_rate_Layer_2': 0.22749496736060773, 'dropout_rate_Layer_3': 0.24567449463242397, 'dropout_rate_Layer_4': 0.1931043757326894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00024405705597696094, 'l1_Layer_2': 0.0007646151306611552, 'l1_Layer_3': 0.029816640240179305, 'l1_Layer_4': 6.572690812085061e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 175, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 16.63% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 51.73% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:25:05,773]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:26:32,288]\u001b[0m Trial 804 finished with value: 6.488159364845944 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012208552615470887, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18452207941562662, 'dropout_rate_Layer_2': 0.21964736029859366, 'dropout_rate_Layer_3': 0.2394890527834149, 'dropout_rate_Layer_4': 0.18650228445588957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00030892261830270715, 'l1_Layer_2': 0.0029060828091060633, 'l1_Layer_3': 0.02784332938539642, 'l1_Layer_4': 6.600249011921192e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.25 | sMAPE for Test Set is: 51.99% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:27:58,905]\u001b[0m Trial 805 finished with value: 6.543739034272662 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011722202151100223, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18287221278013555, 'dropout_rate_Layer_2': 0.22863349620019305, 'dropout_rate_Layer_3': 0.24491886059360618, 'dropout_rate_Layer_4': 0.21333608892773998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000318008514535011, 'l1_Layer_2': 0.0022565467430624695, 'l1_Layer_3': 0.030569441318079454, 'l1_Layer_4': 6.517685452163002e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 190, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 52.43% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:29:24,169]\u001b[0m Trial 806 finished with value: 6.503772422073053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011281243823374225, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18245426561860928, 'dropout_rate_Layer_2': 0.22609173034485175, 'dropout_rate_Layer_3': 0.24499514822448895, 'dropout_rate_Layer_4': 0.1804313630962462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003055052441116244, 'l1_Layer_2': 0.002252975576913018, 'l1_Layer_3': 0.029567013426938526, 'l1_Layer_4': 6.853732769188548e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 52.19% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:29:34,158]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:29:50,133]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:31:13,561]\u001b[0m Trial 809 finished with value: 6.474496766530824 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011641846418359142, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18349052092319681, 'dropout_rate_Layer_2': 0.22791674386407884, 'dropout_rate_Layer_3': 0.23926912922383045, 'dropout_rate_Layer_4': 0.19285641682043378, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00030351382812851096, 'l1_Layer_2': 0.0027267684224188795, 'l1_Layer_3': 0.030773675928109374, 'l1_Layer_4': 6.57277015693322e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 185, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 51.77% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:33:05,322]\u001b[0m Trial 810 finished with value: 6.514034657158667 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010572162105413163, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18070090959187196, 'dropout_rate_Layer_2': 0.22947652067296945, 'dropout_rate_Layer_3': 0.23835045020263548, 'dropout_rate_Layer_4': 0.19036918456050503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003207982570796177, 'l1_Layer_2': 0.0025670887232034263, 'l1_Layer_3': 0.030240005002687958, 'l1_Layer_4': 6.417989528508829e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 255, 'n_units_Layer_3': 180, 'n_units_Layer_4': 220}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 51.64% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:33:11,096]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:33:19,059]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:34:41,447]\u001b[0m Trial 813 finished with value: 6.4628419489478715 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010404590140824313, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1845065967213073, 'dropout_rate_Layer_2': 0.2277981037261682, 'dropout_rate_Layer_3': 0.23330541196060128, 'dropout_rate_Layer_4': 0.19196236301677966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003161271118722395, 'l1_Layer_2': 0.002901391789207569, 'l1_Layer_3': 0.029134950639069387, 'l1_Layer_4': 6.890716032304033e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185, 'n_units_Layer_4': 225}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 50.54% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:36:04,565]\u001b[0m Trial 814 finished with value: 6.529242292205272 and parameters: {'n_hidden': 4, 'learning_rate': 0.001013533127396634, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1800434293126247, 'dropout_rate_Layer_2': 0.2290555319920225, 'dropout_rate_Layer_3': 0.2300024373984065, 'dropout_rate_Layer_4': 0.20004757671758183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003775107556543837, 'l1_Layer_2': 0.002849422582935085, 'l1_Layer_3': 0.031088553264258172, 'l1_Layer_4': 6.672697948072061e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 185, 'n_units_Layer_4': 230}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 16.41% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.26 | sMAPE for Test Set is: 52.07% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:37:19,654]\u001b[0m Trial 815 finished with value: 6.5707531184723935 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010558264848439145, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1779210559437779, 'dropout_rate_Layer_2': 0.22855816003842272, 'dropout_rate_Layer_3': 0.22935011703079078, 'dropout_rate_Layer_4': 0.1929813333038013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003837033019090497, 'l1_Layer_2': 0.0031678383649104457, 'l1_Layer_3': 0.029130634833733057, 'l1_Layer_4': 6.713184290336862e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 230}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 16.49% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 51.33% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:38:21,923]\u001b[0m Trial 816 finished with value: 6.490888470342484 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010430873439966702, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1747818978298256, 'dropout_rate_Layer_2': 0.2277252810886711, 'dropout_rate_Layer_3': 0.22927245485851971, 'dropout_rate_Layer_4': 0.1917982412447527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00035807421428953127, 'l1_Layer_2': 0.0031082074040757425, 'l1_Layer_3': 0.02875699092993086, 'l1_Layer_4': 6.572245820116812e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 51.24% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:38:55,584]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:39:32,708]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:41:12,051]\u001b[0m Trial 819 finished with value: 6.436092017793567 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010146341229691103, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.177205368949327, 'dropout_rate_Layer_2': 0.22864815141299827, 'dropout_rate_Layer_3': 0.22708197489140058, 'dropout_rate_Layer_4': 0.18974638920729636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003895237521268221, 'l1_Layer_2': 0.003000339519240668, 'l1_Layer_3': 0.030566562025331232, 'l1_Layer_4': 6.564358489258933e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 240}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 16.24% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 51.27% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:42:23,602]\u001b[0m Trial 820 finished with value: 6.50470156789492 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009893016202218894, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17753099889408508, 'dropout_rate_Layer_2': 0.22798475645428362, 'dropout_rate_Layer_3': 0.2240577557001649, 'dropout_rate_Layer_4': 0.18640555549153195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003981604329175666, 'l1_Layer_2': 0.0028750310891299986, 'l1_Layer_3': 0.02978474012543012, 'l1_Layer_4': 6.246963311196046e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 16.38% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.98 | sMAPE for Test Set is: 51.09% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:42:54,707]\u001b[0m Trial 821 finished with value: 5.511913976780306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006404597768330009, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1001938888971956, 'dropout_rate_Layer_2': 0.24790858581372263, 'dropout_rate_Layer_3': 0.07704297490351014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003876642860994385, 'l1_Layer_2': 2.701600062627967e-05, 'l1_Layer_3': 3.9465187761385435e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 240, 'n_units_Layer_3': 270}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.17 | sMAPE for Test Set is: 45.04% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:44:21,592]\u001b[0m Trial 822 finished with value: 6.596782139097957 and parameters: {'n_hidden': 4, 'learning_rate': 0.000943494335020037, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18081792082797352, 'dropout_rate_Layer_2': 0.2276867134466976, 'dropout_rate_Layer_3': 0.21912804798147634, 'dropout_rate_Layer_4': 0.196492955809346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003944993399577858, 'l1_Layer_2': 0.0028995791531732013, 'l1_Layer_3': 0.02920033209653713, 'l1_Layer_4': 6.177835230521692e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 255, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 52.38% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:45:51,847]\u001b[0m Trial 823 finished with value: 5.264299487943313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005850713475982632, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08848886589583306, 'dropout_rate_Layer_2': 0.2652330398134414, 'dropout_rate_Layer_3': 0.05808281707445384, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011674585129985175, 'l1_Layer_2': 2.1137660891692166e-05, 'l1_Layer_3': 2.1499888964659492e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 46.19% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:46:07,756]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:46:30,578]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:47:14,853]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:48:25,935]\u001b[0m Trial 827 finished with value: 6.514100532647174 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010134187743085763, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18447374905411787, 'dropout_rate_Layer_2': 0.22569287619271555, 'dropout_rate_Layer_3': 0.22706695133570992, 'dropout_rate_Layer_4': 0.18818449936483808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004235324714743238, 'l1_Layer_2': 0.002739816990458884, 'l1_Layer_3': 0.032308340733603974, 'l1_Layer_4': 5.798094381283936e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.17 | sMAPE for Test Set is: 51.77% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:49:31,560]\u001b[0m Trial 828 finished with value: 6.491426003001479 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010317190841140494, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18336644627298085, 'dropout_rate_Layer_2': 0.2253371128711721, 'dropout_rate_Layer_3': 0.22619276566462138, 'dropout_rate_Layer_4': 0.1892209017646166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00044521167350095075, 'l1_Layer_2': 0.0026820141972354714, 'l1_Layer_3': 0.03382630765152314, 'l1_Layer_4': 6.144142856643795e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.12 | sMAPE for Test Set is: 51.61% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:50:07,958]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:51:32,235]\u001b[0m Trial 830 finished with value: 6.608663961953958 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010051726977330126, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18549293735099187, 'dropout_rate_Layer_2': 0.22540666866036568, 'dropout_rate_Layer_3': 0.2223267430757858, 'dropout_rate_Layer_4': 0.18728093348582042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004241425316636152, 'l1_Layer_2': 0.003277232355883341, 'l1_Layer_3': 0.0327472040196619, 'l1_Layer_4': 5.9648046984480965e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 16.57% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 51.96% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:52:20,560]\u001b[0m Trial 831 finished with value: 5.379151984078036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016595280282845548, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06179601417341468, 'dropout_rate_Layer_2': 0.3729298396907489, 'dropout_rate_Layer_3': 0.048938636925678014, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019840375335931402, 'l1_Layer_2': 3.0432458006193348e-05, 'l1_Layer_3': 2.573568794554553e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 46.76% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:53:59,458]\u001b[0m Trial 832 finished with value: 6.484754667681689 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009814268481855846, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1822254355940981, 'dropout_rate_Layer_2': 0.22478465177147325, 'dropout_rate_Layer_3': 0.22085111570884972, 'dropout_rate_Layer_4': 0.1857208982991582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000468615304130863, 'l1_Layer_2': 0.0029141582105598612, 'l1_Layer_3': 0.03341488702809932, 'l1_Layer_4': 5.9830768489496155e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 195, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 50.22% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:55:25,980]\u001b[0m Trial 833 finished with value: 6.5522524456116535 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009920426833734362, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18416582655102376, 'dropout_rate_Layer_2': 0.22067884779141325, 'dropout_rate_Layer_3': 0.22369773218083883, 'dropout_rate_Layer_4': 0.18493027826625147, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004608667464341374, 'l1_Layer_2': 0.0028920494174810114, 'l1_Layer_3': 0.03487073987166368, 'l1_Layer_4': 5.886507457998503e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 52.56% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:55:42,161]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 17:57:21,434]\u001b[0m Trial 835 finished with value: 6.556956574246427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009720346954902654, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18382953228840948, 'dropout_rate_Layer_2': 0.22304821584078618, 'dropout_rate_Layer_3': 0.21989867865236443, 'dropout_rate_Layer_4': 0.19148712952478852, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004692642056166908, 'l1_Layer_2': 0.003276320253324943, 'l1_Layer_3': 0.036053112025013795, 'l1_Layer_4': 6.179377584524391e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 240}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 52.45% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:58:47,096]\u001b[0m Trial 836 finished with value: 6.581628310835785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009850335652355035, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18379378100654037, 'dropout_rate_Layer_2': 0.22530095910378295, 'dropout_rate_Layer_3': 0.2211242443396305, 'dropout_rate_Layer_4': 0.1930987537566468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004756985192470255, 'l1_Layer_2': 0.0028992214553074723, 'l1_Layer_3': 0.03552210926326921, 'l1_Layer_4': 6.159410568283124e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.92 | sMAPE for Test Set is: 53.99% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 17:58:57,204]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:00:39,757]\u001b[0m Trial 838 finished with value: 6.532843153490035 and parameters: {'n_hidden': 4, 'learning_rate': 0.000874751985490559, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18306167228038145, 'dropout_rate_Layer_2': 0.22610651532398962, 'dropout_rate_Layer_3': 0.2203099771699927, 'dropout_rate_Layer_4': 0.18730318818338737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000456065162830087, 'l1_Layer_2': 0.0029471756283100028, 'l1_Layer_3': 0.043453103989091885, 'l1_Layer_4': 6.18982447160641e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 235}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.35 | sMAPE for Test Set is: 52.35% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:00:47,753]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:01:50,182]\u001b[0m Trial 840 finished with value: 6.566481890456416 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008804723622719573, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1843877408593356, 'dropout_rate_Layer_2': 0.22476117814145077, 'dropout_rate_Layer_3': 0.21723966485042373, 'dropout_rate_Layer_4': 0.18710665642536248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004502202433163206, 'l1_Layer_2': 0.0029895609881650945, 'l1_Layer_3': 0.04296188907310379, 'l1_Layer_4': 6.26405490273562e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 240}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 16.54% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.61 | sMAPE for Test Set is: 53.15% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:03:26,555]\u001b[0m Trial 841 finished with value: 6.546764262499534 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008676895842511093, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18167161171176832, 'dropout_rate_Layer_2': 0.22499946182566835, 'dropout_rate_Layer_3': 0.2200437924944698, 'dropout_rate_Layer_4': 0.18700165068086574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00045998428065998357, 'l1_Layer_2': 0.0029074310056880783, 'l1_Layer_3': 0.04455965189055321, 'l1_Layer_4': 6.618630528601619e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 240}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.45% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 52.51% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:05:05,456]\u001b[0m Trial 842 finished with value: 5.604943978169332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009343834098565059, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30932115597473914, 'dropout_rate_Layer_2': 0.2269794224215434, 'dropout_rate_Layer_3': 0.3115136044546788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016019565548098923, 'l1_Layer_2': 0.00011132384331316308, 'l1_Layer_3': 1.4715635803922696e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 145}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 14.24% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.29 | sMAPE for Test Set is: 49.30% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:06:26,833]\u001b[0m Trial 843 finished with value: 5.3120530554524565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005007460739265432, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09236445912526746, 'dropout_rate_Layer_2': 0.24292518326645207, 'dropout_rate_Layer_3': 0.04483396627065074, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005242008561624827, 'l1_Layer_2': 1.4553439197907117e-05, 'l1_Layer_3': 2.3082366303629793e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 270, 'n_units_Layer_3': 290}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 46.20% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:08:04,294]\u001b[0m Trial 844 finished with value: 6.581855135274778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008546511118266235, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18138152982589062, 'dropout_rate_Layer_2': 0.2219755126880448, 'dropout_rate_Layer_3': 0.21791506429414337, 'dropout_rate_Layer_4': 0.1835529113066358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00045876380696820775, 'l1_Layer_2': 0.0029253548301004387, 'l1_Layer_3': 0.044715562828136816, 'l1_Layer_4': 5.0288454319455365e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 240}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 52.68% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:09:31,013]\u001b[0m Trial 845 finished with value: 6.557599608112315 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008558145269404918, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17895765818310355, 'dropout_rate_Layer_2': 0.21949296332243304, 'dropout_rate_Layer_3': 0.21724738420496906, 'dropout_rate_Layer_4': 0.1747194652410659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000467765344470543, 'l1_Layer_2': 0.0029007147413690477, 'l1_Layer_3': 0.04546667750226571, 'l1_Layer_4': 4.5910576823939436e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 16.44% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.37 | sMAPE for Test Set is: 52.37% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:10:55,817]\u001b[0m Trial 846 finished with value: 6.546867544193731 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008498138960608123, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17991570375399757, 'dropout_rate_Layer_2': 0.2198553203522147, 'dropout_rate_Layer_3': 0.2181108542423118, 'dropout_rate_Layer_4': 0.17524132060302958, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005904254971137416, 'l1_Layer_2': 0.0028898422716084936, 'l1_Layer_3': 0.04474818914552686, 'l1_Layer_4': 4.875958169287427e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.32 | sMAPE for Test Set is: 52.21% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:11:11,381]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:12:34,789]\u001b[0m Trial 848 finished with value: 6.519673253926041 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007902644945648734, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18066647182840564, 'dropout_rate_Layer_2': 0.22088332518159876, 'dropout_rate_Layer_3': 0.21763008937109632, 'dropout_rate_Layer_4': 0.18385954973612592, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00048356359682890385, 'l1_Layer_2': 0.0028407222393467707, 'l1_Layer_3': 0.045234514859323935, 'l1_Layer_4': 4.811266287324462e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 260, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 51.76% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:13:13,237]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:13:30,261]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:15:10,581]\u001b[0m Trial 851 finished with value: 6.593472107873062 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008430507965454117, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1822803121065973, 'dropout_rate_Layer_2': 0.2310216509123475, 'dropout_rate_Layer_3': 0.2231537103388845, 'dropout_rate_Layer_4': 0.17805349769274556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00048263732868861003, 'l1_Layer_2': 0.002674596518994343, 'l1_Layer_3': 0.04433862320792663, 'l1_Layer_4': 4.685740375748178e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 16.55% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.37 | sMAPE for Test Set is: 52.27% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:16:57,656]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:17:14,262]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:17:53,626]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:19:27,930]\u001b[0m Trial 855 finished with value: 6.612978684791197 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007710823902929917, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16823868112414123, 'dropout_rate_Layer_2': 0.221106727037528, 'dropout_rate_Layer_3': 0.22844561485033238, 'dropout_rate_Layer_4': 0.1723179349678127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006022706022093951, 'l1_Layer_2': 0.0033812665975568664, 'l1_Layer_3': 0.045171736960515546, 'l1_Layer_4': 6.9227394083546e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 185, 'n_units_Layer_4': 240}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 16.52% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.55 | sMAPE for Test Set is: 52.84% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:20:08,980]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:21:17,887]\u001b[0m Trial 857 finished with value: 6.553186173962925 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008813588480994846, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1846105317386157, 'dropout_rate_Layer_2': 0.21923420668134502, 'dropout_rate_Layer_3': 0.20406314117359267, 'dropout_rate_Layer_4': 0.18956577869003888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004651651158671218, 'l1_Layer_2': 0.004037270314293286, 'l1_Layer_3': 0.055840219564637826, 'l1_Layer_4': 4.137449791678601e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 190, 'n_units_Layer_4': 230}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.48% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.14 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:21:34,621]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:21:42,209]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:23:02,529]\u001b[0m Trial 860 finished with value: 6.550193957554342 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009461048452373754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.169544017135852, 'dropout_rate_Layer_2': 0.2336351398026177, 'dropout_rate_Layer_3': 0.22727579127193193, 'dropout_rate_Layer_4': 0.19043357624563978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006073267628595794, 'l1_Layer_2': 0.0025916931691069736, 'l1_Layer_3': 0.035560116883655846, 'l1_Layer_4': 6.708324287776629e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195, 'n_units_Layer_4': 250}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 16.46% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 51.71% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:24:48,590]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:24:55,005]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:26:59,065]\u001b[0m Trial 863 finished with value: 6.491919610193989 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006644161763883796, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16639504616845632, 'dropout_rate_Layer_2': 0.2343306245910306, 'dropout_rate_Layer_3': 0.2271104764706942, 'dropout_rate_Layer_4': 0.18928091475101222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006257647535997685, 'l1_Layer_2': 0.0020810057910549996, 'l1_Layer_3': 0.05797527351096333, 'l1_Layer_4': 6.851906873657463e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 185, 'n_units_Layer_4': 255}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 51.45% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:28:49,775]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:29:04,001]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:29:21,556]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:29:29,537]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:30:10,633]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:30:26,573]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:31:06,494]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:32:09,598]\u001b[0m Trial 871 finished with value: 5.356800351720061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007718210411718611, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09771570584373195, 'dropout_rate_Layer_2': 0.25596825870092266, 'dropout_rate_Layer_3': 0.04386846859348878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046687726106041464, 'l1_Layer_2': 2.0459315624175936e-05, 'l1_Layer_3': 1.3930003103247067e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 45.94% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:32:17,656]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:32:25,127]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:33:12,932]\u001b[0m Trial 874 finished with value: 5.42978979892127 and parameters: {'n_hidden': 3, 'learning_rate': 0.001029828617162571, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03639472028403688, 'dropout_rate_Layer_2': 0.39915056434133284, 'dropout_rate_Layer_3': 0.065313308663133, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012929033637651774, 'l1_Layer_2': 2.526512339644406e-05, 'l1_Layer_3': 1.4360344808524936e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 150}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 13.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 47.84% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:33:18,534]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:33:25,843]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:33:43,960]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:35:02,371]\u001b[0m Trial 878 finished with value: 6.532851351492899 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010050363157845805, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16617026187851047, 'dropout_rate_Layer_2': 0.22599893216118383, 'dropout_rate_Layer_3': 0.2142035905477167, 'dropout_rate_Layer_4': 0.17948152070698262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004197919981188967, 'l1_Layer_2': 0.0031718986239999258, 'l1_Layer_3': 0.026968309204738524, 'l1_Layer_4': 4.1398131001648805e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200, 'n_units_Layer_4': 245}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.11 | sMAPE for Test Set is: 51.58% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:36:34,153]\u001b[0m Trial 879 finished with value: 6.558711805849768 and parameters: {'n_hidden': 4, 'learning_rate': 0.001027806992605844, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1645368960132447, 'dropout_rate_Layer_2': 0.21612591474687615, 'dropout_rate_Layer_3': 0.2021601313635396, 'dropout_rate_Layer_4': 0.17713895051968082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00040406834634750276, 'l1_Layer_2': 0.004147055160921153, 'l1_Layer_3': 0.02673800906352558, 'l1_Layer_4': 3.3753854345644076e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200, 'n_units_Layer_4': 250}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 16.50% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.88 | sMAPE for Test Set is: 53.88% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:36:42,485]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:37:54,405]\u001b[0m Trial 881 finished with value: 6.498169750394768 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007959410559298402, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16955652320431314, 'dropout_rate_Layer_2': 0.23548963401673284, 'dropout_rate_Layer_3': 0.23118865901093175, 'dropout_rate_Layer_4': 0.1997922932526211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005776515170430512, 'l1_Layer_2': 0.0024406477613474675, 'l1_Layer_3': 0.03308499438676971, 'l1_Layer_4': 4.129541141815901e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195, 'n_units_Layer_4': 245}. Best is trial 721 with value: 5.241306146167955.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 51.60% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:37:59,963]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:38:36,565]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:38:54,081]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:09,958]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:39:52,052]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:41:17,560]\u001b[0m Trial 887 finished with value: 5.179240364180375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007903836599608448, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06572010771703157, 'dropout_rate_Layer_2': 0.26979434207862035, 'dropout_rate_Layer_3': 0.048014032828226444, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015088529229384021, 'l1_Layer_2': 2.1895016461239418e-05, 'l1_Layer_3': 1.616647610430498e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 13.42% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 46.40% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:41:25,636]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:42:51,258]\u001b[0m Trial 889 finished with value: 6.4924920116101354 and parameters: {'n_hidden': 4, 'learning_rate': 0.000770534929697002, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15650589584723987, 'dropout_rate_Layer_2': 0.22483682534173843, 'dropout_rate_Layer_3': 0.22499110724272198, 'dropout_rate_Layer_4': 0.19172359073149256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005382772613093023, 'l1_Layer_2': 0.002355958503905234, 'l1_Layer_3': 0.026292779084940526, 'l1_Layer_4': 5.1743424878125015e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 185, 'n_units_Layer_4': 235}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 16.34% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 51.37% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:42:57,853]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:23,853]\u001b[0m Trial 891 finished with value: 6.534125387752968 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007707249472938104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1579136173426329, 'dropout_rate_Layer_2': 0.2372450611482168, 'dropout_rate_Layer_3': 0.23225606848575583, 'dropout_rate_Layer_4': 0.17914040963635708, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000716425154417541, 'l1_Layer_2': 0.0024364913957320173, 'l1_Layer_3': 0.026393777019108736, 'l1_Layer_4': 5.2528271129250516e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185, 'n_units_Layer_4': 235}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 16.43% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 51.13% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:44:31,996]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:44:46,459]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:45:27,708]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:47:03,166]\u001b[0m Trial 895 finished with value: 6.499343739479393 and parameters: {'n_hidden': 4, 'learning_rate': 0.000726091675208856, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15564856521915402, 'dropout_rate_Layer_2': 0.23808107782302512, 'dropout_rate_Layer_3': 0.22770975094333049, 'dropout_rate_Layer_4': 0.1604147352082687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006966407016103722, 'l1_Layer_2': 0.002107887579727878, 'l1_Layer_3': 0.026611732358160875, 'l1_Layer_4': 5.431651658499562e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180, 'n_units_Layer_4': 245}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 16.32% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.80 | sMAPE for Test Set is: 50.49% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:48:40,581]\u001b[0m Trial 896 finished with value: 6.471805152120537 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006546171025785488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.158762364641818, 'dropout_rate_Layer_2': 0.23241793817866357, 'dropout_rate_Layer_3': 0.2347352726721548, 'dropout_rate_Layer_4': 0.1626303558951232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006987386837579908, 'l1_Layer_2': 0.0019065756720476675, 'l1_Layer_3': 0.026422143581889025, 'l1_Layer_4': 7.349653964728929e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180, 'n_units_Layer_4': 245}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 16.31% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.74 | sMAPE for Test Set is: 50.23% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:48:48,674]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:49:05,329]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:50:41,945]\u001b[0m Trial 899 finished with value: 6.5152378734840815 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005924599526887829, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15543584507442482, 'dropout_rate_Layer_2': 0.23927514918499881, 'dropout_rate_Layer_3': 0.23502971281719837, 'dropout_rate_Layer_4': 0.16304351001198175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008852464584287161, 'l1_Layer_2': 0.002144271260746782, 'l1_Layer_3': 0.02589757252174101, 'l1_Layer_4': 8.09328596238604e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 50.93% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:51:45,588]\u001b[0m Trial 900 finished with value: 5.236499191919963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007001315063731013, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0751774784436623, 'dropout_rate_Layer_2': 0.26552786905044035, 'dropout_rate_Layer_3': 0.010559189208918955, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009594164125973065, 'l1_Layer_2': 1.9360955512423583e-05, 'l1_Layer_3': 2.1241108990496213e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 13.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 45.96% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:52:24,846]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:15,498]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:30,699]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:46,550]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:54:56,689]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:41,121]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:55:48,801]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:57:17,413]\u001b[0m Trial 908 finished with value: 5.234021844828372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006992825319142422, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06326669869622499, 'dropout_rate_Layer_2': 0.25195401644711973, 'dropout_rate_Layer_3': 0.012780927534161476, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018268797368512879, 'l1_Layer_2': 1.9927954332088686e-05, 'l1_Layer_3': 2.0232582729416226e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 46.36% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:58:04,608]\u001b[0m Trial 909 finished with value: 5.415011804485677 and parameters: {'n_hidden': 3, 'learning_rate': 0.001040119940227218, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01728176310854316, 'dropout_rate_Layer_2': 0.3618163849109106, 'dropout_rate_Layer_3': 0.10413536838981513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000333011398586112, 'l1_Layer_2': 2.4752973733963953e-05, 'l1_Layer_3': 1.7093008479905353e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 290, 'n_units_Layer_3': 120}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.87% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 40.29% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 18:58:26,909]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 18:58:35,750]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:26,154]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:00:34,376]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:02:37,829]\u001b[0m Trial 914 finished with value: 6.4706967351600895 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005647465854093314, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15394148824087664, 'dropout_rate_Layer_2': 0.20949281588789637, 'dropout_rate_Layer_3': 0.2290395369898925, 'dropout_rate_Layer_4': 0.19950440626517932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003682710352743292, 'l1_Layer_2': 0.0023107948271058605, 'l1_Layer_3': 0.028715732883056684, 'l1_Layer_4': 5.612509041480023e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180, 'n_units_Layer_4': 240}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 16.30% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 51.20% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:02:45,850]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:24,240]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:32,028]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:03:39,349]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:04:19,506]\u001b[0m Trial 919 finished with value: 5.468679078123646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010642788935258684, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016395523675177954, 'dropout_rate_Layer_2': 0.36764156831558104, 'dropout_rate_Layer_3': 0.08539216000364594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.603210569784935e-05, 'l1_Layer_2': 1.5930716088614653e-05, 'l1_Layer_3': 1.7397084310203793e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 120}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.26 | sMAPE for Test Set is: 40.76% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:04:27,114]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:05:38,165]\u001b[0m Trial 921 finished with value: 5.419101886497308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009919067528794544, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019953459558749703, 'dropout_rate_Layer_2': 0.37051513221848986, 'dropout_rate_Layer_3': 0.10698395410404318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.504685932484089e-05, 'l1_Layer_2': 1.50661990996811e-05, 'l1_Layer_3': 1.0119186874268422e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 300, 'n_units_Layer_3': 115}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.14 | sMAPE for Test Set is: 39.61% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:07:49,397]\u001b[0m Trial 922 finished with value: 6.512866548657196 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005890033894348138, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15431622829192096, 'dropout_rate_Layer_2': 0.21054303396770385, 'dropout_rate_Layer_3': 0.22964118512143314, 'dropout_rate_Layer_4': 0.19890978060475092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007134168943330882, 'l1_Layer_2': 0.0019014368742715346, 'l1_Layer_3': 0.02345597406237781, 'l1_Layer_4': 4.201815975094254e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180, 'n_units_Layer_4': 225}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 16.36% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 51.57% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:09:41,119]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:09:59,305]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:06,944]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:10:22,932]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:11:09,251]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:12:47,127]\u001b[0m Trial 928 finished with value: 6.515850095633467 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005595059733499482, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14767044348654496, 'dropout_rate_Layer_2': 0.24226795468625176, 'dropout_rate_Layer_3': 0.2359727406470696, 'dropout_rate_Layer_4': 0.17132721145415833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009384909772182096, 'l1_Layer_2': 0.0024179488540937836, 'l1_Layer_3': 0.024648205172623627, 'l1_Layer_4': 4.0860383840895454e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170, 'n_units_Layer_4': 240}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 16.35% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 12.03 | sMAPE for Test Set is: 51.36% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:12:54,740]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:15:47,816]\u001b[0m Trial 930 finished with value: 5.502398880278375 and parameters: {'n_hidden': 4, 'learning_rate': 0.000558533529893018, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1458066722152766, 'dropout_rate_Layer_2': 0.2121451417414423, 'dropout_rate_Layer_3': 0.2364854399110915, 'dropout_rate_Layer_4': 0.16252980981209864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005567287973357657, 'l1_Layer_2': 0.0017043376165917742, 'l1_Layer_3': 0.0004117284158047963, 'l1_Layer_4': 3.9505258901216765e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170, 'n_units_Layer_4': 250}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 14.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 47.92% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:18:01,725]\u001b[0m Trial 931 finished with value: 5.443591837931834 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005741351704153043, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14432973937733806, 'dropout_rate_Layer_2': 0.20540550251403, 'dropout_rate_Layer_3': 0.23539936760499786, 'dropout_rate_Layer_4': 0.1510026647899126, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009018703247212762, 'l1_Layer_2': 0.001698219844085903, 'l1_Layer_3': 9.611135163308462e-05, 'l1_Layer_4': 3.274073380690337e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 47.49% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:18:09,522]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:17,557]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:18:27,894]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:02,852]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:19:08,287]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:21:58,707]\u001b[0m Trial 937 finished with value: 5.509145792702722 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005634810937175935, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15075090530985483, 'dropout_rate_Layer_2': 0.20075824695545505, 'dropout_rate_Layer_3': 0.23655915538453653, 'dropout_rate_Layer_4': 0.1512159718948778, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009740426011160667, 'l1_Layer_2': 0.0016609113845113034, 'l1_Layer_3': 3.361202243662757e-05, 'l1_Layer_4': 2.8305519749518463e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 250}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.99 | sMAPE for Test Set is: 48.44% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:22:06,052]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:24:38,341]\u001b[0m Trial 939 finished with value: 5.399832022123497 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005950005866138932, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14796931945877656, 'dropout_rate_Layer_2': 0.20883125302480166, 'dropout_rate_Layer_3': 0.23986560169533608, 'dropout_rate_Layer_4': 0.14835011040720777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009566306812833739, 'l1_Layer_2': 0.001617982631499676, 'l1_Layer_3': 2.5995481140421878e-05, 'l1_Layer_4': 2.9450882882468933e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 47.53% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:26:18,819]\u001b[0m Trial 940 finished with value: 5.537036989427811 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005848067651978157, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14307692408415315, 'dropout_rate_Layer_2': 0.1960476892205229, 'dropout_rate_Layer_3': 0.2365889865452985, 'dropout_rate_Layer_4': 0.14772988623066607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009476088615380568, 'l1_Layer_2': 0.0015153140055629473, 'l1_Layer_3': 2.3717660748729944e-05, 'l1_Layer_4': 2.7846152004124583e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.54 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 46.84% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:26:35,484]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:28:11,523]\u001b[0m Trial 942 finished with value: 5.587909388573254 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005968980139063524, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14000808407382342, 'dropout_rate_Layer_2': 0.1962042160871156, 'dropout_rate_Layer_3': 0.23591961022215613, 'dropout_rate_Layer_4': 0.1477213403121272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010543656373638692, 'l1_Layer_2': 0.0016736608271477812, 'l1_Layer_3': 3.9296313169384954e-05, 'l1_Layer_4': 2.6228887011588322e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.59 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 47.73% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:28:55,153]\u001b[0m Trial 943 finished with value: 5.390069070697053 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011162068428329087, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07973112639196944, 'dropout_rate_Layer_2': 0.28776095877742774, 'dropout_rate_Layer_3': 0.026758646256615275, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014101150384835013, 'l1_Layer_2': 4.708456786545259e-05, 'l1_Layer_3': 1.848390297010922e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 47.48% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:30:27,177]\u001b[0m Trial 944 finished with value: 5.547326148928211 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005150105742617459, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14183131318985123, 'dropout_rate_Layer_2': 0.18810420834837135, 'dropout_rate_Layer_3': 0.23617027458244688, 'dropout_rate_Layer_4': 0.14679760258886468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010516115775734893, 'l1_Layer_2': 0.0015603356538149355, 'l1_Layer_3': 2.6324594202663487e-05, 'l1_Layer_4': 2.6856321332734792e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.55 | sMAPE for Validation Set is: 14.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.53% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:30:34,718]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:13,446]\u001b[0m Trial 946 finished with value: 5.402240046833259 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005041556410452324, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14091088020879977, 'dropout_rate_Layer_2': 0.19690696887341974, 'dropout_rate_Layer_3': 0.23956292044096006, 'dropout_rate_Layer_4': 0.15164183016255786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011022112504378236, 'l1_Layer_2': 0.0013756507651044784, 'l1_Layer_3': 3.4781003365814285e-05, 'l1_Layer_4': 2.7465729263450753e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 47.65% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:33:29,202]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:36,959]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:44,893]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:52,916]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:33:59,966]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:21,157]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:34:51,822]\u001b[0m Trial 953 finished with value: 5.381000848075087 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016674090107018597, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011664432780839886, 'dropout_rate_Layer_2': 0.37367011421317853, 'dropout_rate_Layer_3': 0.1021280707696996, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000131455882724976, 'l1_Layer_2': 2.092960462163925e-05, 'l1_Layer_3': 2.436699082708218e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 160}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 40.22% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:37:46,844]\u001b[0m Trial 954 finished with value: 5.501160409215221 and parameters: {'n_hidden': 4, 'learning_rate': 0.000503351980159514, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14532884243582883, 'dropout_rate_Layer_2': 0.18948740405448208, 'dropout_rate_Layer_3': 0.24043940207282008, 'dropout_rate_Layer_4': 0.14669564752948894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010931416301579945, 'l1_Layer_2': 0.001575991110235094, 'l1_Layer_3': 3.6967900165199786e-05, 'l1_Layer_4': 2.1767770497259233e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 14.01% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.06 | sMAPE for Test Set is: 48.46% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:37:55,947]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:37,643]\u001b[0m Trial 956 finished with value: 5.434686327313578 and parameters: {'n_hidden': 4, 'learning_rate': 0.000500780613064555, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14506573467440598, 'dropout_rate_Layer_2': 0.18819580938790087, 'dropout_rate_Layer_3': 0.2398971371132393, 'dropout_rate_Layer_4': 0.14451388644429908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011419788540876048, 'l1_Layer_2': 0.0015714936375103737, 'l1_Layer_3': 3.8661514561953005e-05, 'l1_Layer_4': 2.5536003335317005e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 46.77% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:40:46,017]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:40:54,141]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:41:03,697]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:44:08,675]\u001b[0m Trial 960 finished with value: 5.39112099270137 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005087521163512701, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14365696344787446, 'dropout_rate_Layer_2': 0.1856942129235228, 'dropout_rate_Layer_3': 0.24262944260667685, 'dropout_rate_Layer_4': 0.14714366036095786, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010994956356640267, 'l1_Layer_2': 0.0015588330936851262, 'l1_Layer_3': 3.451207028291494e-05, 'l1_Layer_4': 2.58793009917469e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 47.96% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:46:54,377]\u001b[0m Trial 961 finished with value: 5.38858398030812 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005057486173873292, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1434922395352133, 'dropout_rate_Layer_2': 0.1839434036943072, 'dropout_rate_Layer_3': 0.23818826294820317, 'dropout_rate_Layer_4': 0.1434777788405631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012032858646801037, 'l1_Layer_2': 0.0015699363016431927, 'l1_Layer_3': 3.749556888605044e-05, 'l1_Layer_4': 2.025806451861242e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170, 'n_units_Layer_4': 270}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 46.47% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:47:57,591]\u001b[0m Trial 962 finished with value: 5.314184715001943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008714205309158259, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10730170193627553, 'dropout_rate_Layer_2': 0.27696750248533386, 'dropout_rate_Layer_3': 0.011675541985385264, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008431467443527496, 'l1_Layer_2': 1.5455721509047593e-05, 'l1_Layer_3': 2.7676105847080284e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 280, 'n_units_Layer_3': 300}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.47 | sMAPE for Test Set is: 46.50% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:49:51,047]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:49:58,665]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:50:06,576]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:52:10,055]\u001b[0m Trial 966 finished with value: 5.495834654753878 and parameters: {'n_hidden': 4, 'learning_rate': 0.000500006942567354, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14647796356295945, 'dropout_rate_Layer_2': 0.18319986375931796, 'dropout_rate_Layer_3': 0.23850333520770237, 'dropout_rate_Layer_4': 0.15057719877099643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010506168986048278, 'l1_Layer_2': 0.0016024229609418498, 'l1_Layer_3': 3.6468733008085955e-05, 'l1_Layer_4': 2.640111379440558e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.50 | sMAPE for Validation Set is: 14.07% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 46.65% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:53:58,900]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:04,105]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:54:19,404]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:55:38,198]\u001b[0m Trial 970 finished with value: 5.265869585442143 and parameters: {'n_hidden': 3, 'learning_rate': 0.000660583543955719, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11100659764033186, 'dropout_rate_Layer_2': 0.2513053871549578, 'dropout_rate_Layer_3': 0.021697827197692802, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012340839929545452, 'l1_Layer_2': 1.1609741210037556e-05, 'l1_Layer_3': 4.5655759358644814e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 46.82% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:55:54,299]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:35,136]\u001b[0m Trial 972 finished with value: 5.5699019086072346 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006210880466403559, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14874947148804413, 'dropout_rate_Layer_2': 0.18997313001693888, 'dropout_rate_Layer_3': 0.23929149636681823, 'dropout_rate_Layer_4': 0.1476595629189583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001351878138558457, 'l1_Layer_2': 0.0016595523755425577, 'l1_Layer_3': 3.112583208916244e-05, 'l1_Layer_4': 1.878453053000531e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 14.14% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 48.03% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 19:57:43,059]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:57:50,671]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 19:59:41,949]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:00:33,313]\u001b[0m Trial 976 finished with value: 5.436114793081301 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006826137906644942, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07949086462425556, 'dropout_rate_Layer_2': 0.25843962987680275, 'dropout_rate_Layer_3': 0.007035429633139259, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017207621562835974, 'l1_Layer_2': 1.164590324531715e-05, 'l1_Layer_3': 1.0554436650283494e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.93% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 48.57% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:02:24,747]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:02:33,668]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:09,585]\u001b[0m Trial 979 finished with value: 5.558785248499787 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006315464679838786, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13380570973493577, 'dropout_rate_Layer_2': 0.19799971027968494, 'dropout_rate_Layer_3': 0.15534187065070446, 'dropout_rate_Layer_4': 0.14721373481119868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010062217649399882, 'l1_Layer_2': 0.001607209065478863, 'l1_Layer_3': 3.728210114724949e-05, 'l1_Layer_4': 1.7159108203338883e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175, 'n_units_Layer_4': 270}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 14.15% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.52 | sMAPE for Test Set is: 46.65% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:04:18,084]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:04:26,551]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:06:14,066]\u001b[0m Trial 982 finished with value: 5.5660258086167245 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005792407953571083, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1479219939453555, 'dropout_rate_Layer_2': 0.18602435546845444, 'dropout_rate_Layer_3': 0.18324052355341977, 'dropout_rate_Layer_4': 0.13909162956397492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009516396285785448, 'l1_Layer_2': 0.001260875028484934, 'l1_Layer_3': 4.646648656070179e-05, 'l1_Layer_4': 1.9414616361368957e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175, 'n_units_Layer_4': 270}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 14.18% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 48.24% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:08:04,377]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:08:19,487]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:10:10,147]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:11:43,708]\u001b[0m Trial 986 finished with value: 5.508175672792189 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006115417252000164, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13319948246083668, 'dropout_rate_Layer_2': 0.1968771775951672, 'dropout_rate_Layer_3': 0.18790796871970664, 'dropout_rate_Layer_4': 0.1335291117925513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012894874993064518, 'l1_Layer_2': 0.0016867410151169748, 'l1_Layer_3': 2.4102244918653132e-05, 'l1_Layer_4': 2.049225072343717e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.78 | sMAPE for Test Set is: 47.70% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:13:19,107]\u001b[0m Trial 987 finished with value: 5.508032501716188 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006383603839013307, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13168376421759048, 'dropout_rate_Layer_2': 0.19769742267094279, 'dropout_rate_Layer_3': 0.1890507491494435, 'dropout_rate_Layer_4': 0.14033314217540752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013125056227057557, 'l1_Layer_2': 0.0017026149079489477, 'l1_Layer_3': 2.248314139740509e-05, 'l1_Layer_4': 2.1193345515289507e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.04% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 47.11% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:15:08,607]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:14,491]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:21,785]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:15:47,421]\u001b[0m Trial 991 finished with value: 5.404556878984973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016209702007614075, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02913912260490588, 'dropout_rate_Layer_2': 0.3576340284213362, 'dropout_rate_Layer_3': 0.12991478874463297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.010064145853281e-05, 'l1_Layer_2': 2.206589805057002e-05, 'l1_Layer_3': 2.1288953398138472e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 38.90% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:16:38,571]\u001b[0m Trial 992 finished with value: 5.597387772343457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008350064197315176, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07281664552419699, 'dropout_rate_Layer_2': 0.25025677797616935, 'dropout_rate_Layer_3': 0.0312973847843012, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002766513975594451, 'l1_Layer_2': 1.0094182305313922e-05, 'l1_Layer_3': 2.4717562758325323e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.60 | sMAPE for Validation Set is: 14.25% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 48.82% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:18:19,392]\u001b[0m Trial 993 finished with value: 5.514192493596778 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006242133846274776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14755855011294547, 'dropout_rate_Layer_2': 0.18656601924032923, 'dropout_rate_Layer_3': 0.1410537103135428, 'dropout_rate_Layer_4': 0.1519251170905693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012269957924344024, 'l1_Layer_2': 0.0016566489978321578, 'l1_Layer_3': 2.9414394850338444e-05, 'l1_Layer_4': 2.278008341638981e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 46.65% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:20:53,735]\u001b[0m Trial 994 finished with value: 5.386664235689564 and parameters: {'n_hidden': 4, 'learning_rate': 0.000622601542324421, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14732764318417618, 'dropout_rate_Layer_2': 0.18504892240420803, 'dropout_rate_Layer_3': 0.18545879354145714, 'dropout_rate_Layer_4': 0.15332885879866434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001295464010118585, 'l1_Layer_2': 0.0016809375287836824, 'l1_Layer_3': 2.8188073660920007e-05, 'l1_Layer_4': 2.2656088898293045e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.81% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 46.29% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:23:34,396]\u001b[0m Trial 995 finished with value: 5.478160808117475 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006278807144047651, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.148631532167931, 'dropout_rate_Layer_2': 0.18412107855932794, 'dropout_rate_Layer_3': 0.18072914451311828, 'dropout_rate_Layer_4': 0.15083142199620655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013756638972893523, 'l1_Layer_2': 0.0014788794716837257, 'l1_Layer_3': 1.92806786758795e-05, 'l1_Layer_4': 2.2042158709550978e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 47.72% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:25:26,631]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:30,307]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:25:58,163]\u001b[0m Trial 998 finished with value: 5.386896728858822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017017679009076643, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030264878895981714, 'dropout_rate_Layer_2': 0.3571307054739923, 'dropout_rate_Layer_3': 0.12610532341132044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015128546497344131, 'l1_Layer_2': 1.0662111007139376e-05, 'l1_Layer_3': 1.9913725612830818e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.82% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.37 | sMAPE for Test Set is: 40.82% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:26:29,951]\u001b[0m Trial 999 finished with value: 5.471507747002376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016330125950554766, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03145218944216124, 'dropout_rate_Layer_2': 0.35786406655323577, 'dropout_rate_Layer_3': 0.1292791174855211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.562668350534741e-05, 'l1_Layer_2': 1.170209993053944e-05, 'l1_Layer_3': 1.2212428046372418e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.47 | sMAPE for Validation Set is: 13.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.50 | sMAPE for Test Set is: 41.95% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:28:07,708]\u001b[0m Trial 1000 finished with value: 5.433570338778433 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005064230638535467, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14657976013744992, 'dropout_rate_Layer_2': 0.19029988289525587, 'dropout_rate_Layer_3': 0.14977817413612926, 'dropout_rate_Layer_4': 0.15278655516203998, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001461634160193555, 'l1_Layer_2': 0.0013830651201880472, 'l1_Layer_3': 3.477191662982985e-05, 'l1_Layer_4': 1.5027181167952761e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165, 'n_units_Layer_4': 270}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 13.94% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 48.09% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:28:15,703]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:28:25,452]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:03,722]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:11,653]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:21,755]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:30,053]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:45,681]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:29:51,526]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:33:35,786]\u001b[0m Trial 1009 finished with value: 5.336710690528542 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006450876554834694, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1298191832668081, 'dropout_rate_Layer_2': 0.17330844466202486, 'dropout_rate_Layer_3': 0.18632865922460623, 'dropout_rate_Layer_4': 0.12829906784103434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000993568545063442, 'l1_Layer_2': 0.0014014623531921474, 'l1_Layer_3': 2.9392925775727348e-05, 'l1_Layer_4': 1.4347944376396248e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 46.17% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:33:51,768]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:34:20,295]\u001b[0m Trial 1011 finished with value: 5.39786442526781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016682318803384255, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012043559975905473, 'dropout_rate_Layer_2': 0.35504897701592414, 'dropout_rate_Layer_3': 0.1485429285217433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011029896127630085, 'l1_Layer_2': 1.0152573434630308e-05, 'l1_Layer_3': 1.9395198350312588e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 175}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 40.05% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:36:01,543]\u001b[0m Trial 1012 finished with value: 5.441330797161691 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006520579153905518, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1280254639376699, 'dropout_rate_Layer_2': 0.16813621177360322, 'dropout_rate_Layer_3': 0.1868515352361291, 'dropout_rate_Layer_4': 0.12606295448788185, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010329214699697712, 'l1_Layer_2': 0.0014111347542162267, 'l1_Layer_3': 3.0274079894484893e-05, 'l1_Layer_4': 1.4026227018989562e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 165, 'n_units_Layer_4': 265}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.17 | sMAPE for Test Set is: 49.07% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:37:48,239]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:37:56,722]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:38:05,453]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:38:46,432]\u001b[0m Trial 1016 finished with value: 5.419291268473896 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006274467833006477, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08660315000273172, 'dropout_rate_Layer_2': 0.2747499376750196, 'dropout_rate_Layer_3': 0.003629229759239419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012151607338780107, 'l1_Layer_2': 1.5027409428910792e-05, 'l1_Layer_3': 1.2762669800355404e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 46.14% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:39:30,660]\u001b[0m Trial 1017 finished with value: 5.453813556381665 and parameters: {'n_hidden': 3, 'learning_rate': 0.002107989662775806, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011955042635017815, 'dropout_rate_Layer_2': 0.3089723700152914, 'dropout_rate_Layer_3': 0.1471224983003586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.310306592576243e-05, 'l1_Layer_2': 1.099042043538985e-05, 'l1_Layer_3': 1.8807387861410264e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.97 | sMAPE for Test Set is: 38.68% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:39:37,804]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:42:31,416]\u001b[0m Trial 1019 finished with value: 5.506112697608422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005644820948250064, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2785715828267846, 'dropout_rate_Layer_2': 0.19185332661682583, 'dropout_rate_Layer_3': 0.3440114837186696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000978111858465182, 'l1_Layer_2': 0.00027032754858838, 'l1_Layer_3': 1.9823883441130746e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.11% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 47.80% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:44:44,682]\u001b[0m Trial 1020 finished with value: 5.3017309680198155 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006526484214106518, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13657693418645733, 'dropout_rate_Layer_2': 0.18997429202553048, 'dropout_rate_Layer_3': 0.1782659865622924, 'dropout_rate_Layer_4': 0.15478676535761227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011444658349441567, 'l1_Layer_2': 0.0013874884453267406, 'l1_Layer_3': 4.751190133622824e-05, 'l1_Layer_4': 1.2177355152937463e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 46.97% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:44:52,989]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:45:02,097]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:46:48,009]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:46:53,873]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:46:59,379]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:47:07,828]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:47:35,448]\u001b[0m Trial 1027 finished with value: 5.46278141871289 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015917819900864733, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002445622785013809, 'dropout_rate_Layer_2': 0.3279541579027728, 'dropout_rate_Layer_3': 0.12624571577559834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015210301622683832, 'l1_Layer_2': 1.4695179091397656e-05, 'l1_Layer_3': 2.0322856026543527e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 195}. Best is trial 887 with value: 5.179240364180375.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.23 | sMAPE for Test Set is: 39.87% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:51:34,774]\u001b[0m Trial 1028 finished with value: 5.128994690821378 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005713583842334772, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12445857105960448, 'dropout_rate_Layer_2': 0.16191438744622946, 'dropout_rate_Layer_3': 0.1633563599114167, 'dropout_rate_Layer_4': 0.12219115979431597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009078009883033397, 'l1_Layer_2': 0.0016867592807107085, 'l1_Layer_3': 5.5226859488491123e-05, 'l1_Layer_4': 1.565995889347553e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 13.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.35 | sMAPE for Test Set is: 46.40% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:51:43,356]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:53:34,346]\u001b[0m Trial 1030 finished with value: 5.184331946355227 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005570588058698446, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11032915961963474, 'dropout_rate_Layer_2': 0.24293982139504028, 'dropout_rate_Layer_3': 0.0780794467830047, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000731848973435643, 'l1_Layer_2': 1.2324387782981045e-05, 'l1_Layer_3': 4.9559976990689804e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 270}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.18 | sMAPE for Validation Set is: 13.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 46.48% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:53:41,452]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:53:46,961]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:53:55,454]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:54:22,771]\u001b[0m Trial 1034 finished with value: 5.688057666537482 and parameters: {'n_hidden': 3, 'learning_rate': 0.002778102109289816, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024510242531639706, 'dropout_rate_Layer_2': 0.34995908426159034, 'dropout_rate_Layer_3': 0.15802653984175072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010311758928312433, 'l1_Layer_2': 2.0566605242939167e-05, 'l1_Layer_3': 1.0099468855111784e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 14.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 41.32% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:57:32,961]\u001b[0m Trial 1035 finished with value: 5.242753871108788 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006875630133555959, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12329321071397259, 'dropout_rate_Layer_2': 0.1554379090352005, 'dropout_rate_Layer_3': 0.1474817446579659, 'dropout_rate_Layer_4': 0.1402589055004361, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011249051138752441, 'l1_Layer_2': 0.001734249725767259, 'l1_Layer_3': 6.290737372670418e-05, 'l1_Layer_4': 1.1517312025416965e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165, 'n_units_Layer_4': 280}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 13.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 46.57% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 20:57:40,465]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 20:59:07,091]\u001b[0m Trial 1037 finished with value: 5.2998032094380045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005514997985562602, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09360138617691305, 'dropout_rate_Layer_2': 0.24025821405792475, 'dropout_rate_Layer_3': 0.07450454331761613, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009443434806133664, 'l1_Layer_2': 1.6810309337999775e-05, 'l1_Layer_3': 4.6213978435984915e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.32 | sMAPE for Test Set is: 46.15% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:00:46,965]\u001b[0m Trial 1038 finished with value: 5.479346762609215 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006248309116940253, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12345106542224157, 'dropout_rate_Layer_2': 0.1649080523275338, 'dropout_rate_Layer_3': 0.1496741980238199, 'dropout_rate_Layer_4': 0.12516618180344988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011031047951419021, 'l1_Layer_2': 0.0017644294077462294, 'l1_Layer_3': 1.825249930706634e-05, 'l1_Layer_4': 1.0370897402576402e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165, 'n_units_Layer_4': 260}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.48 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 48.99% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:00:52,882]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:00:58,546]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:01:06,618]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:01:12,576]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:01:51,194]\u001b[0m Trial 1043 finished with value: 5.4881825845616445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016578289203451712, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04889981871762483, 'dropout_rate_Layer_2': 0.3554207305130571, 'dropout_rate_Layer_3': 0.13816170466654093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.60908312085448e-05, 'l1_Layer_2': 1.0412387152424382e-05, 'l1_Layer_3': 2.3983693550323096e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.27 | sMAPE for Test Set is: 41.99% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:01:59,546]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:03:13,605]\u001b[0m Trial 1045 finished with value: 5.317572930795964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005484730170147953, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10874425055021907, 'dropout_rate_Layer_2': 0.23130451657679615, 'dropout_rate_Layer_3': 0.07561201047438901, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007830133273415962, 'l1_Layer_2': 1.695102351014616e-05, 'l1_Layer_3': 5.996478751370012e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 47.95% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:03:42,981]\u001b[0m Trial 1046 finished with value: 5.204110960318903 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012862553231173758, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010696158060535768, 'dropout_rate_Layer_2': 0.337098882065242, 'dropout_rate_Layer_3': 0.10349102035399989, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022117562618092698, 'l1_Layer_2': 1.9549912606934814e-05, 'l1_Layer_3': 1.7316192109610573e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 300, 'n_units_Layer_3': 205}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.20 | sMAPE for Validation Set is: 13.26% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 38.03% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:03:47,118]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:05:38,386]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:05:44,746]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:06:01,607]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:06:07,964]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:06:16,349]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:09:32,297]\u001b[0m Trial 1053 finished with value: 5.313600047065337 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006804746185778907, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15000173184276028, 'dropout_rate_Layer_2': 0.19000568010893082, 'dropout_rate_Layer_3': 0.1528748897860827, 'dropout_rate_Layer_4': 0.14312611130022296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001305951817559436, 'l1_Layer_2': 0.0017743589081174497, 'l1_Layer_3': 6.745359835241507e-05, 'l1_Layer_4': 2.2561581336956505e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165, 'n_units_Layer_4': 280}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.04 | sMAPE for Test Set is: 48.68% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:11:19,387]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:11:27,304]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:11:34,869]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:11:50,188]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:11:58,529]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:13:42,168]\u001b[0m Trial 1059 finished with value: 5.370175449932532 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006961025642724308, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15018134749909376, 'dropout_rate_Layer_2': 0.19433197312011072, 'dropout_rate_Layer_3': 0.15042650428525448, 'dropout_rate_Layer_4': 0.15842673425753806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008652636133725214, 'l1_Layer_2': 0.0018879982141975387, 'l1_Layer_3': 3.4523280838249704e-05, 'l1_Layer_4': 1.6716396528385197e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165, 'n_units_Layer_4': 255}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 13.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 47.83% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:15:29,704]\u001b[0m Trial 1060 finished with value: 5.459125008618588 and parameters: {'n_hidden': 4, 'learning_rate': 0.000715296196027063, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14902757514210588, 'dropout_rate_Layer_2': 0.18221262452128115, 'dropout_rate_Layer_3': 0.15410587370477205, 'dropout_rate_Layer_4': 0.1599786523296329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011335686734457123, 'l1_Layer_2': 0.0018307731253308416, 'l1_Layer_3': 3.609979677053857e-05, 'l1_Layer_4': 1.7238172475817706e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 14.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 47.07% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:16:58,319]\u001b[0m Trial 1061 finished with value: 5.238698838871506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007148418993120746, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09724570415533829, 'dropout_rate_Layer_2': 0.23322047022799047, 'dropout_rate_Layer_3': 0.07362555978131444, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007864896567319117, 'l1_Layer_2': 1.7694527536612938e-05, 'l1_Layer_3': 4.1206519311911126e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.24 | sMAPE for Validation Set is: 13.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.73 | sMAPE for Test Set is: 47.40% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:20:06,545]\u001b[0m Trial 1062 finished with value: 5.29661545907985 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007261801205000273, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12930948959756214, 'dropout_rate_Layer_2': 0.16476724568303197, 'dropout_rate_Layer_3': 0.14956443854824739, 'dropout_rate_Layer_4': 0.15996240142654006, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008669493923435662, 'l1_Layer_2': 0.0018709158149028, 'l1_Layer_3': 3.7699837282395623e-05, 'l1_Layer_4': 1.5806983379686798e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155, 'n_units_Layer_4': 255}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.30 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 47.98% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:20:15,855]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:21:41,547]\u001b[0m Trial 1064 finished with value: 5.273929283010672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006921840759318092, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11244561993167321, 'dropout_rate_Layer_2': 0.2307525320777917, 'dropout_rate_Layer_3': 0.07396859056786505, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007994588619286009, 'l1_Layer_2': 2.5962186889614197e-05, 'l1_Layer_3': 4.6143527882203704e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 46.48% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:21:58,387]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:23:01,342]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:23:06,528]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:23:14,392]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:25:31,726]\u001b[0m Trial 1069 finished with value: 5.267702228983022 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007047220057133977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13494712898371802, 'dropout_rate_Layer_2': 0.144867347060908, 'dropout_rate_Layer_3': 0.16169531768061307, 'dropout_rate_Layer_4': 0.15765784350572606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014204434482781446, 'l1_Layer_2': 0.0017970599973074143, 'l1_Layer_3': 3.766355054384435e-05, 'l1_Layer_4': 1.4287002815256082e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155, 'n_units_Layer_4': 280}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 47.15% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:25:40,817]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:25:48,812]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:27:17,761]\u001b[0m Trial 1072 finished with value: 5.415046468322726 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007350097962249554, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1354941567903043, 'dropout_rate_Layer_2': 0.16627803631541455, 'dropout_rate_Layer_3': 0.15741734900467702, 'dropout_rate_Layer_4': 0.15820000504827753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008307406374410489, 'l1_Layer_2': 0.0009807209209480164, 'l1_Layer_3': 6.84321425678934e-05, 'l1_Layer_4': 1.6252711180649076e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155, 'n_units_Layer_4': 290}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 49.11% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:27:25,486]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:27:33,990]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:27:40,412]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:28:03,952]\u001b[0m Trial 1076 finished with value: 5.437078233700336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012995151999455551, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014517484952165989, 'dropout_rate_Layer_2': 0.3346965069031494, 'dropout_rate_Layer_3': 0.10224457170072436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003044421890805007, 'l1_Layer_2': 2.0980832046399694e-05, 'l1_Layer_3': 1.6400682552898064e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 300, 'n_units_Layer_3': 200}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.07 | sMAPE for Test Set is: 39.10% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:28:12,777]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:30:04,170]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:32:47,407]\u001b[0m Trial 1079 finished with value: 5.289270819170292 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005458601237911333, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14157397148205722, 'dropout_rate_Layer_2': 0.14175771040810356, 'dropout_rate_Layer_3': 0.166572522735781, 'dropout_rate_Layer_4': 0.12369215810873413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014741299554342543, 'l1_Layer_2': 0.0013799616809813348, 'l1_Layer_3': 4.1456019353644356e-05, 'l1_Layer_4': 1.5436576050162672e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165, 'n_units_Layer_4': 260}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.29 | sMAPE for Validation Set is: 13.72% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 47.28% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:32:55,506]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:34:27,297]\u001b[0m Trial 1081 finished with value: 5.492504750381413 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006522155457530125, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11857912184443697, 'dropout_rate_Layer_2': 0.14064157230282023, 'dropout_rate_Layer_3': 0.16625332211937385, 'dropout_rate_Layer_4': 0.11342136666558511, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015166495469759404, 'l1_Layer_2': 0.0009585038115885079, 'l1_Layer_3': 4.2344352074008775e-05, 'l1_Layer_4': 1.4817538437154626e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 155, 'n_units_Layer_4': 260}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 14.08% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 45.63% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:35:55,967]\u001b[0m Trial 1082 finished with value: 5.275713569096792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007881670812855445, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08141941790102981, 'dropout_rate_Layer_2': 0.2418937304066166, 'dropout_rate_Layer_3': 0.06929825260161648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009090057390552958, 'l1_Layer_2': 2.0281937699715457e-05, 'l1_Layer_3': 3.880316853354123e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.64% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 46.69% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:36:25,178]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:38:04,342]\u001b[0m Trial 1084 finished with value: 5.512448516336011 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006685294985272313, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11487846536967232, 'dropout_rate_Layer_2': 0.14024806412686502, 'dropout_rate_Layer_3': 0.16756031006673253, 'dropout_rate_Layer_4': 0.11358911005281781, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00172426378352319, 'l1_Layer_2': 0.000984465999662642, 'l1_Layer_3': 4.3741031901258795e-05, 'l1_Layer_4': 1.4726738610543835e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155, 'n_units_Layer_4': 260}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.51 | sMAPE for Validation Set is: 14.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 11.30 | sMAPE for Test Set is: 49.47% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:38:13,721]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:39:19,555]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:39:25,662]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:39:30,473]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:39:54,321]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:40:56,565]\u001b[0m Trial 1090 finished with value: 5.398945694875451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008903755789997639, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11572112291056139, 'dropout_rate_Layer_2': 0.24669887174950916, 'dropout_rate_Layer_3': 0.039259801717797915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008478907290548437, 'l1_Layer_2': 1.873925324280954e-05, 'l1_Layer_3': 2.8009733630265138e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 13.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 47.66% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:41:05,801]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:42:56,214]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:43:06,681]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:43:30,169]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:44:09,179]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:44:12,981]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:44:30,091]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:44:38,224]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:44:46,731]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:44:55,497]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:45:04,186]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:46:56,554]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:47:01,972]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:47:08,493]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:47:41,451]\u001b[0m Trial 1105 finished with value: 5.392390206466174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013642681809726196, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008432061035076589, 'dropout_rate_Layer_2': 0.3730985429099764, 'dropout_rate_Layer_3': 0.10279774806744794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015689443132324704, 'l1_Layer_2': 2.9712480864679435e-05, 'l1_Layer_3': 1.2800548254126515e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 300, 'n_units_Layer_3': 185}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 39.15% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:47:49,519]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:48:06,381]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:49:00,578]\u001b[0m Trial 1108 finished with value: 5.44113754271573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006207973072520518, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10338002580679306, 'dropout_rate_Layer_2': 0.23855153669684864, 'dropout_rate_Layer_3': 0.05391447049680757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009219232003940197, 'l1_Layer_2': 1.590736816304718e-05, 'l1_Layer_3': 4.813480670987515e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.88 | sMAPE for Test Set is: 48.37% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:49:04,604]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:49:10,808]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:49:19,187]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:49:26,940]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:49:32,945]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:52:20,540]\u001b[0m Trial 1114 finished with value: 5.276821825841729 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005563298334837005, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1340501364896842, 'dropout_rate_Layer_2': 0.14638348214470448, 'dropout_rate_Layer_3': 0.15145920142210903, 'dropout_rate_Layer_4': 0.15286753397208172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015831515773125637, 'l1_Layer_2': 0.0019974366526811756, 'l1_Layer_3': 1.3194469795508149e-05, 'l1_Layer_4': 1.858586269233531e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 300, 'n_units_Layer_3': 165, 'n_units_Layer_4': 280}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 46.77% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:52:28,690]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:54:06,792]\u001b[0m Trial 1116 finished with value: 5.258441504499765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011189187188250127, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1266077091410575, 'dropout_rate_Layer_2': 0.25070630198249805, 'dropout_rate_Layer_3': 0.033576161857849354, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001080645742175453, 'l1_Layer_2': 5.8789472322094456e-05, 'l1_Layer_3': 3.8120066430815704e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 270, 'n_units_Layer_3': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 13.54% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.95 | sMAPE for Test Set is: 48.12% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 21:54:14,731]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:56:07,569]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:56:12,495]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:56:21,313]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:58:10,703]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 21:58:34,689]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:01:47,966]\u001b[0m Trial 1123 finished with value: 5.266069327714945 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005682775767118608, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12813474976010283, 'dropout_rate_Layer_2': 0.15166396015653913, 'dropout_rate_Layer_3': 0.15461477036774823, 'dropout_rate_Layer_4': 0.14217898254711067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012360144630987405, 'l1_Layer_2': 0.002066786517936581, 'l1_Layer_3': 1.78987934865635e-05, 'l1_Layer_4': 1.0287367741641188e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165, 'n_units_Layer_4': 300}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 49.27% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:01:53,671]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:02:55,007]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:03:02,912]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:04:57,464]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:05:03,670]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:05:42,157]\u001b[0m Trial 1129 finished with value: 5.374692650637147 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008646323776732055, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010035369977338077, 'dropout_rate_Layer_2': 0.35992304403819786, 'dropout_rate_Layer_3': 0.10108841874665542, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016531226656184292, 'l1_Layer_2': 2.9862816309089128e-05, 'l1_Layer_3': 1.4707939875322515e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 13.66% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 38.78% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:05:46,384]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:05:51,644]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:07:42,346]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:07:50,614]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:09:44,809]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:09:49,215]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:10:27,324]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:11:16,596]\u001b[0m Trial 1137 finished with value: 5.325711554830522 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013649840926496836, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010617934324463164, 'dropout_rate_Layer_2': 0.3564500444113236, 'dropout_rate_Layer_3': 0.10446900112506825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021438541168617459, 'l1_Layer_2': 3.398990159484978e-05, 'l1_Layer_3': 1.6157684132992158e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 38.87% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:13:01,380]\u001b[0m Trial 1138 finished with value: 5.44615296633328 and parameters: {'n_hidden': 4, 'learning_rate': 0.000798619767357859, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12705138783024852, 'dropout_rate_Layer_2': 0.17134135632706135, 'dropout_rate_Layer_3': 0.1420313723324412, 'dropout_rate_Layer_4': 0.16817978923652438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014339638044342474, 'l1_Layer_2': 0.0019476444884490905, 'l1_Layer_3': 2.7974810971059146e-05, 'l1_Layer_4': 1.561697050669544e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 165, 'n_units_Layer_4': 270}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.99% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.57 | sMAPE for Test Set is: 46.89% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:13:09,592]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:13:17,938]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:13:23,722]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:13:27,877]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:14:52,667]\u001b[0m Trial 1143 finished with value: 5.70918543858235 and parameters: {'n_hidden': 3, 'learning_rate': 0.001262488798637945, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27776397901114647, 'dropout_rate_Layer_2': 0.14763914376452683, 'dropout_rate_Layer_3': 0.2823064811060799, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008109718154992881, 'l1_Layer_2': 0.0005408230386153742, 'l1_Layer_3': 5.834424450915931e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 14.64% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 49.64% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:15:01,658]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:15:05,985]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:15:14,379]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:15:20,466]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:17:17,538]\u001b[0m Trial 1148 finished with value: 5.486343855509323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012568608066185704, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007505086621401983, 'dropout_rate_Layer_2': 0.3369986059393379, 'dropout_rate_Layer_3': 0.1210185596425333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017759772527392573, 'l1_Layer_2': 3.585299377239056e-05, 'l1_Layer_3': 2.895133273048112e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.17 | sMAPE for Test Set is: 39.23% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:17:28,295]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:17:33,571]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:18:22,585]\u001b[0m Trial 1151 finished with value: 5.441490496987515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008349052200766037, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03275836060153055, 'dropout_rate_Layer_2': 0.35303916503362737, 'dropout_rate_Layer_3': 0.0969907317752521, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002152922051116142, 'l1_Layer_2': 2.9614205656502856e-05, 'l1_Layer_3': 1.4730772413286125e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.44 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.09 | sMAPE for Test Set is: 39.07% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:18:30,680]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:18:39,394]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:19:49,994]\u001b[0m Trial 1154 finished with value: 5.3730372364782975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010319583642382595, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1144162518351119, 'dropout_rate_Layer_2': 0.22067681701770986, 'dropout_rate_Layer_3': 0.03585586006050173, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001439905863272027, 'l1_Layer_2': 2.3527467507192823e-05, 'l1_Layer_3': 3.620767220284094e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 13.86% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.50 | sMAPE for Test Set is: 46.82% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:23:07,056]\u001b[0m Trial 1155 finished with value: 5.26478626572664 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006706200647445042, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1568152555002523, 'dropout_rate_Layer_2': 0.13316869793964292, 'dropout_rate_Layer_3': 0.14552987870563297, 'dropout_rate_Layer_4': 0.15113396555075748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009418119893903153, 'l1_Layer_2': 0.0018633655371349028, 'l1_Layer_3': 3.367778621208074e-05, 'l1_Layer_4': 1.5389651081731736e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155, 'n_units_Layer_4': 280}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.26 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.83 | sMAPE for Test Set is: 48.12% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:23:44,872]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:24:04,951]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:24:14,057]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:24:19,639]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:24:43,868]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:25:01,059]\u001b[0m Trial 1161 finished with value: 5.429360545310895 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013668048635431945, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04842503916918142, 'dropout_rate_Layer_2': 0.30272670714441935, 'dropout_rate_Layer_3': 0.1563971492836587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010986212364401232, 'l1_Layer_2': 4.1503041410289876e-05, 'l1_Layer_3': 2.2232951974941002e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 280, 'n_units_Layer_3': 245}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.43 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.10 | sMAPE for Test Set is: 40.13% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:25:54,578]\u001b[0m Trial 1162 finished with value: 5.267518815030821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008253357806179506, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10001859219394306, 'dropout_rate_Layer_2': 0.20820772134315282, 'dropout_rate_Layer_3': 0.025080492996439708, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008613678536360958, 'l1_Layer_2': 1.7050744399536076e-05, 'l1_Layer_3': 3.189826649266661e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.70 | sMAPE for Test Set is: 47.64% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:26:03,095]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:26:08,109]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:26:47,974]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:28:42,794]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:29:21,186]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:31:13,307]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:31:31,182]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:34:08,524]\u001b[0m Trial 1170 finished with value: 5.347354998331053 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006767521558570399, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15924599728423494, 'dropout_rate_Layer_2': 0.15836281387722384, 'dropout_rate_Layer_3': 0.1704650653614734, 'dropout_rate_Layer_4': 0.133264889688693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020474544842382213, 'l1_Layer_2': 0.0011567324975109911, 'l1_Layer_3': 0.00012825226235976472, 'l1_Layer_4': 3.0269572544414397e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160, 'n_units_Layer_4': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.45 | sMAPE for Test Set is: 46.50% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:34:42,796]\u001b[0m Trial 1171 finished with value: 5.3264742183901745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016895831801454434, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010429633821811033, 'dropout_rate_Layer_2': 0.35625964471156774, 'dropout_rate_Layer_3': 0.09988211445060642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028041007316327484, 'l1_Layer_2': 2.197872474757589e-05, 'l1_Layer_3': 1.7176066657396064e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 210}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 13.59% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.05 | sMAPE for Test Set is: 41.00% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:34:52,932]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:35:01,464]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:35:10,473]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:02,326]\u001b[0m Trial 1175 finished with value: 5.44779411120316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017761251387611906, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01042418935100603, 'dropout_rate_Layer_2': 0.3420236795461486, 'dropout_rate_Layer_3': 0.11243026170522688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016272025781954586, 'l1_Layer_2': 2.1107799192210064e-05, 'l1_Layer_3': 1.2527623345122617e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.45 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.75 | sMAPE for Test Set is: 38.81% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:36:10,768]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:16,364]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:23,944]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:32,128]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:40,492]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:48,711]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:36:53,486]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:37:11,021]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:37:20,347]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:37:28,416]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:37:37,254]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:37:43,345]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:39:32,476]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:41:14,870]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:41:21,283]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:41:58,551]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:42:15,773]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:42:19,731]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:42:25,506]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:42:29,757]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:42:36,306]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:42:57,160]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:43:03,527]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:43:12,737]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:43:34,888]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:43:43,464]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:43:52,843]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:44:00,425]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:44:08,770]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:28,265]\u001b[0m Trial 1205 finished with value: 5.207327183620445 and parameters: {'n_hidden': 3, 'learning_rate': 0.000655562891636838, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08557046877344078, 'dropout_rate_Layer_2': 0.2276066012620347, 'dropout_rate_Layer_3': 0.021421548120602124, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007805867635820279, 'l1_Layer_2': 2.1489784002431115e-05, 'l1_Layer_3': 3.173402927776369e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.21 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 48.28% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:45:36,162]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:44,909]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:45:51,113]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:46:49,233]\u001b[0m Trial 1209 finished with value: 5.281346213160503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009397188667061851, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07688023365183044, 'dropout_rate_Layer_2': 0.21332531241536104, 'dropout_rate_Layer_3': 0.0006008032244571096, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008171576734243223, 'l1_Layer_2': 2.0852749532490513e-05, 'l1_Layer_3': 2.9859810457028582e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 46.56% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:46:57,591]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:20,215]\u001b[0m Trial 1211 finished with value: 5.347232811775065 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005037447785902383, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1306265131861591, 'dropout_rate_Layer_2': 0.19183791054385588, 'dropout_rate_Layer_3': 0.3336224281244765, 'dropout_rate_Layer_4': 0.13698093994406396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012443255086221562, 'l1_Layer_2': 0.0013795628513996044, 'l1_Layer_3': 6.834368096630444e-05, 'l1_Layer_4': 1.9907951430135053e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.69% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 47.65% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:50:37,242]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:43,378]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:50,790]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:50:57,803]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:51:45,130]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:52:46,304]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:55:48,234]\u001b[0m Trial 1218 finished with value: 5.247576446115859 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005112208774171977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03854161674087159, 'dropout_rate_Layer_2': 0.20368007020270223, 'dropout_rate_Layer_3': 0.16279236231041652, 'dropout_rate_Layer_4': 0.13573384318866366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021577742015081286, 'l1_Layer_2': 0.0011192265156051515, 'l1_Layer_3': 7.191391916225565e-05, 'l1_Layer_4': 1.9369676023867193e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 295, 'n_units_Layer_3': 170, 'n_units_Layer_4': 265}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.25 | sMAPE for Validation Set is: 13.60% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.12 | sMAPE for Test Set is: 45.56% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:58:31,681]\u001b[0m Trial 1219 finished with value: 5.346649532025086 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005011362359669528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15254047267865456, 'dropout_rate_Layer_2': 0.20372361969775446, 'dropout_rate_Layer_3': 0.17778064228322515, 'dropout_rate_Layer_4': 0.13501577986058955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021144889935672644, 'l1_Layer_2': 0.0010231801793856258, 'l1_Layer_3': 7.246529959663811e-05, 'l1_Layer_4': 1.9504288583867637e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175, 'n_units_Layer_4': 260}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.83% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 47.54% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 22:58:38,786]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 22:58:47,618]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:01:31,554]\u001b[0m Trial 1222 finished with value: 5.307137208042642 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005027873968268992, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10808528445653609, 'dropout_rate_Layer_2': 0.19321714112381172, 'dropout_rate_Layer_3': 0.16313905358437342, 'dropout_rate_Layer_4': 0.12573884775388677, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0022529483146846575, 'l1_Layer_2': 0.0012319106013165349, 'l1_Layer_3': 6.80362804682142e-05, 'l1_Layer_4': 1.9912494592863442e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175, 'n_units_Layer_4': 255}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 45.91% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:01:37,635]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:00,947]\u001b[0m Trial 1224 finished with value: 5.565601845491311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011691829687836123, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011395104931635498, 'dropout_rate_Layer_2': 0.37881339054735186, 'dropout_rate_Layer_3': 0.09071181464936848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.47201584945885e-05, 'l1_Layer_2': 7.962459054980031e-05, 'l1_Layer_3': 3.578981993632337e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.57 | sMAPE for Validation Set is: 14.10% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.36 | sMAPE for Test Set is: 40.85% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:02:10,045]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:18,274]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:02:58,426]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:04,401]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:48,974]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:03:57,444]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:04,010]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:25,545]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:04:57,584]\u001b[0m Trial 1233 finished with value: 5.359196785787186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014800332066643269, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020446579174960608, 'dropout_rate_Layer_2': 0.36233725102847203, 'dropout_rate_Layer_3': 0.10100237447455494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029559606518650655, 'l1_Layer_2': 2.3775648835232838e-05, 'l1_Layer_3': 1.6070387603215817e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 38.29% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:05:11,374]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:20,316]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:05:26,508]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:12,840]\u001b[0m Trial 1237 finished with value: 5.269485680346604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007968059397947061, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05724627275156018, 'dropout_rate_Layer_2': 0.21444256783217827, 'dropout_rate_Layer_3': 0.012360704381710278, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014140232952877206, 'l1_Layer_2': 2.703842138594806e-05, 'l1_Layer_3': 3.1133754671693384e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.27 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.57 | sMAPE for Test Set is: 46.96% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:07:18,654]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:07:23,581]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:28,413]\u001b[0m Trial 1240 finished with value: 5.389631543017411 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008232575361618723, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05848473644818029, 'dropout_rate_Layer_2': 0.19316786477706052, 'dropout_rate_Layer_3': 0.0017343013613540356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014966751864041669, 'l1_Layer_2': 2.8200358175799158e-05, 'l1_Layer_3': 3.082315491045576e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.84% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.28 | sMAPE for Test Set is: 46.36% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:08:36,507]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:43,027]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:08:50,991]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:08,014]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:12,946]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:23,244]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:34,049]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:42,983]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:52,319]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:09:56,333]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:10:02,258]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:11:41,653]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:17,405]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:12:49,762]\u001b[0m Trial 1254 finished with value: 5.322414864017534 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022985100310530596, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 2.0003330417794896e-05, 'dropout_rate_Layer_2': 0.38369470810992967, 'dropout_rate_Layer_3': 0.12222485767067937, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002237204624418752, 'l1_Layer_2': 3.808427446931355e-05, 'l1_Layer_3': 1.1962344712541369e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 180}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.32 | sMAPE for Validation Set is: 13.58% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.53 | sMAPE for Test Set is: 41.69% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:12:55,977]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:03,910]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:10,412]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:45,706]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:50,039]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:13:58,635]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:07,595]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:14:16,750]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:14,070]\u001b[0m Trial 1263 finished with value: 5.3698877395686715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006416330244065563, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0749307697781639, 'dropout_rate_Layer_2': 0.2134245913742765, 'dropout_rate_Layer_3': 0.031101418430171925, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009470225071552084, 'l1_Layer_2': 0.00010562566000628395, 'l1_Layer_3': 2.2603063270254684e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 13.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 47.73% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:15:34,610]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:15:48,415]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:24,479]\u001b[0m Trial 1266 finished with value: 5.494540355962527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022754108996987407, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008141119602690018, 'dropout_rate_Layer_2': 0.38678166402621394, 'dropout_rate_Layer_3': 0.07392474052127584, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004216002050776329, 'l1_Layer_2': 1.8410695090603695e-05, 'l1_Layer_3': 1.1668005537742437e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 13.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 42.60% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:16:28,566]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:33,828]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:40,067]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:46,544]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:16:51,345]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:46,566]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:18:54,376]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:02,005]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:14,826]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:22,757]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:28,584]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:34,615]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:40,962]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:19:54,467]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:02,435]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:10,457]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:18,655]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:25,142]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:29,714]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:20:38,391]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:00,354]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:23,898]\u001b[0m Trial 1288 finished with value: 5.390901514390549 and parameters: {'n_hidden': 3, 'learning_rate': 0.002461810944638213, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022746186316000158, 'dropout_rate_Layer_2': 0.369662933681479, 'dropout_rate_Layer_3': 0.11060707334137443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003337798566346234, 'l1_Layer_2': 5.248574891583376e-05, 'l1_Layer_3': 3.764361907742885e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 38.96% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:21:28,115]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:36,994]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:42,434]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:46,299]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:51,701]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:21:58,096]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:07,067]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:23,667]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:29,593]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:34,315]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:50,935]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:22:56,929]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:23:02,537]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:08,742]\u001b[0m Trial 1302 finished with value: 5.330415524490719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006905046817587, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05568634227663668, 'dropout_rate_Layer_2': 0.1947289276342928, 'dropout_rate_Layer_3': 0.00056076427466875, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017377150464689987, 'l1_Layer_2': 1.7563125538844536e-05, 'l1_Layer_3': 2.5234409815047514e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 13.71% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.43 | sMAPE for Test Set is: 46.62% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:24:16,778]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:25,181]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:30,477]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:35,270]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:42,901]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:48,993]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:24:57,270]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:05,364]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:11,346]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:53,729]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:25:59,837]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:05,833]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:24,864]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:29,352]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:42,363]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:26:48,696]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:03,487]\u001b[0m Trial 1319 finished with value: 5.349043713401815 and parameters: {'n_hidden': 3, 'learning_rate': 0.001104920841782513, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03442033146538588, 'dropout_rate_Layer_2': 0.26571646735586896, 'dropout_rate_Layer_3': 0.010050440866543033, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009431908119448335, 'l1_Layer_2': 2.1211004745912028e-05, 'l1_Layer_3': 9.276629971392872e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 205, 'n_units_Layer_3': 275}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.35 | sMAPE for Validation Set is: 13.74% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.23 | sMAPE for Test Set is: 49.29% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:28:11,996]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:28:20,738]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:30:44,660]\u001b[0m Trial 1322 finished with value: 5.5237770988421735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007386021065235546, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1097885004781062, 'dropout_rate_Layer_2': 0.3534510415207709, 'dropout_rate_Layer_3': 0.3010027690966703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015373999197435897, 'l1_Layer_2': 2.842176356421696e-05, 'l1_Layer_3': 2.7900147802689542e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 14.05% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 48.45% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:31:46,483]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:54,091]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:31:59,664]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:13,844]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:19,677]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:32,537]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:38,786]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:43,377]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:32:49,253]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:38,131]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:44,426]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:52,222]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:34:58,316]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:03,098]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:11,143]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:17,131]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:23,134]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:30,783]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:38,441]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:44,625]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:53,463]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:35:58,923]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:05,155]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:09,757]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:16,010]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:23,860]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:29,843]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:38,577]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:36:44,296]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:39:26,770]\u001b[0m Trial 1352 finished with value: 5.357885682112233 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005017880550241681, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1020262606716657, 'dropout_rate_Layer_2': 0.18914663212001345, 'dropout_rate_Layer_3': 0.16240168988366718, 'dropout_rate_Layer_4': 0.1654748392245568, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006952407396998677, 'l1_Layer_2': 0.006315639033626568, 'l1_Layer_3': 2.851340719011212e-05, 'l1_Layer_4': 1.7428261535314676e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 285, 'n_units_Layer_3': 170, 'n_units_Layer_4': 260}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 46.95% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:39:35,726]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:40:12,808]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:42:05,386]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:43:59,634]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:04,622]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:13,870]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:20,421]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:35,350]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:44:41,461]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:06,033]\u001b[0m Trial 1362 finished with value: 5.382335717875644 and parameters: {'n_hidden': 3, 'learning_rate': 0.001368553920378437, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03285645750864573, 'dropout_rate_Layer_2': 0.37641058168322855, 'dropout_rate_Layer_3': 0.09847810344301053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017276541357049587, 'l1_Layer_2': 1.6353163176378792e-05, 'l1_Layer_3': 1.804593070419155e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 13.76% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 38.86% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:45:29,129]\u001b[0m Trial 1363 finished with value: 5.391928218580934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014078081079352774, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04776255865250556, 'dropout_rate_Layer_2': 0.3777804650691616, 'dropout_rate_Layer_3': 0.08129077538939636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001796104301990951, 'l1_Layer_2': 2.2197775475289493e-05, 'l1_Layer_3': 1.1382866468970631e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.39 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.03 | sMAPE for Test Set is: 38.93% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:45:35,111]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:47,017]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:45:55,093]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:47:05,094]\u001b[0m Trial 1367 finished with value: 5.310623611604701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006172645612720932, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10832198235169437, 'dropout_rate_Layer_2': 0.2306865158748038, 'dropout_rate_Layer_3': 0.07200081870921303, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008659626184252207, 'l1_Layer_2': 1.3370354130386122e-05, 'l1_Layer_3': 5.089772346276059e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.67% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 47.54% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:47:22,312]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:14,396]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:49:22,733]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:51:09,961]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:41,972]\u001b[0m Trial 1372 finished with value: 5.325896228203338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006572683829011989, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10168407783540342, 'dropout_rate_Layer_2': 0.21773542463619555, 'dropout_rate_Layer_3': 0.0537885222296986, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015559345375394226, 'l1_Layer_2': 1.6795457961329904e-05, 'l1_Layer_3': 6.848262637926021e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 13.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 47.13% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:52:49,167]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:52:59,530]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:53:17,835]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:11,476]\u001b[0m Trial 1376 finished with value: 5.37636951834574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005706879784820439, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08341166349826634, 'dropout_rate_Layer_2': 0.23483762373692516, 'dropout_rate_Layer_3': 0.023275209999021232, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007842280099416424, 'l1_Layer_2': 1.3037214604000907e-05, 'l1_Layer_3': 5.711428522798753e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.38 | sMAPE for Validation Set is: 13.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 46.89% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-26 23:54:17,010]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:54:52,544]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:00,647]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:11,358]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:19,254]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:55:25,257]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:16,663]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:24,960]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:29,546]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:35,307]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:39,078]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:47,463]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:57:53,177]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:58:02,465]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-26 23:59:56,879]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:02,709]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:11,125]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:16,972]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:25,015]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:31,162]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:00:36,248]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:39,128]\u001b[0m Trial 1398 finished with value: 5.640296594603767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009592997560695027, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.090932448437979, 'dropout_rate_Layer_2': 0.25718974236990116, 'dropout_rate_Layer_3': 0.08246780385513329, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012634204139443453, 'l1_Layer_2': 2.3586141204933303e-05, 'l1_Layer_3': 2.726238605798824e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.64 | sMAPE for Validation Set is: 14.40% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 50.87% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:01:42,980]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:48,935]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:01:55,137]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:03,995]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:09,912]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:15,480]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:23,724]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:31,896]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:02:44,680]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:25,070]\u001b[0m Trial 1408 finished with value: 5.5637538664833786 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005455621373615963, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13064544984971183, 'dropout_rate_Layer_2': 0.20968659871966286, 'dropout_rate_Layer_3': 0.12267986388404871, 'dropout_rate_Layer_4': 0.15295310854071303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.009491697705723327, 'l1_Layer_2': 0.0010073682176000211, 'l1_Layer_3': 3.0202455072293108e-05, 'l1_Layer_4': 2.191617679316672e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 165, 'n_units_Layer_4': 250}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.56 | sMAPE for Validation Set is: 14.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.24 | sMAPE for Test Set is: 49.27% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:04:40,662]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:49,414]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:04:57,413]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:05,066]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:28,569]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:05:53,660]\u001b[0m Trial 1414 finished with value: 5.461747477243288 and parameters: {'n_hidden': 3, 'learning_rate': 0.001989898467282129, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06765219666765576, 'dropout_rate_Layer_2': 0.3771818881138949, 'dropout_rate_Layer_3': 0.07933735371728806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020751113572145422, 'l1_Layer_2': 4.231092885798467e-05, 'l1_Layer_3': 1.4637533769184802e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 235}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.46 | sMAPE for Validation Set is: 13.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.92 | sMAPE for Test Set is: 39.08% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:05:58,163]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:04,070]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:06:10,156]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:07:59,406]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:08:34,898]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:37,774]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:09:46,137]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:11,868]\u001b[0m Trial 1422 finished with value: 5.325838225903458 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015129098687543614, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029657749294817813, 'dropout_rate_Layer_2': 0.3916855627913391, 'dropout_rate_Layer_3': 0.11742571892933842, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017533286763171476, 'l1_Layer_2': 3.4331262267061835e-05, 'l1_Layer_3': 5.6419270035608325e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 220}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.33 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 38.98% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:10:18,257]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:24,352]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:10:30,199]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:06,028]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:26,479]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:32,941]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:41,552]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:11:59,492]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:05,943]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:12:11,207]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:06,164]\u001b[0m Trial 1433 finished with value: 5.371009311627187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006215241886858479, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10812606296661258, 'dropout_rate_Layer_2': 0.22940969172443215, 'dropout_rate_Layer_3': 0.07379001622897358, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008553609543122948, 'l1_Layer_2': 1.3223404624582895e-05, 'l1_Layer_3': 3.8241447125893245e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.37 | sMAPE for Validation Set is: 13.80% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 47.70% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:13:11,944]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:13:28,271]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:06,114]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:14,057]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:23,098]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:29,158]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:38,274]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:14:46,665]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:15:54,701]\u001b[0m Trial 1442 finished with value: 5.356876652760214 and parameters: {'n_hidden': 3, 'learning_rate': 0.00056032515760682, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10996990712582613, 'dropout_rate_Layer_2': 0.2482979243694895, 'dropout_rate_Layer_3': 0.019926861771699566, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001015952400381626, 'l1_Layer_2': 1.1784085247875139e-05, 'l1_Layer_3': 4.988473207901253e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.36 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.48 | sMAPE for Test Set is: 46.84% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:15:59,672]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:39,907]\u001b[0m Trial 1444 finished with value: 5.283440391275914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007033533495985474, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11936739113510403, 'dropout_rate_Layer_2': 0.23744074138498905, 'dropout_rate_Layer_3': 0.06969201576453539, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013710085982188386, 'l1_Layer_2': 1.3791288075212235e-05, 'l1_Layer_3': 5.901756087604144e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 295, 'n_units_Layer_3': 295}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.28 | sMAPE for Validation Set is: 13.62% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 47.95% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:17:44,719]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:53,313]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:17:58,221]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:04,366]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:13,961]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:17,980]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:25,682]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:31,522]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:40,962]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:49,102]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:18:59,096]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:04,958]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:09,727]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:16,016]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:23,834]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:31,358]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:19:37,800]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:17,755]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:20:34,183]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:01,198]\u001b[0m Trial 1464 finished with value: 5.338994600157387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012555973316672941, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0339692277700898, 'dropout_rate_Layer_2': 0.3937641079485579, 'dropout_rate_Layer_3': 0.11736729194944667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016979777093642403, 'l1_Layer_2': 3.504657607585315e-05, 'l1_Layer_3': 4.956221409310284e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 220}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.34 | sMAPE for Validation Set is: 13.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 38.02% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:21:20,630]\u001b[0m Trial 1465 finished with value: 5.417830654856657 and parameters: {'n_hidden': 3, 'learning_rate': 0.001210648038987134, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031321621099683214, 'dropout_rate_Layer_2': 0.3933645713132967, 'dropout_rate_Layer_3': 0.11981363133173822, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013072817993381222, 'l1_Layer_2': 5.5795340318427177e-05, 'l1_Layer_3': 5.181679696872227e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 270, 'n_units_Layer_3': 220}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.42 | sMAPE for Validation Set is: 13.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.13 | sMAPE for Test Set is: 39.65% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:21:27,323]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:39,492]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:21:53,063]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:08,458]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:22,019]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:41,073]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:46,912]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:22:52,873]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:02,146]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:12,821]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:17,619]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:24,815]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:31,323]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:49,130]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:23:56,889]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:10,523]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:16,572]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:40,174]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:44,981]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:50,978]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:24:57,383]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:03,399]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:09,204]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:23,968]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:32,199]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:41,117]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:44,702]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:48,644]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:25:53,602]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:26:01,132]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:26:05,495]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:26:22,555]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 00:27:38,605]\u001b[0m Trial 1498 finished with value: 5.31168000003701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009331711281325608, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09061236492416302, 'dropout_rate_Layer_2': 0.24019040810098977, 'dropout_rate_Layer_3': 0.08986675546730062, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015955117357076508, 'l1_Layer_2': 1.4320688878909913e-05, 'l1_Layer_3': 4.527961387813189e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 1028 with value: 5.128994690821378.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.31 | sMAPE for Validation Set is: 13.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 47.01% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 00:27:44,671]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-01-01, MAE is:4.16 & sMAPE is:13.93% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 13.93% & 0.56\n",
      "for 2020-01-02, MAE is:5.65 & sMAPE is:20.08% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 17.00% & 0.57\n",
      "for 2020-01-03, MAE is:9.85 & sMAPE is:48.53% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 27.51% & 0.56\n",
      "for 2020-01-04, MAE is:6.59 & sMAPE is:36.41% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 29.74% & 0.55\n",
      "for 2020-01-05, MAE is:2.66 & sMAPE is:9.91% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :5.78 & 25.77% & 0.63\n",
      "for 2020-01-06, MAE is:2.56 & sMAPE is:8.13% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.25 & 22.83% & 0.60\n",
      "for 2020-01-07, MAE is:6.91 & sMAPE is:20.01% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 22.43% & 0.69\n",
      "for 2020-01-08, MAE is:6.87 & sMAPE is:40.60% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 24.70% & 0.76\n",
      "for 2020-01-09, MAE is:4.80 & sMAPE is:15.18% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 23.64% & 0.89\n",
      "for 2020-01-10, MAE is:5.25 & sMAPE is:15.36% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 22.81% & 0.84\n",
      "for 2020-01-11, MAE is:4.28 & sMAPE is:15.79% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :5.42 & 22.18% & 0.82\n",
      "for 2020-01-12, MAE is:1.60 & sMAPE is:7.55% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.10 & 20.96% & 0.77\n",
      "for 2020-01-13, MAE is:6.47 & sMAPE is:19.07% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 20.81% & 0.85\n",
      "for 2020-01-14, MAE is:8.53 & sMAPE is:31.94% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.44 & 21.61% & 0.89\n",
      "for 2020-01-15, MAE is:4.25 & sMAPE is:17.92% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :5.36 & 21.36% & 0.92\n",
      "for 2020-01-16, MAE is:6.86 & sMAPE is:19.36% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 21.24% & 0.92\n",
      "for 2020-01-17, MAE is:3.49 & sMAPE is:10.84% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :5.34 & 20.62% & 0.92\n",
      "for 2020-01-18, MAE is:1.76 & sMAPE is:7.15% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.14 & 19.88% & 0.91\n",
      "for 2020-01-19, MAE is:2.22 & sMAPE is:9.15% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 19.31% & 0.92\n",
      "for 2020-01-20, MAE is:9.12 & sMAPE is:31.26% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.19 & 19.91% & 0.94\n",
      "for 2020-01-21, MAE is:3.62 & sMAPE is:15.51% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 19.70% & 0.94\n",
      "for 2020-01-22, MAE is:6.84 & sMAPE is:24.88% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 19.94% & 0.99\n",
      "for 2020-01-23, MAE is:15.58 & sMAPE is:36.71% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :5.65 & 20.66% & 1.01\n",
      "for 2020-01-24, MAE is:5.82 & sMAPE is:22.06% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 20.72% & 1.01\n",
      "for 2020-01-25, MAE is:3.08 & sMAPE is:12.52% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 20.39% & 1.00\n",
      "for 2020-01-26, MAE is:3.20 & sMAPE is:14.47% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 20.17% & 1.00\n",
      "for 2020-01-27, MAE is:6.16 & sMAPE is:19.48% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :5.49 & 20.14% & 0.99\n",
      "for 2020-01-28, MAE is:9.63 & sMAPE is:27.78% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 20.41% & 0.98\n",
      "for 2020-01-29, MAE is:9.65 & sMAPE is:29.20% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.77 & 20.72% & 0.99\n",
      "for 2020-01-30, MAE is:8.74 & sMAPE is:27.29% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 20.94% & 0.99\n",
      "for 2020-01-31, MAE is:5.83 & sMAPE is:23.62% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :5.87 & 21.02% & 1.00\n",
      "for 2020-02-01, MAE is:8.24 & sMAPE is:45.63% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 21.79% & 1.00\n",
      "for 2020-02-02, MAE is:4.07 & sMAPE is:26.11% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 21.92% & 0.99\n",
      "for 2020-02-03, MAE is:6.15 & sMAPE is:22.94% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :5.90 & 21.95% & 1.00\n",
      "for 2020-02-04, MAE is:10.39 & sMAPE is:29.34% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.03 & 22.16% & 1.01\n",
      "for 2020-02-05, MAE is:7.98 & sMAPE is:28.93% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 22.35% & 1.02\n",
      "for 2020-02-06, MAE is:5.80 & sMAPE is:23.05% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.07 & 22.37% & 1.01\n",
      "for 2020-02-07, MAE is:10.09 & sMAPE is:32.46% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 22.64% & 1.02\n",
      "for 2020-02-08, MAE is:6.86 & sMAPE is:39.96% & rMAE is:6.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 23.08% & 1.16\n",
      "for 2020-02-09, MAE is:12.11 & sMAPE is:90.61% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 24.77% & 1.17\n",
      "for 2020-02-10, MAE is:12.42 & sMAPE is:94.76% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 26.48% & 1.16\n",
      "for 2020-02-11, MAE is:8.97 & sMAPE is:53.62% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 27.12% & 1.14\n",
      "for 2020-02-12, MAE is:16.68 & sMAPE is:45.49% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 27.55% & 1.14\n",
      "for 2020-02-13, MAE is:14.55 & sMAPE is:38.77% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 27.80% & 1.14\n",
      "for 2020-02-14, MAE is:16.16 & sMAPE is:40.66% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 28.09% & 1.15\n",
      "for 2020-02-15, MAE is:12.49 & sMAPE is:66.41% & rMAE is:3.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 28.92% & 1.20\n",
      "for 2020-02-16, MAE is:10.38 & sMAPE is:73.13% & rMAE is:4.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 29.86% & 1.28\n",
      "for 2020-02-17, MAE is:11.89 & sMAPE is:74.99% & rMAE is:4.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 30.80% & 1.35\n",
      "for 2020-02-18, MAE is:7.98 & sMAPE is:35.40% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 30.90% & 1.33\n",
      "for 2020-02-19, MAE is:8.96 & sMAPE is:32.14% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 30.92% & 1.32\n",
      "for 2020-02-20, MAE is:12.11 & sMAPE is:40.43% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 31.11% & 1.32\n",
      "for 2020-02-21, MAE is:6.14 & sMAPE is:40.03% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 31.28% & 1.30\n",
      "for 2020-02-22, MAE is:12.04 & sMAPE is:94.22% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 32.47% & 1.31\n",
      "for 2020-02-23, MAE is:8.18 & sMAPE is:65.74% & rMAE is:5.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 33.08% & 1.39\n",
      "for 2020-02-24, MAE is:8.17 & sMAPE is:35.98% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 33.14% & 1.37\n",
      "for 2020-02-25, MAE is:11.04 & sMAPE is:31.83% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 33.11% & 1.36\n",
      "for 2020-02-26, MAE is:8.89 & sMAPE is:23.16% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 32.94% & 1.36\n",
      "for 2020-02-27, MAE is:11.84 & sMAPE is:27.56% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 32.85% & 1.36\n",
      "for 2020-02-28, MAE is:7.85 & sMAPE is:21.17% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 32.65% & 1.34\n",
      "for 2020-02-29, MAE is:4.39 & sMAPE is:19.12% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 32.42% & 1.32\n",
      "for 2020-03-01, MAE is:4.31 & sMAPE is:22.65% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 32.26% & 1.31\n",
      "for 2020-03-02, MAE is:9.94 & sMAPE is:33.43% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 32.28% & 1.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-03, MAE is:8.23 & sMAPE is:28.70% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 32.22% & 1.31\n",
      "for 2020-03-04, MAE is:10.45 & sMAPE is:35.17% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 32.27% & 1.31\n",
      "for 2020-03-05, MAE is:8.44 & sMAPE is:28.17% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 32.21% & 1.30\n",
      "for 2020-03-06, MAE is:6.85 & sMAPE is:25.40% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 32.10% & 1.29\n",
      "for 2020-03-07, MAE is:4.66 & sMAPE is:23.26% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 31.97% & 1.28\n",
      "for 2020-03-08, MAE is:10.73 & sMAPE is:71.93% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 32.56% & 1.28\n",
      "for 2020-03-09, MAE is:14.09 & sMAPE is:73.89% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 33.16% & 1.27\n",
      "for 2020-03-10, MAE is:8.70 & sMAPE is:36.19% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 33.20% & 1.26\n",
      "for 2020-03-11, MAE is:6.22 & sMAPE is:22.32% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 33.05% & 1.26\n",
      "for 2020-03-12, MAE is:6.49 & sMAPE is:30.19% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 33.01% & 1.25\n",
      "for 2020-03-13, MAE is:7.57 & sMAPE is:40.71% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 33.11% & 1.25\n",
      "for 2020-03-14, MAE is:8.26 & sMAPE is:42.04% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 33.24% & 1.25\n",
      "for 2020-03-15, MAE is:13.63 & sMAPE is:99.35% & rMAE is:5.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 34.12% & 1.31\n",
      "for 2020-03-16, MAE is:9.47 & sMAPE is:44.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 34.26% & 1.30\n",
      "for 2020-03-17, MAE is:12.74 & sMAPE is:61.38% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 34.61% & 1.30\n",
      "for 2020-03-18, MAE is:7.85 & sMAPE is:51.95% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 34.83% & 1.29\n",
      "for 2020-03-19, MAE is:9.05 & sMAPE is:48.80% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 35.01% & 1.30\n",
      "for 2020-03-20, MAE is:8.72 & sMAPE is:35.54% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 35.02% & 1.29\n",
      "for 2020-03-21, MAE is:4.55 & sMAPE is:25.26% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 34.90% & 1.28\n",
      "for 2020-03-22, MAE is:9.44 & sMAPE is:70.61% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 35.33% & 1.30\n",
      "for 2020-03-23, MAE is:7.94 & sMAPE is:46.37% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 35.46% & 1.30\n",
      "for 2020-03-24, MAE is:10.95 & sMAPE is:64.86% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 35.81% & 1.30\n",
      "for 2020-03-25, MAE is:12.47 & sMAPE is:86.41% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 36.41% & 1.30\n",
      "for 2020-03-26, MAE is:7.65 & sMAPE is:42.58% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 36.48% & 1.31\n",
      "for 2020-03-27, MAE is:11.01 & sMAPE is:60.90% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 36.76% & 1.31\n",
      "for 2020-03-28, MAE is:12.06 & sMAPE is:102.14% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 37.50% & 1.30\n",
      "for 2020-03-29, MAE is:7.02 & sMAPE is:60.94% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 37.77% & 1.30\n",
      "for 2020-03-30, MAE is:5.27 & sMAPE is:21.21% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 37.58% & 1.30\n",
      "for 2020-03-31, MAE is:6.24 & sMAPE is:21.57% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 37.41% & 1.29\n",
      "for 2020-04-01, MAE is:7.24 & sMAPE is:39.63% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 37.43% & 1.28\n",
      "for 2020-04-02, MAE is:5.75 & sMAPE is:24.48% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 37.29% & 1.27\n",
      "for 2020-04-03, MAE is:8.37 & sMAPE is:43.76% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 37.36% & 1.27\n",
      "for 2020-04-04, MAE is:3.93 & sMAPE is:21.63% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 37.20% & 1.26\n",
      "for 2020-04-05, MAE is:11.91 & sMAPE is:82.56% & rMAE is:4.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 37.67% & 1.30\n",
      "for 2020-04-06, MAE is:11.91 & sMAPE is:61.92% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 37.92% & 1.29\n",
      "for 2020-04-07, MAE is:9.31 & sMAPE is:64.61% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 38.19% & 1.29\n",
      "for 2020-04-08, MAE is:11.86 & sMAPE is:75.41% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 38.57% & 1.29\n",
      "for 2020-04-09, MAE is:8.47 & sMAPE is:55.58% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 38.74% & 1.28\n",
      "for 2020-04-10, MAE is:8.37 & sMAPE is:47.53% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 38.82% & 1.29\n",
      "for 2020-04-11, MAE is:5.21 & sMAPE is:32.33% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 38.76% & 1.29\n",
      "for 2020-04-12, MAE is:15.11 & sMAPE is:129.43% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 39.64% & 1.30\n",
      "for 2020-04-13, MAE is:11.13 & sMAPE is:104.22% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 40.26% & 1.30\n",
      "for 2020-04-14, MAE is:11.91 & sMAPE is:49.71% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 40.35% & 1.29\n",
      "for 2020-04-15, MAE is:8.39 & sMAPE is:22.09% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 40.18% & 1.28\n",
      "for 2020-04-16, MAE is:7.32 & sMAPE is:30.91% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 40.09% & 1.28\n",
      "for 2020-04-17, MAE is:10.84 & sMAPE is:38.52% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 40.08% & 1.27\n",
      "for 2020-04-18, MAE is:8.61 & sMAPE is:42.73% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 40.10% & 1.28\n",
      "for 2020-04-19, MAE is:5.92 & sMAPE is:45.40% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 40.15% & 1.28\n",
      "for 2020-04-20, MAE is:9.99 & sMAPE is:43.82% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 40.18% & 1.27\n",
      "for 2020-04-21, MAE is:9.55 & sMAPE is:40.61% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 40.19% & 1.27\n",
      "for 2020-04-22, MAE is:7.67 & sMAPE is:29.86% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 40.10% & 1.27\n",
      "for 2020-04-23, MAE is:7.36 & sMAPE is:29.44% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 40.00% & 1.28\n",
      "for 2020-04-24, MAE is:10.04 & sMAPE is:50.87% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 40.10% & 1.27\n",
      "for 2020-04-25, MAE is:10.52 & sMAPE is:81.82% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 40.46% & 1.27\n",
      "for 2020-04-26, MAE is:5.22 & sMAPE is:45.38% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 40.50% & 1.28\n",
      "for 2020-04-27, MAE is:4.41 & sMAPE is:19.28% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 40.32% & 1.27\n",
      "for 2020-04-28, MAE is:4.78 & sMAPE is:16.39% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 40.12% & 1.27\n",
      "for 2020-04-29, MAE is:4.68 & sMAPE is:21.10% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 39.96% & 1.27\n",
      "for 2020-04-30, MAE is:6.28 & sMAPE is:24.95% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 39.84% & 1.27\n",
      "for 2020-05-01, MAE is:11.69 & sMAPE is:89.58% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 40.24% & 1.27\n",
      "for 2020-05-02, MAE is:8.62 & sMAPE is:63.56% & rMAE is:2.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 40.43% & 1.29\n",
      "for 2020-05-03, MAE is:7.62 & sMAPE is:57.02% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 40.57% & 1.29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-04, MAE is:6.96 & sMAPE is:33.33% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 40.51% & 1.29\n",
      "for 2020-05-05, MAE is:12.27 & sMAPE is:52.30% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 40.60% & 1.29\n",
      "for 2020-05-06, MAE is:13.76 & sMAPE is:78.52% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :8.26 & 40.90% & 1.28\n",
      "for 2020-05-07, MAE is:6.09 & sMAPE is:39.68% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 40.89% & 1.28\n",
      "for 2020-05-08, MAE is:12.57 & sMAPE is:50.33% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 40.96% & 1.27\n",
      "for 2020-05-09, MAE is:7.96 & sMAPE is:57.63% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 41.09% & 1.28\n",
      "for 2020-05-10, MAE is:10.01 & sMAPE is:71.89% & rMAE is:4.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.29 & 41.33% & 1.31\n",
      "for 2020-05-11, MAE is:11.10 & sMAPE is:54.07% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 41.42% & 1.31\n",
      "for 2020-05-12, MAE is:10.34 & sMAPE is:38.13% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 41.40% & 1.31\n",
      "for 2020-05-13, MAE is:4.85 & sMAPE is:16.65% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 41.22% & 1.30\n",
      "for 2020-05-14, MAE is:9.64 & sMAPE is:38.72% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 41.20% & 1.30\n",
      "for 2020-05-15, MAE is:12.65 & sMAPE is:47.73% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 41.24% & 1.30\n",
      "for 2020-05-16, MAE is:7.33 & sMAPE is:46.82% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 41.29% & 1.30\n",
      "for 2020-05-17, MAE is:9.97 & sMAPE is:65.08% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.34 & 41.46% & 1.31\n",
      "for 2020-05-18, MAE is:26.67 & sMAPE is:62.84% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 41.61% & 1.31\n",
      "for 2020-05-19, MAE is:9.13 & sMAPE is:29.46% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 41.53% & 1.31\n",
      "for 2020-05-20, MAE is:10.38 & sMAPE is:36.77% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.49 & 41.49% & 1.31\n",
      "for 2020-05-21, MAE is:9.24 & sMAPE is:47.89% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 41.54% & 1.31\n",
      "for 2020-05-22, MAE is:10.01 & sMAPE is:46.97% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 41.57% & 1.31\n",
      "for 2020-05-23, MAE is:11.84 & sMAPE is:114.42% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 42.08% & 1.31\n",
      "for 2020-05-24, MAE is:10.73 & sMAPE is:116.23% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 42.59% & 1.31\n",
      "for 2020-05-25, MAE is:7.28 & sMAPE is:30.23% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 42.51% & 1.30\n",
      "for 2020-05-26, MAE is:6.59 & sMAPE is:20.67% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 42.36% & 1.30\n",
      "for 2020-05-27, MAE is:15.13 & sMAPE is:68.45% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 42.53% & 1.30\n",
      "for 2020-05-28, MAE is:8.31 & sMAPE is:55.75% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.57 & 42.62% & 1.30\n",
      "for 2020-05-29, MAE is:7.08 & sMAPE is:48.52% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 42.66% & 1.30\n",
      "for 2020-05-30, MAE is:8.01 & sMAPE is:73.94% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.55 & 42.87% & 1.30\n",
      "for 2020-05-31, MAE is:11.71 & sMAPE is:122.13% & rMAE is:6.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 43.39% & 1.33\n",
      "for 2020-06-01, MAE is:10.71 & sMAPE is:51.08% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 43.44% & 1.34\n",
      "for 2020-06-02, MAE is:8.82 & sMAPE is:39.96% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 43.42% & 1.34\n",
      "for 2020-06-03, MAE is:6.36 & sMAPE is:17.87% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 43.25% & 1.34\n",
      "for 2020-06-04, MAE is:11.22 & sMAPE is:32.73% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 43.19% & 1.33\n",
      "for 2020-06-05, MAE is:9.16 & sMAPE is:43.03% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 43.19% & 1.33\n",
      "for 2020-06-06, MAE is:13.35 & sMAPE is:116.15% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 43.65% & 1.34\n",
      "for 2020-06-07, MAE is:11.32 & sMAPE is:114.98% & rMAE is:3.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 44.10% & 1.35\n",
      "for 2020-06-08, MAE is:6.65 & sMAPE is:41.69% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 44.08% & 1.35\n",
      "for 2020-06-09, MAE is:10.57 & sMAPE is:51.24% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 44.13% & 1.36\n",
      "for 2020-06-10, MAE is:8.82 & sMAPE is:54.62% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 44.19% & 1.35\n",
      "for 2020-06-11, MAE is:14.17 & sMAPE is:96.77% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 44.51% & 1.35\n",
      "for 2020-06-12, MAE is:9.93 & sMAPE is:78.59% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 44.72% & 1.35\n",
      "for 2020-06-13, MAE is:13.19 & sMAPE is:145.64% & rMAE is:3.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.71 & 45.33% & 1.37\n",
      "for 2020-06-14, MAE is:10.32 & sMAPE is:127.99% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 45.83% & 1.37\n",
      "for 2020-06-15, MAE is:18.55 & sMAPE is:75.85% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 46.01% & 1.37\n",
      "for 2020-06-16, MAE is:14.19 & sMAPE is:55.34% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 46.07% & 1.37\n",
      "for 2020-06-17, MAE is:15.94 & sMAPE is:55.06% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 46.12% & 1.37\n",
      "for 2020-06-18, MAE is:9.26 & sMAPE is:29.06% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 46.02% & 1.37\n",
      "for 2020-06-19, MAE is:14.59 & sMAPE is:100.60% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 46.34% & 1.36\n",
      "for 2020-06-20, MAE is:7.21 & sMAPE is:74.41% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 46.50% & 1.36\n",
      "for 2020-06-21, MAE is:7.56 & sMAPE is:67.69% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 46.62% & 1.36\n",
      "for 2020-06-22, MAE is:11.79 & sMAPE is:39.61% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 46.58% & 1.36\n",
      "for 2020-06-23, MAE is:11.05 & sMAPE is:26.21% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 46.47% & 1.36\n",
      "for 2020-06-24, MAE is:2.84 & sMAPE is:8.13% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 46.25% & 1.35\n",
      "for 2020-06-25, MAE is:41.68 & sMAPE is:47.46% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 46.26% & 1.35\n",
      "for 2020-06-26, MAE is:11.30 & sMAPE is:24.05% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 46.13% & 1.34\n",
      "for 2020-06-27, MAE is:11.82 & sMAPE is:42.21% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 46.11% & 1.34\n",
      "for 2020-06-28, MAE is:5.50 & sMAPE is:20.92% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 45.97% & 1.33\n",
      "for 2020-06-29, MAE is:7.72 & sMAPE is:36.99% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 45.92% & 1.33\n",
      "for 2020-06-30, MAE is:7.84 & sMAPE is:36.91% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 45.87% & 1.33\n",
      "for 2020-07-01, MAE is:8.58 & sMAPE is:60.68% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 45.95% & 1.32\n",
      "for 2020-07-02, MAE is:6.06 & sMAPE is:24.28% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 45.83% & 1.32\n",
      "for 2020-07-03, MAE is:12.42 & sMAPE is:51.68% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 45.86% & 1.31\n",
      "for 2020-07-04, MAE is:23.11 & sMAPE is:157.44% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 46.46% & 1.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-05, MAE is:14.07 & sMAPE is:152.37% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 47.03% & 1.31\n",
      "for 2020-07-06, MAE is:14.58 & sMAPE is:136.69% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 47.51% & 1.30\n",
      "for 2020-07-07, MAE is:6.59 & sMAPE is:72.58% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 47.64% & 1.30\n",
      "for 2020-07-08, MAE is:5.62 & sMAPE is:28.38% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 47.54% & 1.30\n",
      "for 2020-07-09, MAE is:6.48 & sMAPE is:24.23% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 47.42% & 1.29\n",
      "for 2020-07-10, MAE is:8.86 & sMAPE is:40.84% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 47.38% & 1.29\n",
      "for 2020-07-11, MAE is:4.56 & sMAPE is:43.25% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 47.36% & 1.29\n",
      "for 2020-07-12, MAE is:4.58 & sMAPE is:36.30% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 47.30% & 1.28\n",
      "for 2020-07-13, MAE is:4.96 & sMAPE is:23.40% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 47.18% & 1.28\n",
      "for 2020-07-14, MAE is:4.19 & sMAPE is:19.15% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 47.04% & 1.27\n",
      "for 2020-07-15, MAE is:3.06 & sMAPE is:11.22% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 46.86% & 1.27\n",
      "for 2020-07-16, MAE is:3.70 & sMAPE is:13.15% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 46.69% & 1.27\n",
      "for 2020-07-17, MAE is:10.54 & sMAPE is:31.62% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 46.61% & 1.26\n",
      "for 2020-07-18, MAE is:5.32 & sMAPE is:36.26% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 46.56% & 1.26\n",
      "for 2020-07-19, MAE is:6.57 & sMAPE is:57.49% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 46.61% & 1.27\n",
      "for 2020-07-20, MAE is:10.76 & sMAPE is:39.21% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 46.58% & 1.27\n",
      "for 2020-07-21, MAE is:5.18 & sMAPE is:33.34% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 46.51% & 1.27\n",
      "for 2020-07-22, MAE is:14.54 & sMAPE is:93.13% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 46.74% & 1.27\n",
      "for 2020-07-23, MAE is:6.52 & sMAPE is:58.63% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 46.80% & 1.26\n",
      "for 2020-07-24, MAE is:6.01 & sMAPE is:56.01% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 46.84% & 1.26\n",
      "for 2020-07-25, MAE is:5.56 & sMAPE is:50.60% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 46.86% & 1.26\n",
      "for 2020-07-26, MAE is:5.52 & sMAPE is:44.61% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 46.85% & 1.26\n",
      "for 2020-07-27, MAE is:8.03 & sMAPE is:54.35% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 46.89% & 1.25\n",
      "for 2020-07-28, MAE is:6.27 & sMAPE is:37.62% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 46.84% & 1.25\n",
      "for 2020-07-29, MAE is:5.69 & sMAPE is:41.35% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 46.82% & 1.25\n",
      "for 2020-07-30, MAE is:8.88 & sMAPE is:63.59% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 46.90% & 1.25\n",
      "for 2020-07-31, MAE is:12.18 & sMAPE is:62.88% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 46.97% & 1.24\n",
      "for 2020-08-01, MAE is:3.61 & sMAPE is:11.68% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 46.81% & 1.24\n",
      "for 2020-08-02, MAE is:4.43 & sMAPE is:19.21% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 46.68% & 1.24\n",
      "for 2020-08-03, MAE is:3.63 & sMAPE is:11.62% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 46.51% & 1.23\n",
      "for 2020-08-04, MAE is:7.34 & sMAPE is:35.02% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 46.46% & 1.23\n",
      "for 2020-08-05, MAE is:9.07 & sMAPE is:23.15% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 46.35% & 1.22\n",
      "for 2020-08-06, MAE is:10.25 & sMAPE is:25.43% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 46.26% & 1.22\n",
      "for 2020-08-07, MAE is:3.37 & sMAPE is:9.10% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 46.09% & 1.22\n",
      "for 2020-08-08, MAE is:4.61 & sMAPE is:16.56% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :8.79 & 45.96% & 1.22\n",
      "for 2020-08-09, MAE is:3.81 & sMAPE is:19.88% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 45.84% & 1.21\n",
      "for 2020-08-10, MAE is:7.80 & sMAPE is:24.02% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 45.74% & 1.22\n",
      "for 2020-08-11, MAE is:3.61 & sMAPE is:10.79% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 45.59% & 1.21\n",
      "for 2020-08-12, MAE is:9.34 & sMAPE is:21.83% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 45.48% & 1.22\n",
      "for 2020-08-13, MAE is:6.11 & sMAPE is:13.52% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 45.34% & 1.22\n",
      "for 2020-08-14, MAE is:7.47 & sMAPE is:22.69% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 45.24% & 1.22\n",
      "for 2020-08-15, MAE is:3.48 & sMAPE is:13.20% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 45.10% & 1.22\n",
      "for 2020-08-16, MAE is:6.02 & sMAPE is:28.39% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 45.02% & 1.22\n",
      "for 2020-08-17, MAE is:15.36 & sMAPE is:37.98% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 44.99% & 1.22\n",
      "for 2020-08-18, MAE is:32.00 & sMAPE is:46.09% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 45.00% & 1.22\n",
      "for 2020-08-19, MAE is:17.10 & sMAPE is:32.09% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 44.94% & 1.22\n",
      "for 2020-08-20, MAE is:17.24 & sMAPE is:39.00% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 44.92% & 1.23\n",
      "for 2020-08-21, MAE is:12.60 & sMAPE is:30.04% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 44.85% & 1.23\n",
      "for 2020-08-22, MAE is:3.68 & sMAPE is:14.36% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 44.72% & 1.22\n",
      "for 2020-08-23, MAE is:5.17 & sMAPE is:20.60% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 44.62% & 1.23\n",
      "for 2020-08-24, MAE is:7.47 & sMAPE is:17.25% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 44.51% & 1.22\n",
      "for 2020-08-25, MAE is:8.16 & sMAPE is:16.01% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 44.39% & 1.22\n",
      "for 2020-08-26, MAE is:4.95 & sMAPE is:13.97% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 44.26% & 1.22\n",
      "for 2020-08-27, MAE is:13.10 & sMAPE is:28.38% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 44.19% & 1.22\n",
      "for 2020-08-28, MAE is:7.34 & sMAPE is:15.63% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 44.08% & 1.21\n",
      "for 2020-08-29, MAE is:6.60 & sMAPE is:21.21% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 43.98% & 1.21\n",
      "for 2020-08-30, MAE is:3.40 & sMAPE is:11.64% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 43.85% & 1.21\n",
      "for 2020-08-31, MAE is:13.62 & sMAPE is:26.55% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 43.78% & 1.21\n",
      "for 2020-09-01, MAE is:7.88 & sMAPE is:17.00% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 43.67% & 1.21\n",
      "for 2020-09-02, MAE is:6.47 & sMAPE is:12.98% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 43.54% & 1.21\n",
      "for 2020-09-03, MAE is:4.91 & sMAPE is:11.80% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 43.41% & 1.21\n",
      "for 2020-09-04, MAE is:4.85 & sMAPE is:12.50% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 43.29% & 1.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-05, MAE is:2.19 & sMAPE is:7.70% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 43.15% & 1.21\n",
      "for 2020-09-06, MAE is:4.55 & sMAPE is:16.08% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 43.04% & 1.21\n",
      "for 2020-09-07, MAE is:9.34 & sMAPE is:21.64% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 42.95% & 1.21\n",
      "for 2020-09-08, MAE is:6.88 & sMAPE is:25.42% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 42.88% & 1.21\n",
      "for 2020-09-09, MAE is:10.87 & sMAPE is:26.27% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 42.82% & 1.21\n",
      "for 2020-09-10, MAE is:12.17 & sMAPE is:35.01% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 42.79% & 1.21\n",
      "for 2020-09-11, MAE is:7.40 & sMAPE is:16.20% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 42.68% & 1.21\n",
      "for 2020-09-12, MAE is:2.75 & sMAPE is:9.65% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 42.55% & 1.21\n",
      "for 2020-09-13, MAE is:4.33 & sMAPE is:21.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 42.47% & 1.21\n",
      "for 2020-09-14, MAE is:13.03 & sMAPE is:32.42% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 42.43% & 1.21\n",
      "for 2020-09-15, MAE is:26.22 & sMAPE is:40.34% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 42.42% & 1.21\n",
      "for 2020-09-16, MAE is:12.78 & sMAPE is:27.02% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 42.36% & 1.21\n",
      "for 2020-09-17, MAE is:13.41 & sMAPE is:39.37% & rMAE is:3.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 42.35% & 1.22\n",
      "for 2020-09-18, MAE is:11.73 & sMAPE is:29.32% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 42.30% & 1.22\n",
      "for 2020-09-19, MAE is:4.73 & sMAPE is:15.66% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 42.20% & 1.22\n",
      "for 2020-09-20, MAE is:2.07 & sMAPE is:9.38% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 42.08% & 1.21\n",
      "for 2020-09-21, MAE is:10.42 & sMAPE is:46.92% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 42.10% & 1.21\n",
      "for 2020-09-22, MAE is:7.95 & sMAPE is:36.75% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 42.08% & 1.21\n",
      "for 2020-09-23, MAE is:8.59 & sMAPE is:26.00% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 42.02% & 1.20\n",
      "for 2020-09-24, MAE is:12.62 & sMAPE is:45.28% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 42.03% & 1.21\n",
      "for 2020-09-25, MAE is:14.30 & sMAPE is:49.54% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 42.06% & 1.21\n",
      "for 2020-09-26, MAE is:3.94 & sMAPE is:19.31% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 41.97% & 1.21\n",
      "for 2020-09-27, MAE is:4.39 & sMAPE is:40.14% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.81 & 41.96% & 1.20\n",
      "for 2020-09-28, MAE is:17.20 & sMAPE is:49.41% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 41.99% & 1.20\n",
      "for 2020-09-29, MAE is:15.05 & sMAPE is:28.73% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 41.94% & 1.20\n",
      "for 2020-09-30, MAE is:7.25 & sMAPE is:16.45% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 41.85% & 1.20\n",
      "for 2020-10-01, MAE is:6.38 & sMAPE is:20.62% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 41.77% & 1.20\n",
      "for 2020-10-02, MAE is:12.77 & sMAPE is:54.17% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 41.82% & 1.20\n",
      "for 2020-10-03, MAE is:6.68 & sMAPE is:51.52% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 41.85% & 1.20\n",
      "for 2020-10-04, MAE is:12.88 & sMAPE is:103.56% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 42.07% & 1.20\n",
      "for 2020-10-05, MAE is:18.61 & sMAPE is:58.19% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 42.13% & 1.21\n",
      "for 2020-10-06, MAE is:4.52 & sMAPE is:17.04% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 42.04% & 1.20\n",
      "for 2020-10-07, MAE is:14.42 & sMAPE is:48.74% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 42.07% & 1.21\n",
      "for 2020-10-08, MAE is:18.59 & sMAPE is:51.80% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 42.10% & 1.21\n",
      "for 2020-10-09, MAE is:13.52 & sMAPE is:40.38% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 42.10% & 1.21\n",
      "for 2020-10-10, MAE is:4.09 & sMAPE is:14.12% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 42.00% & 1.21\n",
      "for 2020-10-11, MAE is:5.77 & sMAPE is:25.55% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 41.94% & 1.21\n",
      "for 2020-10-12, MAE is:14.19 & sMAPE is:30.57% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 41.90% & 1.21\n",
      "for 2020-10-13, MAE is:10.65 & sMAPE is:22.22% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 41.83% & 1.21\n",
      "for 2020-10-14, MAE is:8.86 & sMAPE is:24.96% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 41.77% & 1.21\n",
      "for 2020-10-15, MAE is:6.86 & sMAPE is:19.62% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 41.70% & 1.21\n",
      "for 2020-10-16, MAE is:9.72 & sMAPE is:23.89% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 41.63% & 1.21\n",
      "for 2020-10-17, MAE is:6.71 & sMAPE is:27.48% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 41.59% & 1.21\n",
      "for 2020-10-18, MAE is:4.31 & sMAPE is:18.88% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 41.51% & 1.21\n",
      "for 2020-10-19, MAE is:6.61 & sMAPE is:16.58% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 41.42% & 1.20\n",
      "for 2020-10-20, MAE is:21.75 & sMAPE is:36.51% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 41.41% & 1.21\n",
      "for 2020-10-21, MAE is:9.48 & sMAPE is:27.81% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 41.36% & 1.21\n",
      "for 2020-10-22, MAE is:14.46 & sMAPE is:43.51% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 41.37% & 1.22\n",
      "for 2020-10-23, MAE is:9.92 & sMAPE is:30.80% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 41.33% & 1.22\n",
      "for 2020-10-24, MAE is:5.79 & sMAPE is:29.21% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 41.29% & 1.22\n",
      "for 2020-10-25, MAE is:5.53 & sMAPE is:37.02% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 41.28% & 1.22\n",
      "for 2020-10-26, MAE is:7.72 & sMAPE is:30.44% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :8.96 & 41.24% & 1.21\n",
      "for 2020-10-27, MAE is:13.83 & sMAPE is:57.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 41.30% & 1.21\n",
      "for 2020-10-28, MAE is:13.28 & sMAPE is:65.20% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 41.37% & 1.21\n",
      "for 2020-10-29, MAE is:8.10 & sMAPE is:38.64% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 41.37% & 1.21\n",
      "for 2020-10-30, MAE is:19.18 & sMAPE is:58.40% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.02 & 41.42% & 1.21\n",
      "for 2020-10-31, MAE is:9.79 & sMAPE is:61.21% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 41.49% & 1.21\n",
      "for 2020-11-01, MAE is:12.62 & sMAPE is:108.10% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 41.70% & 1.21\n",
      "for 2020-11-02, MAE is:18.59 & sMAPE is:150.06% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 42.06% & 1.21\n",
      "for 2020-11-03, MAE is:12.64 & sMAPE is:101.91% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 42.25% & 1.21\n",
      "for 2020-11-04, MAE is:14.40 & sMAPE is:111.34% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.10 & 42.48% & 1.21\n",
      "for 2020-11-05, MAE is:19.30 & sMAPE is:151.66% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 42.83% & 1.21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-06, MAE is:13.17 & sMAPE is:84.34% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.14 & 42.96% & 1.21\n",
      "for 2020-11-07, MAE is:17.19 & sMAPE is:137.43% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 43.26% & 1.21\n",
      "for 2020-11-08, MAE is:13.15 & sMAPE is:70.53% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 43.35% & 1.21\n",
      "for 2020-11-09, MAE is:19.94 & sMAPE is:55.43% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 43.39% & 1.21\n",
      "for 2020-11-10, MAE is:22.34 & sMAPE is:39.21% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 43.38% & 1.20\n",
      "for 2020-11-11, MAE is:11.89 & sMAPE is:31.15% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 43.34% & 1.20\n",
      "for 2020-11-12, MAE is:17.75 & sMAPE is:52.42% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 43.37% & 1.20\n",
      "for 2020-11-13, MAE is:14.95 & sMAPE is:53.84% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 43.40% & 1.20\n",
      "for 2020-11-14, MAE is:20.67 & sMAPE is:121.69% & rMAE is:3.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 43.64% & 1.21\n",
      "for 2020-11-15, MAE is:18.11 & sMAPE is:144.39% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 43.96% & 1.21\n",
      "for 2020-11-16, MAE is:15.72 & sMAPE is:107.12% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 44.16% & 1.20\n",
      "for 2020-11-17, MAE is:16.53 & sMAPE is:102.19% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 44.34% & 1.20\n",
      "for 2020-11-18, MAE is:17.66 & sMAPE is:93.79% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 44.49% & 1.20\n",
      "for 2020-11-19, MAE is:13.73 & sMAPE is:83.99% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 44.61% & 1.20\n",
      "for 2020-11-20, MAE is:29.31 & sMAPE is:70.23% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 44.69% & 1.20\n",
      "for 2020-11-21, MAE is:25.76 & sMAPE is:125.12% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 44.94% & 1.20\n",
      "for 2020-11-22, MAE is:17.25 & sMAPE is:157.82% & rMAE is:5.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 45.28% & 1.22\n",
      "for 2020-11-23, MAE is:14.40 & sMAPE is:87.78% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 45.41% & 1.22\n",
      "for 2020-11-24, MAE is:16.33 & sMAPE is:63.10% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 45.47% & 1.22\n",
      "for 2020-11-25, MAE is:21.32 & sMAPE is:82.87% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 45.58% & 1.21\n",
      "for 2020-11-26, MAE is:25.06 & sMAPE is:75.31% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 45.67% & 1.21\n",
      "for 2020-11-27, MAE is:25.40 & sMAPE is:48.54% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 45.68% & 1.21\n",
      "for 2020-11-28, MAE is:8.02 & sMAPE is:19.96% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 45.60% & 1.21\n",
      "for 2020-11-29, MAE is:7.84 & sMAPE is:25.15% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 45.54% & 1.21\n",
      "for 2020-11-30, MAE is:39.61 & sMAPE is:44.18% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.83 & 45.53% & 1.21\n",
      "for 2020-12-01, MAE is:35.77 & sMAPE is:63.15% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 45.59% & 1.21\n",
      "for 2020-12-02, MAE is:28.02 & sMAPE is:58.17% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 45.62% & 1.20\n",
      "for 2020-12-03, MAE is:10.36 & sMAPE is:39.75% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 45.61% & 1.20\n",
      "for 2020-12-04, MAE is:7.44 & sMAPE is:26.07% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 45.55% & 1.20\n",
      "for 2020-12-05, MAE is:3.54 & sMAPE is:16.13% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 45.46% & 1.20\n",
      "for 2020-12-06, MAE is:4.38 & sMAPE is:19.29% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 45.39% & 1.20\n",
      "for 2020-12-07, MAE is:11.37 & sMAPE is:37.61% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 45.36% & 1.19\n",
      "for 2020-12-08, MAE is:15.14 & sMAPE is:33.36% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.94 & 45.33% & 1.19\n",
      "for 2020-12-09, MAE is:18.44 & sMAPE is:35.74% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 45.30% & 1.19\n",
      "for 2020-12-10, MAE is:29.07 & sMAPE is:48.50% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 45.31% & 1.19\n",
      "for 2020-12-11, MAE is:18.90 & sMAPE is:36.27% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 45.28% & 1.19\n",
      "for 2020-12-12, MAE is:17.36 & sMAPE is:38.89% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 45.27% & 1.19\n",
      "for 2020-12-13, MAE is:16.66 & sMAPE is:34.46% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 45.23% & 1.19\n",
      "for 2020-12-14, MAE is:57.55 & sMAPE is:56.68% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 45.27% & 1.19\n",
      "for 2020-12-15, MAE is:9.71 & sMAPE is:24.36% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 45.21% & 1.19\n",
      "for 2020-12-16, MAE is:17.96 & sMAPE is:34.16% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 45.18% & 1.19\n",
      "for 2020-12-17, MAE is:14.96 & sMAPE is:31.73% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.14% & 1.19\n",
      "for 2020-12-18, MAE is:11.92 & sMAPE is:28.59% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.09% & 1.19\n",
      "for 2020-12-19, MAE is:10.88 & sMAPE is:39.39% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.07% & 1.19\n",
      "for 2020-12-20, MAE is:2.99 & sMAPE is:17.53% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 45.00% & 1.18\n",
      "for 2020-12-21, MAE is:16.37 & sMAPE is:48.07% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.01% & 1.18\n",
      "for 2020-12-22, MAE is:9.90 & sMAPE is:43.68% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.00% & 1.18\n",
      "for 2020-12-23, MAE is:10.89 & sMAPE is:38.34% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 44.98% & 1.18\n",
      "for 2020-12-24, MAE is:5.21 & sMAPE is:25.92% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 44.93% & 1.17\n",
      "for 2020-12-25, MAE is:2.76 & sMAPE is:15.73% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 44.85% & 1.17\n",
      "for 2020-12-26, MAE is:13.29 & sMAPE is:45.29% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 44.85% & 1.17\n",
      "for 2020-12-27, MAE is:22.17 & sMAPE is:123.69% & rMAE is:2.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 45.07% & 1.17\n",
      "for 2020-12-28, MAE is:9.49 & sMAPE is:38.21% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.05% & 1.17\n",
      "for 2020-12-29, MAE is:8.72 & sMAPE is:25.91% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 45.00% & 1.17\n",
      "for 2020-12-30, MAE is:10.88 & sMAPE is:31.91% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 44.96% & 1.17\n",
      "for 2020-12-31, MAE is:10.85 & sMAPE is:29.79% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 44.92% & 1.17\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:13:43,678]\u001b[0m A new study created in RDB with name: FI_2021\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:14:02,269]\u001b[0m Trial 0 finished with value: 12.813752416957831 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23356429238410611, 'dropout_rate_Layer_2': 0.2895177235751562, 'dropout_rate_Layer_3': 0.13811964446957742, 'dropout_rate_Layer_4': 0.23512881495271107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032357461094841447, 'l1_Layer_2': 2.5278958822460455e-05, 'l1_Layer_3': 0.001538041990319464, 'l1_Layer_4': 0.009407852546072591, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 0 with value: 12.813752416957831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.81 | sMAPE for Validation Set is: 53.30% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 34.34 | sMAPE for Test Set is: 46.69% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:14:19,849]\u001b[0m Trial 1 finished with value: 13.794759316023788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0994312055922404, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3300030187772457, 'dropout_rate_Layer_2': 0.03604777472282006, 'dropout_rate_Layer_3': 0.05307700861067186, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029916299186771114, 'l1_Layer_2': 5.721154410662058e-05, 'l1_Layer_3': 0.011397007896641838, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75}. Best is trial 0 with value: 12.813752416957831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.79 | sMAPE for Validation Set is: 55.78% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 36.53 | sMAPE for Test Set is: 50.85% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:15:33,104]\u001b[0m Trial 2 finished with value: 18.43349285396693 and parameters: {'n_hidden': 4, 'learning_rate': 0.04957571112605778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12241905910384072, 'dropout_rate_Layer_2': 0.1669226097601424, 'dropout_rate_Layer_3': 0.2883681312389442, 'dropout_rate_Layer_4': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00041300516202926124, 'l1_Layer_2': 0.006776833188207501, 'l1_Layer_3': 0.003622560816032839, 'l1_Layer_4': 1.8618864261152286e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155, 'n_units_Layer_4': 240}. Best is trial 0 with value: 12.813752416957831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.43 | sMAPE for Validation Set is: 65.79% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 40.66 | sMAPE for Test Set is: 58.49% | rMAE for Test Set is: 1.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:15:47,588]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:16:04,910]\u001b[0m Trial 4 finished with value: 15.719190359097892 and parameters: {'n_hidden': 3, 'learning_rate': 0.000538931037206045, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36034107667384696, 'dropout_rate_Layer_2': 0.341581972917073, 'dropout_rate_Layer_3': 0.07492186353135755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.815941733649343e-05, 'l1_Layer_2': 0.00019109307464167227, 'l1_Layer_3': 0.00017941955197833077, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 95}. Best is trial 0 with value: 12.813752416957831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.72 | sMAPE for Validation Set is: 61.98% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 51.13 | sMAPE for Test Set is: 84.16% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:16:40,859]\u001b[0m Trial 5 finished with value: 11.5187078387403 and parameters: {'n_hidden': 3, 'learning_rate': 0.06273340606916275, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.267437882750762, 'dropout_rate_Layer_2': 0.11718456276956052, 'dropout_rate_Layer_3': 0.3727669795240734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005175857267555478, 'l1_Layer_2': 0.00016571962859674677, 'l1_Layer_3': 0.01999031829135244, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 115}. Best is trial 5 with value: 11.5187078387403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.52 | sMAPE for Validation Set is: 48.83% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 32.66 | sMAPE for Test Set is: 45.73% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:16:52,206]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:17:29,537]\u001b[0m Trial 7 finished with value: 13.14985973351513 and parameters: {'n_hidden': 3, 'learning_rate': 0.038497387756701106, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3912062307123102, 'dropout_rate_Layer_2': 0.3483502174341135, 'dropout_rate_Layer_3': 0.2725031564893123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.991703910310738e-05, 'l1_Layer_2': 0.00019580891007468725, 'l1_Layer_3': 0.015569334069484185, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 5 with value: 11.5187078387403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.15 | sMAPE for Validation Set is: 54.29% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 32.29 | sMAPE for Test Set is: 43.41% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:17:33,748]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:17:40,516]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:17:44,994]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:17:49,478]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:17:53,555]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:17:58,969]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:04,237]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:08,498]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:13,110]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:18,619]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:27,537]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:31,634]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:42,066]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:46,811]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:51,757]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:18:58,541]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:04,462]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:11,244]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:17,898]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:22,761]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:27,215]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:36,104]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:41,585]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:45,922]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:19:50,616]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:21:45,231]\u001b[0m Trial 33 finished with value: 10.96464814411011 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027629315292925435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11065952724651945, 'dropout_rate_Layer_2': 0.20605594067041447, 'dropout_rate_Layer_3': 0.3146414138564674, 'dropout_rate_Layer_4': 0.12967861066906303, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0015722313373841199, 'l1_Layer_2': 1.2575175174826582e-05, 'l1_Layer_3': 0.001994223524333624, 'l1_Layer_4': 0.004731388088381415, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 205}. Best is trial 33 with value: 10.96464814411011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.96 | sMAPE for Validation Set is: 47.81% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 30.32 | sMAPE for Test Set is: 39.22% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:21:49,991]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:01,690]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:05,754]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:10,890]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:16,173]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:20,114]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:24,113]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:28,472]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:22:31,969]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:23:00,928]\u001b[0m Trial 43 finished with value: 10.420690447591253 and parameters: {'n_hidden': 3, 'learning_rate': 0.019558005287974026, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21003947169851137, 'dropout_rate_Layer_2': 0.3257030743457425, 'dropout_rate_Layer_3': 0.15773904561185023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008988133106807028, 'l1_Layer_2': 2.0353029775301785e-05, 'l1_Layer_3': 0.0008483196956231498, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 170}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.42 | sMAPE for Validation Set is: 45.12% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 31.27 | sMAPE for Test Set is: 42.90% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:23:05,126]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:23:11,272]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:23:17,079]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:23:23,744]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:23:32,338]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:23:48,945]\u001b[0m Trial 49 finished with value: 20.706981807521014 and parameters: {'n_hidden': 4, 'learning_rate': 0.009566511106001385, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3010756940469215, 'dropout_rate_Layer_2': 0.16331309988752984, 'dropout_rate_Layer_3': 0.1965397474760213, 'dropout_rate_Layer_4': 0.1318640488429923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.03465019250457406, 'l1_Layer_2': 0.03979369732001144, 'l1_Layer_3': 0.0017252214976165162, 'l1_Layer_4': 0.0019774600864238454, 'n_units_Layer_1': 295, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190, 'n_units_Layer_4': 160}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.71 | sMAPE for Validation Set is: 69.93% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 38.95 | sMAPE for Test Set is: 55.00% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:24:00,254]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:08,046]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:12,454]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:17,323]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:22,401]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:26,862]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:31,936]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:39,860]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:44,106]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:51,025]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:24:55,242]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:25:09,502]\u001b[0m Trial 61 finished with value: 15.747291669296578 and parameters: {'n_hidden': 3, 'learning_rate': 0.015789228365588385, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1915951660716237, 'dropout_rate_Layer_2': 0.2773772745360264, 'dropout_rate_Layer_3': 0.12021673026820294, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.002138956304894828, 'l1_Layer_2': 0.00018442457790608964, 'l1_Layer_3': 0.00013090576315876612, 'n_units_Layer_1': 50, 'n_units_Layer_2': 80, 'n_units_Layer_3': 55}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.75 | sMAPE for Validation Set is: 62.62% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 51.04 | sMAPE for Test Set is: 84.65% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:26:34,569]\u001b[0m Trial 62 finished with value: 12.248986782208569 and parameters: {'n_hidden': 3, 'learning_rate': 0.001142132531823054, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31671068721066936, 'dropout_rate_Layer_2': 0.33945326896691325, 'dropout_rate_Layer_3': 0.0819760961607639, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006079329337164799, 'l1_Layer_2': 9.41805014019519e-05, 'l1_Layer_3': 5.654810789890843e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.25 | sMAPE for Validation Set is: 51.85% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 32.47 | sMAPE for Test Set is: 43.05% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:26:40,062]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:27:18,741]\u001b[0m Trial 64 finished with value: 12.777033680725006 and parameters: {'n_hidden': 3, 'learning_rate': 0.027551150878712332, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39268545872923516, 'dropout_rate_Layer_2': 0.34554285852574185, 'dropout_rate_Layer_3': 0.30341121708702073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03777106675133103, 'l1_Layer_2': 0.0004198034514479053, 'l1_Layer_3': 2.5156672394031466e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.78 | sMAPE for Validation Set is: 50.68% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 33.64 | sMAPE for Test Set is: 46.43% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:27:27,490]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:27:50,615]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:27:56,326]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:28:00,177]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:28:05,625]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:28:52,701]\u001b[0m Trial 70 finished with value: 10.464997472825045 and parameters: {'n_hidden': 3, 'learning_rate': 0.010826176187698267, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24472155069640658, 'dropout_rate_Layer_2': 0.3771188803815185, 'dropout_rate_Layer_3': 0.3415173736096326, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024850769223685364, 'l1_Layer_2': 6.994319187787214e-05, 'l1_Layer_3': 0.0026472793990210504, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 135}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.46 | sMAPE for Validation Set is: 46.19% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 30.34 | sMAPE for Test Set is: 39.58% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:29:04,988]\u001b[0m Trial 71 finished with value: 14.44148557650567 and parameters: {'n_hidden': 3, 'learning_rate': 0.014084287422939356, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2786061776111916, 'dropout_rate_Layer_2': 0.28696317691829976, 'dropout_rate_Layer_3': 0.10935885610702648, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.005062933088034299, 'l1_Layer_2': 7.06659671802915e-05, 'l1_Layer_3': 0.00011436691343879587, 'n_units_Layer_1': 255, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.44 | sMAPE for Validation Set is: 57.70% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 34.68 | sMAPE for Test Set is: 47.06% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:29:08,966]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:29:12,553]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:29:15,668]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:29:30,614]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:29:35,332]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:29:42,750]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:29:47,393]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:01,783]\u001b[0m Trial 79 finished with value: 12.862763834575203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0907839636306977, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35470344262288256, 'dropout_rate_Layer_2': 0.1684687461815583, 'dropout_rate_Layer_3': 0.15603644104790504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003404457239000671, 'l1_Layer_2': 2.2435072721336244e-05, 'l1_Layer_3': 0.00698974612088344, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.86 | sMAPE for Validation Set is: 51.73% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 35.13 | sMAPE for Test Set is: 49.23% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:30:08,829]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:19,522]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:24,113]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:27,868]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:31,624]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:40,763]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:45,161]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:55,496]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:30:59,463]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:05,395]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:10,356]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:14,575]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:21,454]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:26,573]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:31,092]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:31:37,398]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:32:08,994]\u001b[0m Trial 96 finished with value: 10.97014748642178 and parameters: {'n_hidden': 3, 'learning_rate': 0.004254071218218566, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06638945650073708, 'dropout_rate_Layer_2': 0.32882516071658635, 'dropout_rate_Layer_3': 0.11035051612210212, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010522194205438609, 'l1_Layer_2': 0.0014258011486175067, 'l1_Layer_3': 0.0008423722572004924, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190}. Best is trial 43 with value: 10.420690447591253.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.97 | sMAPE for Validation Set is: 47.33% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 31.08 | sMAPE for Test Set is: 41.42% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:32:14,371]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:32:29,760]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:32:46,203]\u001b[0m Trial 99 finished with value: 9.782623248083125 and parameters: {'n_hidden': 4, 'learning_rate': 0.00875122433399415, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04693095596648936, 'dropout_rate_Layer_2': 0.28269738047964527, 'dropout_rate_Layer_3': 0.1759581970921504, 'dropout_rate_Layer_4': 0.1594979374248564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013580263519104646, 'l1_Layer_2': 3.51771376003055e-05, 'l1_Layer_3': 0.00013896309315393956, 'l1_Layer_4': 0.000519794226650108, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95, 'n_units_Layer_4': 235}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 43.45% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 28.65 | sMAPE for Test Set is: 38.35% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:32:54,378]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:04,348]\u001b[0m Trial 101 finished with value: 19.799362168475888 and parameters: {'n_hidden': 3, 'learning_rate': 0.08522107375803258, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2659184874467637, 'dropout_rate_Layer_2': 0.3887480575371629, 'dropout_rate_Layer_3': 0.31732238493875736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00013656933160956897, 'l1_Layer_2': 4.154039389616468e-05, 'l1_Layer_3': 0.0004403130580666607, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.80 | sMAPE for Validation Set is: 68.41% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 38.07 | sMAPE for Test Set is: 53.50% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:33:18,129]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:24,393]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:30,344]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:36,691]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:42,213]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:50,870]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:33:56,115]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:14,105]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:19,584]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:32,403]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:36,421]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:41,402]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:52,408]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:34:58,728]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:35:19,926]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:35:23,931]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:35:35,460]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:35:39,688]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:35:43,407]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:35:47,145]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:36:05,208]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:36:10,654]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:37:28,158]\u001b[0m Trial 124 finished with value: 9.940026190210075 and parameters: {'n_hidden': 3, 'learning_rate': 0.004804782758113919, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06945822676878552, 'dropout_rate_Layer_2': 0.25545408757234916, 'dropout_rate_Layer_3': 0.1611807846611532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.832404505935402e-05, 'l1_Layer_2': 0.00024275870763346423, 'l1_Layer_3': 0.0008930668928143256, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 185}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.94 | sMAPE for Validation Set is: 44.24% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 29.00 | sMAPE for Test Set is: 37.11% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:37:32,539]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:37:39,075]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:37:54,133]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:38:36,300]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:38:40,958]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:38:45,528]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:38:51,635]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:38:55,469]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:38:59,904]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:39:08,110]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:39:18,960]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:39:37,849]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:39:48,109]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:39:53,198]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:39:57,147]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:40:07,977]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:40:15,119]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:40:21,300]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:42:38,087]\u001b[0m Trial 143 finished with value: 10.710627871083792 and parameters: {'n_hidden': 3, 'learning_rate': 0.008023680534444497, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08181297631703258, 'dropout_rate_Layer_2': 0.17765564119468263, 'dropout_rate_Layer_3': 0.26801886263450014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007352390339641841, 'l1_Layer_2': 7.090944102645725e-05, 'l1_Layer_3': 0.09969566991194903, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.71 | sMAPE for Validation Set is: 46.85% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 37.06 | sMAPE for Test Set is: 48.88% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:43:40,147]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:43:50,565]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:43:54,453]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:02,164]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:05,978]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:10,479]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:18,061]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:30,895]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:35,412]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:44:40,184]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:45:02,691]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:45:23,966]\u001b[0m Trial 155 finished with value: 12.144295979878256 and parameters: {'n_hidden': 3, 'learning_rate': 0.014181911654688512, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29391697308433895, 'dropout_rate_Layer_2': 0.2855054777631292, 'dropout_rate_Layer_3': 0.12117412058547695, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010527926172556725, 'l1_Layer_2': 0.00011266082793292733, 'l1_Layer_3': 0.00023506488663217604, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 185}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.14 | sMAPE for Validation Set is: 51.91% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 31.66 | sMAPE for Test Set is: 43.30% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:45:44,234]\u001b[0m Trial 156 finished with value: 10.591242483762148 and parameters: {'n_hidden': 3, 'learning_rate': 0.01412149230827973, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2919090023024161, 'dropout_rate_Layer_2': 0.2820372030369428, 'dropout_rate_Layer_3': 0.09212902269988132, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006838227672617525, 'l1_Layer_2': 0.00011164224672901764, 'l1_Layer_3': 0.00024301034010415948, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.59 | sMAPE for Validation Set is: 46.90% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 32.39 | sMAPE for Test Set is: 44.98% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:45:50,410]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:45:56,537]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:46:13,794]\u001b[0m Trial 159 finished with value: 12.529765088872546 and parameters: {'n_hidden': 3, 'learning_rate': 0.008865768923836623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2977637754292417, 'dropout_rate_Layer_2': 0.27671165563710937, 'dropout_rate_Layer_3': 0.09450304637678784, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012386623979002273, 'l1_Layer_2': 0.00020618779366499612, 'l1_Layer_3': 0.00010821016261745299, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 180}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.53 | sMAPE for Validation Set is: 51.85% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 36.14 | sMAPE for Test Set is: 49.60% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:46:21,188]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:46:49,686]\u001b[0m Trial 161 finished with value: 13.36635034302815 and parameters: {'n_hidden': 3, 'learning_rate': 0.01030338411060325, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2856164637478037, 'dropout_rate_Layer_2': 0.24689276687940875, 'dropout_rate_Layer_3': 0.08063470310615067, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012440903982168065, 'l1_Layer_2': 0.0002579326402405187, 'l1_Layer_3': 0.00010866676478609159, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.37 | sMAPE for Validation Set is: 54.04% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 36.26 | sMAPE for Test Set is: 50.78% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:47:07,060]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:47:26,796]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:48:03,919]\u001b[0m Trial 164 finished with value: 13.530035527086744 and parameters: {'n_hidden': 4, 'learning_rate': 0.008466193146450376, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28340844577337654, 'dropout_rate_Layer_2': 0.24962677686092485, 'dropout_rate_Layer_3': 0.08318322314124144, 'dropout_rate_Layer_4': 0.33471087836973656, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001360324068136622, 'l1_Layer_2': 0.0002396716436517506, 'l1_Layer_3': 0.00010854012564495504, 'l1_Layer_4': 8.94980108725127e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175, 'n_units_Layer_4': 165}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.53 | sMAPE for Validation Set is: 55.37% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 34.32 | sMAPE for Test Set is: 46.92% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:48:15,516]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:48:36,537]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:49:36,459]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:50:11,094]\u001b[0m Trial 168 finished with value: 13.687017633341592 and parameters: {'n_hidden': 4, 'learning_rate': 0.008699854258628518, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30278388396615646, 'dropout_rate_Layer_2': 0.25223367748959147, 'dropout_rate_Layer_3': 0.07925701072960617, 'dropout_rate_Layer_4': 0.3378825089363733, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006071323529825661, 'l1_Layer_2': 0.0002928095748256503, 'l1_Layer_3': 0.00010413168045670118, 'l1_Layer_4': 7.768278037631895e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175, 'n_units_Layer_4': 175}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.69 | sMAPE for Validation Set is: 55.14% | rMAE for Validation Set is: 1.09\n",
      "MAE for Test Set is: 33.77 | sMAPE for Test Set is: 46.02% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:50:18,505]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:50:27,680]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:50:36,008]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:51:15,429]\u001b[0m Trial 172 finished with value: 13.249723362484351 and parameters: {'n_hidden': 4, 'learning_rate': 0.00731109166588439, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30033991378771596, 'dropout_rate_Layer_2': 0.24096741881929512, 'dropout_rate_Layer_3': 0.09407499635065748, 'dropout_rate_Layer_4': 0.3517831058360831, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012265399723337775, 'l1_Layer_2': 0.00036868021125021445, 'l1_Layer_3': 9.162885952670845e-05, 'l1_Layer_4': 6.251024477629243e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 70, 'n_units_Layer_3': 170, 'n_units_Layer_4': 110}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.25 | sMAPE for Validation Set is: 54.31% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 37.73 | sMAPE for Test Set is: 52.87% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:51:23,396]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:51:52,152]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:52:08,857]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:52:14,714]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:52:49,381]\u001b[0m Trial 177 finished with value: 12.798980105585153 and parameters: {'n_hidden': 4, 'learning_rate': 0.006469622220160691, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31869039741199995, 'dropout_rate_Layer_2': 0.2573527610500683, 'dropout_rate_Layer_3': 0.06808107386552469, 'dropout_rate_Layer_4': 0.3325447051067118, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0012443115769574455, 'l1_Layer_2': 0.0004197175264062039, 'l1_Layer_3': 5.641643482545655e-05, 'l1_Layer_4': 0.00010361041588899344, 'n_units_Layer_1': 145, 'n_units_Layer_2': 85, 'n_units_Layer_3': 180, 'n_units_Layer_4': 170}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.80 | sMAPE for Validation Set is: 53.12% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 34.94 | sMAPE for Test Set is: 47.85% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:52:53,981]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:53:02,599]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:53:08,394]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:53:24,294]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:12,248]\u001b[0m Trial 182 finished with value: 9.848432438406773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027663625628075146, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0932767202752848, 'dropout_rate_Layer_2': 0.24957247786651623, 'dropout_rate_Layer_3': 0.16443302067585341, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014996892111660888, 'l1_Layer_2': 0.0008810109304992821, 'l1_Layer_3': 0.00017320037142521435, 'n_units_Layer_1': 125, 'n_units_Layer_2': 105, 'n_units_Layer_3': 95}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.85 | sMAPE for Validation Set is: 43.91% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 29.14 | sMAPE for Test Set is: 37.85% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:54:17,907]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:27,009]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:37,874]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:54:53,842]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:56:47,213]\u001b[0m Trial 187 finished with value: 11.826604482580803 and parameters: {'n_hidden': 3, 'learning_rate': 0.005640155089164469, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03538381911834631, 'dropout_rate_Layer_2': 0.21907447543880762, 'dropout_rate_Layer_3': 0.2208257656301525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00113247837805358, 'l1_Layer_2': 5.092360613880499e-05, 'l1_Layer_3': 0.00050020018596191, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 250}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.83 | sMAPE for Validation Set is: 50.51% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 30.81 | sMAPE for Test Set is: 40.35% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:57:23,201]\u001b[0m Trial 188 finished with value: 11.117271956503117 and parameters: {'n_hidden': 4, 'learning_rate': 0.0021733811585186655, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07819317893726241, 'dropout_rate_Layer_2': 0.22582502702549265, 'dropout_rate_Layer_3': 0.11480843402865827, 'dropout_rate_Layer_4': 0.0712574072506961, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00010773166621028323, 'l1_Layer_2': 0.0006378145197893642, 'l1_Layer_3': 0.0001159834238183638, 'l1_Layer_4': 4.099443170618892e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 85, 'n_units_Layer_4': 115}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.12 | sMAPE for Validation Set is: 48.71% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 30.19 | sMAPE for Test Set is: 39.32% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:57:45,931]\u001b[0m Trial 189 finished with value: 12.836153158645667 and parameters: {'n_hidden': 4, 'learning_rate': 0.0068840351895752975, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3299200779430046, 'dropout_rate_Layer_2': 0.26162221801364693, 'dropout_rate_Layer_3': 0.10403941704687594, 'dropout_rate_Layer_4': 0.37030189062954133, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0005076400393883966, 'l1_Layer_2': 0.0001461676276633458, 'l1_Layer_3': 4.728150897057005e-05, 'l1_Layer_4': 3.409230616634406e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 190}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.84 | sMAPE for Validation Set is: 53.08% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 38.48 | sMAPE for Test Set is: 54.85% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:58:10,427]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:32,122]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:58:52,887]\u001b[0m Trial 192 finished with value: 12.637350178907177 and parameters: {'n_hidden': 4, 'learning_rate': 0.007921607610682098, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3254679738722287, 'dropout_rate_Layer_2': 0.21766505616410833, 'dropout_rate_Layer_3': 0.10420428550243639, 'dropout_rate_Layer_4': 0.37439251231812465, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008543950964545383, 'l1_Layer_2': 0.00024090434016427818, 'l1_Layer_3': 3.1521399667547625e-05, 'l1_Layer_4': 1.6579289767582235e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205, 'n_units_Layer_4': 240}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.64 | sMAPE for Validation Set is: 52.45% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 34.56 | sMAPE for Test Set is: 47.16% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:58:57,958]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:04,158]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:13,347]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 10:59:30,309]\u001b[0m Trial 196 finished with value: 12.57211687798177 and parameters: {'n_hidden': 4, 'learning_rate': 0.012518432854352567, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31729829211827504, 'dropout_rate_Layer_2': 0.2614946685557738, 'dropout_rate_Layer_3': 0.1094087397777754, 'dropout_rate_Layer_4': 0.3644053405890588, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004558782407473843, 'l1_Layer_2': 0.0002058066582750598, 'l1_Layer_3': 3.567286788099319e-05, 'l1_Layer_4': 2.2163473494175354e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210, 'n_units_Layer_4': 275}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.57 | sMAPE for Validation Set is: 52.27% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 38.86 | sMAPE for Test Set is: 56.44% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 10:59:35,555]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:26,411]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:00:42,938]\u001b[0m Trial 199 finished with value: 13.449894412925318 and parameters: {'n_hidden': 4, 'learning_rate': 0.013060896835522194, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33247865070840527, 'dropout_rate_Layer_2': 0.280111969717853, 'dropout_rate_Layer_3': 0.10784937485965998, 'dropout_rate_Layer_4': 0.3674127142666773, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003042614377957406, 'l1_Layer_2': 0.00020447885890839416, 'l1_Layer_3': 3.414645371950348e-05, 'l1_Layer_4': 1.7559053903264453e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230, 'n_units_Layer_4': 280}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.45 | sMAPE for Validation Set is: 53.76% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 38.35 | sMAPE for Test Set is: 54.34% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:01:57,874]\u001b[0m Trial 200 finished with value: 11.086440931420249 and parameters: {'n_hidden': 4, 'learning_rate': 0.001702085794864506, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07412983201238257, 'dropout_rate_Layer_2': 0.27475374556682525, 'dropout_rate_Layer_3': 0.1730937929899244, 'dropout_rate_Layer_4': 0.25251121347588434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00021468745575480174, 'l1_Layer_2': 0.002026647661394374, 'l1_Layer_3': 1.0003098167685244e-05, 'l1_Layer_4': 0.00010874189086358496, 'n_units_Layer_1': 250, 'n_units_Layer_2': 150, 'n_units_Layer_3': 90, 'n_units_Layer_4': 255}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.09 | sMAPE for Validation Set is: 48.40% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 29.98 | sMAPE for Test Set is: 39.10% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:02:14,765]\u001b[0m Trial 201 finished with value: 12.235814766852856 and parameters: {'n_hidden': 4, 'learning_rate': 0.007543062714007099, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31793651176772336, 'dropout_rate_Layer_2': 0.2605243772715373, 'dropout_rate_Layer_3': 0.09365636471879052, 'dropout_rate_Layer_4': 0.3755989567856834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00046263540960088205, 'l1_Layer_2': 0.00012784945091710699, 'l1_Layer_3': 2.8953440678290786e-05, 'l1_Layer_4': 3.6955441817343806e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205, 'n_units_Layer_4': 285}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.24 | sMAPE for Validation Set is: 51.04% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 38.69 | sMAPE for Test Set is: 56.62% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:02:21,506]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:12,464]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:17,667]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:36,736]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:42,849]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:03:48,701]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:38,576]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:04:44,450]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:00,594]\u001b[0m Trial 210 finished with value: 12.402461410892593 and parameters: {'n_hidden': 4, 'learning_rate': 0.007712145269102593, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3212807632252557, 'dropout_rate_Layer_2': 0.28729831169302256, 'dropout_rate_Layer_3': 0.10675375721160286, 'dropout_rate_Layer_4': 0.35119847806389, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006286755130137925, 'l1_Layer_2': 0.00018632263554056914, 'l1_Layer_3': 4.956130904759376e-05, 'l1_Layer_4': 4.462121132786874e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 55, 'n_units_Layer_3': 205, 'n_units_Layer_4': 250}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.40 | sMAPE for Validation Set is: 51.62% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 34.39 | sMAPE for Test Set is: 47.53% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:05:09,748]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:18,755]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:05:35,328]\u001b[0m Trial 213 finished with value: 11.79674667503619 and parameters: {'n_hidden': 4, 'learning_rate': 0.005315286418820388, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.329681794679259, 'dropout_rate_Layer_2': 0.27487129067711075, 'dropout_rate_Layer_3': 0.10477795578976067, 'dropout_rate_Layer_4': 0.30645461217089015, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00043376504531117014, 'l1_Layer_2': 9.113459650241045e-05, 'l1_Layer_3': 5.293205391725815e-05, 'l1_Layer_4': 1.6599805486439197e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220, 'n_units_Layer_4': 240}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.80 | sMAPE for Validation Set is: 49.73% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 39.47 | sMAPE for Test Set is: 58.78% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:05:54,928]\u001b[0m Trial 214 finished with value: 12.447317923994781 and parameters: {'n_hidden': 4, 'learning_rate': 0.010675956225274915, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2609685103890144, 'dropout_rate_Layer_2': 0.3078032518510796, 'dropout_rate_Layer_3': 0.13570223505969747, 'dropout_rate_Layer_4': 0.39699032270040424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010428187890229865, 'l1_Layer_2': 0.0014947382650414836, 'l1_Layer_3': 0.0012624400722417168, 'l1_Layer_4': 4.7546360251944516e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 215, 'n_units_Layer_4': 55}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.45 | sMAPE for Validation Set is: 52.24% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 35.78 | sMAPE for Test Set is: 48.86% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:06:12,328]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:18,075]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:24,124]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:29,498]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:33,844]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:06:50,281]\u001b[0m Trial 220 finished with value: 12.332214204864359 and parameters: {'n_hidden': 4, 'learning_rate': 0.009559974296655139, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.321966344569463, 'dropout_rate_Layer_2': 0.27443491389323804, 'dropout_rate_Layer_3': 0.11462884877168762, 'dropout_rate_Layer_4': 0.2568872465897656, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00030066762780259877, 'l1_Layer_2': 0.00020901473476213976, 'l1_Layer_3': 5.565962345334777e-05, 'l1_Layer_4': 1.2781197535517764e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235, 'n_units_Layer_4': 260}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.33 | sMAPE for Validation Set is: 51.12% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 36.73 | sMAPE for Test Set is: 51.24% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:06:59,889]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:07,445]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:07:27,354]\u001b[0m Trial 223 finished with value: 11.46661043507143 and parameters: {'n_hidden': 4, 'learning_rate': 0.027802425802580667, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35756013854201973, 'dropout_rate_Layer_2': 0.28926823882097863, 'dropout_rate_Layer_3': 0.16323036768473578, 'dropout_rate_Layer_4': 0.25812458034821106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007675702870528326, 'l1_Layer_2': 0.0009552968164973918, 'l1_Layer_3': 0.0017303535090463272, 'l1_Layer_4': 5.378718201468499e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235, 'n_units_Layer_4': 130}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.47 | sMAPE for Validation Set is: 48.29% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 43.43 | sMAPE for Test Set is: 66.22% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:07:43,748]\u001b[0m Trial 224 finished with value: 12.332744448045503 and parameters: {'n_hidden': 3, 'learning_rate': 0.007077778067668807, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12122048140592111, 'dropout_rate_Layer_2': 0.24935982261888376, 'dropout_rate_Layer_3': 0.07698293476124005, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003444490410356164, 'l1_Layer_2': 0.00026755252336206045, 'l1_Layer_3': 0.000648297040021859, 'n_units_Layer_1': 90, 'n_units_Layer_2': 145, 'n_units_Layer_3': 70}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.33 | sMAPE for Validation Set is: 51.75% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 32.43 | sMAPE for Test Set is: 44.43% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:07:59,233]\u001b[0m Trial 225 finished with value: 12.335703768539782 and parameters: {'n_hidden': 4, 'learning_rate': 0.00952988588780185, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3241386271982271, 'dropout_rate_Layer_2': 0.27324918800860665, 'dropout_rate_Layer_3': 0.11548991877916219, 'dropout_rate_Layer_4': 0.2675204465117703, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00031899034228515633, 'l1_Layer_2': 0.00019732936909979844, 'l1_Layer_3': 5.611001908025923e-05, 'l1_Layer_4': 1.5438130038637753e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 245, 'n_units_Layer_4': 260}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.34 | sMAPE for Validation Set is: 51.14% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 39.74 | sMAPE for Test Set is: 58.57% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:08:06,564]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:14,715]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:20,107]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:26,071]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:08:39,502]\u001b[0m Trial 230 finished with value: 13.43195718293292 and parameters: {'n_hidden': 4, 'learning_rate': 0.027084154931792264, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34714879333715215, 'dropout_rate_Layer_2': 0.2981903327498295, 'dropout_rate_Layer_3': 0.14231066565451617, 'dropout_rate_Layer_4': 0.3806812677832511, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0014455695962062123, 'l1_Layer_2': 0.0010545668253544127, 'l1_Layer_3': 0.0017420675798527586, 'l1_Layer_4': 7.439755236344795e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240, 'n_units_Layer_4': 125}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.43 | sMAPE for Validation Set is: 54.79% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 41.00 | sMAPE for Test Set is: 59.40% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:08:55,350]\u001b[0m Trial 231 finished with value: 12.461730337466149 and parameters: {'n_hidden': 4, 'learning_rate': 0.009158996211014967, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32495373730038785, 'dropout_rate_Layer_2': 0.28852743141961223, 'dropout_rate_Layer_3': 0.11522699611931672, 'dropout_rate_Layer_4': 0.32010999186240036, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004053549400624481, 'l1_Layer_2': 0.0001720406637015854, 'l1_Layer_3': 3.010741357404247e-05, 'l1_Layer_4': 1.0006246388707772e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 235}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.46 | sMAPE for Validation Set is: 51.53% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 39.28 | sMAPE for Test Set is: 57.15% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:09:10,584]\u001b[0m Trial 232 finished with value: 12.343960663464296 and parameters: {'n_hidden': 4, 'learning_rate': 0.011173386478624585, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3502272577206872, 'dropout_rate_Layer_2': 0.2871311939502016, 'dropout_rate_Layer_3': 0.11723647431401205, 'dropout_rate_Layer_4': 0.2685725011856234, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00038162564438044003, 'l1_Layer_2': 0.00017125937558206978, 'l1_Layer_3': 3.205058037167389e-05, 'l1_Layer_4': 1.0401196273520004e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 265, 'n_units_Layer_4': 235}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.34 | sMAPE for Validation Set is: 50.95% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 39.53 | sMAPE for Test Set is: 57.47% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:09:26,337]\u001b[0m Trial 233 finished with value: 12.169469456402593 and parameters: {'n_hidden': 4, 'learning_rate': 0.010974399257099705, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3574045396670671, 'dropout_rate_Layer_2': 0.2863745307123784, 'dropout_rate_Layer_3': 0.13097246655479813, 'dropout_rate_Layer_4': 0.2733897885334944, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00025561380735051144, 'l1_Layer_2': 0.00018694004696027106, 'l1_Layer_3': 2.5367970234430395e-05, 'l1_Layer_4': 1.0587587792381553e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270, 'n_units_Layer_4': 255}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.17 | sMAPE for Validation Set is: 50.65% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 42.06 | sMAPE for Test Set is: 63.42% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:09:30,691]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:42,609]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:09:59,184]\u001b[0m Trial 236 finished with value: 11.944496931281485 and parameters: {'n_hidden': 4, 'learning_rate': 0.009127479022686279, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3479349287858565, 'dropout_rate_Layer_2': 0.2984919488522023, 'dropout_rate_Layer_3': 0.11870002281971112, 'dropout_rate_Layer_4': 0.2921987293312795, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002004075622414445, 'l1_Layer_2': 0.00017616879388221557, 'l1_Layer_3': 2.522800647651329e-05, 'l1_Layer_4': 1.0970896090781337e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270, 'n_units_Layer_4': 230}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.94 | sMAPE for Validation Set is: 49.76% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 38.94 | sMAPE for Test Set is: 58.07% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:10:28,749]\u001b[0m Trial 237 finished with value: 12.727391349231079 and parameters: {'n_hidden': 4, 'learning_rate': 0.010334263005699377, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2885038443644634, 'dropout_rate_Layer_2': 0.26933976390416414, 'dropout_rate_Layer_3': 0.10278098256768013, 'dropout_rate_Layer_4': 0.3178691920798098, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004652579383943224, 'l1_Layer_2': 0.00018907812562751219, 'l1_Layer_3': 0.00029365389048486255, 'l1_Layer_4': 0.00027896273050399535, 'n_units_Layer_1': 230, 'n_units_Layer_2': 300, 'n_units_Layer_3': 275, 'n_units_Layer_4': 60}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.73 | sMAPE for Validation Set is: 53.12% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 35.22 | sMAPE for Test Set is: 47.72% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:10:45,509]\u001b[0m Trial 238 finished with value: 11.89282956996889 and parameters: {'n_hidden': 4, 'learning_rate': 0.011189852950769866, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35028026517913174, 'dropout_rate_Layer_2': 0.2971518648113746, 'dropout_rate_Layer_3': 0.12573157334891513, 'dropout_rate_Layer_4': 0.26546746670886096, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019226867688420453, 'l1_Layer_2': 0.00012455902794412173, 'l1_Layer_3': 2.2634112803243567e-05, 'l1_Layer_4': 1.091968346477961e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270, 'n_units_Layer_4': 230}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.89 | sMAPE for Validation Set is: 49.63% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 44.50 | sMAPE for Test Set is: 69.75% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:10:49,571]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:10:58,452]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:11:14,864]\u001b[0m Trial 241 finished with value: 12.567808702330737 and parameters: {'n_hidden': 4, 'learning_rate': 0.009879663435553085, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34346232825871, 'dropout_rate_Layer_2': 0.28756600304807867, 'dropout_rate_Layer_3': 0.11719967491827607, 'dropout_rate_Layer_4': 0.265247515165812, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00032334845888227945, 'l1_Layer_2': 0.00016666801463199808, 'l1_Layer_3': 2.6536785797928325e-05, 'l1_Layer_4': 1.0236117468568467e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280, 'n_units_Layer_4': 240}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.57 | sMAPE for Validation Set is: 51.77% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 41.64 | sMAPE for Test Set is: 61.33% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:11:50,372]\u001b[0m Trial 242 finished with value: 10.759031403478696 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026948505584840406, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04369786868494473, 'dropout_rate_Layer_2': 0.3053104255477773, 'dropout_rate_Layer_3': 0.19935185826814633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.876457238495319e-05, 'l1_Layer_2': 1.4372362070136445e-05, 'l1_Layer_3': 0.0002103730596381213, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 50}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.76 | sMAPE for Validation Set is: 47.49% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 30.50 | sMAPE for Test Set is: 39.52% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:12:05,851]\u001b[0m Trial 243 finished with value: 12.119014892376676 and parameters: {'n_hidden': 4, 'learning_rate': 0.009283834453077205, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33844895972651257, 'dropout_rate_Layer_2': 0.2845914699090103, 'dropout_rate_Layer_3': 0.14484211241936462, 'dropout_rate_Layer_4': 0.28241852956611185, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000375076232108424, 'l1_Layer_2': 8.202649646611426e-05, 'l1_Layer_3': 1.8454692288243695e-05, 'l1_Layer_4': 1.0088969291860159e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 230}. Best is trial 99 with value: 9.782623248083125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.12 | sMAPE for Validation Set is: 50.84% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 37.68 | sMAPE for Test Set is: 54.84% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:12:11,017]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:24,062]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:12:47,275]\u001b[0m Trial 246 finished with value: 8.989466544711407 and parameters: {'n_hidden': 4, 'learning_rate': 0.004332955277489509, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27478906757463495, 'dropout_rate_Layer_2': 0.2694069588645089, 'dropout_rate_Layer_3': 0.11574695811667386, 'dropout_rate_Layer_4': 0.2730287572758022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0039363155194012695, 'l1_Layer_2': 0.003433633257355024, 'l1_Layer_3': 0.0010637922704778105, 'l1_Layer_4': 5.1825169798324414e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270, 'n_units_Layer_4': 95}. Best is trial 246 with value: 8.989466544711407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 40.61% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.78 | sMAPE for Test Set is: 31.96% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:13:01,507]\u001b[0m Trial 247 finished with value: 12.441675406631319 and parameters: {'n_hidden': 4, 'learning_rate': 0.013359091029622511, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.348732676683185, 'dropout_rate_Layer_2': 0.2749598411158651, 'dropout_rate_Layer_3': 0.15751989427851437, 'dropout_rate_Layer_4': 0.2884914288823583, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015960874419773503, 'l1_Layer_2': 9.254243474228093e-05, 'l1_Layer_3': 1.3018167822706347e-05, 'l1_Layer_4': 1.3956753731697888e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 255, 'n_units_Layer_4': 255}. Best is trial 246 with value: 8.989466544711407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.44 | sMAPE for Validation Set is: 51.88% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 38.48 | sMAPE for Test Set is: 54.80% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:13:06,918]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:24,045]\u001b[0m Trial 249 finished with value: 12.726838208046795 and parameters: {'n_hidden': 3, 'learning_rate': 0.010790807791249146, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14081929148373445, 'dropout_rate_Layer_2': 0.15951745434243644, 'dropout_rate_Layer_3': 0.33176307808691635, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0011812828987944985, 'l1_Layer_2': 2.6735415328009564e-05, 'l1_Layer_3': 0.020153779671831035, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 246 with value: 8.989466544711407.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.73 | sMAPE for Validation Set is: 64.47% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 34.98 | sMAPE for Test Set is: 50.79% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:13:32,057]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:40,465]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:44,678]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:13:48,631]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:17,848]\u001b[0m Trial 254 finished with value: 8.526232857857186 and parameters: {'n_hidden': 4, 'learning_rate': 0.005481112553601412, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2537428859196357, 'dropout_rate_Layer_2': 0.22787075882506716, 'dropout_rate_Layer_3': 0.17624266197806332, 'dropout_rate_Layer_4': 0.24627230919873525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008679494236025497, 'l1_Layer_2': 0.0029225483881394434, 'l1_Layer_3': 0.0013685874957403443, 'l1_Layer_4': 3.3800287397239675e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270, 'n_units_Layer_4': 105}. Best is trial 254 with value: 8.526232857857186.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 37.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.21 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:14:25,524]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:29,600]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:33,595]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:38,303]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:46,652]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:52,141]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:14:59,462]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:08,144]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:15:34,318]\u001b[0m Trial 263 finished with value: 8.547071142794778 and parameters: {'n_hidden': 4, 'learning_rate': 0.003325405191387339, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3358004488380933, 'dropout_rate_Layer_2': 0.20631446054761549, 'dropout_rate_Layer_3': 0.23242838585309095, 'dropout_rate_Layer_4': 0.2375894415281661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00024363098989428175, 'l1_Layer_2': 0.0028454406382270817, 'l1_Layer_3': 0.002636036522529232, 'l1_Layer_4': 2.5479013254241906e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 225, 'n_units_Layer_3': 265, 'n_units_Layer_4': 95}. Best is trial 254 with value: 8.526232857857186.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 36.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:16:02,205]\u001b[0m Trial 264 finished with value: 8.41478813989899 and parameters: {'n_hidden': 4, 'learning_rate': 0.00396577972307858, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22592491904861026, 'dropout_rate_Layer_2': 0.21270007823651854, 'dropout_rate_Layer_3': 0.225298177877779, 'dropout_rate_Layer_4': 0.22160966661059317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002922382825227511, 'l1_Layer_2': 0.003995531599991261, 'l1_Layer_3': 0.0029222809034947623, 'l1_Layer_4': 1.9194132224089225e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270, 'n_units_Layer_4': 95}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 37.02% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.29 | sMAPE for Test Set is: 29.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:16:07,818]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:12,231]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:17,945]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:22,143]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:26,796]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:31,790]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:16:47,037]\u001b[0m Trial 271 finished with value: 11.802671067621715 and parameters: {'n_hidden': 4, 'learning_rate': 0.009038993826410088, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32625650176619997, 'dropout_rate_Layer_2': 0.28598467343344214, 'dropout_rate_Layer_3': 0.11325436546317562, 'dropout_rate_Layer_4': 0.32777952068428806, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003778546447811362, 'l1_Layer_2': 0.00014980235109263228, 'l1_Layer_3': 2.9211837144879302e-05, 'l1_Layer_4': 1.01170310145358e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 240}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.80 | sMAPE for Validation Set is: 49.56% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 41.47 | sMAPE for Test Set is: 65.22% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:16:55,888]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:04,980]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:10,575]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:19,130]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:41,663]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:17:50,341]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:18:20,722]\u001b[0m Trial 278 finished with value: 8.477649936856999 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038251857778568194, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24058172409660047, 'dropout_rate_Layer_2': 0.2154617968791127, 'dropout_rate_Layer_3': 0.24103492655133868, 'dropout_rate_Layer_4': 0.227403991193035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002875126345367866, 'l1_Layer_2': 0.0036194439488042352, 'l1_Layer_3': 0.0028743816613413346, 'l1_Layer_4': 1.9721353574369693e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 275, 'n_units_Layer_4': 95}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 37.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.06 | sMAPE for Test Set is: 29.08% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:18:56,025]\u001b[0m Trial 279 finished with value: 8.532405569466489 and parameters: {'n_hidden': 4, 'learning_rate': 0.0036239013543193288, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24130705741987127, 'dropout_rate_Layer_2': 0.22133998142320793, 'dropout_rate_Layer_3': 0.23334299895210436, 'dropout_rate_Layer_4': 0.22054727870227656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002477711140312356, 'l1_Layer_2': 0.0031791023990076486, 'l1_Layer_3': 0.0030091512731006084, 'l1_Layer_4': 2.1243226372159858e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 300, 'n_units_Layer_4': 95}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 37.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.76 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:19:17,105]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:23,414]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:34,665]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:19:39,254]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:01,633]\u001b[0m Trial 284 finished with value: 11.604791989679844 and parameters: {'n_hidden': 4, 'learning_rate': 0.009002017538129316, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38151434321054184, 'dropout_rate_Layer_2': 0.2806550070034616, 'dropout_rate_Layer_3': 0.39823404819041497, 'dropout_rate_Layer_4': 0.2827798249366515, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020554164712904819, 'l1_Layer_2': 1.3323287916316877e-05, 'l1_Layer_3': 1.7435075508287165e-05, 'l1_Layer_4': 1.12971913964711e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 285}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.60 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 31.49 | sMAPE for Test Set is: 43.22% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:20:07,462]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:13,371]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:18,440]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:32,529]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:38,554]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:20:44,232]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:21,164]\u001b[0m Trial 291 finished with value: 8.621354725562044 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035043582415517295, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2407751810984279, 'dropout_rate_Layer_2': 0.16602655343543937, 'dropout_rate_Layer_3': 0.19894049492454166, 'dropout_rate_Layer_4': 0.20059450781162635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00028536595338992, 'l1_Layer_2': 0.0034216494623721685, 'l1_Layer_3': 0.0028182702057819435, 'l1_Layer_4': 2.2921657447431023e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 205, 'n_units_Layer_3': 285, 'n_units_Layer_4': 85}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 40.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.40 | sMAPE for Test Set is: 29.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:21:43,938]\u001b[0m Trial 292 finished with value: 11.906545372977783 and parameters: {'n_hidden': 4, 'learning_rate': 0.00936319208267552, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3992980012267802, 'dropout_rate_Layer_2': 0.2693718059682047, 'dropout_rate_Layer_3': 0.38167053036576326, 'dropout_rate_Layer_4': 0.3006577058524794, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017538734968843543, 'l1_Layer_2': 1.7106634265426444e-05, 'l1_Layer_3': 1.5298232191602264e-05, 'l1_Layer_4': 1.2001579431509481e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230, 'n_units_Layer_4': 240}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.91 | sMAPE for Validation Set is: 50.58% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 30.38 | sMAPE for Test Set is: 41.29% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:21:50,488]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:21:55,956]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:18,390]\u001b[0m Trial 295 finished with value: 12.629069765847566 and parameters: {'n_hidden': 4, 'learning_rate': 0.006875044915611021, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39566117187593064, 'dropout_rate_Layer_2': 0.28475737628033854, 'dropout_rate_Layer_3': 0.37357677708850684, 'dropout_rate_Layer_4': 0.32155973769872204, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00018427830774505948, 'l1_Layer_2': 1.1934171558824207e-05, 'l1_Layer_3': 2.6300316869512155e-05, 'l1_Layer_4': 1.6845397609722218e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225, 'n_units_Layer_4': 240}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.63 | sMAPE for Validation Set is: 52.60% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 33.44 | sMAPE for Test Set is: 47.58% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:22:40,365]\u001b[0m Trial 296 finished with value: 12.154953975101924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038719287273743827, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0755041926785053, 'dropout_rate_Layer_2': 0.13467700204048907, 'dropout_rate_Layer_3': 0.3195954483820635, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007641928567598622, 'l1_Layer_2': 0.00015071151071892778, 'l1_Layer_3': 0.015928140190101775, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 80}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.15 | sMAPE for Validation Set is: 51.47% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 35.36 | sMAPE for Test Set is: 48.46% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:22:52,060]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:22:57,372]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:02,811]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:08,897]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:46,863]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:53,961]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:23:59,812]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:06,916]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:12,224]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:17,626]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:25,831]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:24:49,761]\u001b[0m Trial 308 finished with value: 9.704984505333167 and parameters: {'n_hidden': 3, 'learning_rate': 0.005094304871913727, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22479883016544067, 'dropout_rate_Layer_2': 0.31965635423525035, 'dropout_rate_Layer_3': 0.24475920113359118, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048264378888145375, 'l1_Layer_2': 5.183791899574923e-05, 'l1_Layer_3': 0.00011677909472284936, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 42.99% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 29.66 | sMAPE for Test Set is: 38.33% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:24:55,950]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:14,407]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:20,112]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:27,777]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:33,027]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:25:37,112]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:08,495]\u001b[0m Trial 315 finished with value: 9.013756518820534 and parameters: {'n_hidden': 3, 'learning_rate': 0.00370699635052014, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04392126184339218, 'dropout_rate_Layer_2': 0.1317997169833866, 'dropout_rate_Layer_3': 0.2847491403570456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0019340193800693058, 'l1_Layer_2': 0.00014811758369779026, 'l1_Layer_3': 0.003863679665553934, 'n_units_Layer_1': 290, 'n_units_Layer_2': 230, 'n_units_Layer_3': 275}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 40.23% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 28.07 | sMAPE for Test Set is: 36.01% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:27:13,096]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:18,604]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:27:24,181]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:15,999]\u001b[0m Trial 319 finished with value: 9.55372196527798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024201116637381447, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010745296482172303, 'dropout_rate_Layer_2': 0.13092539686896534, 'dropout_rate_Layer_3': 0.27748368683401814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0018874345533855077, 'l1_Layer_2': 0.0001460365530619117, 'l1_Layer_3': 0.0035713008669258912, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 42.81% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.89 | sMAPE for Test Set is: 37.11% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:29:21,607]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:27,079]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:32,514]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:37,096]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:47,575]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:29:56,192]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:31:27,746]\u001b[0m Trial 326 finished with value: 9.309065673150391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037057005980231403, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029792818724456674, 'dropout_rate_Layer_2': 0.1236362037005456, 'dropout_rate_Layer_3': 0.2638570293533903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0033735878039979606, 'l1_Layer_2': 0.00025449985305631985, 'l1_Layer_3': 0.0015150526024452768, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 41.02% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.81 | sMAPE for Test Set is: 36.96% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:32:59,919]\u001b[0m Trial 327 finished with value: 9.088371068914123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026163641595534875, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03148212502286788, 'dropout_rate_Layer_2': 0.1022455322203642, 'dropout_rate_Layer_3': 0.2630326542501262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0031672962929953836, 'l1_Layer_2': 0.0002758357160119876, 'l1_Layer_3': 0.0016569300418677463, 'n_units_Layer_1': 290, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.09 | sMAPE for Validation Set is: 39.32% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 28.97 | sMAPE for Test Set is: 37.07% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:33:07,705]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:34:34,869]\u001b[0m Trial 329 finished with value: 9.246084571078406 and parameters: {'n_hidden': 3, 'learning_rate': 0.00275373687947012, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011659345319038672, 'dropout_rate_Layer_2': 0.10104314936568522, 'dropout_rate_Layer_3': 0.2656393469811997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003385934195443076, 'l1_Layer_2': 0.00024369374666008656, 'l1_Layer_3': 0.0016358760666085547, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 265}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.25 | sMAPE for Validation Set is: 41.20% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 28.61 | sMAPE for Test Set is: 36.56% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:34:49,505]\u001b[0m Trial 330 finished with value: 11.759889775726014 and parameters: {'n_hidden': 4, 'learning_rate': 0.00903557247038248, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33591276165638834, 'dropout_rate_Layer_2': 0.2804127372319167, 'dropout_rate_Layer_3': 0.12621880151446616, 'dropout_rate_Layer_4': 0.32075400714788305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004039321829299716, 'l1_Layer_2': 0.00013873803143872894, 'l1_Layer_3': 3.843738467037988e-05, 'l1_Layer_4': 1.9464936962559377e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270, 'n_units_Layer_4': 215}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.76 | sMAPE for Validation Set is: 49.60% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 40.92 | sMAPE for Test Set is: 60.95% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:36:19,498]\u001b[0m Trial 331 finished with value: 9.244123771922835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026890520315951587, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011075967200156842, 'dropout_rate_Layer_2': 0.1287792139802007, 'dropout_rate_Layer_3': 0.27137833400719485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0037554174910352715, 'l1_Layer_2': 0.00026061853305066644, 'l1_Layer_3': 0.0016416392900202364, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 265}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 43.51% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 29.72 | sMAPE for Test Set is: 38.62% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:36:25,341]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:35,577]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:36:40,735]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:37:58,651]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:03,860]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:19,149]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:29,836]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:38:49,607]\u001b[0m Trial 339 finished with value: 11.506608781509081 and parameters: {'n_hidden': 3, 'learning_rate': 0.006616042463331623, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3162612551080449, 'dropout_rate_Layer_2': 0.2824982592819276, 'dropout_rate_Layer_3': 0.30751651972157673, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016561269956625373, 'l1_Layer_2': 0.00013109543327576741, 'l1_Layer_3': 5.0208063846508556e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 60, 'n_units_Layer_3': 255}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.51 | sMAPE for Validation Set is: 48.69% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 37.95 | sMAPE for Test Set is: 55.79% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:40:19,574]\u001b[0m Trial 340 finished with value: 8.867712710058678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018006383546108394, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002360731218194136, 'dropout_rate_Layer_2': 0.1224292013852436, 'dropout_rate_Layer_3': 0.2791885768031633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00309212812232167, 'l1_Layer_2': 0.00031599990617716485, 'l1_Layer_3': 0.002447573137640304, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 39.26% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 28.18 | sMAPE for Test Set is: 36.52% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:40:27,789]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:32,897]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:37,250]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:40:44,262]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:02,674]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:12,750]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:41:31,240]\u001b[0m Trial 347 finished with value: 11.190698963495569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076060251333615325, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29746462484530667, 'dropout_rate_Layer_2': 0.2924490482505246, 'dropout_rate_Layer_3': 0.15244853440056855, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018236370220075623, 'l1_Layer_2': 0.00013053839001139737, 'l1_Layer_3': 0.0013634647202283503, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.19 | sMAPE for Validation Set is: 47.44% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 38.81 | sMAPE for Test Set is: 56.94% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:42:01,583]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:07,663]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:13,752]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:22,010]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:25,969]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:34,050]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:39,201]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:44,114]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:42:54,485]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:16,878]\u001b[0m Trial 357 finished with value: 11.102171175138972 and parameters: {'n_hidden': 3, 'learning_rate': 0.007614045882385166, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32877323831770255, 'dropout_rate_Layer_2': 0.3447809380541875, 'dropout_rate_Layer_3': 0.08607264579855872, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047412207933487433, 'l1_Layer_2': 1.8048202337452732e-05, 'l1_Layer_3': 0.00043782567465207366, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 195}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.10 | sMAPE for Validation Set is: 47.44% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 38.86 | sMAPE for Test Set is: 57.09% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:43:28,137]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:43:57,603]\u001b[0m Trial 359 finished with value: 9.685262450704224 and parameters: {'n_hidden': 3, 'learning_rate': 0.004495104883216715, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10826503842008742, 'dropout_rate_Layer_2': 0.32110714247596966, 'dropout_rate_Layer_3': 0.23912102800391427, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005018717986102043, 'l1_Layer_2': 3.5589355042190066e-05, 'l1_Layer_3': 0.0001369082630314787, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 105}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.69 | sMAPE for Validation Set is: 43.41% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 28.46 | sMAPE for Test Set is: 36.84% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:44:02,475]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:44:13,086]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:44:30,448]\u001b[0m Trial 362 finished with value: 11.797835257533754 and parameters: {'n_hidden': 3, 'learning_rate': 0.007590822423943478, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3213602403875202, 'dropout_rate_Layer_2': 0.3544708824745296, 'dropout_rate_Layer_3': 0.08726926792312775, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004915198777340426, 'l1_Layer_2': 1.4206992915825649e-05, 'l1_Layer_3': 0.01621335924924948, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.80 | sMAPE for Validation Set is: 49.58% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 39.18 | sMAPE for Test Set is: 56.49% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:44:38,724]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:45:57,625]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:16,734]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:26,418]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:47:46,244]\u001b[0m Trial 367 finished with value: 11.813316419281778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0099973336945473, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22380643040460688, 'dropout_rate_Layer_2': 0.33035218861674936, 'dropout_rate_Layer_3': 0.09347616032629866, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003496712520880556, 'l1_Layer_2': 1.3967979152239576e-05, 'l1_Layer_3': 0.0013915581810101075, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.81 | sMAPE for Validation Set is: 49.97% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 35.99 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:47:50,548]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:48:08,335]\u001b[0m Trial 369 finished with value: 8.695400138338103 and parameters: {'n_hidden': 4, 'learning_rate': 0.004917126062356868, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3329655861758363, 'dropout_rate_Layer_2': 0.19665321632075375, 'dropout_rate_Layer_3': 0.22267957426141227, 'dropout_rate_Layer_4': 0.2557137683526172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011579554965606261, 'l1_Layer_2': 0.004791947520244231, 'l1_Layer_3': 0.004350272247613567, 'l1_Layer_4': 1.5711584093422506e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290, 'n_units_Layer_4': 110}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 38.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.89 | sMAPE for Test Set is: 30.58% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:48:32,392]\u001b[0m Trial 370 finished with value: 11.842587448217964 and parameters: {'n_hidden': 3, 'learning_rate': 0.009497198576787706, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21627974754499377, 'dropout_rate_Layer_2': 0.33618662580280867, 'dropout_rate_Layer_3': 0.07339017553920907, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022903578076742542, 'l1_Layer_2': 1.8349263503088727e-05, 'l1_Layer_3': 0.0013932483182957393, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.84 | sMAPE for Validation Set is: 49.28% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 34.26 | sMAPE for Test Set is: 48.15% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:48:50,161]\u001b[0m Trial 371 finished with value: 12.085860417894224 and parameters: {'n_hidden': 3, 'learning_rate': 0.030711542027683204, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22154046280252487, 'dropout_rate_Layer_2': 0.33493096616994017, 'dropout_rate_Layer_3': 0.07246625355220812, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022888217485811182, 'l1_Layer_2': 1.1776351710849393e-05, 'l1_Layer_3': 0.0013360278553379648, 'n_units_Layer_1': 195, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.09 | sMAPE for Validation Set is: 49.94% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 34.22 | sMAPE for Test Set is: 49.93% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:49:42,439]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:08,057]\u001b[0m Trial 373 finished with value: 9.823669823973736 and parameters: {'n_hidden': 3, 'learning_rate': 0.005041589448024441, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23081351218565432, 'dropout_rate_Layer_2': 0.32809610771028436, 'dropout_rate_Layer_3': 0.2652951656232482, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005662944267981052, 'l1_Layer_2': 4.071560832135238e-05, 'l1_Layer_3': 6.863011248633563e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 130, 'n_units_Layer_3': 120}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 44.12% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 29.68 | sMAPE for Test Set is: 38.55% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:50:13,371]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:19,506]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:25,806]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:50:51,886]\u001b[0m Trial 377 finished with value: 10.24016651748504 and parameters: {'n_hidden': 3, 'learning_rate': 0.007068858237688359, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1586732527302306, 'dropout_rate_Layer_2': 0.30542631916049756, 'dropout_rate_Layer_3': 0.22831044256664362, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012566070690816751, 'l1_Layer_2': 1.6413314235901402e-05, 'l1_Layer_3': 0.0002301121683999788, 'n_units_Layer_1': 55, 'n_units_Layer_2': 85, 'n_units_Layer_3': 175}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.24 | sMAPE for Validation Set is: 45.11% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 28.10 | sMAPE for Test Set is: 36.38% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:51:04,402]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:08,715]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:14,221]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:51:37,324]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:52:07,872]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:28,891]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:39,059]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:54:42,588]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:55:06,786]\u001b[0m Trial 386 finished with value: 9.125363541348953 and parameters: {'n_hidden': 3, 'learning_rate': 0.01971834991369036, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17747094000713276, 'dropout_rate_Layer_2': 0.27388518531347383, 'dropout_rate_Layer_3': 0.21021408365072428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004496110795960237, 'l1_Layer_2': 1.0558568613303296e-05, 'l1_Layer_3': 9.113508407195063e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 135, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 40.98% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 19.72 | sMAPE for Test Set is: 29.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:55:17,260]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:55:27,381]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:55:45,866]\u001b[0m Trial 389 finished with value: 9.060032808529412 and parameters: {'n_hidden': 4, 'learning_rate': 0.006869733776776436, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2897879101623016, 'dropout_rate_Layer_2': 0.21705140366768919, 'dropout_rate_Layer_3': 0.2474936948253561, 'dropout_rate_Layer_4': 0.23178223957272925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004949017558932804, 'l1_Layer_2': 0.01567284082290533, 'l1_Layer_3': 0.010259411403308992, 'l1_Layer_4': 3.661516549962679e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 170, 'n_units_Layer_4': 70}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 39.87% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 20.59 | sMAPE for Test Set is: 30.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:56:09,155]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:56:19,635]\u001b[0m Trial 391 finished with value: 14.045537383408046 and parameters: {'n_hidden': 3, 'learning_rate': 0.029494999238167095, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17560678480062628, 'dropout_rate_Layer_2': 0.3600017326025773, 'dropout_rate_Layer_3': 0.20895612264361538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027176221880185355, 'l1_Layer_2': 1.8342649226535147e-05, 'l1_Layer_3': 8.563640613001766e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 205}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.05 | sMAPE for Validation Set is: 55.47% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 23.71 | sMAPE for Test Set is: 33.89% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:56:25,831]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:56:29,341]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:56:45,613]\u001b[0m Trial 394 finished with value: 12.274416771716503 and parameters: {'n_hidden': 3, 'learning_rate': 0.023765477695630702, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22896177754993982, 'dropout_rate_Layer_2': 0.34619285454130144, 'dropout_rate_Layer_3': 0.0986685796504016, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003446373070893602, 'l1_Layer_2': 2.6247643977158492e-05, 'l1_Layer_3': 0.011261831294305082, 'n_units_Layer_1': 275, 'n_units_Layer_2': 70, 'n_units_Layer_3': 205}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.27 | sMAPE for Validation Set is: 51.20% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 40.35 | sMAPE for Test Set is: 60.41% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:56:49,800]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:56:55,840]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:02,989]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:07,240]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:13,243]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:23,517]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:31,668]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:43,386]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:57:47,892]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:58:40,164]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:58:51,467]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:03,816]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 11:59:51,847]\u001b[0m Trial 407 finished with value: 10.577903293057956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006627796901265341, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23428152505396815, 'dropout_rate_Layer_2': 0.32572927069590996, 'dropout_rate_Layer_3': 0.0865260526115411, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002383342434680252, 'l1_Layer_2': 2.4784402229253084e-05, 'l1_Layer_3': 0.0005171835474876924, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.58 | sMAPE for Validation Set is: 46.11% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 37.55 | sMAPE for Test Set is: 54.31% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 11:59:56,120]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:02,367]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:15,424]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:00:52,370]\u001b[0m Trial 411 finished with value: 9.319145788832072 and parameters: {'n_hidden': 3, 'learning_rate': 0.00276075452831152, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022921438777530438, 'dropout_rate_Layer_2': 0.1494935664401156, 'dropout_rate_Layer_3': 0.288684836706362, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0020321729941759673, 'l1_Layer_2': 0.00026483885397854146, 'l1_Layer_3': 0.0027899886985780424, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.32 | sMAPE for Validation Set is: 40.96% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.00 | sMAPE for Test Set is: 36.04% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:00:56,647]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:01:37,407]\u001b[0m Trial 413 finished with value: 12.020507282891979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013771943656784027, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21225565751938175, 'dropout_rate_Layer_2': 0.335527743185158, 'dropout_rate_Layer_3': 0.2927212845362915, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024553424295059075, 'l1_Layer_2': 1.6388533139855335e-05, 'l1_Layer_3': 0.0009217206031319471, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.02 | sMAPE for Validation Set is: 51.15% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 34.68 | sMAPE for Test Set is: 47.55% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:02:11,344]\u001b[0m Trial 414 finished with value: 10.686736006453396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006890397136709866, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20145227904538185, 'dropout_rate_Layer_2': 0.3171516378146336, 'dropout_rate_Layer_3': 0.27604949365322035, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005558205680917808, 'l1_Layer_2': 1.4862685959092374e-05, 'l1_Layer_3': 0.0008992691700943598, 'n_units_Layer_1': 195, 'n_units_Layer_2': 160, 'n_units_Layer_3': 190}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.69 | sMAPE for Validation Set is: 46.39% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 37.07 | sMAPE for Test Set is: 53.34% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:02:40,416]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:02:44,830]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:28,520]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:34,783]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:41,564]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:03:46,874]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:04:30,502]\u001b[0m Trial 421 finished with value: 10.300242985465955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007518296069086642, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18809317289971345, 'dropout_rate_Layer_2': 0.3292896531041875, 'dropout_rate_Layer_3': 0.17905692623811265, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018594047016913683, 'l1_Layer_2': 1.4471265339910885e-05, 'l1_Layer_3': 0.0006811442092191093, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 180}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.30 | sMAPE for Validation Set is: 45.46% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 36.65 | sMAPE for Test Set is: 52.39% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:05:32,116]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:06:03,722]\u001b[0m Trial 423 finished with value: 10.882122396754243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006213997277937875, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1934309062918681, 'dropout_rate_Layer_2': 0.33270761438786844, 'dropout_rate_Layer_3': 0.272423564845495, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003790760675383953, 'l1_Layer_2': 1.6669710036839582e-05, 'l1_Layer_3': 0.0006538372620716662, 'n_units_Layer_1': 185, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.88 | sMAPE for Validation Set is: 47.83% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 34.91 | sMAPE for Test Set is: 48.71% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:06:38,186]\u001b[0m Trial 424 finished with value: 10.505381502410051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006834726387915673, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18965366343220563, 'dropout_rate_Layer_2': 0.3305937716831039, 'dropout_rate_Layer_3': 0.27448660521394264, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004456298760944435, 'l1_Layer_2': 1.6577165561807456e-05, 'l1_Layer_3': 0.0005602215717762974, 'n_units_Layer_1': 185, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.51 | sMAPE for Validation Set is: 46.04% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 35.46 | sMAPE for Test Set is: 50.25% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:06:51,515]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:07:13,756]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:07:37,320]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:07:57,927]\u001b[0m Trial 428 finished with value: 9.485453218184032 and parameters: {'n_hidden': 3, 'learning_rate': 0.03192668325159258, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22413278458063307, 'dropout_rate_Layer_2': 0.37613720761860636, 'dropout_rate_Layer_3': 0.2887758922978737, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000329524590848105, 'l1_Layer_2': 7.678620814036182e-05, 'l1_Layer_3': 4.5606449729641084e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 43.08% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 23.93 | sMAPE for Test Set is: 35.78% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:08:03,391]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:08:56,368]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:09:06,046]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:09:42,443]\u001b[0m Trial 432 finished with value: 10.000579606078793 and parameters: {'n_hidden': 3, 'learning_rate': 0.002708162742821423, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03862298949318623, 'dropout_rate_Layer_2': 0.09507040723716688, 'dropout_rate_Layer_3': 0.23955887214533894, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.001752614134004202, 'l1_Layer_2': 0.00010457648903220801, 'l1_Layer_3': 0.0008745958237607448, 'n_units_Layer_1': 290, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 43.93% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 31.88 | sMAPE for Test Set is: 41.41% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:10:46,029]\u001b[0m Trial 433 finished with value: 11.014728276439584 and parameters: {'n_hidden': 3, 'learning_rate': 0.000662774183154579, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19427027853864, 'dropout_rate_Layer_2': 0.3149709972627889, 'dropout_rate_Layer_3': 0.3119630710778333, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001965274862699696, 'l1_Layer_2': 1.6362731358701868e-05, 'l1_Layer_3': 0.0008640145940750629, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.01 | sMAPE for Validation Set is: 48.06% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 36.68 | sMAPE for Test Set is: 52.16% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:10:50,747]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:11:12,972]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:11:24,431]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:12:33,900]\u001b[0m Trial 437 finished with value: 9.635339992903068 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005553203556179669, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18855279192604138, 'dropout_rate_Layer_2': 0.3367015735223398, 'dropout_rate_Layer_3': 0.2788253878193598, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021788231840340917, 'l1_Layer_2': 1.2607797759406672e-05, 'l1_Layer_3': 0.0010398892794735114, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 175}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.64 | sMAPE for Validation Set is: 43.18% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 29.33 | sMAPE for Test Set is: 37.75% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:13:41,600]\u001b[0m Trial 438 finished with value: 9.299120086986042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006039841994083578, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18323457661019626, 'dropout_rate_Layer_2': 0.337228604906886, 'dropout_rate_Layer_3': 0.2898508103357375, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025180713356938327, 'l1_Layer_2': 1.1378622422462763e-05, 'l1_Layer_3': 0.0011492083338454308, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 170}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 42.04% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.54 | sMAPE for Test Set is: 38.10% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:14:42,253]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:04,930]\u001b[0m Trial 440 finished with value: 9.41217880914913 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005654176447115219, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1831725694000904, 'dropout_rate_Layer_2': 0.3377467040565176, 'dropout_rate_Layer_3': 0.29223021083932554, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002052053183515853, 'l1_Layer_2': 1.1696715879348691e-05, 'l1_Layer_3': 0.000985890191872498, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 42.34% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 29.71 | sMAPE for Test Set is: 38.07% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:16:12,181]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:29,758]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:16:59,964]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:09,843]\u001b[0m Trial 444 finished with value: 9.376800577381527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005560625161570717, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18678494098028822, 'dropout_rate_Layer_2': 0.3231785237712026, 'dropout_rate_Layer_3': 0.2897448330380947, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00200520994062633, 'l1_Layer_2': 1.0611607906482755e-05, 'l1_Layer_3': 0.0007405938388305162, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 175}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 42.50% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 30.25 | sMAPE for Test Set is: 39.04% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:18:14,370]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:18:25,883]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:19:55,780]\u001b[0m Trial 447 finished with value: 9.58754917344011 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005101112055915537, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1904258380779448, 'dropout_rate_Layer_2': 0.31464806724530026, 'dropout_rate_Layer_3': 0.27963230050234794, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020494340403841333, 'l1_Layer_2': 1.0122973288143137e-05, 'l1_Layer_3': 0.0006459584516920188, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 165}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 43.02% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 29.03 | sMAPE for Test Set is: 37.13% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:20:01,995]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:20:06,951]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:21:25,433]\u001b[0m Trial 450 finished with value: 9.285279086614606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006093447739881627, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1895440692130826, 'dropout_rate_Layer_2': 0.3224155787106915, 'dropout_rate_Layer_3': 0.2758018675757365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016343624369898858, 'l1_Layer_2': 1.2610421856891751e-05, 'l1_Layer_3': 0.0005028959715704931, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.29 | sMAPE for Validation Set is: 42.00% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.61 | sMAPE for Test Set is: 36.68% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:21:59,871]\u001b[0m Trial 451 finished with value: 8.480598903333384 and parameters: {'n_hidden': 4, 'learning_rate': 0.00337994016259151, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22981149632777298, 'dropout_rate_Layer_2': 0.16645434807703935, 'dropout_rate_Layer_3': 0.2091216026712204, 'dropout_rate_Layer_4': 0.20042770632595364, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012505210538675977, 'l1_Layer_2': 0.0026873119967689256, 'l1_Layer_3': 0.0026438637920993997, 'l1_Layer_4': 2.0564850628362095e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280, 'n_units_Layer_4': 85}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 38.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 29.15% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:23:18,168]\u001b[0m Trial 452 finished with value: 9.359124165783355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006028542446605335, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19023119964021876, 'dropout_rate_Layer_2': 0.3216281672600471, 'dropout_rate_Layer_3': 0.2749937621516678, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020560268540166953, 'l1_Layer_2': 1.2912560872268979e-05, 'l1_Layer_3': 0.0005295655289998234, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.36 | sMAPE for Validation Set is: 42.32% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.48 | sMAPE for Test Set is: 34.96% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:24:23,371]\u001b[0m Trial 453 finished with value: 9.451794584612108 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006194854789814353, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18689128482047782, 'dropout_rate_Layer_2': 0.3223919816577354, 'dropout_rate_Layer_3': 0.2771359610038412, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019883974369839623, 'l1_Layer_2': 1.2383772802026883e-05, 'l1_Layer_3': 0.0005072682128192974, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 175}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.45 | sMAPE for Validation Set is: 42.52% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 29.07 | sMAPE for Test Set is: 37.43% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:25:22,893]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:43,558]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:25:55,287]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:26:50,575]\u001b[0m Trial 457 finished with value: 9.620541429926979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005649229725369152, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17519179825316045, 'dropout_rate_Layer_2': 0.3131426275978185, 'dropout_rate_Layer_3': 0.28191954984260303, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021813960978091167, 'l1_Layer_2': 1.2042267071946085e-05, 'l1_Layer_3': 0.0006285169423765118, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 160}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.62 | sMAPE for Validation Set is: 43.09% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 30.62 | sMAPE for Test Set is: 39.52% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:27:03,007]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:28:01,630]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:14,531]\u001b[0m Trial 460 finished with value: 9.801779998617251 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012168961302769, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18658862680585617, 'dropout_rate_Layer_2': 0.3218528678155355, 'dropout_rate_Layer_3': 0.2897885282808233, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016343326014571394, 'l1_Layer_2': 1.0559331523151245e-05, 'l1_Layer_3': 0.0004060916897732703, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 165}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.80 | sMAPE for Validation Set is: 44.20% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 27.73 | sMAPE for Test Set is: 35.72% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:29:44,812]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:29:56,487]\u001b[0m Trial 462 finished with value: 15.647400812274787 and parameters: {'n_hidden': 3, 'learning_rate': 0.020325933138761305, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2780099332636945, 'dropout_rate_Layer_2': 0.3461207523811457, 'dropout_rate_Layer_3': 0.2504786761363581, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00026830279745023876, 'l1_Layer_2': 3.6203812790149806e-05, 'l1_Layer_3': 7.741722301826502e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.65 | sMAPE for Validation Set is: 60.83% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 45.49 | sMAPE for Test Set is: 69.52% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:30:21,660]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:31:42,566]\u001b[0m Trial 464 finished with value: 9.617664092204697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006430352078272308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18726029120203877, 'dropout_rate_Layer_2': 0.3216296567724273, 'dropout_rate_Layer_3': 0.2772304473525541, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017193318664509016, 'l1_Layer_2': 1.0014033249816643e-05, 'l1_Layer_3': 0.00041319200072763285, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 165}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.62 | sMAPE for Validation Set is: 43.26% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 27.18 | sMAPE for Test Set is: 34.94% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:32:13,315]\u001b[0m Trial 465 finished with value: 8.593647484982883 and parameters: {'n_hidden': 4, 'learning_rate': 0.002843107907066479, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23298876301584692, 'dropout_rate_Layer_2': 0.18117524775304228, 'dropout_rate_Layer_3': 0.2485419849460346, 'dropout_rate_Layer_4': 0.15090236185242742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016256952226138813, 'l1_Layer_2': 0.005950464240070967, 'l1_Layer_3': 0.001473415053102854, 'l1_Layer_4': 3.864322197779544e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245, 'n_units_Layer_4': 95}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.28% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.80 | sMAPE for Test Set is: 29.90% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:33:13,952]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:34:19,423]\u001b[0m Trial 467 finished with value: 9.24788741668951 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006796451473124846, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18217423499539898, 'dropout_rate_Layer_2': 0.3150410052272637, 'dropout_rate_Layer_3': 0.289247913868489, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015273033312494595, 'l1_Layer_2': 1.009135939818614e-05, 'l1_Layer_3': 0.0003935730217627545, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.25 | sMAPE for Validation Set is: 41.08% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.97 | sMAPE for Test Set is: 38.56% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:34:43,545]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:42,247]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:35:53,034]\u001b[0m Trial 470 finished with value: 15.281907020730893 and parameters: {'n_hidden': 3, 'learning_rate': 0.05213119093734282, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23685794744944086, 'dropout_rate_Layer_2': 0.37132095540868965, 'dropout_rate_Layer_3': 0.3147187417184011, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008563479390842247, 'l1_Layer_2': 2.0635267794396055e-05, 'l1_Layer_3': 1.8792138964808223e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 85, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.28 | sMAPE for Validation Set is: 60.22% | rMAE for Validation Set is: 1.21\n",
      "MAE for Test Set is: 47.14 | sMAPE for Test Set is: 73.78% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:37:15,692]\u001b[0m Trial 471 finished with value: 9.705446850259545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007021200130759261, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1928778336657706, 'dropout_rate_Layer_2': 0.310209494124893, 'dropout_rate_Layer_3': 0.26066842240783544, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021210790592766657, 'l1_Layer_2': 1.2162422133608084e-05, 'l1_Layer_3': 0.000628693903932301, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 175}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 43.59% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 27.89 | sMAPE for Test Set is: 35.85% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:37:54,120]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:01,530]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:38:54,904]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:39:01,112]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:40:31,842]\u001b[0m Trial 476 finished with value: 9.83578573285814 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006443254967682515, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18409169942199, 'dropout_rate_Layer_2': 0.3171510740125871, 'dropout_rate_Layer_3': 0.26657941625784926, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002790950612824192, 'l1_Layer_2': 1.2304489386689194e-05, 'l1_Layer_3': 0.0005018380541138645, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 170}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.84 | sMAPE for Validation Set is: 43.98% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 28.24 | sMAPE for Test Set is: 36.38% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:41:58,255]\u001b[0m Trial 477 finished with value: 10.079026429726222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006581470665557866, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1830844698031257, 'dropout_rate_Layer_2': 0.3175773725467534, 'dropout_rate_Layer_3': 0.2728984984721229, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002951311490331832, 'l1_Layer_2': 1.2087397457578608e-05, 'l1_Layer_3': 0.0005156633958667687, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 170}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.08 | sMAPE for Validation Set is: 45.27% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 27.29 | sMAPE for Test Set is: 35.18% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:42:19,416]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:43:53,930]\u001b[0m Trial 479 finished with value: 9.966236107643821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006658314784600088, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1840111762718521, 'dropout_rate_Layer_2': 0.3175883599123539, 'dropout_rate_Layer_3': 0.2681690465397654, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002824929964402136, 'l1_Layer_2': 1.2265078856802944e-05, 'l1_Layer_3': 0.0005321528836525366, 'n_units_Layer_1': 165, 'n_units_Layer_2': 175, 'n_units_Layer_3': 170}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.97 | sMAPE for Validation Set is: 44.59% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 28.19 | sMAPE for Test Set is: 36.30% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:44:02,736]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:45:48,277]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:04,130]\u001b[0m Trial 482 finished with value: 9.996679132898981 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005701370670711849, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16902366461344626, 'dropout_rate_Layer_2': 0.3151732707709199, 'dropout_rate_Layer_3': 0.27973500855798583, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026004390036752523, 'l1_Layer_2': 1.2142041710689859e-05, 'l1_Layer_3': 0.0005442082974466694, 'n_units_Layer_1': 175, 'n_units_Layer_2': 180, 'n_units_Layer_3': 165}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 44.65% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 29.24 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:47:11,344]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:17,047]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:22,924]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:47:32,330]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:13,356]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:48:50,493]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:50:12,368]\u001b[0m Trial 489 finished with value: 9.541823523259318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007888836008795906, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18766794353978863, 'dropout_rate_Layer_2': 0.31572068146479093, 'dropout_rate_Layer_3': 0.255817696786521, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015536762705957235, 'l1_Layer_2': 1.1578615144919491e-05, 'l1_Layer_3': 0.0003723312949272602, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 160}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 42.74% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.98 | sMAPE for Test Set is: 37.34% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:50:19,755]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:51:39,175]\u001b[0m Trial 491 finished with value: 9.487229703453368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005541628765907316, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18567773392273654, 'dropout_rate_Layer_2': 0.32640708382419203, 'dropout_rate_Layer_3': 0.25089939744529194, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014683501972911988, 'l1_Layer_2': 1.000311297875102e-05, 'l1_Layer_3': 0.0003586747200225926, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 42.46% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.60 | sMAPE for Test Set is: 36.92% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:52:47,403]\u001b[0m Trial 492 finished with value: 9.654769804285095 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008129758046604556, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18417835382139658, 'dropout_rate_Layer_2': 0.32511591168216997, 'dropout_rate_Layer_3': 0.26277002909160185, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014443338989973333, 'l1_Layer_2': 1.0052644415016218e-05, 'l1_Layer_3': 0.0003632967099779626, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.65 | sMAPE for Validation Set is: 43.48% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 28.12 | sMAPE for Test Set is: 36.06% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:52:54,080]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:53:05,609]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:54:31,435]\u001b[0m Trial 495 finished with value: 9.591351598918493 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008222623491388216, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18448496172007595, 'dropout_rate_Layer_2': 0.32432139962826506, 'dropout_rate_Layer_3': 0.2530399948249022, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014559385363387605, 'l1_Layer_2': 1.0036917251364224e-05, 'l1_Layer_3': 0.0003319554227447885, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 43.43% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 26.59 | sMAPE for Test Set is: 34.15% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:55:49,716]\u001b[0m Trial 496 finished with value: 9.548237576759183 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008204799389776178, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16809174718083894, 'dropout_rate_Layer_2': 0.3253225581139564, 'dropout_rate_Layer_3': 0.25984062648722384, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014716320339426157, 'l1_Layer_2': 1.00834162682461e-05, 'l1_Layer_3': 0.0003410227532272018, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 42.97% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 30.31 | sMAPE for Test Set is: 39.39% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:57:02,072]\u001b[0m Trial 497 finished with value: 9.560225321257013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007964296476070229, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16634164721967284, 'dropout_rate_Layer_2': 0.32600753876633776, 'dropout_rate_Layer_3': 0.25678773929544046, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015258256262255824, 'l1_Layer_2': 1.0137493484787235e-05, 'l1_Layer_3': 0.00034632925382578763, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 42.98% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 30.41 | sMAPE for Test Set is: 39.55% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:57:08,021]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:26,922]\u001b[0m Trial 499 finished with value: 9.712887665811467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007781428952490274, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16642234417792118, 'dropout_rate_Layer_2': 0.3080700222510717, 'dropout_rate_Layer_3': 0.2543135167594499, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016113111173570436, 'l1_Layer_2': 1.0111054701704236e-05, 'l1_Layer_3': 0.0003548839474725234, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 44.01% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 26.93 | sMAPE for Test Set is: 34.51% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 12:58:31,511]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:58:38,890]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 12:59:56,457]\u001b[0m Trial 502 finished with value: 9.40420605685164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007908776808704232, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16314693873581743, 'dropout_rate_Layer_2': 0.3227307531436622, 'dropout_rate_Layer_3': 0.2528760673553573, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016685736906005594, 'l1_Layer_2': 1.0117485283740467e-05, 'l1_Layer_3': 0.0003478181695416954, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 42.51% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.87 | sMAPE for Test Set is: 37.22% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:00:26,545]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:36,205]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:00:42,074]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:02:06,260]\u001b[0m Trial 506 finished with value: 9.479818335841292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008096861945648909, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1660258747320672, 'dropout_rate_Layer_2': 0.305724700994747, 'dropout_rate_Layer_3': 0.2525737797829474, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015086377832309306, 'l1_Layer_2': 1.0201721242989875e-05, 'l1_Layer_3': 0.0003451205949729222, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 43.13% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 26.87 | sMAPE for Test Set is: 34.50% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:03:28,027]\u001b[0m Trial 507 finished with value: 9.58595790356536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008373825709781895, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1620453116101609, 'dropout_rate_Layer_2': 0.30776793808735015, 'dropout_rate_Layer_3': 0.25321421055125704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014649422913924532, 'l1_Layer_2': 1.0068025649760777e-05, 'l1_Layer_3': 0.00035039816181845667, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 43.15% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.47 | sMAPE for Test Set is: 36.67% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:04:50,779]\u001b[0m Trial 508 finished with value: 9.53326897303706 and parameters: {'n_hidden': 3, 'learning_rate': 0.000844908288708959, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16050468742603466, 'dropout_rate_Layer_2': 0.3067671039753283, 'dropout_rate_Layer_3': 0.25377743550687715, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001500265435499531, 'l1_Layer_2': 1.0029182549537615e-05, 'l1_Layer_3': 0.0003095696054879027, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 43.27% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 27.02 | sMAPE for Test Set is: 34.79% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:06:13,492]\u001b[0m Trial 509 finished with value: 9.350912260668302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008043060872462548, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1600186409919285, 'dropout_rate_Layer_2': 0.30404579635086854, 'dropout_rate_Layer_3': 0.25490703923937896, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001425176783519172, 'l1_Layer_2': 1.0785033781964296e-05, 'l1_Layer_3': 0.0003280885246607216, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.35 | sMAPE for Validation Set is: 42.42% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.94 | sMAPE for Test Set is: 35.75% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:06:24,530]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:07:46,336]\u001b[0m Trial 511 finished with value: 9.698217969117833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008481926677934899, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1568150658212298, 'dropout_rate_Layer_2': 0.3098753360844829, 'dropout_rate_Layer_3': 0.25224843028443816, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014375039613588436, 'l1_Layer_2': 1.081955368073465e-05, 'l1_Layer_3': 0.0003366470195071427, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 43.48% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 28.99 | sMAPE for Test Set is: 37.29% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:09:07,517]\u001b[0m Trial 512 finished with value: 9.507109996145703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008010695906045594, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16011872168496774, 'dropout_rate_Layer_2': 0.3072910175130545, 'dropout_rate_Layer_3': 0.2531901280125965, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014274427243368985, 'l1_Layer_2': 1.0021178703793546e-05, 'l1_Layer_3': 0.0003299339067250142, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 42.84% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 29.72 | sMAPE for Test Set is: 38.30% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:09:43,387]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:09:53,916]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:11:31,339]\u001b[0m Trial 515 finished with value: 9.66246983162872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008725377959976779, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15871267494367985, 'dropout_rate_Layer_2': 0.3066922088892658, 'dropout_rate_Layer_3': 0.2563937198809812, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014416460468373786, 'l1_Layer_2': 1.0992751800423072e-05, 'l1_Layer_3': 0.00034149544201099246, 'n_units_Layer_1': 175, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.66 | sMAPE for Validation Set is: 43.37% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 28.34 | sMAPE for Test Set is: 36.36% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:12:47,907]\u001b[0m Trial 516 finished with value: 9.382998004021639 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008600552340631704, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.159541983770045, 'dropout_rate_Layer_2': 0.3052420714711501, 'dropout_rate_Layer_3': 0.2498064724526271, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00135563461355947, 'l1_Layer_2': 1.0139517431649384e-05, 'l1_Layer_3': 0.00032330535562942497, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 42.40% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.95 | sMAPE for Test Set is: 35.72% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:13:50,084]\u001b[0m Trial 517 finished with value: 9.517554020252954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009077764073211831, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1627076831952661, 'dropout_rate_Layer_2': 0.3051639216273496, 'dropout_rate_Layer_3': 0.24216102252123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013547473583945674, 'l1_Layer_2': 1.0083889781647108e-05, 'l1_Layer_3': 0.0002836898343493736, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 42.95% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.90 | sMAPE for Test Set is: 37.14% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:15:10,622]\u001b[0m Trial 518 finished with value: 9.466359687411574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009256890782951134, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16224827741155554, 'dropout_rate_Layer_2': 0.30496558848035926, 'dropout_rate_Layer_3': 0.24339983391073575, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012723111194884794, 'l1_Layer_2': 1.0068115550881185e-05, 'l1_Layer_3': 0.00026061436036670354, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.47 | sMAPE for Validation Set is: 42.62% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.94 | sMAPE for Test Set is: 35.69% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:16:16,856]\u001b[0m Trial 519 finished with value: 9.409834080521664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008623676232564166, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14820617998028715, 'dropout_rate_Layer_2': 0.30395536903999576, 'dropout_rate_Layer_3': 0.24420563797071737, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001322800418938631, 'l1_Layer_2': 1.0234078598529966e-05, 'l1_Layer_3': 0.00028881593460568033, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 42.49% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.61 | sMAPE for Test Set is: 35.55% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:16:39,245]\u001b[0m Trial 520 finished with value: 8.732785732539694 and parameters: {'n_hidden': 3, 'learning_rate': 0.008436383489701896, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14476657934977918, 'dropout_rate_Layer_2': 0.34377628756980716, 'dropout_rate_Layer_3': 0.18444960649789144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016440788244496182, 'l1_Layer_2': 4.363417096977708e-05, 'l1_Layer_3': 0.00015549540758482626, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 40.74% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.15 | sMAPE for Test Set is: 29.33% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:16:46,915]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:16:57,464]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:17:52,014]\u001b[0m Trial 523 finished with value: 9.592595094160117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009474291147302734, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14837584645185597, 'dropout_rate_Layer_2': 0.30294267920881734, 'dropout_rate_Layer_3': 0.2369018427452183, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012864744645051066, 'l1_Layer_2': 1.0144223592706387e-05, 'l1_Layer_3': 0.0002761118250306225, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 43.26% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.20 | sMAPE for Test Set is: 36.30% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:19:06,636]\u001b[0m Trial 524 finished with value: 9.555847317904593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009720042804744278, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1490015989274242, 'dropout_rate_Layer_2': 0.30292031496805827, 'dropout_rate_Layer_3': 0.24218772421104398, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012718866175044747, 'l1_Layer_2': 1.0245740033192652e-05, 'l1_Layer_3': 0.00027067369109817974, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 42.71% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.76 | sMAPE for Test Set is: 36.98% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:20:29,361]\u001b[0m Trial 525 finished with value: 9.61185973008031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009465355245012962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14734457612075574, 'dropout_rate_Layer_2': 0.30332322887051416, 'dropout_rate_Layer_3': 0.24112140748850766, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011461664096664536, 'l1_Layer_2': 1.0248115187707414e-05, 'l1_Layer_3': 0.0002869855686054207, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 43.39% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.05 | sMAPE for Test Set is: 36.01% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:21:27,863]\u001b[0m Trial 526 finished with value: 9.29746910418862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009349298294154979, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14862775283634483, 'dropout_rate_Layer_2': 0.3034274652764465, 'dropout_rate_Layer_3': 0.24115807160847344, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012381594313768055, 'l1_Layer_2': 1.0230524421389139e-05, 'l1_Layer_3': 0.0002654612399810785, 'n_units_Layer_1': 160, 'n_units_Layer_2': 195, 'n_units_Layer_3': 130}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 42.01% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 26.79 | sMAPE for Test Set is: 34.27% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:21:35,055]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:10,527]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:21,301]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:28,410]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:22:34,339]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:23:12,973]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:37,470]\u001b[0m Trial 533 finished with value: 9.464812097704398 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008004334026157275, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1529963843889854, 'dropout_rate_Layer_2': 0.3085876661702669, 'dropout_rate_Layer_3': 0.24827142387861473, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001517467810188765, 'l1_Layer_2': 1.3577419245179106e-05, 'l1_Layer_3': 0.0002144655391051119, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 42.68% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.53 | sMAPE for Test Set is: 35.31% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:24:43,970]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:24:51,179]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:25:25,177]\u001b[0m Trial 536 finished with value: 8.514772218793992 and parameters: {'n_hidden': 3, 'learning_rate': 0.014363473546446733, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19065796631192, 'dropout_rate_Layer_2': 0.31700099741331433, 'dropout_rate_Layer_3': 0.28295047070744417, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008434483662268868, 'l1_Layer_2': 2.7068111902535356e-05, 'l1_Layer_3': 0.00056550548435009, 'n_units_Layer_1': 220, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 39.91% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.26 | sMAPE for Test Set is: 30.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:26:25,542]\u001b[0m Trial 537 finished with value: 9.533800776945625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010669266945434398, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1505861000969603, 'dropout_rate_Layer_2': 0.3063162814501513, 'dropout_rate_Layer_3': 0.244309338808998, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001638368566676065, 'l1_Layer_2': 1.374321524446642e-05, 'l1_Layer_3': 0.00025178184672512043, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 43.00% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.84 | sMAPE for Test Set is: 37.10% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:26:33,387]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:26:39,306]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:26:47,202]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:28:59,545]\u001b[0m Trial 541 finished with value: 9.576670039156133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017651875035395678, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009435166884659773, 'dropout_rate_Layer_2': 0.12534837472361815, 'dropout_rate_Layer_3': 0.2211062546276016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0015751790384264366, 'l1_Layer_2': 4.1726666133684224e-05, 'l1_Layer_3': 0.005053928194984793, 'n_units_Layer_1': 300, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 43.14% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 27.75 | sMAPE for Test Set is: 36.38% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:29:50,595]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:31:00,364]\u001b[0m Trial 543 finished with value: 9.431967327751932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009186148240465647, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1517558311828416, 'dropout_rate_Layer_2': 0.30705161860741964, 'dropout_rate_Layer_3': 0.23558390837014703, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011986556170109873, 'l1_Layer_2': 1.3394789576243052e-05, 'l1_Layer_3': 0.0002591966737737028, 'n_units_Layer_1': 160, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.43 | sMAPE for Validation Set is: 42.56% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.31 | sMAPE for Test Set is: 35.08% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:31:11,312]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:31:16,594]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:31:45,172]\u001b[0m Trial 546 finished with value: 8.621989028853681 and parameters: {'n_hidden': 3, 'learning_rate': 0.013070697034050392, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1634218391425893, 'dropout_rate_Layer_2': 0.37696034560608754, 'dropout_rate_Layer_3': 0.28992651650691387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017996593714075947, 'l1_Layer_2': 2.768653288018208e-05, 'l1_Layer_3': 0.0003948311023793041, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 39.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 29.12% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:31:56,764]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:32:02,122]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:32:40,471]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:33:11,032]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:33:48,084]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:34:27,984]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:35:30,860]\u001b[0m Trial 553 finished with value: 9.403770168427528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007850148057424577, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16884062324132498, 'dropout_rate_Layer_2': 0.2998707905187524, 'dropout_rate_Layer_3': 0.25903119862411156, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009487744041144297, 'l1_Layer_2': 1.4370415794696528e-05, 'l1_Layer_3': 0.0001795101646647875, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 140}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 42.73% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 26.88 | sMAPE for Test Set is: 34.52% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:36:09,080]\u001b[0m Trial 554 finished with value: 8.564374086430425 and parameters: {'n_hidden': 4, 'learning_rate': 0.002611358662349526, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2330112500134365, 'dropout_rate_Layer_2': 0.17991593630962732, 'dropout_rate_Layer_3': 0.24653827731804817, 'dropout_rate_Layer_4': 0.1593800115986467, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013428453300420645, 'l1_Layer_2': 0.006147757560837686, 'l1_Layer_3': 0.0015118657628753896, 'l1_Layer_4': 4.005855035116374e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 225, 'n_units_Layer_3': 245, 'n_units_Layer_4': 95}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 37.76% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.28 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:36:45,155]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:38:09,841]\u001b[0m Trial 556 finished with value: 9.79118801410041 and parameters: {'n_hidden': 3, 'learning_rate': 0.000768542064982204, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15491494420732807, 'dropout_rate_Layer_2': 0.305879410098098, 'dropout_rate_Layer_3': 0.23177321053598055, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001255218242739773, 'l1_Layer_2': 0.001465323022717442, 'l1_Layer_3': 0.000205966339089299, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 130}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 43.66% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 29.33 | sMAPE for Test Set is: 37.94% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:39:36,555]\u001b[0m Trial 557 finished with value: 9.78012561364205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008977972058602832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17068156117155417, 'dropout_rate_Layer_2': 0.3129870161323469, 'dropout_rate_Layer_3': 0.25870941206780934, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00177825199091902, 'l1_Layer_2': 1.4299985825844416e-05, 'l1_Layer_3': 0.00025813118378407177, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 43.68% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 29.87 | sMAPE for Test Set is: 38.52% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:39:45,286]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:41:08,095]\u001b[0m Trial 559 finished with value: 9.606464700428777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007561494222578336, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1598227910993084, 'dropout_rate_Layer_2': 0.3010897806972763, 'dropout_rate_Layer_3': 0.25869544415637663, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013772125971501406, 'l1_Layer_2': 1.4626215174333926e-05, 'l1_Layer_3': 0.0002965895241500261, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 43.19% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.06 | sMAPE for Test Set is: 36.06% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:42:26,229]\u001b[0m Trial 560 finished with value: 9.609203286352484 and parameters: {'n_hidden': 3, 'learning_rate': 0.000926189977754682, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13250639638235384, 'dropout_rate_Layer_2': 0.3163580713640148, 'dropout_rate_Layer_3': 0.2480000446299564, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009121933414186521, 'l1_Layer_2': 1.2271180809804417e-05, 'l1_Layer_3': 0.0002374949513048683, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 43.20% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 28.91 | sMAPE for Test Set is: 37.23% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:42:37,466]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:43:13,595]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:43:35,203]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:44:31,472]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:45:31,730]\u001b[0m Trial 565 finished with value: 9.376115065676919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008266013876785933, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15400736498032916, 'dropout_rate_Layer_2': 0.1640393367618106, 'dropout_rate_Layer_3': 0.23653592055425648, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011995213223977416, 'l1_Layer_2': 1.5434973049354655e-05, 'l1_Layer_3': 0.0003052020972639339, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 42.24% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.08 | sMAPE for Test Set is: 36.16% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:45:39,538]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:46:55,094]\u001b[0m Trial 567 finished with value: 9.382977540003777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007517043131983342, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16362345884478227, 'dropout_rate_Layer_2': 0.18395758092936015, 'dropout_rate_Layer_3': 0.22859130926300592, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010835828350424532, 'l1_Layer_2': 1.5437353079247075e-05, 'l1_Layer_3': 0.0003917097970544915, 'n_units_Layer_1': 180, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.38 | sMAPE for Validation Set is: 42.64% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.83 | sMAPE for Test Set is: 35.55% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:48:10,071]\u001b[0m Trial 568 finished with value: 9.41591918298461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007328071499463968, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15497891477935777, 'dropout_rate_Layer_2': 0.12706043434823144, 'dropout_rate_Layer_3': 0.23122141618577982, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011024423714330578, 'l1_Layer_2': 0.000562851519460608, 'l1_Layer_3': 0.000391352107278964, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.42 | sMAPE for Validation Set is: 42.41% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.70 | sMAPE for Test Set is: 36.82% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:49:31,877]\u001b[0m Trial 569 finished with value: 9.348008890167474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007336272888029148, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1538683652856204, 'dropout_rate_Layer_2': 0.11238568752040551, 'dropout_rate_Layer_3': 0.23199130485498012, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000913169152283587, 'l1_Layer_2': 1.8828524173618976e-05, 'l1_Layer_3': 0.00040671698384558844, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.35 | sMAPE for Validation Set is: 42.12% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.50 | sMAPE for Test Set is: 36.48% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:49:38,993]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:49:45,773]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:49:56,642]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:51:38,082]\u001b[0m Trial 573 finished with value: 9.362667961377399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008756391156112608, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16117699171113314, 'dropout_rate_Layer_2': 0.11601511448111348, 'dropout_rate_Layer_3': 0.22904992679348957, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008779422011457357, 'l1_Layer_2': 1.8019212290443344e-05, 'l1_Layer_3': 0.0004082399260923784, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 145}. Best is trial 264 with value: 8.41478813989899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.36 | sMAPE for Validation Set is: 42.74% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.30 | sMAPE for Test Set is: 34.68% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:51:45,737]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:52:12,407]\u001b[0m Trial 575 finished with value: 8.374221119261108 and parameters: {'n_hidden': 3, 'learning_rate': 0.02275488379126129, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16135728512117523, 'dropout_rate_Layer_2': 0.35002388988083677, 'dropout_rate_Layer_3': 0.2796818513772846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017134980482935193, 'l1_Layer_2': 2.5624239793189856e-05, 'l1_Layer_3': 0.0004380402062471116, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 37.92% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.05 | sMAPE for Test Set is: 31.47% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:53:58,670]\u001b[0m Trial 576 finished with value: 9.392422510441962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007295714432235309, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1557258983570106, 'dropout_rate_Layer_2': 0.12005246148726553, 'dropout_rate_Layer_3': 0.23067739014324468, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010102359170916344, 'l1_Layer_2': 1.9497832702258143e-05, 'l1_Layer_3': 0.00040509505521434987, 'n_units_Layer_1': 165, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 42.55% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 26.51 | sMAPE for Test Set is: 34.05% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:55:08,590]\u001b[0m Trial 577 finished with value: 9.341416661374085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007504170590495646, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15484635232817948, 'dropout_rate_Layer_2': 0.10863231868718187, 'dropout_rate_Layer_3': 0.21725149582630815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009898090065517736, 'l1_Layer_2': 1.9534700558489884e-05, 'l1_Layer_3': 0.0004189074750284943, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 135}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 42.29% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.51 | sMAPE for Test Set is: 35.33% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:55:59,634]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:57:14,812]\u001b[0m Trial 579 finished with value: 9.305201475861567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007260228102851998, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1417970566912745, 'dropout_rate_Layer_2': 0.11275019552274317, 'dropout_rate_Layer_3': 0.21552416297092156, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009469730265180548, 'l1_Layer_2': 2.0683660616523563e-05, 'l1_Layer_3': 0.0004192695423489025, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 42.07% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.00 | sMAPE for Test Set is: 35.88% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:57:26,845]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:57:32,872]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 13:58:57,307]\u001b[0m Trial 582 finished with value: 9.311211079189704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007216991782256318, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14142178879926204, 'dropout_rate_Layer_2': 0.1175812000079617, 'dropout_rate_Layer_3': 0.22031970315498545, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008790055469451908, 'l1_Layer_2': 2.1399145961235994e-05, 'l1_Layer_3': 0.0001630450135050335, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 42.10% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.29 | sMAPE for Test Set is: 36.15% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 13:59:07,983]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:00:13,849]\u001b[0m Trial 584 finished with value: 9.247715739404702 and parameters: {'n_hidden': 3, 'learning_rate': 0.00073073947917017, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1322327603557299, 'dropout_rate_Layer_2': 0.11157749505735087, 'dropout_rate_Layer_3': 0.21550846782183836, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000891894770866035, 'l1_Layer_2': 2.0659323814011314e-05, 'l1_Layer_3': 0.00016481642062428605, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.25 | sMAPE for Validation Set is: 41.67% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.76 | sMAPE for Test Set is: 35.60% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:01:20,847]\u001b[0m Trial 585 finished with value: 9.270497138617541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007124341228834392, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1325237870647966, 'dropout_rate_Layer_2': 0.1094246788319062, 'dropout_rate_Layer_3': 0.21545426418410218, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008857189964072906, 'l1_Layer_2': 1.9997746491713572e-05, 'l1_Layer_3': 0.00015947875074881046, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 42.13% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.15 | sMAPE for Test Set is: 34.83% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:01:30,604]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:01:37,447]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:01:47,831]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:03:16,523]\u001b[0m Trial 589 finished with value: 9.252909282635182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007208701172385987, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13310519876279908, 'dropout_rate_Layer_2': 0.11192864628769854, 'dropout_rate_Layer_3': 0.2146076152853583, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000840771951083863, 'l1_Layer_2': 2.0154270172421145e-05, 'l1_Layer_3': 0.00017762885434511764, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.25 | sMAPE for Validation Set is: 42.14% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.15 | sMAPE for Test Set is: 34.78% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:03:33,367]\u001b[0m Trial 590 finished with value: 8.471087814955077 and parameters: {'n_hidden': 3, 'learning_rate': 0.01947658351786416, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16096132033608399, 'dropout_rate_Layer_2': 0.346867828753703, 'dropout_rate_Layer_3': 0.3250798354585266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015435273233869922, 'l1_Layer_2': 2.4714064698779118e-05, 'l1_Layer_3': 0.0004300079038756258, 'n_units_Layer_1': 190, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 41.70% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 30.22% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:03:40,428]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:04:16,973]\u001b[0m Trial 592 finished with value: 8.756192516720782 and parameters: {'n_hidden': 4, 'learning_rate': 0.003444819829116799, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24650761581470296, 'dropout_rate_Layer_2': 0.14883761856043862, 'dropout_rate_Layer_3': 0.2694672417457355, 'dropout_rate_Layer_4': 0.24491036303896213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00021749396734766294, 'l1_Layer_2': 0.00990503934304826, 'l1_Layer_3': 0.0014009920337310696, 'l1_Layer_4': 6.73209342040239e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250, 'n_units_Layer_4': 90}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 37.66% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 29.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:04:28,460]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:05:21,878]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:06:47,631]\u001b[0m Trial 595 finished with value: 9.3204236519547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007191526340584281, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1336514998365598, 'dropout_rate_Layer_2': 0.11256960182427447, 'dropout_rate_Layer_3': 0.2209052254458451, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000826879110836572, 'l1_Layer_2': 2.1374560352559227e-05, 'l1_Layer_3': 0.00017597156942899034, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.32 | sMAPE for Validation Set is: 42.17% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.58 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:06:55,230]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:07:02,016]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:07:22,764]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:07:28,731]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:08:58,482]\u001b[0m Trial 600 finished with value: 9.301705631401767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007077503661651923, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13079873793896343, 'dropout_rate_Layer_2': 0.11849243971938445, 'dropout_rate_Layer_3': 0.21207837662412257, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008669625756296803, 'l1_Layer_2': 3.215330830662351e-05, 'l1_Layer_3': 0.00014635039072157367, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.30 | sMAPE for Validation Set is: 42.16% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.28 | sMAPE for Test Set is: 34.96% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:09:05,252]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:09:11,766]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:09:16,603]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:10:30,784]\u001b[0m Trial 604 finished with value: 9.387525345652657 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007107971431966967, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13695030265016944, 'dropout_rate_Layer_2': 0.10370589832468005, 'dropout_rate_Layer_3': 0.2165936767792651, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008151642443228191, 'l1_Layer_2': 2.1922441040557765e-05, 'l1_Layer_3': 0.00016269652231674497, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 42.53% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.59 | sMAPE for Test Set is: 36.57% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:11:51,031]\u001b[0m Trial 605 finished with value: 9.385495300985866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007027401947347507, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12908662414958783, 'dropout_rate_Layer_2': 0.1015057663963101, 'dropout_rate_Layer_3': 0.20836569641414043, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000844258389483281, 'l1_Layer_2': 2.1412825899444142e-05, 'l1_Layer_3': 0.0001591425052112643, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 115}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 42.22% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 27.25 | sMAPE for Test Set is: 34.79% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:12:02,761]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:13:17,878]\u001b[0m Trial 607 finished with value: 9.308492109848597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007312511377122778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12955315165043463, 'dropout_rate_Layer_2': 0.10411969882571316, 'dropout_rate_Layer_3': 0.20920504875853468, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008035323068201921, 'l1_Layer_2': 2.190820359158918e-05, 'l1_Layer_3': 0.00015768728319944065, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 42.03% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.28 | sMAPE for Test Set is: 37.58% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:14:35,109]\u001b[0m Trial 608 finished with value: 9.269150475262489 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007111812617817993, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1304358267101823, 'dropout_rate_Layer_2': 0.10193397105791285, 'dropout_rate_Layer_3': 0.21379691640003234, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008021859403353604, 'l1_Layer_2': 2.393345025194394e-05, 'l1_Layer_3': 0.00014740081081838303, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 41.89% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.33 | sMAPE for Test Set is: 37.59% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:15:14,676]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:17:03,233]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:18:21,377]\u001b[0m Trial 611 finished with value: 9.219004177593368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006956400429267901, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12751023352849206, 'dropout_rate_Layer_2': 0.11574682944734925, 'dropout_rate_Layer_3': 0.21738242048052078, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007403649498876568, 'l1_Layer_2': 2.0962520218140426e-05, 'l1_Layer_3': 0.0001369588216883705, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.22 | sMAPE for Validation Set is: 41.72% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 29.45 | sMAPE for Test Set is: 37.81% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:19:39,773]\u001b[0m Trial 612 finished with value: 9.268454250673953 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006124182971963858, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11823487206930239, 'dropout_rate_Layer_2': 0.1094895967124182, 'dropout_rate_Layer_3': 0.21992738664069925, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007333204486713174, 'l1_Layer_2': 3.0196826086034722e-05, 'l1_Layer_3': 0.00012629369937541062, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.27 | sMAPE for Validation Set is: 41.98% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.20 | sMAPE for Test Set is: 37.53% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:20:56,315]\u001b[0m Trial 613 finished with value: 9.137619435030107 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006190145821472556, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12810916887861942, 'dropout_rate_Layer_2': 0.11491076782437655, 'dropout_rate_Layer_3': 0.2192447661423051, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007081230713712867, 'l1_Layer_2': 2.9239845633140618e-05, 'l1_Layer_3': 0.00012978239597391926, 'n_units_Layer_1': 140, 'n_units_Layer_2': 190, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.14 | sMAPE for Validation Set is: 41.49% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 29.09 | sMAPE for Test Set is: 37.40% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:21:05,102]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:21:10,789]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:22:30,982]\u001b[0m Trial 616 finished with value: 9.372601353303082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006253643176172102, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12244849600182403, 'dropout_rate_Layer_2': 0.11329236799302742, 'dropout_rate_Layer_3': 0.2014892049388947, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006977152837548259, 'l1_Layer_2': 2.878093629464013e-05, 'l1_Layer_3': 0.00014642900503004222, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 42.52% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.41 | sMAPE for Test Set is: 37.79% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:22:38,738]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:24:03,296]\u001b[0m Trial 618 finished with value: 9.4250455731801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006131376842455594, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12299077655617774, 'dropout_rate_Layer_2': 0.11414968877408299, 'dropout_rate_Layer_3': 0.2007682177287913, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000684261521927299, 'l1_Layer_2': 3.512796482291744e-05, 'l1_Layer_3': 0.00013772571994196482, 'n_units_Layer_1': 140, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.43 | sMAPE for Validation Set is: 42.80% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 29.10 | sMAPE for Test Set is: 37.30% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:24:12,026]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:25:14,701]\u001b[0m Trial 620 finished with value: 9.310307553166467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006691647278322322, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12165392221367184, 'dropout_rate_Layer_2': 0.1103341219599189, 'dropout_rate_Layer_3': 0.22294807243604708, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009256551625829495, 'l1_Layer_2': 2.5476292554970126e-05, 'l1_Layer_3': 0.00013505953479786925, 'n_units_Layer_1': 140, 'n_units_Layer_2': 205, 'n_units_Layer_3': 115}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.31 | sMAPE for Validation Set is: 42.15% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 36.44% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:25:22,333]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:25:38,670]\u001b[0m Trial 622 finished with value: 8.71093372837138 and parameters: {'n_hidden': 3, 'learning_rate': 0.023208199296778025, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15953291116775503, 'dropout_rate_Layer_2': 0.3489787568245305, 'dropout_rate_Layer_3': 0.3350117487104597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016037852811319513, 'l1_Layer_2': 2.7879229780646142e-05, 'l1_Layer_3': 0.0008771064897524706, 'n_units_Layer_1': 190, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 41.12% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:25:50,771]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:26:05,624]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:27:39,394]\u001b[0m Trial 625 finished with value: 9.36693730933642 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005535808007344934, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13413470902718141, 'dropout_rate_Layer_2': 0.10960975308519266, 'dropout_rate_Layer_3': 0.20532228398879093, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006540293482501896, 'l1_Layer_2': 3.432227391935378e-05, 'l1_Layer_3': 0.00014500157140980233, 'n_units_Layer_1': 135, 'n_units_Layer_2': 200, 'n_units_Layer_3': 115}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 42.70% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 35.44% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:27:44,721]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:27:55,019]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:28:23,482]\u001b[0m Trial 628 finished with value: 8.443490592909003 and parameters: {'n_hidden': 3, 'learning_rate': 0.016460784412762774, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2009606792449836, 'dropout_rate_Layer_2': 0.3571420082767837, 'dropout_rate_Layer_3': 0.3248587010886306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011029938948693897, 'l1_Layer_2': 2.549076794741963e-05, 'l1_Layer_3': 0.0008586490841076442, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 40.12% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 30.27% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:29:43,910]\u001b[0m Trial 629 finished with value: 9.188367958910066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006064271778418394, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1349490718300368, 'dropout_rate_Layer_2': 0.10918493756529841, 'dropout_rate_Layer_3': 0.20394763859990406, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006543689920879994, 'l1_Layer_2': 3.37891036749644e-05, 'l1_Layer_3': 0.00015410693191153705, 'n_units_Layer_1': 140, 'n_units_Layer_2': 205, 'n_units_Layer_3': 110}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.19 | sMAPE for Validation Set is: 41.57% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 28.20 | sMAPE for Test Set is: 36.18% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:29:50,538]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:30:13,534]\u001b[0m Trial 631 finished with value: 8.526798920825941 and parameters: {'n_hidden': 3, 'learning_rate': 0.015758996241778175, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16692446497982033, 'dropout_rate_Layer_2': 0.3602380988607551, 'dropout_rate_Layer_3': 0.3257172435137562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001281378933867435, 'l1_Layer_2': 2.117959317476902e-05, 'l1_Layer_3': 0.0008704674437305701, 'n_units_Layer_1': 200, 'n_units_Layer_2': 60, 'n_units_Layer_3': 225}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 41.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 32.30% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:31:58,209]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:32:06,565]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:32:12,977]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:35:44,304]\u001b[0m Trial 635 finished with value: 8.696123415541074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032150490418892765, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09269455152316308, 'dropout_rate_Layer_2': 0.17354941149583533, 'dropout_rate_Layer_3': 0.2653293726368457, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002961688194778361, 'l1_Layer_2': 9.560059595206091e-05, 'l1_Layer_3': 0.0016730536175565862, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 40.80% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.33 | sMAPE for Test Set is: 31.93% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:37:12,456]\u001b[0m Trial 636 finished with value: 9.282554402293822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006665695588447916, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11853863769452004, 'dropout_rate_Layer_2': 0.09561730583978767, 'dropout_rate_Layer_3': 0.2093702603578172, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006110732578414818, 'l1_Layer_2': 3.340378921843988e-05, 'l1_Layer_3': 0.00010459847755603472, 'n_units_Layer_1': 140, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 42.16% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.79 | sMAPE for Test Set is: 36.89% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:37:21,244]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:39:05,388]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:39:11,753]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:39:46,078]\u001b[0m Trial 640 finished with value: 8.448055327816926 and parameters: {'n_hidden': 3, 'learning_rate': 0.016165792619112107, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19072559786335072, 'dropout_rate_Layer_2': 0.3588296622455606, 'dropout_rate_Layer_3': 0.37181694559350914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011630786341722871, 'l1_Layer_2': 2.3978367424187758e-05, 'l1_Layer_3': 0.0011671807855358452, 'n_units_Layer_1': 205, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 39.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.45 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:39:55,076]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:41:13,903]\u001b[0m Trial 642 finished with value: 9.277018898584938 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006700252739747752, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10949784529209514, 'dropout_rate_Layer_2': 0.11970910324878029, 'dropout_rate_Layer_3': 0.22181785838211124, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009440517923174371, 'l1_Layer_2': 2.889528333689212e-05, 'l1_Layer_3': 0.00014719250385328625, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 41.74% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 29.35 | sMAPE for Test Set is: 37.82% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:42:03,433]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:42:15,565]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:43:33,651]\u001b[0m Trial 645 finished with value: 9.23666918094001 and parameters: {'n_hidden': 3, 'learning_rate': 0.000674269036881669, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10732451519672068, 'dropout_rate_Layer_2': 0.1290982590293348, 'dropout_rate_Layer_3': 0.2230771300179838, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009292082689223755, 'l1_Layer_2': 2.5190849706903347e-05, 'l1_Layer_3': 8.662263312852073e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 41.54% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 30.06 | sMAPE for Test Set is: 38.92% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:43:49,859]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:45:12,841]\u001b[0m Trial 647 finished with value: 9.085779151354219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005033590711802847, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10096239971178839, 'dropout_rate_Layer_2': 0.1319051785064393, 'dropout_rate_Layer_3': 0.21346548535989837, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009476475838834868, 'l1_Layer_2': 3.257139367684273e-05, 'l1_Layer_3': 0.00013092062413237428, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.09 | sMAPE for Validation Set is: 41.26% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 27.28 | sMAPE for Test Set is: 34.99% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:46:38,068]\u001b[0m Trial 648 finished with value: 9.200548209143438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005177711646655553, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1044455631311708, 'dropout_rate_Layer_2': 0.1209498848578084, 'dropout_rate_Layer_3': 0.21303480736893812, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009603772346586551, 'l1_Layer_2': 3.057984884853662e-05, 'l1_Layer_3': 0.00013240303831689625, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 41.75% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 27.29 | sMAPE for Test Set is: 34.98% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:48:07,545]\u001b[0m Trial 649 finished with value: 9.279145777652744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006345481056659622, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10146389156438816, 'dropout_rate_Layer_2': 0.12192978455693512, 'dropout_rate_Layer_3': 0.21473090157398847, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007717775113969564, 'l1_Layer_2': 3.091765095158903e-05, 'l1_Layer_3': 0.00012902162195139408, 'n_units_Layer_1': 150, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 42.18% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.27 | sMAPE for Test Set is: 36.28% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:48:17,664]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:49:39,738]\u001b[0m Trial 651 finished with value: 9.322923835824792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005381551767464646, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09826975411137065, 'dropout_rate_Layer_2': 0.12184603511784764, 'dropout_rate_Layer_3': 0.2141470230903251, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007526127725628128, 'l1_Layer_2': 3.062366977229807e-05, 'l1_Layer_3': 0.00013118175265801823, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.32 | sMAPE for Validation Set is: 42.35% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 28.03 | sMAPE for Test Set is: 35.85% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:50:51,822]\u001b[0m Trial 652 finished with value: 9.203244418737063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005316467050064355, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10334280734778911, 'dropout_rate_Layer_2': 0.1314738622991793, 'dropout_rate_Layer_3': 0.21131274744482392, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007877480601576123, 'l1_Layer_2': 3.1946174608360806e-05, 'l1_Layer_3': 0.00011928755563680368, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 125}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 41.70% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 28.64 | sMAPE for Test Set is: 36.80% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:52:14,758]\u001b[0m Trial 653 finished with value: 9.430281759948784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005217887998291794, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0971394135873335, 'dropout_rate_Layer_2': 0.1323132279049765, 'dropout_rate_Layer_3': 0.19546260478802308, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006044940789688036, 'l1_Layer_2': 4.171852031208517e-05, 'l1_Layer_3': 8.71631803197484e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.43 | sMAPE for Validation Set is: 42.87% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.36 | sMAPE for Test Set is: 36.45% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:52:20,946]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:52:32,723]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:52:39,147]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:52:45,534]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 14:55:42,279]\u001b[0m Trial 658 finished with value: 8.787633628488528 and parameters: {'n_hidden': 3, 'learning_rate': 0.002533522522830876, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09544477733506608, 'dropout_rate_Layer_2': 0.1796433705392517, 'dropout_rate_Layer_3': 0.25113091196859355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001779036860513231, 'l1_Layer_2': 1.4490892690365903e-05, 'l1_Layer_3': 0.008797728434337949, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.79 | sMAPE for Validation Set is: 39.34% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.54 | sMAPE for Test Set is: 31.23% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 14:57:09,112]\u001b[0m Trial 659 finished with value: 8.953745600386915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005124557640780776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10463614614760715, 'dropout_rate_Layer_2': 0.12125516971901418, 'dropout_rate_Layer_3': 0.20852583294076701, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007413023559019481, 'l1_Layer_2': 3.155862514736568e-05, 'l1_Layer_3': 0.00011254553578629326, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 110}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 40.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 28.34 | sMAPE for Test Set is: 36.29% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:00:38,054]\u001b[0m Trial 660 finished with value: 8.829627400958218 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023631289212139948, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0963317631622668, 'dropout_rate_Layer_2': 0.19179603836984904, 'dropout_rate_Layer_3': 0.25111544305550865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019697077496513257, 'l1_Layer_2': 1.5770735224268023e-05, 'l1_Layer_3': 0.0071854351980792115, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 40.07% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.32 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:00:45,872]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:01:59,295]\u001b[0m Trial 662 finished with value: 9.427231519919586 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005226365459109145, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11297708850740248, 'dropout_rate_Layer_2': 0.1326917923615028, 'dropout_rate_Layer_3': 0.1896185513516722, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006035045404523106, 'l1_Layer_2': 3.7244833320853746e-05, 'l1_Layer_3': 0.00011916369287465653, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 100}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.43 | sMAPE for Validation Set is: 42.76% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 28.77 | sMAPE for Test Set is: 36.89% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:02:05,419]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:05:37,880]\u001b[0m Trial 664 finished with value: 8.770594084180663 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022025783380616054, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09612502346141168, 'dropout_rate_Layer_2': 0.1941634992996786, 'dropout_rate_Layer_3': 0.2525569571758055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001881223493532501, 'l1_Layer_2': 1.286476193420276e-05, 'l1_Layer_3': 0.008217359397737926, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 40.55% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 29.00% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:06:02,732]\u001b[0m Trial 665 finished with value: 8.552942745470295 and parameters: {'n_hidden': 3, 'learning_rate': 0.016743972532799765, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1898661808155383, 'dropout_rate_Layer_2': 0.3586864019784777, 'dropout_rate_Layer_3': 0.3617978645724423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001023956920763669, 'l1_Layer_2': 2.061550920550416e-05, 'l1_Layer_3': 0.0012975842103280526, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 40.96% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.72 | sMAPE for Test Set is: 32.90% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:06:52,215]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:09:22,377]\u001b[0m Trial 667 finished with value: 8.834770474734135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025580922445120878, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1024515936905891, 'dropout_rate_Layer_2': 0.18984969449189742, 'dropout_rate_Layer_3': 0.25005076805132503, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021613056952433216, 'l1_Layer_2': 1.8041034626809855e-05, 'l1_Layer_3': 0.009776294037339582, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 42.27% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 24.44 | sMAPE for Test Set is: 33.37% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:09:30,179]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:09:38,777]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:09:47,445]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:09:56,773]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:10:13,297]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:10:19,924]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:11:59,002]\u001b[0m Trial 674 finished with value: 8.459472130165542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005993747980245685, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12743961615255467, 'dropout_rate_Layer_2': 0.1029460055130586, 'dropout_rate_Layer_3': 0.224904534759845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010009255369590438, 'l1_Layer_2': 3.299349607981484e-05, 'l1_Layer_3': 0.00012063317483102942, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 115}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 37.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 28.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:12:04,910]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:12:22,049]\u001b[0m Trial 676 finished with value: 8.66247026759588 and parameters: {'n_hidden': 3, 'learning_rate': 0.018392917839516514, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20204954141624876, 'dropout_rate_Layer_2': 0.3378304829557475, 'dropout_rate_Layer_3': 0.361694315417036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.548723948272489e-05, 'l1_Layer_2': 9.268310983424608e-05, 'l1_Layer_3': 0.0008178996069594174, 'n_units_Layer_1': 180, 'n_units_Layer_2': 65, 'n_units_Layer_3': 280}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 40.02% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.12 | sMAPE for Test Set is: 29.94% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:14:01,866]\u001b[0m Trial 677 finished with value: 8.530752875217503 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006190518901133993, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11580688716198236, 'dropout_rate_Layer_2': 0.104680948062871, 'dropout_rate_Layer_3': 0.21338374259010287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001021715747803705, 'l1_Layer_2': 4.2179418389816936e-05, 'l1_Layer_3': 8.904642906095843e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 37.97% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.42 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:14:11,488]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:14:19,213]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:15:41,411]\u001b[0m Trial 680 finished with value: 8.679648411930811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006206770231527563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10360401223954112, 'dropout_rate_Layer_2': 0.08616080636457825, 'dropout_rate_Layer_3': 0.1982997360005359, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007530529743100181, 'l1_Layer_2': 3.176101164878822e-05, 'l1_Layer_3': 7.495302180280452e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 120}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.83% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:17:19,051]\u001b[0m Trial 681 finished with value: 8.476141125090082 and parameters: {'n_hidden': 3, 'learning_rate': 0.000586058740487143, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0903618256683402, 'dropout_rate_Layer_2': 0.08983001422768108, 'dropout_rate_Layer_3': 0.20054857927959394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005574395020250285, 'l1_Layer_2': 3.156896879434341e-05, 'l1_Layer_3': 7.164462224791367e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 95}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 38.93% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.24 | sMAPE for Test Set is: 29.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:18:54,777]\u001b[0m Trial 682 finished with value: 8.5649314619937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005723763033450533, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09377292971775801, 'dropout_rate_Layer_2': 0.08518207404026218, 'dropout_rate_Layer_3': 0.20109017581240501, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005547967743522182, 'l1_Layer_2': 5.0244522058368034e-05, 'l1_Layer_3': 7.050673827692335e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 38.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 29.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:19:44,237]\u001b[0m Trial 683 finished with value: 8.607522918670789 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005663170991952716, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09108418487766001, 'dropout_rate_Layer_2': 0.08512426537464234, 'dropout_rate_Layer_3': 0.19722654249529925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005406584014900938, 'l1_Layer_2': 4.8849305293633506e-05, 'l1_Layer_3': 8.109603622073366e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.49% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 29.45% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:22:16,283]\u001b[0m Trial 684 finished with value: 8.650090884883978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025215809491808713, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10467547039903768, 'dropout_rate_Layer_2': 0.19555449331408478, 'dropout_rate_Layer_3': 0.2486971367392198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002114327916166507, 'l1_Layer_2': 1.7266537294441276e-05, 'l1_Layer_3': 0.010591399042366695, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 39.57% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 24.57 | sMAPE for Test Set is: 33.65% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:23:43,722]\u001b[0m Trial 685 finished with value: 8.475466855032614 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005008530283457752, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09290634812505126, 'dropout_rate_Layer_2': 0.08385258756288003, 'dropout_rate_Layer_3': 0.1997055310725872, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005970073021908859, 'l1_Layer_2': 4.96129398383304e-05, 'l1_Layer_3': 7.563137771901277e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 37.68% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 30.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:26:23,911]\u001b[0m Trial 686 finished with value: 8.904908742688411 and parameters: {'n_hidden': 3, 'learning_rate': 0.002546194726013968, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10305732727890879, 'dropout_rate_Layer_2': 0.1867333734952491, 'dropout_rate_Layer_3': 0.24674986567234214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016140878173675054, 'l1_Layer_2': 1.5979181970482323e-05, 'l1_Layer_3': 0.010310619490091962, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.90 | sMAPE for Validation Set is: 40.08% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.33 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:28:06,866]\u001b[0m Trial 687 finished with value: 8.534495035355691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005559739627748643, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08945108890783923, 'dropout_rate_Layer_2': 0.08451076793020319, 'dropout_rate_Layer_3': 0.1952169204314382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006051292055691306, 'l1_Layer_2': 5.2229306221915735e-05, 'l1_Layer_3': 7.231043433017254e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 37.86% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.72 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:28:12,884]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:28:34,218]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:29:58,434]\u001b[0m Trial 690 finished with value: 8.749388153641558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005107906143119408, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09484447632068192, 'dropout_rate_Layer_2': 0.08608400894251696, 'dropout_rate_Layer_3': 0.19500383032855506, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000525150927936146, 'l1_Layer_2': 5.239765574897158e-05, 'l1_Layer_3': 6.927109702987697e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 85}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.75 | sMAPE for Validation Set is: 39.01% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.79 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:30:07,216]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:33:41,582]\u001b[0m Trial 692 finished with value: 8.722071354950648 and parameters: {'n_hidden': 3, 'learning_rate': 0.002478622722799344, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11146196004128484, 'dropout_rate_Layer_2': 0.18362007740910274, 'dropout_rate_Layer_3': 0.2579402488588001, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019709625889919596, 'l1_Layer_2': 2.0268526535519967e-05, 'l1_Layer_3': 0.008659597000429946, 'n_units_Layer_1': 280, 'n_units_Layer_2': 255, 'n_units_Layer_3': 230}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 39.95% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.85 | sMAPE for Test Set is: 28.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:35:03,314]\u001b[0m Trial 693 finished with value: 8.593775732254917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022513326857718, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0895034715080051, 'dropout_rate_Layer_2': 0.08043946805684095, 'dropout_rate_Layer_3': 0.1959069141261708, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005117662666166995, 'l1_Layer_2': 4.883152356179589e-05, 'l1_Layer_3': 7.456653884566308e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.78% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:35:11,130]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:36:23,599]\u001b[0m Trial 695 finished with value: 8.574932896057101 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005495358369846753, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08835525645558585, 'dropout_rate_Layer_2': 0.08116791564870136, 'dropout_rate_Layer_3': 0.19602540667997725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005172771673970472, 'l1_Layer_2': 5.543812668468597e-05, 'l1_Layer_3': 7.176265210690445e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 38.61% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.73 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:36:50,107]\u001b[0m Trial 696 finished with value: 8.4283100494355 and parameters: {'n_hidden': 3, 'learning_rate': 0.013358514568342724, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1710854380055146, 'dropout_rate_Layer_2': 0.3995051935978527, 'dropout_rate_Layer_3': 0.32014281630599517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010545613912432201, 'l1_Layer_2': 1.3262774693932928e-05, 'l1_Layer_3': 0.0004930038110980263, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 38.59% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:39:35,139]\u001b[0m Trial 697 finished with value: 8.878108046436985 and parameters: {'n_hidden': 3, 'learning_rate': 0.002447463693391053, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12163799565373223, 'dropout_rate_Layer_2': 0.18308286038440857, 'dropout_rate_Layer_3': 0.25590437061384447, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020444783593875606, 'l1_Layer_2': 1.870127742908629e-05, 'l1_Layer_3': 0.00923741467877543, 'n_units_Layer_1': 285, 'n_units_Layer_2': 265, 'n_units_Layer_3': 225}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 41.55% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.09 | sMAPE for Test Set is: 29.02% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:40:13,813]\u001b[0m Trial 698 finished with value: 8.7643977039178 and parameters: {'n_hidden': 4, 'learning_rate': 0.0020312457660672163, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22320899103657646, 'dropout_rate_Layer_2': 0.1980601538044075, 'dropout_rate_Layer_3': 0.20142175692219527, 'dropout_rate_Layer_4': 0.1934151704208748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00017666809096293849, 'l1_Layer_2': 0.002985101711209761, 'l1_Layer_3': 0.004754263945683838, 'l1_Layer_4': 3.771882147282299e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280, 'n_units_Layer_4': 60}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.76 | sMAPE for Validation Set is: 38.35% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.51 | sMAPE for Test Set is: 28.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:41:37,613]\u001b[0m Trial 699 finished with value: 8.588684068119486 and parameters: {'n_hidden': 3, 'learning_rate': 0.000546779021115836, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07812645705352313, 'dropout_rate_Layer_2': 0.08372643735602044, 'dropout_rate_Layer_3': 0.19368833868607047, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005131396553712377, 'l1_Layer_2': 5.690735834103269e-05, 'l1_Layer_3': 7.317649122947738e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.64% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 29.67% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:43:05,828]\u001b[0m Trial 700 finished with value: 8.561056076574902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005432360923443285, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08464579523659489, 'dropout_rate_Layer_2': 0.07907986132254818, 'dropout_rate_Layer_3': 0.19384701062620371, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005424884749019278, 'l1_Layer_2': 5.536190707163826e-05, 'l1_Layer_3': 6.981755463133585e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 38.41% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:44:02,218]\u001b[0m Trial 701 finished with value: 8.908308023862963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005003359861773863, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08274446772725344, 'dropout_rate_Layer_2': 0.07558295218796436, 'dropout_rate_Layer_3': 0.18320856658231982, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005437491399725733, 'l1_Layer_2': 6.0114438936641185e-05, 'l1_Layer_3': 6.83676861703617e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 40.25% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 19.71 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:44:23,212]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:46:47,333]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:07,562]\u001b[0m Trial 704 finished with value: 8.72604349239457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025317341873841927, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11715423079737879, 'dropout_rate_Layer_2': 0.19406669357187148, 'dropout_rate_Layer_3': 0.25693024306388196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013341248240945032, 'l1_Layer_2': 1.340502446381394e-05, 'l1_Layer_3': 0.006679735262263531, 'n_units_Layer_1': 275, 'n_units_Layer_2': 255, 'n_units_Layer_3': 230}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 39.85% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.87 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:50:14,190]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:50:20,607]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:52:45,137]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 15:56:09,772]\u001b[0m Trial 708 finished with value: 8.90827717378445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020651658625926326, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10072357496764944, 'dropout_rate_Layer_2': 0.17577616965100118, 'dropout_rate_Layer_3': 0.27283836192211924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001357369860945004, 'l1_Layer_2': 1.8531839820706124e-05, 'l1_Layer_3': 0.013465570300469278, 'n_units_Layer_1': 270, 'n_units_Layer_2': 265, 'n_units_Layer_3': 210}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 40.73% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.41 | sMAPE for Test Set is: 30.42% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 15:58:33,478]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:03:02,789]\u001b[0m Trial 710 finished with value: 8.876982654463172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019976530505379053, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11135004361837231, 'dropout_rate_Layer_2': 0.19346733364707527, 'dropout_rate_Layer_3': 0.24282644746114423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001353219466595408, 'l1_Layer_2': 1.483737238811379e-05, 'l1_Layer_3': 0.008682225434723915, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 210}. Best is trial 575 with value: 8.374221119261108.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 43.37% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 23.08 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:03:28,926]\u001b[0m Trial 711 finished with value: 8.31396963428571 and parameters: {'n_hidden': 3, 'learning_rate': 0.011544167613349447, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19264754936152498, 'dropout_rate_Layer_2': 0.3988341739060425, 'dropout_rate_Layer_3': 0.315263493621726, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.106893997434728e-05, 'l1_Layer_2': 1.1770783445660897e-05, 'l1_Layer_3': 0.0005063033533204002, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 39.08% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 32.54% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:04:20,578]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:06:47,092]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:09:39,823]\u001b[0m Trial 714 finished with value: 8.811527029427259 and parameters: {'n_hidden': 3, 'learning_rate': 0.002539302018978318, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10042371922680701, 'dropout_rate_Layer_2': 0.20060101440856565, 'dropout_rate_Layer_3': 0.2629989830501774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022653290850152698, 'l1_Layer_2': 1.5505723568587802e-05, 'l1_Layer_3': 0.010921791632593134, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 41.73% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 22.82 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:09:46,468]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:15,030]\u001b[0m Trial 716 finished with value: 8.492385915583805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005457068605643909, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0824412485775674, 'dropout_rate_Layer_2': 0.07548961124657907, 'dropout_rate_Layer_3': 0.18018081801597635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005039475524997511, 'l1_Layer_2': 4.930010779704606e-05, 'l1_Layer_3': 7.634874177244053e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 37.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:11:21,493]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:11:36,483]\u001b[0m Trial 718 finished with value: 10.172202301060809 and parameters: {'n_hidden': 3, 'learning_rate': 0.01084725284523863, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13835014299778642, 'dropout_rate_Layer_2': 0.3966835565289977, 'dropout_rate_Layer_3': 0.3563561977193688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.800374596724822e-05, 'l1_Layer_2': 1.504778834768809e-05, 'l1_Layer_3': 0.0015886221827790415, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 195}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.17 | sMAPE for Validation Set is: 44.63% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 26.58 | sMAPE for Test Set is: 41.60% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:12:56,403]\u001b[0m Trial 719 finished with value: 8.541186842743166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005027557207411857, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08250944782313385, 'dropout_rate_Layer_2': 0.07746967898346352, 'dropout_rate_Layer_3': 0.17930624247870003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005166051229722154, 'l1_Layer_2': 4.556746683949003e-05, 'l1_Layer_3': 7.915853821044045e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 37.73% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:14:02,558]\u001b[0m Trial 720 finished with value: 8.398292623181364 and parameters: {'n_hidden': 3, 'learning_rate': 0.000504242199424675, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07681820696028577, 'dropout_rate_Layer_2': 0.07644122944805574, 'dropout_rate_Layer_3': 0.18737236972768004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004947009793003338, 'l1_Layer_2': 4.9568594495371656e-05, 'l1_Layer_3': 7.701163472076072e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 37.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 29.45% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:14:08,928]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:14:30,410]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:16:02,514]\u001b[0m Trial 723 finished with value: 8.814448881968994 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005040844239183354, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08458904020713615, 'dropout_rate_Layer_2': 0.07855859863386634, 'dropout_rate_Layer_3': 0.18044132023207562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005042898835563369, 'l1_Layer_2': 4.7454675010189044e-05, 'l1_Layer_3': 7.70545811662845e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.81 | sMAPE for Validation Set is: 39.10% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 30.21% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:17:20,733]\u001b[0m Trial 724 finished with value: 8.717102131069039 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501196573337612, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08051795634423368, 'dropout_rate_Layer_2': 0.07559085057186006, 'dropout_rate_Layer_3': 0.17710480507463755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004933995968061599, 'l1_Layer_2': 5.337498782125685e-05, 'l1_Layer_3': 6.644671271653464e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 38.91% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.12 | sMAPE for Test Set is: 29.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:17:26,870]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:53,765]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:19:59,810]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:27,145]\u001b[0m Trial 728 finished with value: 8.650983140660777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005392059696527247, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08611217426543848, 'dropout_rate_Layer_2': 0.08077665449266533, 'dropout_rate_Layer_3': 0.1759297497457115, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005550967972362198, 'l1_Layer_2': 4.721937973989931e-05, 'l1_Layer_3': 6.207065780018908e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 38.43% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 29.66% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:21:33,574]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:21:37,618]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:22:58,873]\u001b[0m Trial 731 finished with value: 8.420221947560792 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005503749684983928, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08774121210058776, 'dropout_rate_Layer_2': 0.07788431696482108, 'dropout_rate_Layer_3': 0.17831012261563634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005042815605184286, 'l1_Layer_2': 4.485199306632478e-05, 'l1_Layer_3': 6.300080926036576e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 37.59% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.89 | sMAPE for Test Set is: 31.65% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:24:17,333]\u001b[0m Trial 732 finished with value: 8.398067093304496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005614429065240218, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08734365760195316, 'dropout_rate_Layer_2': 0.07661007598748841, 'dropout_rate_Layer_3': 0.1778227460284731, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005277666783186444, 'l1_Layer_2': 4.769188892294171e-05, 'l1_Layer_3': 6.211651759876584e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 37.28% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.66 | sMAPE for Test Set is: 31.05% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:25:34,493]\u001b[0m Trial 733 finished with value: 8.430920484949356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005564633736259508, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08711799059384807, 'dropout_rate_Layer_2': 0.07643438426740469, 'dropout_rate_Layer_3': 0.17567224996731534, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005357767521226905, 'l1_Layer_2': 4.618669038842965e-05, 'l1_Layer_3': 6.310970186921949e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 37.72% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.68 | sMAPE for Test Set is: 31.18% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:25:40,722]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:03,550]\u001b[0m Trial 735 finished with value: 8.60325331543357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005593982327711214, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0742228292773063, 'dropout_rate_Layer_2': 0.06439942299362755, 'dropout_rate_Layer_3': 0.18268141873185448, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005522442923987003, 'l1_Layer_2': 4.6392380720090124e-05, 'l1_Layer_3': 5.688954437762645e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 250, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.60 | sMAPE for Validation Set is: 38.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.66 | sMAPE for Test Set is: 28.86% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:27:09,542]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:22,144]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:28,767]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:27:54,115]\u001b[0m Trial 739 finished with value: 8.458681327746826 and parameters: {'n_hidden': 3, 'learning_rate': 0.011691470409771178, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21028746273896706, 'dropout_rate_Layer_2': 0.3850872282934047, 'dropout_rate_Layer_3': 0.31839722386450764, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000121803939511334, 'l1_Layer_2': 1.2817776644868513e-05, 'l1_Layer_3': 0.00039051893140722166, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 39.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.03 | sMAPE for Test Set is: 30.78% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:29:14,775]\u001b[0m Trial 740 finished with value: 8.605293221517138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005640571985000551, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09093670263810338, 'dropout_rate_Layer_2': 0.06303314392486653, 'dropout_rate_Layer_3': 0.186983271889886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005451163738059799, 'l1_Layer_2': 4.2927840210631854e-05, 'l1_Layer_3': 5.969938718920041e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.50% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.16 | sMAPE for Test Set is: 29.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:32:02,838]\u001b[0m Trial 741 finished with value: 9.004081170420433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023262666722838406, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11097330922204286, 'dropout_rate_Layer_2': 0.19239604717210687, 'dropout_rate_Layer_3': 0.2584624727981054, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020875943240497197, 'l1_Layer_2': 1.8954993164148614e-05, 'l1_Layer_3': 0.013506905420895764, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 41.01% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 22.53 | sMAPE for Test Set is: 31.25% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:32:08,905]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:15,147]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:32:50,758]\u001b[0m Trial 744 finished with value: 8.325373775156953 and parameters: {'n_hidden': 4, 'learning_rate': 0.004136410651594322, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2136895848528053, 'dropout_rate_Layer_2': 0.18107077966793536, 'dropout_rate_Layer_3': 0.21497056287502317, 'dropout_rate_Layer_4': 0.18095051977653465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.000328488646934368, 'l1_Layer_2': 0.003327801474023785, 'l1_Layer_3': 0.0026966669000687143, 'l1_Layer_4': 1.7959530257260517e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295, 'n_units_Layer_4': 85}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 36.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:37:17,500]\u001b[0m Trial 745 finished with value: 8.724099435547545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016174632158624577, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1121269122996403, 'dropout_rate_Layer_2': 0.18731211612993426, 'dropout_rate_Layer_3': 0.2567330003941357, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012987352072671584, 'l1_Layer_2': 1.9212938157183973e-05, 'l1_Layer_3': 0.012299562873984364, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 210}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 40.10% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 33.00% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:38:34,084]\u001b[0m Trial 746 finished with value: 8.509822978313354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005535653396995759, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06704609200688816, 'dropout_rate_Layer_2': 0.08263032346378159, 'dropout_rate_Layer_3': 0.16766918755750182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005434914506771049, 'l1_Layer_2': 6.512046581638107e-05, 'l1_Layer_3': 7.53027810871414e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 37.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.09 | sMAPE for Test Set is: 29.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:38:40,217]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:39:39,074]\u001b[0m Trial 748 finished with value: 8.664326984548083 and parameters: {'n_hidden': 3, 'learning_rate': 0.00186342299511632, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0633059677655323, 'dropout_rate_Layer_2': 0.08147110688706811, 'dropout_rate_Layer_3': 0.176182592652549, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005428390057360554, 'l1_Layer_2': 6.908025003207176e-05, 'l1_Layer_3': 7.770620459535351e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 250, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 38.99% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.00 | sMAPE for Test Set is: 30.47% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:40:10,502]\u001b[0m Trial 749 finished with value: 8.613271431640387 and parameters: {'n_hidden': 4, 'learning_rate': 0.004546386636054992, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21110784043973757, 'dropout_rate_Layer_2': 0.18490904215878373, 'dropout_rate_Layer_3': 0.2173691415770072, 'dropout_rate_Layer_4': 0.1782422525186754, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014951557692720425, 'l1_Layer_2': 0.002128466695138127, 'l1_Layer_3': 0.002116842499621218, 'l1_Layer_4': 1.2759141368722248e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295, 'n_units_Layer_4': 85}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 42.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 30.75% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:41:00,373]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:06,540]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:27,815]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:33,958]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:40,403]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:46,394]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:52,601]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:41:58,564]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:42:19,690]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:44:41,138]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:01,029]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:47:27,351]\u001b[0m Trial 761 finished with value: 8.39013709514337 and parameters: {'n_hidden': 3, 'learning_rate': 0.011850240758625844, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21227434555412772, 'dropout_rate_Layer_2': 0.3946796363767853, 'dropout_rate_Layer_3': 0.3063406748482452, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.581596197822416e-05, 'l1_Layer_2': 1.4004846446886114e-05, 'l1_Layer_3': 0.001071994324059626, 'n_units_Layer_1': 180, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 40.52% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 33.12% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:47:41,032]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:48:05,375]\u001b[0m Trial 763 finished with value: 8.612655855840352 and parameters: {'n_hidden': 3, 'learning_rate': 0.01083707158897205, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21245726214789812, 'dropout_rate_Layer_2': 0.3965094082221924, 'dropout_rate_Layer_3': 0.31268831794696944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.06866858191483e-05, 'l1_Layer_2': 1.2488096574216992e-05, 'l1_Layer_3': 0.0011777192555877795, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 210}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 43.05% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.15 | sMAPE for Test Set is: 30.72% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:48:30,308]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:49:33,984]\u001b[0m Trial 765 finished with value: 8.587299881290052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005583523658526693, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09338449605090973, 'dropout_rate_Layer_2': 0.07966074284677165, 'dropout_rate_Layer_3': 0.17624374782711888, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004740198102185348, 'l1_Layer_2': 5.953134152697127e-05, 'l1_Layer_3': 5.7982482275203376e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 100}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.59 | sMAPE for Validation Set is: 38.95% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.67 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:49:38,123]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:00,516]\u001b[0m Trial 767 finished with value: 8.493560682856716 and parameters: {'n_hidden': 3, 'learning_rate': 0.01274508165330392, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2058432325245631, 'dropout_rate_Layer_2': 0.38528158836846726, 'dropout_rate_Layer_3': 0.3028761841955656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1801131444779324e-05, 'l1_Layer_2': 1.4099143399845873e-05, 'l1_Layer_3': 0.0003003406597915436, 'n_units_Layer_1': 155, 'n_units_Layer_2': 80, 'n_units_Layer_3': 235}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 40.45% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.96 | sMAPE for Test Set is: 32.07% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:50:21,914]\u001b[0m Trial 768 finished with value: 8.521012708089534 and parameters: {'n_hidden': 3, 'learning_rate': 0.010085205505442356, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19292899301715175, 'dropout_rate_Layer_2': 0.3689791254497123, 'dropout_rate_Layer_3': 0.3503252999249776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2778433397643827e-05, 'l1_Layer_2': 1.789226968059041e-05, 'l1_Layer_3': 0.001891834000394199, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 39.37% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.62 | sMAPE for Test Set is: 32.55% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:50:33,112]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:50:44,993]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:51:51,133]\u001b[0m Trial 771 finished with value: 8.774941190147745 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005741875972094897, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07645645923887609, 'dropout_rate_Layer_2': 0.0788852733904108, 'dropout_rate_Layer_3': 0.1769588991387221, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047221532042921333, 'l1_Layer_2': 4.1420352052007636e-05, 'l1_Layer_3': 8.102329672093501e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 225, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 39.21% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.79 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:52:02,444]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:08,563]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:52:32,153]\u001b[0m Trial 774 finished with value: 8.449113618737863 and parameters: {'n_hidden': 3, 'learning_rate': 0.01266649934071111, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2147071144555276, 'dropout_rate_Layer_2': 0.36586355778985324, 'dropout_rate_Layer_3': 0.3192658553613647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6879011141179364e-05, 'l1_Layer_2': 1.0146016108640811e-05, 'l1_Layer_3': 0.0004779443271300492, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 39.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.00 | sMAPE for Test Set is: 30.31% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:55:30,146]\u001b[0m Trial 775 finished with value: 8.884425424707358 and parameters: {'n_hidden': 3, 'learning_rate': 0.002604711478141947, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10100934590236557, 'dropout_rate_Layer_2': 0.17805816297311763, 'dropout_rate_Layer_3': 0.2651286754600985, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020469994565608764, 'l1_Layer_2': 2.1290549397780014e-05, 'l1_Layer_3': 0.0097549271425122, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 215}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 40.14% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.69 | sMAPE for Test Set is: 30.67% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:58:22,285]\u001b[0m Trial 776 finished with value: 8.645155569035337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025445607550680363, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10092191187311883, 'dropout_rate_Layer_2': 0.17666071845513, 'dropout_rate_Layer_3': 0.25972911214825956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001785554235927793, 'l1_Layer_2': 2.0253609706636094e-05, 'l1_Layer_3': 0.009678068347053804, 'n_units_Layer_1': 280, 'n_units_Layer_2': 265, 'n_units_Layer_3': 215}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 41.26% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.63 | sMAPE for Test Set is: 29.57% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:59:00,744]\u001b[0m Trial 777 finished with value: 9.133644268619122 and parameters: {'n_hidden': 3, 'learning_rate': 0.004755683682331362, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05857914803688923, 'dropout_rate_Layer_2': 0.07851690070777519, 'dropout_rate_Layer_3': 0.18696851175814738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006015222365897612, 'l1_Layer_2': 6.333097103646847e-05, 'l1_Layer_3': 6.141246160885571e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 95}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 39.96% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 22.53 | sMAPE for Test Set is: 33.70% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 16:59:07,156]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 16:59:13,564]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:08,778]\u001b[0m Trial 780 finished with value: 8.680549730719962 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012408536093007339, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0963391478074401, 'dropout_rate_Layer_2': 0.08270779291363392, 'dropout_rate_Layer_3': 0.19841857048913872, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048316882341868883, 'l1_Layer_2': 7.35288524954576e-05, 'l1_Layer_3': 7.058048158697203e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 38.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.17 | sMAPE for Test Set is: 30.99% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:00:15,317]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:21,214]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:31,743]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:00:38,028]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:01:31,423]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:02:52,302]\u001b[0m Trial 786 finished with value: 8.566020994895071 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006180584561952279, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07403040839720074, 'dropout_rate_Layer_2': 0.06337020648598198, 'dropout_rate_Layer_3': 0.19874900731822998, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003530000604309716, 'l1_Layer_2': 7.928357373614568e-05, 'l1_Layer_3': 9.32094502795984e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 85}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 39.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.61 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:03:07,069]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:13,402]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:24,104]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:34,803]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:40,802]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:03:47,352]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:26,456]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:32,792]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:04:38,865]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:05:26,056]\u001b[0m Trial 796 finished with value: 8.728439981476955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015028060336342009, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06626413992103375, 'dropout_rate_Layer_2': 0.09208444873499205, 'dropout_rate_Layer_3': 0.1823420540989174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2427924484046928e-05, 'l1_Layer_2': 3.99653546563858e-05, 'l1_Layer_3': 5.023005833116346e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 39.00% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.88 | sMAPE for Test Set is: 30.65% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:05:33,199]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:06:10,178]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:33,618]\u001b[0m Trial 799 finished with value: 8.580367637497332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005649867900597839, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07300988823988615, 'dropout_rate_Layer_2': 0.061515113500895564, 'dropout_rate_Layer_3': 0.1913993009765258, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005241257070352269, 'l1_Layer_2': 5.7922262488936584e-05, 'l1_Layer_3': 9.742415593406497e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 220, 'n_units_Layer_3': 100}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 38.21% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:07:39,875]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:07:46,112]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:08:07,241]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:08:57,090]\u001b[0m Trial 803 finished with value: 8.53261633576872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019953163803956096, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08406288306136597, 'dropout_rate_Layer_2': 0.04594371039799022, 'dropout_rate_Layer_3': 0.16825438375765356, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005381891497536782, 'l1_Layer_2': 6.0875835043985865e-05, 'l1_Layer_3': 9.614083737017417e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 90}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 38.11% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 29.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:09:37,035]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:09:57,948]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:04,456]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:10:30,384]\u001b[0m Trial 807 finished with value: 8.366171751977562 and parameters: {'n_hidden': 3, 'learning_rate': 0.018209243697051274, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17239986697524073, 'dropout_rate_Layer_2': 0.3297678312780627, 'dropout_rate_Layer_3': 0.33106732140307266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.8027688734236506e-05, 'l1_Layer_2': 3.712130867413174e-05, 'l1_Layer_3': 0.0004809007319670257, 'n_units_Layer_1': 225, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 37.73% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.77 | sMAPE for Test Set is: 30.34% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:10:36,375]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:11:43,355]\u001b[0m Trial 809 finished with value: 8.400110228721921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006269830183649492, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09649007153145855, 'dropout_rate_Layer_2': 0.062024235137895165, 'dropout_rate_Layer_3': 0.16677219583503675, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004185437163733645, 'l1_Layer_2': 5.9763267365626157e-05, 'l1_Layer_3': 6.383101957556038e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95}. Best is trial 711 with value: 8.31396963428571.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 37.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.72 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:14:08,190]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:15:05,255]\u001b[0m Trial 811 finished with value: 8.274493039953924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006267521390980387, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09716728091326662, 'dropout_rate_Layer_2': 0.04233432677139978, 'dropout_rate_Layer_3': 0.19912132924926587, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031122218868753597, 'l1_Layer_2': 6.0917175787599585e-05, 'l1_Layer_3': 8.953628534648238e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 37.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.48 | sMAPE for Test Set is: 28.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:15:25,040]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:15:30,783]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:15:37,069]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:15:43,568]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:16:55,208]\u001b[0m Trial 816 finished with value: 8.327907041483659 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006253191884143604, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08041981952789944, 'dropout_rate_Layer_2': 0.06304052432961779, 'dropout_rate_Layer_3': 0.16474747937972828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031022271961057184, 'l1_Layer_2': 3.950796974063119e-05, 'l1_Layer_3': 4.03145663129189e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 37.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.13 | sMAPE for Test Set is: 29.57% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:19:12,282]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:18,321]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:24,188]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:19:34,754]\u001b[0m Trial 820 finished with value: 15.316565683935124 and parameters: {'n_hidden': 3, 'learning_rate': 0.017977838647196816, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16975435319549387, 'dropout_rate_Layer_2': 0.3983702304208544, 'dropout_rate_Layer_3': 0.34802430701726694, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.6194967251966563e-05, 'l1_Layer_2': 4.371681659561948e-05, 'l1_Layer_3': 0.00025373973960123844, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 300}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.32 | sMAPE for Validation Set is: 59.93% | rMAE for Validation Set is: 1.22\n",
      "MAE for Test Set is: 35.81 | sMAPE for Test Set is: 49.04% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:20:23,544]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:38,965]\u001b[0m Trial 822 finished with value: 8.492261266102227 and parameters: {'n_hidden': 3, 'learning_rate': 0.000635144309085977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07142436890616635, 'dropout_rate_Layer_2': 0.034439579946021474, 'dropout_rate_Layer_3': 0.1762368895282385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.262812752556609e-05, 'l1_Layer_2': 3.788817143906684e-05, 'l1_Layer_3': 8.126347977483931e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 37.79% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.55 | sMAPE for Test Set is: 30.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:21:46,814]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:53,028]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:21:59,210]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:25:39,859]\u001b[0m Trial 826 finished with value: 8.563548265634973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026588514798602126, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08478776162378185, 'dropout_rate_Layer_2': 0.20011512400516154, 'dropout_rate_Layer_3': 0.2772469324493653, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013597151751923862, 'l1_Layer_2': 1.7104841379953645e-05, 'l1_Layer_3': 0.013760035749324025, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 40.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.86 | sMAPE for Test Set is: 30.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:25:45,999]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:26:26,581]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:08,480]\u001b[0m Trial 829 finished with value: 8.645407042463372 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032024602359464953, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07185797139207817, 'dropout_rate_Layer_2': 0.05418625432679518, 'dropout_rate_Layer_3': 0.19281128740172196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004097400811777827, 'l1_Layer_2': 6.682683970390413e-05, 'l1_Layer_3': 7.015211878323466e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 38.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.31 | sMAPE for Test Set is: 31.49% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:27:50,173]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:27:56,591]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:28:17,239]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:29:19,331]\u001b[0m Trial 833 finished with value: 8.607258485966987 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011203252545821055, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06103223100557926, 'dropout_rate_Layer_2': 0.09478525826919097, 'dropout_rate_Layer_3': 0.1788497355401906, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7071613783760592e-05, 'l1_Layer_2': 5.808618102430399e-05, 'l1_Layer_3': 6.748292738972056e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 90}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 38.48% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.44 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:30:25,575]\u001b[0m Trial 834 finished with value: 8.702404197413498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011931947336527226, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09068722800858812, 'dropout_rate_Layer_2': 0.0716366446491375, 'dropout_rate_Layer_3': 0.1891857349141297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011775046077880995, 'l1_Layer_2': 8.733067289094901e-05, 'l1_Layer_3': 0.0001026506984156398, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 85}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 39.35% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.27 | sMAPE for Test Set is: 31.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:32:50,796]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:32:56,872]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:35:24,767]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:35:31,261]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:36:20,435]\u001b[0m Trial 839 finished with value: 8.401947064365961 and parameters: {'n_hidden': 3, 'learning_rate': 0.001543491058628174, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06876920518373243, 'dropout_rate_Layer_2': 0.029115514478108347, 'dropout_rate_Layer_3': 0.1533428926562194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011058507616263893, 'l1_Layer_2': 7.056340363184933e-05, 'l1_Layer_3': 5.203672047965781e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 100}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 38.05% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.82 | sMAPE for Test Set is: 30.51% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:36:33,557]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:36:55,136]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:36:59,283]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:37:31,075]\u001b[0m Trial 843 finished with value: 8.499151866655163 and parameters: {'n_hidden': 4, 'learning_rate': 0.004538529325475059, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20675064500289503, 'dropout_rate_Layer_2': 0.18640633948433627, 'dropout_rate_Layer_3': 0.21758858251442928, 'dropout_rate_Layer_4': 0.17883277880648496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00015819574068910946, 'l1_Layer_2': 0.001960957441395426, 'l1_Layer_3': 0.0023505431371902753, 'l1_Layer_4': 1.6858433431202638e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295, 'n_units_Layer_4': 85}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 37.56% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 30.10% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:37:52,196]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:38:01,405]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:38:22,884]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:38:59,924]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:39:10,773]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:39:15,472]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:40:03,903]\u001b[0m Trial 850 finished with value: 8.573637151087643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012086748676829711, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.061543248594603944, 'dropout_rate_Layer_2': 0.09321036140732046, 'dropout_rate_Layer_3': 0.17614304518580684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004146164947417908, 'l1_Layer_2': 7.147846919911607e-05, 'l1_Layer_3': 0.00010258504460539969, 'n_units_Layer_1': 135, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 38.60% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.56 | sMAPE for Test Set is: 29.95% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:40:42,312]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:40:48,470]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:40:54,796]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:41:19,984]\u001b[0m Trial 854 finished with value: 8.493133908180084 and parameters: {'n_hidden': 3, 'learning_rate': 0.0072777580430989025, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1964971523623382, 'dropout_rate_Layer_2': 0.3518819837189135, 'dropout_rate_Layer_3': 0.30420842474087156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.751826249501036e-05, 'l1_Layer_2': 2.160992856082913e-05, 'l1_Layer_3': 0.00033887401232631686, 'n_units_Layer_1': 200, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 41.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.09 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:41:26,466]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:42:18,563]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:42:24,725]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:43:16,395]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:43:23,040]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:43:52,727]\u001b[0m Trial 860 finished with value: 8.3414434954073 and parameters: {'n_hidden': 3, 'learning_rate': 0.012730567276970273, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14973929945316572, 'dropout_rate_Layer_2': 0.36796923862497916, 'dropout_rate_Layer_3': 0.3285772194727521, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.083540911730265e-05, 'l1_Layer_2': 1.0180058324050075e-05, 'l1_Layer_3': 0.0005013993856313804, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 38.38% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 30.63% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:44:08,724]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:44:19,022]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:46:45,503]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:46:51,602]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:46:58,310]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:47:04,841]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:49:29,315]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:49:35,362]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:49:41,742]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:49:46,201]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:49:52,955]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:50:29,450]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:51:03,665]\u001b[0m Trial 873 finished with value: 8.281716864442206 and parameters: {'n_hidden': 3, 'learning_rate': 0.010012173602878007, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1493674023693242, 'dropout_rate_Layer_2': 0.35598412528678475, 'dropout_rate_Layer_3': 0.3303444272299403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5775120814094076e-05, 'l1_Layer_2': 1.600408764448989e-05, 'l1_Layer_3': 0.0007558686474710187, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 39.23% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.20 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:51:55,009]\u001b[0m Trial 874 finished with value: 8.48429294923637 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020385707173439216, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09451934105173015, 'dropout_rate_Layer_2': 0.09433360993748721, 'dropout_rate_Layer_3': 0.17322878055823349, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.966237475813432e-05, 'l1_Layer_2': 4.866249285326308e-05, 'l1_Layer_3': 5.50555956901188e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 38.17% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.42 | sMAPE for Test Set is: 31.88% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:51:59,141]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:52:24,464]\u001b[0m Trial 876 finished with value: 8.418319646642372 and parameters: {'n_hidden': 3, 'learning_rate': 0.009496318555805605, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14928484387394841, 'dropout_rate_Layer_2': 0.33348053967372177, 'dropout_rate_Layer_3': 0.33154302884098735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.204722788266323e-05, 'l1_Layer_2': 1.000671847472916e-05, 'l1_Layer_3': 0.000694213752430776, 'n_units_Layer_1': 230, 'n_units_Layer_2': 55, 'n_units_Layer_3': 200}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.42 | sMAPE for Validation Set is: 40.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.98 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:52:35,712]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:52:41,675]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:52:57,265]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:53:35,791]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:53:42,049]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:53:54,092]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:54:31,627]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:55:10,620]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:55:16,852]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:55:22,943]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:55:34,143]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:55:38,730]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:56:32,644]\u001b[0m Trial 889 finished with value: 8.787565620643404 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024802902250929083, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1098837355530037, 'dropout_rate_Layer_2': 0.07572547365986951, 'dropout_rate_Layer_3': 0.16338541136747745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001535903056103475, 'l1_Layer_2': 3.678121459820083e-05, 'l1_Layer_3': 6.60431886614003e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 80}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.79 | sMAPE for Validation Set is: 39.50% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.60 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:57:26,106]\u001b[0m Trial 890 finished with value: 8.69432563495946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019510825322995996, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08117267937648266, 'dropout_rate_Layer_2': 0.08850880412869006, 'dropout_rate_Layer_3': 0.2022255651971202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1012732575214479e-05, 'l1_Layer_2': 6.871911472852657e-05, 'l1_Layer_3': 8.593287312391463e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 38.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.24 | sMAPE for Test Set is: 31.23% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 17:57:46,738]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:58:08,472]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:58:30,418]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:58:41,569]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:59:20,993]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 17:59:27,238]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:03:02,525]\u001b[0m Trial 897 finished with value: 8.893004661680598 and parameters: {'n_hidden': 3, 'learning_rate': 0.002210878842028265, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09622417228266858, 'dropout_rate_Layer_2': 0.17962551937518495, 'dropout_rate_Layer_3': 0.23281221080354358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015878193107526862, 'l1_Layer_2': 1.7801739601413555e-05, 'l1_Layer_3': 0.008513593227458979, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 215}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.89 | sMAPE for Validation Set is: 42.74% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.75 | sMAPE for Test Set is: 29.59% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:03:39,610]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:03:45,576]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:03:52,292]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:04:13,408]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:04:19,626]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:04:25,629]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:04:31,912]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:04:38,169]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:05:56,037]\u001b[0m Trial 906 finished with value: 8.51283315060918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014540801185801975, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06955530097374248, 'dropout_rate_Layer_2': 0.08150082578036352, 'dropout_rate_Layer_3': 0.19657632950367596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003518707559236479, 'l1_Layer_2': 0.0002921997813853839, 'l1_Layer_3': 0.00010940585576470126, 'n_units_Layer_1': 155, 'n_units_Layer_2': 220, 'n_units_Layer_3': 90}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 38.06% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.29 | sMAPE for Test Set is: 30.57% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:08:19,494]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:08:25,840]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:08:30,968]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:08:41,680]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:09:36,644]\u001b[0m Trial 911 finished with value: 8.721341203577339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030078068185499913, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057755194759359904, 'dropout_rate_Layer_2': 0.01951025768823797, 'dropout_rate_Layer_3': 0.1449890873347342, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026843619280827216, 'l1_Layer_2': 9.436961823005227e-05, 'l1_Layer_3': 6.097420223831784e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 85}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 39.04% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.57 | sMAPE for Test Set is: 31.01% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:09:42,696]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:10:20,503]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:10:30,306]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:10:48,041]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:11:42,022]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:11:48,908]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:11:55,096]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:15:29,130]\u001b[0m Trial 919 finished with value: 8.714336618544776 and parameters: {'n_hidden': 3, 'learning_rate': 0.002357432165223104, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09460774422800583, 'dropout_rate_Layer_2': 0.20103901614302785, 'dropout_rate_Layer_3': 0.2599962850118188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.333705297617352e-05, 'l1_Layer_2': 1.7213924104403323e-05, 'l1_Layer_3': 0.006488207162352302, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 230}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 39.41% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.31 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:15:35,481]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:15:57,700]\u001b[0m Trial 921 finished with value: 8.54329873400575 and parameters: {'n_hidden': 3, 'learning_rate': 0.005977888603960841, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12579899145237358, 'dropout_rate_Layer_2': 0.37460947311154436, 'dropout_rate_Layer_3': 0.27844100504321967, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9592974819629272e-05, 'l1_Layer_2': 1.4928102864408992e-05, 'l1_Layer_3': 0.0005133445511298571, 'n_units_Layer_1': 255, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 41.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.16 | sMAPE for Test Set is: 32.56% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:16:03,798]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:16:14,713]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:16:56,573]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:17:02,905]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:17:56,273]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:18:50,224]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:19:20,401]\u001b[0m Trial 928 finished with value: 8.928991894870306 and parameters: {'n_hidden': 3, 'learning_rate': 0.003581709822484427, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.260845563978081, 'dropout_rate_Layer_2': 0.09086970552826575, 'dropout_rate_Layer_3': 0.17572251065544667, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.475759144291497e-05, 'l1_Layer_2': 0.00024866316482043685, 'l1_Layer_3': 0.0022271425452565123, 'n_units_Layer_1': 145, 'n_units_Layer_2': 225, 'n_units_Layer_3': 50}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 40.26% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 21.56 | sMAPE for Test Set is: 31.42% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:19:32,078]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:20:52,812]\u001b[0m Trial 930 finished with value: 8.986925231925627 and parameters: {'n_hidden': 3, 'learning_rate': 0.002296523517696797, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006637397783621296, 'dropout_rate_Layer_2': 0.06690926717489037, 'dropout_rate_Layer_3': 0.153205634006785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026140340743452, 'l1_Layer_2': 0.00010570312583151158, 'l1_Layer_3': 0.0018357632426371459, 'n_units_Layer_1': 150, 'n_units_Layer_2': 260, 'n_units_Layer_3': 85}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.99 | sMAPE for Validation Set is: 40.77% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 20.68 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:22:10,175]\u001b[0m Trial 931 finished with value: 8.427356620882826 and parameters: {'n_hidden': 3, 'learning_rate': 0.001617026978597381, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07884775726989153, 'dropout_rate_Layer_2': 0.050758076060459845, 'dropout_rate_Layer_3': 0.18179244012571774, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020146849166675405, 'l1_Layer_2': 0.0016048118902573817, 'l1_Layer_3': 0.003997342334240677, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 65}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 38.16% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.79 | sMAPE for Test Set is: 29.74% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:22:16,462]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:22:22,688]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:22:33,563]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:22:39,788]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:23:31,388]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:23:36,547]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:23:53,784]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:24:00,037]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:24:39,189]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:24:45,444]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:26:08,501]\u001b[0m Trial 942 finished with value: 8.526908984819606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016016042230950877, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06831712086748534, 'dropout_rate_Layer_2': 0.029760254202095198, 'dropout_rate_Layer_3': 0.18389736418154834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003427496396010103, 'l1_Layer_2': 0.0011490022834237006, 'l1_Layer_3': 0.003820857625557844, 'n_units_Layer_1': 140, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 38.68% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 30.12% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:26:29,885]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:27:20,439]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:28:22,792]\u001b[0m Trial 945 finished with value: 8.671008779005033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019933250225436364, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08454506438443557, 'dropout_rate_Layer_2': 0.03404573797443274, 'dropout_rate_Layer_3': 0.18694532537311495, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025374217078489474, 'l1_Layer_2': 0.0009491894566039179, 'l1_Layer_3': 0.004342148119938014, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 55}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 39.30% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 29.12% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:28:43,646]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:30:03,665]\u001b[0m Trial 947 finished with value: 8.487314424621859 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018738347916709788, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07496803135741756, 'dropout_rate_Layer_2': 0.011385775306028783, 'dropout_rate_Layer_3': 0.19158978710759222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001727825035954535, 'l1_Layer_2': 0.0016652609750433154, 'l1_Layer_3': 0.0036941974085957364, 'n_units_Layer_1': 140, 'n_units_Layer_2': 250, 'n_units_Layer_3': 55}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 38.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:32:50,501]\u001b[0m Trial 948 finished with value: 9.033588170672912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026526721509664967, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11696465614797656, 'dropout_rate_Layer_2': 0.20127391242340342, 'dropout_rate_Layer_3': 0.2662635299919505, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019006537718926211, 'l1_Layer_2': 2.310738834387437e-05, 'l1_Layer_3': 0.015173256402153102, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.03 | sMAPE for Validation Set is: 42.63% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 21.23 | sMAPE for Test Set is: 30.25% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:32:54,956]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:33:46,175]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:34:23,880]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:34:51,416]\u001b[0m Trial 952 finished with value: 8.723347421628851 and parameters: {'n_hidden': 4, 'learning_rate': 0.006258818153130174, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2405695889123093, 'dropout_rate_Layer_2': 0.17076324486185526, 'dropout_rate_Layer_3': 0.2136214302181858, 'dropout_rate_Layer_4': 0.23895443776452585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010131923907687967, 'l1_Layer_2': 0.001841654054259357, 'l1_Layer_3': 0.0026735974113532893, 'l1_Layer_4': 2.1389329544036002e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275, 'n_units_Layer_4': 65}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.72 | sMAPE for Validation Set is: 40.01% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.52 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:34:56,604]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:37:21,193]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:38:33,407]\u001b[0m Trial 955 finished with value: 8.712292840480805 and parameters: {'n_hidden': 3, 'learning_rate': 0.001826793918210177, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.088385918537591, 'dropout_rate_Layer_2': 0.012180821145099588, 'dropout_rate_Layer_3': 0.17950811656750235, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020695626820750723, 'l1_Layer_2': 0.002384193066715215, 'l1_Layer_3': 0.0051080617799869055, 'n_units_Layer_1': 140, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 39.80% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.98 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:38:45,767]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:38:52,129]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:38:58,237]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:39:51,680]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:41:24,882]\u001b[0m Trial 960 finished with value: 8.659106825797119 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016023374981174393, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06921600700426639, 'dropout_rate_Layer_2': 0.015088351306979574, 'dropout_rate_Layer_3': 0.20500979129231792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015273669020605707, 'l1_Layer_2': 0.000768475132831938, 'l1_Layer_3': 0.0026222799559178925, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 60}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 39.17% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.20 | sMAPE for Test Set is: 29.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:41:31,334]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:41:36,180]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:42:00,314]\u001b[0m Trial 963 finished with value: 8.58220528573019 and parameters: {'n_hidden': 3, 'learning_rate': 0.011359957520861455, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17438814797546764, 'dropout_rate_Layer_2': 0.33676978672226304, 'dropout_rate_Layer_3': 0.2993094018075913, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.986163786234831e-05, 'l1_Layer_2': 3.660084764850516e-05, 'l1_Layer_3': 0.00032428105479141494, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 38.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.93 | sMAPE for Test Set is: 34.61% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:43:41,364]\u001b[0m Trial 964 finished with value: 8.630740169447224 and parameters: {'n_hidden': 3, 'learning_rate': 0.001665524938984528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08295669879767353, 'dropout_rate_Layer_2': 0.025099947720733005, 'dropout_rate_Layer_3': 0.17094811951903496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.40437942734398e-05, 'l1_Layer_2': 0.0014241441327889558, 'l1_Layer_3': 0.002287643882286776, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 65}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 38.64% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.30 | sMAPE for Test Set is: 29.88% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:43:57,121]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:44:04,964]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:46:31,955]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:46:37,028]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:46:43,325]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:46:58,558]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:48:34,306]\u001b[0m Trial 971 finished with value: 8.519651914109426 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018445322642260272, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05269298990403753, 'dropout_rate_Layer_2': 0.005936424282654891, 'dropout_rate_Layer_3': 0.18207181627238722, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019126171762959073, 'l1_Layer_2': 0.0015197236676339273, 'l1_Layer_3': 0.007351144597480605, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 38.49% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 29.28% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:49:25,519]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:49:31,970]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:49:48,925]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:51:11,601]\u001b[0m Trial 975 finished with value: 8.661696816486902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017132534937621211, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05514725975060472, 'dropout_rate_Layer_2': 0.019875643175466747, 'dropout_rate_Layer_3': 0.16636080041188564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018904467410424253, 'l1_Layer_2': 0.0024123233359506753, 'l1_Layer_3': 0.0037550512833581344, 'n_units_Layer_1': 165, 'n_units_Layer_2': 245, 'n_units_Layer_3': 50}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.66 | sMAPE for Validation Set is: 38.69% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 29.30% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:52:31,188]\u001b[0m Trial 976 finished with value: 8.540827465895823 and parameters: {'n_hidden': 3, 'learning_rate': 0.001904862969557755, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.050778997802086334, 'dropout_rate_Layer_2': 0.006308922599622218, 'dropout_rate_Layer_3': 0.17581838963872518, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002579089618161188, 'l1_Layer_2': 0.0009836532552312748, 'l1_Layer_3': 0.0028667760760505367, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 50}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 38.62% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 29.29% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:52:37,255]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:52:42,393]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:53:03,476]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:53:09,382]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:53:22,224]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:53:28,246]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:53:39,554]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:24,122]\u001b[0m Trial 984 finished with value: 8.412418163297154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020707982882692206, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04921383178972412, 'dropout_rate_Layer_2': 0.006291685895936944, 'dropout_rate_Layer_3': 0.00681685072392782, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002288178637455348, 'l1_Layer_2': 0.0011371942439905864, 'l1_Layer_3': 0.008007804044269696, 'n_units_Layer_1': 160, 'n_units_Layer_2': 255, 'n_units_Layer_3': 60}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 37.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:55:30,094]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:55:59,128]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:56:05,435]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:08,361]\u001b[0m Trial 988 finished with value: 8.634008163843536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018747583406300125, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045463329318407075, 'dropout_rate_Layer_2': 0.009407459099590638, 'dropout_rate_Layer_3': 0.14043411464241093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.350216995440125e-05, 'l1_Layer_2': 0.001718783681977373, 'l1_Layer_3': 0.008284785815979032, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 39.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.58 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:57:14,775]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:57:41,462]\u001b[0m Trial 990 finished with value: 8.569992914326011 and parameters: {'n_hidden': 3, 'learning_rate': 0.020038692819843627, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1806219809674327, 'dropout_rate_Layer_2': 0.3779986115063818, 'dropout_rate_Layer_3': 0.3183055636897912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7382334235127798e-05, 'l1_Layer_2': 1.2438919056307883e-05, 'l1_Layer_3': 0.000583366253366313, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 225}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 39.89% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 31.11% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 18:58:33,506]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:58:37,812]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 18:59:49,093]\u001b[0m Trial 993 finished with value: 8.775214553574445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021315490181314524, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05382057034875915, 'dropout_rate_Layer_2': 0.02859276890223087, 'dropout_rate_Layer_3': 0.348155420604078, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017276278913368003, 'l1_Layer_2': 0.0014317872177180848, 'l1_Layer_3': 0.008413903006091374, 'n_units_Layer_1': 165, 'n_units_Layer_2': 255, 'n_units_Layer_3': 50}. Best is trial 811 with value: 8.274493039953924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.78 | sMAPE for Validation Set is: 39.56% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.26 | sMAPE for Test Set is: 31.12% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:00:27,608]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:42,772]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:00:48,601]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:17,565]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:23,715]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:01:34,459]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:41,081]\u001b[0m Trial 1000 finished with value: 8.225517201367888 and parameters: {'n_hidden': 3, 'learning_rate': 0.002698934573973206, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02786380063858465, 'dropout_rate_Layer_2': 0.024867517303593586, 'dropout_rate_Layer_3': 0.03801085065331131, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028757571689785215, 'l1_Layer_2': 0.000985303525414039, 'l1_Layer_3': 0.007489338636266134, 'n_units_Layer_1': 165, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.23 | sMAPE for Validation Set is: 36.86% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 19.32 | sMAPE for Test Set is: 28.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:02:48,071]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:54,633]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:02:59,618]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:03:53,012]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:04:30,402]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:06:00,193]\u001b[0m Trial 1006 finished with value: 8.584957987711926 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014570484209428267, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020265105235832314, 'dropout_rate_Layer_2': 0.02007734926991816, 'dropout_rate_Layer_3': 0.012716513580742085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0929007761678005e-05, 'l1_Layer_2': 0.0010630388324056742, 'l1_Layer_3': 0.00986602944805264, 'n_units_Layer_1': 135, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 38.78% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.52 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:06:06,429]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:07:24,340]\u001b[0m Trial 1008 finished with value: 8.40605349696059 and parameters: {'n_hidden': 3, 'learning_rate': 0.001602467439168624, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0233569176344052, 'dropout_rate_Layer_2': 0.19325587171337869, 'dropout_rate_Layer_3': 0.04676930841496381, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000245136317953745, 'l1_Layer_2': 0.0015084433901564021, 'l1_Layer_3': 0.0077953759893683245, 'n_units_Layer_1': 130, 'n_units_Layer_2': 245, 'n_units_Layer_3': 75}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 37.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.12 | sMAPE for Test Set is: 29.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:07:44,575]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:00,513]\u001b[0m Trial 1010 finished with value: 8.65468673844551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017431147647726539, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037883624346550515, 'dropout_rate_Layer_2': 0.1772619899514402, 'dropout_rate_Layer_3': 0.07287458341677354, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022281831335437203, 'l1_Layer_2': 0.0015738037329721052, 'l1_Layer_3': 0.007887265667317591, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 75}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 39.21% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 28.78% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:09:08,270]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:22,284]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:09:56,078]\u001b[0m Trial 1013 finished with value: 8.555475841631134 and parameters: {'n_hidden': 3, 'learning_rate': 0.014735644297472995, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13481009732833082, 'dropout_rate_Layer_2': 0.3656217166247672, 'dropout_rate_Layer_3': 0.33437436240146345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3133450552219855e-05, 'l1_Layer_2': 2.4143029478283163e-05, 'l1_Layer_3': 0.0007746427139439142, 'n_units_Layer_1': 215, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 39.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.36 | sMAPE for Test Set is: 30.42% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:10:03,494]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:08,504]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:10:14,752]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:11:17,373]\u001b[0m Trial 1017 finished with value: 8.623429519570086 and parameters: {'n_hidden': 3, 'learning_rate': 0.001721597623057957, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038362994145363684, 'dropout_rate_Layer_2': 0.16450919768024813, 'dropout_rate_Layer_3': 0.041405191828182544, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002049490406060781, 'l1_Layer_2': 0.0016352984991288245, 'l1_Layer_3': 0.005353238092725808, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 39.13% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.28 | sMAPE for Test Set is: 29.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:15:03,774]\u001b[0m Trial 1018 finished with value: 8.85292112943411 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024381444047872013, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10285519670370516, 'dropout_rate_Layer_2': 0.18473017700806466, 'dropout_rate_Layer_3': 0.2622234155774347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.316109734241088e-05, 'l1_Layer_2': 2.0373542658495088e-05, 'l1_Layer_3': 0.007456371472752123, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 40.84% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 28.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:15:08,141]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:24,908]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:30,910]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:36,821]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:15:53,531]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:16:29,365]\u001b[0m Trial 1024 finished with value: 8.553053063037309 and parameters: {'n_hidden': 3, 'learning_rate': 0.002729990025522703, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03043289597022105, 'dropout_rate_Layer_2': 0.1481159154390499, 'dropout_rate_Layer_3': 0.003575644736191756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014701853235077645, 'l1_Layer_2': 0.0006363889512173294, 'l1_Layer_3': 0.01592711608012982, 'n_units_Layer_1': 145, 'n_units_Layer_2': 245, 'n_units_Layer_3': 75}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 38.26% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.93 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:17:44,929]\u001b[0m Trial 1025 finished with value: 8.81921728039297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017989356805212914, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015448700538134096, 'dropout_rate_Layer_2': 0.17033853414582367, 'dropout_rate_Layer_3': 0.07759314409009654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002406985228637403, 'l1_Layer_2': 0.0018684000993400244, 'l1_Layer_3': 0.0022806418902927544, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 60}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.82 | sMAPE for Validation Set is: 40.29% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 29.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:18:06,483]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:19:23,845]\u001b[0m Trial 1027 finished with value: 8.360615152953507 and parameters: {'n_hidden': 3, 'learning_rate': 0.003716307206481329, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008983252545852397, 'dropout_rate_Layer_2': 0.045583837803800126, 'dropout_rate_Layer_3': 0.0023101009686251617, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002948327503297617, 'l1_Layer_2': 0.001089406217217995, 'l1_Layer_3': 0.009888873073990804, 'n_units_Layer_1': 120, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 37.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 29.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:20:46,289]\u001b[0m Trial 1028 finished with value: 8.358597541813952 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025304474980118864, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0014535626603214176, 'dropout_rate_Layer_2': 0.2377415055038639, 'dropout_rate_Layer_3': 0.01777042259845895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002520224437891222, 'l1_Layer_2': 0.0009602055214090817, 'l1_Layer_3': 0.006620534278223463, 'n_units_Layer_1': 115, 'n_units_Layer_2': 215, 'n_units_Layer_3': 55}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 37.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 28.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:20:57,486]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:03,953]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:17,379]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:21:37,364]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:22:00,692]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:23:25,494]\u001b[0m Trial 1034 finished with value: 8.288210525907845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024706893768273396, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003534099369158631, 'dropout_rate_Layer_2': 0.1566247367923249, 'dropout_rate_Layer_3': 0.009666332805873357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002146341596246959, 'l1_Layer_2': 0.0009019043949780811, 'l1_Layer_3': 0.008106403849665426, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 36.63% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.28 | sMAPE for Test Set is: 29.78% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:25:04,805]\u001b[0m Trial 1035 finished with value: 8.296894320217183 and parameters: {'n_hidden': 3, 'learning_rate': 0.003037354539662984, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003894299692073287, 'dropout_rate_Layer_2': 0.149936621562088, 'dropout_rate_Layer_3': 0.011263383174338115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018830811613910196, 'l1_Layer_2': 0.0009325929133257291, 'l1_Layer_3': 0.0062384765119511115, 'n_units_Layer_1': 115, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 38.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.88 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:26:32,030]\u001b[0m Trial 1036 finished with value: 8.368677658680532 and parameters: {'n_hidden': 3, 'learning_rate': 0.003194132866734573, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0059720460069480836, 'dropout_rate_Layer_2': 0.19365360877964655, 'dropout_rate_Layer_3': 0.0013242759592275955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000217340361675515, 'l1_Layer_2': 0.0009247066309723118, 'l1_Layer_3': 0.009508990779834513, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 38.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 28.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:28:10,834]\u001b[0m Trial 1037 finished with value: 8.281411687446726 and parameters: {'n_hidden': 3, 'learning_rate': 0.003383711052525778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0030527418617592623, 'dropout_rate_Layer_2': 0.23438644598536146, 'dropout_rate_Layer_3': 0.0003992012284268027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022028268077941434, 'l1_Layer_2': 0.000734025202260486, 'l1_Layer_3': 0.010395918977012334, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.28 | sMAPE for Validation Set is: 38.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.05 | sMAPE for Test Set is: 27.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:29:13,550]\u001b[0m Trial 1038 finished with value: 8.264938454721245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032014973268771033, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0034341336050345804, 'dropout_rate_Layer_2': 0.2147500227812279, 'dropout_rate_Layer_3': 0.0035792748818162783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002209648014680313, 'l1_Layer_2': 0.0008538825348629473, 'l1_Layer_3': 0.01122539790524138, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 1000 with value: 8.225517201367888.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.26 | sMAPE for Validation Set is: 37.06% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.40 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:29:24,059]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:29:45,499]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:31:26,561]\u001b[0m Trial 1041 finished with value: 8.21054602502476 and parameters: {'n_hidden': 3, 'learning_rate': 0.003056294430752643, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006063466945455814, 'dropout_rate_Layer_2': 0.21126747006872354, 'dropout_rate_Layer_3': 0.00046574392352873115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021742514434156804, 'l1_Layer_2': 0.0007554985666473075, 'l1_Layer_3': 0.010363728704733899, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1041 with value: 8.21054602502476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 37.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:32:37,105]\u001b[0m Trial 1042 finished with value: 8.286892069051857 and parameters: {'n_hidden': 3, 'learning_rate': 0.003066560080310489, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.003462733584395425, 'dropout_rate_Layer_2': 0.214525164712903, 'dropout_rate_Layer_3': 0.004642095502009817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020000999823612109, 'l1_Layer_2': 0.0009079016266753967, 'l1_Layer_3': 0.012223496386158472, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50}. Best is trial 1041 with value: 8.21054602502476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 37.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:35:06,853]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:35:12,947]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:36:31,823]\u001b[0m Trial 1045 finished with value: 8.209372054931181 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034656922586568215, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0031557738230065724, 'dropout_rate_Layer_2': 0.21628336662117936, 'dropout_rate_Layer_3': 0.0001734165346322005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023017440189353254, 'l1_Layer_2': 0.000849850064830964, 'l1_Layer_3': 0.01072987882277849, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.21 | sMAPE for Validation Set is: 35.98% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:37:53,446]\u001b[0m Trial 1046 finished with value: 8.267271259201824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031908125941757315, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00010391734451725004, 'dropout_rate_Layer_2': 0.21173615764642847, 'dropout_rate_Layer_3': 9.267443119607803e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021923491002738728, 'l1_Layer_2': 0.0008212625934701854, 'l1_Layer_3': 0.009957257418369767, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 37.03% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.17 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:37:58,626]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:38:58,701]\u001b[0m Trial 1048 finished with value: 8.326661553711611 and parameters: {'n_hidden': 3, 'learning_rate': 0.003110661550656325, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008722738251021767, 'dropout_rate_Layer_2': 0.22570864014807854, 'dropout_rate_Layer_3': 0.011721240267034898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023937636429799945, 'l1_Layer_2': 0.0007544666814377198, 'l1_Layer_3': 0.01344390477832667, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 37.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.02 | sMAPE for Test Set is: 28.96% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:39:33,367]\u001b[0m Trial 1049 finished with value: 8.434624239000023 and parameters: {'n_hidden': 4, 'learning_rate': 0.002707498433235349, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24831872515065628, 'dropout_rate_Layer_2': 0.19728768125025833, 'dropout_rate_Layer_3': 0.19552576596884716, 'dropout_rate_Layer_4': 0.19224165756076236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00020635520411857474, 'l1_Layer_2': 0.009221478724713726, 'l1_Layer_3': 0.003221491458250537, 'l1_Layer_4': 1.1623812291720336e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 190, 'n_units_Layer_3': 290, 'n_units_Layer_4': 90}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 38.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 29.74% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:39:39,381]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:39:54,985]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:40:15,664]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:41:06,555]\u001b[0m Trial 1053 finished with value: 8.329927646888969 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030774661390889054, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0056310320005390204, 'dropout_rate_Layer_2': 0.22275957553648448, 'dropout_rate_Layer_3': 0.0006476633115265551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000229171401157616, 'l1_Layer_2': 0.000768097526162644, 'l1_Layer_3': 0.013712414829566526, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 37.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.48 | sMAPE for Test Set is: 28.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:42:26,969]\u001b[0m Trial 1054 finished with value: 8.339040105672433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030720648281053376, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0076582594067327574, 'dropout_rate_Layer_2': 0.2170259346277177, 'dropout_rate_Layer_3': 0.011272568908666594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024117015911712588, 'l1_Layer_2': 0.0007576502161819851, 'l1_Layer_3': 0.013170940757425583, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 39.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.41 | sMAPE for Test Set is: 28.31% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:43:10,551]\u001b[0m Trial 1055 finished with value: 8.4633297249708 and parameters: {'n_hidden': 3, 'learning_rate': 0.003222283355901586, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010598805682451237, 'dropout_rate_Layer_2': 0.22452421560452193, 'dropout_rate_Layer_3': 0.011246053382348572, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023738483910432228, 'l1_Layer_2': 0.0007803842600358975, 'l1_Layer_3': 0.013723768270067022, 'n_units_Layer_1': 110, 'n_units_Layer_2': 105, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 37.34% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:43:17,225]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:39,969]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:43:51,856]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:44:02,764]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:45:05,563]\u001b[0m Trial 1060 finished with value: 8.311495996911491 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035163172263322573, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011408573917984256, 'dropout_rate_Layer_2': 0.21054456241724684, 'dropout_rate_Layer_3': 0.011072073316434908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024063621425741963, 'l1_Layer_2': 0.0008978265765910392, 'l1_Layer_3': 0.010294455702020353, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.31 | sMAPE for Validation Set is: 37.14% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.12 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:45:51,444]\u001b[0m Trial 1061 finished with value: 8.465138750609801 and parameters: {'n_hidden': 3, 'learning_rate': 0.003664539724923457, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00012388642091978354, 'dropout_rate_Layer_2': 0.22924679952766477, 'dropout_rate_Layer_3': 0.008612286068522892, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024145040683235092, 'l1_Layer_2': 0.0009167952845498133, 'l1_Layer_3': 0.01321372723283094, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 37.77% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 29.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:48:22,132]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:49:21,079]\u001b[0m Trial 1063 finished with value: 8.348053074074544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030415638122727683, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010299874564876082, 'dropout_rate_Layer_2': 0.21521467261027802, 'dropout_rate_Layer_3': 0.013092606507537019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002502113550640467, 'l1_Layer_2': 0.0007259433156238495, 'l1_Layer_3': 0.010601195864496682, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 37.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 29.94% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:50:55,806]\u001b[0m Trial 1064 finished with value: 8.331646596070174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029778125612538167, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011023047182486055, 'dropout_rate_Layer_2': 0.2100260363753399, 'dropout_rate_Layer_3': 0.01271269742759045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025239933297418413, 'l1_Layer_2': 0.0006927285291753726, 'l1_Layer_3': 0.00982544254130944, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 37.36% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.09 | sMAPE for Test Set is: 27.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:51:58,370]\u001b[0m Trial 1065 finished with value: 8.437899233442883 and parameters: {'n_hidden': 3, 'learning_rate': 0.00312491770689862, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010501421469601667, 'dropout_rate_Layer_2': 0.21506855461900926, 'dropout_rate_Layer_3': 0.012850479477304293, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002489178463323735, 'l1_Layer_2': 0.0005759478512272568, 'l1_Layer_3': 0.010653521032115686, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 37.24% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.36 | sMAPE for Test Set is: 27.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:52:41,597]\u001b[0m Trial 1066 finished with value: 8.483287696099131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035266594447361877, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005661103574784079, 'dropout_rate_Layer_2': 0.20733581683010435, 'dropout_rate_Layer_3': 0.01476088736786292, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017365092907239345, 'l1_Layer_2': 0.0007197688771089389, 'l1_Layer_3': 0.014975548314661764, 'n_units_Layer_1': 105, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 39.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:53:06,157]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:54:08,152]\u001b[0m Trial 1068 finished with value: 8.296296051399453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029340397760508515, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011354833035607088, 'dropout_rate_Layer_2': 0.20916221128784082, 'dropout_rate_Layer_3': 0.02164219206841956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027754409362595027, 'l1_Layer_2': 0.0008131663682881183, 'l1_Layer_3': 0.010422676811879028, 'n_units_Layer_1': 120, 'n_units_Layer_2': 115, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 36.76% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.27 | sMAPE for Test Set is: 28.19% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:55:02,773]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:55:13,348]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:55:20,548]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:46,038]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:57:51,487]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:01,069]\u001b[0m Trial 1074 finished with value: 8.293329729919314 and parameters: {'n_hidden': 3, 'learning_rate': 0.003385934146041495, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010178464736918507, 'dropout_rate_Layer_2': 0.22308372252452346, 'dropout_rate_Layer_3': 0.02001384114537015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002790009639351702, 'l1_Layer_2': 0.000729565481504566, 'l1_Layer_3': 0.012967144333398883, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.29 | sMAPE for Validation Set is: 36.47% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 19:59:06,544]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:13,038]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:23,218]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:28,663]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 19:59:58,226]\u001b[0m Trial 1079 finished with value: 8.504309541444703 and parameters: {'n_hidden': 3, 'learning_rate': 0.01650636046726437, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18719649642465008, 'dropout_rate_Layer_2': 0.35923615540430553, 'dropout_rate_Layer_3': 0.3688072957376623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010556790743349506, 'l1_Layer_2': 2.521091230314476e-05, 'l1_Layer_3': 0.0011220294040786925, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 260}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 40.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.34 | sMAPE for Test Set is: 31.53% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:01:00,761]\u001b[0m Trial 1080 finished with value: 8.500085116047325 and parameters: {'n_hidden': 3, 'learning_rate': 0.003770122626627614, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014803323718232472, 'dropout_rate_Layer_2': 0.22286739304589728, 'dropout_rate_Layer_3': 0.01685205107599382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027628796460587066, 'l1_Layer_2': 0.0006736171364270966, 'l1_Layer_3': 0.012841644373528633, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 37.34% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:01:52,896]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:03:33,785]\u001b[0m Trial 1082 finished with value: 8.25456494421597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028888815796800004, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007874136851531453, 'dropout_rate_Layer_2': 0.2154921309475893, 'dropout_rate_Layer_3': 0.0061084121874633, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001656231479676906, 'l1_Layer_2': 0.0005334936479758322, 'l1_Layer_3': 0.02237797218523144, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 36.53% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.93 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:04:49,144]\u001b[0m Trial 1083 finished with value: 8.344831980261796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029000444035775703, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005672551299525071, 'dropout_rate_Layer_2': 0.21437892390797747, 'dropout_rate_Layer_3': 0.0016288148483211337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016496427991800065, 'l1_Layer_2': 0.0009921070641174532, 'l1_Layer_3': 0.010919176041159589, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 37.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:04:59,551]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:06:04,884]\u001b[0m Trial 1085 finished with value: 8.45616334129315 and parameters: {'n_hidden': 3, 'learning_rate': 0.002860915454228197, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014451356575131292, 'dropout_rate_Layer_2': 0.2140444113251732, 'dropout_rate_Layer_3': 0.008439611893431214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001648643064953175, 'l1_Layer_2': 0.0005421366841817121, 'l1_Layer_3': 0.01950661100583871, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 38.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.64 | sMAPE for Test Set is: 32.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:06:57,617]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:07:03,267]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:15,410]\u001b[0m Trial 1088 finished with value: 8.388947879842785 and parameters: {'n_hidden': 3, 'learning_rate': 0.003899329385799867, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007674229207717876, 'dropout_rate_Layer_2': 0.2057491626685089, 'dropout_rate_Layer_3': 0.012782834906626354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015485509291222744, 'l1_Layer_2': 0.0007210455910433992, 'l1_Layer_3': 0.015984749511260294, 'n_units_Layer_1': 115, 'n_units_Layer_2': 115, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 36.81% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 29.11% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:08:26,212]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:37,342]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:42,680]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:08:53,248]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:12:29,795]\u001b[0m Trial 1093 finished with value: 8.543877893448043 and parameters: {'n_hidden': 3, 'learning_rate': 0.002503627314094843, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09695899650004124, 'dropout_rate_Layer_2': 0.15512428263068803, 'dropout_rate_Layer_3': 0.26269761612202247, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015033666844694042, 'l1_Layer_2': 1.1412685294798246e-05, 'l1_Layer_3': 0.004936170368290059, 'n_units_Layer_1': 275, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.54 | sMAPE for Validation Set is: 40.94% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.81 | sMAPE for Test Set is: 30.46% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:13:46,623]\u001b[0m Trial 1094 finished with value: 8.367472581087767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027027537194486105, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016098723358498424, 'dropout_rate_Layer_2': 0.2150596842864419, 'dropout_rate_Layer_3': 5.29599964139045e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017724802779708494, 'l1_Layer_2': 0.0005201777669989441, 'l1_Layer_3': 0.011914587035366315, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.37 | sMAPE for Validation Set is: 37.50% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.33 | sMAPE for Test Set is: 28.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:14:45,047]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:14:50,813]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:01,136]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:15:21,863]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:16:44,842]\u001b[0m Trial 1099 finished with value: 8.406659566440181 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026338133924205397, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015397934493214447, 'dropout_rate_Layer_2': 0.23991536325709048, 'dropout_rate_Layer_3': 0.02166919698040342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013775176432921833, 'l1_Layer_2': 0.0008447411435926669, 'l1_Layer_3': 0.011708972324499856, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 37.62% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.21 | sMAPE for Test Set is: 31.05% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:17:07,551]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:18:06,760]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:21:06,159]\u001b[0m Trial 1102 finished with value: 8.834752702737918 and parameters: {'n_hidden': 3, 'learning_rate': 0.002097706198755787, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10416909263715393, 'dropout_rate_Layer_2': 0.18592690924388547, 'dropout_rate_Layer_3': 0.27209844265090916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.497358936968894e-05, 'l1_Layer_2': 1.091124800520378e-05, 'l1_Layer_3': 0.005791126302270038, 'n_units_Layer_1': 265, 'n_units_Layer_2': 255, 'n_units_Layer_3': 195}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.83 | sMAPE for Validation Set is: 39.81% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.52 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:22:08,032]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:26:11,788]\u001b[0m Trial 1104 finished with value: 8.698619858932473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020166432572221943, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09298077182700182, 'dropout_rate_Layer_2': 0.18588325012081594, 'dropout_rate_Layer_3': 0.27382478158826745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003646099333582269, 'l1_Layer_2': 1.0279377809065438e-05, 'l1_Layer_3': 0.0052151014472576135, 'n_units_Layer_1': 265, 'n_units_Layer_2': 255, 'n_units_Layer_3': 195}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 41.18% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.78 | sMAPE for Test Set is: 30.53% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:27:11,801]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:32:10,463]\u001b[0m Trial 1106 finished with value: 8.734868249509661 and parameters: {'n_hidden': 3, 'learning_rate': 0.00201207888403829, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15656547401564652, 'dropout_rate_Layer_2': 0.17917892555490308, 'dropout_rate_Layer_3': 0.2740974252644073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003666854178533768, 'l1_Layer_2': 1.0677390114841677e-05, 'l1_Layer_3': 0.0054630328544486, 'n_units_Layer_1': 260, 'n_units_Layer_2': 255, 'n_units_Layer_3': 190}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.73 | sMAPE for Validation Set is: 39.28% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.18 | sMAPE for Test Set is: 30.63% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:32:20,382]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:32:26,668]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:32:47,226]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:10,912]\u001b[0m Trial 1110 finished with value: 8.73983058680731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016594087156824873, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1564005706421945, 'dropout_rate_Layer_2': 0.17201744741485758, 'dropout_rate_Layer_3': 0.2921570583420099, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048349831716620764, 'l1_Layer_2': 1.020257109624917e-05, 'l1_Layer_3': 0.004722570234749216, 'n_units_Layer_1': 255, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.74 | sMAPE for Validation Set is: 40.41% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 30.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:37:17,219]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:37:24,085]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:09,829]\u001b[0m Trial 1113 finished with value: 8.339200202014121 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036349349210879536, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005708689520196224, 'dropout_rate_Layer_2': 0.2161574035147394, 'dropout_rate_Layer_3': 0.018047902424369537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002570924536954871, 'l1_Layer_2': 0.0007931561319057928, 'l1_Layer_3': 0.01286249240050844, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 36.92% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.44 | sMAPE for Test Set is: 29.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:38:32,355]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:38:42,799]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:39:11,249]\u001b[0m Trial 1116 finished with value: 8.458803345304235 and parameters: {'n_hidden': 3, 'learning_rate': 0.015572949541811239, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1980200733611875, 'dropout_rate_Layer_2': 0.37994172979616203, 'dropout_rate_Layer_3': 0.3602758886429665, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012941801986402325, 'l1_Layer_2': 1.2852519363993052e-05, 'l1_Layer_3': 0.0006431307175480871, 'n_units_Layer_1': 205, 'n_units_Layer_2': 70, 'n_units_Layer_3': 280}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 39.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 31.74% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:40:07,206]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:17,404]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:27,699]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:40:33,090]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:41:21,253]\u001b[0m Trial 1121 finished with value: 8.431008060298508 and parameters: {'n_hidden': 3, 'learning_rate': 0.002761017646044864, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008310037239767164, 'dropout_rate_Layer_2': 0.21201560876890085, 'dropout_rate_Layer_3': 0.009031165248480053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000184360622525334, 'l1_Layer_2': 0.0004793357259076395, 'l1_Layer_3': 0.027491341184871114, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.43 | sMAPE for Validation Set is: 37.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.44 | sMAPE for Test Set is: 29.47% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:41:44,211]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:34,057]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:44,953]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:42:50,217]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:48,301]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:43:59,237]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:09,987]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:44:15,495]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:14,137]\u001b[0m Trial 1130 finished with value: 8.482460473121153 and parameters: {'n_hidden': 3, 'learning_rate': 0.00258226956462154, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01635847200507363, 'dropout_rate_Layer_2': 0.22654414182666277, 'dropout_rate_Layer_3': 0.03549994326856746, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017941515940035792, 'l1_Layer_2': 0.001052950023580587, 'l1_Layer_3': 0.013920018700532524, 'n_units_Layer_1': 85, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 37.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.06 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:45:36,458]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:45:57,779]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:46:09,035]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:47:00,868]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:00,805]\u001b[0m Trial 1135 finished with value: 8.219596734540596 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032815631998519977, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00015833425046913522, 'dropout_rate_Layer_2': 0.20778897261779633, 'dropout_rate_Layer_3': 0.012581352367397465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031240448076455155, 'l1_Layer_2': 0.00044511051336634957, 'l1_Layer_3': 0.017147925750847035, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.22 | sMAPE for Validation Set is: 36.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 19.15 | sMAPE for Test Set is: 27.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:48:22,242]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:33,481]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:40,749]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:46,196]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:51,689]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:48:57,163]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:49:13,223]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:50:04,988]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:51:04,243]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:20,440]\u001b[0m Trial 1145 finished with value: 8.327471284401451 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032912933764637623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 3.995221593736109e-06, 'dropout_rate_Layer_2': 0.2214388707644911, 'dropout_rate_Layer_3': 0.015197480986084075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003093116468582706, 'l1_Layer_2': 0.0005572062100626517, 'l1_Layer_3': 0.013693134815433293, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.33 | sMAPE for Validation Set is: 39.21% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 18.91 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:52:31,387]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:52:42,678]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 36.98% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.53 | sMAPE for Test Set is: 28.77% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:54:12,025]\u001b[0m Trial 1148 finished with value: 8.357487990716706 and parameters: {'n_hidden': 3, 'learning_rate': 0.002955093429283463, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008447766743263698, 'dropout_rate_Layer_2': 0.22480550925210796, 'dropout_rate_Layer_3': 0.018183565500256342, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002280797007489959, 'l1_Layer_2': 0.0005887699449314965, 'l1_Layer_3': 0.013949578954158678, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:22,859]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:28,460]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:39,081]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:54:45,528]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:35,166]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:43,041]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:55:48,419]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:56:11,998]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:41,048]\u001b[0m Trial 1157 finished with value: 8.622135492579575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017038940760886738, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10805454862442973, 'dropout_rate_Layer_2': 0.2063095269556606, 'dropout_rate_Layer_3': 0.24073347757583613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.584930662425719e-05, 'l1_Layer_2': 1.0037518353372096e-05, 'l1_Layer_3': 0.00335957279355455, 'n_units_Layer_1': 295, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 39.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 19.77 | sMAPE for Test Set is: 28.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 20:59:46,379]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 20:59:54,365]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:00:19,542]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:02:40,575]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:06:46,221]\u001b[0m Trial 1162 finished with value: 8.636104546405424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017658747298931554, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09235581164706724, 'dropout_rate_Layer_2': 0.21229020807684748, 'dropout_rate_Layer_3': 0.24045368220874358, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035438842629506925, 'l1_Layer_2': 1.3234958345689148e-05, 'l1_Layer_3': 0.004488007102788989, 'n_units_Layer_1': 295, 'n_units_Layer_2': 250, 'n_units_Layer_3': 215}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 39.68% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:09:10,844]\u001b[0m Trial 1163 finished with value: 8.61874083027977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015182963207993872, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06656996814465281, 'dropout_rate_Layer_2': 0.21568287123347923, 'dropout_rate_Layer_3': 0.2667490131626319, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003488598661821112, 'l1_Layer_2': 1.0009314339089789e-05, 'l1_Layer_3': 0.004610159630852122, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 230}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 40.38% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 28.53 | sMAPE for Test Set is: 38.39% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:09:16,238]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:09:55,886]\u001b[0m Trial 1165 finished with value: 8.576347440501939 and parameters: {'n_hidden': 3, 'learning_rate': 0.00394496593628156, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010141687214416788, 'dropout_rate_Layer_2': 0.21173125030049098, 'dropout_rate_Layer_3': 0.008316121778772619, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002313750330471044, 'l1_Layer_2': 0.0008162469638150764, 'l1_Layer_3': 0.012071579897620654, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 38.60% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.15 | sMAPE for Test Set is: 29.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:10:01,251]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:10:06,644]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:10:17,680]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:10:28,936]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:10:38,489]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:10:49,046]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:11:01,206]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:11:22,007]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:11:27,968]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:11:33,167]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:11:54,714]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:12:16,765]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:12:22,134]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:12:57,545]\u001b[0m Trial 1179 finished with value: 8.444190213830524 and parameters: {'n_hidden': 3, 'learning_rate': 0.012096112166747282, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1661293076146601, 'dropout_rate_Layer_2': 0.3548389438947373, 'dropout_rate_Layer_3': 0.34033896884954284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002183813918430611, 'l1_Layer_2': 2.4033842778768358e-05, 'l1_Layer_3': 0.0014461354927652998, 'n_units_Layer_1': 175, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 38.58% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.24 | sMAPE for Test Set is: 31.30% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:13:09,417]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:13:16,272]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:13:40,637]\u001b[0m Trial 1182 finished with value: 8.442187612465858 and parameters: {'n_hidden': 3, 'learning_rate': 0.012396029667999726, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16995127409429198, 'dropout_rate_Layer_2': 0.33868722386241157, 'dropout_rate_Layer_3': 0.3421061155103812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.140067339218552e-05, 'l1_Layer_2': 1.8594609444471504e-05, 'l1_Layer_3': 0.0015829905705054472, 'n_units_Layer_1': 170, 'n_units_Layer_2': 50, 'n_units_Layer_3': 175}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 39.95% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 23.58 | sMAPE for Test Set is: 32.70% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:14:33,468]\u001b[0m Trial 1183 finished with value: 8.411180176281801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027156792723519933, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008621793491840675, 'dropout_rate_Layer_2': 0.21482371649823281, 'dropout_rate_Layer_3': 0.02213971948067251, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000173141530666913, 'l1_Layer_2': 0.000585356188900002, 'l1_Layer_3': 0.018124421287526848, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 37.45% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.06 | sMAPE for Test Set is: 29.30% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:14:38,805]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:14:46,164]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:15:07,708]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:15:31,044]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:15:37,398]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:15:42,556]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:15:48,348]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:16:30,184]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:16:35,631]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:16:46,104]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:16:51,477]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:17:04,574]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:17:25,950]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:18:19,946]\u001b[0m Trial 1197 finished with value: 8.512464693004375 and parameters: {'n_hidden': 3, 'learning_rate': 0.003927724086615688, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007671889651540222, 'dropout_rate_Layer_2': 0.19755247500631848, 'dropout_rate_Layer_3': 0.05085946987794582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016242580325081745, 'l1_Layer_2': 0.000903720817601702, 'l1_Layer_3': 0.03196748418891528, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 37.61% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.73 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:18:43,830]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:19:06,831]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:19:30,119]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:20:30,297]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:21:45,942]\u001b[0m Trial 1202 finished with value: 8.472115689572519 and parameters: {'n_hidden': 3, 'learning_rate': 0.002748395050474168, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006031651673775056, 'dropout_rate_Layer_2': 0.1563891186835848, 'dropout_rate_Layer_3': 0.009900186684133247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015090281225589288, 'l1_Layer_2': 0.0011683506675027387, 'l1_Layer_3': 0.01060406448606215, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 38.15% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 29.53% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:22:39,600]\u001b[0m Trial 1203 finished with value: 8.461313650391395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035847838498712196, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0138429032028091, 'dropout_rate_Layer_2': 0.19063686894096835, 'dropout_rate_Layer_3': 0.03502499687377549, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002342297923130617, 'l1_Layer_2': 0.0006844840080336266, 'l1_Layer_3': 0.009322040202537135, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 37.73% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 29.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:22:45,091]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:23:06,433]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:23:11,748]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:23:18,988]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:24:04,214]\u001b[0m Trial 1208 finished with value: 8.615420919831916 and parameters: {'n_hidden': 3, 'learning_rate': 0.004893507513551698, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 8.89907597942663e-05, 'dropout_rate_Layer_2': 0.1580098349138138, 'dropout_rate_Layer_3': 0.028388957519334183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003228095072356786, 'l1_Layer_2': 0.0008257007226471733, 'l1_Layer_3': 0.011390963753579607, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 37.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.27 | sMAPE for Test Set is: 29.08% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:24:15,020]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:25:07,993]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:25:15,550]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:25:21,479]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:25:32,401]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:25:55,950]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:27:19,147]\u001b[0m Trial 1215 finished with value: 8.233687736432145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028628913992790397, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014821212270864878, 'dropout_rate_Layer_2': 0.21063245944921918, 'dropout_rate_Layer_3': 0.0198486404105926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002437325188469153, 'l1_Layer_2': 0.0006969917909757349, 'l1_Layer_3': 0.016322932353629496, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.23 | sMAPE for Validation Set is: 37.48% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 21.05 | sMAPE for Test Set is: 31.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:27:23,984]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:27:30,416]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:27:52,650]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:27:58,361]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:28:08,511]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:28:16,075]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:28:29,628]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:28:36,361]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:28:42,793]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:28:53,369]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:30:14,145]\u001b[0m Trial 1226 finished with value: 8.271915431555046 and parameters: {'n_hidden': 3, 'learning_rate': 0.002795021105488085, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0006007403703277552, 'dropout_rate_Layer_2': 0.20504512615973813, 'dropout_rate_Layer_3': 0.022578927287771104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002894487963769101, 'l1_Layer_2': 0.0007251759937776316, 'l1_Layer_3': 0.011620155063824245, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.27 | sMAPE for Validation Set is: 37.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.03 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:30:38,677]\u001b[0m Trial 1227 finished with value: 8.303085611188644 and parameters: {'n_hidden': 3, 'learning_rate': 0.010442653349063863, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13651418763113166, 'dropout_rate_Layer_2': 0.32226412304352503, 'dropout_rate_Layer_3': 0.3187545032622439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.2563254974053804e-05, 'l1_Layer_2': 1.2096020249439486e-05, 'l1_Layer_3': 0.0008538873770237246, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 195}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 38.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.74 | sMAPE for Test Set is: 32.81% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:30:46,644]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:31:01,842]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:31:12,599]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:31:17,373]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:31:29,465]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:34:06,651]\u001b[0m Trial 1233 finished with value: 8.691444806167812 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030000513890802234, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09388083047492887, 'dropout_rate_Layer_2': 0.23043482023208595, 'dropout_rate_Layer_3': 0.2790202383001746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013758125915443607, 'l1_Layer_2': 7.91903108253038e-05, 'l1_Layer_3': 0.0064588410012132716, 'n_units_Layer_1': 275, 'n_units_Layer_2': 275, 'n_units_Layer_3': 220}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.69 | sMAPE for Validation Set is: 41.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 20.27 | sMAPE for Test Set is: 29.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:34:11,575]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:34:16,984]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:35:16,369]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:35:40,044]\u001b[0m Trial 1237 finished with value: 9.147436086279214 and parameters: {'n_hidden': 4, 'learning_rate': 0.005701655863808937, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23073686977178454, 'dropout_rate_Layer_2': 0.21983339596172258, 'dropout_rate_Layer_3': 0.2321029978742455, 'dropout_rate_Layer_4': 0.26174984554131914, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020451586162857592, 'l1_Layer_2': 0.004664694334143679, 'l1_Layer_3': 0.006053271231074365, 'l1_Layer_4': 1.5718319480976055e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295, 'n_units_Layer_4': 110}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.15 | sMAPE for Validation Set is: 40.51% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 20.80 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:35:47,108]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:35:53,810]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:36:46,412]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:36:51,580]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:37:18,553]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:37:29,300]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:39:55,715]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:40:16,298]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:40:38,614]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:40:49,977]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:42:09,541]\u001b[0m Trial 1248 finished with value: 8.237022440738166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023507128281144538, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018614308202730242, 'dropout_rate_Layer_2': 0.2096320251907802, 'dropout_rate_Layer_3': 0.006706711009172962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013340322241047647, 'l1_Layer_2': 0.0006411306644325661, 'l1_Layer_3': 0.027622021419878028, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 55}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 37.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 20.46 | sMAPE for Test Set is: 30.47% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:42:31,673]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:42:42,020]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:42:55,424]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:43:00,772]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:43:12,244]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:44:10,394]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:44:17,690]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:44:28,787]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:44:34,188]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:44:39,163]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:44:53,638]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:45:00,433]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:46:22,522]\u001b[0m Trial 1261 finished with value: 8.362201282623861 and parameters: {'n_hidden': 3, 'learning_rate': 0.002872317972830853, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014605746624232464, 'dropout_rate_Layer_2': 0.15178421986297091, 'dropout_rate_Layer_3': 0.008104872532332122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003592556306005701, 'l1_Layer_2': 0.0007598259932396101, 'l1_Layer_3': 0.04326911640265312, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 38.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.42 | sMAPE for Test Set is: 28.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:46:49,915]\u001b[0m Trial 1262 finished with value: 8.558896917733696 and parameters: {'n_hidden': 3, 'learning_rate': 0.006586470632786039, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10479626214303045, 'dropout_rate_Layer_2': 0.37115189870124776, 'dropout_rate_Layer_3': 0.2913608358898463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.912271583193564e-05, 'l1_Layer_2': 1.4564617414920825e-05, 'l1_Layer_3': 0.0004470771030110044, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.56 | sMAPE for Validation Set is: 40.23% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.01 | sMAPE for Test Set is: 30.70% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:46:55,004]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:47:06,800]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:49:35,226]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:49:40,938]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:49:50,127]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:49:56,405]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:50:01,630]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:50:12,382]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:50:23,545]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:50:49,677]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:51:00,411]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:51:14,529]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:51:19,852]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:51:40,563]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:52:03,836]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:52:14,858]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:52:22,372]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:53:43,439]\u001b[0m Trial 1280 finished with value: 8.383889164997951 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026209213500592706, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03518829591011641, 'dropout_rate_Layer_2': 0.21988973011639165, 'dropout_rate_Layer_3': 0.015474490504356855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017859692302268646, 'l1_Layer_2': 0.0004868623430007924, 'l1_Layer_3': 0.006024235576130634, 'n_units_Layer_1': 100, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.38 | sMAPE for Validation Set is: 38.43% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:55:05,550]\u001b[0m Trial 1281 finished with value: 8.337948113240737 and parameters: {'n_hidden': 3, 'learning_rate': 0.002323752193382581, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01783973896845547, 'dropout_rate_Layer_2': 0.2308816805112004, 'dropout_rate_Layer_3': 0.030155397269678454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.007883484520916e-05, 'l1_Layer_2': 0.0008021802069201529, 'l1_Layer_3': 0.01252756561838901, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 65}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 37.98% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.20 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:55:10,798]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:56:09,609]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:56:31,442]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:56:37,986]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:56:43,233]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:56:50,324]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:56:55,959]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:57:03,485]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:57:54,405]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:58:16,250]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:58:27,249]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:58:38,454]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:58:44,039]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:58:55,441]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:59:01,680]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 21:59:39,860]\u001b[0m Trial 1297 finished with value: 8.483322702145953 and parameters: {'n_hidden': 3, 'learning_rate': 0.010894350723930031, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17006079313231603, 'dropout_rate_Layer_2': 0.35012873919178605, 'dropout_rate_Layer_3': 0.32306143331823006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9607890516558384e-05, 'l1_Layer_2': 1.972792668412196e-05, 'l1_Layer_3': 0.0007872006097927628, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 215}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 40.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.81 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 21:59:46,343]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:01:10,518]\u001b[0m Trial 1299 finished with value: 8.316996515407647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029133460113800152, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 5.62112833681785e-06, 'dropout_rate_Layer_2': 0.22302974092322783, 'dropout_rate_Layer_3': 0.007615754958830295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.142421776648253e-05, 'l1_Layer_2': 0.0006883737243006323, 'l1_Layer_3': 0.014989204400660735, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 38.45% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.34 | sMAPE for Test Set is: 30.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:01:17,458]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:01:22,895]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:02:38,549]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:02:50,290]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:02:56,708]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:03:07,047]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:03:17,904]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:03:37,876]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:03:49,525]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:03:55,574]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:04:19,953]\u001b[0m Trial 1310 finished with value: 8.505763408815767 and parameters: {'n_hidden': 3, 'learning_rate': 0.014275732723078784, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14335375423427146, 'dropout_rate_Layer_2': 0.3647816575887076, 'dropout_rate_Layer_3': 0.33778578427141737, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.004386584439371e-05, 'l1_Layer_2': 1.1156210355057657e-05, 'l1_Layer_3': 0.0005361587536849017, 'n_units_Layer_1': 180, 'n_units_Layer_2': 60, 'n_units_Layer_3': 185}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.51 | sMAPE for Validation Set is: 39.91% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.33 | sMAPE for Test Set is: 30.36% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:04:29,769]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:04:35,128]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:05:16,285]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:05:22,156]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:05:27,494]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:05:46,709]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:06:27,880]\u001b[0m Trial 1317 finished with value: 8.868168105613941 and parameters: {'n_hidden': 3, 'learning_rate': 0.00300009487567866, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00022593149514365043, 'dropout_rate_Layer_2': 0.15566349213817965, 'dropout_rate_Layer_3': 0.3253885932277967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9255236262231682e-05, 'l1_Layer_2': 0.0010520558440289957, 'l1_Layer_3': 0.0308398379414503, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 60}. Best is trial 1045 with value: 8.209372054931181.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 39.06% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 19.94 | sMAPE for Test Set is: 29.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:06:39,302]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:06:50,822]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:07:02,003]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:07:07,537]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:08:13,253]\u001b[0m Trial 1322 finished with value: 8.193906719931984 and parameters: {'n_hidden': 3, 'learning_rate': 0.00311776003531551, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 2.0655090709719316e-05, 'dropout_rate_Layer_2': 0.2301364725170176, 'dropout_rate_Layer_3': 0.049420418661600324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1110699546204987e-05, 'l1_Layer_2': 0.0008619577537623179, 'l1_Layer_3': 0.011443242425697702, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 36.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:08:18,772]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:08:23,873]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:08:34,667]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:08:39,823]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:08:45,412]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:09:08,526]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:09:19,958]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:09:30,452]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:09:39,693]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:12:03,797]\u001b[0m Trial 1332 finished with value: 8.74713947059841 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021926181919151434, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08893900013492471, 'dropout_rate_Layer_2': 0.2059824477279908, 'dropout_rate_Layer_3': 0.26652151033281624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00026358055964994376, 'l1_Layer_2': 1.21957517381272e-05, 'l1_Layer_3': 0.0022629869209550096, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.75 | sMAPE for Validation Set is: 41.54% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 28.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:12:54,925]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:13:01,299]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:13:11,547]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:13:16,260]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:13:34,618]\u001b[0m Trial 1337 finished with value: 8.552501706205371 and parameters: {'n_hidden': 3, 'learning_rate': 0.01804902608778217, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1803684023308992, 'dropout_rate_Layer_2': 0.3307221329892096, 'dropout_rate_Layer_3': 0.3157836893577117, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014481141182299376, 'l1_Layer_2': 1.4409472651477122e-05, 'l1_Layer_3': 0.0012260078373604116, 'n_units_Layer_1': 190, 'n_units_Layer_2': 70, 'n_units_Layer_3': 200}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.55 | sMAPE for Validation Set is: 40.33% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.91 | sMAPE for Test Set is: 31.46% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:13:57,117]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:14:51,673]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:14:59,042]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:15:04,420]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:15:14,459]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:15:20,326]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:15:43,398]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:15:57,831]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:16:03,172]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:16:08,717]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:16:30,824]\u001b[0m Trial 1348 finished with value: 8.492595600718243 and parameters: {'n_hidden': 3, 'learning_rate': 0.026032256573874365, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20311511918939318, 'dropout_rate_Layer_2': 0.37974932033919273, 'dropout_rate_Layer_3': 0.35553927976092164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.84892400513715e-05, 'l1_Layer_2': 1.8116583794016246e-05, 'l1_Layer_3': 0.00035020881220988563, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 230}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 40.03% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 24.34 | sMAPE for Test Set is: 33.04% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:16:41,075]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:16:52,100]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:17:02,066]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:17:07,556]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:17:18,416]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:17:25,370]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:17:35,398]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:18:14,218]\u001b[0m Trial 1356 finished with value: 8.528830970889624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038451120697768704, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02133484304554442, 'dropout_rate_Layer_2': 0.2246927287262922, 'dropout_rate_Layer_3': 0.049526318975631346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.358140765161136e-05, 'l1_Layer_2': 0.00045099836146950063, 'l1_Layer_3': 0.040417422416297144, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 60}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.53 | sMAPE for Validation Set is: 37.36% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 20.82 | sMAPE for Test Set is: 29.92% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:18:19,576]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:18:25,479]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:18:31,030]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:18:38,225]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:18:43,671]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:18:49,188]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:19:01,843]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:19:16,849]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:19:27,700]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:19:46,008]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:19:51,913]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:20:00,740]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:20:05,405]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:20:18,568]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:20:29,290]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:20:35,633]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:21:11,643]\u001b[0m Trial 1373 finished with value: 8.251279929318052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031761446235095032, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032691065347764184, 'dropout_rate_Layer_2': 0.21410838303520685, 'dropout_rate_Layer_3': 0.007034864038124789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5767168361273367e-05, 'l1_Layer_2': 0.0008553178742610405, 'l1_Layer_3': 0.002019652383783805, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 37.91% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 28.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:21:19,011]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:21:30,250]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:22:15,267]\u001b[0m Trial 1376 finished with value: 8.251047868706777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032421538213317333, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03364027045238134, 'dropout_rate_Layer_2': 0.22700225020692427, 'dropout_rate_Layer_3': 0.004145545811964553, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6567141198287866e-05, 'l1_Layer_2': 0.0013830009146121695, 'l1_Layer_3': 0.0020240266468854766, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 70}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 38.13% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 29.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:22:52,565]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:23:13,424]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:23:19,689]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:23:31,504]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:27:05,238]\u001b[0m Trial 1381 finished with value: 8.57185173897773 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026221426713863385, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1057510056948196, 'dropout_rate_Layer_2': 0.19231668894240403, 'dropout_rate_Layer_3': 0.24787371090629037, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000337784150666182, 'l1_Layer_2': 2.336649527469053e-05, 'l1_Layer_3': 0.0012326878422525517, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 38.90% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.55 | sMAPE for Test Set is: 30.20% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:27:10,068]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:27:14,913]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:31:18,315]\u001b[0m Trial 1384 finished with value: 8.581285864808768 and parameters: {'n_hidden': 3, 'learning_rate': 0.003328722837343331, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10702302979926316, 'dropout_rate_Layer_2': 0.1931428008091138, 'dropout_rate_Layer_3': 0.24709839645819903, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002773063971337776, 'l1_Layer_2': 2.1736545883626587e-05, 'l1_Layer_3': 0.0012512191313733194, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.58 | sMAPE for Validation Set is: 40.67% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.90 | sMAPE for Test Set is: 31.03% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:31:37,275]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:31:42,383]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:32:19,275]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:32:24,065]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:33:00,882]\u001b[0m Trial 1389 finished with value: 8.39985490933206 and parameters: {'n_hidden': 3, 'learning_rate': 0.002259693822424796, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035225312736876686, 'dropout_rate_Layer_2': 0.22525353811967225, 'dropout_rate_Layer_3': 0.03872932316469867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5918300423481277e-05, 'l1_Layer_2': 0.0009194484333577772, 'l1_Layer_3': 0.005163553902026482, 'n_units_Layer_1': 105, 'n_units_Layer_2': 135, 'n_units_Layer_3': 65}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.40 | sMAPE for Validation Set is: 37.00% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:33:55,340]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:34:01,198]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:34:22,995]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:34:50,884]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:34:59,388]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:35:04,671]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:35:09,742]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:35:14,732]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:35:21,357]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:35:27,330]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:36:08,054]\u001b[0m Trial 1400 finished with value: 8.3364058784493 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031820812022362675, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008688546121835396, 'dropout_rate_Layer_2': 0.2432042607230326, 'dropout_rate_Layer_3': 0.019964991921025247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4271142452985454e-05, 'l1_Layer_2': 0.005110036694844299, 'l1_Layer_3': 0.0019615442463003048, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 37.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:36:13,241]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:36:25,606]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:36:31,601]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:36:41,620]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:37:11,582]\u001b[0m Trial 1405 finished with value: 8.393052049357108 and parameters: {'n_hidden': 3, 'learning_rate': 0.004012109728626097, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0002305538691436352, 'dropout_rate_Layer_2': 0.38114796535960355, 'dropout_rate_Layer_3': 4.073891069938593e-06, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2500361311101884e-05, 'l1_Layer_2': 0.0032217402048956914, 'l1_Layer_3': 0.0014634300946615934, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 55}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.39 | sMAPE for Validation Set is: 37.57% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.51 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:37:17,911]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:37:23,091]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:37:28,491]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:37:55,529]\u001b[0m Trial 1409 finished with value: 8.339683732846156 and parameters: {'n_hidden': 3, 'learning_rate': 0.012139088261729306, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16522409055839538, 'dropout_rate_Layer_2': 0.35576910221999863, 'dropout_rate_Layer_3': 0.34057543875104634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019518297363390298, 'l1_Layer_2': 1.6069598839540345e-05, 'l1_Layer_3': 0.0015235825847017101, 'n_units_Layer_1': 155, 'n_units_Layer_2': 60, 'n_units_Layer_3': 175}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 38.34% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 30.90% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:38:01,748]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:38:34,610]\u001b[0m Trial 1411 finished with value: 8.437880825441722 and parameters: {'n_hidden': 3, 'learning_rate': 0.010405503200837501, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13109245257541832, 'dropout_rate_Layer_2': 0.36294815355667864, 'dropout_rate_Layer_3': 0.3187541858210321, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012836534596639049, 'l1_Layer_2': 1.5459246587701313e-05, 'l1_Layer_3': 0.0007171283891966015, 'n_units_Layer_1': 135, 'n_units_Layer_2': 65, 'n_units_Layer_3': 175}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.44 | sMAPE for Validation Set is: 39.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 30.55% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:38:40,113]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:39:03,614]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:39:15,399]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:39:21,472]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:39:26,833]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:39:32,130]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:39:44,643]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:42:12,619]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:42:22,783]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:42:33,994]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:42:39,493]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:43:23,272]\u001b[0m Trial 1423 finished with value: 8.486597746821777 and parameters: {'n_hidden': 3, 'learning_rate': 0.010724823922006075, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13710632929133978, 'dropout_rate_Layer_2': 0.3635404597529673, 'dropout_rate_Layer_3': 0.31893085202902866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001297563647522073, 'l1_Layer_2': 1.501999991875996e-05, 'l1_Layer_3': 0.0006998248885905101, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 39.35% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.14 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:43:34,526]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:44:02,448]\u001b[0m Trial 1425 finished with value: 8.80103194018454 and parameters: {'n_hidden': 3, 'learning_rate': 0.008426695455958646, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1266778388872424, 'dropout_rate_Layer_2': 0.34361605908023407, 'dropout_rate_Layer_3': 0.3452296288886499, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.517238812410401e-05, 'l1_Layer_2': 1.711878308112844e-05, 'l1_Layer_3': 0.0011104102559185006, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.80 | sMAPE for Validation Set is: 40.04% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.79 | sMAPE for Test Set is: 30.99% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:44:13,005]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:44:27,229]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:47:19,253]\u001b[0m Trial 1428 finished with value: 8.789764766205542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028215416695636327, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1427272853335292, 'dropout_rate_Layer_2': 0.17751533341930423, 'dropout_rate_Layer_3': 0.2367076658931285, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004872600307480624, 'l1_Layer_2': 1.0011234317386282e-05, 'l1_Layer_3': 0.0015377463516757768, 'n_units_Layer_1': 265, 'n_units_Layer_2': 245, 'n_units_Layer_3': 225}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.79 | sMAPE for Validation Set is: 40.62% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 21.10 | sMAPE for Test Set is: 29.90% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:47:30,449]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:47:35,646]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:47:43,980]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:47:55,825]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:48:21,979]\u001b[0m Trial 1433 finished with value: 8.413464034226694 and parameters: {'n_hidden': 3, 'learning_rate': 0.009352828469098925, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16500655610787945, 'dropout_rate_Layer_2': 0.3338959710274306, 'dropout_rate_Layer_3': 0.35537174980860986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.284927352774146e-05, 'l1_Layer_2': 2.020104760395865e-05, 'l1_Layer_3': 0.000314876468447784, 'n_units_Layer_1': 115, 'n_units_Layer_2': 55, 'n_units_Layer_3': 155}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.41 | sMAPE for Validation Set is: 40.56% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.29 | sMAPE for Test Set is: 30.34% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:48:28,052]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:48:50,840]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:48:57,385]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:51:23,996]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:53:51,315]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:54:14,907]\u001b[0m Trial 1439 finished with value: 8.297138779434267 and parameters: {'n_hidden': 3, 'learning_rate': 0.009257953162863555, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15533687302363475, 'dropout_rate_Layer_2': 0.31676779296432356, 'dropout_rate_Layer_3': 0.35485430643306703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026599325007561035, 'l1_Layer_2': 1.2051472369719026e-05, 'l1_Layer_3': 0.00027292558519538307, 'n_units_Layer_1': 125, 'n_units_Layer_2': 205, 'n_units_Layer_3': 155}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 38.16% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.39 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:55:01,056]\u001b[0m Trial 1440 finished with value: 8.356994420413548 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022210476548521325, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009832248035545851, 'dropout_rate_Layer_2': 0.1876227041052671, 'dropout_rate_Layer_3': 0.13783306460649042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.002610090607525e-05, 'l1_Layer_2': 0.0010147825451893723, 'l1_Layer_3': 0.0007158236573210451, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.36 | sMAPE for Validation Set is: 38.55% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 28.90% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:55:11,614]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:55:34,006]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:55:41,183]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:55:54,236]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:55:59,676]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:56:06,604]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:56:11,818]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:56:23,023]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:56:46,397]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:57:37,048]\u001b[0m Trial 1450 finished with value: 8.458527802354281 and parameters: {'n_hidden': 3, 'learning_rate': 0.003060522566395994, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3586299472865105, 'dropout_rate_Layer_2': 0.15392296325762744, 'dropout_rate_Layer_3': 8.064181929467659e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2712618520110542e-05, 'l1_Layer_2': 0.00013307879393872706, 'l1_Layer_3': 0.004262197948502483, 'n_units_Layer_1': 105, 'n_units_Layer_2': 120, 'n_units_Layer_3': 60}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.46 | sMAPE for Validation Set is: 37.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:57:42,204]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:58:05,897]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:58:30,212]\u001b[0m Trial 1453 finished with value: 8.380755650306064 and parameters: {'n_hidden': 3, 'learning_rate': 0.009592502717782217, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1592880011352219, 'dropout_rate_Layer_2': 0.31754356532186245, 'dropout_rate_Layer_3': 0.3827788230686756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002797628300117641, 'l1_Layer_2': 1.0043094537718872e-05, 'l1_Layer_3': 0.0002594010160315455, 'n_units_Layer_1': 120, 'n_units_Layer_2': 205, 'n_units_Layer_3': 160}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.38 | sMAPE for Validation Set is: 38.67% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 20.51 | sMAPE for Test Set is: 29.32% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:58:35,675]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:58:47,104]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:59:15,351]\u001b[0m Trial 1456 finished with value: 8.296728688291305 and parameters: {'n_hidden': 3, 'learning_rate': 0.001233951150223551, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022226474526134965, 'dropout_rate_Layer_2': 0.2092039272119597, 'dropout_rate_Layer_3': 0.007775225522714762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028829548830169475, 'l1_Layer_2': 0.00020557502061596783, 'l1_Layer_3': 2.7852670893316948e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 70}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.30 | sMAPE for Validation Set is: 38.54% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 19.65 | sMAPE for Test Set is: 29.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 22:59:39,252]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:59:50,327]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 22:59:57,285]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:00:04,346]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:01:03,346]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:01:25,122]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:01:35,908]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:01:43,029]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:01:50,231]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:01:57,398]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:02:10,304]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:02:15,681]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:02:21,283]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:02:59,528]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:03:22,093]\u001b[0m Trial 1471 finished with value: 8.336324225569225 and parameters: {'n_hidden': 3, 'learning_rate': 0.008855610162193436, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15810895986166673, 'dropout_rate_Layer_2': 0.30070020181584445, 'dropout_rate_Layer_3': 0.3849832112567323, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026802234796717816, 'l1_Layer_2': 1.0019268571725967e-05, 'l1_Layer_3': 0.0002620942085894734, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 145}. Best is trial 1322 with value: 8.193906719931984.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.34 | sMAPE for Validation Set is: 39.51% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 21.30 | sMAPE for Test Set is: 29.92% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:03:29,703]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:03:35,436]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:03:47,634]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:03:54,463]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:04:51,112]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:05:02,427]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:05:09,832]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:05:16,317]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:05:30,841]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:05:36,031]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:06:23,966]\u001b[0m Trial 1482 finished with value: 8.095488816517973 and parameters: {'n_hidden': 3, 'learning_rate': 0.008673678128637688, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15790563474469174, 'dropout_rate_Layer_2': 0.2869212212205032, 'dropout_rate_Layer_3': 0.3849707273010388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041407664943976427, 'l1_Layer_2': 1.0277324373617852e-05, 'l1_Layer_3': 0.0002690224199540282, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145}. Best is trial 1482 with value: 8.095488816517973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.10 | sMAPE for Validation Set is: 36.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 19.66 | sMAPE for Test Set is: 28.21% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:06:29,995]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:06:41,541]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:06:48,335]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:06:53,832]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:09:18,227]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:09:23,257]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:09:29,023]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:10:28,038]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:10:38,883]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:11:13,204]\u001b[0m Trial 1492 finished with value: 8.321595055483897 and parameters: {'n_hidden': 3, 'learning_rate': 0.006286294675834128, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1603659094906221, 'dropout_rate_Layer_2': 0.3014952903321588, 'dropout_rate_Layer_3': 0.3770624960908299, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000291251286567269, 'l1_Layer_2': 1.1609560091225459e-05, 'l1_Layer_3': 0.00024922363873424385, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145}. Best is trial 1482 with value: 8.095488816517973.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 39.13% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.15 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-27 23:11:20,139]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:11:27,487]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:11:47,898]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:14:12,011]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:14:17,099]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:14:27,539]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-27 23:14:38,353]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-01-01, MAE is:4.95 & sMAPE is:21.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.95 & 21.86% & 0.64\n",
      "for 2021-01-02, MAE is:6.72 & sMAPE is:18.39% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :5.84 & 20.12% & 0.83\n",
      "for 2021-01-03, MAE is:2.20 & sMAPE is:7.87% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 16.04% & 0.59\n",
      "for 2021-01-04, MAE is:10.98 & sMAPE is:25.67% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 18.45% & 0.61\n",
      "for 2021-01-05, MAE is:5.13 & sMAPE is:10.53% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.86% & 0.56\n",
      "for 2021-01-06, MAE is:6.02 & sMAPE is:14.46% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 16.46% & 0.57\n",
      "for 2021-01-07, MAE is:25.85 & sMAPE is:45.47% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 20.61% & 0.60\n",
      "for 2021-01-08, MAE is:18.47 & sMAPE is:23.06% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 20.91% & 0.57\n",
      "for 2021-01-09, MAE is:3.82 & sMAPE is:7.03% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 19.37% & 0.53\n",
      "for 2021-01-10, MAE is:3.37 & sMAPE is:8.09% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 18.24% & 0.49\n",
      "for 2021-01-11, MAE is:6.47 & sMAPE is:15.35% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 17.98% & 0.51\n",
      "for 2021-01-12, MAE is:9.89 & sMAPE is:24.46% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 18.52% & 0.62\n",
      "for 2021-01-13, MAE is:5.77 & sMAPE is:10.88% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 17.93% & 0.61\n",
      "for 2021-01-14, MAE is:20.16 & sMAPE is:27.42% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 18.61% & 0.72\n",
      "for 2021-01-15, MAE is:9.05 & sMAPE is:11.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 18.12% & 0.72\n",
      "for 2021-01-16, MAE is:7.80 & sMAPE is:12.24% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 17.75% & 0.74\n",
      "for 2021-01-17, MAE is:4.44 & sMAPE is:7.99% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 17.18% & 0.72\n",
      "for 2021-01-18, MAE is:7.98 & sMAPE is:13.16% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.84 & 16.96% & 0.70\n",
      "for 2021-01-19, MAE is:10.98 & sMAPE is:19.81% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 17.11% & 0.70\n",
      "for 2021-01-20, MAE is:13.83 & sMAPE is:27.28% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 17.61% & 0.72\n",
      "for 2021-01-21, MAE is:6.91 & sMAPE is:18.50% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.09 & 17.66% & 0.70\n",
      "for 2021-01-22, MAE is:10.53 & sMAPE is:33.31% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 18.37% & 0.68\n",
      "for 2021-01-23, MAE is:8.05 & sMAPE is:20.99% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.10 & 18.48% & 0.66\n",
      "for 2021-01-24, MAE is:10.05 & sMAPE is:22.11% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.14 & 18.63% & 0.71\n",
      "for 2021-01-25, MAE is:9.56 & sMAPE is:16.60% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 18.55% & 0.77\n",
      "for 2021-01-26, MAE is:10.13 & sMAPE is:17.81% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 18.52% & 0.80\n",
      "for 2021-01-27, MAE is:4.03 & sMAPE is:7.09% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 18.10% & 0.78\n",
      "for 2021-01-28, MAE is:4.81 & sMAPE is:8.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 17.75% & 0.76\n",
      "for 2021-01-29, MAE is:4.13 & sMAPE is:7.64% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 17.40% & 0.74\n",
      "for 2021-01-30, MAE is:2.98 & sMAPE is:5.92% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 17.02% & 0.72\n",
      "for 2021-01-31, MAE is:4.12 & sMAPE is:8.06% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 16.73% & 0.78\n",
      "for 2021-02-01, MAE is:34.20 & sMAPE is:35.28% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 17.31% & 0.79\n",
      "for 2021-02-02, MAE is:14.33 & sMAPE is:18.76% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 17.36% & 0.80\n",
      "for 2021-02-03, MAE is:5.83 & sMAPE is:10.21% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 17.15% & 0.80\n",
      "for 2021-02-04, MAE is:10.47 & sMAPE is:16.79% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 17.14% & 0.82\n",
      "for 2021-02-05, MAE is:24.80 & sMAPE is:23.53% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 17.31% & 0.82\n",
      "for 2021-02-06, MAE is:10.52 & sMAPE is:20.67% & rMAE is:2.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 17.40% & 0.88\n",
      "for 2021-02-07, MAE is:3.28 & sMAPE is:7.64% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 17.15% & 0.87\n",
      "for 2021-02-08, MAE is:5.57 & sMAPE is:9.92% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 16.96% & 0.85\n",
      "for 2021-02-09, MAE is:16.06 & sMAPE is:22.64% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 17.10% & 0.86\n",
      "for 2021-02-10, MAE is:8.69 & sMAPE is:11.21% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 16.96% & 0.85\n",
      "for 2021-02-11, MAE is:34.20 & sMAPE is:30.57% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 17.28% & 0.85\n",
      "for 2021-02-12, MAE is:25.07 & sMAPE is:24.73% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 17.46% & 0.88\n",
      "for 2021-02-13, MAE is:6.19 & sMAPE is:11.08% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 17.31% & 0.88\n",
      "for 2021-02-14, MAE is:4.33 & sMAPE is:8.91% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 17.13% & 0.88\n",
      "for 2021-02-15, MAE is:13.11 & sMAPE is:15.53% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 17.09% & 0.89\n",
      "for 2021-02-16, MAE is:6.06 & sMAPE is:9.33% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 16.93% & 0.88\n",
      "for 2021-02-17, MAE is:19.44 & sMAPE is:21.41% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 17.02% & 0.89\n",
      "for 2021-02-18, MAE is:9.07 & sMAPE is:13.78% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 16.95% & 0.87\n",
      "for 2021-02-19, MAE is:9.20 & sMAPE is:15.44% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.39 & 16.92% & 0.86\n",
      "for 2021-02-20, MAE is:9.07 & sMAPE is:19.32% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 16.97% & 0.86\n",
      "for 2021-02-21, MAE is:6.81 & sMAPE is:18.37% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 17.00% & 0.86\n",
      "for 2021-02-22, MAE is:5.63 & sMAPE is:11.98% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 16.90% & 0.85\n",
      "for 2021-02-23, MAE is:7.46 & sMAPE is:15.90% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 16.88% & 0.84\n",
      "for 2021-02-24, MAE is:12.18 & sMAPE is:29.94% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 17.12% & 0.83\n",
      "for 2021-02-25, MAE is:3.42 & sMAPE is:10.30% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 17.00% & 0.82\n",
      "for 2021-02-26, MAE is:7.30 & sMAPE is:20.92% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 17.07% & 0.81\n",
      "for 2021-02-27, MAE is:1.99 & sMAPE is:6.16% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 16.88% & 0.79\n",
      "for 2021-02-28, MAE is:4.39 & sMAPE is:14.99% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 16.85% & 0.79\n",
      "for 2021-03-01, MAE is:4.39 & sMAPE is:14.26% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 16.80% & 0.79\n",
      "for 2021-03-02, MAE is:12.32 & sMAPE is:32.69% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :9.75 & 17.06% & 0.80\n",
      "for 2021-03-03, MAE is:6.09 & sMAPE is:14.88% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 17.03% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-04, MAE is:7.73 & sMAPE is:17.14% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 17.03% & 0.80\n",
      "for 2021-03-05, MAE is:9.13 & sMAPE is:17.38% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 17.04% & 0.79\n",
      "for 2021-03-06, MAE is:16.58 & sMAPE is:54.13% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.76 & 17.61% & 0.81\n",
      "for 2021-03-07, MAE is:6.35 & sMAPE is:22.53% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 17.68% & 0.81\n",
      "for 2021-03-08, MAE is:11.82 & sMAPE is:20.61% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 17.73% & 0.81\n",
      "for 2021-03-09, MAE is:6.82 & sMAPE is:12.24% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 17.64% & 0.80\n",
      "for 2021-03-10, MAE is:15.89 & sMAPE is:24.51% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 17.74% & 0.80\n",
      "for 2021-03-11, MAE is:11.67 & sMAPE is:34.97% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 17.99% & 0.81\n",
      "for 2021-03-12, MAE is:4.99 & sMAPE is:14.84% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 17.95% & 0.80\n",
      "for 2021-03-13, MAE is:3.69 & sMAPE is:12.20% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 17.87% & 0.79\n",
      "for 2021-03-14, MAE is:6.24 & sMAPE is:21.12% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 17.91% & 0.80\n",
      "for 2021-03-15, MAE is:9.41 & sMAPE is:17.63% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 17.91% & 0.81\n",
      "for 2021-03-16, MAE is:7.88 & sMAPE is:14.85% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 17.87% & 0.81\n",
      "for 2021-03-17, MAE is:5.52 & sMAPE is:10.81% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 17.77% & 0.81\n",
      "for 2021-03-18, MAE is:9.14 & sMAPE is:17.54% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 17.77% & 0.80\n",
      "for 2021-03-19, MAE is:8.72 & sMAPE is:17.39% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 17.77% & 0.80\n",
      "for 2021-03-20, MAE is:7.68 & sMAPE is:29.39% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 17.91% & 0.80\n",
      "for 2021-03-21, MAE is:3.32 & sMAPE is:16.97% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 17.90% & 0.80\n",
      "for 2021-03-22, MAE is:11.74 & sMAPE is:24.23% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 17.98% & 0.81\n",
      "for 2021-03-23, MAE is:8.80 & sMAPE is:25.21% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 18.07% & 0.81\n",
      "for 2021-03-24, MAE is:4.99 & sMAPE is:16.98% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 18.05% & 0.80\n",
      "for 2021-03-25, MAE is:13.00 & sMAPE is:30.67% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 18.20% & 0.81\n",
      "for 2021-03-26, MAE is:11.41 & sMAPE is:29.48% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 18.34% & 0.81\n",
      "for 2021-03-27, MAE is:2.27 & sMAPE is:12.08% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 18.26% & 0.80\n",
      "for 2021-03-28, MAE is:3.56 & sMAPE is:18.31% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 18.26% & 0.81\n",
      "for 2021-03-29, MAE is:8.98 & sMAPE is:32.36% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 18.42% & 0.80\n",
      "for 2021-03-30, MAE is:7.19 & sMAPE is:28.51% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 18.54% & 0.80\n",
      "for 2021-03-31, MAE is:5.99 & sMAPE is:20.06% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 18.55% & 0.81\n",
      "for 2021-04-01, MAE is:5.56 & sMAPE is:16.39% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 18.53% & 0.80\n",
      "for 2021-04-02, MAE is:6.85 & sMAPE is:23.20% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 18.58% & 0.80\n",
      "for 2021-04-03, MAE is:3.65 & sMAPE is:17.13% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 18.57% & 0.80\n",
      "for 2021-04-04, MAE is:8.97 & sMAPE is:64.69% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 19.06% & 0.81\n",
      "for 2021-04-05, MAE is:11.08 & sMAPE is:115.49% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 20.07% & 0.80\n",
      "for 2021-04-06, MAE is:10.72 & sMAPE is:40.83% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 20.29% & 0.81\n",
      "for 2021-04-07, MAE is:11.23 & sMAPE is:25.88% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 20.35% & 0.81\n",
      "for 2021-04-08, MAE is:13.97 & sMAPE is:31.62% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 20.46% & 0.81\n",
      "for 2021-04-09, MAE is:11.67 & sMAPE is:45.20% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 20.71% & 0.82\n",
      "for 2021-04-10, MAE is:3.97 & sMAPE is:24.70% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 20.75% & 0.82\n",
      "for 2021-04-11, MAE is:6.06 & sMAPE is:24.22% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 20.79% & 0.82\n",
      "for 2021-04-12, MAE is:9.63 & sMAPE is:23.69% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 20.81% & 0.81\n",
      "for 2021-04-13, MAE is:17.69 & sMAPE is:38.51% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 20.99% & 0.82\n",
      "for 2021-04-14, MAE is:15.26 & sMAPE is:26.65% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.30 & 21.04% & 0.82\n",
      "for 2021-04-15, MAE is:13.08 & sMAPE is:23.51% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 21.06% & 0.82\n",
      "for 2021-04-16, MAE is:9.02 & sMAPE is:17.61% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 21.03% & 0.82\n",
      "for 2021-04-17, MAE is:3.65 & sMAPE is:13.66% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.28 & 20.96% & 0.82\n",
      "for 2021-04-18, MAE is:1.99 & sMAPE is:8.48% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 20.85% & 0.81\n",
      "for 2021-04-19, MAE is:15.10 & sMAPE is:32.32% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 20.95% & 0.82\n",
      "for 2021-04-20, MAE is:18.71 & sMAPE is:41.65% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 21.14% & 0.83\n",
      "for 2021-04-21, MAE is:4.87 & sMAPE is:15.65% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 21.09% & 0.83\n",
      "for 2021-04-22, MAE is:9.71 & sMAPE is:35.06% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 21.21% & 0.82\n",
      "for 2021-04-23, MAE is:13.05 & sMAPE is:45.02% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 21.43% & 0.82\n",
      "for 2021-04-24, MAE is:2.60 & sMAPE is:14.68% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 21.37% & 0.82\n",
      "for 2021-04-25, MAE is:6.11 & sMAPE is:51.00% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :9.26 & 21.62% & 0.81\n",
      "for 2021-04-26, MAE is:20.80 & sMAPE is:40.84% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 21.79% & 0.83\n",
      "for 2021-04-27, MAE is:13.99 & sMAPE is:26.08% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 21.83% & 0.83\n",
      "for 2021-04-28, MAE is:7.95 & sMAPE is:13.75% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 21.76% & 0.82\n",
      "for 2021-04-29, MAE is:8.36 & sMAPE is:15.54% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 21.71% & 0.82\n",
      "for 2021-04-30, MAE is:10.15 & sMAPE is:19.07% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 21.68% & 0.82\n",
      "for 2021-05-01, MAE is:7.09 & sMAPE is:16.73% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 21.64% & 0.81\n",
      "for 2021-05-02, MAE is:6.63 & sMAPE is:15.28% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 21.59% & 0.81\n",
      "for 2021-05-03, MAE is:12.30 & sMAPE is:21.21% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 21.59% & 0.81\n",
      "for 2021-05-04, MAE is:24.00 & sMAPE is:37.54% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 21.72% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-05, MAE is:11.59 & sMAPE is:26.09% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.51 & 21.75% & 0.81\n",
      "for 2021-05-06, MAE is:13.41 & sMAPE is:22.86% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 21.76% & 0.81\n",
      "for 2021-05-07, MAE is:9.99 & sMAPE is:15.66% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 21.71% & 0.81\n",
      "for 2021-05-08, MAE is:7.98 & sMAPE is:17.76% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 21.68% & 0.81\n",
      "for 2021-05-09, MAE is:21.44 & sMAPE is:63.97% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.62 & 22.01% & 0.82\n",
      "for 2021-05-10, MAE is:6.84 & sMAPE is:16.90% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 21.97% & 0.81\n",
      "for 2021-05-11, MAE is:9.45 & sMAPE is:24.61% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 21.99% & 0.81\n",
      "for 2021-05-12, MAE is:10.38 & sMAPE is:21.73% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.60 & 21.99% & 0.81\n",
      "for 2021-05-13, MAE is:5.91 & sMAPE is:16.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 21.95% & 0.81\n",
      "for 2021-05-14, MAE is:9.14 & sMAPE is:23.52% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 21.96% & 0.80\n",
      "for 2021-05-15, MAE is:5.73 & sMAPE is:25.16% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 21.98% & 0.80\n",
      "for 2021-05-16, MAE is:10.98 & sMAPE is:39.18% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 22.11% & 0.81\n",
      "for 2021-05-17, MAE is:17.72 & sMAPE is:29.43% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 22.16% & 0.81\n",
      "for 2021-05-18, MAE is:19.77 & sMAPE is:32.46% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :9.69 & 22.24% & 0.81\n",
      "for 2021-05-19, MAE is:12.35 & sMAPE is:23.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :9.71 & 22.24% & 0.81\n",
      "for 2021-05-20, MAE is:9.30 & sMAPE is:28.53% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 22.29% & 0.81\n",
      "for 2021-05-21, MAE is:12.66 & sMAPE is:41.46% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 22.42% & 0.81\n",
      "for 2021-05-22, MAE is:17.97 & sMAPE is:73.14% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 22.78% & 0.81\n",
      "for 2021-05-23, MAE is:18.77 & sMAPE is:78.37% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 23.17% & 0.82\n",
      "for 2021-05-24, MAE is:15.69 & sMAPE is:31.50% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.89 & 23.23% & 0.82\n",
      "for 2021-05-25, MAE is:13.00 & sMAPE is:24.58% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.91 & 23.24% & 0.82\n",
      "for 2021-05-26, MAE is:12.82 & sMAPE is:30.39% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 23.28% & 0.82\n",
      "for 2021-05-27, MAE is:22.05 & sMAPE is:49.19% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 23.46% & 0.83\n",
      "for 2021-05-28, MAE is:10.65 & sMAPE is:18.73% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 23.43% & 0.83\n",
      "for 2021-05-29, MAE is:7.58 & sMAPE is:18.66% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 23.40% & 0.83\n",
      "for 2021-05-30, MAE is:13.93 & sMAPE is:42.31% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 23.52% & 0.83\n",
      "for 2021-05-31, MAE is:10.61 & sMAPE is:21.62% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 23.51% & 0.83\n",
      "for 2021-06-01, MAE is:17.72 & sMAPE is:29.73% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 23.55% & 0.84\n",
      "for 2021-06-02, MAE is:18.08 & sMAPE is:30.02% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 23.59% & 0.84\n",
      "for 2021-06-03, MAE is:9.35 & sMAPE is:16.91% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 23.55% & 0.84\n",
      "for 2021-06-04, MAE is:11.82 & sMAPE is:19.79% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 23.53% & 0.84\n",
      "for 2021-06-05, MAE is:2.61 & sMAPE is:6.23% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 23.41% & 0.84\n",
      "for 2021-06-06, MAE is:2.34 & sMAPE is:6.06% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 23.30% & 0.83\n",
      "for 2021-06-07, MAE is:13.71 & sMAPE is:21.02% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 23.29% & 0.83\n",
      "for 2021-06-08, MAE is:14.45 & sMAPE is:22.28% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 23.28% & 0.84\n",
      "for 2021-06-09, MAE is:12.08 & sMAPE is:20.46% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 23.27% & 0.84\n",
      "for 2021-06-10, MAE is:15.97 & sMAPE is:24.32% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 23.27% & 0.84\n",
      "for 2021-06-11, MAE is:21.47 & sMAPE is:40.04% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 23.38% & 0.85\n",
      "for 2021-06-12, MAE is:13.63 & sMAPE is:46.31% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 23.52% & 0.85\n",
      "for 2021-06-13, MAE is:22.31 & sMAPE is:105.97% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 24.02% & 0.85\n",
      "for 2021-06-14, MAE is:26.50 & sMAPE is:49.27% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 24.17% & 0.86\n",
      "for 2021-06-15, MAE is:21.01 & sMAPE is:50.49% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 24.33% & 0.86\n",
      "for 2021-06-16, MAE is:27.71 & sMAPE is:36.16% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 24.40% & 0.86\n",
      "for 2021-06-17, MAE is:16.07 & sMAPE is:24.70% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :10.60 & 24.40% & 0.86\n",
      "for 2021-06-18, MAE is:15.59 & sMAPE is:28.80% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 24.43% & 0.87\n",
      "for 2021-06-19, MAE is:6.35 & sMAPE is:17.58% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 24.39% & 0.87\n",
      "for 2021-06-20, MAE is:6.85 & sMAPE is:18.98% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 24.36% & 0.86\n",
      "for 2021-06-21, MAE is:14.54 & sMAPE is:43.50% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.61 & 24.47% & 0.86\n",
      "for 2021-06-22, MAE is:24.10 & sMAPE is:37.09% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 24.54% & 0.87\n",
      "for 2021-06-23, MAE is:25.06 & sMAPE is:34.14% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :10.77 & 24.60% & 0.87\n",
      "for 2021-06-24, MAE is:19.38 & sMAPE is:30.04% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 24.63% & 0.88\n",
      "for 2021-06-25, MAE is:10.88 & sMAPE is:26.03% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 24.64% & 0.87\n",
      "for 2021-06-26, MAE is:6.33 & sMAPE is:17.07% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :10.79 & 24.59% & 0.87\n",
      "for 2021-06-27, MAE is:2.61 & sMAPE is:8.06% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 24.50% & 0.87\n",
      "for 2021-06-28, MAE is:26.82 & sMAPE is:41.67% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.84 & 24.60% & 0.87\n",
      "for 2021-06-29, MAE is:21.47 & sMAPE is:28.01% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.90 & 24.62% & 0.88\n",
      "for 2021-06-30, MAE is:15.60 & sMAPE is:23.58% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 24.61% & 0.88\n",
      "for 2021-07-01, MAE is:24.43 & sMAPE is:32.20% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 24.65% & 0.88\n",
      "for 2021-07-02, MAE is:14.75 & sMAPE is:17.04% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 24.61% & 0.88\n",
      "for 2021-07-03, MAE is:9.05 & sMAPE is:13.77% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 24.55% & 0.87\n",
      "for 2021-07-04, MAE is:9.22 & sMAPE is:14.44% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 24.50% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-05, MAE is:12.18 & sMAPE is:16.08% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :11.00 & 24.45% & 0.87\n",
      "for 2021-07-06, MAE is:7.09 & sMAPE is:9.93% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.98 & 24.37% & 0.87\n",
      "for 2021-07-07, MAE is:22.40 & sMAPE is:24.15% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.37% & 0.87\n",
      "for 2021-07-08, MAE is:8.86 & sMAPE is:12.19% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 24.31% & 0.87\n",
      "for 2021-07-09, MAE is:16.04 & sMAPE is:20.36% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 24.29% & 0.88\n",
      "for 2021-07-10, MAE is:6.25 & sMAPE is:8.05% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.03 & 24.20% & 0.88\n",
      "for 2021-07-11, MAE is:9.74 & sMAPE is:13.86% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 24.15% & 0.88\n",
      "for 2021-07-12, MAE is:14.39 & sMAPE is:16.04% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :11.04 & 24.11% & 0.88\n",
      "for 2021-07-13, MAE is:14.23 & sMAPE is:15.82% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.06 & 24.06% & 0.88\n",
      "for 2021-07-14, MAE is:22.52 & sMAPE is:22.93% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 24.06% & 0.88\n",
      "for 2021-07-15, MAE is:12.15 & sMAPE is:13.97% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :11.12 & 24.01% & 0.88\n",
      "for 2021-07-16, MAE is:7.77 & sMAPE is:10.17% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 23.94% & 0.88\n",
      "for 2021-07-17, MAE is:12.19 & sMAPE is:18.37% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 23.91% & 0.88\n",
      "for 2021-07-18, MAE is:34.49 & sMAPE is:73.41% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 24.16% & 0.89\n",
      "for 2021-07-19, MAE is:21.21 & sMAPE is:27.20% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 24.17% & 0.89\n",
      "for 2021-07-20, MAE is:6.58 & sMAPE is:9.06% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 24.10% & 0.89\n",
      "for 2021-07-21, MAE is:12.28 & sMAPE is:18.10% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 24.07% & 0.88\n",
      "for 2021-07-22, MAE is:6.55 & sMAPE is:12.68% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 24.01% & 0.88\n",
      "for 2021-07-23, MAE is:18.24 & sMAPE is:25.23% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 24.02% & 0.88\n",
      "for 2021-07-24, MAE is:5.40 & sMAPE is:7.49% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.94% & 0.88\n",
      "for 2021-07-25, MAE is:9.89 & sMAPE is:14.14% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.89% & 0.88\n",
      "for 2021-07-26, MAE is:11.80 & sMAPE is:15.19% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.85% & 0.88\n",
      "for 2021-07-27, MAE is:10.78 & sMAPE is:12.85% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.79% & 0.88\n",
      "for 2021-07-28, MAE is:11.10 & sMAPE is:13.91% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.75% & 0.88\n",
      "for 2021-07-29, MAE is:9.85 & sMAPE is:12.91% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 23.69% & 0.88\n",
      "for 2021-07-30, MAE is:10.09 & sMAPE is:13.32% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 23.65% & 0.88\n",
      "for 2021-07-31, MAE is:7.17 & sMAPE is:12.40% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 23.59% & 0.88\n",
      "for 2021-08-01, MAE is:9.06 & sMAPE is:16.60% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 23.56% & 0.88\n",
      "for 2021-08-02, MAE is:11.88 & sMAPE is:15.85% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 23.52% & 0.88\n",
      "for 2021-08-03, MAE is:13.18 & sMAPE is:20.02% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 23.51% & 0.88\n",
      "for 2021-08-04, MAE is:10.27 & sMAPE is:14.49% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 23.47% & 0.88\n",
      "for 2021-08-05, MAE is:7.71 & sMAPE is:10.98% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :11.19 & 23.41% & 0.88\n",
      "for 2021-08-06, MAE is:9.45 & sMAPE is:13.65% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 23.36% & 0.88\n",
      "for 2021-08-07, MAE is:8.13 & sMAPE is:14.54% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 23.32% & 0.88\n",
      "for 2021-08-08, MAE is:27.02 & sMAPE is:97.21% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.66% & 0.88\n",
      "for 2021-08-09, MAE is:20.15 & sMAPE is:27.37% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.28 & 23.68% & 0.89\n",
      "for 2021-08-10, MAE is:10.24 & sMAPE is:13.18% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :11.27 & 23.63% & 0.89\n",
      "for 2021-08-11, MAE is:16.95 & sMAPE is:23.94% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 23.63% & 0.89\n",
      "for 2021-08-12, MAE is:10.16 & sMAPE is:11.58% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.29 & 23.58% & 0.89\n",
      "for 2021-08-13, MAE is:10.91 & sMAPE is:15.56% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.29 & 23.54% & 0.89\n",
      "for 2021-08-14, MAE is:5.29 & sMAPE is:8.65% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.26 & 23.47% & 0.89\n",
      "for 2021-08-15, MAE is:5.93 & sMAPE is:10.16% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.42% & 0.88\n",
      "for 2021-08-16, MAE is:9.39 & sMAPE is:13.76% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 23.37% & 0.88\n",
      "for 2021-08-17, MAE is:7.99 & sMAPE is:12.43% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 23.33% & 0.88\n",
      "for 2021-08-18, MAE is:11.22 & sMAPE is:33.55% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 23.37% & 0.88\n",
      "for 2021-08-19, MAE is:18.92 & sMAPE is:27.95% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 23.39% & 0.88\n",
      "for 2021-08-20, MAE is:8.63 & sMAPE is:11.45% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.34% & 0.88\n",
      "for 2021-08-21, MAE is:2.63 & sMAPE is:5.25% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.20 & 23.26% & 0.88\n",
      "for 2021-08-22, MAE is:3.23 & sMAPE is:5.95% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 23.19% & 0.88\n",
      "for 2021-08-23, MAE is:4.42 & sMAPE is:6.34% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 23.12% & 0.87\n",
      "for 2021-08-24, MAE is:30.08 & sMAPE is:37.22% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 23.17% & 0.88\n",
      "for 2021-08-25, MAE is:11.60 & sMAPE is:25.52% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 23.18% & 0.88\n",
      "for 2021-08-26, MAE is:10.90 & sMAPE is:17.56% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :11.22 & 23.16% & 0.88\n",
      "for 2021-08-27, MAE is:15.07 & sMAPE is:24.59% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :11.24 & 23.17% & 0.88\n",
      "for 2021-08-28, MAE is:9.11 & sMAPE is:17.58% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 23.14% & 0.88\n",
      "for 2021-08-29, MAE is:11.23 & sMAPE is:18.64% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :11.23 & 23.13% & 0.88\n",
      "for 2021-08-30, MAE is:27.57 & sMAPE is:29.95% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 23.15% & 0.88\n",
      "for 2021-08-31, MAE is:15.27 & sMAPE is:18.76% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 23.14% & 0.89\n",
      "for 2021-09-01, MAE is:15.03 & sMAPE is:19.59% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 23.12% & 0.89\n",
      "for 2021-09-02, MAE is:16.28 & sMAPE is:23.30% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 23.12% & 0.89\n",
      "for 2021-09-03, MAE is:7.92 & sMAPE is:12.93% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 23.08% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-04, MAE is:10.76 & sMAPE is:17.66% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 23.06% & 0.89\n",
      "for 2021-09-05, MAE is:9.78 & sMAPE is:14.50% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :11.33 & 23.02% & 0.89\n",
      "for 2021-09-06, MAE is:29.37 & sMAPE is:32.54% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.40 & 23.06% & 0.90\n",
      "for 2021-09-07, MAE is:12.41 & sMAPE is:16.77% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :11.40 & 23.04% & 0.90\n",
      "for 2021-09-08, MAE is:5.17 & sMAPE is:11.14% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 22.99% & 0.89\n",
      "for 2021-09-09, MAE is:23.41 & sMAPE is:33.02% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 23.03% & 0.90\n",
      "for 2021-09-10, MAE is:27.93 & sMAPE is:30.43% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :11.49 & 23.06% & 0.90\n",
      "for 2021-09-11, MAE is:27.08 & sMAPE is:32.43% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 23.10% & 0.90\n",
      "for 2021-09-12, MAE is:21.50 & sMAPE is:26.83% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.59 & 23.11% & 0.90\n",
      "for 2021-09-13, MAE is:16.70 & sMAPE is:20.91% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 23.10% & 0.90\n",
      "for 2021-09-14, MAE is:24.95 & sMAPE is:31.01% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :11.66 & 23.13% & 0.90\n",
      "for 2021-09-15, MAE is:60.15 & sMAPE is:51.16% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.85 & 23.24% & 0.90\n",
      "for 2021-09-16, MAE is:23.06 & sMAPE is:23.80% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.89 & 23.24% & 0.90\n",
      "for 2021-09-17, MAE is:20.22 & sMAPE is:22.74% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :11.93 & 23.24% & 0.90\n",
      "for 2021-09-18, MAE is:11.42 & sMAPE is:13.55% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :11.92 & 23.20% & 0.90\n",
      "for 2021-09-19, MAE is:11.17 & sMAPE is:14.28% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.92 & 23.17% & 0.90\n",
      "for 2021-09-20, MAE is:43.96 & sMAPE is:43.98% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :12.04 & 23.25% & 0.90\n",
      "for 2021-09-21, MAE is:23.62 & sMAPE is:24.24% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 23.25% & 0.90\n",
      "for 2021-09-22, MAE is:10.51 & sMAPE is:12.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 23.21% & 0.89\n",
      "for 2021-09-23, MAE is:17.10 & sMAPE is:25.40% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :12.10 & 23.22% & 0.89\n",
      "for 2021-09-24, MAE is:25.46 & sMAPE is:35.73% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 23.27% & 0.89\n",
      "for 2021-09-25, MAE is:14.97 & sMAPE is:19.51% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :12.16 & 23.25% & 0.89\n",
      "for 2021-09-26, MAE is:18.12 & sMAPE is:25.05% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.18 & 23.26% & 0.90\n",
      "for 2021-09-27, MAE is:10.42 & sMAPE is:11.75% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :12.18 & 23.22% & 0.90\n",
      "for 2021-09-28, MAE is:24.20 & sMAPE is:27.82% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 23.23% & 0.90\n",
      "for 2021-09-29, MAE is:24.06 & sMAPE is:24.49% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 23.24% & 0.90\n",
      "for 2021-09-30, MAE is:11.04 & sMAPE is:14.15% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 23.21% & 0.90\n",
      "for 2021-10-01, MAE is:19.39 & sMAPE is:32.34% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :12.29 & 23.24% & 0.90\n",
      "for 2021-10-02, MAE is:10.75 & sMAPE is:25.50% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.28 & 23.25% & 0.90\n",
      "for 2021-10-03, MAE is:36.16 & sMAPE is:128.67% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 23.63% & 0.89\n",
      "for 2021-10-04, MAE is:31.45 & sMAPE is:80.41% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 23.83% & 0.89\n",
      "for 2021-10-05, MAE is:15.06 & sMAPE is:26.83% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 23.84% & 0.89\n",
      "for 2021-10-06, MAE is:17.09 & sMAPE is:26.42% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.46 & 23.85% & 0.89\n",
      "for 2021-10-07, MAE is:31.99 & sMAPE is:36.76% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :12.53 & 23.90% & 0.89\n",
      "for 2021-10-08, MAE is:25.09 & sMAPE is:26.26% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 23.91% & 0.89\n",
      "for 2021-10-09, MAE is:15.02 & sMAPE is:18.80% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 23.89% & 0.89\n",
      "for 2021-10-10, MAE is:21.79 & sMAPE is:49.05% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :12.62 & 23.98% & 0.89\n",
      "for 2021-10-11, MAE is:29.86 & sMAPE is:40.43% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :12.68 & 24.04% & 0.89\n",
      "for 2021-10-12, MAE is:40.57 & sMAPE is:36.80% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :12.78 & 24.08% & 0.89\n",
      "for 2021-10-13, MAE is:67.36 & sMAPE is:49.10% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :12.97 & 24.17% & 0.89\n",
      "for 2021-10-14, MAE is:52.60 & sMAPE is:60.19% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :13.10 & 24.29% & 0.89\n",
      "for 2021-10-15, MAE is:24.16 & sMAPE is:83.25% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :13.14 & 24.50% & 0.89\n",
      "for 2021-10-16, MAE is:28.29 & sMAPE is:117.48% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :13.20 & 24.82% & 0.89\n",
      "for 2021-10-17, MAE is:45.52 & sMAPE is:170.61% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :13.31 & 25.32% & 0.90\n",
      "for 2021-10-18, MAE is:38.47 & sMAPE is:47.15% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :13.39 & 25.40% & 0.90\n",
      "for 2021-10-19, MAE is:66.27 & sMAPE is:62.16% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :13.57 & 25.52% & 0.90\n",
      "for 2021-10-20, MAE is:59.45 & sMAPE is:105.56% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :13.73 & 25.80% & 0.90\n",
      "for 2021-10-21, MAE is:20.63 & sMAPE is:38.35% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :13.75 & 25.84% & 0.90\n",
      "for 2021-10-22, MAE is:23.94 & sMAPE is:70.03% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :13.79 & 25.99% & 0.91\n",
      "for 2021-10-23, MAE is:55.99 & sMAPE is:96.21% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :13.93 & 26.23% & 0.90\n",
      "for 2021-10-24, MAE is:47.38 & sMAPE is:86.39% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.04 & 26.43% & 0.91\n",
      "for 2021-10-25, MAE is:35.15 & sMAPE is:49.94% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.11 & 26.51% & 0.91\n",
      "for 2021-10-26, MAE is:17.53 & sMAPE is:34.81% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :14.13 & 26.54% & 0.91\n",
      "for 2021-10-27, MAE is:35.44 & sMAPE is:44.93% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 26.60% & 0.91\n",
      "for 2021-10-28, MAE is:31.13 & sMAPE is:80.95% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.25 & 26.78% & 0.91\n",
      "for 2021-10-29, MAE is:21.95 & sMAPE is:89.25% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.28 & 26.99% & 0.91\n",
      "for 2021-10-30, MAE is:19.48 & sMAPE is:58.65% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.30 & 27.09% & 0.91\n",
      "for 2021-10-31, MAE is:31.82 & sMAPE is:79.62% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :14.35 & 27.26% & 0.91\n",
      "for 2021-11-01, MAE is:14.15 & sMAPE is:38.03% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :14.35 & 27.30% & 0.91\n",
      "for 2021-11-02, MAE is:23.35 & sMAPE is:58.10% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.38 & 27.40% & 0.91\n",
      "for 2021-11-03, MAE is:21.95 & sMAPE is:34.10% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 27.42% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-04, MAE is:14.96 & sMAPE is:26.66% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 27.42% & 0.91\n",
      "for 2021-11-05, MAE is:14.53 & sMAPE is:36.98% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :14.41 & 27.45% & 0.91\n",
      "for 2021-11-06, MAE is:9.84 & sMAPE is:55.37% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 27.54% & 0.91\n",
      "for 2021-11-07, MAE is:13.94 & sMAPE is:67.40% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :14.39 & 27.67% & 0.90\n",
      "for 2021-11-08, MAE is:75.98 & sMAPE is:107.42% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 27.92% & 0.91\n",
      "for 2021-11-09, MAE is:46.25 & sMAPE is:73.56% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.69 & 28.07% & 0.91\n",
      "for 2021-11-10, MAE is:18.56 & sMAPE is:55.79% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :14.70 & 28.16% & 0.91\n",
      "for 2021-11-11, MAE is:16.14 & sMAPE is:81.76% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :14.71 & 28.33% & 0.91\n",
      "for 2021-11-12, MAE is:32.14 & sMAPE is:52.95% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :14.76 & 28.41% & 0.91\n",
      "for 2021-11-13, MAE is:17.00 & sMAPE is:40.78% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.77 & 28.44% & 0.91\n",
      "for 2021-11-14, MAE is:26.50 & sMAPE is:55.74% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :14.81 & 28.53% & 0.91\n",
      "for 2021-11-15, MAE is:24.65 & sMAPE is:49.94% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :14.84 & 28.60% & 0.91\n",
      "for 2021-11-16, MAE is:24.10 & sMAPE is:42.89% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :14.87 & 28.64% & 0.91\n",
      "for 2021-11-17, MAE is:14.01 & sMAPE is:29.30% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 28.64% & 0.91\n",
      "for 2021-11-18, MAE is:14.99 & sMAPE is:41.19% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.87 & 28.68% & 0.90\n",
      "for 2021-11-19, MAE is:25.66 & sMAPE is:40.44% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :14.90 & 28.72% & 0.91\n",
      "for 2021-11-20, MAE is:41.96 & sMAPE is:120.11% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :14.98 & 29.00% & 0.91\n",
      "for 2021-11-21, MAE is:42.64 & sMAPE is:89.14% & rMAE is:5.34 ||| daily mean of MAE & sMAPE & rMAE till now are :15.07 & 29.19% & 0.92\n",
      "for 2021-11-22, MAE is:62.17 & sMAPE is:58.35% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :15.21 & 29.28% & 0.92\n",
      "for 2021-11-23, MAE is:44.41 & sMAPE is:37.83% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :15.30 & 29.30% & 0.92\n",
      "for 2021-11-24, MAE is:32.27 & sMAPE is:43.54% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.35 & 29.35% & 0.92\n",
      "for 2021-11-25, MAE is:32.29 & sMAPE is:35.89% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :15.40 & 29.37% & 0.92\n",
      "for 2021-11-26, MAE is:74.20 & sMAPE is:58.02% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :15.58 & 29.45% & 0.92\n",
      "for 2021-11-27, MAE is:79.79 & sMAPE is:60.63% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :15.78 & 29.55% & 0.92\n",
      "for 2021-11-28, MAE is:67.34 & sMAPE is:47.84% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 29.60% & 0.92\n",
      "for 2021-11-29, MAE is:136.91 & sMAPE is:67.00% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :16.29 & 29.71% & 0.92\n",
      "for 2021-11-30, MAE is:35.97 & sMAPE is:20.74% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :16.35 & 29.69% & 0.92\n",
      "for 2021-12-01, MAE is:23.04 & sMAPE is:16.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :16.37 & 29.65% & 0.92\n",
      "for 2021-12-02, MAE is:60.54 & sMAPE is:35.88% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :16.51 & 29.67% & 0.92\n",
      "for 2021-12-03, MAE is:53.07 & sMAPE is:34.62% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :16.61 & 29.68% & 0.92\n",
      "for 2021-12-04, MAE is:54.86 & sMAPE is:39.47% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :16.73 & 29.71% & 0.93\n",
      "for 2021-12-05, MAE is:47.13 & sMAPE is:32.89% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 29.72% & 0.93\n",
      "for 2021-12-06, MAE is:159.33 & sMAPE is:72.04% & rMAE is:3.33 ||| daily mean of MAE & sMAPE & rMAE till now are :17.24 & 29.84% & 0.93\n",
      "for 2021-12-07, MAE is:212.29 & sMAPE is:44.39% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :17.81 & 29.89% & 0.93\n",
      "for 2021-12-08, MAE is:156.72 & sMAPE is:44.85% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :18.21 & 29.93% & 0.93\n",
      "for 2021-12-09, MAE is:33.62 & sMAPE is:13.24% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :18.26 & 29.88% & 0.93\n",
      "for 2021-12-10, MAE is:39.64 & sMAPE is:16.30% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :18.32 & 29.84% & 0.93\n",
      "for 2021-12-11, MAE is:44.02 & sMAPE is:28.30% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :18.40 & 29.84% & 0.93\n",
      "for 2021-12-12, MAE is:45.30 & sMAPE is:28.48% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :18.47 & 29.83% & 0.94\n",
      "for 2021-12-13, MAE is:46.51 & sMAPE is:26.02% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :18.55 & 29.82% & 0.94\n",
      "for 2021-12-14, MAE is:44.73 & sMAPE is:32.27% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :18.63 & 29.83% & 0.93\n",
      "for 2021-12-15, MAE is:76.10 & sMAPE is:83.10% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :18.79 & 29.98% & 0.93\n",
      "for 2021-12-16, MAE is:50.73 & sMAPE is:56.01% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :18.89 & 30.06% & 0.93\n",
      "for 2021-12-17, MAE is:49.04 & sMAPE is:45.00% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :18.97 & 30.10% & 0.93\n",
      "for 2021-12-18, MAE is:49.33 & sMAPE is:61.58% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :19.06 & 30.19% & 0.93\n",
      "for 2021-12-19, MAE is:39.04 & sMAPE is:68.11% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :19.11 & 30.30% & 0.93\n",
      "for 2021-12-20, MAE is:181.43 & sMAPE is:90.01% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :19.57 & 30.47% & 0.93\n",
      "for 2021-12-21, MAE is:193.33 & sMAPE is:57.44% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :20.06 & 30.54% & 0.93\n",
      "for 2021-12-22, MAE is:110.70 & sMAPE is:36.02% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :20.32 & 30.56% & 0.93\n",
      "for 2021-12-23, MAE is:103.15 & sMAPE is:42.39% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :20.55 & 30.59% & 0.93\n",
      "for 2021-12-24, MAE is:44.91 & sMAPE is:26.46% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :20.62 & 30.58% & 0.93\n",
      "for 2021-12-25, MAE is:16.39 & sMAPE is:12.62% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 30.53% & 0.93\n",
      "for 2021-12-26, MAE is:23.42 & sMAPE is:14.73% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :20.61 & 30.48% & 0.93\n",
      "for 2021-12-27, MAE is:17.84 & sMAPE is:11.47% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :20.60 & 30.43% & 0.92\n",
      "for 2021-12-28, MAE is:21.76 & sMAPE is:15.14% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :20.61 & 30.39% & 0.92\n",
      "for 2021-12-29, MAE is:24.78 & sMAPE is:16.05% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :20.62 & 30.35% & 0.92\n",
      "for 2021-12-30, MAE is:66.30 & sMAPE is:64.54% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :20.75 & 30.44% & 0.92\n",
      "for 2021-12-31, MAE is:17.33 & sMAPE is:30.53% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :20.74 & 30.44% & 0.92\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:51:24,306]\u001b[0m A new study created in RDB with name: FI_2022\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:51:41,577]\u001b[0m Trial 0 finished with value: 31.201360010314925 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23356429238410611, 'dropout_rate_Layer_2': 0.2895177235751562, 'dropout_rate_Layer_3': 0.13811964446957742, 'dropout_rate_Layer_4': 0.23512881495271107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032357461094841447, 'l1_Layer_2': 2.5278958822460455e-05, 'l1_Layer_3': 0.001538041990319464, 'l1_Layer_4': 0.009407852546072591, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 0 with value: 31.201360010314925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.20 | sMAPE for Validation Set is: 42.50% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 110.96 | sMAPE for Test Set is: 89.52% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:51:58,109]\u001b[0m Trial 1 finished with value: 32.826275970951365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0994312055922404, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3300030187772457, 'dropout_rate_Layer_2': 0.03604777472282006, 'dropout_rate_Layer_3': 0.05307700861067186, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029916299186771114, 'l1_Layer_2': 5.721154410662058e-05, 'l1_Layer_3': 0.011397007896641838, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75}. Best is trial 0 with value: 31.201360010314925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.83 | sMAPE for Validation Set is: 44.77% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 113.32 | sMAPE for Test Set is: 92.53% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:53:25,168]\u001b[0m Trial 2 finished with value: 40.00231201921317 and parameters: {'n_hidden': 4, 'learning_rate': 0.04957571112605778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12241905910384072, 'dropout_rate_Layer_2': 0.1669226097601424, 'dropout_rate_Layer_3': 0.2883681312389442, 'dropout_rate_Layer_4': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00041300516202926124, 'l1_Layer_2': 0.006776833188207501, 'l1_Layer_3': 0.003622560816032839, 'l1_Layer_4': 1.8618864261152286e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155, 'n_units_Layer_4': 240}. Best is trial 0 with value: 31.201360010314925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.00 | sMAPE for Validation Set is: 57.57% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 122.86 | sMAPE for Test Set is: 104.58% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:53:30,367]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:53:34,836]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:53:39,409]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:53:43,224]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:54:16,677]\u001b[0m Trial 7 finished with value: 32.82740150318022 and parameters: {'n_hidden': 3, 'learning_rate': 0.038497387756701106, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3912062307123102, 'dropout_rate_Layer_2': 0.3483502174341135, 'dropout_rate_Layer_3': 0.2725031564893123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.991703910310738e-05, 'l1_Layer_2': 0.00019580891007468725, 'l1_Layer_3': 0.015569334069484185, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 0 with value: 31.201360010314925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.83 | sMAPE for Validation Set is: 44.12% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 113.05 | sMAPE for Test Set is: 91.69% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:54:20,935]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:54:27,710]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:54:32,246]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:54:52,193]\u001b[0m Trial 11 finished with value: 31.230633359987923 and parameters: {'n_hidden': 4, 'learning_rate': 0.02633257471980183, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1817215599256533, 'dropout_rate_Layer_2': 0.35876350176109895, 'dropout_rate_Layer_3': 0.010588496926302772, 'dropout_rate_Layer_4': 0.24005720586119758, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004781233019198209, 'l1_Layer_2': 2.1848802394313182e-05, 'l1_Layer_3': 0.022665202224437988, 'l1_Layer_4': 2.264541865863889e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 285, 'n_units_Layer_3': 70, 'n_units_Layer_4': 260}. Best is trial 0 with value: 31.201360010314925.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.23 | sMAPE for Validation Set is: 42.93% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 111.85 | sMAPE for Test Set is: 90.94% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:54:59,016]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:55:04,128]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:55:32,118]\u001b[0m Trial 14 finished with value: 26.443912022523374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009916026644663464, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024375571808317488, 'dropout_rate_Layer_2': 0.27253302708968685, 'dropout_rate_Layer_3': 0.03516191622460912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0002512100982739921, 'l1_Layer_2': 0.0008717018088031334, 'l1_Layer_3': 0.0030445549470699395, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 14 with value: 26.443912022523374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.44 | sMAPE for Validation Set is: 35.59% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 102.09 | sMAPE for Test Set is: 80.69% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:55:35,744]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:55:40,916]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:55:46,915]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:55:56,879]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:56:01,921]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:56:31,414]\u001b[0m Trial 20 finished with value: 30.753908838901662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025020775906272916, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1039708447233906, 'dropout_rate_Layer_2': 0.36245170686893513, 'dropout_rate_Layer_3': 0.12861968817823075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0001149559086542844, 'l1_Layer_2': 0.0005393030781726091, 'l1_Layer_3': 0.0008039203174934494, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 170}. Best is trial 14 with value: 26.443912022523374.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.75 | sMAPE for Validation Set is: 41.56% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 110.72 | sMAPE for Test Set is: 89.47% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:56:36,367]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:56:43,200]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:56:46,833]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:56:54,060]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:56:59,803]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:57:04,591]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:57:19,082]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:57:24,178]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:57:29,561]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:57:52,942]\u001b[0m Trial 30 finished with value: 22.313354491173 and parameters: {'n_hidden': 3, 'learning_rate': 0.03550211358145328, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32810360041304754, 'dropout_rate_Layer_2': 0.04802558077881597, 'dropout_rate_Layer_3': 0.000312174241216448, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0066838453412304e-05, 'l1_Layer_2': 2.8984167836590518e-05, 'l1_Layer_3': 0.008324163917316016, 'n_units_Layer_1': 120, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 30 with value: 22.313354491173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.31 | sMAPE for Validation Set is: 32.55% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 68.47 | sMAPE for Test Set is: 57.53% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:57:57,857]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:05,254]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:09,751]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:20,725]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:25,991]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:48,340]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:52,855]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:58:57,682]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:59:03,368]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:59:07,383]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:59:39,221]\u001b[0m Trial 41 finished with value: 28.266174558842874 and parameters: {'n_hidden': 4, 'learning_rate': 0.01967291120203762, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1954363971512427, 'dropout_rate_Layer_2': 0.3772364997799744, 'dropout_rate_Layer_3': 0.008192216723738814, 'dropout_rate_Layer_4': 0.26910261734264496, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03298369655386027, 'l1_Layer_2': 1.5424349419425316e-05, 'l1_Layer_3': 0.009755542994717424, 'l1_Layer_4': 1.0762804384424748e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 280, 'n_units_Layer_3': 60, 'n_units_Layer_4': 295}. Best is trial 30 with value: 22.313354491173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.27 | sMAPE for Validation Set is: 38.86% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 104.25 | sMAPE for Test Set is: 82.13% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 01:59:44,688]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:59:51,562]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 01:59:55,552]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:00,734]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:07,564]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:12,625]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:22,533]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:26,786]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:35,830]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:40,863]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:45,809]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:51,216]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:00:55,731]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:01:35,896]\u001b[0m Trial 55 finished with value: 27.02963228485882 and parameters: {'n_hidden': 3, 'learning_rate': 0.010826176187698267, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24472155069640658, 'dropout_rate_Layer_2': 0.3771188803815185, 'dropout_rate_Layer_3': 0.3415173736096326, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024850769223685364, 'l1_Layer_2': 6.994319187787214e-05, 'l1_Layer_3': 0.0026472793990210504, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 135}. Best is trial 30 with value: 22.313354491173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.03 | sMAPE for Validation Set is: 36.20% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 99.18 | sMAPE for Test Set is: 77.54% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:01:41,329]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:01:47,224]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:01,677]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:06,288]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:10,525]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:16,598]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:31,283]\u001b[0m Trial 62 finished with value: 28.402543780305866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0907839636306977, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35470344262288256, 'dropout_rate_Layer_2': 0.1684687461815583, 'dropout_rate_Layer_3': 0.15603644104790504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003404457239000671, 'l1_Layer_2': 2.2435072721336244e-05, 'l1_Layer_3': 0.00698974612088344, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240}. Best is trial 30 with value: 22.313354491173.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.40 | sMAPE for Validation Set is: 43.88% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 100.93 | sMAPE for Test Set is: 81.03% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:02:35,172]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:40,647]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:51,885]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:02:58,787]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:05,650]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:11,119]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:15,357]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:24,369]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:30,227]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:35,543]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:03:39,756]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:04:01,077]\u001b[0m Trial 74 finished with value: 20.96368363667689 and parameters: {'n_hidden': 3, 'learning_rate': 0.04003468297016133, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3278819338651773, 'dropout_rate_Layer_2': 0.09605136616261498, 'dropout_rate_Layer_3': 0.002875961738579555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000964040566402716, 'l1_Layer_2': 3.3372743376071316e-05, 'l1_Layer_3': 0.0996989956512455, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180}. Best is trial 74 with value: 20.96368363667689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.96 | sMAPE for Validation Set is: 31.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.43 | sMAPE for Test Set is: 54.51% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:04:05,589]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:04:12,447]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:04:28,135]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:04:32,408]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:04:43,767]\u001b[0m Trial 79 finished with value: 30.45464096176239 and parameters: {'n_hidden': 3, 'learning_rate': 0.013788652859474884, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34258906933181554, 'dropout_rate_Layer_2': 0.15074178370383642, 'dropout_rate_Layer_3': 0.2342829099080042, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00064730956358648, 'l1_Layer_2': 5.51506373914722e-05, 'l1_Layer_3': 0.0030132136317456886, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 130}. Best is trial 74 with value: 20.96368363667689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.45 | sMAPE for Validation Set is: 45.52% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 108.28 | sMAPE for Test Set is: 88.50% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:04:53,171]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:04:58,545]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:05:03,262]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:05:09,698]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:05:16,026]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:05:21,439]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:05:28,607]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:05:47,022]\u001b[0m Trial 87 finished with value: 28.583953760572374 and parameters: {'n_hidden': 4, 'learning_rate': 0.00875122433399415, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04693095596648936, 'dropout_rate_Layer_2': 0.28269738047964527, 'dropout_rate_Layer_3': 0.1759581970921504, 'dropout_rate_Layer_4': 0.1594979374248564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013580263519104646, 'l1_Layer_2': 3.51771376003055e-05, 'l1_Layer_3': 0.00013896309315393956, 'l1_Layer_4': 0.000519794226650108, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95, 'n_units_Layer_4': 235}. Best is trial 74 with value: 20.96368363667689.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.58 | sMAPE for Validation Set is: 43.28% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 103.71 | sMAPE for Test Set is: 82.42% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:05:54,437]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:06:12,065]\u001b[0m Trial 89 finished with value: 20.34116402806517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0363315111709512, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36469378986896456, 'dropout_rate_Layer_2': 0.011396006037802851, 'dropout_rate_Layer_3': 0.013496779073761928, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046014581399066526, 'l1_Layer_2': 1.624544555035832e-05, 'l1_Layer_3': 0.043567158887058734, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 220}. Best is trial 89 with value: 20.34116402806517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.34 | sMAPE for Validation Set is: 30.10% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 64.63 | sMAPE for Test Set is: 55.57% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:06:27,286]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:06:31,123]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:06:36,916]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:06:43,193]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:06:48,039]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:06:51,917]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:01,458]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:06,022]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:12,966]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:18,276]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:22,291]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:27,497]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:31,915]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:43,669]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:07:55,819]\u001b[0m Trial 104 finished with value: 21.04428393082246 and parameters: {'n_hidden': 3, 'learning_rate': 0.01936886193416385, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3327999233837361, 'dropout_rate_Layer_2': 0.2777411475667876, 'dropout_rate_Layer_3': 0.3341868286831832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07809007124063094, 'l1_Layer_2': 0.00013477571237641197, 'l1_Layer_3': 0.016383312394519407, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 80}. Best is trial 89 with value: 20.34116402806517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.04 | sMAPE for Validation Set is: 31.37% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.55 | sMAPE for Test Set is: 54.60% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:08:03,126]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:08:06,743]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:08:20,035]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:08:34,075]\u001b[0m Trial 108 finished with value: 22.147852046529678 and parameters: {'n_hidden': 3, 'learning_rate': 0.015702805520366996, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30435997305939005, 'dropout_rate_Layer_2': 0.2792448539938714, 'dropout_rate_Layer_3': 0.3388812728015964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09767849260235754, 'l1_Layer_2': 0.0001390195137405063, 'l1_Layer_3': 0.022447983756995936, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 89 with value: 20.34116402806517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.15 | sMAPE for Validation Set is: 32.90% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 63.82 | sMAPE for Test Set is: 55.77% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:08:43,099]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:08:57,438]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:09:10,949]\u001b[0m Trial 111 finished with value: 29.467149611368523 and parameters: {'n_hidden': 4, 'learning_rate': 0.009995414260754832, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24379004423225173, 'dropout_rate_Layer_2': 0.3706613780077204, 'dropout_rate_Layer_3': 0.0878463268487518, 'dropout_rate_Layer_4': 0.2078586613140465, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026074714235101086, 'l1_Layer_2': 8.029525611058423e-05, 'l1_Layer_3': 0.003966689141807911, 'l1_Layer_4': 1.1296584017399049e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 115, 'n_units_Layer_4': 275}. Best is trial 89 with value: 20.34116402806517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.47 | sMAPE for Validation Set is: 40.52% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 104.66 | sMAPE for Test Set is: 83.31% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:09:18,175]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:09:38,624]\u001b[0m Trial 113 finished with value: 21.09462029087033 and parameters: {'n_hidden': 3, 'learning_rate': 0.07552269763128468, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34805957661306347, 'dropout_rate_Layer_2': 0.0009312233302710173, 'dropout_rate_Layer_3': 0.033760419123399985, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00290941379254462, 'l1_Layer_2': 7.231106658068285e-05, 'l1_Layer_3': 0.030315680898147648, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 170}. Best is trial 89 with value: 20.34116402806517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.09 | sMAPE for Validation Set is: 31.65% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 60.83 | sMAPE for Test Set is: 54.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:09:50,344]\u001b[0m Trial 114 finished with value: 21.627420242130203 and parameters: {'n_hidden': 3, 'learning_rate': 0.018731948669302063, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34260408752494154, 'dropout_rate_Layer_2': 0.2788197352975621, 'dropout_rate_Layer_3': 0.2808065485684878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09472494789416504, 'l1_Layer_2': 0.00020367060207983632, 'l1_Layer_3': 0.030568485830956085, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80}. Best is trial 89 with value: 20.34116402806517.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.63 | sMAPE for Validation Set is: 32.23% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 62.28 | sMAPE for Test Set is: 54.68% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:09:53,280]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:09:56,176]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:07,089]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:12,576]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:16,679]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:31,270]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:42,157]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:45,632]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:50,128]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:10:56,357]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:11:00,216]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:11:25,897]\u001b[0m Trial 126 finished with value: 19.870393655846243 and parameters: {'n_hidden': 3, 'learning_rate': 0.007781541544442967, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34633475067904307, 'dropout_rate_Layer_2': 0.24100036511407036, 'dropout_rate_Layer_3': 0.2662805025011732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010253542637573297, 'l1_Layer_2': 0.0004185733553073206, 'l1_Layer_3': 0.04867255447229922, 'n_units_Layer_1': 185, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.87 | sMAPE for Validation Set is: 29.90% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.23 | sMAPE for Test Set is: 52.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:11:39,523]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:11:50,737]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:11:58,141]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:03,700]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:16,739]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:29,041]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:32,263]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:36,721]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:43,925]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:48,448]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:12:52,762]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:13:21,906]\u001b[0m Trial 138 finished with value: 19.890462088345014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031167445914121873, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1985037299714581, 'dropout_rate_Layer_2': 0.1318079545157866, 'dropout_rate_Layer_3': 0.07894729649006345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011264765000210928, 'l1_Layer_2': 0.07397655060509639, 'l1_Layer_3': 1.886314940527639e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.89 | sMAPE for Validation Set is: 29.43% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.64 | sMAPE for Test Set is: 54.07% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:13:26,535]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:13:31,344]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:13:40,764]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:13:47,350]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:13:55,718]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:14:15,427]\u001b[0m Trial 144 finished with value: 29.86353662691192 and parameters: {'n_hidden': 4, 'learning_rate': 0.022703382702427145, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1847827157894366, 'dropout_rate_Layer_2': 0.34844871728461674, 'dropout_rate_Layer_3': 0.03268281470720534, 'dropout_rate_Layer_4': 0.24203776856952958, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0034652785704917892, 'l1_Layer_2': 1.9282478250695115e-05, 'l1_Layer_3': 0.017459030301514456, 'l1_Layer_4': 1.0904545281066254e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 65, 'n_units_Layer_4': 250}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.86 | sMAPE for Validation Set is: 41.27% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 108.90 | sMAPE for Test Set is: 87.34% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:14:21,311]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:14:25,112]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:14:29,239]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:14:52,048]\u001b[0m Trial 148 finished with value: 21.379909116990962 and parameters: {'n_hidden': 3, 'learning_rate': 0.022917590595149574, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3375206883306861, 'dropout_rate_Layer_2': 0.2921017588357312, 'dropout_rate_Layer_3': 0.27176615182446007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03662026655805222, 'l1_Layer_2': 0.0003090699416573152, 'l1_Layer_3': 0.02805637722680886, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 85}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.38 | sMAPE for Validation Set is: 30.66% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 63.88 | sMAPE for Test Set is: 55.32% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:14:55,636]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:15:00,922]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:15:14,304]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:15:21,379]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:15:26,162]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:15:30,283]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:15:55,274]\u001b[0m Trial 155 finished with value: 20.998919998522805 and parameters: {'n_hidden': 3, 'learning_rate': 0.009854282176541175, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3343610140729531, 'dropout_rate_Layer_2': 0.30220063808164654, 'dropout_rate_Layer_3': 0.25102530277712704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03238409522373421, 'l1_Layer_2': 0.0014381313429869206, 'l1_Layer_3': 0.04293073847021647, 'n_units_Layer_1': 145, 'n_units_Layer_2': 50, 'n_units_Layer_3': 80}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.00 | sMAPE for Validation Set is: 31.67% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 61.17 | sMAPE for Test Set is: 54.57% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:16:01,093]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:16:18,432]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:16:26,656]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:16:45,704]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:16:49,741]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:17:11,074]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:17:17,553]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:17:34,290]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:17:37,750]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:17:43,364]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:17:58,810]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:18:16,529]\u001b[0m Trial 167 finished with value: 20.647961868524998 and parameters: {'n_hidden': 3, 'learning_rate': 0.010372252596156243, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3267572186723064, 'dropout_rate_Layer_2': 0.25412006527845754, 'dropout_rate_Layer_3': 0.19708177117754336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.042674306142373934, 'l1_Layer_2': 0.0008046909613850702, 'l1_Layer_3': 0.010642323550508622, 'n_units_Layer_1': 95, 'n_units_Layer_2': 50, 'n_units_Layer_3': 75}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.65 | sMAPE for Validation Set is: 29.84% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 63.22 | sMAPE for Test Set is: 54.87% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:18:35,922]\u001b[0m Trial 168 finished with value: 21.45514287427484 and parameters: {'n_hidden': 3, 'learning_rate': 0.010096852391977445, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.275255317216112, 'dropout_rate_Layer_2': 0.23799209617390107, 'dropout_rate_Layer_3': 0.20629535633504967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007031551489122352, 'l1_Layer_2': 0.002355757805657403, 'l1_Layer_3': 0.09739503214845349, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.46 | sMAPE for Validation Set is: 32.02% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 62.93 | sMAPE for Test Set is: 55.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:18:39,634]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:19:03,373]\u001b[0m Trial 170 finished with value: 20.669605516663697 and parameters: {'n_hidden': 3, 'learning_rate': 0.047596819814305295, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2872171459725101, 'dropout_rate_Layer_2': 0.03866689418501322, 'dropout_rate_Layer_3': 0.06044304048157089, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025293627853418704, 'l1_Layer_2': 2.1606772716275944e-05, 'l1_Layer_3': 0.015644777788812105, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 135}. Best is trial 126 with value: 19.870393655846243.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.67 | sMAPE for Validation Set is: 31.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 60.37 | sMAPE for Test Set is: 54.09% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:19:07,519]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:19:14,599]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:20:16,903]\u001b[0m Trial 173 finished with value: 19.84137239560069 and parameters: {'n_hidden': 3, 'learning_rate': 0.004897499306740949, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36968809369524114, 'dropout_rate_Layer_2': 0.31387613349126525, 'dropout_rate_Layer_3': 0.17806315087899519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028727946928850776, 'l1_Layer_2': 0.0006323721393858777, 'l1_Layer_3': 0.03972837702925649, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 65}. Best is trial 173 with value: 19.84137239560069.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.84 | sMAPE for Validation Set is: 29.80% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.83 | sMAPE for Test Set is: 52.46% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:20:22,034]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:20:25,955]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:20:30,413]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:20:38,302]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:20:52,726]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:20:57,077]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:21:02,166]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:21:44,990]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:21:50,487]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:21:55,153]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:22:09,382]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:22:13,809]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:22:39,382]\u001b[0m Trial 186 finished with value: 19.2971444359505 and parameters: {'n_hidden': 3, 'learning_rate': 0.03614330744273077, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29947761234362463, 'dropout_rate_Layer_2': 0.06839790580839054, 'dropout_rate_Layer_3': 0.008684810012190038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021920296799977615, 'l1_Layer_2': 2.095183722745957e-05, 'l1_Layer_3': 0.040623169059012525, 'n_units_Layer_1': 105, 'n_units_Layer_2': 105, 'n_units_Layer_3': 140}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.30 | sMAPE for Validation Set is: 28.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.71 | sMAPE for Test Set is: 52.34% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:22:43,888]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:22:53,752]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:22:57,960]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:23:02,868]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:23:07,325]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:23:11,595]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:23:21,816]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:23:31,861]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:23:36,288]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:24:05,722]\u001b[0m Trial 196 finished with value: 21.933213588456653 and parameters: {'n_hidden': 3, 'learning_rate': 0.010240423149849347, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31523565079422755, 'dropout_rate_Layer_2': 0.31078359621143775, 'dropout_rate_Layer_3': 0.26198362291892274, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01871034250894981, 'l1_Layer_2': 0.0011699418709598096, 'l1_Layer_3': 0.03593087778789858, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 70}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.93 | sMAPE for Validation Set is: 32.33% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 63.41 | sMAPE for Test Set is: 55.73% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:24:17,624]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:24:22,031]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:24:36,530]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:24:42,887]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:24:51,374]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:24:56,300]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:01,160]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:19,801]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:26,320]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:33,704]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:40,935]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:45,783]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:25:59,861]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:26:26,062]\u001b[0m Trial 210 finished with value: 19.97723816274709 and parameters: {'n_hidden': 3, 'learning_rate': 0.023130363197785456, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3513309207655526, 'dropout_rate_Layer_2': 0.06541857949121284, 'dropout_rate_Layer_3': 0.0774903635430232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021109591847885854, 'l1_Layer_2': 4.9421804669424435e-05, 'l1_Layer_3': 0.0092340142861084, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.98 | sMAPE for Validation Set is: 30.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.44 | sMAPE for Test Set is: 53.30% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:26:40,191]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:26:46,130]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:26:50,255]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:26:55,770]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:27:01,831]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:27:05,777]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:27:11,743]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:27:15,403]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:27:26,822]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:27:47,510]\u001b[0m Trial 220 finished with value: 19.511158850188583 and parameters: {'n_hidden': 3, 'learning_rate': 0.020523187007308253, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33393155687905396, 'dropout_rate_Layer_2': 0.0748509240635697, 'dropout_rate_Layer_3': 0.04415789552125711, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022262638061685707, 'l1_Layer_2': 5.542043369271731e-05, 'l1_Layer_3': 0.023127133346821704, 'n_units_Layer_1': 70, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.51 | sMAPE for Validation Set is: 28.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.10 | sMAPE for Test Set is: 53.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:27:59,909]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:28:10,701]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:28:24,664]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:28:31,420]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:28:36,904]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:28:49,747]\u001b[0m Trial 226 finished with value: 19.72992748545757 and parameters: {'n_hidden': 3, 'learning_rate': 0.019154525548500684, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3319710025704485, 'dropout_rate_Layer_2': 0.08374081943860588, 'dropout_rate_Layer_3': 0.0695398257929492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00127683902847937, 'l1_Layer_2': 6.44227471139419e-05, 'l1_Layer_3': 0.011210059729238255, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 115}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.73 | sMAPE for Validation Set is: 29.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.57 | sMAPE for Test Set is: 52.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:29:03,297]\u001b[0m Trial 227 finished with value: 20.140826602128634 and parameters: {'n_hidden': 3, 'learning_rate': 0.020443102577797082, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.331873413257784, 'dropout_rate_Layer_2': 0.09691085623335811, 'dropout_rate_Layer_3': 0.07024608635885396, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007906316069327524, 'l1_Layer_2': 6.46757057160009e-05, 'l1_Layer_3': 0.010642409463880577, 'n_units_Layer_1': 65, 'n_units_Layer_2': 130, 'n_units_Layer_3': 125}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.14 | sMAPE for Validation Set is: 30.11% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 61.10 | sMAPE for Test Set is: 54.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:29:12,916]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:29:26,569]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:16,737]\u001b[0m Trial 230 finished with value: 20.865978135207957 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026427671145700733, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28966792110456946, 'dropout_rate_Layer_2': 0.3027879230519508, 'dropout_rate_Layer_3': 0.19132535776199275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01193444918576841, 'l1_Layer_2': 0.0004667350216053449, 'l1_Layer_3': 0.027645378027994126, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 80}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.87 | sMAPE for Validation Set is: 31.72% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 60.97 | sMAPE for Test Set is: 54.27% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:30:20,118]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:23,478]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:28,857]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:32,829]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:39,023]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:46,846]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:30:59,001]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:31:04,723]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:31:09,723]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:31:38,867]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:32:02,773]\u001b[0m Trial 241 finished with value: 20.02412261126872 and parameters: {'n_hidden': 3, 'learning_rate': 0.02461735214757111, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37389244056141707, 'dropout_rate_Layer_2': 0.09302783243930192, 'dropout_rate_Layer_3': 0.05260372537053598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7070497939223046e-05, 'l1_Layer_2': 9.261379776865463e-05, 'l1_Layer_3': 0.01856306350669762, 'n_units_Layer_1': 65, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.02 | sMAPE for Validation Set is: 30.05% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.43 | sMAPE for Test Set is: 54.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:32:55,901]\u001b[0m Trial 242 finished with value: 19.48468863482138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028790578232894505, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3793004086189398, 'dropout_rate_Layer_2': 0.3511065129410566, 'dropout_rate_Layer_3': 0.19242756188398086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028182284275178157, 'l1_Layer_2': 0.0003641448072748487, 'l1_Layer_3': 0.008593430265764122, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 150}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.48 | sMAPE for Validation Set is: 29.07% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.48 | sMAPE for Test Set is: 52.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:33:01,366]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:33:05,516]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:33:27,271]\u001b[0m Trial 245 finished with value: 19.46171308527002 and parameters: {'n_hidden': 3, 'learning_rate': 0.020407196846358968, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38326514314324367, 'dropout_rate_Layer_2': 0.0904802969867065, 'dropout_rate_Layer_3': 0.05664044030602612, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3194878799195607e-05, 'l1_Layer_2': 0.0001103929387496525, 'l1_Layer_3': 0.01668462609287874, 'n_units_Layer_1': 65, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.46 | sMAPE for Validation Set is: 29.04% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.92 | sMAPE for Test Set is: 53.59% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:33:30,653]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:33:35,775]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:33:39,008]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:33:45,539]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:33:51,359]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:34:07,207]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:34:18,961]\u001b[0m Trial 252 finished with value: 20.900639714078086 and parameters: {'n_hidden': 3, 'learning_rate': 0.026180237593622865, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3802937065591079, 'dropout_rate_Layer_2': 0.09255557040612299, 'dropout_rate_Layer_3': 0.10169838834915988, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2396696479290849e-05, 'l1_Layer_2': 4.746247040843525e-05, 'l1_Layer_3': 0.014561301598211592, 'n_units_Layer_1': 50, 'n_units_Layer_2': 125, 'n_units_Layer_3': 105}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.90 | sMAPE for Validation Set is: 31.95% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 60.94 | sMAPE for Test Set is: 54.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:34:24,082]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:34:29,445]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:34:38,015]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:34:43,298]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:35:04,661]\u001b[0m Trial 257 finished with value: 19.440084747910447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029857315532775815, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1265152862875034, 'dropout_rate_Layer_2': 0.16690761737931248, 'dropout_rate_Layer_3': 0.1074739989511572, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003757218457378823, 'l1_Layer_2': 0.00024294559753912723, 'l1_Layer_3': 4.2098251507739964e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.44 | sMAPE for Validation Set is: 28.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 62.60 | sMAPE for Test Set is: 55.14% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:35:48,907]\u001b[0m Trial 258 finished with value: 19.500292739477462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024655221393678583, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35581804809439926, 'dropout_rate_Layer_2': 0.3490876339329728, 'dropout_rate_Layer_3': 0.20298791265896635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033593395940054636, 'l1_Layer_2': 0.0005110120272336109, 'l1_Layer_3': 0.01188831046816685, 'n_units_Layer_1': 275, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 28.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.17 | sMAPE for Test Set is: 52.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:36:00,803]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:05,015]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:22,498]\u001b[0m Trial 261 finished with value: 20.377044469543232 and parameters: {'n_hidden': 3, 'learning_rate': 0.019236035737855532, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3775051477175924, 'dropout_rate_Layer_2': 0.08739486621069124, 'dropout_rate_Layer_3': 0.05348049920637353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.450050073976233e-05, 'l1_Layer_2': 3.7057228123679677e-05, 'l1_Layer_3': 0.007643615651439724, 'n_units_Layer_1': 85, 'n_units_Layer_2': 140, 'n_units_Layer_3': 105}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.38 | sMAPE for Validation Set is: 30.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 65.00 | sMAPE for Test Set is: 55.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:36:26,950]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:31,745]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:35,154]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:39,128]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:44,320]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:49,393]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:36:59,501]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:37:04,894]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:37:19,750]\u001b[0m Trial 270 finished with value: 19.503278844358757 and parameters: {'n_hidden': 3, 'learning_rate': 0.01898044645562021, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34392023622631046, 'dropout_rate_Layer_2': 0.09707416696968317, 'dropout_rate_Layer_3': 0.05230757757582403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1077376484814578e-05, 'l1_Layer_2': 7.173218818759811e-05, 'l1_Layer_3': 0.02409787923129955, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120}. Best is trial 186 with value: 19.2971444359505.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 28.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 60.70 | sMAPE for Test Set is: 53.86% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:37:25,450]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:38:17,682]\u001b[0m Trial 272 finished with value: 18.873902493087055 and parameters: {'n_hidden': 3, 'learning_rate': 0.004339025527718613, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.377057217013024, 'dropout_rate_Layer_2': 0.34380151626762234, 'dropout_rate_Layer_3': 0.16700133816090013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012397877150589624, 'l1_Layer_2': 0.0005976554831642067, 'l1_Layer_3': 0.001932600965755994, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 150}. Best is trial 272 with value: 18.873902493087055.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.87 | sMAPE for Validation Set is: 27.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.37 | sMAPE for Test Set is: 51.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:38:28,177]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:38:33,926]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:38:39,931]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:38:43,397]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:25,127]\u001b[0m Trial 277 finished with value: 18.849794846487892 and parameters: {'n_hidden': 3, 'learning_rate': 0.00391205387440579, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3802336474162537, 'dropout_rate_Layer_2': 0.3520742872354482, 'dropout_rate_Layer_3': 0.15882053008276178, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008818560695935819, 'l1_Layer_2': 0.0005112261219808836, 'l1_Layer_3': 0.0018676691650985823, 'n_units_Layer_1': 300, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 28.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.40 | sMAPE for Test Set is: 51.38% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:39:28,520]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:39,254]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:42,702]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:46,012]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:50,225]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:54,610]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:39:58,246]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:04,341]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:09,885]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:14,012]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:20,066]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:31,239]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:35,311]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:40:52,240]\u001b[0m Trial 291 finished with value: 21.57965111065788 and parameters: {'n_hidden': 3, 'learning_rate': 0.003629319073512195, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23443997403619796, 'dropout_rate_Layer_2': 0.09967026403345769, 'dropout_rate_Layer_3': 0.12735799932856473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006094569633359965, 'l1_Layer_2': 0.00019724733838788618, 'l1_Layer_3': 3.454464996313094e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.58 | sMAPE for Validation Set is: 38.29% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 62.23 | sMAPE for Test Set is: 56.42% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:40:56,492]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:00,285]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:05,667]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:09,804]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:14,198]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:29,153]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:33,035]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:36,908]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:42,698]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:41:58,416]\u001b[0m Trial 301 finished with value: 26.575412102727366 and parameters: {'n_hidden': 3, 'learning_rate': 0.005449448454034198, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13491001240116518, 'dropout_rate_Layer_2': 0.18048327913715337, 'dropout_rate_Layer_3': 0.1165129481026286, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003041445597228652, 'l1_Layer_2': 0.00020193272206768233, 'l1_Layer_3': 4.4753636413316506e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 255, 'n_units_Layer_3': 75}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.58 | sMAPE for Validation Set is: 37.67% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 101.34 | sMAPE for Test Set is: 80.64% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:42:01,955]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:42:12,808]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:42:43,878]\u001b[0m Trial 304 finished with value: 19.351439251955217 and parameters: {'n_hidden': 3, 'learning_rate': 0.002024202347349902, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.395323720739424, 'dropout_rate_Layer_2': 0.3486432841088255, 'dropout_rate_Layer_3': 0.10839073275457704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015363681759638767, 'l1_Layer_2': 0.00010154481771922194, 'l1_Layer_3': 0.0016868561320817549, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.35 | sMAPE for Validation Set is: 28.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.52 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:42:56,698]\u001b[0m Trial 305 finished with value: 20.867189329335368 and parameters: {'n_hidden': 3, 'learning_rate': 0.02667138514013202, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3318603497248118, 'dropout_rate_Layer_2': 0.08175479997073234, 'dropout_rate_Layer_3': 0.0703226548599998, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.5096423771934804e-05, 'l1_Layer_2': 5.821371839653581e-05, 'l1_Layer_3': 0.017401163580462807, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 110}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.87 | sMAPE for Validation Set is: 31.35% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 62.72 | sMAPE for Test Set is: 55.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:43:14,181]\u001b[0m Trial 306 finished with value: 19.71471749437588 and parameters: {'n_hidden': 3, 'learning_rate': 0.02590719583492341, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3348563502598349, 'dropout_rate_Layer_2': 0.07927691002193962, 'dropout_rate_Layer_3': 0.07831133307204222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019191689948615048, 'l1_Layer_2': 5.899505497299124e-05, 'l1_Layer_3': 0.016385189440399173, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 110}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.71 | sMAPE for Validation Set is: 29.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.98 | sMAPE for Test Set is: 53.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:43:28,588]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:43:34,896]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:43:38,737]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:43:48,869]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:43:52,451]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:43:58,805]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:44:11,591]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:44:15,310]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:44:19,291]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:44:28,612]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:44:38,652]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:44:43,135]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:45:46,461]\u001b[0m Trial 319 finished with value: 30.750888940531002 and parameters: {'n_hidden': 4, 'learning_rate': 0.018505973736626862, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26225147110709635, 'dropout_rate_Layer_2': 0.370901241585152, 'dropout_rate_Layer_3': 0.06297176991696729, 'dropout_rate_Layer_4': 0.20779158530838684, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0070597206456725565, 'l1_Layer_2': 1.3504238215873859e-05, 'l1_Layer_3': 0.010721053080452935, 'l1_Layer_4': 0.00014173408548980701, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 115, 'n_units_Layer_4': 280}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.75 | sMAPE for Validation Set is: 40.63% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 111.06 | sMAPE for Test Set is: 89.49% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:45:58,659]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:46:04,866]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:46:16,864]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:46:28,715]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:46:36,999]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:46:55,307]\u001b[0m Trial 325 finished with value: 29.189936071636513 and parameters: {'n_hidden': 4, 'learning_rate': 0.011656248558500181, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22674394443727025, 'dropout_rate_Layer_2': 0.38947121527539774, 'dropout_rate_Layer_3': 0.03245410564858736, 'dropout_rate_Layer_4': 0.2383912495979636, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0036216239767071904, 'l1_Layer_2': 1.2845922346800891e-05, 'l1_Layer_3': 0.007779256854062796, 'l1_Layer_4': 1.4104685961359044e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 295, 'n_units_Layer_3': 110, 'n_units_Layer_4': 250}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.19 | sMAPE for Validation Set is: 38.67% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 109.08 | sMAPE for Test Set is: 87.72% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:47:02,067]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:47:06,132]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:47:20,959]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:47:48,263]\u001b[0m Trial 329 finished with value: 20.602472390471444 and parameters: {'n_hidden': 4, 'learning_rate': 0.0043861303868998735, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17626524695016293, 'dropout_rate_Layer_2': 0.22513043222276607, 'dropout_rate_Layer_3': 0.0642648480330549, 'dropout_rate_Layer_4': 0.30207032364517916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010883159278503654, 'l1_Layer_2': 0.00022620892527167762, 'l1_Layer_3': 1.8258478380640575e-05, 'l1_Layer_4': 0.09401451285735768, 'n_units_Layer_1': 150, 'n_units_Layer_2': 260, 'n_units_Layer_3': 265, 'n_units_Layer_4': 155}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.60 | sMAPE for Validation Set is: 30.44% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 60.88 | sMAPE for Test Set is: 53.42% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:47:51,950]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:48:09,787]\u001b[0m Trial 331 finished with value: 19.073691040053273 and parameters: {'n_hidden': 3, 'learning_rate': 0.021764195565407034, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25679198410805953, 'dropout_rate_Layer_2': 0.08020347009410764, 'dropout_rate_Layer_3': 0.0012782529636423201, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.274246863936896e-05, 'l1_Layer_2': 3.817871973565927e-05, 'l1_Layer_3': 0.023839318855379755, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 210}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.07 | sMAPE for Validation Set is: 28.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.51 | sMAPE for Test Set is: 53.07% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:48:20,850]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:48:33,806]\u001b[0m Trial 333 finished with value: 20.676723132242262 and parameters: {'n_hidden': 3, 'learning_rate': 0.022152064548806367, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32181672248957166, 'dropout_rate_Layer_2': 0.0794333545121582, 'dropout_rate_Layer_3': 0.0002200869422350634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.819342186136575e-05, 'l1_Layer_2': 3.516247263659953e-05, 'l1_Layer_3': 0.014234778012209143, 'n_units_Layer_1': 195, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.68 | sMAPE for Validation Set is: 30.60% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 61.81 | sMAPE for Test Set is: 54.39% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:48:38,056]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:48:54,916]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:49:06,634]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:49:17,868]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:49:35,412]\u001b[0m Trial 338 finished with value: 30.723513088503534 and parameters: {'n_hidden': 4, 'learning_rate': 0.0315135583611159, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20000052242335875, 'dropout_rate_Layer_2': 0.3597413011859131, 'dropout_rate_Layer_3': 0.001491039842341113, 'dropout_rate_Layer_4': 0.26350650039943313, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013847530937337186, 'l1_Layer_2': 4.477965636732771e-05, 'l1_Layer_3': 0.010999520333908178, 'l1_Layer_4': 1.0126194395721367e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 255, 'n_units_Layer_3': 80, 'n_units_Layer_4': 210}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.72 | sMAPE for Validation Set is: 42.12% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 108.50 | sMAPE for Test Set is: 87.00% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:49:38,710]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:49:48,044]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:49:54,623]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:49:58,426]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:50:15,359]\u001b[0m Trial 343 finished with value: 19.39234036142378 and parameters: {'n_hidden': 3, 'learning_rate': 0.02338560044961589, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24607487610581674, 'dropout_rate_Layer_2': 0.05250756521807015, 'dropout_rate_Layer_3': 0.010598595035618025, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002240610961075846, 'l1_Layer_2': 4.696413007719168e-05, 'l1_Layer_3': 0.011166395289699442, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.39 | sMAPE for Validation Set is: 28.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.81 | sMAPE for Test Set is: 52.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:40,496]\u001b[0m Trial 344 finished with value: 19.594192561539415 and parameters: {'n_hidden': 3, 'learning_rate': 0.023282498785760292, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2508117160015163, 'dropout_rate_Layer_2': 0.05221136884236785, 'dropout_rate_Layer_3': 0.012274254037449962, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018049255113078587, 'l1_Layer_2': 4.559708865224057e-05, 'l1_Layer_3': 0.011645022762233323, 'n_units_Layer_1': 70, 'n_units_Layer_2': 120, 'n_units_Layer_3': 210}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.59 | sMAPE for Validation Set is: 28.96% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.33 | sMAPE for Test Set is: 52.90% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:50:59,285]\u001b[0m Trial 345 finished with value: 19.078975180010115 and parameters: {'n_hidden': 3, 'learning_rate': 0.02338436593630983, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2480299790450032, 'dropout_rate_Layer_2': 0.08424148367477187, 'dropout_rate_Layer_3': 0.010825629802353113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020275294344115615, 'l1_Layer_2': 4.6708389468471146e-05, 'l1_Layer_3': 0.01205382703529689, 'n_units_Layer_1': 70, 'n_units_Layer_2': 125, 'n_units_Layer_3': 220}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 28.22% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.24 | sMAPE for Test Set is: 51.93% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:51:02,754]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:08,777]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:26,693]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:30,631]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:34,707]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:51:46,419]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:29,165]\u001b[0m Trial 352 finished with value: 19.120744289098727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026206480333535133, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3545606326737703, 'dropout_rate_Layer_2': 0.34687840730088004, 'dropout_rate_Layer_3': 0.15794887181850303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005036949661482375, 'l1_Layer_2': 0.0001023555656533998, 'l1_Layer_3': 0.0053300700584126195, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 195}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 28.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.85 | sMAPE for Test Set is: 52.21% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:52:41,002]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:52:51,027]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:07,399]\u001b[0m Trial 355 finished with value: 31.278616808176707 and parameters: {'n_hidden': 4, 'learning_rate': 0.021266032760925507, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16903176388860983, 'dropout_rate_Layer_2': 0.3893545736749468, 'dropout_rate_Layer_3': 0.032052871544962606, 'dropout_rate_Layer_4': 0.2521280600564272, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00233190956531684, 'l1_Layer_2': 1.257867039176464e-05, 'l1_Layer_3': 0.007456670558041827, 'l1_Layer_4': 1.9114758870195348e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 255, 'n_units_Layer_3': 55, 'n_units_Layer_4': 180}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.28 | sMAPE for Validation Set is: 45.67% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 111.07 | sMAPE for Test Set is: 90.29% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:53:23,538]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:29,013]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:32,031]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:40,600]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:46,772]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:53:55,869]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:00,196]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:22,370]\u001b[0m Trial 363 finished with value: 19.148513227280514 and parameters: {'n_hidden': 3, 'learning_rate': 0.017824225937435146, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2643819016233113, 'dropout_rate_Layer_2': 0.09462637514567276, 'dropout_rate_Layer_3': 0.018885015070414516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023280515054721744, 'l1_Layer_2': 7.419160745362274e-05, 'l1_Layer_3': 0.02226053543701659, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.15 | sMAPE for Validation Set is: 28.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.52 | sMAPE for Test Set is: 52.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:54:29,690]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:54:53,216]\u001b[0m Trial 365 finished with value: 19.018997691454615 and parameters: {'n_hidden': 3, 'learning_rate': 0.01725409016765455, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2642960906223687, 'dropout_rate_Layer_2': 0.09367967578058164, 'dropout_rate_Layer_3': 0.0003855521667215987, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019087299865432911, 'l1_Layer_2': 4.8133732258494375e-05, 'l1_Layer_3': 0.02328159806177675, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.02 | sMAPE for Validation Set is: 28.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.14 | sMAPE for Test Set is: 51.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:55:02,260]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:55:25,450]\u001b[0m Trial 367 finished with value: 19.238677907895777 and parameters: {'n_hidden': 3, 'learning_rate': 0.016615974998487163, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26792566282859737, 'dropout_rate_Layer_2': 0.09083256352388624, 'dropout_rate_Layer_3': 0.017393462511718315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001975007677557357, 'l1_Layer_2': 5.177971106986976e-05, 'l1_Layer_3': 0.022485834133415723, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.24 | sMAPE for Validation Set is: 28.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.26 | sMAPE for Test Set is: 52.59% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:57:00,835]\u001b[0m Trial 368 finished with value: 19.466947203901228 and parameters: {'n_hidden': 3, 'learning_rate': 0.002646017735328648, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35092518809626966, 'dropout_rate_Layer_2': 0.3479295340684376, 'dropout_rate_Layer_3': 0.15075612118463624, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001222188219433224, 'l1_Layer_2': 0.00013445104629626235, 'l1_Layer_3': 0.00218945917485393, 'n_units_Layer_1': 270, 'n_units_Layer_2': 140, 'n_units_Layer_3': 190}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.47 | sMAPE for Validation Set is: 28.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 60.08 | sMAPE for Test Set is: 53.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:58:26,768]\u001b[0m Trial 369 finished with value: 19.74222767784498 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038265455446924498, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.351657895305285, 'dropout_rate_Layer_2': 0.344236764043088, 'dropout_rate_Layer_3': 0.14624568141126792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012848657382965795, 'l1_Layer_2': 0.00011611631091013658, 'l1_Layer_3': 0.002040566004976979, 'n_units_Layer_1': 270, 'n_units_Layer_2': 145, 'n_units_Layer_3': 195}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.74 | sMAPE for Validation Set is: 28.73% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 61.10 | sMAPE for Test Set is: 53.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:58:55,746]\u001b[0m Trial 370 finished with value: 20.108187406865028 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018910153955317155, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23890117682243678, 'dropout_rate_Layer_2': 0.1814788073226303, 'dropout_rate_Layer_3': 0.04924114914775503, 'dropout_rate_Layer_4': 0.2762675254531513, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006925105049913293, 'l1_Layer_2': 0.00010093499622823965, 'l1_Layer_3': 2.4378160006315437e-05, 'l1_Layer_4': 0.007725556870769502, 'n_units_Layer_1': 195, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240, 'n_units_Layer_4': 110}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.11 | sMAPE for Validation Set is: 30.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 59.31 | sMAPE for Test Set is: 53.74% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:59:10,717]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 02:59:26,505]\u001b[0m Trial 372 finished with value: 19.457097570509884 and parameters: {'n_hidden': 3, 'learning_rate': 0.015956864262836944, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27357384282197583, 'dropout_rate_Layer_2': 0.08088485762470422, 'dropout_rate_Layer_3': 0.017069913275347907, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019209266043127538, 'l1_Layer_2': 7.794760390343474e-05, 'l1_Layer_3': 0.02304872103076265, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.46 | sMAPE for Validation Set is: 28.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.67 | sMAPE for Test Set is: 52.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:59:49,043]\u001b[0m Trial 373 finished with value: 18.90158148166854 and parameters: {'n_hidden': 3, 'learning_rate': 0.016249179479461678, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2650732208304213, 'dropout_rate_Layer_2': 0.06466842165076181, 'dropout_rate_Layer_3': 0.016974297921417074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019556292424745213, 'l1_Layer_2': 7.710492877465222e-05, 'l1_Layer_3': 0.023253846616788733, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 27.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.97 | sMAPE for Test Set is: 51.77% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 02:59:52,584]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:13,244]\u001b[0m Trial 375 finished with value: 31.725794759845318 and parameters: {'n_hidden': 4, 'learning_rate': 0.018835299073823333, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1539028988873028, 'dropout_rate_Layer_2': 0.37268427619213107, 'dropout_rate_Layer_3': 0.011469193451267153, 'dropout_rate_Layer_4': 0.2748306761881447, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005646574567188738, 'l1_Layer_2': 1.0054306027982717e-05, 'l1_Layer_3': 0.011751156742747541, 'l1_Layer_4': 1.3601552574393444e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65, 'n_units_Layer_4': 185}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.73 | sMAPE for Validation Set is: 43.23% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 110.85 | sMAPE for Test Set is: 89.68% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:00:16,699]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:19,627]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:29,448]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:00:44,429]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:01:08,575]\u001b[0m Trial 380 finished with value: 19.370505482082706 and parameters: {'n_hidden': 3, 'learning_rate': 0.014671147898529113, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2804337453943018, 'dropout_rate_Layer_2': 0.05704124838672528, 'dropout_rate_Layer_3': 0.027164154524643422, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020857748475514963, 'l1_Layer_2': 0.002941365271022794, 'l1_Layer_3': 0.033626529846917434, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.37 | sMAPE for Validation Set is: 28.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.54 | sMAPE for Test Set is: 52.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:02:07,932]\u001b[0m Trial 381 finished with value: 19.282112375940695 and parameters: {'n_hidden': 3, 'learning_rate': 0.002552885699770943, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39351318331091945, 'dropout_rate_Layer_2': 0.3698559915196742, 'dropout_rate_Layer_3': 0.15701830891250534, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009161980703363161, 'l1_Layer_2': 6.662882945327072e-05, 'l1_Layer_3': 0.0038901655373827825, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.28 | sMAPE for Validation Set is: 29.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.07 | sMAPE for Test Set is: 51.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:02:14,690]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:02:34,484]\u001b[0m Trial 383 finished with value: 29.580045848873965 and parameters: {'n_hidden': 4, 'learning_rate': 0.017672215946282467, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1430391074027516, 'dropout_rate_Layer_2': 0.37110723051090433, 'dropout_rate_Layer_3': 0.020130045731851596, 'dropout_rate_Layer_4': 0.25788798049429185, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030804973530274993, 'l1_Layer_2': 1.995076540884424e-05, 'l1_Layer_3': 0.0059453652946033515, 'l1_Layer_4': 2.1300111605678583e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 295, 'n_units_Layer_3': 80, 'n_units_Layer_4': 145}. Best is trial 277 with value: 18.849794846487892.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.58 | sMAPE for Validation Set is: 40.69% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 106.89 | sMAPE for Test Set is: 85.51% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:04:14,498]\u001b[0m Trial 384 finished with value: 18.602600595890035 and parameters: {'n_hidden': 3, 'learning_rate': 0.002337466885928948, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3994788701161943, 'dropout_rate_Layer_2': 0.3753052255199323, 'dropout_rate_Layer_3': 0.12950044439773634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004912225442907616, 'l1_Layer_2': 3.34239754675044e-05, 'l1_Layer_3': 0.003719229695981828, 'n_units_Layer_1': 300, 'n_units_Layer_2': 210, 'n_units_Layer_3': 230}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 27.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.65 | sMAPE for Test Set is: 51.10% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:04:55,911]\u001b[0m Trial 385 finished with value: 19.235997248044452 and parameters: {'n_hidden': 3, 'learning_rate': 0.014922871054876618, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27556846903828064, 'dropout_rate_Layer_2': 0.06794701500746038, 'dropout_rate_Layer_3': 0.026507893579202173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020730103524197073, 'l1_Layer_2': 0.0028165431782821303, 'l1_Layer_3': 0.033408494514589375, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.24 | sMAPE for Validation Set is: 28.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.37 | sMAPE for Test Set is: 52.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:05:16,406]\u001b[0m Trial 386 finished with value: 19.40559871093632 and parameters: {'n_hidden': 3, 'learning_rate': 0.014799311762530609, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27926463073298147, 'dropout_rate_Layer_2': 0.05830912513768203, 'dropout_rate_Layer_3': 0.0263550255739014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018190196261121529, 'l1_Layer_2': 0.005082493195538898, 'l1_Layer_3': 0.034476581974575, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.41 | sMAPE for Validation Set is: 28.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.52 | sMAPE for Test Set is: 52.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:05:33,518]\u001b[0m Trial 387 finished with value: 20.21163444229289 and parameters: {'n_hidden': 3, 'learning_rate': 0.002736879309249578, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2093084974397823, 'dropout_rate_Layer_2': 0.18571062329964977, 'dropout_rate_Layer_3': 0.10393755389107481, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005959214762621193, 'l1_Layer_2': 0.0015256237653030736, 'l1_Layer_3': 2.4751326392271115e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 230, 'n_units_Layer_3': 155}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.21 | sMAPE for Validation Set is: 29.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 62.03 | sMAPE for Test Set is: 54.62% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:05:37,371]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:03,665]\u001b[0m Trial 389 finished with value: 19.165766331166086 and parameters: {'n_hidden': 3, 'learning_rate': 0.013533047121133084, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27759255359133295, 'dropout_rate_Layer_2': 0.06756257938045657, 'dropout_rate_Layer_3': 0.021435147033551823, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001490687773610521, 'l1_Layer_2': 0.0034636113129259244, 'l1_Layer_3': 0.03218927008331965, 'n_units_Layer_1': 60, 'n_units_Layer_2': 110, 'n_units_Layer_3': 225}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.17 | sMAPE for Validation Set is: 27.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 59.03 | sMAPE for Test Set is: 52.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:06:09,329]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:14,940]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:19,881]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:25,162]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:34,833]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:42,911]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:06:59,020]\u001b[0m Trial 396 finished with value: 30.227913571206827 and parameters: {'n_hidden': 4, 'learning_rate': 0.012807224686089228, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1942387648460215, 'dropout_rate_Layer_2': 0.33160459964680816, 'dropout_rate_Layer_3': 0.04466530793630641, 'dropout_rate_Layer_4': 0.21295102805272736, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001195050850129121, 'l1_Layer_2': 3.362134113935645e-05, 'l1_Layer_3': 0.0068572321053575365, 'l1_Layer_4': 1.962585248006201e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 290, 'n_units_Layer_3': 100, 'n_units_Layer_4': 145}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.23 | sMAPE for Validation Set is: 42.79% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 108.93 | sMAPE for Test Set is: 87.87% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:07:08,537]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:07:50,093]\u001b[0m Trial 398 finished with value: 27.04785758933542 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014094542730383132, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3160661213985745, 'dropout_rate_Layer_2': 0.18186561323324585, 'dropout_rate_Layer_3': 0.057913842215382524, 'dropout_rate_Layer_4': 0.2574253462442383, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002376222418021838, 'l1_Layer_2': 0.0004853081917300051, 'l1_Layer_3': 6.605067146118022e-05, 'l1_Layer_4': 0.0003117029989407607, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190, 'n_units_Layer_4': 110}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.05 | sMAPE for Validation Set is: 35.04% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 104.14 | sMAPE for Test Set is: 82.16% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:07:53,929]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:11,582]\u001b[0m Trial 400 finished with value: 18.892192884397243 and parameters: {'n_hidden': 3, 'learning_rate': 0.002248241149914427, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39755521595631604, 'dropout_rate_Layer_2': 0.37713111367334656, 'dropout_rate_Layer_3': 0.1338716375731474, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00048531061101135363, 'l1_Layer_2': 4.5598230949304954e-05, 'l1_Layer_3': 0.0037633932236852043, 'n_units_Layer_1': 285, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.89 | sMAPE for Validation Set is: 28.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.91 | sMAPE for Test Set is: 52.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:09:15,058]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:20,468]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:09:41,952]\u001b[0m Trial 403 finished with value: 18.97311958086779 and parameters: {'n_hidden': 3, 'learning_rate': 0.015412852791928945, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2697181615921702, 'dropout_rate_Layer_2': 0.047510015665530494, 'dropout_rate_Layer_3': 0.02437177576815019, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00250773404360501, 'l1_Layer_2': 0.00012599463199979038, 'l1_Layer_3': 0.04655066655265032, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.97 | sMAPE for Validation Set is: 28.11% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.11 | sMAPE for Test Set is: 51.68% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:10:05,719]\u001b[0m Trial 404 finished with value: 19.156426594816775 and parameters: {'n_hidden': 3, 'learning_rate': 0.003239632368968801, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.231043705048245, 'dropout_rate_Layer_2': 0.12284410394602564, 'dropout_rate_Layer_3': 0.02192686524659023, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002032287880176851, 'l1_Layer_2': 8.358409992999568e-05, 'l1_Layer_3': 0.00022673950551465672, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.16 | sMAPE for Validation Set is: 28.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.71 | sMAPE for Test Set is: 52.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:10:24,823]\u001b[0m Trial 405 finished with value: 18.945811220338673 and parameters: {'n_hidden': 3, 'learning_rate': 0.01491306477657955, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26851557312361884, 'dropout_rate_Layer_2': 0.04728656498514953, 'dropout_rate_Layer_3': 0.034174059387583736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026812949232661682, 'l1_Layer_2': 0.0001208023259056981, 'l1_Layer_3': 0.025409778496437465, 'n_units_Layer_1': 70, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.95 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.70 | sMAPE for Test Set is: 51.50% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:10:44,099]\u001b[0m Trial 406 finished with value: 19.008610394834587 and parameters: {'n_hidden': 3, 'learning_rate': 0.014712836636200672, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27188072774560507, 'dropout_rate_Layer_2': 0.047658766034572114, 'dropout_rate_Layer_3': 0.025630943536476956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026056067238814664, 'l1_Layer_2': 8.46798341551058e-05, 'l1_Layer_3': 0.02680476906693167, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.01 | sMAPE for Validation Set is: 28.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.93 | sMAPE for Test Set is: 52.53% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:12:04,710]\u001b[0m Trial 407 finished with value: 30.654405942985463 and parameters: {'n_hidden': 4, 'learning_rate': 0.014045061359106829, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19571910516630348, 'dropout_rate_Layer_2': 0.3311077525103077, 'dropout_rate_Layer_3': 0.055780728611979996, 'dropout_rate_Layer_4': 0.20625088161391406, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010254527758073067, 'l1_Layer_2': 5.8870334134889866e-05, 'l1_Layer_3': 0.017573596082757246, 'l1_Layer_4': 6.320776697917648e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 290, 'n_units_Layer_3': 100, 'n_units_Layer_4': 150}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.65 | sMAPE for Validation Set is: 42.89% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 110.32 | sMAPE for Test Set is: 89.47% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:12:16,336]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:19,343]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:28,590]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:31,606]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:48,448]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:12:55,384]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:01,041]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:13:22,504]\u001b[0m Trial 415 finished with value: 18.7761071305457 and parameters: {'n_hidden': 3, 'learning_rate': 0.014474030737413124, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24627264982973052, 'dropout_rate_Layer_2': 0.06493620828056743, 'dropout_rate_Layer_3': 0.007793971016939219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018164599936951824, 'l1_Layer_2': 0.00010103413432727766, 'l1_Layer_3': 0.025145516476047392, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.78 | sMAPE for Validation Set is: 27.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.01 | sMAPE for Test Set is: 52.05% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:14:22,112]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:15:55,764]\u001b[0m Trial 417 finished with value: 18.927865448346576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023365248695552143, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3313878879904018, 'dropout_rate_Layer_2': 0.3955410426851646, 'dropout_rate_Layer_3': 0.12733284746205983, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023885899284295086, 'l1_Layer_2': 3.353551867509911e-05, 'l1_Layer_3': 0.006155831765967227, 'n_units_Layer_1': 250, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 27.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.58 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:15:59,297]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:07,133]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:18,231]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:29,954]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:16:56,138]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:17:33,059]\u001b[0m Trial 423 finished with value: 18.650909396687478 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023065418451165515, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33101670079687406, 'dropout_rate_Layer_2': 0.399361057673768, 'dropout_rate_Layer_3': 0.13129891843900054, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001916991220097411, 'l1_Layer_2': 3.430573364939593e-05, 'l1_Layer_3': 0.006285097116637711, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 260}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 27.48% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.06 | sMAPE for Test Set is: 51.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:17:37,965]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:18:03,631]\u001b[0m Trial 425 finished with value: 21.681166953340142 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008324382113790937, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38859175131971424, 'dropout_rate_Layer_2': 0.13300473323131903, 'dropout_rate_Layer_3': 0.02099871485269803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002512040058649653, 'l1_Layer_2': 0.0008811953303470608, 'l1_Layer_3': 0.00017472681690675846, 'n_units_Layer_1': 75, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.68 | sMAPE for Validation Set is: 31.94% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 70.49 | sMAPE for Test Set is: 58.75% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:18:57,504]\u001b[0m Trial 426 finished with value: 19.414782526002472 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017552256962217756, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33785126268027, 'dropout_rate_Layer_2': 0.3974249540085145, 'dropout_rate_Layer_3': 0.12594354981671074, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021236186235935062, 'l1_Layer_2': 1.8261231401124543e-05, 'l1_Layer_3': 0.006346216444000238, 'n_units_Layer_1': 230, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.41 | sMAPE for Validation Set is: 29.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.07 | sMAPE for Test Set is: 52.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:19:03,655]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:23,077]\u001b[0m Trial 428 finished with value: 19.39177368706165 and parameters: {'n_hidden': 3, 'learning_rate': 0.004540916686924126, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22005584862229877, 'dropout_rate_Layer_2': 0.08490259429878308, 'dropout_rate_Layer_3': 0.0020823975096233883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002441974165841754, 'l1_Layer_2': 0.0009970655303479065, 'l1_Layer_3': 0.0007067691688066179, 'n_units_Layer_1': 300, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.39 | sMAPE for Validation Set is: 28.69% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.64 | sMAPE for Test Set is: 53.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:19:26,699]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:35,004]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:19:51,527]\u001b[0m Trial 431 finished with value: 19.030763403465855 and parameters: {'n_hidden': 3, 'learning_rate': 0.004350304944229879, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21368061921044795, 'dropout_rate_Layer_2': 0.08177690272194407, 'dropout_rate_Layer_3': 0.02374003028222582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029942119874190126, 'l1_Layer_2': 0.0011363243393937097, 'l1_Layer_3': 0.0006662662557304625, 'n_units_Layer_1': 270, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.03 | sMAPE for Validation Set is: 28.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.66 | sMAPE for Test Set is: 52.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:20:09,938]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:20:37,098]\u001b[0m Trial 433 finished with value: 19.108222656345458 and parameters: {'n_hidden': 3, 'learning_rate': 0.004893945031920611, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22193499701410252, 'dropout_rate_Layer_2': 0.07428144142818335, 'dropout_rate_Layer_3': 0.02117705071047987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028405369000981603, 'l1_Layer_2': 0.0008013822979534664, 'l1_Layer_3': 0.0008820519569872689, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 280}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.11 | sMAPE for Validation Set is: 28.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.16 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:20:48,258]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:12,465]\u001b[0m Trial 435 finished with value: 29.6943850962321 and parameters: {'n_hidden': 4, 'learning_rate': 0.017329574433750924, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23394144515162124, 'dropout_rate_Layer_2': 0.3319519456478599, 'dropout_rate_Layer_3': 0.04420152014345587, 'dropout_rate_Layer_4': 0.21416347527770035, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017197446801704526, 'l1_Layer_2': 1.7674413888815307e-05, 'l1_Layer_3': 0.015544744366514401, 'l1_Layer_4': 2.0302158329056896e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.69 | sMAPE for Validation Set is: 39.21% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 110.80 | sMAPE for Test Set is: 89.26% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:21:36,934]\u001b[0m Trial 436 finished with value: 19.067763433844906 and parameters: {'n_hidden': 3, 'learning_rate': 0.005052623211861136, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22688553519452392, 'dropout_rate_Layer_2': 0.07334071034009657, 'dropout_rate_Layer_3': 0.001615803443435683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016461870114914436, 'l1_Layer_2': 0.001172447185415592, 'l1_Layer_3': 0.0008921032506391965, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.07 | sMAPE for Validation Set is: 28.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.43 | sMAPE for Test Set is: 52.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:21:42,072]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:21:47,229]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:02,923]\u001b[0m Trial 439 finished with value: 28.946497113320635 and parameters: {'n_hidden': 4, 'learning_rate': 0.017336147912201415, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23281271753299393, 'dropout_rate_Layer_2': 0.3246903574058615, 'dropout_rate_Layer_3': 0.07300962685226381, 'dropout_rate_Layer_4': 0.22470904738824912, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001105395176090315, 'l1_Layer_2': 4.056506081459655e-05, 'l1_Layer_3': 0.00740421188290515, 'l1_Layer_4': 2.049444510183957e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 295, 'n_units_Layer_3': 125, 'n_units_Layer_4': 150}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.95 | sMAPE for Validation Set is: 38.11% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 107.80 | sMAPE for Test Set is: 86.10% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:22:08,042]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:22:29,506]\u001b[0m Trial 441 finished with value: 19.24759727616772 and parameters: {'n_hidden': 3, 'learning_rate': 0.013397903326336214, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2564987758320671, 'dropout_rate_Layer_2': 0.06885113163094769, 'dropout_rate_Layer_3': 0.017621842488543513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003215579294137853, 'l1_Layer_2': 0.00021602901957819786, 'l1_Layer_3': 0.047170546147295295, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.25 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.07 | sMAPE for Test Set is: 52.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:22:34,134]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:23:06,496]\u001b[0m Trial 443 finished with value: 19.2555653160089 and parameters: {'n_hidden': 3, 'learning_rate': 0.013050982258615645, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25787358748079486, 'dropout_rate_Layer_2': 0.03869830179502705, 'dropout_rate_Layer_3': 0.016260701093686037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029722438235429685, 'l1_Layer_2': 0.00011002407652733644, 'l1_Layer_3': 0.049928681680151715, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.26 | sMAPE for Validation Set is: 27.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.84 | sMAPE for Test Set is: 52.25% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:23:29,499]\u001b[0m Trial 444 finished with value: 19.36578231955707 and parameters: {'n_hidden': 3, 'learning_rate': 0.012038756578497851, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25621332176530354, 'dropout_rate_Layer_2': 0.03389910281788461, 'dropout_rate_Layer_3': 0.019838829478300606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034789527598686576, 'l1_Layer_2': 0.000144656504241905, 'l1_Layer_3': 0.05468483115792745, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 200}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.37 | sMAPE for Validation Set is: 28.14% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.76 | sMAPE for Test Set is: 52.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:23:49,124]\u001b[0m Trial 445 finished with value: 19.02732232713278 and parameters: {'n_hidden': 3, 'learning_rate': 0.012043974903727848, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25838235885178523, 'dropout_rate_Layer_2': 0.03737309017881642, 'dropout_rate_Layer_3': 0.016188793116698234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0035656091485448452, 'l1_Layer_2': 0.0002219480333969912, 'l1_Layer_3': 0.03784550425822388, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.03 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.41 | sMAPE for Test Set is: 51.97% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:24:07,024]\u001b[0m Trial 446 finished with value: 19.0005786115586 and parameters: {'n_hidden': 3, 'learning_rate': 0.011662283933996317, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2536571223202253, 'dropout_rate_Layer_2': 0.035848148241453354, 'dropout_rate_Layer_3': 0.018037839431580865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0038010015408963724, 'l1_Layer_2': 0.0001448404689128743, 'l1_Layer_3': 0.0541033582308311, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.00 | sMAPE for Validation Set is: 27.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.35 | sMAPE for Test Set is: 51.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:24:12,505]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:16,284]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:35,464]\u001b[0m Trial 449 finished with value: 19.11924976587407 and parameters: {'n_hidden': 3, 'learning_rate': 0.012109011268709483, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26726107334152005, 'dropout_rate_Layer_2': 0.0289917053710108, 'dropout_rate_Layer_3': 0.02506501517870291, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031646321916749248, 'l1_Layer_2': 0.0002498364216795024, 'l1_Layer_3': 0.04810959989556251, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 27.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.01 | sMAPE for Test Set is: 52.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:24:38,486]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:51,355]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:24:57,175]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:02,210]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:33,678]\u001b[0m Trial 454 finished with value: 18.706355568088412 and parameters: {'n_hidden': 3, 'learning_rate': 0.006925383595193426, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2549318612453854, 'dropout_rate_Layer_2': 0.06181210084165777, 'dropout_rate_Layer_3': 0.024464942805330105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013377115314891643, 'l1_Layer_2': 0.00160718671782999, 'l1_Layer_3': 0.0011494263666807128, 'n_units_Layer_1': 295, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.71 | sMAPE for Validation Set is: 27.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.37 | sMAPE for Test Set is: 52.25% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:25:38,932]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:42,108]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:25:59,995]\u001b[0m Trial 457 finished with value: 18.715659914592788 and parameters: {'n_hidden': 3, 'learning_rate': 0.006697366436814628, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26362246984608095, 'dropout_rate_Layer_2': 0.06293745183589416, 'dropout_rate_Layer_3': 0.030955230435214302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.596299509839919e-05, 'l1_Layer_2': 0.002187974755750513, 'l1_Layer_3': 0.0007978828824452755, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 27.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.06 | sMAPE for Test Set is: 52.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:26:18,364]\u001b[0m Trial 458 finished with value: 19.051415060440036 and parameters: {'n_hidden': 3, 'learning_rate': 0.013281951668379866, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2633019254025354, 'dropout_rate_Layer_2': 0.03393659527668249, 'dropout_rate_Layer_3': 0.028007656850903097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029028825324888255, 'l1_Layer_2': 0.00012857575757953537, 'l1_Layer_3': 0.042052262951278646, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 195}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.05 | sMAPE for Validation Set is: 27.85% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.06 | sMAPE for Test Set is: 51.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:26:30,652]\u001b[0m Trial 459 finished with value: 29.87780706707548 and parameters: {'n_hidden': 4, 'learning_rate': 0.017364057568621374, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21567187128752488, 'dropout_rate_Layer_2': 0.34749855757964104, 'dropout_rate_Layer_3': 0.038332164011758346, 'dropout_rate_Layer_4': 0.2163190070531853, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001260464355379922, 'l1_Layer_2': 2.166832520356474e-05, 'l1_Layer_3': 0.005121500039401468, 'l1_Layer_4': 1.5167420185732454e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 285, 'n_units_Layer_3': 105, 'n_units_Layer_4': 150}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.88 | sMAPE for Validation Set is: 40.21% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 108.46 | sMAPE for Test Set is: 87.16% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:26:52,209]\u001b[0m Trial 460 finished with value: 19.036316538911517 and parameters: {'n_hidden': 3, 'learning_rate': 0.006703236640623675, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2641604166012009, 'dropout_rate_Layer_2': 0.04654084034594874, 'dropout_rate_Layer_3': 0.041360922014844294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010680479220027793, 'l1_Layer_2': 0.0028333985966586765, 'l1_Layer_3': 0.0017807641800779365, 'n_units_Layer_1': 275, 'n_units_Layer_2': 215, 'n_units_Layer_3': 290}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.04 | sMAPE for Validation Set is: 28.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.57 | sMAPE for Test Set is: 51.91% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:26:55,256]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:07,492]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:48,049]\u001b[0m Trial 463 finished with value: 18.646622751573833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022414080509620808, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3232937747244936, 'dropout_rate_Layer_2': 0.38565055022942063, 'dropout_rate_Layer_3': 0.13105916588004407, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005007032232067628, 'l1_Layer_2': 3.9106304722714395e-05, 'l1_Layer_3': 0.004963946677735006, 'n_units_Layer_1': 250, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285}. Best is trial 384 with value: 18.602600595890035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 27.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.74 | sMAPE for Test Set is: 51.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:27:51,846]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:27:59,557]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:21,039]\u001b[0m Trial 466 finished with value: 18.472032257113156 and parameters: {'n_hidden': 3, 'learning_rate': 0.006729372798420842, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2635239781884755, 'dropout_rate_Layer_2': 0.002371638883100907, 'dropout_rate_Layer_3': 0.039595920637548104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.11582765611122e-05, 'l1_Layer_2': 0.0024534056865058405, 'l1_Layer_3': 0.0017415652525137357, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 290}. Best is trial 466 with value: 18.472032257113156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.47 | sMAPE for Validation Set is: 27.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.92 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:28:26,745]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:30,573]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:28:54,205]\u001b[0m Trial 469 finished with value: 19.14718420642326 and parameters: {'n_hidden': 3, 'learning_rate': 0.012335809890549203, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24050470737207816, 'dropout_rate_Layer_2': 0.0437635259760326, 'dropout_rate_Layer_3': 0.005042772633958199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002739005364543055, 'l1_Layer_2': 0.00014678861489386794, 'l1_Layer_3': 0.048364049198089024, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190}. Best is trial 466 with value: 18.472032257113156.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.15 | sMAPE for Validation Set is: 27.88% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.12 | sMAPE for Test Set is: 52.33% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:29:33,850]\u001b[0m Trial 470 finished with value: 18.430243481706473 and parameters: {'n_hidden': 3, 'learning_rate': 0.002089873060884097, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3242619191675442, 'dropout_rate_Layer_2': 0.3844854978194514, 'dropout_rate_Layer_3': 0.1349475244579146, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015157473672212473, 'l1_Layer_2': 3.1994692549338e-05, 'l1_Layer_3': 0.0027479564025651598, 'n_units_Layer_1': 250, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.43 | sMAPE for Validation Set is: 28.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.81 | sMAPE for Test Set is: 50.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:29:44,824]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:29:50,351]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:29,690]\u001b[0m Trial 473 finished with value: 18.606704365623564 and parameters: {'n_hidden': 3, 'learning_rate': 0.002076832376221939, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3058095719421337, 'dropout_rate_Layer_2': 0.3842456112992141, 'dropout_rate_Layer_3': 0.08863645627837637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014145157284081234, 'l1_Layer_2': 3.9398970620765244e-05, 'l1_Layer_3': 0.0026282126480817202, 'n_units_Layer_1': 260, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.61 | sMAPE for Validation Set is: 27.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.97 | sMAPE for Test Set is: 52.00% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:30:33,305]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:37,122]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:48,951]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:30:59,502]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:03,197]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:08,505]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:19,972]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:23,735]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:31:46,693]\u001b[0m Trial 482 finished with value: 19.309149587351964 and parameters: {'n_hidden': 3, 'learning_rate': 0.010413051058437626, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2637279862021538, 'dropout_rate_Layer_2': 0.03672516793203044, 'dropout_rate_Layer_3': 0.030560233044414506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025498539735260032, 'l1_Layer_2': 0.0001357500665527229, 'l1_Layer_3': 0.031641756667914196, 'n_units_Layer_1': 60, 'n_units_Layer_2': 90, 'n_units_Layer_3': 210}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.31 | sMAPE for Validation Set is: 27.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.35 | sMAPE for Test Set is: 52.80% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:31:55,874]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:19,242]\u001b[0m Trial 484 finished with value: 19.204737519631838 and parameters: {'n_hidden': 3, 'learning_rate': 0.01003160781507092, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24755025547580065, 'dropout_rate_Layer_2': 0.037252011953540456, 'dropout_rate_Layer_3': 0.032564004677481516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027674015749461337, 'l1_Layer_2': 0.00013152122587164737, 'l1_Layer_3': 0.03424196315105327, 'n_units_Layer_1': 90, 'n_units_Layer_2': 95, 'n_units_Layer_3': 210}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.20 | sMAPE for Validation Set is: 27.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.94 | sMAPE for Test Set is: 52.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:32:30,920]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:36,656]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:39,654]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:50,442]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:32:57,626]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:08,404]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:16,497]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:33:43,205]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:06,888]\u001b[0m Trial 493 finished with value: 19.11746830708044 and parameters: {'n_hidden': 3, 'learning_rate': 0.008619445712574166, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26575229746469226, 'dropout_rate_Layer_2': 0.04220452485253684, 'dropout_rate_Layer_3': 0.25277879096546363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030815073761227964, 'l1_Layer_2': 0.0003436109908236171, 'l1_Layer_3': 0.04376573660141492, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 27.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.66 | sMAPE for Test Set is: 52.32% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:34:18,160]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:21,709]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:24,845]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:28,488]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:31,611]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:40,416]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:52,273]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:55,412]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:34:59,214]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:02,956]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:08,054]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:36,365]\u001b[0m Trial 505 finished with value: 19.130199435778394 and parameters: {'n_hidden': 3, 'learning_rate': 0.010126359932215575, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25147563303635323, 'dropout_rate_Layer_2': 0.043186278535246946, 'dropout_rate_Layer_3': 0.015321040495853628, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00240139157966241, 'l1_Layer_2': 0.00012511473851201934, 'l1_Layer_3': 0.037001158728303084, 'n_units_Layer_1': 70, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.13 | sMAPE for Validation Set is: 28.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.77 | sMAPE for Test Set is: 52.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:35:40,033]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:35:46,176]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:09,340]\u001b[0m Trial 508 finished with value: 18.932903116492895 and parameters: {'n_hidden': 3, 'learning_rate': 0.007049280549494317, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26073616833757496, 'dropout_rate_Layer_2': 0.04890859982969405, 'dropout_rate_Layer_3': 0.05034506002465522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012567763763367113, 'l1_Layer_2': 0.0033148500767180935, 'l1_Layer_3': 0.0015748605007653634, 'n_units_Layer_1': 285, 'n_units_Layer_2': 210, 'n_units_Layer_3': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.38 | sMAPE for Test Set is: 52.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:36:31,190]\u001b[0m Trial 509 finished with value: 19.016924731918166 and parameters: {'n_hidden': 3, 'learning_rate': 0.00941807802496567, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26405644649915316, 'dropout_rate_Layer_2': 0.04640843595152807, 'dropout_rate_Layer_3': 0.022872191727541256, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00244127849304858, 'l1_Layer_2': 0.00014843822098377897, 'l1_Layer_3': 0.036251482647107806, 'n_units_Layer_1': 70, 'n_units_Layer_2': 110, 'n_units_Layer_3': 205}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.02 | sMAPE for Validation Set is: 28.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.22 | sMAPE for Test Set is: 51.95% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:36:36,406]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:36:56,908]\u001b[0m Trial 511 finished with value: 18.639964060194 and parameters: {'n_hidden': 3, 'learning_rate': 0.008410425979108448, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2646915503392528, 'dropout_rate_Layer_2': 0.04474981084052533, 'dropout_rate_Layer_3': 0.006364563770641761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002645922445619804, 'l1_Layer_2': 0.00011115183007262734, 'l1_Layer_3': 0.035506706035724, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 205}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.64 | sMAPE for Validation Set is: 26.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.97 | sMAPE for Test Set is: 51.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:36:59,945]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:03,316]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:06,377]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:18,290]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:44,062]\u001b[0m Trial 516 finished with value: 18.94132174052978 and parameters: {'n_hidden': 3, 'learning_rate': 0.004270111349965861, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27107554935112804, 'dropout_rate_Layer_2': 0.3280260843695705, 'dropout_rate_Layer_3': 0.11568544459523958, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003636923860047913, 'l1_Layer_2': 7.175835722461453e-05, 'l1_Layer_3': 0.003006056742879796, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.94 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.50 | sMAPE for Test Set is: 51.98% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:37:54,046]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:37:59,065]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:02,922]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:08,176]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:14,089]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:36,579]\u001b[0m Trial 522 finished with value: 18.641420513421465 and parameters: {'n_hidden': 3, 'learning_rate': 0.007767097483911843, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28544171372886723, 'dropout_rate_Layer_2': 0.018937422732919207, 'dropout_rate_Layer_3': 0.026834400364162455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012814759108783537, 'l1_Layer_2': 0.0036383732648334307, 'l1_Layer_3': 0.003251778713093339, 'n_units_Layer_1': 285, 'n_units_Layer_2': 215, 'n_units_Layer_3': 300}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.64 | sMAPE for Validation Set is: 28.43% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.94 | sMAPE for Test Set is: 51.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:38:39,541]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:43,091]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:38:54,174]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:31,377]\u001b[0m Trial 526 finished with value: 19.733873594975453 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032077719873278183, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31840222848056576, 'dropout_rate_Layer_2': 0.39826733124614705, 'dropout_rate_Layer_3': 0.0979368032501446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008896885884403366, 'l1_Layer_2': 3.986454594016466e-05, 'l1_Layer_3': 0.0008752224689885912, 'n_units_Layer_1': 215, 'n_units_Layer_2': 210, 'n_units_Layer_3': 270}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.73 | sMAPE for Validation Set is: 29.17% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.99 | sMAPE for Test Set is: 53.44% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:39:39,027]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:39:42,084]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:09,090]\u001b[0m Trial 529 finished with value: 19.15390963740855 and parameters: {'n_hidden': 3, 'learning_rate': 0.007048665040148597, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25968467712767485, 'dropout_rate_Layer_2': 0.060030029596709125, 'dropout_rate_Layer_3': 0.011289097666169614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002079304029877547, 'l1_Layer_2': 0.00019425260688784, 'l1_Layer_3': 0.050721293913241365, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.15 | sMAPE for Validation Set is: 27.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.24 | sMAPE for Test Set is: 52.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:40:17,728]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:21,951]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:40:49,193]\u001b[0m Trial 532 finished with value: 18.897223458918337 and parameters: {'n_hidden': 3, 'learning_rate': 0.005952437076008449, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26022649494326194, 'dropout_rate_Layer_2': 0.04870276417580345, 'dropout_rate_Layer_3': 0.018841381598628224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020336142149688825, 'l1_Layer_2': 0.0002293122737997874, 'l1_Layer_3': 0.05716242881812483, 'n_units_Layer_1': 290, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 27.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.95 | sMAPE for Test Set is: 51.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:40:59,078]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:09,187]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:20,641]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:41:48,778]\u001b[0m Trial 536 finished with value: 27.579318650613786 and parameters: {'n_hidden': 4, 'learning_rate': 0.01737005138979658, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20003405724155718, 'dropout_rate_Layer_2': 0.33820738319033133, 'dropout_rate_Layer_3': 0.04783966291335895, 'dropout_rate_Layer_4': 0.22639216685597136, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001832511303281199, 'l1_Layer_2': 2.627265004631544e-05, 'l1_Layer_3': 0.01060312151405133, 'l1_Layer_4': 3.6734844010897384e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 275, 'n_units_Layer_3': 85, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.58 | sMAPE for Validation Set is: 37.72% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 102.33 | sMAPE for Test Set is: 80.78% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:42:06,808]\u001b[0m Trial 537 finished with value: 18.456496396858935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064516051266557016, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2885572189357266, 'dropout_rate_Layer_2': 0.02581356394609846, 'dropout_rate_Layer_3': 0.0392677025558376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014363335166673458, 'l1_Layer_2': 0.003684710186020713, 'l1_Layer_3': 0.0032877067933595188, 'n_units_Layer_1': 285, 'n_units_Layer_2': 220, 'n_units_Layer_3': 295}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.46 | sMAPE for Validation Set is: 27.33% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.23 | sMAPE for Test Set is: 51.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:42:10,289]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:15,923]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:42:54,261]\u001b[0m Trial 540 finished with value: 18.648435765077505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010384684420097206, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3402787245160798, 'dropout_rate_Layer_2': 0.3616020700589098, 'dropout_rate_Layer_3': 0.047560178422418734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.537227151313096e-05, 'l1_Layer_2': 2.6278387131413276e-05, 'l1_Layer_3': 0.007298699714224438, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 250}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 27.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.70 | sMAPE for Test Set is: 51.55% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 27.66 | sMAPE for Validation Set is: 37.35% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 103.47 | sMAPE for Test Set is: 81.81% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:43:21,508]\u001b[0m Trial 541 finished with value: 27.659445475719497 and parameters: {'n_hidden': 4, 'learning_rate': 0.016529340001377478, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2033486166763838, 'dropout_rate_Layer_2': 0.3629390495442255, 'dropout_rate_Layer_3': 0.050707014493997296, 'dropout_rate_Layer_4': 0.22658425688533754, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001219293304102172, 'l1_Layer_2': 5.322782474298017e-05, 'l1_Layer_3': 0.010854655800259959, 'l1_Layer_4': 3.4605858159299134e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:43:40,381]\u001b[0m Trial 542 finished with value: 28.056093007691302 and parameters: {'n_hidden': 4, 'learning_rate': 0.016459785441370303, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19789119090482205, 'dropout_rate_Layer_2': 0.3399441905923384, 'dropout_rate_Layer_3': 0.050065787123139145, 'dropout_rate_Layer_4': 0.24696731784624992, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005891771918702399, 'l1_Layer_2': 5.393252431243944e-05, 'l1_Layer_3': 0.014754654403852844, 'l1_Layer_4': 2.7054817652321835e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.06 | sMAPE for Validation Set is: 42.72% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 101.92 | sMAPE for Test Set is: 80.88% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:43:47,966]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:06,727]\u001b[0m Trial 544 finished with value: 28.168385422132925 and parameters: {'n_hidden': 4, 'learning_rate': 0.014119646891978564, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17525633728915438, 'dropout_rate_Layer_2': 0.33984743369581877, 'dropout_rate_Layer_3': 0.04737181406135939, 'dropout_rate_Layer_4': 0.22780962417580947, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005980786950613831, 'l1_Layer_2': 7.916054785337665e-05, 'l1_Layer_3': 0.014325091841212651, 'l1_Layer_4': 3.56761440397793e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.17 | sMAPE for Validation Set is: 39.23% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 103.85 | sMAPE for Test Set is: 82.92% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:44:23,950]\u001b[0m Trial 545 finished with value: 19.358690479156916 and parameters: {'n_hidden': 3, 'learning_rate': 0.009229528405459805, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20724970824717248, 'dropout_rate_Layer_2': 0.04540537908696426, 'dropout_rate_Layer_3': 0.23983185571234397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001167643689590845, 'l1_Layer_2': 0.00018580244741104405, 'l1_Layer_3': 0.03736213889738269, 'n_units_Layer_1': 75, 'n_units_Layer_2': 85, 'n_units_Layer_3': 205}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.36 | sMAPE for Validation Set is: 28.00% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 58.27 | sMAPE for Test Set is: 52.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:44:27,199]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:30,390]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:36,538]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:44:46,994]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:45:01,197]\u001b[0m Trial 550 finished with value: 27.43486411792523 and parameters: {'n_hidden': 4, 'learning_rate': 0.014398639154619029, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1758963790155246, 'dropout_rate_Layer_2': 0.34008995951600035, 'dropout_rate_Layer_3': 0.05005201657388407, 'dropout_rate_Layer_4': 0.22509378709484656, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005198423035136544, 'l1_Layer_2': 9.627996013645517e-05, 'l1_Layer_3': 0.014492733839339073, 'l1_Layer_4': 3.6874920304019826e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.43 | sMAPE for Validation Set is: 45.25% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 97.12 | sMAPE for Test Set is: 77.08% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:45:16,705]\u001b[0m Trial 551 finished with value: 28.053474426470714 and parameters: {'n_hidden': 4, 'learning_rate': 0.01656290725446567, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17479476470689698, 'dropout_rate_Layer_2': 0.33717009289317207, 'dropout_rate_Layer_3': 0.04861248178638687, 'dropout_rate_Layer_4': 0.22771789484993715, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003778176007775895, 'l1_Layer_2': 7.410685971739206e-05, 'l1_Layer_3': 0.00881296411826847, 'l1_Layer_4': 3.410379496139719e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.05 | sMAPE for Validation Set is: 43.11% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 99.03 | sMAPE for Test Set is: 78.45% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:45:38,064]\u001b[0m Trial 552 finished with value: 19.1401108125557 and parameters: {'n_hidden': 3, 'learning_rate': 0.008213594159577746, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26345606029141877, 'dropout_rate_Layer_2': 0.051328001580994216, 'dropout_rate_Layer_3': 0.014139168371004443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0034281692367645064, 'l1_Layer_2': 0.00013189049586967953, 'l1_Layer_3': 0.02132869593647855, 'n_units_Layer_1': 155, 'n_units_Layer_2': 115, 'n_units_Layer_3': 210}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.14 | sMAPE for Validation Set is: 27.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.32 | sMAPE for Test Set is: 52.16% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:45:51,834]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:19,505]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:46:59,729]\u001b[0m Trial 555 finished with value: 18.852216156277688 and parameters: {'n_hidden': 3, 'learning_rate': 0.002128802658394758, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3372804245175664, 'dropout_rate_Layer_2': 0.3604547226896612, 'dropout_rate_Layer_3': 0.0875804291812258, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.33008185287318e-05, 'l1_Layer_2': 2.4717241138375812e-05, 'l1_Layer_3': 0.00783054664491739, 'n_units_Layer_1': 265, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 27.90% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.06 | sMAPE for Test Set is: 52.32% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:47:19,072]\u001b[0m Trial 556 finished with value: 27.867960514445375 and parameters: {'n_hidden': 4, 'learning_rate': 0.01660375577123181, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16812762026846356, 'dropout_rate_Layer_2': 0.3420629941404803, 'dropout_rate_Layer_3': 0.029401372111716485, 'dropout_rate_Layer_4': 0.22653614324108723, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003789128249670124, 'l1_Layer_2': 9.33286933861919e-05, 'l1_Layer_3': 0.014602400217105314, 'l1_Layer_4': 3.6862009976367335e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.87 | sMAPE for Validation Set is: 39.16% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 103.09 | sMAPE for Test Set is: 81.71% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:47:34,402]\u001b[0m Trial 557 finished with value: 28.041607583992363 and parameters: {'n_hidden': 4, 'learning_rate': 0.01573669264747122, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17677144341366702, 'dropout_rate_Layer_2': 0.3394905988491094, 'dropout_rate_Layer_3': 0.028847420369054792, 'dropout_rate_Layer_4': 0.24756780335984296, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00039245007431407516, 'l1_Layer_2': 8.488647055792678e-05, 'l1_Layer_3': 0.014562727223323642, 'l1_Layer_4': 4.773563195927122e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.04 | sMAPE for Validation Set is: 43.02% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 100.86 | sMAPE for Test Set is: 79.99% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:47:49,730]\u001b[0m Trial 558 finished with value: 27.128729538930724 and parameters: {'n_hidden': 4, 'learning_rate': 0.015543882537042976, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17637649945427739, 'dropout_rate_Layer_2': 0.3372779647869285, 'dropout_rate_Layer_3': 0.048940049948241346, 'dropout_rate_Layer_4': 0.2470028688214707, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00044170189073943194, 'l1_Layer_2': 9.923248113983903e-05, 'l1_Layer_3': 0.01459576475533785, 'l1_Layer_4': 4.395620446584472e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 265, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.13 | sMAPE for Validation Set is: 38.32% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 100.29 | sMAPE for Test Set is: 79.16% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:48:00,599]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:03,824]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:48:41,715]\u001b[0m Trial 561 finished with value: 18.906976612715308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015027967342290897, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.341184783635217, 'dropout_rate_Layer_2': 0.3864375823471993, 'dropout_rate_Layer_3': 0.05560500074700935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.314382335640496e-05, 'l1_Layer_2': 3.926081140913773e-05, 'l1_Layer_3': 0.00782563289656267, 'n_units_Layer_1': 265, 'n_units_Layer_2': 200, 'n_units_Layer_3': 250}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.91 | sMAPE for Validation Set is: 27.79% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.15 | sMAPE for Test Set is: 52.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:49:01,342]\u001b[0m Trial 562 finished with value: 19.321075938393395 and parameters: {'n_hidden': 3, 'learning_rate': 0.008372457450797942, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26516111520724606, 'dropout_rate_Layer_2': 0.01630395056393147, 'dropout_rate_Layer_3': 0.1361247674963241, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021221173433306688, 'l1_Layer_2': 0.00014022879900942685, 'l1_Layer_3': 0.026495179010724196, 'n_units_Layer_1': 300, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.32 | sMAPE for Validation Set is: 28.12% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.97 | sMAPE for Test Set is: 52.63% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:49:04,366]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:08,182]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:11,353]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:17,230]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:21,006]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:24,620]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:28,545]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:31,737]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:49:46,865]\u001b[0m Trial 571 finished with value: 27.359424112359378 and parameters: {'n_hidden': 4, 'learning_rate': 0.011358286175884939, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16508888572264063, 'dropout_rate_Layer_2': 0.33973501031845005, 'dropout_rate_Layer_3': 0.050248838151445124, 'dropout_rate_Layer_4': 0.25615305334231603, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00038871178616615027, 'l1_Layer_2': 0.00010001360066785753, 'l1_Layer_3': 0.008238733571921392, 'l1_Layer_4': 3.9169954799297504e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.36 | sMAPE for Validation Set is: 40.48% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 101.40 | sMAPE for Test Set is: 80.51% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:50:02,545]\u001b[0m Trial 572 finished with value: 27.749619787840704 and parameters: {'n_hidden': 4, 'learning_rate': 0.011848173664994724, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1625093240783676, 'dropout_rate_Layer_2': 0.320824210923515, 'dropout_rate_Layer_3': 0.0736300212166486, 'dropout_rate_Layer_4': 0.22745102950000087, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034431749045538205, 'l1_Layer_2': 0.00010712173087656991, 'l1_Layer_3': 0.009219538746620069, 'l1_Layer_4': 3.70374838984859e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 260, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.75 | sMAPE for Validation Set is: 41.20% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 100.52 | sMAPE for Test Set is: 79.85% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:50:06,293]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:12,214]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:16,148]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:21,707]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:24,972]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:28,170]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:50:48,606]\u001b[0m Trial 579 finished with value: 18.443589565125563 and parameters: {'n_hidden': 3, 'learning_rate': 0.008647878850039512, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3240321855755904, 'dropout_rate_Layer_2': 0.016712419078539313, 'dropout_rate_Layer_3': 0.07176315843897686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016816814386249183, 'l1_Layer_2': 0.014614268371490812, 'l1_Layer_3': 0.0031032108614616164, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 300}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.44 | sMAPE for Validation Set is: 28.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.82 | sMAPE for Test Set is: 51.52% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:50:54,269]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:15,710]\u001b[0m Trial 581 finished with value: 27.80562555418723 and parameters: {'n_hidden': 4, 'learning_rate': 0.011125881473292477, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16505914469082356, 'dropout_rate_Layer_2': 0.3122605870003721, 'dropout_rate_Layer_3': 0.053119263172303276, 'dropout_rate_Layer_4': 0.2475063526957264, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003060039375684091, 'l1_Layer_2': 0.00010221904221704605, 'l1_Layer_3': 0.012389996278602869, 'l1_Layer_4': 3.4048105699282846e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.81 | sMAPE for Validation Set is: 40.29% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 103.41 | sMAPE for Test Set is: 82.17% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:51:21,508]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:25,245]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:33,631]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:37,107]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:42,264]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:51:55,717]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:18,790]\u001b[0m Trial 588 finished with value: 28.358196290352936 and parameters: {'n_hidden': 4, 'learning_rate': 0.008989219757004164, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16972328618931198, 'dropout_rate_Layer_2': 0.32360621222585545, 'dropout_rate_Layer_3': 0.06284500880248621, 'dropout_rate_Layer_4': 0.2553225570084841, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003175160076898386, 'l1_Layer_2': 0.00014155541043147434, 'l1_Layer_3': 0.024541817027179686, 'l1_Layer_4': 4.6532781674039984e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 470 with value: 18.430243481706473.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.36 | sMAPE for Validation Set is: 44.22% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 101.50 | sMAPE for Test Set is: 80.54% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:52:21,890]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:25,141]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:52:47,653]\u001b[0m Trial 591 finished with value: 18.244891689520752 and parameters: {'n_hidden': 3, 'learning_rate': 0.009195248009652239, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31868368659722945, 'dropout_rate_Layer_2': 0.002277699987874684, 'dropout_rate_Layer_3': 0.07344574358379583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015064275986427232, 'l1_Layer_2': 0.012012125699325868, 'l1_Layer_3': 0.0033063844776105994, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 300}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 27.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 57.15 | sMAPE for Test Set is: 51.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:52:53,313]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:01,399]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:04,992]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:08,615]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:24,247]\u001b[0m Trial 596 finished with value: 27.37915712405017 and parameters: {'n_hidden': 4, 'learning_rate': 0.00854053501812542, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17131466061474454, 'dropout_rate_Layer_2': 0.3395860150990951, 'dropout_rate_Layer_3': 0.08288772424454921, 'dropout_rate_Layer_4': 0.24622598238861593, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003225472021492768, 'l1_Layer_2': 0.00010637202404930727, 'l1_Layer_3': 0.03242946633121727, 'l1_Layer_4': 4.371117702313278e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.38 | sMAPE for Validation Set is: 39.48% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 98.85 | sMAPE for Test Set is: 77.63% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:30,303]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:52,123]\u001b[0m Trial 598 finished with value: 19.293923645239303 and parameters: {'n_hidden': 3, 'learning_rate': 0.01538051218947324, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26492872217984165, 'dropout_rate_Layer_2': 0.03662730246140128, 'dropout_rate_Layer_3': 0.0005935878705135272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003056190950372454, 'l1_Layer_2': 0.0006150814954884204, 'l1_Layer_3': 0.028502024574063218, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.29 | sMAPE for Validation Set is: 28.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.83 | sMAPE for Test Set is: 52.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:53:55,861]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:53:59,786]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:15,376]\u001b[0m Trial 601 finished with value: 28.292270856268107 and parameters: {'n_hidden': 4, 'learning_rate': 0.008168362192870485, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.170432919724574, 'dropout_rate_Layer_2': 0.34096912074733693, 'dropout_rate_Layer_3': 0.06352510995916719, 'dropout_rate_Layer_4': 0.24976961358521999, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00030867588289596105, 'l1_Layer_2': 0.00011460581089029311, 'l1_Layer_3': 0.035282650027636434, 'l1_Layer_4': 4.567770204632635e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.29 | sMAPE for Validation Set is: 42.02% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 100.23 | sMAPE for Test Set is: 79.14% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:54:28,630]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:54:49,276]\u001b[0m Trial 603 finished with value: 19.099605700787667 and parameters: {'n_hidden': 3, 'learning_rate': 0.011301164412956366, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2922318589175329, 'dropout_rate_Layer_2': 0.0684046291651491, 'dropout_rate_Layer_3': 0.03943736518323502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017320264283957408, 'l1_Layer_2': 0.0010214500378394192, 'l1_Layer_3': 0.032857836765188275, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 215}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.10 | sMAPE for Validation Set is: 27.67% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.81 | sMAPE for Test Set is: 52.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:55:02,023]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:55:44,776]\u001b[0m Trial 605 finished with value: 18.787075423943485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017519100065263955, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3222088215237431, 'dropout_rate_Layer_2': 0.3600941039523494, 'dropout_rate_Layer_3': 0.07477330969810522, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001656909714204272, 'l1_Layer_2': 1.7962081705352643e-05, 'l1_Layer_3': 0.006859493604049805, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 27.17% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.54 | sMAPE for Test Set is: 51.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:55:56,083]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:07,819]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:11,662]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:38,660]\u001b[0m Trial 609 finished with value: 26.956848195200052 and parameters: {'n_hidden': 4, 'learning_rate': 0.006359102745613951, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17942399500521705, 'dropout_rate_Layer_2': 0.3398681182496193, 'dropout_rate_Layer_3': 0.08230523477819564, 'dropout_rate_Layer_4': 0.26852190979074064, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021996754173902636, 'l1_Layer_2': 7.346213262745807e-05, 'l1_Layer_3': 0.03641621140355956, 'l1_Layer_4': 5.837170457858265e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 265, 'n_units_Layer_3': 65, 'n_units_Layer_4': 290}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 38.44% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 102.17 | sMAPE for Test Set is: 80.48% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:56:42,457]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:56:56,066]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:01,472]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:16,940]\u001b[0m Trial 613 finished with value: 27.218284455149455 and parameters: {'n_hidden': 4, 'learning_rate': 0.01039884651947144, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1535914574809859, 'dropout_rate_Layer_2': 0.35110172006651147, 'dropout_rate_Layer_3': 0.050558792099390404, 'dropout_rate_Layer_4': 0.23639582232231743, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004910634886261401, 'l1_Layer_2': 9.319037014591257e-05, 'l1_Layer_3': 0.031679058185438584, 'l1_Layer_4': 5.7223317259034654e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 50, 'n_units_Layer_4': 280}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.22 | sMAPE for Validation Set is: 38.63% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 102.18 | sMAPE for Test Set is: 80.66% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:57:20,155]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:23,366]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:30,459]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:36,086]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:39,294]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:57:45,167]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:11,848]\u001b[0m Trial 620 finished with value: 19.078440885875285 and parameters: {'n_hidden': 3, 'learning_rate': 0.006198085790250744, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33074343208733453, 'dropout_rate_Layer_2': 0.03437956884480566, 'dropout_rate_Layer_3': 0.057115847000071315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016267020175345757, 'l1_Layer_2': 0.008187939124515093, 'l1_Layer_3': 0.002527632390021726, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 28.71% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.85 | sMAPE for Test Set is: 52.14% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:58:16,778]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:58:32,002]\u001b[0m Trial 622 finished with value: 27.837301868745982 and parameters: {'n_hidden': 4, 'learning_rate': 0.010556311601117627, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1607256780245828, 'dropout_rate_Layer_2': 0.3377745998902445, 'dropout_rate_Layer_3': 0.05234502895196115, 'dropout_rate_Layer_4': 0.2644892461552085, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000552590808072525, 'l1_Layer_2': 9.282347655309331e-05, 'l1_Layer_3': 0.0486109601149499, 'l1_Layer_4': 3.75100691175247e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 60, 'n_units_Layer_4': 280}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.84 | sMAPE for Validation Set is: 37.23% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 105.89 | sMAPE for Test Set is: 84.25% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:58:52,842]\u001b[0m Trial 623 finished with value: 19.35182586144913 and parameters: {'n_hidden': 3, 'learning_rate': 0.011652567285958638, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2952667281134358, 'dropout_rate_Layer_2': 0.008828818263316333, 'dropout_rate_Layer_3': 0.03929959985980986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.60946730232368e-05, 'l1_Layer_2': 0.0018141206452950047, 'l1_Layer_3': 0.0012934353435396799, 'n_units_Layer_1': 280, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.35 | sMAPE for Validation Set is: 29.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.73 | sMAPE for Test Set is: 51.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:22,203]\u001b[0m Trial 624 finished with value: 18.70315860309775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018088151916144436, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3168418295027444, 'dropout_rate_Layer_2': 0.358700157791404, 'dropout_rate_Layer_3': 0.07448871774471975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017936898809621383, 'l1_Layer_2': 1.8683627527475103e-05, 'l1_Layer_3': 0.0024929723124152304, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.70 | sMAPE for Validation Set is: 28.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.33 | sMAPE for Test Set is: 50.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:30,291]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 03:59:54,221]\u001b[0m Trial 626 finished with value: 27.330375951490954 and parameters: {'n_hidden': 4, 'learning_rate': 0.008033023219851129, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1591779600719639, 'dropout_rate_Layer_2': 0.3463747056182284, 'dropout_rate_Layer_3': 0.05394178746286461, 'dropout_rate_Layer_4': 0.26782904669317487, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004049636161938925, 'l1_Layer_2': 6.900610131718596e-05, 'l1_Layer_3': 0.040235574542749696, 'l1_Layer_4': 5.3698054035200474e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 65, 'n_units_Layer_4': 275}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.33 | sMAPE for Validation Set is: 38.35% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 102.57 | sMAPE for Test Set is: 80.71% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 03:59:57,384]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:01,254]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:09,278]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:18,847]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:24,542]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:32,562]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:37,080]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:00:40,983]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:07,257]\u001b[0m Trial 635 finished with value: 18.940995623596447 and parameters: {'n_hidden': 3, 'learning_rate': 0.007979051436486796, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3484368372838933, 'dropout_rate_Layer_2': 0.001610008496836084, 'dropout_rate_Layer_3': 0.10606020545084273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001535143335545474, 'l1_Layer_2': 0.003357096345227023, 'l1_Layer_3': 0.002643633281729408, 'n_units_Layer_1': 290, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.94 | sMAPE for Validation Set is: 28.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.66 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:01:10,489]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:25,957]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:29,709]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:01:33,812]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:25,016]\u001b[0m Trial 640 finished with value: 26.831018730936165 and parameters: {'n_hidden': 4, 'learning_rate': 0.010432156383713653, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15832660866408974, 'dropout_rate_Layer_2': 0.3563378917487169, 'dropout_rate_Layer_3': 0.07024552165720549, 'dropout_rate_Layer_4': 0.2842199802514252, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004609017905673336, 'l1_Layer_2': 0.0001579523254020784, 'l1_Layer_3': 0.0315875107416949, 'l1_Layer_4': 4.1395172110908966e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85, 'n_units_Layer_4': 300}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.83 | sMAPE for Validation Set is: 36.13% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 102.68 | sMAPE for Test Set is: 81.48% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:02:28,326]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:31,621]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:37,338]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:40,599]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:44,597]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:02:47,780]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:02,916]\u001b[0m Trial 647 finished with value: 19.643697544085473 and parameters: {'n_hidden': 3, 'learning_rate': 0.013589398705270667, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2711467962763274, 'dropout_rate_Layer_2': 0.07335006576761866, 'dropout_rate_Layer_3': 0.22942049435684905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013993000479146742, 'l1_Layer_2': 0.0009642501062122677, 'l1_Layer_3': 0.031671762933058116, 'n_units_Layer_1': 90, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.64 | sMAPE for Validation Set is: 29.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.77 | sMAPE for Test Set is: 53.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:34,488]\u001b[0m Trial 648 finished with value: 18.689093569248527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012706345229224626, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29846759444864807, 'dropout_rate_Layer_2': 0.33367753283703466, 'dropout_rate_Layer_3': 0.07727270874494685, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018229176958017875, 'l1_Layer_2': 1.0784449342834024e-05, 'l1_Layer_3': 0.003860457880964655, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.69 | sMAPE for Validation Set is: 27.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.76 | sMAPE for Test Set is: 51.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:03:37,718]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:41,150]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:44,545]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:03:47,826]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:04,826]\u001b[0m Trial 653 finished with value: 28.09225270595353 and parameters: {'n_hidden': 4, 'learning_rate': 0.010368103613274334, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1582354464850471, 'dropout_rate_Layer_2': 0.3604716395092239, 'dropout_rate_Layer_3': 0.08820655303933367, 'dropout_rate_Layer_4': 0.28369615004984583, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002241341755563335, 'l1_Layer_2': 0.0001787082442496522, 'l1_Layer_3': 0.03082536234205579, 'l1_Layer_4': 4.201019063965052e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 85, 'n_units_Layer_4': 300}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.09 | sMAPE for Validation Set is: 37.55% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 106.73 | sMAPE for Test Set is: 85.29% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:04:11,457]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:15,006]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:22,818]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:29,551]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:04:52,747]\u001b[0m Trial 658 finished with value: 25.99342377713606 and parameters: {'n_hidden': 4, 'learning_rate': 0.009402468811994927, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14884117101785566, 'dropout_rate_Layer_2': 0.35492983344485757, 'dropout_rate_Layer_3': 0.06788749462443903, 'dropout_rate_Layer_4': 0.2705499871141461, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00037436463095284544, 'l1_Layer_2': 0.0001203332916582465, 'l1_Layer_3': 0.03454286596072362, 'l1_Layer_4': 5.0741407515203e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 240, 'n_units_Layer_3': 85, 'n_units_Layer_4': 285}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.99 | sMAPE for Validation Set is: 36.74% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 101.15 | sMAPE for Test Set is: 79.94% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:04:58,652]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:13,147]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:46,811]\u001b[0m Trial 661 finished with value: 18.72046228597173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016865444587998743, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3038623725548021, 'dropout_rate_Layer_2': 0.3600356299828455, 'dropout_rate_Layer_3': 0.07665803404510058, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014798248890413783, 'l1_Layer_2': 1.9085626456541763e-05, 'l1_Layer_3': 0.007272918557989448, 'n_units_Layer_1': 220, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 27.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.76 | sMAPE for Test Set is: 52.42% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:05:52,071]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:05:55,748]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:03,604]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:06,645]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:12,574]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:18,930]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:22,878]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:26,295]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:42,090]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:06:59,015]\u001b[0m Trial 671 finished with value: 18.717831630865792 and parameters: {'n_hidden': 3, 'learning_rate': 0.005459518221786662, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3066281695648872, 'dropout_rate_Layer_2': 0.05360475677784379, 'dropout_rate_Layer_3': 0.011187326466682038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.596695949712963e-05, 'l1_Layer_2': 0.005647355850848683, 'l1_Layer_3': 0.001282124057251045, 'n_units_Layer_1': 260, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 28.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.44 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:07:13,881]\u001b[0m Trial 672 finished with value: 27.730131471978023 and parameters: {'n_hidden': 4, 'learning_rate': 0.012021305679950856, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13425139639918177, 'dropout_rate_Layer_2': 0.33493453351097763, 'dropout_rate_Layer_3': 0.039766255873338, 'dropout_rate_Layer_4': 0.2611158596992502, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002517203576832345, 'l1_Layer_2': 0.00012741513703648082, 'l1_Layer_3': 0.04430300145473526, 'l1_Layer_4': 5.058218188844405e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 240, 'n_units_Layer_3': 60, 'n_units_Layer_4': 280}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.73 | sMAPE for Validation Set is: 38.17% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 105.18 | sMAPE for Test Set is: 83.79% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:07:17,453]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:20,720]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:07:43,732]\u001b[0m Trial 675 finished with value: 27.241222338365944 and parameters: {'n_hidden': 4, 'learning_rate': 0.011442200241101382, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13569713569368697, 'dropout_rate_Layer_2': 0.3551776945724838, 'dropout_rate_Layer_3': 0.03793555840043307, 'dropout_rate_Layer_4': 0.26815562425615685, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023207221941651038, 'l1_Layer_2': 0.00013544003051123884, 'l1_Layer_3': 0.0467948818546063, 'l1_Layer_4': 5.149876323741568e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55, 'n_units_Layer_4': 275}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.24 | sMAPE for Validation Set is: 39.38% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 103.30 | sMAPE for Test Set is: 81.79% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:07:59,631]\u001b[0m Trial 676 finished with value: 18.614502566951284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015568129378165148, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31282324079597223, 'dropout_rate_Layer_2': 0.3991195468942393, 'dropout_rate_Layer_3': 0.05095062188212449, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.789772795362522e-05, 'l1_Layer_2': 1.0920086257297798e-05, 'l1_Layer_3': 0.002807751074906153, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.61 | sMAPE for Validation Set is: 27.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.87 | sMAPE for Test Set is: 52.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:08:02,883]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:06,158]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:20,124]\u001b[0m Trial 679 finished with value: 28.340884945679118 and parameters: {'n_hidden': 4, 'learning_rate': 0.011326918149500728, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13489075997148, 'dropout_rate_Layer_2': 0.3535954961043908, 'dropout_rate_Layer_3': 0.038290010537142115, 'dropout_rate_Layer_4': 0.2700098813552489, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019761218629506835, 'l1_Layer_2': 0.0001879403810204865, 'l1_Layer_3': 0.04441744768561783, 'l1_Layer_4': 7.25216074166839e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 240, 'n_units_Layer_3': 55, 'n_units_Layer_4': 270}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.34 | sMAPE for Validation Set is: 42.48% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 103.15 | sMAPE for Test Set is: 81.92% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:08:23,499]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:27,352]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:08:50,717]\u001b[0m Trial 682 finished with value: 19.16279550813874 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015034529971605292, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26043768230402575, 'dropout_rate_Layer_2': 0.39758319491634797, 'dropout_rate_Layer_3': 0.019822295170847038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001040674643580911, 'l1_Layer_2': 1.4183752196788786e-05, 'l1_Layer_3': 0.002766235266942295, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.16 | sMAPE for Validation Set is: 27.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 62.04 | sMAPE for Test Set is: 53.09% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:09:03,204]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:06,395]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:12,553]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:16,320]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:21,688]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:25,620]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:29,557]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:09:41,968]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:04,864]\u001b[0m Trial 691 finished with value: 18.707394944556487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0057920811710666185, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2522818596843435, 'dropout_rate_Layer_2': 0.01484307110229871, 'dropout_rate_Layer_3': 0.029755458864146003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004259538325174559, 'l1_Layer_2': 0.003773197116572439, 'l1_Layer_3': 0.004409060139361454, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.71 | sMAPE for Validation Set is: 27.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.03 | sMAPE for Test Set is: 51.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:10:08,560]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:12,543]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:25,431]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:28,830]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:39,600]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:43,617]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:46,896]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:50,718]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:53,943]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:10:58,522]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:04,534]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:09,829]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:14,573]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:18,362]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:23,686]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:27,679]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:46,375]\u001b[0m Trial 708 finished with value: 27.823742686346645 and parameters: {'n_hidden': 4, 'learning_rate': 0.010963353849912434, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12157056719827403, 'dropout_rate_Layer_2': 0.3336597616303653, 'dropout_rate_Layer_3': 0.037780193665225933, 'dropout_rate_Layer_4': 0.26340261770546247, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004268587856428565, 'l1_Layer_2': 8.820212751223363e-05, 'l1_Layer_3': 0.030581785857325766, 'l1_Layer_4': 4.995377048280004e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 70, 'n_units_Layer_4': 285}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.82 | sMAPE for Validation Set is: 37.56% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 104.14 | sMAPE for Test Set is: 82.42% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:11:49,699]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:11:56,813]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:05,989]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:14,354]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:18,301]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:35,959]\u001b[0m Trial 714 finished with value: 19.05106612905222 and parameters: {'n_hidden': 3, 'learning_rate': 0.014509456085787006, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2541282749638012, 'dropout_rate_Layer_2': 0.034628037836600886, 'dropout_rate_Layer_3': 0.012732681739492241, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003879823680280507, 'l1_Layer_2': 0.00028378665958183886, 'l1_Layer_3': 0.021158505987559206, 'n_units_Layer_1': 75, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.05 | sMAPE for Validation Set is: 27.50% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.90 | sMAPE for Test Set is: 51.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:12:41,350]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:44,533]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:12:51,747]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:04,233]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:30,262]\u001b[0m Trial 719 finished with value: 18.557346399622368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020472379323758934, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.282321401205333, 'dropout_rate_Layer_2': 0.39994940179403066, 'dropout_rate_Layer_3': 0.055300858872526386, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039481864613603786, 'l1_Layer_2': 5.951658434277347e-05, 'l1_Layer_3': 0.004925759728712958, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 250}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.56 | sMAPE for Validation Set is: 27.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.70 | sMAPE for Test Set is: 51.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:13:34,251]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:37,719]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:46,245]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:49,541]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:13:53,220]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:06,066]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:10,021]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:13,769]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:14:54,818]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:02,123]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:05,516]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:11,503]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:19,085]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:24,575]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:28,362]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:32,235]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:37,802]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:41,983]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:45,357]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:48,565]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:53,748]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:15:57,463]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:16:00,728]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:16:04,124]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:16:08,095]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:16:19,073]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:16:23,071]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:16:49,386]\u001b[0m Trial 747 finished with value: 18.397429810771285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016348884156349545, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.282921367725675, 'dropout_rate_Layer_2': 0.3857252736895059, 'dropout_rate_Layer_3': 0.04299071324446525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002769944233093121, 'l1_Layer_2': 5.993944971518073e-05, 'l1_Layer_3': 0.003995925912919485, 'n_units_Layer_1': 210, 'n_units_Layer_2': 230, 'n_units_Layer_3': 250}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.40 | sMAPE for Validation Set is: 27.35% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.79 | sMAPE for Test Set is: 51.08% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:16:53,626]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:17:43,747]\u001b[0m Trial 749 finished with value: 18.459399297038715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011152040431875708, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28389504558907275, 'dropout_rate_Layer_2': 0.38703874800574944, 'dropout_rate_Layer_3': 0.03404686078081276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003050869715964997, 'l1_Layer_2': 6.041781930008708e-05, 'l1_Layer_3': 0.0036518437179797214, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.46 | sMAPE for Validation Set is: 27.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.29 | sMAPE for Test Set is: 51.48% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:17:47,642]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:17:51,549]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:04,066]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:09,527]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:13,244]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:17,231]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:22,638]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:25,941]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:29,342]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:37,326]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:18:45,780]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:10,800]\u001b[0m Trial 761 finished with value: 18.64301524901579 and parameters: {'n_hidden': 3, 'learning_rate': 0.005610360387138493, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27769873313369886, 'dropout_rate_Layer_2': 0.015831867403707494, 'dropout_rate_Layer_3': 0.026723193100272404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005791197749866671, 'l1_Layer_2': 0.003426108359111933, 'l1_Layer_3': 0.0045184870010841535, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 260}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.64 | sMAPE for Validation Set is: 28.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.18 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:19:14,091]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:17,164]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:21,091]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:24,393]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:37,818]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:41,450]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:46,915]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:50,116]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:53,445]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:19:56,687]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:20:00,211]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:20:15,826]\u001b[0m Trial 773 finished with value: 28.665774274819864 and parameters: {'n_hidden': 4, 'learning_rate': 0.007963008711447202, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14694724846013546, 'dropout_rate_Layer_2': 0.3168440297539466, 'dropout_rate_Layer_3': 0.06905332439163762, 'dropout_rate_Layer_4': 0.23839840368523327, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005042142215744819, 'l1_Layer_2': 8.959126031194624e-05, 'l1_Layer_3': 0.03408944215817063, 'l1_Layer_4': 4.741658900227533e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65, 'n_units_Layer_4': 285}. Best is trial 591 with value: 18.244891689520752.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.67 | sMAPE for Validation Set is: 42.94% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 103.75 | sMAPE for Test Set is: 82.76% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:20:21,217]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:20:24,392]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:20:36,440]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:20:40,433]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:21:07,838]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:21:13,025]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:21:17,357]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:21:20,642]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:21:44,976]\u001b[0m Trial 782 finished with value: 18.220758934482184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022718261047204665, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3098365074195428, 'dropout_rate_Layer_2': 0.3822284188071183, 'dropout_rate_Layer_3': 0.04791140492242946, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005818930239911066, 'l1_Layer_2': 3.9727451454651604e-05, 'l1_Layer_3': 0.0017452007277258797, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.22 | sMAPE for Validation Set is: 27.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.58 | sMAPE for Test Set is: 50.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:21:48,908]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:21:56,068]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:22:29,012]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:22:32,666]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:22:38,372]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:22:59,459]\u001b[0m Trial 788 finished with value: 18.79658591984759 and parameters: {'n_hidden': 3, 'learning_rate': 0.007608931307972922, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2995343769458365, 'dropout_rate_Layer_2': 0.03705191315887646, 'dropout_rate_Layer_3': 0.011839511589924983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047157010178474306, 'l1_Layer_2': 0.0014001924910132773, 'l1_Layer_3': 0.004128842531957006, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 280}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 28.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.80 | sMAPE for Test Set is: 52.52% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:23:04,567]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:23:12,365]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:23:29,191]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:23:32,295]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:23:38,876]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:24:01,654]\u001b[0m Trial 794 finished with value: 27.21338965907998 and parameters: {'n_hidden': 4, 'learning_rate': 0.013450300095957737, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16883793521544613, 'dropout_rate_Layer_2': 0.35223559113939334, 'dropout_rate_Layer_3': 0.09061944846894335, 'dropout_rate_Layer_4': 0.24542363586990473, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003691777222415118, 'l1_Layer_2': 0.00016142818390599585, 'l1_Layer_3': 0.021714194439405622, 'l1_Layer_4': 2.5672141847445347e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55, 'n_units_Layer_4': 290}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 36.19% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 104.77 | sMAPE for Test Set is: 83.09% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:24:05,031]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:24:08,229]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:24:15,653]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:24:19,479]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:24:23,397]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:24:43,630]\u001b[0m Trial 800 finished with value: 18.64821115344208 and parameters: {'n_hidden': 3, 'learning_rate': 0.009501185424042574, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28525176628336574, 'dropout_rate_Layer_2': 0.01988048680842746, 'dropout_rate_Layer_3': 0.03665805868087366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003167488402460499, 'l1_Layer_2': 0.0021394643780904914, 'l1_Layer_3': 0.0028847515389154796, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 220}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 27.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.39 | sMAPE for Test Set is: 51.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:24:47,203]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:25:14,775]\u001b[0m Trial 802 finished with value: 18.5174206415568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016060081260776062, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26986157690049983, 'dropout_rate_Layer_2': 0.38775674400037646, 'dropout_rate_Layer_3': 0.0006403243198518441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004149764792671445, 'l1_Layer_2': 5.736178062193801e-05, 'l1_Layer_3': 0.001959874082712555, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.52 | sMAPE for Validation Set is: 27.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.54 | sMAPE for Test Set is: 51.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:25:26,092]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:25:48,613]\u001b[0m Trial 804 finished with value: 18.83738363332311 and parameters: {'n_hidden': 3, 'learning_rate': 0.009394585915601685, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28912009989248805, 'dropout_rate_Layer_2': 0.018474291672869046, 'dropout_rate_Layer_3': 0.05531419467528236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034812179858327905, 'l1_Layer_2': 0.0057963301946569, 'l1_Layer_3': 0.0027481848725624623, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.84 | sMAPE for Validation Set is: 28.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.13 | sMAPE for Test Set is: 50.88% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:25:55,510]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:25:58,909]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:26:22,499]\u001b[0m Trial 807 finished with value: 18.930762474561316 and parameters: {'n_hidden': 3, 'learning_rate': 0.008344375436355907, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2728297770499856, 'dropout_rate_Layer_2': 0.055133783838360685, 'dropout_rate_Layer_3': 0.022168802744279698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0036330535158118665, 'l1_Layer_2': 0.001056714930468526, 'l1_Layer_3': 0.005805966484066076, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 190}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 27.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.17 | sMAPE for Test Set is: 51.90% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:26:25,812]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:26:31,342]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:26:46,662]\u001b[0m Trial 810 finished with value: 27.471608929502423 and parameters: {'n_hidden': 4, 'learning_rate': 0.010385279437548807, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18629902166711373, 'dropout_rate_Layer_2': 0.2590643188947195, 'dropout_rate_Layer_3': 0.07489186584904883, 'dropout_rate_Layer_4': 0.2533963041363194, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005282004397149431, 'l1_Layer_2': 0.00018936739164370037, 'l1_Layer_3': 0.012203873683039242, 'l1_Layer_4': 2.9713580138534856e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 280, 'n_units_Layer_3': 80, 'n_units_Layer_4': 285}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.47 | sMAPE for Validation Set is: 42.43% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 102.43 | sMAPE for Test Set is: 81.38% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:27:03,059]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:27,874]\u001b[0m Trial 812 finished with value: 18.9126962733069 and parameters: {'n_hidden': 3, 'learning_rate': 0.008389908078527105, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27162289352685653, 'dropout_rate_Layer_2': 0.07070938172741574, 'dropout_rate_Layer_3': 0.24867595474522936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003901670629735899, 'l1_Layer_2': 0.0016880045326434817, 'l1_Layer_3': 0.0014435576783903717, 'n_units_Layer_1': 60, 'n_units_Layer_2': 125, 'n_units_Layer_3': 185}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.91 | sMAPE for Validation Set is: 27.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.53 | sMAPE for Test Set is: 51.49% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:27:31,053]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:34,902]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:40,096]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:43,742]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:46,870]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:52,191]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:27:55,945]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:28:03,154]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:28:08,585]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:28:23,030]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:28:44,885]\u001b[0m Trial 823 finished with value: 18.611641181953797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016559349356189024, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2438803750738071, 'dropout_rate_Layer_2': 0.3811268433169226, 'dropout_rate_Layer_3': 0.05759226551859677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000616408567742397, 'l1_Layer_2': 7.771642032590692e-05, 'l1_Layer_3': 0.0020522648132711555, 'n_units_Layer_1': 235, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.61 | sMAPE for Validation Set is: 27.31% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.33 | sMAPE for Test Set is: 51.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:29:12,441]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:29:20,541]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:29:46,511]\u001b[0m Trial 826 finished with value: 18.46131421260994 and parameters: {'n_hidden': 3, 'learning_rate': 0.001463549674572905, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2412163352742337, 'dropout_rate_Layer_2': 0.3684249784732283, 'dropout_rate_Layer_3': 0.030789351925827768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00033617885787333603, 'l1_Layer_2': 5.2181581487911106e-05, 'l1_Layer_3': 0.001822575649704982, 'n_units_Layer_1': 240, 'n_units_Layer_2': 265, 'n_units_Layer_3': 295}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.46 | sMAPE for Validation Set is: 27.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.61 | sMAPE for Test Set is: 51.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:29:50,734]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:29:54,442]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:30:09,134]\u001b[0m Trial 829 finished with value: 27.48231767739317 and parameters: {'n_hidden': 4, 'learning_rate': 0.011696395821286907, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17840965110043133, 'dropout_rate_Layer_2': 0.33670714899566867, 'dropout_rate_Layer_3': 0.0447929996865965, 'dropout_rate_Layer_4': 0.24985197017858773, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00039322813678437573, 'l1_Layer_2': 9.579409732425679e-05, 'l1_Layer_3': 0.015338925755033471, 'l1_Layer_4': 4.669580915623442e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.48 | sMAPE for Validation Set is: 42.84% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 98.97 | sMAPE for Test Set is: 78.21% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:30:24,787]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:30:43,786]\u001b[0m Trial 831 finished with value: 18.555126084734166 and parameters: {'n_hidden': 3, 'learning_rate': 0.005234386325176463, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3234932514634773, 'dropout_rate_Layer_2': 0.016096378852771997, 'dropout_rate_Layer_3': 0.03707691196335947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005238683342103914, 'l1_Layer_2': 0.0035205040277636775, 'l1_Layer_3': 0.0020289085320890536, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.56 | sMAPE for Validation Set is: 27.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.09 | sMAPE for Test Set is: 51.06% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:30:47,348]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:31:13,381]\u001b[0m Trial 833 finished with value: 19.08178922658082 and parameters: {'n_hidden': 3, 'learning_rate': 0.004438784354419852, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3206893851333254, 'dropout_rate_Layer_2': 0.0368089140412014, 'dropout_rate_Layer_3': 0.07978650964782097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007988431299812026, 'l1_Layer_2': 0.004127358184227879, 'l1_Layer_3': 0.002205242641264079, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 27.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.62 | sMAPE for Test Set is: 51.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:31:29,093]\u001b[0m Trial 834 finished with value: 27.534743086214917 and parameters: {'n_hidden': 4, 'learning_rate': 0.010353209656654582, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16579652437863152, 'dropout_rate_Layer_2': 0.3194398272588946, 'dropout_rate_Layer_3': 0.043088447500141465, 'dropout_rate_Layer_4': 0.2713231085822144, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000463714335218127, 'l1_Layer_2': 9.517916567173268e-05, 'l1_Layer_3': 0.015841080635041502, 'l1_Layer_4': 6.021592219245559e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 270, 'n_units_Layer_3': 75, 'n_units_Layer_4': 295}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.53 | sMAPE for Validation Set is: 37.61% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 104.77 | sMAPE for Test Set is: 83.57% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:31:34,804]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:31:56,009]\u001b[0m Trial 836 finished with value: 19.097460387758705 and parameters: {'n_hidden': 3, 'learning_rate': 0.005749665849338531, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28109931436184193, 'dropout_rate_Layer_2': 0.054321451265296646, 'dropout_rate_Layer_3': 0.2475930490379587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004123691521802716, 'l1_Layer_2': 5.716333041556173e-05, 'l1_Layer_3': 0.0012579518745622835, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 195}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.10 | sMAPE for Validation Set is: 27.82% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.71 | sMAPE for Test Set is: 52.72% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:31:59,175]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:02,273]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:30,403]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:41,761]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:45,729]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:50,774]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:55,205]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:32:58,576]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:33:09,708]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:33:13,498]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:33:16,658]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:33:45,761]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:33:54,202]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:33:57,473]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:34:30,597]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:34:41,391]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:35:10,241]\u001b[0m Trial 853 finished with value: 18.932913132388723 and parameters: {'n_hidden': 3, 'learning_rate': 0.004673217461133573, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3024777734537989, 'dropout_rate_Layer_2': 0.20436440800446604, 'dropout_rate_Layer_3': 0.24842465448577217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003361746969506157, 'l1_Layer_2': 0.00011151890788499828, 'l1_Layer_3': 0.0013893301598413702, 'n_units_Layer_1': 265, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 27.74% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.26 | sMAPE for Test Set is: 51.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:35:22,557]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:35:28,215]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:35:36,712]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:35:59,715]\u001b[0m Trial 857 finished with value: 18.594054067766425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024773347239552563, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26747637896231324, 'dropout_rate_Layer_2': 0.367957929763797, 'dropout_rate_Layer_3': 0.030260084880235363, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006140757167306806, 'l1_Layer_2': 3.509174607629234e-05, 'l1_Layer_3': 0.001048170350824768, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.59 | sMAPE for Validation Set is: 27.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.92 | sMAPE for Test Set is: 51.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:36:03,161]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:07,409]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:19,413]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:23,809]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:28,166]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:31,986]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:35,535]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:38,781]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:42,201]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:36:48,546]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:37:32,868]\u001b[0m Trial 868 finished with value: 18.377153011739697 and parameters: {'n_hidden': 3, 'learning_rate': 0.002452473182005143, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23788314976429806, 'dropout_rate_Layer_2': 0.35402783977090924, 'dropout_rate_Layer_3': 0.0109062273738917, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006324562034149798, 'l1_Layer_2': 3.080488119154131e-05, 'l1_Layer_3': 0.0007613848140524368, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 290}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 26.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.48 | sMAPE for Test Set is: 50.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:37:37,093]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:37:52,171]\u001b[0m Trial 870 finished with value: 18.717863029927518 and parameters: {'n_hidden': 3, 'learning_rate': 0.008314977651258632, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.321858285256085, 'dropout_rate_Layer_2': 0.025920265399317355, 'dropout_rate_Layer_3': 0.034532973147123475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003464050238422793, 'l1_Layer_2': 0.002341918982875065, 'l1_Layer_3': 0.001803174227660474, 'n_units_Layer_1': 245, 'n_units_Layer_2': 220, 'n_units_Layer_3': 190}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.66 | sMAPE for Test Set is: 51.04% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:37:59,884]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:38:03,109]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:38:09,031]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:38:29,309]\u001b[0m Trial 874 finished with value: 19.121564073263073 and parameters: {'n_hidden': 3, 'learning_rate': 0.006790701959535813, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2992568587134368, 'dropout_rate_Layer_2': 0.025857551586308092, 'dropout_rate_Layer_3': 0.006738487877597399, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020641051167039832, 'l1_Layer_2': 0.0030077418231122775, 'l1_Layer_3': 0.003418384452014114, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 28.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.92 | sMAPE for Test Set is: 51.47% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:38:43,408]\u001b[0m Trial 875 finished with value: 27.45913808597339 and parameters: {'n_hidden': 4, 'learning_rate': 0.008875572417115557, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15299282722093321, 'dropout_rate_Layer_2': 0.3490019510022221, 'dropout_rate_Layer_3': 0.04480619696077996, 'dropout_rate_Layer_4': 0.2515627941796705, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005943623560605918, 'l1_Layer_2': 5.855551672683877e-05, 'l1_Layer_3': 0.01678749718631403, 'l1_Layer_4': 5.7577289895780295e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60, 'n_units_Layer_4': 270}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.46 | sMAPE for Validation Set is: 39.20% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 103.58 | sMAPE for Test Set is: 82.52% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:38:50,773]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:38:54,168]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:39:22,503]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:39:26,923]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:39:30,964]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:39:38,865]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:39:52,082]\u001b[0m Trial 882 finished with value: 27.54011637747364 and parameters: {'n_hidden': 4, 'learning_rate': 0.009739469954415676, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15799436765803018, 'dropout_rate_Layer_2': 0.3489491835337108, 'dropout_rate_Layer_3': 0.04710326627188218, 'dropout_rate_Layer_4': 0.24210079582050492, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006111836227409552, 'l1_Layer_2': 6.852585856825067e-05, 'l1_Layer_3': 0.020726374914876233, 'l1_Layer_4': 4.819233516513055e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 220, 'n_units_Layer_3': 55, 'n_units_Layer_4': 280}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.54 | sMAPE for Validation Set is: 44.02% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 97.39 | sMAPE for Test Set is: 77.36% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:40:06,063]\u001b[0m Trial 883 finished with value: 26.408694269782146 and parameters: {'n_hidden': 4, 'learning_rate': 0.009678562604407411, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17434355760302447, 'dropout_rate_Layer_2': 0.34883785520984273, 'dropout_rate_Layer_3': 0.05015903656900952, 'dropout_rate_Layer_4': 0.24113201498740036, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006307426949579737, 'l1_Layer_2': 7.624261357974405e-05, 'l1_Layer_3': 0.02013690173336654, 'l1_Layer_4': 5.0558490583109576e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 55, 'n_units_Layer_4': 295}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.41 | sMAPE for Validation Set is: 37.12% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 100.11 | sMAPE for Test Set is: 78.89% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:40:13,877]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:40:19,241]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:40:24,433]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:40:32,566]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:40:35,985]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:41:04,766]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:41:38,484]\u001b[0m Trial 890 finished with value: 18.851949350809473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028077714895385674, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2515727231960839, 'dropout_rate_Layer_2': 0.3682112839142815, 'dropout_rate_Layer_3': 0.030214377078148266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003441661839952318, 'l1_Layer_2': 3.6384682238314924e-05, 'l1_Layer_3': 0.0021567297212587676, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 27.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.63 | sMAPE for Test Set is: 52.10% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:41:42,598]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:41:46,001]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:41:49,892]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:41:53,362]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:41:56,654]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:16,806]\u001b[0m Trial 896 finished with value: 19.00945906793494 and parameters: {'n_hidden': 3, 'learning_rate': 0.015489471515918087, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22666830818652908, 'dropout_rate_Layer_2': 0.03098425895786435, 'dropout_rate_Layer_3': 0.21979944689934294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004224472441987344, 'l1_Layer_2': 0.0003400923678289169, 'l1_Layer_3': 0.00047236019297449084, 'n_units_Layer_1': 175, 'n_units_Layer_2': 110, 'n_units_Layer_3': 190}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.01 | sMAPE for Validation Set is: 27.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.69 | sMAPE for Test Set is: 51.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:42:22,536]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:27,995]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:31,414]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:34,785]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:38,215]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:41,778]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:49,676]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:42:55,425]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:43:01,187]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:43:29,142]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:43:39,941]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:09,493]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:13,042]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:21,181]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:28,803]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:34,170]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:37,649]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:44,626]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:48,575]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:44:52,934]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:45:23,544]\u001b[0m Trial 917 finished with value: 18.972678645227653 and parameters: {'n_hidden': 3, 'learning_rate': 0.009849524678197353, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27306581554516046, 'dropout_rate_Layer_2': 0.012736818502499279, 'dropout_rate_Layer_3': 0.028943654354417533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024134728451178793, 'l1_Layer_2': 0.005278754126949394, 'l1_Layer_3': 0.006563336463602344, 'n_units_Layer_1': 255, 'n_units_Layer_2': 205, 'n_units_Layer_3': 275}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.97 | sMAPE for Validation Set is: 27.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.71 | sMAPE for Test Set is: 51.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:45:27,150]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:45:32,529]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:45:35,933]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:00,741]\u001b[0m Trial 921 finished with value: 18.798031204117105 and parameters: {'n_hidden': 3, 'learning_rate': 0.005431437830331942, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3060024074841549, 'dropout_rate_Layer_2': 5.4573099340381875e-05, 'dropout_rate_Layer_3': 0.04591297495059955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003719665156778264, 'l1_Layer_2': 0.0018998102849616754, 'l1_Layer_3': 0.003004605749314927, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 215}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 28.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.50 | sMAPE for Test Set is: 51.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:46:08,591]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:11,955]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:25,422]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:28,698]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:33,905]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:37,337]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:46:43,296]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:47:06,324]\u001b[0m Trial 929 finished with value: 18.900457453552907 and parameters: {'n_hidden': 3, 'learning_rate': 0.003425453881675793, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25180513935804594, 'dropout_rate_Layer_2': 0.019300533772560285, 'dropout_rate_Layer_3': 0.27941547173740866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006090418519515897, 'l1_Layer_2': 0.0008783384236170607, 'l1_Layer_3': 0.0005341519321932652, 'n_units_Layer_1': 60, 'n_units_Layer_2': 100, 'n_units_Layer_3': 195}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 27.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.14 | sMAPE for Test Set is: 51.64% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:47:09,496]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:47:12,884]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:47:16,191]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:47:30,673]\u001b[0m Trial 933 finished with value: 28.30651935643657 and parameters: {'n_hidden': 4, 'learning_rate': 0.007441390874556491, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16492923415045238, 'dropout_rate_Layer_2': 0.34978388376844766, 'dropout_rate_Layer_3': 0.06460549041655517, 'dropout_rate_Layer_4': 0.2418838230936791, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003868482846324859, 'l1_Layer_2': 5.0686501153112704e-05, 'l1_Layer_3': 0.029036998939298717, 'l1_Layer_4': 3.184633927426102e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70, 'n_units_Layer_4': 290}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.31 | sMAPE for Validation Set is: 40.51% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 105.32 | sMAPE for Test Set is: 84.23% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:47:38,416]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:47:53,615]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:48:08,183]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:48:24,826]\u001b[0m Trial 937 finished with value: 26.947528965636753 and parameters: {'n_hidden': 4, 'learning_rate': 0.008455372670277427, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1729646071794944, 'dropout_rate_Layer_2': 0.3260958897452113, 'dropout_rate_Layer_3': 0.09399871933773318, 'dropout_rate_Layer_4': 0.2707626569439285, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00042136376112740135, 'l1_Layer_2': 0.00010163218718168598, 'l1_Layer_3': 0.015673303024830235, 'l1_Layer_4': 4.6616953026086435e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 275, 'n_units_Layer_3': 65, 'n_units_Layer_4': 285}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.95 | sMAPE for Validation Set is: 37.17% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 101.86 | sMAPE for Test Set is: 80.18% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:48:28,653]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:48:34,614]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:48:56,975]\u001b[0m Trial 940 finished with value: 27.906665748972273 and parameters: {'n_hidden': 4, 'learning_rate': 0.008568893229099485, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1680122608857285, 'dropout_rate_Layer_2': 0.3322405671157689, 'dropout_rate_Layer_3': 0.1455483583490126, 'dropout_rate_Layer_4': 0.26010456639541396, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000531345199940271, 'l1_Layer_2': 7.993486719494324e-05, 'l1_Layer_3': 0.01220730316508792, 'l1_Layer_4': 4.8374018271337935e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 275, 'n_units_Layer_3': 70, 'n_units_Layer_4': 280}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.91 | sMAPE for Validation Set is: 37.77% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 105.20 | sMAPE for Test Set is: 83.43% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:49:26,723]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:50:05,609]\u001b[0m Trial 942 finished with value: 18.88868487674764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034791082801825892, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25138948874681455, 'dropout_rate_Layer_2': 0.031697348546895675, 'dropout_rate_Layer_3': 0.2772227433601992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0051361226338666206, 'l1_Layer_2': 0.002226687656087379, 'l1_Layer_3': 0.0002956951705996293, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 195}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.89 | sMAPE for Validation Set is: 27.81% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.28 | sMAPE for Test Set is: 52.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:50:08,888]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:50:16,477]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:50:24,960]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:50:41,235]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:06,935]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:10,359]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:14,263]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:18,658]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:22,806]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:40,197]\u001b[0m Trial 952 finished with value: 27.617427163098142 and parameters: {'n_hidden': 4, 'learning_rate': 0.009913680436039353, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1728949429747201, 'dropout_rate_Layer_2': 0.3011798245430714, 'dropout_rate_Layer_3': 0.0526190471647408, 'dropout_rate_Layer_4': 0.23756953770394318, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007734742443617473, 'l1_Layer_2': 9.669267181458263e-05, 'l1_Layer_3': 0.010589607593946846, 'l1_Layer_4': 2.50311339127228e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 255, 'n_units_Layer_3': 60, 'n_units_Layer_4': 285}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.62 | sMAPE for Validation Set is: 40.48% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 100.98 | sMAPE for Test Set is: 79.18% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:51:48,569]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:54,214]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:51:57,541]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:52:01,689]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:52:05,757]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:52:46,415]\u001b[0m Trial 958 finished with value: 18.342256899912822 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012076230105781815, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2844423252019731, 'dropout_rate_Layer_2': 0.34656999362588303, 'dropout_rate_Layer_3': 0.030968811221998974, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004859730031291295, 'l1_Layer_2': 3.9375778128859634e-05, 'l1_Layer_3': 0.0008728261561999406, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.34 | sMAPE for Validation Set is: 26.88% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.90 | sMAPE for Test Set is: 51.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:53:04,278]\u001b[0m Trial 959 finished with value: 18.595222680495443 and parameters: {'n_hidden': 3, 'learning_rate': 0.006189143520612983, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3164203247683905, 'dropout_rate_Layer_2': 0.06622542464328299, 'dropout_rate_Layer_3': 0.017010396992080994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021811871694024757, 'l1_Layer_2': 0.0019735310049904466, 'l1_Layer_3': 0.0019904420880755163, 'n_units_Layer_1': 225, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.60 | sMAPE for Validation Set is: 27.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.31 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:53:35,928]\u001b[0m Trial 960 finished with value: 18.480074891536542 and parameters: {'n_hidden': 3, 'learning_rate': 0.003079559190126817, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2042110577673184, 'dropout_rate_Layer_2': 0.030546253299847254, 'dropout_rate_Layer_3': 0.08856507250736462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.217436430475273e-05, 'l1_Layer_2': 0.0003792264650790666, 'l1_Layer_3': 0.0005939986922739917, 'n_units_Layer_1': 55, 'n_units_Layer_2': 95, 'n_units_Layer_3': 185}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.48 | sMAPE for Validation Set is: 27.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.26 | sMAPE for Test Set is: 51.16% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:53:44,645]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:53:50,483]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:53:56,066]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:54:17,947]\u001b[0m Trial 964 finished with value: 18.724786848950874 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021632937499549724, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2843043304786476, 'dropout_rate_Layer_2': 0.3830762019362056, 'dropout_rate_Layer_3': 0.023094224041355138, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006284336426578783, 'l1_Layer_2': 4.0428179621002154e-05, 'l1_Layer_3': 0.0007176006854380502, 'n_units_Layer_1': 235, 'n_units_Layer_2': 170, 'n_units_Layer_3': 275}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.72 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.84 | sMAPE for Test Set is: 51.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:54:21,814]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:54:57,466]\u001b[0m Trial 966 finished with value: 18.36497901544225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030255019742895465, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.141094297785046, 'dropout_rate_Layer_2': 0.08300976033789897, 'dropout_rate_Layer_3': 0.04528316043926066, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.278628810207638e-05, 'l1_Layer_2': 0.0019865905300297457, 'l1_Layer_3': 0.0003907483081891998, 'n_units_Layer_1': 60, 'n_units_Layer_2': 90, 'n_units_Layer_3': 185}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 26.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.65 | sMAPE for Test Set is: 51.22% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:55:23,691]\u001b[0m Trial 967 finished with value: 18.580304169187556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011977378389797914, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2553081891752846, 'dropout_rate_Layer_2': 0.3911900673139129, 'dropout_rate_Layer_3': 0.05563540738342549, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000513987613274723, 'l1_Layer_2': 4.885406214309908e-05, 'l1_Layer_3': 0.00137575747420145, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 27.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.08 | sMAPE for Test Set is: 50.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:55:28,786]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:55:44,704]\u001b[0m Trial 969 finished with value: 27.60720466802282 and parameters: {'n_hidden': 4, 'learning_rate': 0.00824763162769437, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16633668938739143, 'dropout_rate_Layer_2': 0.30252609235553435, 'dropout_rate_Layer_3': 0.08631841364731271, 'dropout_rate_Layer_4': 0.23059444915385643, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006139203499764465, 'l1_Layer_2': 9.615498780885804e-05, 'l1_Layer_3': 0.01902507173436775, 'l1_Layer_4': 2.241916428109082e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 255, 'n_units_Layer_3': 55, 'n_units_Layer_4': 280}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.61 | sMAPE for Validation Set is: 41.63% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 99.80 | sMAPE for Test Set is: 78.34% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:56:15,388]\u001b[0m Trial 970 finished with value: 18.62832457828622 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012400544144634442, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2556548776876263, 'dropout_rate_Layer_2': 0.3540171306718766, 'dropout_rate_Layer_3': 0.038552540751868467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046781176141352646, 'l1_Layer_2': 4.872318726718342e-05, 'l1_Layer_3': 0.00057416473600209, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.63 | sMAPE for Validation Set is: 28.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.66 | sMAPE for Test Set is: 51.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:56:19,863]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:56:23,905]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:56:27,474]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:57:00,636]\u001b[0m Trial 974 finished with value: 18.889303146560767 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009841326261874823, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2659632494766504, 'dropout_rate_Layer_2': 0.36758478870645933, 'dropout_rate_Layer_3': 0.048143085286371026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003639880943133016, 'l1_Layer_2': 2.46271632992123e-05, 'l1_Layer_3': 0.0010736028534592164, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.89 | sMAPE for Validation Set is: 27.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.28 | sMAPE for Test Set is: 51.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:57:06,946]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:57:19,399]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:57:23,900]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:57:27,909]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:58:00,251]\u001b[0m Trial 979 finished with value: 18.38047024908207 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032104090045552017, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12137240368140506, 'dropout_rate_Layer_2': 0.07160955815319879, 'dropout_rate_Layer_3': 0.05838130721238538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011029940390523987, 'l1_Layer_2': 0.0007939839799599834, 'l1_Layer_3': 0.0003498028026357834, 'n_units_Layer_1': 50, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 27.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.68 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:58:04,316]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:58:35,153]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:58:39,209]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:58:56,343]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:59:14,850]\u001b[0m Trial 984 finished with value: 18.994177531727644 and parameters: {'n_hidden': 3, 'learning_rate': 0.006158665694436495, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.332782260526235, 'dropout_rate_Layer_2': 0.04711866677532059, 'dropout_rate_Layer_3': 0.06678228248589389, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023404048529536995, 'l1_Layer_2': 0.004482090989169544, 'l1_Layer_3': 0.0014620820118761808, 'n_units_Layer_1': 235, 'n_units_Layer_2': 235, 'n_units_Layer_3': 145}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.99 | sMAPE for Validation Set is: 29.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.46 | sMAPE for Test Set is: 52.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 04:59:23,567]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 04:59:38,526]\u001b[0m Trial 986 finished with value: 27.094711845555732 and parameters: {'n_hidden': 4, 'learning_rate': 0.007316839369993194, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1621159383381321, 'dropout_rate_Layer_2': 0.31691267336445905, 'dropout_rate_Layer_3': 0.04958835100925945, 'dropout_rate_Layer_4': 0.23179846746816551, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005007729902948621, 'l1_Layer_2': 0.00013204673473919492, 'l1_Layer_3': 0.015815766557103032, 'l1_Layer_4': 3.40215880480028e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 60, 'n_units_Layer_4': 290}. Best is trial 782 with value: 18.220758934482184.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.09 | sMAPE for Validation Set is: 39.10% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 100.53 | sMAPE for Test Set is: 79.31% | rMAE for Test Set is: 1.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:00:16,116]\u001b[0m Trial 987 finished with value: 18.079535929462292 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035225091655982145, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19008744565536145, 'dropout_rate_Layer_2': 0.08569839696809217, 'dropout_rate_Layer_3': 0.05523267522155235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.293003600412897e-05, 'l1_Layer_2': 3.755311015752122e-05, 'l1_Layer_3': 0.00048086537287700295, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.08 | sMAPE for Validation Set is: 26.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.49 | sMAPE for Test Set is: 51.69% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:00:21,999]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:00:26,486]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:00:31,000]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:00:35,143]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:00:50,163]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:00:54,293]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:00,087]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:04,569]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:09,529]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:15,102]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:19,010]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:35,329]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:01:40,180]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:02:17,766]\u001b[0m Trial 1001 finished with value: 18.763011891965096 and parameters: {'n_hidden': 3, 'learning_rate': 0.004034063395330385, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16038327601518532, 'dropout_rate_Layer_2': 0.09524750899397505, 'dropout_rate_Layer_3': 0.06297421191207371, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.557626024487995e-05, 'l1_Layer_2': 3.4300517324765945e-05, 'l1_Layer_3': 0.0004837385464245146, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.76 | sMAPE for Validation Set is: 27.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.82 | sMAPE for Test Set is: 51.91% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:02:23,651]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:02:27,207]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:03:01,140]\u001b[0m Trial 1004 finished with value: 18.410634945651008 and parameters: {'n_hidden': 3, 'learning_rate': 0.004243505389767324, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16429275357563258, 'dropout_rate_Layer_2': 0.11068668659001552, 'dropout_rate_Layer_3': 0.07080963558032993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.085607285755799e-05, 'l1_Layer_2': 2.283350519890579e-05, 'l1_Layer_3': 0.0006123160423744742, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 185}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.41 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.12 | sMAPE for Test Set is: 52.32% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:03:07,072]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:03:14,848]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:03:21,151]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:03:25,260]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:04:00,830]\u001b[0m Trial 1009 finished with value: 18.238057547381473 and parameters: {'n_hidden': 3, 'learning_rate': 0.003587986171050546, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1716293486835001, 'dropout_rate_Layer_2': 0.11898744972235507, 'dropout_rate_Layer_3': 0.07326277383995751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.8240045563099625e-05, 'l1_Layer_2': 2.5634714476107088e-05, 'l1_Layer_3': 0.0005211254706730311, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 26.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.57 | sMAPE for Test Set is: 50.98% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:04:04,889]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:04:26,144]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:04:33,107]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:04:38,490]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:05:11,498]\u001b[0m Trial 1014 finished with value: 18.23436369932924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033114183452500065, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13702333592754684, 'dropout_rate_Layer_2': 0.11469854990492351, 'dropout_rate_Layer_3': 0.0673587424153711, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.536578355150326e-05, 'l1_Layer_2': 3.073783181608136e-05, 'l1_Layer_3': 0.0007028280170527843, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 180}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 26.43% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.07 | sMAPE for Test Set is: 50.97% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:05:23,810]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:05:29,334]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:05:55,274]\u001b[0m Trial 1017 finished with value: 18.814740152196403 and parameters: {'n_hidden': 3, 'learning_rate': 0.007463634735893406, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.359443072886175, 'dropout_rate_Layer_2': 0.02804747831692783, 'dropout_rate_Layer_3': 0.05183577769118386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001672858301325022, 'l1_Layer_2': 0.0028537611504739027, 'l1_Layer_3': 0.002173951111031103, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 265}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.81 | sMAPE for Validation Set is: 28.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.80 | sMAPE for Test Set is: 51.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:06:03,439]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:06:08,069]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:06:12,101]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:06:20,535]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:06:33,040]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:07:07,800]\u001b[0m Trial 1023 finished with value: 18.22984797006879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032533048690196855, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14109691072835875, 'dropout_rate_Layer_2': 0.09978543112463592, 'dropout_rate_Layer_3': 0.05918104031204843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.458594979410738e-05, 'l1_Layer_2': 3.1976895308827937e-05, 'l1_Layer_3': 0.0004973554952471529, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 26.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.67 | sMAPE for Test Set is: 50.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:07:13,677]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:07:35,643]\u001b[0m Trial 1025 finished with value: 27.49769679779891 and parameters: {'n_hidden': 4, 'learning_rate': 0.013549882216091498, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19791719193325263, 'dropout_rate_Layer_2': 0.26101816308525344, 'dropout_rate_Layer_3': 0.08332082809984179, 'dropout_rate_Layer_4': 0.25635027940821803, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004479182472582098, 'l1_Layer_2': 0.00011968413839325477, 'l1_Layer_3': 0.02248769691759209, 'l1_Layer_4': 5.65958995206936e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65, 'n_units_Layer_4': 275}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.50 | sMAPE for Validation Set is: 36.80% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 104.71 | sMAPE for Test Set is: 83.40% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:07:50,014]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:08:20,228]\u001b[0m Trial 1027 finished with value: 27.037607639474132 and parameters: {'n_hidden': 4, 'learning_rate': 0.013159126198100403, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20874966336466044, 'dropout_rate_Layer_2': 0.23802067659458895, 'dropout_rate_Layer_3': 0.08087894807831329, 'dropout_rate_Layer_4': 0.26429833982285705, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005634712073313504, 'l1_Layer_2': 0.0001321544522273601, 'l1_Layer_3': 0.02003759468408168, 'l1_Layer_4': 6.567527268404236e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 60, 'n_units_Layer_4': 275}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.04 | sMAPE for Validation Set is: 37.74% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 101.12 | sMAPE for Test Set is: 79.49% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:08:40,830]\u001b[0m Trial 1028 finished with value: 27.310956755059333 and parameters: {'n_hidden': 4, 'learning_rate': 0.014052847255305872, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20346600643686924, 'dropout_rate_Layer_2': 0.2582905817240208, 'dropout_rate_Layer_3': 0.08993305914643832, 'dropout_rate_Layer_4': 0.28016679087717444, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006261018342270754, 'l1_Layer_2': 0.00030439977622653846, 'l1_Layer_3': 0.019318685520371245, 'l1_Layer_4': 6.636227625713698e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.31 | sMAPE for Validation Set is: 39.51% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 103.23 | sMAPE for Test Set is: 81.69% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:09:01,981]\u001b[0m Trial 1029 finished with value: 18.376049443273363 and parameters: {'n_hidden': 3, 'learning_rate': 0.003375909309280566, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1390051438818739, 'dropout_rate_Layer_2': 0.11702417399295625, 'dropout_rate_Layer_3': 0.0639450690792987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.601319643744303e-05, 'l1_Layer_2': 2.570585020281173e-05, 'l1_Layer_3': 0.0004686512491976155, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 26.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.82 | sMAPE for Test Set is: 51.36% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:09:06,852]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:09:43,519]\u001b[0m Trial 1031 finished with value: 18.378772794261327 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032110139663527187, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15293300183073608, 'dropout_rate_Layer_2': 0.1063610108968772, 'dropout_rate_Layer_3': 0.06809156720951595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.9566841823701134e-05, 'l1_Layer_2': 2.2396440361708135e-05, 'l1_Layer_3': 0.0005963010344065631, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.38 | sMAPE for Validation Set is: 27.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.81 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:09:50,358]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:10:06,806]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:10:46,559]\u001b[0m Trial 1034 finished with value: 18.52690083517972 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029972304652047454, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15629732217922854, 'dropout_rate_Layer_2': 0.10226961748318901, 'dropout_rate_Layer_3': 0.08120097176910371, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.2671815798338455e-05, 'l1_Layer_2': 2.4680141081821617e-05, 'l1_Layer_3': 0.0004940134448266938, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 26.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.79 | sMAPE for Test Set is: 51.18% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:11:25,653]\u001b[0m Trial 1035 finished with value: 18.40679651932385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027689358700846473, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1590766301264209, 'dropout_rate_Layer_2': 0.1057679621520365, 'dropout_rate_Layer_3': 0.0847731845119421, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4478005252063674e-05, 'l1_Layer_2': 2.1223075435820673e-05, 'l1_Layer_3': 0.0007677902859529605, 'n_units_Layer_1': 50, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.41 | sMAPE for Validation Set is: 27.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.75 | sMAPE for Test Set is: 51.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:11:29,551]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:11:34,944]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:11:39,977]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:11:44,164]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:11:48,084]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:11:52,285]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:12:06,893]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:12:11,488]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:12:48,429]\u001b[0m Trial 1044 finished with value: 18.46866864752836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034970019048316185, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1511882855579285, 'dropout_rate_Layer_2': 0.11987697872132086, 'dropout_rate_Layer_3': 0.08437614721441034, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.053849079910584e-05, 'l1_Layer_2': 2.3721349544809864e-05, 'l1_Layer_3': 0.0009105730761459239, 'n_units_Layer_1': 55, 'n_units_Layer_2': 70, 'n_units_Layer_3': 160}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.47 | sMAPE for Validation Set is: 27.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.59 | sMAPE for Test Set is: 51.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:12:52,518]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:13:05,689]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:13:30,315]\u001b[0m Trial 1047 finished with value: 18.462794409292567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036758485673329825, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13636130974916433, 'dropout_rate_Layer_2': 0.10864946279656633, 'dropout_rate_Layer_3': 0.08442313787569203, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1969511935625086e-05, 'l1_Layer_2': 2.1810530521494112e-05, 'l1_Layer_3': 0.0008416193802060014, 'n_units_Layer_1': 55, 'n_units_Layer_2': 75, 'n_units_Layer_3': 160}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.46 | sMAPE for Validation Set is: 27.43% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.40 | sMAPE for Test Set is: 51.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:13:57,881]\u001b[0m Trial 1048 finished with value: 18.775823514108552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016757201833097056, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2428745596931521, 'dropout_rate_Layer_2': 0.383421202800647, 'dropout_rate_Layer_3': 0.05867362088769668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006474966085541159, 'l1_Layer_2': 6.483226481671647e-05, 'l1_Layer_3': 0.0019328543398270982, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 280}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.78 | sMAPE for Validation Set is: 27.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.95 | sMAPE for Test Set is: 51.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:14:06,508]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:14:11,182]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:14:38,530]\u001b[0m Trial 1051 finished with value: 18.45684097905177 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016375716036007083, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23094490477005722, 'dropout_rate_Layer_2': 0.3822229343117161, 'dropout_rate_Layer_3': 0.05999368766816608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003922683948388564, 'l1_Layer_2': 3.728042463545227e-05, 'l1_Layer_3': 0.0015064732397539178, 'n_units_Layer_1': 255, 'n_units_Layer_2': 185, 'n_units_Layer_3': 275}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.46 | sMAPE for Validation Set is: 27.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.88 | sMAPE for Test Set is: 51.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:14:43,086]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:15:14,245]\u001b[0m Trial 1053 finished with value: 18.201622845862108 and parameters: {'n_hidden': 3, 'learning_rate': 0.002290636250879603, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15045747377099278, 'dropout_rate_Layer_2': 0.11228875449179287, 'dropout_rate_Layer_3': 0.08626870862931045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.123609782699803e-05, 'l1_Layer_2': 3.081668094998641e-05, 'l1_Layer_3': 0.0008687327485467341, 'n_units_Layer_1': 50, 'n_units_Layer_2': 75, 'n_units_Layer_3': 165}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.20 | sMAPE for Validation Set is: 26.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.59 | sMAPE for Test Set is: 51.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:15:18,257]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:15:22,990]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:15:47,854]\u001b[0m Trial 1056 finished with value: 18.59338783923918 and parameters: {'n_hidden': 3, 'learning_rate': 0.002027754005681635, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2324187505645941, 'dropout_rate_Layer_2': 0.37430652588381136, 'dropout_rate_Layer_3': 0.00034267505352193056, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000357535352232607, 'l1_Layer_2': 3.76587820743432e-05, 'l1_Layer_3': 0.0015423872513189597, 'n_units_Layer_1': 255, 'n_units_Layer_2': 185, 'n_units_Layer_3': 270}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.59 | sMAPE for Validation Set is: 27.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.55 | sMAPE for Test Set is: 51.26% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:15:57,510]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:16:30,041]\u001b[0m Trial 1058 finished with value: 18.210762286230757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024028037373536627, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12609823510583534, 'dropout_rate_Layer_2': 0.10373379536756383, 'dropout_rate_Layer_3': 0.06770705836182529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8480584161692677e-05, 'l1_Layer_2': 2.6149813911220976e-05, 'l1_Layer_3': 0.001021792255494089, 'n_units_Layer_1': 55, 'n_units_Layer_2': 55, 'n_units_Layer_3': 160}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.21 | sMAPE for Validation Set is: 26.93% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.43 | sMAPE for Test Set is: 50.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:16:33,907]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:16:57,226]\u001b[0m Trial 1060 finished with value: 18.897684306156037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019409221678898705, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22893746347910665, 'dropout_rate_Layer_2': 0.3749577229497274, 'dropout_rate_Layer_3': 0.00235637401724954, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003875765782700346, 'l1_Layer_2': 3.6468313556675e-05, 'l1_Layer_3': 0.0015467576925619992, 'n_units_Layer_1': 255, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.14 | sMAPE for Test Set is: 52.15% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:17:10,593]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:17:14,904]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:17:45,386]\u001b[0m Trial 1063 finished with value: 26.814650879350783 and parameters: {'n_hidden': 4, 'learning_rate': 0.013321873118314913, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20779626341230406, 'dropout_rate_Layer_2': 0.2547779485565769, 'dropout_rate_Layer_3': 0.09699011853668955, 'dropout_rate_Layer_4': 0.28180571712441876, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000634135193693803, 'l1_Layer_2': 0.00020288038607756917, 'l1_Layer_3': 0.02007963274375827, 'l1_Layer_4': 9.471165188732715e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 165, 'n_units_Layer_3': 55, 'n_units_Layer_4': 265}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.81 | sMAPE for Validation Set is: 35.58% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 102.53 | sMAPE for Test Set is: 81.22% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:18:07,307]\u001b[0m Trial 1064 finished with value: 19.117998166292548 and parameters: {'n_hidden': 3, 'learning_rate': 0.01107937576061376, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26781757191262745, 'dropout_rate_Layer_2': 0.008431863324200239, 'dropout_rate_Layer_3': 0.02022609348065836, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001476595510203091, 'l1_Layer_2': 0.0020071828485150158, 'l1_Layer_3': 0.0038568895571530976, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 285}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 28.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 58.51 | sMAPE for Test Set is: 52.70% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:18:11,386]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:18:36,867]\u001b[0m Trial 1066 finished with value: 18.263670744329996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030362899527668235, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15070642874368326, 'dropout_rate_Layer_2': 0.12093301293206957, 'dropout_rate_Layer_3': 0.0744077786773869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.524163701392776e-05, 'l1_Layer_2': 2.0967507593085823e-05, 'l1_Layer_3': 0.0009934246986243248, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 26.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.26 | sMAPE for Test Set is: 51.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:18:41,758]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:18:48,124]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:18:57,654]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:19:06,694]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:19:11,445]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:19:36,143]\u001b[0m Trial 1072 finished with value: 18.25566887113635 and parameters: {'n_hidden': 3, 'learning_rate': 0.002610773145799642, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13888231323385913, 'dropout_rate_Layer_2': 0.11304586042255531, 'dropout_rate_Layer_3': 0.07361881215924374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8181010786573246e-05, 'l1_Layer_2': 2.6742576924902192e-05, 'l1_Layer_3': 0.00036881561623896674, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 155}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 26.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.96 | sMAPE for Test Set is: 51.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:19:59,809]\u001b[0m Trial 1073 finished with value: 18.53997537721469 and parameters: {'n_hidden': 3, 'learning_rate': 0.002605691017262014, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21679457187719403, 'dropout_rate_Layer_2': 0.35453875768630216, 'dropout_rate_Layer_3': 0.01591661656963385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005499958303586958, 'l1_Layer_2': 2.810745277884871e-05, 'l1_Layer_3': 0.0011817251763513767, 'n_units_Layer_1': 265, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 27.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.74 | sMAPE for Test Set is: 51.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:20:29,498]\u001b[0m Trial 1074 finished with value: 18.36048267393014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026855860954845315, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13975561133784528, 'dropout_rate_Layer_2': 0.11138092618236846, 'dropout_rate_Layer_3': 0.07404343080882121, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.3952192988046986e-05, 'l1_Layer_2': 2.7236042245318153e-05, 'l1_Layer_3': 0.0002861627460256584, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 26.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.80 | sMAPE for Test Set is: 51.19% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:20:59,399]\u001b[0m Trial 1075 finished with value: 18.265696998185984 and parameters: {'n_hidden': 3, 'learning_rate': 0.002600938436112408, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12715531791267354, 'dropout_rate_Layer_2': 0.1108472986433289, 'dropout_rate_Layer_3': 0.07576894936416233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.131227505487922e-05, 'l1_Layer_2': 2.75045674390684e-05, 'l1_Layer_3': 0.00029812730763212857, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 27.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.54 | sMAPE for Test Set is: 51.06% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:21:22,853]\u001b[0m Trial 1076 finished with value: 18.65823048668645 and parameters: {'n_hidden': 3, 'learning_rate': 0.00754292361532907, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30233846041131585, 'dropout_rate_Layer_2': 0.042944610045609635, 'dropout_rate_Layer_3': 0.010403186309495709, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003249755942981824, 'l1_Layer_2': 0.006695413981306811, 'l1_Layer_3': 0.002780283654959123, 'n_units_Layer_1': 250, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.66 | sMAPE for Validation Set is: 28.37% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.16 | sMAPE for Test Set is: 50.87% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:21:28,921]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:22:10,821]\u001b[0m Trial 1078 finished with value: 18.25131700679771 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024815405387146345, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13196335470212534, 'dropout_rate_Layer_2': 0.11113415734893403, 'dropout_rate_Layer_3': 0.07524464753636854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0060458027808544e-05, 'l1_Layer_2': 2.5923279272433777e-05, 'l1_Layer_3': 0.0002709421986811843, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 145}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.25 | sMAPE for Validation Set is: 26.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.22 | sMAPE for Test Set is: 51.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:22:31,673]\u001b[0m Trial 1079 finished with value: 18.263344508498296 and parameters: {'n_hidden': 3, 'learning_rate': 0.002528225815211929, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12931067605748806, 'dropout_rate_Layer_2': 0.11166195841353829, 'dropout_rate_Layer_3': 0.07716720526686333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.949296028466886e-05, 'l1_Layer_2': 2.785035867726751e-05, 'l1_Layer_3': 0.00028387138850375954, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 26.86% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.66 | sMAPE for Test Set is: 50.96% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:22:50,441]\u001b[0m Trial 1080 finished with value: 19.1560955428783 and parameters: {'n_hidden': 3, 'learning_rate': 0.004746894824992493, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28860988242092056, 'dropout_rate_Layer_2': 0.02999245188706618, 'dropout_rate_Layer_3': 0.04347523615492019, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018318601789645678, 'l1_Layer_2': 0.0006568279068875793, 'l1_Layer_3': 0.0014432149481811833, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.16 | sMAPE for Validation Set is: 28.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.48 | sMAPE for Test Set is: 51.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:23:20,947]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:23:26,180]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:23:30,386]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:23:42,460]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:24:19,550]\u001b[0m Trial 1085 finished with value: 18.180079996306418 and parameters: {'n_hidden': 3, 'learning_rate': 0.002534679073694161, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1351543954330827, 'dropout_rate_Layer_2': 0.10908607846612157, 'dropout_rate_Layer_3': 0.07673677241551001, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.104569831882998e-05, 'l1_Layer_2': 3.17324443992779e-05, 'l1_Layer_3': 0.0003458969122365249, 'n_units_Layer_1': 50, 'n_units_Layer_2': 65, 'n_units_Layer_3': 140}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.18 | sMAPE for Validation Set is: 26.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.06 | sMAPE for Test Set is: 50.58% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:24:23,837]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:24:28,483]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:24:33,028]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:24:37,774]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:25:02,467]\u001b[0m Trial 1090 finished with value: 18.358725311958423 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026417679124086397, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12226703465613102, 'dropout_rate_Layer_2': 0.12739689865936785, 'dropout_rate_Layer_3': 0.10021244931373098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.445918951365297e-05, 'l1_Layer_2': 1.8781845827097935e-05, 'l1_Layer_3': 0.00034014260538470166, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.12 | sMAPE for Test Set is: 51.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:25:44,282]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:26:24,302]\u001b[0m Trial 1092 finished with value: 18.280798728878523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025984796873343985, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12088587998083276, 'dropout_rate_Layer_2': 0.12277681438784231, 'dropout_rate_Layer_3': 0.10235391126852947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.005724673444818e-05, 'l1_Layer_2': 1.7080386318892226e-05, 'l1_Layer_3': 0.0003786721649927587, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.28 | sMAPE for Validation Set is: 27.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.64 | sMAPE for Test Set is: 51.02% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:26:46,044]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:26:58,137]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:27:03,200]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:27:43,482]\u001b[0m Trial 1096 finished with value: 18.26133664439691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027561086925251563, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12122480558727436, 'dropout_rate_Layer_2': 0.11081357534679386, 'dropout_rate_Layer_3': 0.08351311204750987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0661833512543105e-05, 'l1_Layer_2': 1.533212110247419e-05, 'l1_Layer_3': 0.0003524353989483297, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.26 | sMAPE for Validation Set is: 27.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.89 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:28:21,586]\u001b[0m Trial 1097 finished with value: 18.334294532621815 and parameters: {'n_hidden': 3, 'learning_rate': 0.002642598618091824, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11755548332315782, 'dropout_rate_Layer_2': 0.13330781120345672, 'dropout_rate_Layer_3': 0.0895136535976172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0922968710779734e-05, 'l1_Layer_2': 1.3745821892967558e-05, 'l1_Layer_3': 0.000357072806704398, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.33 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.14 | sMAPE for Test Set is: 51.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:29:00,111]\u001b[0m Trial 1098 finished with value: 18.36845547098174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025469019507449345, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1211452410299297, 'dropout_rate_Layer_2': 0.12941923682708464, 'dropout_rate_Layer_3': 0.1025298750302426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.57544200840907e-05, 'l1_Layer_2': 1.0888336658101593e-05, 'l1_Layer_3': 0.00036994682638748265, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 145}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 27.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.39 | sMAPE for Test Set is: 52.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:29:04,390]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:29:10,766]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:29:17,001]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:29:27,249]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:29:58,614]\u001b[0m Trial 1103 finished with value: 18.815027217670746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011156291598304771, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20724649160933323, 'dropout_rate_Layer_2': 0.3278291308786634, 'dropout_rate_Layer_3': 0.0014729736680729997, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022404420701335466, 'l1_Layer_2': 5.270741375029064e-05, 'l1_Layer_3': 0.0012331535410437888, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.82 | sMAPE for Validation Set is: 27.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.60 | sMAPE for Test Set is: 51.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:30:03,130]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:30:09,066]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:30:20,566]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:30:53,461]\u001b[0m Trial 1107 finished with value: 18.573715538881874 and parameters: {'n_hidden': 3, 'learning_rate': 0.002689094362404069, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12968061394563732, 'dropout_rate_Layer_2': 0.11665452261128811, 'dropout_rate_Layer_3': 0.10520986632381696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.7282174194777816e-05, 'l1_Layer_2': 1.0891374635845273e-05, 'l1_Layer_3': 0.0002344509900704931, 'n_units_Layer_1': 55, 'n_units_Layer_2': 55, 'n_units_Layer_3': 155}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.57 | sMAPE for Validation Set is: 27.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.46 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:31:14,977]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:31:19,526]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:31:59,375]\u001b[0m Trial 1110 finished with value: 18.34036933603365 and parameters: {'n_hidden': 3, 'learning_rate': 0.00197104033784249, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13655937541650795, 'dropout_rate_Layer_2': 0.12528406984029122, 'dropout_rate_Layer_3': 0.09277979327722785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.852930596569796e-05, 'l1_Layer_2': 1.700130692714796e-05, 'l1_Layer_3': 0.00037567043655140065, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 140}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.34 | sMAPE for Validation Set is: 27.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.48 | sMAPE for Test Set is: 51.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:32:12,172]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:33:05,516]\u001b[0m Trial 1112 finished with value: 18.33915561568165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019194489906274768, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11988359022853534, 'dropout_rate_Layer_2': 0.12788282851061247, 'dropout_rate_Layer_3': 0.09141309985987793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.917203548251296e-05, 'l1_Layer_2': 1.6414476866262778e-05, 'l1_Layer_3': 0.00031255072013879856, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 145}. Best is trial 987 with value: 18.079535929462292.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.34 | sMAPE for Validation Set is: 27.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.50 | sMAPE for Test Set is: 51.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:33:18,296]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:34:23,852]\u001b[0m Trial 1114 finished with value: 18.0223487129154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018326517481887228, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11540610306153924, 'dropout_rate_Layer_2': 0.1289502623981313, 'dropout_rate_Layer_3': 0.09249605546014218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.711775187048719e-05, 'l1_Layer_2': 1.2085443898113458e-05, 'l1_Layer_3': 0.0002963091797503506, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1114 with value: 18.0223487129154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.02 | sMAPE for Validation Set is: 26.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.43 | sMAPE for Test Set is: 51.32% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:34:29,899]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:35:31,874]\u001b[0m Trial 1116 finished with value: 17.98294410035278 and parameters: {'n_hidden': 3, 'learning_rate': 0.00185277759236696, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11521915271376816, 'dropout_rate_Layer_2': 0.1297979623376848, 'dropout_rate_Layer_3': 0.09583302401528832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.396784514443793e-05, 'l1_Layer_2': 1.1891860998112067e-05, 'l1_Layer_3': 0.00029097771482302677, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1116 with value: 17.98294410035278.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.98 | sMAPE for Validation Set is: 26.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.53 | sMAPE for Test Set is: 51.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:36:53,709]\u001b[0m Trial 1117 finished with value: 17.680435972813125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019260516520651332, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11501667331446173, 'dropout_rate_Layer_2': 0.14019358825280864, 'dropout_rate_Layer_3': 0.0986740658422589, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.952498779891988e-05, 'l1_Layer_2': 1.0746317436928247e-05, 'l1_Layer_3': 0.00025416637917716873, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.68 | sMAPE for Validation Set is: 26.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 54.52 | sMAPE for Test Set is: 50.41% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:36:59,253]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:37:21,558]\u001b[0m Trial 1119 finished with value: 18.35603218362873 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023299998479715824, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24845644084072757, 'dropout_rate_Layer_2': 0.3743496923938427, 'dropout_rate_Layer_3': 0.01665313561854731, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005243211916072852, 'l1_Layer_2': 3.202661395770529e-05, 'l1_Layer_3': 0.0008030243760736643, 'n_units_Layer_1': 285, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.25 | sMAPE for Test Set is: 50.37% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:37:50,172]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:39:10,582]\u001b[0m Trial 1121 finished with value: 17.960782585362427 and parameters: {'n_hidden': 3, 'learning_rate': 0.00197247919936382, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10932147240568894, 'dropout_rate_Layer_2': 0.13136410057727263, 'dropout_rate_Layer_3': 0.09828675376172377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.716092804725413e-05, 'l1_Layer_2': 1.4256178982963845e-05, 'l1_Layer_3': 0.0003020150969074814, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.96 | sMAPE for Validation Set is: 26.72% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.02 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:40:23,739]\u001b[0m Trial 1122 finished with value: 17.8709975615141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019503534384675077, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10394264824367971, 'dropout_rate_Layer_2': 0.13492434151758514, 'dropout_rate_Layer_3': 0.09764610536360308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.382596770754061e-05, 'l1_Layer_2': 1.2478300125630147e-05, 'l1_Layer_3': 0.0002636287704580276, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.87 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 54.86 | sMAPE for Test Set is: 50.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:40:29,809]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:40:36,434]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:40:45,149]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:41:59,393]\u001b[0m Trial 1126 finished with value: 18.09051547434521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020081957664093747, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10387323321753207, 'dropout_rate_Layer_2': 0.1364877810116567, 'dropout_rate_Layer_3': 0.09337451170812056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010884381538888947, 'l1_Layer_2': 1.5248780189880208e-05, 'l1_Layer_3': 0.00030070498398427617, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.09 | sMAPE for Validation Set is: 26.79% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.13 | sMAPE for Test Set is: 50.92% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:42:21,243]\u001b[0m Trial 1127 finished with value: 19.029014331089332 and parameters: {'n_hidden': 3, 'learning_rate': 0.002707997153471282, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2478364462010018, 'dropout_rate_Layer_2': 0.35727403238140687, 'dropout_rate_Layer_3': 0.04000561712426953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004222933752287845, 'l1_Layer_2': 3.145210063229528e-05, 'l1_Layer_3': 0.00047985506377229615, 'n_units_Layer_1': 280, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.03 | sMAPE for Validation Set is: 28.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.68 | sMAPE for Test Set is: 51.14% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:42:34,140]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:42:47,294]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:42:57,057]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:43:17,989]\u001b[0m Trial 1131 finished with value: 18.75693015006446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030456860111655547, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23270265215876304, 'dropout_rate_Layer_2': 0.38084573994163756, 'dropout_rate_Layer_3': 5.348190007918211e-05, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009465045390883044, 'l1_Layer_2': 2.6575279412322495e-05, 'l1_Layer_3': 0.0006792696841129927, 'n_units_Layer_1': 250, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.76 | sMAPE for Validation Set is: 28.18% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.84 | sMAPE for Test Set is: 51.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:44:27,559]\u001b[0m Trial 1132 finished with value: 17.989334213227533 and parameters: {'n_hidden': 3, 'learning_rate': 0.002008909300369599, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11036380420723935, 'dropout_rate_Layer_2': 0.13829963866397835, 'dropout_rate_Layer_3': 0.09302302309478579, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010243745737973347, 'l1_Layer_2': 1.5407876412963273e-05, 'l1_Layer_3': 0.0002945655147647009, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.99 | sMAPE for Validation Set is: 26.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.76 | sMAPE for Test Set is: 51.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:45:44,151]\u001b[0m Trial 1133 finished with value: 18.124933595328525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019222356479887365, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10710746210374558, 'dropout_rate_Layer_2': 0.13826525062885003, 'dropout_rate_Layer_3': 0.10199212572156469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.956973456492669e-05, 'l1_Layer_2': 1.574486068122742e-05, 'l1_Layer_3': 0.00021135130035289834, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 135}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.12 | sMAPE for Validation Set is: 26.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.65 | sMAPE for Test Set is: 50.75% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:45:52,082]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:46:39,590]\u001b[0m Trial 1135 finished with value: 18.513786578519163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017913573775616796, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10905230077039263, 'dropout_rate_Layer_2': 0.13883342445719346, 'dropout_rate_Layer_3': 0.0931542044878794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010860456248265101, 'l1_Layer_2': 1.582109330889135e-05, 'l1_Layer_3': 0.0001737024606127449, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 130}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.51 | sMAPE for Validation Set is: 27.48% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.45 | sMAPE for Test Set is: 52.14% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:48:01,022]\u001b[0m Trial 1136 finished with value: 18.582215720592156 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020503781764034524, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10963564864363916, 'dropout_rate_Layer_2': 0.14040275628312776, 'dropout_rate_Layer_3': 0.10368149971894386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.638962658302994e-05, 'l1_Layer_2': 1.2788094663816958e-05, 'l1_Layer_3': 0.00021427441716239653, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 27.65% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.53 | sMAPE for Test Set is: 51.08% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:49:24,701]\u001b[0m Trial 1137 finished with value: 18.304022106744725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020546271903349443, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09890209205028115, 'dropout_rate_Layer_2': 0.13689693427768812, 'dropout_rate_Layer_3': 0.092160379452693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011989067056268293, 'l1_Layer_2': 1.5385274242435817e-05, 'l1_Layer_3': 0.00024489975963683355, 'n_units_Layer_1': 60, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.30 | sMAPE for Validation Set is: 26.64% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.02 | sMAPE for Test Set is: 50.60% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:49:31,003]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:49:37,005]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:49:43,411]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:50:00,980]\u001b[0m Trial 1141 finished with value: 18.365526969195855 and parameters: {'n_hidden': 3, 'learning_rate': 0.008107042265506691, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2991254247250366, 'dropout_rate_Layer_2': 0.04039244057201794, 'dropout_rate_Layer_3': 0.0004957457036456683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003400375914405757, 'l1_Layer_2': 0.009196598737283618, 'l1_Layer_3': 0.002940508255401095, 'n_units_Layer_1': 250, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 27.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 57.10 | sMAPE for Test Set is: 51.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:50:21,792]\u001b[0m Trial 1142 finished with value: 18.536615669025835 and parameters: {'n_hidden': 3, 'learning_rate': 0.002394849672781942, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22789479924935718, 'dropout_rate_Layer_2': 0.3850528217206542, 'dropout_rate_Layer_3': 0.048986117624655594, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007180244948866032, 'l1_Layer_2': 2.038690255768002e-05, 'l1_Layer_3': 0.0015933562938924679, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.54 | sMAPE for Validation Set is: 27.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.09 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:50:27,599]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:50:34,056]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:50:40,160]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:51:19,657]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:51:44,641]\u001b[0m Trial 1147 finished with value: 18.91082886274467 and parameters: {'n_hidden': 3, 'learning_rate': 0.010123809740308036, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2925611865566853, 'dropout_rate_Layer_2': 0.02043325213555089, 'dropout_rate_Layer_3': 8.917614129405615e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014377480112196867, 'l1_Layer_2': 0.008679662530303415, 'l1_Layer_3': 0.0023227783435458894, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.91 | sMAPE for Validation Set is: 28.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.45 | sMAPE for Test Set is: 52.46% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:52:09,406]\u001b[0m Trial 1148 finished with value: 18.509599279209667 and parameters: {'n_hidden': 3, 'learning_rate': 0.007474965447082569, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2728498907615036, 'dropout_rate_Layer_2': 0.006129696898723088, 'dropout_rate_Layer_3': 0.03747105794235089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002838324780867012, 'l1_Layer_2': 0.005311934054913606, 'l1_Layer_3': 0.003946463725746155, 'n_units_Layer_1': 260, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.51 | sMAPE for Validation Set is: 27.62% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.19 | sMAPE for Test Set is: 51.38% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:52:15,150]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:52:35,027]\u001b[0m Trial 1150 finished with value: 18.92640389611879 and parameters: {'n_hidden': 3, 'learning_rate': 0.005213763722756642, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2592817795361146, 'dropout_rate_Layer_2': 0.0008648300721678349, 'dropout_rate_Layer_3': 0.015311856493093705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020434559922111588, 'l1_Layer_2': 0.0057312411498325, 'l1_Layer_3': 0.004084026628252591, 'n_units_Layer_1': 260, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 28.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.59 | sMAPE for Test Set is: 51.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:52:40,995]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:52:49,485]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:54:08,856]\u001b[0m Trial 1153 finished with value: 18.187412521101578 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022643273766249548, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10771075059438823, 'dropout_rate_Layer_2': 0.13387033310639973, 'dropout_rate_Layer_3': 0.09943416751981585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.763462560939656e-05, 'l1_Layer_2': 1.0610366008615248e-05, 'l1_Layer_3': 0.00025670467480542087, 'n_units_Layer_1': 55, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.19 | sMAPE for Validation Set is: 26.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.14 | sMAPE for Test Set is: 50.75% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:54:50,015]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:55:05,648]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:55:14,448]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:55:22,395]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:55:35,635]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:55:41,643]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:56:55,411]\u001b[0m Trial 1160 finished with value: 18.241111554339998 and parameters: {'n_hidden': 3, 'learning_rate': 0.002301745149645539, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11141852452165962, 'dropout_rate_Layer_2': 0.13368928829117419, 'dropout_rate_Layer_3': 0.08619435180562544, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.27471132964913e-05, 'l1_Layer_2': 1.2787190574961095e-05, 'l1_Layer_3': 0.00020485115106002956, 'n_units_Layer_1': 60, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.24 | sMAPE for Validation Set is: 27.25% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.96 | sMAPE for Test Set is: 51.67% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:57:10,705]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:57:16,739]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:57:36,486]\u001b[0m Trial 1163 finished with value: 19.14318768895566 and parameters: {'n_hidden': 3, 'learning_rate': 0.002279534996116861, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2286676968236045, 'dropout_rate_Layer_2': 0.39170826879352344, 'dropout_rate_Layer_3': 0.03649357935862943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003689125738936656, 'l1_Layer_2': 1.4627226779481887e-05, 'l1_Layer_3': 0.0014267820246893627, 'n_units_Layer_1': 285, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.14 | sMAPE for Validation Set is: 28.73% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.07 | sMAPE for Test Set is: 51.49% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:57:48,913]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:57:56,809]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:58:02,889]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:58:08,730]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:58:13,812]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:58:19,967]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 05:59:45,972]\u001b[0m Trial 1170 finished with value: 18.49781966066671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020421960474720827, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12550823675129175, 'dropout_rate_Layer_2': 0.1316045496411146, 'dropout_rate_Layer_3': 0.09719869364519806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.984664692534038e-05, 'l1_Layer_2': 1.6628660290265163e-05, 'l1_Layer_3': 0.00030933702575956947, 'n_units_Layer_1': 55, 'n_units_Layer_2': 55, 'n_units_Layer_3': 155}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.50 | sMAPE for Validation Set is: 26.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.37 | sMAPE for Test Set is: 51.31% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 05:59:52,428]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:00:12,456]\u001b[0m Trial 1172 finished with value: 18.26751575630193 and parameters: {'n_hidden': 3, 'learning_rate': 0.007376054275590389, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2694126360190854, 'dropout_rate_Layer_2': 0.03477741922180339, 'dropout_rate_Layer_3': 0.028940945640938437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026219861006188783, 'l1_Layer_2': 0.00993639132369245, 'l1_Layer_3': 0.0059789875205783875, 'n_units_Layer_1': 280, 'n_units_Layer_2': 190, 'n_units_Layer_3': 290}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.27 | sMAPE for Validation Set is: 27.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.39 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:00:27,996]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:00:34,183]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:00:39,951]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:00:56,407]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:02,691]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:08,865]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:13,996]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:20,011]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:25,028]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:36,570]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:52,728]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:01:58,368]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:04,148]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:16,157]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:33,269]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:38,089]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:46,590]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:52,433]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:02:58,690]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:10,865]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:17,003]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:28,551]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:34,503]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:39,434]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:54,922]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:03:59,688]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:04:19,922]\u001b[0m Trial 1199 finished with value: 18.534058888857732 and parameters: {'n_hidden': 3, 'learning_rate': 0.008671899474414374, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31609182493365673, 'dropout_rate_Layer_2': 0.09007984917484024, 'dropout_rate_Layer_3': 0.048334828867715326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010699005909901216, 'l1_Layer_2': 0.007969040503392066, 'l1_Layer_3': 0.001306638753579132, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 270}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 27.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.14 | sMAPE for Test Set is: 51.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:04:26,019]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:04:31,385]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:04:37,144]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:04:45,848]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:04:51,306]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:04:58,428]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:05:13,821]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:05:19,112]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:05:24,916]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:05:41,913]\u001b[0m Trial 1209 finished with value: 27.74662668948497 and parameters: {'n_hidden': 4, 'learning_rate': 0.008532188910920953, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1969346522525842, 'dropout_rate_Layer_2': 0.2630168013241478, 'dropout_rate_Layer_3': 0.07743605009034739, 'dropout_rate_Layer_4': 0.27098563528956127, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010338179434453728, 'l1_Layer_2': 0.00014046346585258433, 'l1_Layer_3': 0.021079034414993553, 'l1_Layer_4': 3.0795590751360874e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 270, 'n_units_Layer_3': 55, 'n_units_Layer_4': 285}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.75 | sMAPE for Validation Set is: 39.28% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 102.32 | sMAPE for Test Set is: 81.52% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:05:47,356]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:05:56,141]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:06,513]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:20,342]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:29,377]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:34,923]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:41,678]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:48,120]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:06:52,996]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:07:19,743]\u001b[0m Trial 1219 finished with value: 18.85725252894272 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022928364903285433, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21335014838717722, 'dropout_rate_Layer_2': 0.3712431514719751, 'dropout_rate_Layer_3': 0.043657521651130515, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005519181970989038, 'l1_Layer_2': 7.076663876932101e-05, 'l1_Layer_3': 0.003182069503316654, 'n_units_Layer_1': 255, 'n_units_Layer_2': 205, 'n_units_Layer_3': 270}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.86 | sMAPE for Validation Set is: 27.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.26 | sMAPE for Test Set is: 51.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:07:41,352]\u001b[0m Trial 1220 finished with value: 27.605590319009135 and parameters: {'n_hidden': 4, 'learning_rate': 0.009160348256450974, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15904235296247726, 'dropout_rate_Layer_2': 0.28371421780044526, 'dropout_rate_Layer_3': 0.12945220224073808, 'dropout_rate_Layer_4': 0.24320027886261705, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005281560395766039, 'l1_Layer_2': 6.566729151508955e-05, 'l1_Layer_3': 0.03706825662294202, 'l1_Layer_4': 4.613480378817362e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 225, 'n_units_Layer_3': 60, 'n_units_Layer_4': 295}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.61 | sMAPE for Validation Set is: 40.27% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 104.43 | sMAPE for Test Set is: 83.06% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:07:45,688]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:07:52,031]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:07:57,229]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:08:02,233]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:08:55,100]\u001b[0m Trial 1225 finished with value: 18.394280267873125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022008828942135243, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09650970864544463, 'dropout_rate_Layer_2': 0.12822959702241943, 'dropout_rate_Layer_3': 0.06702848321144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013940068272201027, 'l1_Layer_2': 1.9793383810398148e-05, 'l1_Layer_3': 0.00028026729647038167, 'n_units_Layer_1': 55, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.39 | sMAPE for Validation Set is: 27.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.41 | sMAPE for Test Set is: 50.82% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:08:59,374]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:09:05,875]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:09:11,757]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:09:29,546]\u001b[0m Trial 1229 finished with value: 18.389818845945143 and parameters: {'n_hidden': 3, 'learning_rate': 0.007382507836974787, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3051056774451578, 'dropout_rate_Layer_2': 0.06551718680592218, 'dropout_rate_Layer_3': 0.032985910294607054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011225283417546096, 'l1_Layer_2': 0.0074941286438444344, 'l1_Layer_3': 0.002050933226033348, 'n_units_Layer_1': 295, 'n_units_Layer_2': 200, 'n_units_Layer_3': 295}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.39 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.52 | sMAPE for Test Set is: 51.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:09:51,146]\u001b[0m Trial 1230 finished with value: 18.575531901305396 and parameters: {'n_hidden': 3, 'learning_rate': 0.00711524293691084, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3235117344683193, 'dropout_rate_Layer_2': 0.06366988012604896, 'dropout_rate_Layer_3': 0.0678511800479612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.29167307042137e-05, 'l1_Layer_2': 0.007305188641444968, 'l1_Layer_3': 0.00210989958896665, 'n_units_Layer_1': 295, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.58 | sMAPE for Validation Set is: 27.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.47 | sMAPE for Test Set is: 51.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:09:57,103]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:01,766]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:06,604]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:18,279]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:24,279]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:30,101]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:34,631]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:45,646]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:51,023]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:10:57,548]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:11:02,049]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:11:08,623]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:11:14,809]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:11:59,531]\u001b[0m Trial 1244 finished with value: 18.80371480362528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012643810731566868, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27962131227426357, 'dropout_rate_Layer_2': 0.3923497416822759, 'dropout_rate_Layer_3': 0.0185485775878182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000988787521089999, 'l1_Layer_2': 3.219508524560278e-05, 'l1_Layer_3': 0.0009367059114135802, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 27.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.26 | sMAPE for Test Set is: 50.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:12:05,385]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:12:11,196]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:12:31,153]\u001b[0m Trial 1247 finished with value: 18.05730549862008 and parameters: {'n_hidden': 3, 'learning_rate': 0.00202048322560249, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1386709396821769, 'dropout_rate_Layer_2': 0.10495308221850075, 'dropout_rate_Layer_3': 0.10884650657157867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.051737435311306e-05, 'l1_Layer_2': 2.417997887366517e-05, 'l1_Layer_3': 0.00016915136979825192, 'n_units_Layer_1': 55, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.06 | sMAPE for Validation Set is: 26.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 56.70 | sMAPE for Test Set is: 51.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:12:35,800]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:12:41,113]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:12:48,239]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:12:53,967]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:13:22,801]\u001b[0m Trial 1252 finished with value: 26.249651883879135 and parameters: {'n_hidden': 4, 'learning_rate': 0.009177450901928744, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14865569428161493, 'dropout_rate_Layer_2': 0.3492942673590756, 'dropout_rate_Layer_3': 0.05856729140775971, 'dropout_rate_Layer_4': 0.25663592868177987, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00039230255614977193, 'l1_Layer_2': 7.81312710893378e-05, 'l1_Layer_3': 0.04407562658032678, 'l1_Layer_4': 5.519393392486449e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65, 'n_units_Layer_4': 275}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.25 | sMAPE for Validation Set is: 35.89% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 101.85 | sMAPE for Test Set is: 80.26% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:13:27,190]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:13:44,947]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:13:52,124]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:13:56,961]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:14:01,545]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:14:29,447]\u001b[0m Trial 1258 finished with value: 18.73671170728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019866229684748857, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22546224282597094, 'dropout_rate_Layer_2': 0.37455809182827016, 'dropout_rate_Layer_3': 0.0518141553605108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004238417271373022, 'l1_Layer_2': 2.5251140481497196e-05, 'l1_Layer_3': 0.002200794023119079, 'n_units_Layer_1': 240, 'n_units_Layer_2': 155, 'n_units_Layer_3': 250}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.74 | sMAPE for Validation Set is: 27.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.45 | sMAPE for Test Set is: 51.63% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:14:34,413]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:14:39,264]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:14:53,555]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:14:58,370]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:15:03,973]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:15:30,619]\u001b[0m Trial 1264 finished with value: 17.84959165119925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024440558768951477, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1208725802950103, 'dropout_rate_Layer_2': 0.10641857172859992, 'dropout_rate_Layer_3': 0.09816993277105018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.566385671727115e-05, 'l1_Layer_2': 4.347150529229338e-05, 'l1_Layer_3': 0.0003426326511503105, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 150}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.32 | sMAPE for Test Set is: 50.85% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:15:38,464]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:15:44,273]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:15:48,978]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:15:54,375]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:00,813]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:05,511]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:11,341]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:16,792]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:23,428]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:28,989]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:16:37,638]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:17:06,182]\u001b[0m Trial 1276 finished with value: 18.75166361730636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023036944897829727, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26619940011881005, 'dropout_rate_Layer_2': 0.3745358010961941, 'dropout_rate_Layer_3': 0.06664244559783603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006711886069365823, 'l1_Layer_2': 4.44437785406205e-05, 'l1_Layer_3': 0.0043345726311746526, 'n_units_Layer_1': 295, 'n_units_Layer_2': 205, 'n_units_Layer_3': 260}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.75 | sMAPE for Validation Set is: 27.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.61 | sMAPE for Test Set is: 51.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:17:11,777]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:17:23,624]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:17:49,528]\u001b[0m Trial 1279 finished with value: 18.37032076162083 and parameters: {'n_hidden': 3, 'learning_rate': 0.002942069721182765, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14796349555442587, 'dropout_rate_Layer_2': 0.1134128059851138, 'dropout_rate_Layer_3': 0.16516209921115615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2984936799279818e-05, 'l1_Layer_2': 3.2716445913919934e-05, 'l1_Layer_3': 0.00019914358467847422, 'n_units_Layer_1': 60, 'n_units_Layer_2': 65, 'n_units_Layer_3': 145}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.37 | sMAPE for Validation Set is: 26.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.37 | sMAPE for Test Set is: 51.49% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:17:54,475]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:17:59,971]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:18:14,030]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:18:22,719]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:18:27,645]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:18:43,624]\u001b[0m Trial 1285 finished with value: 27.21917701825278 and parameters: {'n_hidden': 4, 'learning_rate': 0.008247515440721406, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39285528918721124, 'dropout_rate_Layer_2': 0.362994896381034, 'dropout_rate_Layer_3': 0.056973451775288196, 'dropout_rate_Layer_4': 0.23508720773079222, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003823281806528741, 'l1_Layer_2': 0.00011268246553682312, 'l1_Layer_3': 0.013095881839215916, 'l1_Layer_4': 6.649103891669109e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 85, 'n_units_Layer_4': 275}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.22 | sMAPE for Validation Set is: 40.95% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 99.61 | sMAPE for Test Set is: 78.86% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:18:48,798]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:18:53,730]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:00,106]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:08,640]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:13,672]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:20,940]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:26,396]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:38,102]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:19:56,526]\u001b[0m Trial 1294 finished with value: 18.802577129719534 and parameters: {'n_hidden': 3, 'learning_rate': 0.007810046562541191, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33632900909236246, 'dropout_rate_Layer_2': 0.04868609463833708, 'dropout_rate_Layer_3': 0.08717577348869149, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.4182573096193844e-05, 'l1_Layer_2': 0.01804537532920285, 'l1_Layer_3': 0.0021476209015882292, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 27.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.69 | sMAPE for Test Set is: 52.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:20:07,192]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:21:39,776]\u001b[0m Trial 1296 finished with value: 18.121178967250824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016690125169880102, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11708883702782162, 'dropout_rate_Layer_2': 0.09207702589815518, 'dropout_rate_Layer_3': 0.10685567486669499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001499936998637807, 'l1_Layer_2': 4.171274282963112e-05, 'l1_Layer_3': 0.00029423280445950087, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 155}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.12 | sMAPE for Validation Set is: 26.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.61 | sMAPE for Test Set is: 50.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:21:46,253]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:23:04,626]\u001b[0m Trial 1298 finished with value: 18.22676196123496 and parameters: {'n_hidden': 3, 'learning_rate': 0.001475591120345187, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10536953848683919, 'dropout_rate_Layer_2': 0.09043173677122247, 'dropout_rate_Layer_3': 0.11669942213039282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012250773281572376, 'l1_Layer_2': 3.523058525364842e-05, 'l1_Layer_3': 9.252789981495576e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 26.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.83 | sMAPE for Test Set is: 51.56% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:23:20,054]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:23:25,888]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:23:34,147]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:23:40,751]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:23:47,332]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:24:39,006]\u001b[0m Trial 1304 finished with value: 18.008145546712107 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015735774999577818, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10365673125332699, 'dropout_rate_Layer_2': 0.09176379602587013, 'dropout_rate_Layer_3': 0.10809698660704954, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015222947119943235, 'l1_Layer_2': 4.013386145479999e-05, 'l1_Layer_3': 6.706684962523091e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.01 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.97 | sMAPE for Test Set is: 50.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:24:51,301]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:25:43,068]\u001b[0m Trial 1306 finished with value: 18.514838354907777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014548602721273273, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09282067018046569, 'dropout_rate_Layer_2': 0.08857979648781585, 'dropout_rate_Layer_3': 0.10958825249516287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014643523950729143, 'l1_Layer_2': 3.662637861605665e-05, 'l1_Layer_3': 0.00014691448771237287, 'n_units_Layer_1': 65, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.51 | sMAPE for Validation Set is: 26.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.18 | sMAPE for Test Set is: 52.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:26:05,583]\u001b[0m Trial 1307 finished with value: 18.54701018006997 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014866783445762742, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21416736013201068, 'dropout_rate_Layer_2': 0.26597501739418167, 'dropout_rate_Layer_3': 0.01445866340546162, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005800255913845674, 'l1_Layer_2': 5.0564831268113045e-05, 'l1_Layer_3': 0.001128149635880176, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.55 | sMAPE for Validation Set is: 27.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.74 | sMAPE for Test Set is: 51.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:26:30,920]\u001b[0m Trial 1308 finished with value: 18.78889073000163 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015008927639745553, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23337717289388596, 'dropout_rate_Layer_2': 0.272030846955676, 'dropout_rate_Layer_3': 0.01446074428513153, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005985634706170858, 'l1_Layer_2': 7.632542183672926e-05, 'l1_Layer_3': 0.0006005210581439171, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.79 | sMAPE for Validation Set is: 27.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.59 | sMAPE for Test Set is: 51.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:26:37,824]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:27:28,839]\u001b[0m Trial 1310 finished with value: 17.847159382801376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016061421574891088, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1053916234051996, 'dropout_rate_Layer_2': 0.09898047970942192, 'dropout_rate_Layer_3': 0.12380950532491453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016636949597102386, 'l1_Layer_2': 4.4156853395202184e-05, 'l1_Layer_3': 5.671773907733767e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.85 | sMAPE for Validation Set is: 26.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.04 | sMAPE for Test Set is: 50.40% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:27:37,295]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:28:30,705]\u001b[0m Trial 1312 finished with value: 18.358568379145733 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016384927219503468, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10221208637397561, 'dropout_rate_Layer_2': 0.09024501202462762, 'dropout_rate_Layer_3': 0.11481944692331524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001663640469439877, 'l1_Layer_2': 3.716252001686804e-05, 'l1_Layer_3': 9.725221894928653e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.36 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.60 | sMAPE for Test Set is: 51.66% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:28:36,226]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:28:42,240]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:28:48,227]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:28:53,325]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:29:40,995]\u001b[0m Trial 1317 finished with value: 18.226729222497237 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011114913079922498, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1034724608520641, 'dropout_rate_Layer_2': 0.09471555105713331, 'dropout_rate_Layer_3': 0.1273951982059524, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014350091855243858, 'l1_Layer_2': 5.027197306027186e-05, 'l1_Layer_3': 5.462731408019099e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 80, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.23 | sMAPE for Validation Set is: 26.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.09 | sMAPE for Test Set is: 51.56% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:29:49,123]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:29:55,728]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:11,759]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:19,771]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:26,622]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:41,731]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:30:48,045]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:03,363]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:31:57,170]\u001b[0m Trial 1326 finished with value: 18.283641684144126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010120333450476986, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09595779306459913, 'dropout_rate_Layer_2': 0.0896356173840947, 'dropout_rate_Layer_3': 0.11067672513847834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011866192812508065, 'l1_Layer_2': 3.931499961161678e-05, 'l1_Layer_3': 3.9146872641202884e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.28 | sMAPE for Validation Set is: 26.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.51 | sMAPE for Test Set is: 52.07% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:32:05,174]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:10,188]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:15,886]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:31,872]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:38,258]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:44,253]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:32:50,254]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:00,522]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:12,039]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:25,972]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:34,244]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:43,115]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:33:54,744]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:34:38,381]\u001b[0m Trial 1340 finished with value: 18.936866136994386 and parameters: {'n_hidden': 3, 'learning_rate': 0.001364901650885776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11449728724123515, 'dropout_rate_Layer_2': 0.10039396041925013, 'dropout_rate_Layer_3': 0.11741678915148607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012949773807729103, 'l1_Layer_2': 3.811275971244669e-05, 'l1_Layer_3': 5.814709977581903e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.94 | sMAPE for Validation Set is: 27.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.23 | sMAPE for Test Set is: 51.89% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:34:55,107]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:35:32,045]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:36:50,458]\u001b[0m Trial 1343 finished with value: 17.891307542600725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014919644743368013, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11317062981954272, 'dropout_rate_Layer_2': 0.10324434285736112, 'dropout_rate_Layer_3': 0.12695022311097848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014796919001078848, 'l1_Layer_2': 3.362370261503839e-05, 'l1_Layer_3': 4.304910489556412e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.89 | sMAPE for Validation Set is: 26.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 55.28 | sMAPE for Test Set is: 51.10% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:36:56,533]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:03,214]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:17,906]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:22,481]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:37:37,730]\u001b[0m Trial 1348 finished with value: 28.21727208824339 and parameters: {'n_hidden': 4, 'learning_rate': 0.008680875087992328, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3847097712205365, 'dropout_rate_Layer_2': 0.08664868755387456, 'dropout_rate_Layer_3': 0.10008824072430844, 'dropout_rate_Layer_4': 0.2109810256211133, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007226371859367127, 'l1_Layer_2': 7.086793326278058e-05, 'l1_Layer_3': 0.01248900381803826, 'l1_Layer_4': 5.931290852387971e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 55, 'n_units_Layer_4': 285}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.22 | sMAPE for Validation Set is: 44.49% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 102.77 | sMAPE for Test Set is: 81.94% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:38:16,373]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:38:31,305]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:09,647]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:16,011]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:21,881]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:29,005]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:35,060]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:49,510]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:39:55,617]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:48,351]\u001b[0m Trial 1358 finished with value: 18.471693402034834 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014922644727438355, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11728095987777348, 'dropout_rate_Layer_2': 0.10351359791294532, 'dropout_rate_Layer_3': 0.09890384267829466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.285672191204144e-05, 'l1_Layer_2': 5.894494165879924e-05, 'l1_Layer_3': 5.836425932574907e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 55, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.47 | sMAPE for Validation Set is: 27.12% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.38 | sMAPE for Test Set is: 51.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:40:53,692]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:40:59,396]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:01,397]\u001b[0m Trial 1361 finished with value: 18.48055231574361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015893074031691152, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19495585336898524, 'dropout_rate_Layer_2': 0.09317043645317659, 'dropout_rate_Layer_3': 0.11048389110676271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014223020121760773, 'l1_Layer_2': 3.344890813966993e-05, 'l1_Layer_3': 4.49138714196412e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 70, 'n_units_Layer_3': 130}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.48 | sMAPE for Validation Set is: 26.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.03 | sMAPE for Test Set is: 52.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:42:09,213]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:17,107]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:28,768]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:42:34,974]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:01,976]\u001b[0m Trial 1366 finished with value: 18.084860104734506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017084660909167555, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09755809145284362, 'dropout_rate_Layer_2': 0.08596267587775056, 'dropout_rate_Layer_3': 0.13733602979679624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011746639852830246, 'l1_Layer_2': 4.911605345848367e-05, 'l1_Layer_3': 5.696362522424644e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 175}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.08 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.91 | sMAPE for Test Set is: 50.94% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:44:10,379]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:15,884]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:24,904]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:31,387]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:44:37,393]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:05,343]\u001b[0m Trial 1372 finished with value: 26.90669157171563 and parameters: {'n_hidden': 4, 'learning_rate': 0.009520253877510772, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2861303321526715, 'dropout_rate_Layer_2': 0.21811060923494133, 'dropout_rate_Layer_3': 0.31414900603878865, 'dropout_rate_Layer_4': 0.21675284291668012, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000589583960742622, 'l1_Layer_2': 7.455718625366886e-05, 'l1_Layer_3': 0.07406710995428976, 'l1_Layer_4': 4.522488916841308e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70, 'n_units_Layer_4': 275}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.91 | sMAPE for Validation Set is: 36.31% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 103.03 | sMAPE for Test Set is: 81.13% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:45:21,879]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:27,977]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:33,911]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:46,284]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:45:52,776]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:08,772]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:35,527]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:42,320]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:50,372]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:46:57,112]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:03,824]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:19,245]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:25,048]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:31,219]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:37,908]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:47:44,069]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:00,791]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:48:07,287]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:02,069]\u001b[0m Trial 1391 finished with value: 18.5265556397912 and parameters: {'n_hidden': 3, 'learning_rate': 0.001767857231864014, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11249713506347866, 'dropout_rate_Layer_2': 0.10438227936571956, 'dropout_rate_Layer_3': 0.1700458641344268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002229095672331457, 'l1_Layer_2': 4.328033560263061e-05, 'l1_Layer_3': 6.190340918800654e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 27.41% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.73 | sMAPE for Test Set is: 52.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:49:07,623]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:13,790]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:19,816]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:36,202]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:44,579]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:50,685]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:49:56,855]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:03,535]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:12,406]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:17,505]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:25,589]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:50:31,010]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:51:58,930]\u001b[0m Trial 1404 finished with value: 18.530419479862996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020105752049744273, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10670393909337807, 'dropout_rate_Layer_2': 0.1304223169665359, 'dropout_rate_Layer_3': 0.09721292317984409, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004240865658637987, 'l1_Layer_2': 0.005578056022410117, 'l1_Layer_3': 3.68770779820005e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 65, 'n_units_Layer_3': 115}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.53 | sMAPE for Validation Set is: 26.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.73 | sMAPE for Test Set is: 51.59% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:52:16,505]\u001b[0m Trial 1405 finished with value: 18.564004668199583 and parameters: {'n_hidden': 3, 'learning_rate': 0.00588861364763169, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30641102772578893, 'dropout_rate_Layer_2': 0.060494554840273676, 'dropout_rate_Layer_3': 0.015231918536776773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019788395190155374, 'l1_Layer_2': 0.005116016838388549, 'l1_Layer_3': 0.0024943772770415124, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.56 | sMAPE for Validation Set is: 27.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.87 | sMAPE for Test Set is: 51.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:52:27,092]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:36,496]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:52:42,963]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:23,936]\u001b[0m Trial 1409 finished with value: 18.672746090039308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011700898720064653, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26718603058788254, 'dropout_rate_Layer_2': 0.3628412436370701, 'dropout_rate_Layer_3': 0.009032841063812948, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005387838808949582, 'l1_Layer_2': 8.346304714325006e-05, 'l1_Layer_3': 0.0010200302872865837, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.67 | sMAPE for Validation Set is: 27.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 57.10 | sMAPE for Test Set is: 51.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:53:30,074]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:36,186]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:41,291]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:53:56,731]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:15,409]\u001b[0m Trial 1414 finished with value: 18.43499360213136 and parameters: {'n_hidden': 3, 'learning_rate': 0.008976772733878412, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29467553687780423, 'dropout_rate_Layer_2': 0.04754432186836832, 'dropout_rate_Layer_3': 0.02552210588934454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003040626230752901, 'l1_Layer_2': 0.010311045199858348, 'l1_Layer_3': 0.0030868026358832996, 'n_units_Layer_1': 290, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.43 | sMAPE for Validation Set is: 26.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.25 | sMAPE for Test Set is: 51.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:54:22,128]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:28,320]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:34,372]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:43,458]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:54:59,683]\u001b[0m Trial 1419 finished with value: 18.860026829836396 and parameters: {'n_hidden': 3, 'learning_rate': 0.012075039973166602, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25485012748213826, 'dropout_rate_Layer_2': 0.00807738404679756, 'dropout_rate_Layer_3': 0.024961367245481075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029576113691795616, 'l1_Layer_2': 0.011451122981025975, 'l1_Layer_3': 0.0029282733478074776, 'n_units_Layer_1': 255, 'n_units_Layer_2': 205, 'n_units_Layer_3': 300}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.86 | sMAPE for Validation Set is: 27.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.53 | sMAPE for Test Set is: 52.20% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:55:16,221]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:22,470]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:28,349]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:33,997]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:42,998]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:55:48,072]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:56:14,017]\u001b[0m Trial 1426 finished with value: 28.22790651556278 and parameters: {'n_hidden': 4, 'learning_rate': 0.010826093408567912, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30054673082090877, 'dropout_rate_Layer_2': 0.21628479463293693, 'dropout_rate_Layer_3': 0.2871903383562185, 'dropout_rate_Layer_4': 0.39075657909890527, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005574073958400125, 'l1_Layer_2': 5.9420242127279107e-05, 'l1_Layer_3': 0.040454986765560835, 'l1_Layer_4': 3.742555655121054e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90, 'n_units_Layer_4': 300}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.23 | sMAPE for Validation Set is: 37.36% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 106.66 | sMAPE for Test Set is: 85.21% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:56:50,910]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:43,725]\u001b[0m Trial 1428 finished with value: 18.899060377322098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020837840652366195, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10343684259222653, 'dropout_rate_Layer_2': 0.13917796621207337, 'dropout_rate_Layer_3': 0.09299770175242927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.811585752088997e-05, 'l1_Layer_2': 0.0038979597253191696, 'l1_Layer_3': 2.1751314827167607e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 27.84% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.57 | sMAPE for Test Set is: 52.95% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 06:57:48,563]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:57:54,513]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:04,697]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:12,762]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:27,742]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:42,405]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:47,019]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:58:52,501]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:02,274]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:08,534]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:19,180]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:24,570]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:30,918]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:47,795]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 06:59:54,664]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:00,231]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:08,212]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:14,496]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:20,257]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:26,517]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:33,389]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:39,188]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:00:51,180]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:04,731]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:21,704]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:27,963]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:33,013]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:39,598]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:44,253]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:01:53,152]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:12,389]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:19,065]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:25,610]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:02:33,107]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:07,637]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:13,804]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:03:19,830]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:05,974]\u001b[0m Trial 1466 finished with value: 18.35266183650472 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017181058570363283, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10949145496706955, 'dropout_rate_Layer_2': 0.29095752786160334, 'dropout_rate_Layer_3': 0.1454554674026853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.166723529632934e-05, 'l1_Layer_2': 3.0828312761251126e-05, 'l1_Layer_3': 0.00025113041069232223, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 27.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.87 | sMAPE for Test Set is: 50.96% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:04:11,482]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:16,478]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:22,751]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:28,461]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:04:39,527]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:18,108]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:38,123]\u001b[0m Trial 1473 finished with value: 28.327369129886396 and parameters: {'n_hidden': 4, 'learning_rate': 0.012869926388702478, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1695356810276901, 'dropout_rate_Layer_2': 0.3630296380270381, 'dropout_rate_Layer_3': 0.19871857539505092, 'dropout_rate_Layer_4': 0.24022530926029298, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005082915729812036, 'l1_Layer_2': 0.00012440793561536797, 'l1_Layer_3': 0.018097030396123856, 'l1_Layer_4': 4.027210202377646e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 235, 'n_units_Layer_3': 55, 'n_units_Layer_4': 300}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.33 | sMAPE for Validation Set is: 39.97% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 105.63 | sMAPE for Test Set is: 83.89% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:05:46,990]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:52,493]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:05:58,833]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:07,127]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:06:33,183]\u001b[0m Trial 1478 finished with value: 18.441254354585553 and parameters: {'n_hidden': 3, 'learning_rate': 0.008186833272911417, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26149805952715777, 'dropout_rate_Layer_2': 0.0132652960513511, 'dropout_rate_Layer_3': 0.0303456363847194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001566963723196318, 'l1_Layer_2': 0.004120752515528349, 'l1_Layer_3': 0.0032297635218843067, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.44 | sMAPE for Validation Set is: 27.52% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.01 | sMAPE for Test Set is: 50.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:06:49,109]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:07:30,235]\u001b[0m Trial 1480 finished with value: 18.354883201624954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018694718220623745, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11454667155733655, 'dropout_rate_Layer_2': 0.13981077759128419, 'dropout_rate_Layer_3': 0.0898385610817975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.652353829047781e-05, 'l1_Layer_2': 0.006029723844987772, 'l1_Layer_3': 5.198863276390823e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 1117 with value: 17.680435972813125.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.35 | sMAPE for Validation Set is: 27.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 55.65 | sMAPE for Test Set is: 51.56% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 07:08:09,930]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:20,984]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:08:38,119]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:16,084]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:21,732]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:28,460]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:34,044]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:44,165]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:50,318]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:09:55,168]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:00,251]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:06,676]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:12,932]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:19,283]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:25,960]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:38,964]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:48,099]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:10:53,965]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 07:11:02,727]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-01-01, MAE is:27.07 & sMAPE is:32.31% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :27.07 & 32.31% & 0.58\n",
      "for 2022-01-02, MAE is:44.55 & sMAPE is:56.56% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :35.81 & 44.44% & 0.52\n",
      "for 2022-01-03, MAE is:21.70 & sMAPE is:34.84% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :31.11 & 41.24% & 0.44\n",
      "for 2022-01-04, MAE is:60.98 & sMAPE is:58.79% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :38.57 & 45.63% & 0.91\n",
      "for 2022-01-05, MAE is:18.49 & sMAPE is:19.96% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :34.56 & 40.49% & 0.83\n",
      "for 2022-01-06, MAE is:73.03 & sMAPE is:48.96% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :40.97 & 41.91% & 0.82\n",
      "for 2022-01-07, MAE is:29.64 & sMAPE is:17.83% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :39.35 & 38.47% & 0.75\n",
      "for 2022-01-08, MAE is:21.62 & sMAPE is:14.45% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :37.13 & 35.46% & 0.69\n",
      "for 2022-01-09, MAE is:26.22 & sMAPE is:18.40% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :35.92 & 33.57% & 0.64\n",
      "for 2022-01-10, MAE is:79.07 & sMAPE is:35.70% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :40.24 & 33.78% & 0.63\n",
      "for 2022-01-11, MAE is:31.01 & sMAPE is:17.04% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :39.40 & 32.26% & 0.64\n",
      "for 2022-01-12, MAE is:63.73 & sMAPE is:70.47% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :41.43 & 35.44% & 0.71\n",
      "for 2022-01-13, MAE is:68.02 & sMAPE is:128.83% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :43.47 & 42.63% & 0.69\n",
      "for 2022-01-14, MAE is:28.27 & sMAPE is:53.52% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :42.39 & 43.40% & 0.66\n",
      "for 2022-01-15, MAE is:52.88 & sMAPE is:63.18% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :43.09 & 44.72% & 0.66\n",
      "for 2022-01-16, MAE is:48.67 & sMAPE is:106.54% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :43.43 & 48.59% & 0.65\n",
      "for 2022-01-17, MAE is:24.00 & sMAPE is:35.86% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :42.29 & 47.84% & 0.62\n",
      "for 2022-01-18, MAE is:59.75 & sMAPE is:47.75% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :43.26 & 47.83% & 0.67\n",
      "for 2022-01-19, MAE is:34.97 & sMAPE is:53.42% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :42.83 & 48.13% & 0.70\n",
      "for 2022-01-20, MAE is:37.04 & sMAPE is:62.14% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :42.54 & 48.83% & 0.70\n",
      "for 2022-01-21, MAE is:37.38 & sMAPE is:48.41% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :42.29 & 48.81% & 0.70\n",
      "for 2022-01-22, MAE is:62.48 & sMAPE is:50.17% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :43.21 & 48.87% & 0.71\n",
      "for 2022-01-23, MAE is:25.36 & sMAPE is:30.79% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :42.43 & 48.08% & 0.69\n",
      "for 2022-01-24, MAE is:30.30 & sMAPE is:66.52% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :41.93 & 48.85% & 0.70\n",
      "for 2022-01-25, MAE is:64.98 & sMAPE is:60.34% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :42.85 & 49.31% & 0.72\n",
      "for 2022-01-26, MAE is:16.75 & sMAPE is:19.12% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :41.84 & 48.15% & 0.71\n",
      "for 2022-01-27, MAE is:49.57 & sMAPE is:43.15% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :42.13 & 47.97% & 0.71\n",
      "for 2022-01-28, MAE is:20.60 & sMAPE is:18.41% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :41.36 & 46.91% & 0.72\n",
      "for 2022-01-29, MAE is:79.77 & sMAPE is:128.34% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :42.69 & 49.72% & 0.72\n",
      "for 2022-01-30, MAE is:20.23 & sMAPE is:63.44% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :41.94 & 50.17% & 0.71\n",
      "for 2022-01-31, MAE is:92.48 & sMAPE is:69.20% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :43.57 & 50.79% & 0.71\n",
      "for 2022-02-01, MAE is:39.19 & sMAPE is:27.45% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :43.43 & 50.06% & 0.71\n",
      "for 2022-02-02, MAE is:49.44 & sMAPE is:31.41% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :43.61 & 49.49% & 0.71\n",
      "for 2022-02-03, MAE is:30.73 & sMAPE is:18.55% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :43.23 & 48.58% & 0.71\n",
      "for 2022-02-04, MAE is:61.10 & sMAPE is:65.16% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :43.75 & 49.06% & 0.72\n",
      "for 2022-02-05, MAE is:26.69 & sMAPE is:50.61% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :43.27 & 49.10% & 0.72\n",
      "for 2022-02-06, MAE is:29.16 & sMAPE is:68.41% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :42.89 & 49.62% & 0.76\n",
      "for 2022-02-07, MAE is:22.76 & sMAPE is:35.23% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.36 & 49.24% & 0.75\n",
      "for 2022-02-08, MAE is:24.39 & sMAPE is:29.39% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :41.90 & 48.73% & 0.74\n",
      "for 2022-02-09, MAE is:25.03 & sMAPE is:34.43% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :41.48 & 48.38% & 0.73\n",
      "for 2022-02-10, MAE is:23.66 & sMAPE is:52.66% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :41.04 & 48.48% & 0.72\n",
      "for 2022-02-11, MAE is:58.73 & sMAPE is:74.95% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :41.46 & 49.11% & 0.73\n",
      "for 2022-02-12, MAE is:27.30 & sMAPE is:61.77% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :41.13 & 49.41% & 0.74\n",
      "for 2022-02-13, MAE is:35.17 & sMAPE is:105.06% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :41.00 & 50.67% & 0.76\n",
      "for 2022-02-14, MAE is:29.77 & sMAPE is:56.11% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :40.75 & 50.79% & 0.76\n",
      "for 2022-02-15, MAE is:35.85 & sMAPE is:59.81% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :40.64 & 50.99% & 0.78\n",
      "for 2022-02-16, MAE is:29.49 & sMAPE is:43.23% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :40.41 & 50.82% & 0.79\n",
      "for 2022-02-17, MAE is:16.96 & sMAPE is:30.17% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :39.92 & 50.39% & 0.80\n",
      "for 2022-02-18, MAE is:26.79 & sMAPE is:43.29% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :39.65 & 50.25% & 0.80\n",
      "for 2022-02-19, MAE is:17.12 & sMAPE is:32.08% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :39.20 & 49.88% & 0.80\n",
      "for 2022-02-20, MAE is:16.07 & sMAPE is:26.80% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :38.75 & 49.43% & 0.79\n",
      "for 2022-02-21, MAE is:13.99 & sMAPE is:23.56% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :38.27 & 48.93% & 0.79\n",
      "for 2022-02-22, MAE is:62.82 & sMAPE is:73.05% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :38.73 & 49.39% & 0.80\n",
      "for 2022-02-23, MAE is:28.20 & sMAPE is:35.46% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :38.54 & 49.13% & 0.80\n",
      "for 2022-02-24, MAE is:22.78 & sMAPE is:52.39% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :38.25 & 49.19% & 0.81\n",
      "for 2022-02-25, MAE is:26.58 & sMAPE is:43.26% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :38.04 & 49.08% & 0.81\n",
      "for 2022-02-26, MAE is:41.03 & sMAPE is:59.90% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :38.10 & 49.27% & 0.83\n",
      "for 2022-02-27, MAE is:19.83 & sMAPE is:54.98% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :37.78 & 49.37% & 0.82\n",
      "for 2022-02-28, MAE is:45.50 & sMAPE is:57.51% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :37.91 & 49.51% & 0.83\n",
      "for 2022-03-01, MAE is:20.18 & sMAPE is:36.23% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :37.62 & 49.29% & 0.83\n",
      "for 2022-03-02, MAE is:21.66 & sMAPE is:41.61% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :37.35 & 49.16% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-03, MAE is:24.80 & sMAPE is:38.89% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :37.15 & 49.00% & 0.82\n",
      "for 2022-03-04, MAE is:118.59 & sMAPE is:82.61% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :38.44 & 49.53% & 0.83\n",
      "for 2022-03-05, MAE is:29.79 & sMAPE is:31.74% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :38.31 & 49.25% & 0.82\n",
      "for 2022-03-06, MAE is:25.65 & sMAPE is:41.35% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :38.11 & 49.13% & 0.82\n",
      "for 2022-03-07, MAE is:89.87 & sMAPE is:47.67% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :38.90 & 49.11% & 0.83\n",
      "for 2022-03-08, MAE is:100.28 & sMAPE is:69.90% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :39.81 & 49.42% & 0.83\n",
      "for 2022-03-09, MAE is:80.96 & sMAPE is:44.60% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :40.42 & 49.35% & 0.83\n",
      "for 2022-03-10, MAE is:26.27 & sMAPE is:49.45% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :40.21 & 49.35% & 0.83\n",
      "for 2022-03-11, MAE is:30.45 & sMAPE is:38.91% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :40.08 & 49.20% & 0.82\n",
      "for 2022-03-12, MAE is:28.14 & sMAPE is:26.08% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :39.91 & 48.88% & 0.82\n",
      "for 2022-03-13, MAE is:31.26 & sMAPE is:50.77% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :39.79 & 48.90% & 0.83\n",
      "for 2022-03-14, MAE is:25.04 & sMAPE is:22.62% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :39.59 & 48.54% & 0.82\n",
      "for 2022-03-15, MAE is:48.75 & sMAPE is:42.33% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :39.71 & 48.46% & 0.82\n",
      "for 2022-03-16, MAE is:33.38 & sMAPE is:40.75% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :39.62 & 48.36% & 0.82\n",
      "for 2022-03-17, MAE is:23.52 & sMAPE is:73.74% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :39.41 & 48.69% & 0.82\n",
      "for 2022-03-18, MAE is:13.39 & sMAPE is:35.61% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :39.07 & 48.52% & 0.81\n",
      "for 2022-03-19, MAE is:12.43 & sMAPE is:63.33% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :38.73 & 48.71% & 0.80\n",
      "for 2022-03-20, MAE is:13.09 & sMAPE is:65.47% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :38.41 & 48.92% & 0.80\n",
      "for 2022-03-21, MAE is:20.27 & sMAPE is:44.79% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :38.18 & 48.87% & 0.79\n",
      "for 2022-03-22, MAE is:51.57 & sMAPE is:46.14% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :38.35 & 48.84% & 0.79\n",
      "for 2022-03-23, MAE is:84.82 & sMAPE is:83.15% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :38.91 & 49.25% & 0.80\n",
      "for 2022-03-24, MAE is:60.82 & sMAPE is:77.05% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :39.18 & 49.59% & 0.80\n",
      "for 2022-03-25, MAE is:24.50 & sMAPE is:62.05% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :39.00 & 49.74% & 0.80\n",
      "for 2022-03-26, MAE is:11.08 & sMAPE is:47.61% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :38.67 & 49.71% & 0.80\n",
      "for 2022-03-27, MAE is:29.43 & sMAPE is:74.34% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :38.57 & 50.00% & 0.80\n",
      "for 2022-03-28, MAE is:14.86 & sMAPE is:62.07% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :38.29 & 50.14% & 0.80\n",
      "for 2022-03-29, MAE is:60.66 & sMAPE is:82.55% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :38.55 & 50.51% & 0.81\n",
      "for 2022-03-30, MAE is:35.76 & sMAPE is:39.65% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :38.52 & 50.38% & 0.81\n",
      "for 2022-03-31, MAE is:82.11 & sMAPE is:55.25% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :39.00 & 50.44% & 0.81\n",
      "for 2022-04-01, MAE is:38.49 & sMAPE is:26.52% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :39.00 & 50.18% & 0.81\n",
      "for 2022-04-02, MAE is:59.73 & sMAPE is:75.93% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :39.22 & 50.46% & 0.82\n",
      "for 2022-04-03, MAE is:10.25 & sMAPE is:18.58% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :38.91 & 50.11% & 0.81\n",
      "for 2022-04-04, MAE is:13.09 & sMAPE is:18.85% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :38.64 & 49.78% & 0.80\n",
      "for 2022-04-05, MAE is:21.68 & sMAPE is:45.48% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :38.46 & 49.73% & 0.80\n",
      "for 2022-04-06, MAE is:37.85 & sMAPE is:50.78% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :38.45 & 49.75% & 0.81\n",
      "for 2022-04-07, MAE is:25.24 & sMAPE is:31.18% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :38.31 & 49.55% & 0.80\n",
      "for 2022-04-08, MAE is:27.41 & sMAPE is:73.59% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :38.20 & 49.80% & 0.79\n",
      "for 2022-04-09, MAE is:7.99 & sMAPE is:31.66% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :37.90 & 49.62% & 0.79\n",
      "for 2022-04-10, MAE is:13.91 & sMAPE is:59.55% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :37.66 & 49.72% & 0.79\n",
      "for 2022-04-11, MAE is:44.26 & sMAPE is:62.62% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :37.72 & 49.84% & 0.79\n",
      "for 2022-04-12, MAE is:68.33 & sMAPE is:71.92% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :38.02 & 50.06% & 0.80\n",
      "for 2022-04-13, MAE is:30.32 & sMAPE is:27.71% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :37.95 & 49.84% & 0.80\n",
      "for 2022-04-14, MAE is:39.61 & sMAPE is:53.73% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :37.96 & 49.88% & 0.81\n",
      "for 2022-04-15, MAE is:11.83 & sMAPE is:21.01% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :37.72 & 49.61% & 0.80\n",
      "for 2022-04-16, MAE is:13.12 & sMAPE is:23.88% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :37.48 & 49.36% & 0.80\n",
      "for 2022-04-17, MAE is:17.55 & sMAPE is:41.78% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :37.30 & 49.29% & 0.80\n",
      "for 2022-04-18, MAE is:15.55 & sMAPE is:25.88% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :37.10 & 49.07% & 0.79\n",
      "for 2022-04-19, MAE is:22.81 & sMAPE is:25.23% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :36.97 & 48.86% & 0.79\n",
      "for 2022-04-20, MAE is:8.96 & sMAPE is:12.23% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :36.71 & 48.52% & 0.79\n",
      "for 2022-04-21, MAE is:16.45 & sMAPE is:34.17% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :36.53 & 48.39% & 0.78\n",
      "for 2022-04-22, MAE is:13.18 & sMAPE is:33.23% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :36.32 & 48.26% & 0.78\n",
      "for 2022-04-23, MAE is:8.49 & sMAPE is:33.71% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :36.07 & 48.13% & 0.78\n",
      "for 2022-04-24, MAE is:53.67 & sMAPE is:92.05% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :36.23 & 48.52% & 0.78\n",
      "for 2022-04-25, MAE is:82.65 & sMAPE is:65.02% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :36.63 & 48.66% & 0.78\n",
      "for 2022-04-26, MAE is:86.33 & sMAPE is:92.37% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :37.06 & 49.04% & 0.79\n",
      "for 2022-04-27, MAE is:56.41 & sMAPE is:43.19% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :37.23 & 48.99% & 0.79\n",
      "for 2022-04-28, MAE is:57.68 & sMAPE is:46.91% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :37.40 & 48.97% & 0.79\n",
      "for 2022-04-29, MAE is:66.87 & sMAPE is:57.84% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :37.65 & 49.04% & 0.79\n",
      "for 2022-04-30, MAE is:54.55 & sMAPE is:81.41% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :37.79 & 49.31% & 0.79\n",
      "for 2022-05-01, MAE is:44.64 & sMAPE is:35.57% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :37.84 & 49.20% & 0.79\n",
      "for 2022-05-02, MAE is:104.99 & sMAPE is:121.29% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :38.39 & 49.79% & 0.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-03, MAE is:61.79 & sMAPE is:54.14% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :38.58 & 49.82% & 0.79\n",
      "for 2022-05-04, MAE is:47.49 & sMAPE is:26.97% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :38.66 & 49.64% & 0.79\n",
      "for 2022-05-05, MAE is:49.63 & sMAPE is:44.30% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :38.74 & 49.60% & 0.81\n",
      "for 2022-05-06, MAE is:67.98 & sMAPE is:89.91% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :38.98 & 49.92% & 0.81\n",
      "for 2022-05-07, MAE is:26.71 & sMAPE is:100.54% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :38.88 & 50.32% & 0.81\n",
      "for 2022-05-08, MAE is:44.72 & sMAPE is:74.50% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :38.92 & 50.51% & 0.81\n",
      "for 2022-05-09, MAE is:74.70 & sMAPE is:61.89% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :39.20 & 50.59% & 0.81\n",
      "for 2022-05-10, MAE is:50.28 & sMAPE is:74.07% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :39.29 & 50.77% & 0.81\n",
      "for 2022-05-11, MAE is:42.69 & sMAPE is:52.70% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :39.31 & 50.79% & 0.80\n",
      "for 2022-05-12, MAE is:29.71 & sMAPE is:39.60% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :39.24 & 50.70% & 0.80\n",
      "for 2022-05-13, MAE is:50.85 & sMAPE is:48.11% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :39.33 & 50.68% & 0.80\n",
      "for 2022-05-14, MAE is:41.12 & sMAPE is:46.16% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :39.34 & 50.65% & 0.80\n",
      "for 2022-05-15, MAE is:45.23 & sMAPE is:73.04% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :39.38 & 50.82% & 0.81\n",
      "for 2022-05-16, MAE is:42.52 & sMAPE is:56.02% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :39.41 & 50.85% & 0.81\n",
      "for 2022-05-17, MAE is:60.15 & sMAPE is:57.35% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :39.56 & 50.90% & 0.81\n",
      "for 2022-05-18, MAE is:53.49 & sMAPE is:46.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :39.66 & 50.87% & 0.81\n",
      "for 2022-05-19, MAE is:83.52 & sMAPE is:40.66% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :39.98 & 50.80% & 0.80\n",
      "for 2022-05-20, MAE is:89.83 & sMAPE is:40.06% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :40.33 & 50.72% & 0.80\n",
      "for 2022-05-21, MAE is:24.07 & sMAPE is:15.62% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :40.22 & 50.47% & 0.80\n",
      "for 2022-05-22, MAE is:26.57 & sMAPE is:18.19% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :40.12 & 50.24% & 0.80\n",
      "for 2022-05-23, MAE is:34.40 & sMAPE is:19.09% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :40.08 & 50.03% & 0.80\n",
      "for 2022-05-24, MAE is:23.96 & sMAPE is:13.54% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :39.97 & 49.77% & 0.79\n",
      "for 2022-05-25, MAE is:29.76 & sMAPE is:28.41% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :39.90 & 49.62% & 0.79\n",
      "for 2022-05-26, MAE is:32.74 & sMAPE is:37.92% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :39.85 & 49.54% & 0.79\n",
      "for 2022-05-27, MAE is:28.04 & sMAPE is:20.59% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :39.77 & 49.35% & 0.79\n",
      "for 2022-05-28, MAE is:23.11 & sMAPE is:19.18% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :39.66 & 49.14% & 0.79\n",
      "for 2022-05-29, MAE is:35.40 & sMAPE is:35.27% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :39.63 & 49.05% & 0.79\n",
      "for 2022-05-30, MAE is:54.48 & sMAPE is:35.18% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :39.73 & 48.96% & 0.80\n",
      "for 2022-05-31, MAE is:48.05 & sMAPE is:47.10% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :39.78 & 48.95% & 0.80\n",
      "for 2022-06-01, MAE is:47.58 & sMAPE is:55.19% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :39.83 & 48.99% & 0.80\n",
      "for 2022-06-02, MAE is:33.01 & sMAPE is:30.73% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :39.79 & 48.87% & 0.80\n",
      "for 2022-06-03, MAE is:50.73 & sMAPE is:55.72% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :39.86 & 48.91% & 0.80\n",
      "for 2022-06-04, MAE is:57.41 & sMAPE is:45.31% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :39.97 & 48.89% & 0.80\n",
      "for 2022-06-05, MAE is:108.26 & sMAPE is:123.75% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :40.41 & 49.37% & 0.80\n",
      "for 2022-06-06, MAE is:120.59 & sMAPE is:89.30% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :40.92 & 49.62% & 0.81\n",
      "for 2022-06-07, MAE is:37.91 & sMAPE is:37.61% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :40.90 & 49.55% & 0.81\n",
      "for 2022-06-08, MAE is:56.96 & sMAPE is:31.63% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :41.00 & 49.43% & 0.81\n",
      "for 2022-06-09, MAE is:55.55 & sMAPE is:32.21% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :41.09 & 49.33% & 0.81\n",
      "for 2022-06-10, MAE is:57.24 & sMAPE is:31.98% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :41.19 & 49.22% & 0.81\n",
      "for 2022-06-11, MAE is:135.85 & sMAPE is:159.05% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :41.78 & 49.90% & 0.81\n",
      "for 2022-06-12, MAE is:17.99 & sMAPE is:101.01% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :41.63 & 50.21% & 0.81\n",
      "for 2022-06-13, MAE is:64.83 & sMAPE is:59.91% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :41.77 & 50.27% & 0.81\n",
      "for 2022-06-14, MAE is:57.39 & sMAPE is:36.20% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :41.87 & 50.18% & 0.82\n",
      "for 2022-06-15, MAE is:45.01 & sMAPE is:47.95% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :41.89 & 50.17% & 0.82\n",
      "for 2022-06-16, MAE is:52.10 & sMAPE is:59.80% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :41.95 & 50.23% & 0.82\n",
      "for 2022-06-17, MAE is:52.02 & sMAPE is:38.57% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :42.01 & 50.16% & 0.82\n",
      "for 2022-06-18, MAE is:44.74 & sMAPE is:52.59% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :42.02 & 50.17% & 0.82\n",
      "for 2022-06-19, MAE is:19.22 & sMAPE is:106.93% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :41.89 & 50.51% & 0.82\n",
      "for 2022-06-20, MAE is:157.61 & sMAPE is:95.37% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :42.57 & 50.77% & 0.83\n",
      "for 2022-06-21, MAE is:40.29 & sMAPE is:27.74% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :42.55 & 50.64% & 0.83\n",
      "for 2022-06-22, MAE is:70.57 & sMAPE is:63.00% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :42.72 & 50.71% & 0.83\n",
      "for 2022-06-23, MAE is:46.56 & sMAPE is:78.19% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :42.74 & 50.87% & 0.83\n",
      "for 2022-06-24, MAE is:23.61 & sMAPE is:41.07% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :42.63 & 50.81% & 0.83\n",
      "for 2022-06-25, MAE is:31.99 & sMAPE is:49.07% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :42.57 & 50.80% & 0.83\n",
      "for 2022-06-26, MAE is:28.54 & sMAPE is:33.62% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :42.49 & 50.70% & 0.82\n",
      "for 2022-06-27, MAE is:67.39 & sMAPE is:38.93% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :42.63 & 50.64% & 0.83\n",
      "for 2022-06-28, MAE is:49.03 & sMAPE is:43.64% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :42.66 & 50.60% & 0.83\n",
      "for 2022-06-29, MAE is:137.00 & sMAPE is:71.89% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :43.19 & 50.72% & 0.83\n",
      "for 2022-06-30, MAE is:95.62 & sMAPE is:44.78% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :43.48 & 50.68% & 0.83\n",
      "for 2022-07-01, MAE is:57.64 & sMAPE is:38.54% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :43.56 & 50.62% & 0.83\n",
      "for 2022-07-02, MAE is:37.74 & sMAPE is:76.53% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :43.52 & 50.76% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-03, MAE is:27.87 & sMAPE is:84.66% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :43.44 & 50.94% & 0.83\n",
      "for 2022-07-04, MAE is:106.17 & sMAPE is:76.86% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :43.78 & 51.08% & 0.84\n",
      "for 2022-07-05, MAE is:72.02 & sMAPE is:57.46% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :43.93 & 51.12% & 0.84\n",
      "for 2022-07-06, MAE is:60.20 & sMAPE is:77.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :44.02 & 51.26% & 0.84\n",
      "for 2022-07-07, MAE is:51.55 & sMAPE is:38.20% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :44.06 & 51.19% & 0.84\n",
      "for 2022-07-08, MAE is:53.89 & sMAPE is:62.25% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :44.11 & 51.24% & 0.83\n",
      "for 2022-07-09, MAE is:38.83 & sMAPE is:32.71% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :44.08 & 51.15% & 0.83\n",
      "for 2022-07-10, MAE is:67.80 & sMAPE is:46.66% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :44.21 & 51.12% & 0.83\n",
      "for 2022-07-11, MAE is:193.23 & sMAPE is:62.74% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :44.98 & 51.18% & 0.83\n",
      "for 2022-07-12, MAE is:69.54 & sMAPE is:21.48% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :45.11 & 51.03% & 0.83\n",
      "for 2022-07-13, MAE is:112.95 & sMAPE is:34.10% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :45.46 & 50.94% & 0.83\n",
      "for 2022-07-14, MAE is:60.41 & sMAPE is:19.76% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :45.54 & 50.78% & 0.82\n",
      "for 2022-07-15, MAE is:54.82 & sMAPE is:20.27% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.58 & 50.63% & 0.82\n",
      "for 2022-07-16, MAE is:49.17 & sMAPE is:20.87% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :45.60 & 50.48% & 0.82\n",
      "for 2022-07-17, MAE is:49.73 & sMAPE is:29.19% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :45.62 & 50.37% & 0.82\n",
      "for 2022-07-18, MAE is:74.28 & sMAPE is:32.88% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :45.77 & 50.28% & 0.82\n",
      "for 2022-07-19, MAE is:59.39 & sMAPE is:27.69% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :45.83 & 50.17% & 0.82\n",
      "for 2022-07-20, MAE is:47.92 & sMAPE is:41.86% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :45.84 & 50.13% & 0.81\n",
      "for 2022-07-21, MAE is:40.47 & sMAPE is:29.58% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :45.82 & 50.02% & 0.81\n",
      "for 2022-07-22, MAE is:45.82 & sMAPE is:30.98% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :45.82 & 49.93% & 0.81\n",
      "for 2022-07-23, MAE is:21.62 & sMAPE is:25.84% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :45.70 & 49.81% & 0.81\n",
      "for 2022-07-24, MAE is:59.90 & sMAPE is:44.76% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :45.77 & 49.79% & 0.81\n",
      "for 2022-07-25, MAE is:61.88 & sMAPE is:44.90% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :45.85 & 49.76% & 0.81\n",
      "for 2022-07-26, MAE is:125.43 & sMAPE is:180.91% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :46.23 & 50.40% & 0.81\n",
      "for 2022-07-27, MAE is:57.04 & sMAPE is:121.90% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :46.28 & 50.74% & 0.81\n",
      "for 2022-07-28, MAE is:59.67 & sMAPE is:64.92% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :46.35 & 50.81% & 0.81\n",
      "for 2022-07-29, MAE is:35.16 & sMAPE is:33.58% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :46.29 & 50.73% & 0.81\n",
      "for 2022-07-30, MAE is:49.05 & sMAPE is:54.24% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :46.31 & 50.74% & 0.81\n",
      "for 2022-07-31, MAE is:27.11 & sMAPE is:24.81% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :46.22 & 50.62% & 0.81\n",
      "for 2022-08-01, MAE is:177.07 & sMAPE is:95.97% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :46.83 & 50.83% & 0.81\n",
      "for 2022-08-02, MAE is:52.05 & sMAPE is:37.91% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :46.86 & 50.77% & 0.81\n",
      "for 2022-08-03, MAE is:107.40 & sMAPE is:174.56% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :47.14 & 51.35% & 0.81\n",
      "for 2022-08-04, MAE is:30.87 & sMAPE is:142.65% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :47.06 & 51.77% & 0.81\n",
      "for 2022-08-05, MAE is:33.44 & sMAPE is:83.92% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :47.00 & 51.92% & 0.81\n",
      "for 2022-08-06, MAE is:62.39 & sMAPE is:144.61% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :47.07 & 52.35% & 0.81\n",
      "for 2022-08-07, MAE is:35.50 & sMAPE is:129.53% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :47.02 & 52.70% & 0.80\n",
      "for 2022-08-08, MAE is:368.42 & sMAPE is:122.47% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :48.48 & 53.02% & 0.81\n",
      "for 2022-08-09, MAE is:120.37 & sMAPE is:39.35% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :48.80 & 52.95% & 0.81\n",
      "for 2022-08-10, MAE is:108.94 & sMAPE is:115.14% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :49.07 & 53.23% & 0.81\n",
      "for 2022-08-11, MAE is:49.36 & sMAPE is:94.49% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 53.42% & 0.81\n",
      "for 2022-08-12, MAE is:132.94 & sMAPE is:61.64% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :49.45 & 53.46% & 0.81\n",
      "for 2022-08-13, MAE is:103.91 & sMAPE is:46.17% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :49.69 & 53.42% & 0.81\n",
      "for 2022-08-14, MAE is:133.30 & sMAPE is:49.74% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :50.06 & 53.41% & 0.80\n",
      "for 2022-08-15, MAE is:74.45 & sMAPE is:27.37% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :50.17 & 53.29% & 0.80\n",
      "for 2022-08-16, MAE is:139.51 & sMAPE is:65.50% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :50.56 & 53.35% & 0.80\n",
      "for 2022-08-17, MAE is:56.09 & sMAPE is:60.29% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :50.58 & 53.38% & 0.80\n",
      "for 2022-08-18, MAE is:249.31 & sMAPE is:71.53% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :51.45 & 53.46% & 0.80\n",
      "for 2022-08-19, MAE is:80.91 & sMAPE is:25.44% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :51.58 & 53.33% & 0.80\n",
      "for 2022-08-20, MAE is:127.64 & sMAPE is:109.76% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :51.90 & 53.58% & 0.80\n",
      "for 2022-08-21, MAE is:31.84 & sMAPE is:125.71% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :51.82 & 53.89% & 0.80\n",
      "for 2022-08-22, MAE is:257.60 & sMAPE is:112.12% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :52.70 & 54.14% & 0.80\n",
      "for 2022-08-23, MAE is:156.91 & sMAPE is:37.91% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :53.14 & 54.07% & 0.80\n",
      "for 2022-08-24, MAE is:36.82 & sMAPE is:9.55% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :53.07 & 53.88% & 0.80\n",
      "for 2022-08-25, MAE is:147.24 & sMAPE is:32.64% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :53.47 & 53.79% & 0.81\n",
      "for 2022-08-26, MAE is:112.31 & sMAPE is:26.94% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :53.72 & 53.68% & 0.81\n",
      "for 2022-08-27, MAE is:64.83 & sMAPE is:24.14% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :53.76 & 53.55% & 0.80\n",
      "for 2022-08-28, MAE is:77.51 & sMAPE is:33.52% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :53.86 & 53.47% & 0.80\n",
      "for 2022-08-29, MAE is:119.57 & sMAPE is:67.79% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :54.13 & 53.53% & 0.81\n",
      "for 2022-08-30, MAE is:252.42 & sMAPE is:73.14% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :54.95 & 53.61% & 0.81\n",
      "for 2022-08-31, MAE is:98.99 & sMAPE is:50.61% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :55.14 & 53.60% & 0.81\n",
      "for 2022-09-01, MAE is:149.91 & sMAPE is:59.46% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :55.52 & 53.62% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-02, MAE is:84.65 & sMAPE is:39.11% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :55.64 & 53.56% & 0.81\n",
      "for 2022-09-03, MAE is:74.91 & sMAPE is:49.43% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :55.72 & 53.54% & 0.81\n",
      "for 2022-09-04, MAE is:100.02 & sMAPE is:53.41% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :55.90 & 53.54% & 0.81\n",
      "for 2022-09-05, MAE is:83.63 & sMAPE is:28.01% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :56.01 & 53.44% & 0.81\n",
      "for 2022-09-06, MAE is:98.67 & sMAPE is:39.62% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :56.18 & 53.39% & 0.81\n",
      "for 2022-09-07, MAE is:174.09 & sMAPE is:66.94% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :56.65 & 53.44% & 0.81\n",
      "for 2022-09-08, MAE is:87.48 & sMAPE is:31.49% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :56.78 & 53.35% & 0.81\n",
      "for 2022-09-09, MAE is:63.45 & sMAPE is:27.31% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :56.80 & 53.25% & 0.81\n",
      "for 2022-09-10, MAE is:58.86 & sMAPE is:26.76% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :56.81 & 53.14% & 0.81\n",
      "for 2022-09-11, MAE is:84.61 & sMAPE is:37.89% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :56.92 & 53.08% & 0.81\n",
      "for 2022-09-12, MAE is:71.99 & sMAPE is:31.50% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :56.98 & 53.00% & 0.81\n",
      "for 2022-09-13, MAE is:101.70 & sMAPE is:86.21% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :57.16 & 53.13% & 0.81\n",
      "for 2022-09-14, MAE is:38.81 & sMAPE is:39.09% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :57.08 & 53.07% & 0.80\n",
      "for 2022-09-15, MAE is:32.97 & sMAPE is:27.66% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :56.99 & 52.98% & 0.80\n",
      "for 2022-09-16, MAE is:40.76 & sMAPE is:39.23% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :56.93 & 52.92% & 0.80\n",
      "for 2022-09-17, MAE is:38.27 & sMAPE is:37.39% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :56.86 & 52.86% & 0.80\n",
      "for 2022-09-18, MAE is:24.93 & sMAPE is:27.18% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :56.73 & 52.76% & 0.80\n",
      "for 2022-09-19, MAE is:60.67 & sMAPE is:64.45% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :56.75 & 52.81% & 0.79\n",
      "for 2022-09-20, MAE is:56.43 & sMAPE is:93.76% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :56.75 & 52.97% & 0.79\n",
      "for 2022-09-21, MAE is:186.12 & sMAPE is:79.73% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :57.24 & 53.07% & 0.79\n",
      "for 2022-09-22, MAE is:77.67 & sMAPE is:35.15% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :57.31 & 53.00% & 0.79\n",
      "for 2022-09-23, MAE is:103.44 & sMAPE is:53.20% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :57.49 & 53.00% & 0.79\n",
      "for 2022-09-24, MAE is:73.26 & sMAPE is:38.63% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :57.55 & 52.95% & 0.79\n",
      "for 2022-09-25, MAE is:32.45 & sMAPE is:18.37% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :57.45 & 52.82% & 0.79\n",
      "for 2022-09-26, MAE is:50.35 & sMAPE is:31.37% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :57.43 & 52.74% & 0.79\n",
      "for 2022-09-27, MAE is:43.48 & sMAPE is:43.98% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :57.38 & 52.70% & 0.79\n",
      "for 2022-09-28, MAE is:112.30 & sMAPE is:55.90% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :57.58 & 52.72% & 0.79\n",
      "for 2022-09-29, MAE is:62.36 & sMAPE is:34.39% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :57.60 & 52.65% & 0.79\n",
      "for 2022-09-30, MAE is:192.99 & sMAPE is:69.41% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :58.09 & 52.71% & 0.79\n",
      "for 2022-10-01, MAE is:57.48 & sMAPE is:24.08% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :58.09 & 52.61% & 0.79\n",
      "for 2022-10-02, MAE is:131.46 & sMAPE is:61.37% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :58.36 & 52.64% & 0.80\n",
      "for 2022-10-03, MAE is:43.94 & sMAPE is:19.33% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :58.30 & 52.52% & 0.80\n",
      "for 2022-10-04, MAE is:49.83 & sMAPE is:22.24% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :58.27 & 52.41% & 0.80\n",
      "for 2022-10-05, MAE is:181.05 & sMAPE is:146.11% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :58.72 & 52.75% & 0.80\n",
      "for 2022-10-06, MAE is:61.89 & sMAPE is:174.34% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 53.18% & 0.79\n",
      "for 2022-10-07, MAE is:46.49 & sMAPE is:148.61% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :58.68 & 53.52% & 0.79\n",
      "for 2022-10-08, MAE is:33.09 & sMAPE is:149.75% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :58.59 & 53.86% & 0.79\n",
      "for 2022-10-09, MAE is:16.98 & sMAPE is:111.28% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :58.44 & 54.07% & 0.79\n",
      "for 2022-10-10, MAE is:68.84 & sMAPE is:126.18% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :58.48 & 54.32% & 0.78\n",
      "for 2022-10-11, MAE is:41.07 & sMAPE is:148.11% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :58.42 & 54.65% & 0.78\n",
      "for 2022-10-12, MAE is:106.67 & sMAPE is:152.89% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :58.59 & 55.00% & 0.78\n",
      "for 2022-10-13, MAE is:29.85 & sMAPE is:51.27% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :58.49 & 54.98% & 0.78\n",
      "for 2022-10-14, MAE is:140.98 & sMAPE is:129.69% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :58.78 & 55.24% & 0.78\n",
      "for 2022-10-15, MAE is:103.37 & sMAPE is:121.31% & rMAE is:3.62 ||| daily mean of MAE & sMAPE & rMAE till now are :58.93 & 55.47% & 0.79\n",
      "for 2022-10-16, MAE is:17.34 & sMAPE is:99.20% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :58.79 & 55.63% & 0.80\n",
      "for 2022-10-17, MAE is:43.16 & sMAPE is:66.78% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 55.66% & 0.80\n",
      "for 2022-10-18, MAE is:60.83 & sMAPE is:57.01% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :58.74 & 55.67% & 0.80\n",
      "for 2022-10-19, MAE is:58.98 & sMAPE is:61.72% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :58.74 & 55.69% & 0.80\n",
      "for 2022-10-20, MAE is:92.45 & sMAPE is:60.93% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :58.86 & 55.71% & 0.80\n",
      "for 2022-10-21, MAE is:101.76 & sMAPE is:52.66% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :59.00 & 55.70% & 0.80\n",
      "for 2022-10-22, MAE is:45.41 & sMAPE is:41.21% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :58.96 & 55.65% & 0.80\n",
      "for 2022-10-23, MAE is:18.61 & sMAPE is:25.94% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :58.82 & 55.55% & 0.80\n",
      "for 2022-10-24, MAE is:105.15 & sMAPE is:62.09% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :58.98 & 55.57% & 0.80\n",
      "for 2022-10-25, MAE is:41.43 & sMAPE is:31.79% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :58.92 & 55.49% & 0.80\n",
      "for 2022-10-26, MAE is:63.97 & sMAPE is:57.64% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :58.93 & 55.50% & 0.81\n",
      "for 2022-10-27, MAE is:31.17 & sMAPE is:24.41% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :58.84 & 55.39% & 0.81\n",
      "for 2022-10-28, MAE is:59.00 & sMAPE is:50.66% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :58.84 & 55.38% & 0.81\n",
      "for 2022-10-29, MAE is:48.08 & sMAPE is:122.00% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :58.81 & 55.60% & 0.81\n",
      "for 2022-10-30, MAE is:35.06 & sMAPE is:62.11% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 55.62% & 0.81\n",
      "for 2022-10-31, MAE is:29.80 & sMAPE is:25.71% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :58.63 & 55.52% & 0.81\n",
      "for 2022-11-01, MAE is:95.25 & sMAPE is:42.61% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :58.75 & 55.48% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-02, MAE is:27.33 & sMAPE is:23.80% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :58.65 & 55.38% & 0.81\n",
      "for 2022-11-03, MAE is:25.70 & sMAPE is:32.47% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :58.54 & 55.30% & 0.80\n",
      "for 2022-11-04, MAE is:17.09 & sMAPE is:34.97% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :58.41 & 55.23% & 0.80\n",
      "for 2022-11-05, MAE is:19.66 & sMAPE is:31.61% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :58.28 & 55.16% & 0.80\n",
      "for 2022-11-06, MAE is:25.12 & sMAPE is:47.33% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :58.18 & 55.13% & 0.80\n",
      "for 2022-11-07, MAE is:87.76 & sMAPE is:80.70% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :58.27 & 55.22% & 0.80\n",
      "for 2022-11-08, MAE is:41.40 & sMAPE is:30.84% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :58.22 & 55.14% & 0.80\n",
      "for 2022-11-09, MAE is:52.32 & sMAPE is:39.32% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :58.20 & 55.09% & 0.80\n",
      "for 2022-11-10, MAE is:43.44 & sMAPE is:35.17% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :58.15 & 55.02% & 0.80\n",
      "for 2022-11-11, MAE is:123.77 & sMAPE is:193.62% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :58.36 & 55.46% & 0.81\n",
      "for 2022-11-12, MAE is:25.01 & sMAPE is:141.83% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :58.25 & 55.74% & 0.81\n",
      "for 2022-11-13, MAE is:64.23 & sMAPE is:92.73% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :58.27 & 55.85% & 0.81\n",
      "for 2022-11-14, MAE is:52.99 & sMAPE is:39.94% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :58.26 & 55.80% & 0.81\n",
      "for 2022-11-15, MAE is:46.29 & sMAPE is:43.89% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :58.22 & 55.77% & 0.81\n",
      "for 2022-11-16, MAE is:153.65 & sMAPE is:67.29% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :58.52 & 55.80% & 0.81\n",
      "for 2022-11-17, MAE is:63.67 & sMAPE is:26.86% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :58.53 & 55.71% & 0.81\n",
      "for 2022-11-18, MAE is:87.06 & sMAPE is:36.93% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :58.62 & 55.65% & 0.81\n",
      "for 2022-11-19, MAE is:31.99 & sMAPE is:15.54% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :58.54 & 55.53% & 0.81\n",
      "for 2022-11-20, MAE is:53.18 & sMAPE is:28.49% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :58.52 & 55.45% & 0.81\n",
      "for 2022-11-21, MAE is:66.57 & sMAPE is:27.67% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :58.55 & 55.36% & 0.81\n",
      "for 2022-11-22, MAE is:68.60 & sMAPE is:29.83% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :58.58 & 55.28% & 0.81\n",
      "for 2022-11-23, MAE is:34.80 & sMAPE is:15.54% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :58.50 & 55.16% & 0.81\n",
      "for 2022-11-24, MAE is:74.40 & sMAPE is:32.77% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :58.55 & 55.09% & 0.81\n",
      "for 2022-11-25, MAE is:72.59 & sMAPE is:29.67% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :58.60 & 55.01% & 0.82\n",
      "for 2022-11-26, MAE is:54.37 & sMAPE is:23.81% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :58.58 & 54.92% & 0.82\n",
      "for 2022-11-27, MAE is:43.74 & sMAPE is:20.09% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :58.54 & 54.81% & 0.82\n",
      "for 2022-11-28, MAE is:57.17 & sMAPE is:22.59% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :58.53 & 54.72% & 0.82\n",
      "for 2022-11-29, MAE is:125.01 & sMAPE is:40.33% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 54.67% & 0.83\n",
      "for 2022-11-30, MAE is:90.27 & sMAPE is:26.37% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :58.83 & 54.59% & 0.83\n",
      "for 2022-12-01, MAE is:88.93 & sMAPE is:26.21% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :58.92 & 54.51% & 0.82\n",
      "for 2022-12-02, MAE is:53.96 & sMAPE is:17.34% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :58.90 & 54.39% & 0.82\n",
      "for 2022-12-03, MAE is:45.39 & sMAPE is:14.89% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :58.86 & 54.28% & 0.82\n",
      "for 2022-12-04, MAE is:27.55 & sMAPE is:9.80% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :58.77 & 54.15% & 0.82\n",
      "for 2022-12-05, MAE is:35.90 & sMAPE is:12.28% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :58.70 & 54.02% & 0.82\n",
      "for 2022-12-06, MAE is:69.71 & sMAPE is:33.48% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :58.74 & 53.96% & 0.82\n",
      "for 2022-12-07, MAE is:59.92 & sMAPE is:20.88% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :58.74 & 53.86% & 0.82\n",
      "for 2022-12-08, MAE is:59.71 & sMAPE is:20.30% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :58.74 & 53.77% & 0.83\n",
      "for 2022-12-09, MAE is:105.07 & sMAPE is:29.79% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :58.88 & 53.70% & 0.83\n",
      "for 2022-12-10, MAE is:40.30 & sMAPE is:12.60% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :58.82 & 53.58% & 0.83\n",
      "for 2022-12-11, MAE is:50.51 & sMAPE is:17.30% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :58.80 & 53.47% & 0.83\n",
      "for 2022-12-12, MAE is:85.33 & sMAPE is:22.63% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :58.88 & 53.38% & 0.83\n",
      "for 2022-12-13, MAE is:134.43 & sMAPE is:35.40% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :59.09 & 53.33% & 0.83\n",
      "for 2022-12-14, MAE is:76.76 & sMAPE is:17.75% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :59.14 & 53.23% & 0.83\n",
      "for 2022-12-15, MAE is:35.21 & sMAPE is:10.25% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :59.08 & 53.11% & 0.83\n",
      "for 2022-12-16, MAE is:78.78 & sMAPE is:23.21% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :59.13 & 53.02% & 0.84\n",
      "for 2022-12-17, MAE is:72.69 & sMAPE is:28.40% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :59.17 & 52.95% & 0.84\n",
      "for 2022-12-18, MAE is:56.65 & sMAPE is:27.03% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :59.16 & 52.88% & 0.83\n",
      "for 2022-12-19, MAE is:23.10 & sMAPE is:16.61% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :59.06 & 52.77% & 0.83\n",
      "for 2022-12-20, MAE is:38.74 & sMAPE is:18.54% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :59.00 & 52.68% & 0.83\n",
      "for 2022-12-21, MAE is:48.52 & sMAPE is:25.79% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :58.97 & 52.60% & 0.83\n",
      "for 2022-12-22, MAE is:21.76 & sMAPE is:12.78% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :58.87 & 52.49% & 0.83\n",
      "for 2022-12-23, MAE is:36.19 & sMAPE is:19.66% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :58.81 & 52.40% & 0.82\n",
      "for 2022-12-24, MAE is:65.78 & sMAPE is:58.74% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :58.83 & 52.42% & 0.82\n",
      "for 2022-12-25, MAE is:24.30 & sMAPE is:27.13% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :58.73 & 52.34% & 0.82\n",
      "for 2022-12-26, MAE is:56.94 & sMAPE is:86.91% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :58.72 & 52.44% & 0.82\n",
      "for 2022-12-27, MAE is:29.83 & sMAPE is:37.00% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :58.64 & 52.40% & 0.82\n",
      "for 2022-12-28, MAE is:34.34 & sMAPE is:28.30% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :58.58 & 52.33% & 0.82\n",
      "for 2022-12-29, MAE is:94.11 & sMAPE is:105.05% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :58.68 & 52.48% & 0.82\n",
      "for 2022-12-30, MAE is:20.05 & sMAPE is:105.03% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :58.57 & 52.62% & 0.82\n",
      "for 2022-12-31, MAE is:11.81 & sMAPE is:123.62% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :58.44 & 52.82% & 0.81\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3 (PC Version)\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:33:43,022]\u001b[0m A new study created in RDB with name: FI_2023\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:33:56,648]\u001b[0m Trial 0 finished with value: 80.3611380931341 and parameters: {'n_hidden': 4, 'learning_rate': 0.01964219392381131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23356429238410611, 'dropout_rate_Layer_2': 0.2895177235751562, 'dropout_rate_Layer_3': 0.13811964446957742, 'dropout_rate_Layer_4': 0.23512881495271107, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0032357461094841447, 'l1_Layer_2': 2.5278958822460455e-05, 'l1_Layer_3': 0.001538041990319464, 'l1_Layer_4': 0.009407852546072591, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 0 with value: 80.3611380931341.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 80.36 | sMAPE for Validation Set is: 63.87% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 24.75 | sMAPE for Test Set is: 58.76% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:34:18,164]\u001b[0m Trial 1 finished with value: 77.3122041758523 and parameters: {'n_hidden': 3, 'learning_rate': 0.0994312055922404, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3300030187772457, 'dropout_rate_Layer_2': 0.03604777472282006, 'dropout_rate_Layer_3': 0.05307700861067186, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029916299186771114, 'l1_Layer_2': 5.721154410662058e-05, 'l1_Layer_3': 0.011397007896641838, 'n_units_Layer_1': 50, 'n_units_Layer_2': 275, 'n_units_Layer_3': 75}. Best is trial 1 with value: 77.3122041758523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 77.31 | sMAPE for Validation Set is: 61.65% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 33.21 | sMAPE for Test Set is: 64.41% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:34:57,874]\u001b[0m Trial 2 finished with value: 102.94963962233487 and parameters: {'n_hidden': 4, 'learning_rate': 0.04957571112605778, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12241905910384072, 'dropout_rate_Layer_2': 0.1669226097601424, 'dropout_rate_Layer_3': 0.2883681312389442, 'dropout_rate_Layer_4': 0.019627450864788412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00041300516202926124, 'l1_Layer_2': 0.006776833188207501, 'l1_Layer_3': 0.003622560816032839, 'l1_Layer_4': 1.8618864261152286e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155, 'n_units_Layer_4': 240}. Best is trial 1 with value: 77.3122041758523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 102.95 | sMAPE for Validation Set is: 83.79% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 32.04 | sMAPE for Test Set is: 71.38% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:35:03,321]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:37:24,023]\u001b[0m Trial 4 finished with value: 88.48172333889165 and parameters: {'n_hidden': 3, 'learning_rate': 0.000538931037206045, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36034107667384696, 'dropout_rate_Layer_2': 0.341581972917073, 'dropout_rate_Layer_3': 0.07492186353135755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.815941733649343e-05, 'l1_Layer_2': 0.00019109307464167227, 'l1_Layer_3': 0.00017941955197833077, 'n_units_Layer_1': 105, 'n_units_Layer_2': 160, 'n_units_Layer_3': 95}. Best is trial 1 with value: 77.3122041758523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.48 | sMAPE for Validation Set is: 69.15% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 25.98 | sMAPE for Test Set is: 58.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:37:28,800]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:37:32,602]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:38:07,358]\u001b[0m Trial 7 finished with value: 79.07297618511669 and parameters: {'n_hidden': 3, 'learning_rate': 0.038497387756701106, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3912062307123102, 'dropout_rate_Layer_2': 0.3483502174341135, 'dropout_rate_Layer_3': 0.2725031564893123, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.991703910310738e-05, 'l1_Layer_2': 0.00019580891007468725, 'l1_Layer_3': 0.015569334069484185, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 1 with value: 77.3122041758523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.07 | sMAPE for Validation Set is: 62.82% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 32.54 | sMAPE for Test Set is: 63.80% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:38:45,642]\u001b[0m Trial 8 finished with value: 68.39466581044915 and parameters: {'n_hidden': 3, 'learning_rate': 0.00677870442791322, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32689480008285016, 'dropout_rate_Layer_2': 0.06313324617619172, 'dropout_rate_Layer_3': 0.16620203044048362, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2550235711595995e-05, 'l1_Layer_2': 1.3446731684873852e-05, 'l1_Layer_3': 0.0003791378281637164, 'n_units_Layer_1': 70, 'n_units_Layer_2': 55, 'n_units_Layer_3': 275}. Best is trial 8 with value: 68.39466581044915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 68.39 | sMAPE for Validation Set is: 57.69% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 30.04 | sMAPE for Test Set is: 61.63% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:38:52,381]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:38:56,594]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:39:02,745]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:39:33,154]\u001b[0m Trial 12 finished with value: 70.16399314459476 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037895349735942102, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2999618852908729, 'dropout_rate_Layer_2': 0.20971305671501878, 'dropout_rate_Layer_3': 0.06645964863016118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00031863819083437255, 'l1_Layer_2': 0.005156177121835492, 'l1_Layer_3': 0.00010420685726117585, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 100}. Best is trial 8 with value: 68.39466581044915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.16 | sMAPE for Validation Set is: 57.28% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 57.03% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:39:38,277]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:39:46,313]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:39:49,822]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:39:55,340]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:39:58,595]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:40:05,258]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:40:09,930]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:40:16,602]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:40:21,052]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:40:46,295]\u001b[0m Trial 22 finished with value: 75.15396702725572 and parameters: {'n_hidden': 4, 'learning_rate': 0.04316368971028778, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37894498791133946, 'dropout_rate_Layer_2': 0.008217223503562993, 'dropout_rate_Layer_3': 0.013716239493861977, 'dropout_rate_Layer_4': 0.026698866246563036, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5888013512879795e-05, 'l1_Layer_2': 0.0003380743789140514, 'l1_Layer_3': 0.0055656138293367985, 'l1_Layer_4': 1.1869076593136421e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 65, 'n_units_Layer_4': 55}. Best is trial 8 with value: 68.39466581044915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.15 | sMAPE for Validation Set is: 60.77% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 32.12 | sMAPE for Test Set is: 64.41% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:40:51,223]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:43:16,089]\u001b[0m Trial 24 finished with value: 72.27882109442625 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027629315292925435, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11065952724651945, 'dropout_rate_Layer_2': 0.20605594067041447, 'dropout_rate_Layer_3': 0.3146414138564674, 'dropout_rate_Layer_4': 0.12967861066906303, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0015722313373841199, 'l1_Layer_2': 1.2575175174826582e-05, 'l1_Layer_3': 0.001994223524333624, 'l1_Layer_4': 0.004731388088381415, 'n_units_Layer_1': 65, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285, 'n_units_Layer_4': 205}. Best is trial 8 with value: 68.39466581044915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.28 | sMAPE for Validation Set is: 57.73% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 26.99 | sMAPE for Test Set is: 65.36% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:43:21,578]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:43:26,616]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:43:32,255]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:43:38,018]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:43:48,012]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:00,264]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:07,884]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:12,852]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:17,909]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:23,921]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:28,692]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:35,661]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:41,286]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:47,769]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:53,062]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:44:57,308]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:45:01,330]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:45:06,686]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:45:35,890]\u001b[0m Trial 43 finished with value: 65.59610589364831 and parameters: {'n_hidden': 3, 'learning_rate': 0.027551150878712332, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39268545872923516, 'dropout_rate_Layer_2': 0.34554285852574185, 'dropout_rate_Layer_3': 0.30341121708702073, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.03777106675133103, 'l1_Layer_2': 0.0004198034514479053, 'l1_Layer_3': 2.5156672394031466e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 190, 'n_units_Layer_3': 295}. Best is trial 43 with value: 65.59610589364831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.60 | sMAPE for Validation Set is: 55.36% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 28.05 | sMAPE for Test Set is: 59.44% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:45:40,015]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:45:44,188]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:46:04,981]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:46:28,158]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:46:33,266]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:46:37,459]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:46:41,609]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:46:46,464]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:47:08,634]\u001b[0m Trial 52 finished with value: 72.82035917247363 and parameters: {'n_hidden': 3, 'learning_rate': 0.010807845893372256, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34734051045810366, 'dropout_rate_Layer_2': 0.38824078053021444, 'dropout_rate_Layer_3': 0.17628319982048993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.1204726120041495e-05, 'l1_Layer_2': 1.0909516409855557e-05, 'l1_Layer_3': 0.001690448481527035, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115}. Best is trial 43 with value: 65.59610589364831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.82 | sMAPE for Validation Set is: 58.64% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 26.35 | sMAPE for Test Set is: 59.20% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:47:13,144]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:47:19,257]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:47:24,010]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:47:30,620]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:47:36,006]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:48:03,172]\u001b[0m Trial 58 finished with value: 69.49028477120665 and parameters: {'n_hidden': 3, 'learning_rate': 0.010826176187698267, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24472155069640658, 'dropout_rate_Layer_2': 0.3771188803815185, 'dropout_rate_Layer_3': 0.3415173736096326, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024850769223685364, 'l1_Layer_2': 6.994319187787214e-05, 'l1_Layer_3': 0.0026472793990210504, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 135}. Best is trial 43 with value: 65.59610589364831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.49 | sMAPE for Validation Set is: 57.47% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 27.08 | sMAPE for Test Set is: 58.47% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:48:18,056]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:48:31,610]\u001b[0m Trial 60 finished with value: 70.01589102983974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0907839636306977, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35470344262288256, 'dropout_rate_Layer_2': 0.1684687461815583, 'dropout_rate_Layer_3': 0.15603644104790504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003404457239000671, 'l1_Layer_2': 2.2435072721336244e-05, 'l1_Layer_3': 0.00698974612088344, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240}. Best is trial 43 with value: 65.59610589364831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.02 | sMAPE for Validation Set is: 61.16% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 31.92 | sMAPE for Test Set is: 66.39% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:48:52,599]\u001b[0m Trial 61 finished with value: 78.43054965942265 and parameters: {'n_hidden': 4, 'learning_rate': 0.06389607446197265, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31003915042102487, 'dropout_rate_Layer_2': 0.06366570002582247, 'dropout_rate_Layer_3': 0.0633369808029556, 'dropout_rate_Layer_4': 0.1297120387560729, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.974281422445654e-05, 'l1_Layer_2': 0.0014411331298033812, 'l1_Layer_3': 0.002475407255288015, 'l1_Layer_4': 0.00035289578379647243, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 70, 'n_units_Layer_4': 270}. Best is trial 43 with value: 65.59610589364831.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.43 | sMAPE for Validation Set is: 66.76% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 32.32 | sMAPE for Test Set is: 72.48% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:49:17,768]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:49:23,229]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:49:33,697]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:49:41,393]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:49:47,016]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:50:02,661]\u001b[0m Trial 67 finished with value: 59.17503920117349 and parameters: {'n_hidden': 3, 'learning_rate': 0.004362930780672444, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3467057088928814, 'dropout_rate_Layer_2': 0.13888110325631933, 'dropout_rate_Layer_3': 0.19638080485336085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7396823494374067e-05, 'l1_Layer_2': 3.496276722020658e-05, 'l1_Layer_3': 0.0016124526203648041, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125}. Best is trial 67 with value: 59.17503920117349.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.18 | sMAPE for Validation Set is: 52.49% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 36.17 | sMAPE for Test Set is: 65.68% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:50:22,230]\u001b[0m Trial 68 finished with value: 74.50221860982269 and parameters: {'n_hidden': 4, 'learning_rate': 0.00875122433399415, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04693095596648936, 'dropout_rate_Layer_2': 0.28269738047964527, 'dropout_rate_Layer_3': 0.1759581970921504, 'dropout_rate_Layer_4': 0.1594979374248564, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013580263519104646, 'l1_Layer_2': 3.51771376003055e-05, 'l1_Layer_3': 0.00013896309315393956, 'l1_Layer_4': 0.000519794226650108, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95, 'n_units_Layer_4': 235}. Best is trial 67 with value: 59.17503920117349.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.50 | sMAPE for Validation Set is: 60.05% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 63.84% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:50:28,019]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:50:32,571]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:50:51,488]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:51:25,835]\u001b[0m Trial 72 finished with value: 61.8120170853853 and parameters: {'n_hidden': 4, 'learning_rate': 0.002421301432599005, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1777416564615551, 'dropout_rate_Layer_2': 0.03657891113648524, 'dropout_rate_Layer_3': 0.21759803689656892, 'dropout_rate_Layer_4': 0.08214503892600132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021000966372914432, 'l1_Layer_2': 0.026329501236773006, 'l1_Layer_3': 0.014039552925453483, 'l1_Layer_4': 0.011708095164733114, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 220, 'n_units_Layer_4': 300}. Best is trial 67 with value: 59.17503920117349.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.81 | sMAPE for Validation Set is: 54.87% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 62.93% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:51:30,594]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:51:35,393]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:51:40,545]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:52:01,198]\u001b[0m Trial 76 finished with value: 58.39752073191398 and parameters: {'n_hidden': 3, 'learning_rate': 0.005365469751872097, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.350302765292726, 'dropout_rate_Layer_2': 0.18135124041195808, 'dropout_rate_Layer_3': 0.18399979064678953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.998335643667852e-05, 'l1_Layer_2': 2.2766533980872464e-05, 'l1_Layer_3': 0.001729889903638393, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125}. Best is trial 76 with value: 58.39752073191398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.40 | sMAPE for Validation Set is: 51.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 36.87 | sMAPE for Test Set is: 66.25% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:52:11,834]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:52:48,628]\u001b[0m Trial 78 finished with value: 74.9804979441774 and parameters: {'n_hidden': 4, 'learning_rate': 0.07789844987732306, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22629092900674505, 'dropout_rate_Layer_2': 0.09046060024613539, 'dropout_rate_Layer_3': 0.02944570036970721, 'dropout_rate_Layer_4': 0.03944091442077953, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.612041473347965e-05, 'l1_Layer_2': 0.0001371790107128211, 'l1_Layer_3': 0.007147816386264072, 'l1_Layer_4': 3.904314523070336e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 75, 'n_units_Layer_4': 280}. Best is trial 76 with value: 58.39752073191398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.98 | sMAPE for Validation Set is: 61.82% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 29.03 | sMAPE for Test Set is: 63.14% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:53:06,497]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:53:20,598]\u001b[0m Trial 80 finished with value: 59.9223310787629 and parameters: {'n_hidden': 3, 'learning_rate': 0.004681044443340815, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3515772220866826, 'dropout_rate_Layer_2': 0.18005624583652638, 'dropout_rate_Layer_3': 0.16417589924819706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1959226319606072e-05, 'l1_Layer_2': 3.2731306138615315e-05, 'l1_Layer_3': 0.001281817652824251, 'n_units_Layer_1': 260, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 76 with value: 58.39752073191398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.92 | sMAPE for Validation Set is: 52.91% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 37.99 | sMAPE for Test Set is: 67.45% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:53:30,858]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:53:36,194]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:53:50,474]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:53:56,661]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:54:01,330]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:54:17,258]\u001b[0m Trial 86 finished with value: 58.824869573964314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037688063133974985, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35555122659874594, 'dropout_rate_Layer_2': 0.13564840539523204, 'dropout_rate_Layer_3': 0.1858823141252759, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7835393942589274e-05, 'l1_Layer_2': 3.499124171307342e-05, 'l1_Layer_3': 0.0013241399547403478, 'n_units_Layer_1': 285, 'n_units_Layer_2': 75, 'n_units_Layer_3': 90}. Best is trial 76 with value: 58.39752073191398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.82 | sMAPE for Validation Set is: 52.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 36.36 | sMAPE for Test Set is: 66.15% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:54:23,297]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:54:27,572]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:54:42,676]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:54:46,981]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:54:57,331]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:55:19,493]\u001b[0m Trial 92 finished with value: 58.21176736899594 and parameters: {'n_hidden': 3, 'learning_rate': 0.003494188720185265, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30635813667268114, 'dropout_rate_Layer_2': 0.12972940652401338, 'dropout_rate_Layer_3': 0.24734546238162655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.218836580331405e-05, 'l1_Layer_2': 6.549994204369674e-05, 'l1_Layer_3': 0.007695285918972639, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 92 with value: 58.21176736899594.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.21 | sMAPE for Validation Set is: 52.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 34.29 | sMAPE for Test Set is: 64.25% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:55:27,092]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:55:34,594]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:56:03,771]\u001b[0m Trial 95 finished with value: 57.418038873281795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021716534882096792, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30171364441639953, 'dropout_rate_Layer_2': 0.11863006524292935, 'dropout_rate_Layer_3': 0.2442943495838723, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023940595405757365, 'l1_Layer_2': 9.037403810749859e-05, 'l1_Layer_3': 0.009025018677112117, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 90}. Best is trial 95 with value: 57.418038873281795.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.42 | sMAPE for Validation Set is: 51.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 38.19 | sMAPE for Test Set is: 67.52% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:56:10,436]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:56:33,701]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:56:43,471]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:56:52,584]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:56:59,835]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:57:05,113]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:57:11,306]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:58:13,814]\u001b[0m Trial 103 finished with value: 56.843721652922234 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024656683058157675, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2554242551129521, 'dropout_rate_Layer_2': 0.16437485919734127, 'dropout_rate_Layer_3': 0.3020848823902757, 'dropout_rate_Layer_4': 0.16031444068949854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.580103826504242e-05, 'l1_Layer_2': 6.710776666391418e-05, 'l1_Layer_3': 0.006945953528237753, 'l1_Layer_4': 0.0002555275138486319, 'n_units_Layer_1': 235, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60, 'n_units_Layer_4': 135}. Best is trial 103 with value: 56.843721652922234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.84 | sMAPE for Validation Set is: 50.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 40.55 | sMAPE for Test Set is: 69.25% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:58:30,994]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:58:41,636]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:58:45,532]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:58:56,726]\u001b[0m Trial 107 finished with value: 104.70917317096969 and parameters: {'n_hidden': 3, 'learning_rate': 0.08522107375803258, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2659184874467637, 'dropout_rate_Layer_2': 0.3887480575371629, 'dropout_rate_Layer_3': 0.31732238493875736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00013656933160956897, 'l1_Layer_2': 4.154039389616468e-05, 'l1_Layer_3': 0.0004403130580666607, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 140}. Best is trial 103 with value: 56.843721652922234.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 104.71 | sMAPE for Validation Set is: 84.26% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 32.14 | sMAPE for Test Set is: 71.30% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 13:59:10,839]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:59:21,894]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:59:32,563]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:59:41,567]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:59:48,025]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 13:59:54,489]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:00:00,212]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:00:19,162]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:00:35,067]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:00:54,184]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:01:01,120]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:01:06,239]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:01:30,065]\u001b[0m Trial 120 finished with value: 55.674220868298015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030142556316797866, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2660336537988053, 'dropout_rate_Layer_2': 0.13472290909859233, 'dropout_rate_Layer_3': 0.23953691812389832, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004810066076895512, 'l1_Layer_2': 0.00010847682012002069, 'l1_Layer_3': 0.002647062692648817, 'n_units_Layer_1': 225, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.67 | sMAPE for Validation Set is: 50.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 40.30 | sMAPE for Test Set is: 68.43% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:01:40,325]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:02:16,952]\u001b[0m Trial 122 finished with value: 56.72867719268999 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024502775596869394, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26442832880407857, 'dropout_rate_Layer_2': 0.12426250597625667, 'dropout_rate_Layer_3': 0.2776133531590813, 'dropout_rate_Layer_4': 0.08930781408629516, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004159795900881362, 'l1_Layer_2': 0.00028412630399882687, 'l1_Layer_3': 0.0041273545239472855, 'l1_Layer_4': 0.013135989345819507, 'n_units_Layer_1': 200, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160, 'n_units_Layer_4': 215}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.73 | sMAPE for Validation Set is: 50.61% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 36.48 | sMAPE for Test Set is: 66.43% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:02:22,529]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:02:29,150]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:02:36,864]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:02:44,110]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:02:51,038]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:02:58,540]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:03:03,942]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:03:09,345]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:03:14,797]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:03:37,462]\u001b[0m Trial 132 finished with value: 59.664415276550606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031167445914121873, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1985037299714581, 'dropout_rate_Layer_2': 0.1318079545157866, 'dropout_rate_Layer_3': 0.07894729649006345, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011264765000210928, 'l1_Layer_2': 0.07397655060509639, 'l1_Layer_3': 1.886314940527639e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.66 | sMAPE for Validation Set is: 53.82% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 22.92 | sMAPE for Test Set is: 55.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:03:43,148]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:03:48,401]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:03:54,127]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:04:21,307]\u001b[0m Trial 136 finished with value: 59.991970641786146 and parameters: {'n_hidden': 3, 'learning_rate': 0.008108188813392241, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19808270383003582, 'dropout_rate_Layer_2': 0.12806391042011991, 'dropout_rate_Layer_3': 0.12520560679336784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.569814238672876e-05, 'l1_Layer_2': 2.7649802842083764e-05, 'l1_Layer_3': 0.007715398608098223, 'n_units_Layer_1': 215, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.99 | sMAPE for Validation Set is: 53.14% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 25.09 | sMAPE for Test Set is: 57.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:04:50,129]\u001b[0m Trial 137 finished with value: 59.8355660407814 and parameters: {'n_hidden': 4, 'learning_rate': 0.02462212409205592, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3856391564093292, 'dropout_rate_Layer_2': 0.015461202010618756, 'dropout_rate_Layer_3': 0.10911072295066584, 'dropout_rate_Layer_4': 0.09720422668189607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.6738665390171563e-05, 'l1_Layer_2': 0.00012051322941480049, 'l1_Layer_3': 0.0013783235554490222, 'l1_Layer_4': 2.4182850347779384e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 70, 'n_units_Layer_4': 250}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.84 | sMAPE for Validation Set is: 54.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 27.99 | sMAPE for Test Set is: 61.15% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:05:07,975]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:05:27,515]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:05:47,239]\u001b[0m Trial 140 finished with value: 57.65805608166219 and parameters: {'n_hidden': 4, 'learning_rate': 0.036203647099769955, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.382076360702831, 'dropout_rate_Layer_2': 0.014558943576161647, 'dropout_rate_Layer_3': 0.10071348461417538, 'dropout_rate_Layer_4': 0.07544682643525001, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.0127333360660866e-05, 'l1_Layer_2': 4.4106088939983356e-05, 'l1_Layer_3': 0.001473648011958913, 'l1_Layer_4': 0.0022620977996653294, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70, 'n_units_Layer_4': 175}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.66 | sMAPE for Validation Set is: 52.29% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 29.15 | sMAPE for Test Set is: 62.27% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:05:56,951]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:03,189]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:07,611]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:15,571]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:20,767]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:42,461]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:47,492]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:51,824]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:06:56,412]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:02,442]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:06,734]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:12,544]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:20,404]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:27,034]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:37,365]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:43,070]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:48,874]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:07:57,956]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:08:04,688]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:08:10,709]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:08:41,554]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:09:28,767]\u001b[0m Trial 162 finished with value: 55.836034953900004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028741606610271963, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18237978842817737, 'dropout_rate_Layer_2': 0.13102044614540934, 'dropout_rate_Layer_3': 0.10068881777638944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0193529201263908e-05, 'l1_Layer_2': 0.00031832463672740874, 'l1_Layer_3': 1.6191359232995528e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.84 | sMAPE for Validation Set is: 50.90% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.17 | sMAPE for Test Set is: 58.76% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:09:33,677]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:09:38,173]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:09:43,883]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:09:50,223]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:09:56,157]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:10:01,892]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:10:43,934]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:10:52,926]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:10:57,691]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:11:07,224]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:11:11,576]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:11:23,045]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:11:29,931]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:11:40,651]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:11:57,272]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:12:02,142]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:12:06,992]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:12:25,721]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:12:32,755]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:12:38,595]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:12:43,690]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:13:25,898]\u001b[0m Trial 184 finished with value: 57.05447728466834 and parameters: {'n_hidden': 4, 'learning_rate': 0.020101913725928896, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28074610367260067, 'dropout_rate_Layer_2': 0.0498220619744847, 'dropout_rate_Layer_3': 0.010091183533383542, 'dropout_rate_Layer_4': 0.011429415942957849, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.395380025040061e-05, 'l1_Layer_2': 0.0002760660869217508, 'l1_Layer_3': 0.003841561510930307, 'l1_Layer_4': 0.0014830324215696787, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 70, 'n_units_Layer_4': 215}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.05 | sMAPE for Validation Set is: 51.28% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.65 | sMAPE for Test Set is: 62.20% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:13:31,169]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:13:38,161]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:13:46,103]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:13:51,270]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:13:56,455]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:14:16,591]\u001b[0m Trial 190 finished with value: 59.21488814693146 and parameters: {'n_hidden': 4, 'learning_rate': 0.025599335940517904, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29697102475796017, 'dropout_rate_Layer_2': 0.027799100031696444, 'dropout_rate_Layer_3': 0.018016039452630635, 'dropout_rate_Layer_4': 0.027812985989993273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.494353739450093e-05, 'l1_Layer_2': 0.00016940914557500567, 'l1_Layer_3': 0.002799988920246465, 'l1_Layer_4': 0.0015031205290430953, 'n_units_Layer_1': 220, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85, 'n_units_Layer_4': 235}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.21 | sMAPE for Validation Set is: 52.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 31.76 | sMAPE for Test Set is: 62.93% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:14:21,360]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:14:46,383]\u001b[0m Trial 192 finished with value: 57.263647003517924 and parameters: {'n_hidden': 4, 'learning_rate': 0.025944309541392475, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26993635706412095, 'dropout_rate_Layer_2': 0.07624359131360002, 'dropout_rate_Layer_3': 0.0019339112340014623, 'dropout_rate_Layer_4': 0.03764212126293336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.5046064688666875e-05, 'l1_Layer_2': 0.000262208238005409, 'l1_Layer_3': 0.002712317783254687, 'l1_Layer_4': 0.0008014438250518906, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 70, 'n_units_Layer_4': 225}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.26 | sMAPE for Validation Set is: 51.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.11 | sMAPE for Test Set is: 60.94% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:14:51,132]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:14:59,201]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:15:20,071]\u001b[0m Trial 195 finished with value: 75.80769491691164 and parameters: {'n_hidden': 4, 'learning_rate': 0.004781141738307277, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18482623834530432, 'dropout_rate_Layer_2': 0.15446718119683092, 'dropout_rate_Layer_3': 0.26578238371853014, 'dropout_rate_Layer_4': 0.0725908457473988, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006221757399081599, 'l1_Layer_2': 0.022506747726987655, 'l1_Layer_3': 0.012106592561717837, 'l1_Layer_4': 0.017168104543297782, 'n_units_Layer_1': 185, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265, 'n_units_Layer_4': 100}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 75.81 | sMAPE for Validation Set is: 60.53% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 24.41 | sMAPE for Test Set is: 55.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:15:27,471]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:15:46,031]\u001b[0m Trial 197 finished with value: 56.80309371472043 and parameters: {'n_hidden': 4, 'learning_rate': 0.02295892827972697, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2522002180537342, 'dropout_rate_Layer_2': 0.013105478172926977, 'dropout_rate_Layer_3': 0.008575543664932224, 'dropout_rate_Layer_4': 0.014394569903599814, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.6965874450065252e-05, 'l1_Layer_2': 0.00029445571463634435, 'l1_Layer_3': 0.0017802724424698898, 'l1_Layer_4': 0.0008444125114319142, 'n_units_Layer_1': 230, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85, 'n_units_Layer_4': 220}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.80 | sMAPE for Validation Set is: 51.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.65 | sMAPE for Test Set is: 61.42% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:15:50,911]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:15:55,249]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:16:00,977]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:16:08,644]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:16:16,637]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:16:35,887]\u001b[0m Trial 203 finished with value: 58.14127584653139 and parameters: {'n_hidden': 4, 'learning_rate': 0.017208703372126592, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2736098955638022, 'dropout_rate_Layer_2': 0.0084302341124471, 'dropout_rate_Layer_3': 0.02493468870910255, 'dropout_rate_Layer_4': 0.0002842311949360337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.6199628799081493e-05, 'l1_Layer_2': 0.00039877455133034505, 'l1_Layer_3': 0.0036153426721527927, 'l1_Layer_4': 0.0006799168414229845, 'n_units_Layer_1': 205, 'n_units_Layer_2': 250, 'n_units_Layer_3': 105, 'n_units_Layer_4': 205}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.14 | sMAPE for Validation Set is: 52.26% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 26.54 | sMAPE for Test Set is: 58.42% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:16:56,800]\u001b[0m Trial 204 finished with value: 56.45701940797451 and parameters: {'n_hidden': 4, 'learning_rate': 0.018324350089952788, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2733654547839086, 'dropout_rate_Layer_2': 0.045755032867834874, 'dropout_rate_Layer_3': 0.028478383268670655, 'dropout_rate_Layer_4': 0.0007117278649425678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.297220955263847e-05, 'l1_Layer_2': 0.0003724012322054985, 'l1_Layer_3': 0.0034914743364736316, 'l1_Layer_4': 0.0006225591573176688, 'n_units_Layer_1': 205, 'n_units_Layer_2': 250, 'n_units_Layer_3': 225, 'n_units_Layer_4': 205}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.46 | sMAPE for Validation Set is: 51.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.06 | sMAPE for Test Set is: 60.15% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:17:11,676]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:17:38,951]\u001b[0m Trial 206 finished with value: 57.20971392022998 and parameters: {'n_hidden': 4, 'learning_rate': 0.022543514209828766, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2862339483614327, 'dropout_rate_Layer_2': 0.011905512640169029, 'dropout_rate_Layer_3': 0.0002994960248081692, 'dropout_rate_Layer_4': 0.0002718481328932989, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.0976818801403004e-05, 'l1_Layer_2': 0.00048276671040613445, 'l1_Layer_3': 0.00490981253426093, 'l1_Layer_4': 0.0007005567975930232, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 230, 'n_units_Layer_4': 190}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.21 | sMAPE for Validation Set is: 51.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 32.49 | sMAPE for Test Set is: 63.15% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:18:01,361]\u001b[0m Trial 207 finished with value: 57.734358846848785 and parameters: {'n_hidden': 4, 'learning_rate': 0.01592022796511352, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27407118448158474, 'dropout_rate_Layer_2': 0.010609093405223192, 'dropout_rate_Layer_3': 0.0012094815556413785, 'dropout_rate_Layer_4': 0.0007467742930036079, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.190034138770931e-05, 'l1_Layer_2': 0.0004971855666644707, 'l1_Layer_3': 0.01077265202194387, 'l1_Layer_4': 0.0008802364596942355, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 240, 'n_units_Layer_4': 185}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.73 | sMAPE for Validation Set is: 52.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 25.94 | sMAPE for Test Set is: 57.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:18:24,778]\u001b[0m Trial 208 finished with value: 57.27992421994856 and parameters: {'n_hidden': 4, 'learning_rate': 0.0130169785996739, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2741920936711688, 'dropout_rate_Layer_2': 0.011088370808048923, 'dropout_rate_Layer_3': 0.0006162234760299298, 'dropout_rate_Layer_4': 0.001618124552681021, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.1339808873976004e-05, 'l1_Layer_2': 0.0004456113346465997, 'l1_Layer_3': 0.004951006795488873, 'l1_Layer_4': 0.0006875727023274804, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 240, 'n_units_Layer_4': 185}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.28 | sMAPE for Validation Set is: 51.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.61 | sMAPE for Test Set is: 61.08% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:18:29,240]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:18:51,878]\u001b[0m Trial 210 finished with value: 57.84832322852793 and parameters: {'n_hidden': 4, 'learning_rate': 0.0156977867673629, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2756022529691944, 'dropout_rate_Layer_2': 0.0143769239909642, 'dropout_rate_Layer_3': 0.0048070440528338665, 'dropout_rate_Layer_4': 0.0016503578013063978, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.511134818395027e-05, 'l1_Layer_2': 0.0004307439182756399, 'l1_Layer_3': 0.005087411665705998, 'l1_Layer_4': 0.0007416453322540788, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 240, 'n_units_Layer_4': 190}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.85 | sMAPE for Validation Set is: 51.44% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 31.63 | sMAPE for Test Set is: 62.99% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:19:26,213]\u001b[0m Trial 211 finished with value: 56.83903261045282 and parameters: {'n_hidden': 4, 'learning_rate': 0.01613380772985059, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29030310095072925, 'dropout_rate_Layer_2': 0.011561594653167827, 'dropout_rate_Layer_3': 5.4137157942657325e-05, 'dropout_rate_Layer_4': 0.0006171139771335866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.983427238274812e-05, 'l1_Layer_2': 0.00046076269909493405, 'l1_Layer_3': 0.01108783642384217, 'l1_Layer_4': 0.0007815020997252799, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255, 'n_units_Layer_4': 190}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.84 | sMAPE for Validation Set is: 51.51% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 29.72 | sMAPE for Test Set is: 61.38% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:19:39,622]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:19:47,993]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:20:03,819]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:20:50,806]\u001b[0m Trial 215 finished with value: 61.614809471692894 and parameters: {'n_hidden': 3, 'learning_rate': 0.002076507453742779, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19396216086997745, 'dropout_rate_Layer_2': 0.12884149001366202, 'dropout_rate_Layer_3': 0.07796422632816398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3051399203416015e-05, 'l1_Layer_2': 0.0003486327797815912, 'l1_Layer_3': 1.0121007541449927e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 250, 'n_units_Layer_3': 180}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.61 | sMAPE for Validation Set is: 54.39% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 25.23 | sMAPE for Test Set is: 66.34% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:21:15,867]\u001b[0m Trial 216 finished with value: 57.51798318340568 and parameters: {'n_hidden': 4, 'learning_rate': 0.01621253147740031, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2749982262619949, 'dropout_rate_Layer_2': 0.02790070124138653, 'dropout_rate_Layer_3': 0.0011907041154568592, 'dropout_rate_Layer_4': 0.01213931940221934, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.285027982254393e-05, 'l1_Layer_2': 0.00041788815932037655, 'l1_Layer_3': 0.011737444446768018, 'l1_Layer_4': 0.0006733810883665472, 'n_units_Layer_1': 250, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245, 'n_units_Layer_4': 190}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.52 | sMAPE for Validation Set is: 51.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 26.56 | sMAPE for Test Set is: 58.61% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:21:24,855]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:21:38,128]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:22:06,469]\u001b[0m Trial 219 finished with value: 56.88217652023116 and parameters: {'n_hidden': 4, 'learning_rate': 0.016539541099124633, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2635669625095988, 'dropout_rate_Layer_2': 0.024559328571149126, 'dropout_rate_Layer_3': 0.027160124470736784, 'dropout_rate_Layer_4': 0.021391869300563592, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.784705428867345e-05, 'l1_Layer_2': 0.0006704879952711195, 'l1_Layer_3': 0.017795477156911238, 'l1_Layer_4': 0.0005645416927390423, 'n_units_Layer_1': 225, 'n_units_Layer_2': 235, 'n_units_Layer_3': 235, 'n_units_Layer_4': 175}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.88 | sMAPE for Validation Set is: 51.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.35 | sMAPE for Test Set is: 59.61% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:22:14,398]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:22:32,571]\u001b[0m Trial 221 finished with value: 57.61475469587457 and parameters: {'n_hidden': 4, 'learning_rate': 0.015069562319858962, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2845708027215594, 'dropout_rate_Layer_2': 0.009589228686969077, 'dropout_rate_Layer_3': 0.007489757322895149, 'dropout_rate_Layer_4': 0.009273741987905093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.4250158575240175e-05, 'l1_Layer_2': 0.0006740330182308064, 'l1_Layer_3': 0.012182042854488971, 'l1_Layer_4': 0.0005508906721683639, 'n_units_Layer_1': 250, 'n_units_Layer_2': 235, 'n_units_Layer_3': 235, 'n_units_Layer_4': 170}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.61 | sMAPE for Validation Set is: 51.86% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 28.53 | sMAPE for Test Set is: 59.55% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:22:45,621]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:23:30,850]\u001b[0m Trial 223 finished with value: 56.49236837930159 and parameters: {'n_hidden': 3, 'learning_rate': 0.003298643175360154, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1482205416066429, 'dropout_rate_Layer_2': 0.05320981256525395, 'dropout_rate_Layer_3': 0.003582586091033055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0283680139446558e-05, 'l1_Layer_2': 0.003991748496298557, 'l1_Layer_3': 3.1852555782083244e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 135, 'n_units_Layer_3': 155}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.49 | sMAPE for Validation Set is: 50.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.53 | sMAPE for Test Set is: 54.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:23:38,982]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:23:46,083]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:23:50,684]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:23:55,881]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:24:23,425]\u001b[0m Trial 228 finished with value: 58.570412038722566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011658742827779839, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12884532688059863, 'dropout_rate_Layer_2': 0.0006402860751739126, 'dropout_rate_Layer_3': 0.0005970260322255005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1662004646567391e-05, 'l1_Layer_2': 0.002200050387692575, 'l1_Layer_3': 5.2182359412143814e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 130, 'n_units_Layer_3': 180}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.57 | sMAPE for Validation Set is: 52.61% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 24.94 | sMAPE for Test Set is: 63.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:24:35,982]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:24:43,752]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:24:58,351]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:25:15,422]\u001b[0m Trial 232 finished with value: 72.86717763181143 and parameters: {'n_hidden': 3, 'learning_rate': 0.09089816211744327, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3345220943996814, 'dropout_rate_Layer_2': 0.06076627803328173, 'dropout_rate_Layer_3': 0.24193972348099335, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010848743392036706, 'l1_Layer_2': 2.1485216626659653e-05, 'l1_Layer_3': 0.002477989807615883, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.87 | sMAPE for Validation Set is: 59.47% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 28.34 | sMAPE for Test Set is: 60.72% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:25:23,243]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:25:39,037]\u001b[0m Trial 234 finished with value: 74.17004416284503 and parameters: {'n_hidden': 3, 'learning_rate': 0.09301175934178628, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39423647276238566, 'dropout_rate_Layer_2': 0.13127635368052448, 'dropout_rate_Layer_3': 0.18753365883712686, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001653526161305062, 'l1_Layer_2': 0.00010147051798332735, 'l1_Layer_3': 0.0055504532987217465, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 74.17 | sMAPE for Validation Set is: 60.79% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 38.07 | sMAPE for Test Set is: 66.79% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:25:54,000]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:25:59,582]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:26:19,763]\u001b[0m Trial 237 finished with value: 57.207725596314155 and parameters: {'n_hidden': 4, 'learning_rate': 0.016293125722363185, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2493688165184553, 'dropout_rate_Layer_2': 0.006927954396433386, 'dropout_rate_Layer_3': 0.014150809100157149, 'dropout_rate_Layer_4': 0.00026044450618461536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.697292149056894e-05, 'l1_Layer_2': 0.0007645954087973207, 'l1_Layer_3': 0.014755772243190635, 'l1_Layer_4': 0.0004340930606454071, 'n_units_Layer_1': 210, 'n_units_Layer_2': 230, 'n_units_Layer_3': 220, 'n_units_Layer_4': 210}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.21 | sMAPE for Validation Set is: 51.49% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.95 | sMAPE for Test Set is: 60.73% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:26:31,652]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:26:39,300]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:27:04,830]\u001b[0m Trial 240 finished with value: 57.59683035073584 and parameters: {'n_hidden': 4, 'learning_rate': 0.014250539941444056, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2487551658658816, 'dropout_rate_Layer_2': 0.0011678052376763361, 'dropout_rate_Layer_3': 0.01485938394566705, 'dropout_rate_Layer_4': 0.028972223080981005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.262981068509358e-05, 'l1_Layer_2': 0.0007930831559137808, 'l1_Layer_3': 0.013295753221483466, 'l1_Layer_4': 0.00031151365861939483, 'n_units_Layer_1': 210, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225, 'n_units_Layer_4': 215}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.60 | sMAPE for Validation Set is: 51.60% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 34.81 | sMAPE for Test Set is: 64.48% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:28:02,529]\u001b[0m Trial 241 finished with value: 57.4650341389571 and parameters: {'n_hidden': 3, 'learning_rate': 0.004018958630758111, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.071108931380153, 'dropout_rate_Layer_2': 0.07416577074830803, 'dropout_rate_Layer_3': 0.02185859201115853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0548315015212098e-05, 'l1_Layer_2': 0.0001783612797961033, 'l1_Layer_3': 1.0418126958942809e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.47 | sMAPE for Validation Set is: 51.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 26.93 | sMAPE for Test Set is: 58.00% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:28:16,602]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:28:30,910]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:28:40,239]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:28:58,312]\u001b[0m Trial 245 finished with value: 57.712659273001066 and parameters: {'n_hidden': 3, 'learning_rate': 0.001813616061678058, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31963669087088864, 'dropout_rate_Layer_2': 0.17281043043365663, 'dropout_rate_Layer_3': 0.2252006746725705, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5953119593461394e-05, 'l1_Layer_2': 0.00012211286440515895, 'l1_Layer_3': 0.007249531902867495, 'n_units_Layer_1': 240, 'n_units_Layer_2': 60, 'n_units_Layer_3': 70}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.71 | sMAPE for Validation Set is: 52.05% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 33.56 | sMAPE for Test Set is: 64.28% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:29:03,159]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:29:08,370]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:29:40,220]\u001b[0m Trial 248 finished with value: 59.036334574161515 and parameters: {'n_hidden': 4, 'learning_rate': 0.051977094191910815, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3327926144513845, 'dropout_rate_Layer_2': 0.12856402486268437, 'dropout_rate_Layer_3': 0.17167830988421318, 'dropout_rate_Layer_4': 0.0833508282050828, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000673490118480661, 'l1_Layer_2': 2.1626819092613705e-05, 'l1_Layer_3': 0.009976844145531879, 'l1_Layer_4': 8.175219530910286e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 105, 'n_units_Layer_3': 75, 'n_units_Layer_4': 255}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.04 | sMAPE for Validation Set is: 53.16% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 25.10 | sMAPE for Test Set is: 58.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:29:53,810]\u001b[0m Trial 249 finished with value: 78.6493169410402 and parameters: {'n_hidden': 4, 'learning_rate': 0.012514954063653768, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24959145546944472, 'dropout_rate_Layer_2': 0.10965268326191319, 'dropout_rate_Layer_3': 0.11444191286569261, 'dropout_rate_Layer_4': 0.07721034552826206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007397119731132915, 'l1_Layer_2': 0.0001852245109041428, 'l1_Layer_3': 0.016820902413664428, 'l1_Layer_4': 8.181902952617729e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 105, 'n_units_Layer_3': 65, 'n_units_Layer_4': 255}. Best is trial 120 with value: 55.674220868298015.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.65 | sMAPE for Validation Set is: 62.27% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 26.18 | sMAPE for Test Set is: 60.17% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:29:59,186]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:30:24,042]\u001b[0m Trial 251 finished with value: 55.02294771841008 and parameters: {'n_hidden': 3, 'learning_rate': 0.001856531527949981, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32650600787334955, 'dropout_rate_Layer_2': 0.1692133946692023, 'dropout_rate_Layer_3': 0.22572724456034968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.4022337385980115e-05, 'l1_Layer_2': 0.00013032475418128017, 'l1_Layer_3': 0.0073504091691145804, 'n_units_Layer_1': 205, 'n_units_Layer_2': 60, 'n_units_Layer_3': 75}. Best is trial 251 with value: 55.02294771841008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.02 | sMAPE for Validation Set is: 49.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 31.54 | sMAPE for Test Set is: 61.73% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:30:30,677]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:31:00,053]\u001b[0m Trial 253 finished with value: 59.53108082596372 and parameters: {'n_hidden': 4, 'learning_rate': 0.024770704046883998, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32452488192680257, 'dropout_rate_Layer_2': 0.1312273617000097, 'dropout_rate_Layer_3': 0.18100251599905393, 'dropout_rate_Layer_4': 0.12538154431677243, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014284181358168021, 'l1_Layer_2': 0.00011394659517081221, 'l1_Layer_3': 0.037475665926691, 'l1_Layer_4': 9.559923070299113e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80, 'n_units_Layer_4': 275}. Best is trial 251 with value: 55.02294771841008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.53 | sMAPE for Validation Set is: 53.07% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 24.01 | sMAPE for Test Set is: 58.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:31:37,288]\u001b[0m Trial 254 finished with value: 59.6055901122515 and parameters: {'n_hidden': 4, 'learning_rate': 0.0226403829400057, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32898852063412193, 'dropout_rate_Layer_2': 0.1339865122226741, 'dropout_rate_Layer_3': 0.19334336217805226, 'dropout_rate_Layer_4': 0.11924181791824114, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016476482204451032, 'l1_Layer_2': 0.00010108693858438998, 'l1_Layer_3': 0.049775138406283635, 'l1_Layer_4': 0.00011193725308624767, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80, 'n_units_Layer_4': 280}. Best is trial 251 with value: 55.02294771841008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.61 | sMAPE for Validation Set is: 52.70% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 24.25 | sMAPE for Test Set is: 56.22% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:31:51,889]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:31:57,513]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:32:03,619]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:32:08,080]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:32:22,681]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:32:28,892]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:32:54,027]\u001b[0m Trial 261 finished with value: 56.581525610152006 and parameters: {'n_hidden': 3, 'learning_rate': 0.018782621540025753, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16038136271772674, 'dropout_rate_Layer_2': 0.08016827545455395, 'dropout_rate_Layer_3': 0.12597627515997384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.708681704144246e-05, 'l1_Layer_2': 0.0053681874278653525, 'l1_Layer_3': 6.41686887979245e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 90}. Best is trial 251 with value: 55.02294771841008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.58 | sMAPE for Validation Set is: 51.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.06 | sMAPE for Test Set is: 61.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:33:00,275]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:33:05,829]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:34:05,443]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:34:11,057]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:34:24,411]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:34:29,406]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:34:34,961]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:34:40,583]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:35:07,125]\u001b[0m Trial 270 finished with value: 58.629483431839624 and parameters: {'n_hidden': 4, 'learning_rate': 0.023960526946679262, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31568414549011037, 'dropout_rate_Layer_2': 0.13551657853927124, 'dropout_rate_Layer_3': 0.1900381606879316, 'dropout_rate_Layer_4': 0.1223617941251468, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014648215488094146, 'l1_Layer_2': 0.0001225175150064052, 'l1_Layer_3': 0.047604147039363616, 'l1_Layer_4': 9.103591517026434e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 80, 'n_units_Layer_4': 285}. Best is trial 251 with value: 55.02294771841008.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.63 | sMAPE for Validation Set is: 52.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.23 | sMAPE for Test Set is: 56.30% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:35:41,942]\u001b[0m Trial 271 finished with value: 54.12886837946039 and parameters: {'n_hidden': 3, 'learning_rate': 0.003752731321010881, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15864546298926788, 'dropout_rate_Layer_2': 0.007344521897336087, 'dropout_rate_Layer_3': 0.0037789370544273615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002373947411161452, 'l1_Layer_2': 0.00013182512567863175, 'l1_Layer_3': 0.00015251480427141937, 'n_units_Layer_1': 195, 'n_units_Layer_2': 235, 'n_units_Layer_3': 170}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.13 | sMAPE for Validation Set is: 50.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.54 | sMAPE for Test Set is: 54.61% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:35:46,801]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:36:00,185]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:36:21,801]\u001b[0m Trial 274 finished with value: 60.000477531924155 and parameters: {'n_hidden': 4, 'learning_rate': 0.02668763398894963, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3136723988731881, 'dropout_rate_Layer_2': 0.13639230624885418, 'dropout_rate_Layer_3': 0.1761478757774785, 'dropout_rate_Layer_4': 0.1355401057391224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014708546239282493, 'l1_Layer_2': 0.0001031237339156447, 'l1_Layer_3': 0.05468823537972513, 'l1_Layer_4': 8.628011832978364e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 80, 'n_units_Layer_4': 265}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.00 | sMAPE for Validation Set is: 53.52% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 25.25 | sMAPE for Test Set is: 60.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:36:35,936]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:36:43,496]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:36:58,212]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:37:03,878]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:37:20,953]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:37:47,595]\u001b[0m Trial 280 finished with value: 57.33635206294571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013484313019915155, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.302247136851443, 'dropout_rate_Layer_2': 0.20488191290276106, 'dropout_rate_Layer_3': 0.23976396034969016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.020144621838589e-05, 'l1_Layer_2': 0.00013046657548842073, 'l1_Layer_3': 0.004853289346046028, 'n_units_Layer_1': 240, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.34 | sMAPE for Validation Set is: 51.46% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 33.40 | sMAPE for Test Set is: 64.04% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:38:11,711]\u001b[0m Trial 281 finished with value: 56.61711352552782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018566681836572677, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3003941293488456, 'dropout_rate_Layer_2': 0.2042087913935317, 'dropout_rate_Layer_3': 0.24191485688216569, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.245174562952121e-05, 'l1_Layer_2': 0.00013077300124707283, 'l1_Layer_3': 0.008137743641684063, 'n_units_Layer_1': 195, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.62 | sMAPE for Validation Set is: 51.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 34.00 | sMAPE for Test Set is: 64.61% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:38:18,381]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:38:23,472]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:38:28,606]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:38:33,679]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:38:39,187]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:38:44,049]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:38:52,004]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:39:58,448]\u001b[0m Trial 289 finished with value: 60.00030754752887 and parameters: {'n_hidden': 4, 'learning_rate': 0.02439148478919264, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32062468666129906, 'dropout_rate_Layer_2': 0.15452436288684865, 'dropout_rate_Layer_3': 0.19485756077124966, 'dropout_rate_Layer_4': 0.10593045024548628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001499595722836649, 'l1_Layer_2': 4.790171703725476e-05, 'l1_Layer_3': 0.03581932221627515, 'l1_Layer_4': 0.00017438778881873182, 'n_units_Layer_1': 90, 'n_units_Layer_2': 100, 'n_units_Layer_3': 100, 'n_units_Layer_4': 220}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.00 | sMAPE for Validation Set is: 53.22% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 24.06 | sMAPE for Test Set is: 60.14% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:40:04,097]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:12,454]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:17,999]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:22,974]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:30,019]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:38,470]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:43,887]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:40:48,733]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:41:11,001]\u001b[0m Trial 298 finished with value: 56.88411269980437 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021095976704933214, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2960402930456623, 'dropout_rate_Layer_2': 0.11894414087531348, 'dropout_rate_Layer_3': 0.2310936788518374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.1516771657506394e-05, 'l1_Layer_2': 0.00013233829087605772, 'l1_Layer_3': 0.02014512166916229, 'n_units_Layer_1': 165, 'n_units_Layer_2': 155, 'n_units_Layer_3': 50}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.88 | sMAPE for Validation Set is: 51.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 35.84 | sMAPE for Test Set is: 65.12% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:41:23,655]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:41:27,975]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:42:03,601]\u001b[0m Trial 301 finished with value: 56.2602498083319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014215786917430792, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3300597563801313, 'dropout_rate_Layer_2': 0.18620192664353266, 'dropout_rate_Layer_3': 0.21310949160265383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.02109839495329e-05, 'l1_Layer_2': 0.0001639497135014893, 'l1_Layer_3': 0.02056916132272808, 'n_units_Layer_1': 170, 'n_units_Layer_2': 155, 'n_units_Layer_3': 60}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.26 | sMAPE for Validation Set is: 51.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 31.95 | sMAPE for Test Set is: 62.36% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:42:08,339]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:42:13,099]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:42:21,232]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:42:26,614]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:42:42,302]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:42:47,773]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:43:15,830]\u001b[0m Trial 308 finished with value: 54.52453815552608 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015356574229805342, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2856585789226673, 'dropout_rate_Layer_2': 0.10640421514679836, 'dropout_rate_Layer_3': 0.21147550753400948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001034714969533527, 'l1_Layer_2': 0.00017248571589565184, 'l1_Layer_3': 0.014487951611184302, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.52 | sMAPE for Validation Set is: 49.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 24.83 | sMAPE for Test Set is: 57.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:43:23,656]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:43:52,782]\u001b[0m Trial 310 finished with value: 54.875514974263346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013029726043590642, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27353927488866225, 'dropout_rate_Layer_2': 0.22055068698979916, 'dropout_rate_Layer_3': 0.2174503090190458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010825672087399301, 'l1_Layer_2': 0.0003659028020502946, 'l1_Layer_3': 0.019214201507468456, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.88 | sMAPE for Validation Set is: 49.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.05 | sMAPE for Test Set is: 57.00% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:43:57,551]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:02,956]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:09,321]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:16,982]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:25,430]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:33,008]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:40,887]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:44:48,697]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:45:27,254]\u001b[0m Trial 319 finished with value: 58.47884022059609 and parameters: {'n_hidden': 4, 'learning_rate': 0.050251656232623294, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2839857701874704, 'dropout_rate_Layer_2': 0.1555742168892722, 'dropout_rate_Layer_3': 0.09376303276858053, 'dropout_rate_Layer_4': 0.05394615251373814, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024853074654907275, 'l1_Layer_2': 3.21532602857292e-05, 'l1_Layer_3': 0.01992600281244972, 'l1_Layer_4': 1.0232533188653342e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 85, 'n_units_Layer_4': 275}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.48 | sMAPE for Validation Set is: 52.40% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 24.05 | sMAPE for Test Set is: 57.14% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:45:32,451]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:45:39,795]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:45:52,887]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:46:32,226]\u001b[0m Trial 323 finished with value: 54.9926127577347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015790063044633016, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2701104723395282, 'dropout_rate_Layer_2': 0.22497986384263013, 'dropout_rate_Layer_3': 0.1985821653174567, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.314393204340689e-05, 'l1_Layer_2': 0.00015693842006913182, 'l1_Layer_3': 0.017367811306733143, 'n_units_Layer_1': 185, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.99 | sMAPE for Validation Set is: 49.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.98 | sMAPE for Test Set is: 56.65% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:46:56,917]\u001b[0m Trial 324 finished with value: 57.57449562872895 and parameters: {'n_hidden': 4, 'learning_rate': 0.016121200702459957, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29382282512388136, 'dropout_rate_Layer_2': 0.015781852903927474, 'dropout_rate_Layer_3': 0.01689155463323331, 'dropout_rate_Layer_4': 0.006561321017284925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.658546727187796e-05, 'l1_Layer_2': 0.0008955283351113009, 'l1_Layer_3': 0.0016360730918797502, 'l1_Layer_4': 0.0006231570658306883, 'n_units_Layer_1': 250, 'n_units_Layer_2': 225, 'n_units_Layer_3': 235, 'n_units_Layer_4': 240}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.57 | sMAPE for Validation Set is: 51.21% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 31.81 | sMAPE for Test Set is: 62.77% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:47:09,439]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:47:23,695]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:47:55,523]\u001b[0m Trial 327 finished with value: 55.046784231469964 and parameters: {'n_hidden': 3, 'learning_rate': 0.001627786293834684, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2651554132701566, 'dropout_rate_Layer_2': 0.23516661846939302, 'dropout_rate_Layer_3': 0.17148322355326379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.576751855077839e-05, 'l1_Layer_2': 0.00016637853662582137, 'l1_Layer_3': 0.021528689167088857, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.05 | sMAPE for Validation Set is: 49.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.90 | sMAPE for Test Set is: 56.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:48:22,591]\u001b[0m Trial 328 finished with value: 55.20005768837126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016946076375186905, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2652395671381599, 'dropout_rate_Layer_2': 0.23601581520801995, 'dropout_rate_Layer_3': 0.19542151176732436, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.677996034241695e-05, 'l1_Layer_2': 0.00019200252875090266, 'l1_Layer_3': 0.015364316574092379, 'n_units_Layer_1': 180, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.20 | sMAPE for Validation Set is: 49.98% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.20 | sMAPE for Test Set is: 57.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:48:27,381]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:48:46,427]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:49:00,097]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:49:33,545]\u001b[0m Trial 332 finished with value: 61.209015796246696 and parameters: {'n_hidden': 4, 'learning_rate': 0.06430302048076464, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2991644430147685, 'dropout_rate_Layer_2': 0.2172176875380557, 'dropout_rate_Layer_3': 0.1036206504150209, 'dropout_rate_Layer_4': 0.026396411326254986, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0003868811858140179, 'l1_Layer_2': 1.069582407405346e-05, 'l1_Layer_3': 0.031406635956035905, 'l1_Layer_4': 1.0152129674076981e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 65, 'n_units_Layer_4': 190}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.21 | sMAPE for Validation Set is: 53.47% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 56.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:50:03,066]\u001b[0m Trial 333 finished with value: 55.01480385523157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016399086812208775, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2636967991841965, 'dropout_rate_Layer_2': 0.228770463654279, 'dropout_rate_Layer_3': 0.17117825307682932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014086660754428443, 'l1_Layer_2': 0.00017540010721657428, 'l1_Layer_3': 0.014599181248770394, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 80}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.01 | sMAPE for Validation Set is: 49.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.97 | sMAPE for Test Set is: 57.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:50:10,845]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:50:18,459]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:50:24,217]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:50:29,883]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:50:37,821]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:51:15,504]\u001b[0m Trial 339 finished with value: 59.28093472888795 and parameters: {'n_hidden': 4, 'learning_rate': 0.045958624869181564, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3403916948939233, 'dropout_rate_Layer_2': 0.14580195121319994, 'dropout_rate_Layer_3': 0.14630982448781518, 'dropout_rate_Layer_4': 0.09602104873747003, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011475378919310283, 'l1_Layer_2': 4.090417666535389e-05, 'l1_Layer_3': 0.04825205198656832, 'l1_Layer_4': 4.123743608740899e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 100, 'n_units_Layer_4': 280}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.28 | sMAPE for Validation Set is: 52.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.38 | sMAPE for Test Set is: 56.12% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:51:29,669]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:51:34,487]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:51:39,699]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:51:45,221]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:51:51,260]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:51:56,733]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:01,395]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:17,197]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:22,188]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:27,060]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:32,106]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:42,437]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:47,273]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:52,027]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:52:59,298]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:53:36,586]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:53:46,006]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:53:51,421]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:53:55,474]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:54:01,736]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:54:08,552]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:54:40,693]\u001b[0m Trial 361 finished with value: 64.48634148193692 and parameters: {'n_hidden': 4, 'learning_rate': 0.045110961831803735, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3162545259184394, 'dropout_rate_Layer_2': 0.11640419799551677, 'dropout_rate_Layer_3': 0.08679730650496525, 'dropout_rate_Layer_4': 0.1570053152466439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002362179267982054, 'l1_Layer_2': 1.871396035193951e-05, 'l1_Layer_3': 0.008963504021308867, 'l1_Layer_4': 0.000164123482926383, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 105, 'n_units_Layer_4': 260}. Best is trial 271 with value: 54.12886837946039.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.49 | sMAPE for Validation Set is: 56.10% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 27.54 | sMAPE for Test Set is: 69.25% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:54:46,364]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:54:54,300]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:54:59,141]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:55:04,284]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:55:35,831]\u001b[0m Trial 366 finished with value: 54.0728335100898 and parameters: {'n_hidden': 3, 'learning_rate': 0.003955299461892815, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15544225469992534, 'dropout_rate_Layer_2': 0.043219203266825885, 'dropout_rate_Layer_3': 0.0004283921895776163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6676228857039446e-05, 'l1_Layer_2': 0.0005534634965312123, 'l1_Layer_3': 2.8438028148950796e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 366 with value: 54.0728335100898.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.07 | sMAPE for Validation Set is: 49.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.78 | sMAPE for Test Set is: 54.65% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:55:41,348]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:55:55,321]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:56:00,497]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:56:26,967]\u001b[0m Trial 370 finished with value: 54.046554367100775 and parameters: {'n_hidden': 3, 'learning_rate': 0.005131089464130175, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16646280935185176, 'dropout_rate_Layer_2': 0.03342607282413264, 'dropout_rate_Layer_3': 0.042272725183168, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.344099299856942e-05, 'l1_Layer_2': 0.0005620882771800642, 'l1_Layer_3': 0.00026191412358707967, 'n_units_Layer_1': 190, 'n_units_Layer_2': 270, 'n_units_Layer_3': 185}. Best is trial 370 with value: 54.046554367100775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.05 | sMAPE for Validation Set is: 49.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.21 | sMAPE for Test Set is: 54.01% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:56:47,534]\u001b[0m Trial 371 finished with value: 54.806101200505815 and parameters: {'n_hidden': 3, 'learning_rate': 0.005557747189760604, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22865114255355906, 'dropout_rate_Layer_2': 0.03133839444135794, 'dropout_rate_Layer_3': 0.0005248549649739375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.212593054617921e-05, 'l1_Layer_2': 0.0007617098555724323, 'l1_Layer_3': 0.0002681620181835005, 'n_units_Layer_1': 195, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 370 with value: 54.046554367100775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.81 | sMAPE for Validation Set is: 50.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 52.85% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:56:52,297]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:56:56,863]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:57:01,551]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:57:22,726]\u001b[0m Trial 375 finished with value: 57.663426647391624 and parameters: {'n_hidden': 4, 'learning_rate': 0.013156480725590966, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2918947706948686, 'dropout_rate_Layer_2': 0.10231064497197094, 'dropout_rate_Layer_3': 0.011056819928437248, 'dropout_rate_Layer_4': 0.01420236611553649, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.856143679519687e-05, 'l1_Layer_2': 0.00125482745441721, 'l1_Layer_3': 0.003196559960865317, 'l1_Layer_4': 0.00045960468515066847, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 230, 'n_units_Layer_4': 235}. Best is trial 370 with value: 54.046554367100775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.66 | sMAPE for Validation Set is: 51.43% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 28.81 | sMAPE for Test Set is: 60.19% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:57:30,389]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:57:48,546]\u001b[0m Trial 377 finished with value: 57.6031851610361 and parameters: {'n_hidden': 4, 'learning_rate': 0.013605024559124998, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2817685505699645, 'dropout_rate_Layer_2': 0.09538935595800226, 'dropout_rate_Layer_3': 0.02360667023720974, 'dropout_rate_Layer_4': 0.006961053835410574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 5.3271706510388996e-05, 'l1_Layer_2': 0.0010990587838809846, 'l1_Layer_3': 0.0032751134436742623, 'l1_Layer_4': 0.0008468881489674145, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235, 'n_units_Layer_4': 240}. Best is trial 370 with value: 54.046554367100775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.60 | sMAPE for Validation Set is: 51.88% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 30.81 | sMAPE for Test Set is: 61.91% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:57:56,274]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:58:04,298]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:58:11,881]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:58:30,352]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:58:36,148]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:58:41,779]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:58:49,626]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:59:02,602]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:59:37,577]\u001b[0m Trial 386 finished with value: 54.13598830668758 and parameters: {'n_hidden': 3, 'learning_rate': 0.004281343459261175, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16437802172304536, 'dropout_rate_Layer_2': 0.028534594949975733, 'dropout_rate_Layer_3': 0.03462171471889819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2932405011917823e-05, 'l1_Layer_2': 0.0006145889381986642, 'l1_Layer_3': 8.702803858751739e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 370 with value: 54.046554367100775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.14 | sMAPE for Validation Set is: 49.65% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 52.49% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 14:59:42,507]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:59:48,061]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 14:59:56,088]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:00,850]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:05,754]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:27,812]\u001b[0m Trial 392 finished with value: 54.44786316098614 and parameters: {'n_hidden': 3, 'learning_rate': 0.011945202382295595, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12377698751732313, 'dropout_rate_Layer_2': 0.05446136219702534, 'dropout_rate_Layer_3': 0.047694490036016564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.6576473839634e-05, 'l1_Layer_2': 0.0002448985350768079, 'l1_Layer_3': 0.000477166253962843, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 370 with value: 54.046554367100775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.45 | sMAPE for Validation Set is: 49.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.79 | sMAPE for Test Set is: 55.46% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:00:35,212]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:40,101]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:46,066]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:53,405]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:00:58,244]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:03,171]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:08,399]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:12,697]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:18,249]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:23,914]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:37,653]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:42,624]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:47,517]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:53,127]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:01:58,124]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:02,485]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:08,534]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:13,122]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:20,877]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:27,244]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:32,416]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:02:37,521]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:03:23,713]\u001b[0m Trial 415 finished with value: 53.29285087090523 and parameters: {'n_hidden': 3, 'learning_rate': 0.00250388513932753, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1683659072606347, 'dropout_rate_Layer_2': 0.0013037710281274817, 'dropout_rate_Layer_3': 0.03532796257039485, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.219527159978979e-05, 'l1_Layer_2': 0.0016374052698303716, 'l1_Layer_3': 0.00027946786274862383, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 100}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.29 | sMAPE for Validation Set is: 48.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.58 | sMAPE for Test Set is: 53.68% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:03:28,050]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:03:45,299]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:03:58,424]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:06,277]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:12,234]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:16,885]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:21,436]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:39,270]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:44,160]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:49,088]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:04:57,418]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:02,308]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:07,088]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:12,254]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:20,491]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:27,548]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:32,145]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:37,618]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:43,031]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:48,421]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:05:55,540]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:01,389]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:07,119]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:13,526]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:18,689]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:25,646]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:30,977]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:35,967]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:42,822]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:48,413]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:06:59,404]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:04,448]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:09,344]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:15,021]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:25,395]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:30,205]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:35,901]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:40,510]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:45,751]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:07:58,630]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:04,341]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:08,834]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:13,931]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:20,285]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:25,732]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:31,114]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:35,938]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:40,510]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:45,760]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:08:55,094]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:09:08,492]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:09:14,036]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:09:19,474]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:09:25,044]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:09:30,580]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:10:07,434]\u001b[0m Trial 471 finished with value: 54.39432990835561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031589087616742083, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2966452080768385, 'dropout_rate_Layer_2': 0.14306348628947527, 'dropout_rate_Layer_3': 0.21673445999711144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.901068193607887e-05, 'l1_Layer_2': 0.00030050052164685867, 'l1_Layer_3': 0.010233035389919981, 'n_units_Layer_1': 230, 'n_units_Layer_2': 165, 'n_units_Layer_3': 60}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.39 | sMAPE for Validation Set is: 49.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 31.27 | sMAPE for Test Set is: 62.75% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:10:12,845]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:10:24,256]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:10:55,973]\u001b[0m Trial 474 finished with value: 54.95865277427549 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029223396797652713, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.323535143309858, 'dropout_rate_Layer_2': 0.16797650261614222, 'dropout_rate_Layer_3': 0.2155838889155144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1642382896146646e-05, 'l1_Layer_2': 0.0002980065871642755, 'l1_Layer_3': 0.006873170633627093, 'n_units_Layer_1': 230, 'n_units_Layer_2': 165, 'n_units_Layer_3': 75}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.96 | sMAPE for Validation Set is: 49.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 31.34 | sMAPE for Test Set is: 62.12% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:11:03,198]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:11:09,073]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:11:14,004]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:11:20,671]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:11:50,176]\u001b[0m Trial 479 finished with value: 53.554422209497524 and parameters: {'n_hidden': 3, 'learning_rate': 0.003991181577884476, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15261905972562, 'dropout_rate_Layer_2': 0.00272077324062274, 'dropout_rate_Layer_3': 0.018379656231978674, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018735824824817792, 'l1_Layer_2': 0.00020560933981006406, 'l1_Layer_3': 0.0001238520095689786, 'n_units_Layer_1': 235, 'n_units_Layer_2': 235, 'n_units_Layer_3': 80}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.55 | sMAPE for Validation Set is: 48.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.88 | sMAPE for Test Set is: 55.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:11:55,643]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:12:14,189]\u001b[0m Trial 481 finished with value: 57.16645377785577 and parameters: {'n_hidden': 4, 'learning_rate': 0.013645984864014473, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2961661063783346, 'dropout_rate_Layer_2': 0.017146515339035665, 'dropout_rate_Layer_3': 0.022827452543645113, 'dropout_rate_Layer_4': 0.00017646696170958348, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.086368777299495e-05, 'l1_Layer_2': 0.0007127448666619497, 'l1_Layer_3': 0.031218803250485237, 'l1_Layer_4': 0.0007231083262632268, 'n_units_Layer_1': 120, 'n_units_Layer_2': 295, 'n_units_Layer_3': 55, 'n_units_Layer_4': 190}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.17 | sMAPE for Validation Set is: 51.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.25 | sMAPE for Test Set is: 59.79% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:12:18,933]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:12:26,047]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:12:34,638]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:13:01,962]\u001b[0m Trial 485 finished with value: 54.01006595385695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042962134584670604, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21093559081347601, 'dropout_rate_Layer_2': 0.02435706549094839, 'dropout_rate_Layer_3': 0.02683074521924356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.143867735554295e-05, 'l1_Layer_2': 0.00042905437292962317, 'l1_Layer_3': 0.00010041832860194573, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 75}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.01 | sMAPE for Validation Set is: 49.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.69 | sMAPE for Test Set is: 53.51% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:13:09,846]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:13:29,442]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:13:34,628]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:13:39,201]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:08,275]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:14,629]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:23,625]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:28,372]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:45,149]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:50,565]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:54,740]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:14:59,452]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:15:33,194]\u001b[0m Trial 498 finished with value: 59.42879247098884 and parameters: {'n_hidden': 4, 'learning_rate': 0.020367256236933202, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3260255440189013, 'dropout_rate_Layer_2': 0.12637818667183143, 'dropout_rate_Layer_3': 0.20109951590874206, 'dropout_rate_Layer_4': 0.15616121035161803, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012708257922977005, 'l1_Layer_2': 7.576706143531771e-05, 'l1_Layer_3': 0.05793896995308634, 'l1_Layer_4': 9.590819356110659e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95, 'n_units_Layer_4': 300}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.43 | sMAPE for Validation Set is: 52.89% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 56.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:15:41,691]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:15:47,508]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:15:53,006]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:01,530]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:05,975]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:13,194]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:18,024]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:27,978]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:33,837]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:38,986]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:47,502]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:52,998]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:16:58,641]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:17:26,187]\u001b[0m Trial 512 finished with value: 56.201910806390394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021271369334290133, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2946677594566883, 'dropout_rate_Layer_2': 0.111606243509726, 'dropout_rate_Layer_3': 0.23483222340832324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.964448712785735e-05, 'l1_Layer_2': 0.000146901493767724, 'l1_Layer_3': 0.020076189031016222, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 50}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.20 | sMAPE for Validation Set is: 50.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 33.39 | sMAPE for Test Set is: 63.15% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:18:22,460]\u001b[0m Trial 513 finished with value: 57.499272584382936 and parameters: {'n_hidden': 4, 'learning_rate': 0.014412032670538212, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32054782512173347, 'dropout_rate_Layer_2': 0.1740971677879496, 'dropout_rate_Layer_3': 0.17922929927941691, 'dropout_rate_Layer_4': 0.07831555415047677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007544597279038272, 'l1_Layer_2': 2.6077360840228873e-05, 'l1_Layer_3': 0.09131910878924306, 'l1_Layer_4': 0.00011929477154203499, 'n_units_Layer_1': 60, 'n_units_Layer_2': 170, 'n_units_Layer_3': 90, 'n_units_Layer_4': 300}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.50 | sMAPE for Validation Set is: 51.94% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 22.47 | sMAPE for Test Set is: 54.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:18:27,358]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:18:32,906]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:18:38,472]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:18:43,367]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:18:51,667]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:18:56,104]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:19:00,856]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:19:08,334]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:19:18,943]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:19:31,088]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:19:38,059]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:19:51,208]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:20:02,005]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:20:09,133]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:20:22,095]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:20:27,951]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:20:32,467]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:21:09,999]\u001b[0m Trial 531 finished with value: 55.92870065605175 and parameters: {'n_hidden': 3, 'learning_rate': 0.001929495274016687, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30662889290466033, 'dropout_rate_Layer_2': 0.10686765885060953, 'dropout_rate_Layer_3': 0.21176981097623215, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010008056254478798, 'l1_Layer_2': 0.00019325139137225407, 'l1_Layer_3': 0.011119501680784283, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 60}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.93 | sMAPE for Validation Set is: 50.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 32.47 | sMAPE for Test Set is: 63.01% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:21:46,938]\u001b[0m Trial 532 finished with value: 53.8465327499915 and parameters: {'n_hidden': 3, 'learning_rate': 0.007287656927853642, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20947609881527932, 'dropout_rate_Layer_2': 0.10135205943770084, 'dropout_rate_Layer_3': 0.02486336875280921, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013474904109342872, 'l1_Layer_2': 6.587347752284914e-05, 'l1_Layer_3': 0.00031407381658446915, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 120}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.85 | sMAPE for Validation Set is: 49.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.42 | sMAPE for Test Set is: 54.15% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:21:54,635]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:21:59,700]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:13,018]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:19,187]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:24,193]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:30,779]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:36,383]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:41,255]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:48,136]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:54,050]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:22:58,832]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:06,120]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:12,226]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:19,256]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:24,515]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:29,993]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:36,702]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:44,589]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:49,665]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:23:59,108]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:24:04,576]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:24:16,799]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:24:27,894]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:24:33,626]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:24:38,367]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:25:04,248]\u001b[0m Trial 558 finished with value: 55.88121334829699 and parameters: {'n_hidden': 3, 'learning_rate': 0.01758431314995496, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28294048052676746, 'dropout_rate_Layer_2': 0.034900315123353606, 'dropout_rate_Layer_3': 0.0076753494362269015, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003118042879083783, 'l1_Layer_2': 0.00011050025452082681, 'l1_Layer_3': 0.0009962504160505642, 'n_units_Layer_1': 245, 'n_units_Layer_2': 235, 'n_units_Layer_3': 260}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.88 | sMAPE for Validation Set is: 50.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 31.59 | sMAPE for Test Set is: 62.18% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:25:09,584]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:25:15,169]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:25:21,031]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:25:35,965]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:25:40,874]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:26:21,178]\u001b[0m Trial 564 finished with value: 58.47948412631033 and parameters: {'n_hidden': 4, 'learning_rate': 0.008558145205790546, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26150002649425114, 'dropout_rate_Layer_2': 0.2037311374488619, 'dropout_rate_Layer_3': 0.20451736397907322, 'dropout_rate_Layer_4': 0.007057862258324471, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00043702349990159834, 'l1_Layer_2': 1.3451728583475946e-05, 'l1_Layer_3': 0.01960582201234886, 'l1_Layer_4': 0.00014181882683519167, 'n_units_Layer_1': 140, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180, 'n_units_Layer_4': 290}. Best is trial 415 with value: 53.29285087090523.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.48 | sMAPE for Validation Set is: 52.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 23.74 | sMAPE for Test Set is: 57.42% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:26:26,791]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:26:31,826]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:26:36,768]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:26:42,552]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:26:48,217]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:26:53,175]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:27:01,375]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:27:06,529]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:27:28,151]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:27:39,489]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:27:44,904]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:27:49,517]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:28:33,793]\u001b[0m Trial 577 finished with value: 53.250623732158424 and parameters: {'n_hidden': 3, 'learning_rate': 0.004710485769159259, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17279429311144737, 'dropout_rate_Layer_2': 0.030558711046673678, 'dropout_rate_Layer_3': 0.050299194245759224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001530721582704605, 'l1_Layer_2': 0.0001771351899385224, 'l1_Layer_3': 0.000287934035311718, 'n_units_Layer_1': 185, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 577 with value: 53.250623732158424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.25 | sMAPE for Validation Set is: 48.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.31 | sMAPE for Test Set is: 54.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:28:39,682]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:28:45,919]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:28:51,844]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:28:57,403]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:29:06,801]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:29:12,376]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:30:01,024]\u001b[0m Trial 584 finished with value: 55.73837369835354 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026346355772557035, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2759271755737278, 'dropout_rate_Layer_2': 0.20818181391354898, 'dropout_rate_Layer_3': 0.2310573284688714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.965154609760855e-05, 'l1_Layer_2': 0.00012587562025941453, 'l1_Layer_3': 0.0036351860532220916, 'n_units_Layer_1': 190, 'n_units_Layer_2': 165, 'n_units_Layer_3': 55}. Best is trial 577 with value: 53.250623732158424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.74 | sMAPE for Validation Set is: 50.59% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.41 | sMAPE for Test Set is: 59.55% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:30:43,957]\u001b[0m Trial 585 finished with value: 58.703645647349084 and parameters: {'n_hidden': 4, 'learning_rate': 0.015756875488175455, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2637879609216816, 'dropout_rate_Layer_2': 0.1473874053579061, 'dropout_rate_Layer_3': 0.1680428472835375, 'dropout_rate_Layer_4': 0.01019478724408815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034375345119051044, 'l1_Layer_2': 1.0439442032882698e-05, 'l1_Layer_3': 0.013375950880926822, 'l1_Layer_4': 0.0001852239322907215, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170, 'n_units_Layer_4': 60}. Best is trial 577 with value: 53.250623732158424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.70 | sMAPE for Validation Set is: 52.74% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 25.47 | sMAPE for Test Set is: 59.15% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:30:54,550]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:31:30,732]\u001b[0m Trial 587 finished with value: 53.76680122843487 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016433313232542574, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2744039526790546, 'dropout_rate_Layer_2': 0.21757216444396038, 'dropout_rate_Layer_3': 0.22902459499878952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001240146515373741, 'l1_Layer_2': 0.0001728258654623582, 'l1_Layer_3': 0.00237929691420387, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 577 with value: 53.250623732158424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.77 | sMAPE for Validation Set is: 49.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.05 | sMAPE for Test Set is: 60.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:31:34,691]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:32:32,535]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:32:46,365]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:33:32,305]\u001b[0m Trial 591 finished with value: 53.82804477253995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016264294857298994, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32918449941086136, 'dropout_rate_Layer_2': 0.21205576081053695, 'dropout_rate_Layer_3': 0.22772761755380055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013334328082828938, 'l1_Layer_2': 0.0001578641581412685, 'l1_Layer_3': 0.024306263348389607, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 577 with value: 53.250623732158424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.83 | sMAPE for Validation Set is: 49.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.35 | sMAPE for Test Set is: 56.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:34:22,435]\u001b[0m Trial 592 finished with value: 57.07571381344476 and parameters: {'n_hidden': 4, 'learning_rate': 0.01545802476369761, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2341438733805432, 'dropout_rate_Layer_2': 0.17531703048523392, 'dropout_rate_Layer_3': 0.1474798666767417, 'dropout_rate_Layer_4': 0.0007404132262245761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002925820168844552, 'l1_Layer_2': 1.773833367581413e-05, 'l1_Layer_3': 0.010252931996877539, 'l1_Layer_4': 0.00018799070203132293, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 200, 'n_units_Layer_4': 100}. Best is trial 577 with value: 53.250623732158424.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.08 | sMAPE for Validation Set is: 51.76% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.81 | sMAPE for Test Set is: 56.07% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:34:27,795]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:34:32,668]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:34:40,278]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:34:45,315]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:34:51,112]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:36:10,442]\u001b[0m Trial 598 finished with value: 53.223402440274334 and parameters: {'n_hidden': 3, 'learning_rate': 0.001577165983439981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3231710731455568, 'dropout_rate_Layer_2': 0.21547448289402638, 'dropout_rate_Layer_3': 0.22952137990160495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012032244939282692, 'l1_Layer_2': 0.0001607469595552138, 'l1_Layer_3': 0.002318225778209037, 'n_units_Layer_1': 165, 'n_units_Layer_2': 165, 'n_units_Layer_3': 55}. Best is trial 598 with value: 53.223402440274334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.22 | sMAPE for Validation Set is: 48.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 56.16% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:36:14,869]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:37:05,783]\u001b[0m Trial 600 finished with value: 57.717840903862005 and parameters: {'n_hidden': 4, 'learning_rate': 0.014624711879543398, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23285743067076173, 'dropout_rate_Layer_2': 0.18248132281978308, 'dropout_rate_Layer_3': 0.17182919972495034, 'dropout_rate_Layer_4': 0.007143056163798995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00025068979251592047, 'l1_Layer_2': 1.993057354128227e-05, 'l1_Layer_3': 0.006406497541393854, 'l1_Layer_4': 0.00022219648214474427, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 195, 'n_units_Layer_4': 70}. Best is trial 598 with value: 53.223402440274334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.72 | sMAPE for Validation Set is: 51.95% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 57.92% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:37:41,770]\u001b[0m Trial 601 finished with value: 54.06445873970815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016114032287785625, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35251870241550365, 'dropout_rate_Layer_2': 0.223519030514965, 'dropout_rate_Layer_3': 0.2298407313748343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001292317967123419, 'l1_Layer_2': 0.00011571669260489031, 'l1_Layer_3': 0.0023491675306522167, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 598 with value: 53.223402440274334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.06 | sMAPE for Validation Set is: 49.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.88 | sMAPE for Test Set is: 57.23% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:37:47,599]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:38:16,251]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:39:37,298]\u001b[0m Trial 604 finished with value: 53.22580150243291 and parameters: {'n_hidden': 3, 'learning_rate': 0.001649425550697067, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34291277046707985, 'dropout_rate_Layer_2': 0.21773881801863518, 'dropout_rate_Layer_3': 0.228469199253878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012059402476297057, 'l1_Layer_2': 0.00011726737833936192, 'l1_Layer_3': 0.0023857494376144785, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 598 with value: 53.223402440274334.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.23 | sMAPE for Validation Set is: 48.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.97 | sMAPE for Test Set is: 55.87% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:40:34,973]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:40:43,156]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:41:44,095]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:41:52,471]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:42:07,380]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:42:12,060]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:42:32,651]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:43:46,300]\u001b[0m Trial 612 finished with value: 53.1043873324685 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017096263630255316, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3645541801999896, 'dropout_rate_Layer_2': 0.21014816985181947, 'dropout_rate_Layer_3': 0.22516016584139573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014987769416293143, 'l1_Layer_2': 0.00010077230100197433, 'l1_Layer_3': 0.002094750118283193, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.10 | sMAPE for Validation Set is: 48.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.89 | sMAPE for Test Set is: 56.85% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:43:59,863]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:44:07,342]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:45:10,520]\u001b[0m Trial 615 finished with value: 53.366855929335735 and parameters: {'n_hidden': 3, 'learning_rate': 0.001270992499783414, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35444826007297575, 'dropout_rate_Layer_2': 0.2124546658601445, 'dropout_rate_Layer_3': 0.22359026836448473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002018812931556039, 'l1_Layer_2': 9.232509294135003e-05, 'l1_Layer_3': 0.001920331000036124, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.37 | sMAPE for Validation Set is: 48.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.64 | sMAPE for Test Set is: 55.49% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:45:25,849]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:45:30,658]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:46:19,359]\u001b[0m Trial 618 finished with value: 54.002913040727435 and parameters: {'n_hidden': 3, 'learning_rate': 0.001270256719588108, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35536547871769564, 'dropout_rate_Layer_2': 0.21368074593415887, 'dropout_rate_Layer_3': 0.2214842790262128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020140255444106345, 'l1_Layer_2': 9.175349281784778e-05, 'l1_Layer_3': 0.0021650214851672137, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.00 | sMAPE for Validation Set is: 49.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.90 | sMAPE for Test Set is: 56.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:47:03,606]\u001b[0m Trial 619 finished with value: 53.77383434628905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012390181963089755, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35759508760797787, 'dropout_rate_Layer_2': 0.21492655035820069, 'dropout_rate_Layer_3': 0.22132156465246206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002015010626895636, 'l1_Layer_2': 9.062312841213149e-05, 'l1_Layer_3': 0.0016705068207011218, 'n_units_Layer_1': 220, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.77 | sMAPE for Validation Set is: 49.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.81 | sMAPE for Test Set is: 60.06% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:48:03,786]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:48:59,383]\u001b[0m Trial 621 finished with value: 53.3629899007071 and parameters: {'n_hidden': 3, 'learning_rate': 0.004249578044284506, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18991973106879922, 'dropout_rate_Layer_2': 0.042156298597667036, 'dropout_rate_Layer_3': 0.06051330121533248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.958068949656463e-05, 'l1_Layer_2': 0.0003089706283682081, 'l1_Layer_3': 0.00012801790912674718, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.36 | sMAPE for Validation Set is: 48.67% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.82 | sMAPE for Test Set is: 53.77% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:50:05,545]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:50:11,364]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:50:24,565]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:50:38,507]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:50:43,468]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:52:18,947]\u001b[0m Trial 627 finished with value: 53.53021509098579 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010531632484863432, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3622065617716384, 'dropout_rate_Layer_2': 0.21282684864558146, 'dropout_rate_Layer_3': 0.22169172357311806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002480748458734578, 'l1_Layer_2': 9.811613182934824e-05, 'l1_Layer_3': 0.0018953089952287016, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 80}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.53 | sMAPE for Validation Set is: 48.40% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.89 | sMAPE for Test Set is: 57.33% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:52:30,313]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:09,927]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:15,538]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:20,151]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:42,835]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:48,900]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:54,032]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:54:58,225]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 15:55:18,458]\u001b[0m Trial 636 finished with value: 57.287396656831994 and parameters: {'n_hidden': 4, 'learning_rate': 0.013907459369358737, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24605855040232447, 'dropout_rate_Layer_2': 0.0008013059320551384, 'dropout_rate_Layer_3': 0.04959450825706806, 'dropout_rate_Layer_4': 0.058056761872541676, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.492835728296515e-05, 'l1_Layer_2': 0.0003745944217015153, 'l1_Layer_3': 0.0010253962852685113, 'l1_Layer_4': 1.5101433643345856e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 85, 'n_units_Layer_4': 250}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.29 | sMAPE for Validation Set is: 51.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 33.83 | sMAPE for Test Set is: 64.14% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:56:04,429]\u001b[0m Trial 637 finished with value: 53.91752739896362 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013184646389343864, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3662878840094408, 'dropout_rate_Layer_2': 0.19796102525963527, 'dropout_rate_Layer_3': 0.20732637832670398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001500589347338023, 'l1_Layer_2': 8.736775734219722e-05, 'l1_Layer_3': 0.001479925225720021, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.92 | sMAPE for Validation Set is: 49.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.50 | sMAPE for Test Set is: 55.38% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:56:24,702]\u001b[0m Trial 638 finished with value: 54.20249924088538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033121657211825158, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1419211904761896, 'dropout_rate_Layer_2': 0.10218741459590364, 'dropout_rate_Layer_3': 0.10305038902954125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003022772298536884, 'l1_Layer_2': 5.23000490340246e-05, 'l1_Layer_3': 0.00036468364274919906, 'n_units_Layer_1': 180, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.20 | sMAPE for Validation Set is: 49.89% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.40 | sMAPE for Test Set is: 54.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 15:57:31,994]\u001b[0m Trial 639 finished with value: 53.19881150931786 and parameters: {'n_hidden': 3, 'learning_rate': 0.001328237799543623, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38342724780888915, 'dropout_rate_Layer_2': 0.2001677757990974, 'dropout_rate_Layer_3': 0.2182281599783458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015213933899485332, 'l1_Layer_2': 8.355031720598098e-05, 'l1_Layer_3': 0.0015364472386461328, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 612 with value: 53.1043873324685.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.20 | sMAPE for Validation Set is: 48.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.94 | sMAPE for Test Set is: 54.73% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:00:15,637]\u001b[0m Trial 640 finished with value: 52.66278075235044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008784169921809981, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3773112795087848, 'dropout_rate_Layer_2': 0.20219131407679808, 'dropout_rate_Layer_3': 0.21016582423516417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014692826070051716, 'l1_Layer_2': 6.490104998102887e-05, 'l1_Layer_3': 0.001689775706064157, 'n_units_Layer_1': 215, 'n_units_Layer_2': 175, 'n_units_Layer_3': 95}. Best is trial 640 with value: 52.66278075235044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.66 | sMAPE for Validation Set is: 47.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 23.90 | sMAPE for Test Set is: 55.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:00:21,433]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:00:27,392]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:00:32,644]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:00:40,451]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:02:11,519]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:02:17,207]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:02:53,579]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:03:08,225]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:03:14,008]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:03:55,453]\u001b[0m Trial 650 finished with value: 57.88248807669353 and parameters: {'n_hidden': 4, 'learning_rate': 0.010930164668782381, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28660280209962186, 'dropout_rate_Layer_2': 0.15386019467123346, 'dropout_rate_Layer_3': 0.17296597379183432, 'dropout_rate_Layer_4': 0.03836951831315801, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003063730190099088, 'l1_Layer_2': 2.2079605383657636e-05, 'l1_Layer_3': 0.010815306948586446, 'l1_Layer_4': 8.428812348907986e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 80, 'n_units_Layer_3': 165, 'n_units_Layer_4': 125}. Best is trial 640 with value: 52.66278075235044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.88 | sMAPE for Validation Set is: 52.31% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.38 | sMAPE for Test Set is: 57.17% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:04:01,061]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:04:54,463]\u001b[0m Trial 652 finished with value: 57.404171155629 and parameters: {'n_hidden': 4, 'learning_rate': 0.009899910561752755, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2867669419401728, 'dropout_rate_Layer_2': 0.1583066294257828, 'dropout_rate_Layer_3': 0.17738580332815135, 'dropout_rate_Layer_4': 0.03815335565188297, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002647187683417365, 'l1_Layer_2': 2.0020020836360738e-05, 'l1_Layer_3': 0.013823966531001963, 'l1_Layer_4': 0.00018316610070829385, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 185, 'n_units_Layer_4': 85}. Best is trial 640 with value: 52.66278075235044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.40 | sMAPE for Validation Set is: 52.14% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.13 | sMAPE for Test Set is: 57.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:05:25,688]\u001b[0m Trial 653 finished with value: 52.64487540667784 and parameters: {'n_hidden': 3, 'learning_rate': 0.005717318795058161, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11858698323984247, 'dropout_rate_Layer_2': 0.04206580180107415, 'dropout_rate_Layer_3': 0.22686078707923585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005692300045327586, 'l1_Layer_2': 1.8936823514270227e-05, 'l1_Layer_3': 0.0001405638769399523, 'n_units_Layer_1': 135, 'n_units_Layer_2': 215, 'n_units_Layer_3': 60}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.64 | sMAPE for Validation Set is: 48.51% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.92 | sMAPE for Test Set is: 60.80% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:05:31,417]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:05:36,580]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:05:46,934]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:05:51,956]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:06:03,445]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:06:08,726]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:06:19,550]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:06:24,719]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:06:30,320]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:06:35,360]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:07:37,975]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:07:43,616]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:07:52,026]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:08:05,675]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:08:59,320]\u001b[0m Trial 668 finished with value: 53.57473692602008 and parameters: {'n_hidden': 3, 'learning_rate': 0.001257803096953202, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3839930374131752, 'dropout_rate_Layer_2': 0.21224708698116243, 'dropout_rate_Layer_3': 0.22562761781727242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015229627829157913, 'l1_Layer_2': 6.658121846900418e-05, 'l1_Layer_3': 0.0011326535886733303, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 100}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.57 | sMAPE for Validation Set is: 48.82% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 56.30% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:09:04,543]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:09:10,993]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:09:16,127]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:09:21,205]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:09:28,383]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:10:08,933]\u001b[0m Trial 674 finished with value: 57.30085033185211 and parameters: {'n_hidden': 4, 'learning_rate': 0.010152482503009323, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2849592345453672, 'dropout_rate_Layer_2': 0.1799753883767975, 'dropout_rate_Layer_3': 0.19479722178910006, 'dropout_rate_Layer_4': 0.033586528093015634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021193484754948266, 'l1_Layer_2': 2.093069949326806e-05, 'l1_Layer_3': 0.006405559779589599, 'l1_Layer_4': 0.0001194970093570224, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185, 'n_units_Layer_4': 85}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.30 | sMAPE for Validation Set is: 52.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.47 | sMAPE for Test Set is: 62.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:10:29,749]\u001b[0m Trial 675 finished with value: 53.59697955850033 and parameters: {'n_hidden': 3, 'learning_rate': 0.006930863020250556, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14794559966464216, 'dropout_rate_Layer_2': 0.016380154932372396, 'dropout_rate_Layer_3': 0.014583218449881974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012504552113989023, 'l1_Layer_2': 0.00010521646243316583, 'l1_Layer_3': 0.00023400691644643231, 'n_units_Layer_1': 220, 'n_units_Layer_2': 215, 'n_units_Layer_3': 70}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.60 | sMAPE for Validation Set is: 48.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.09 | sMAPE for Test Set is: 59.12% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:10:34,933]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:10:39,857]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:11:31,927]\u001b[0m Trial 678 finished with value: 53.37454713386641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012019995600395432, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3817415155396586, 'dropout_rate_Layer_2': 0.21677250019053199, 'dropout_rate_Layer_3': 0.2194900138525082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001889386377486905, 'l1_Layer_2': 8.866938877455763e-05, 'l1_Layer_3': 0.0015306946014922464, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.37 | sMAPE for Validation Set is: 48.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.87 | sMAPE for Test Set is: 55.77% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:11:37,202]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:12:02,114]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:12:45,230]\u001b[0m Trial 681 finished with value: 53.58128941675263 and parameters: {'n_hidden': 3, 'learning_rate': 0.001273174120372045, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37730657731047695, 'dropout_rate_Layer_2': 0.20282445273681457, 'dropout_rate_Layer_3': 0.2179178454302536, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018865252198823487, 'l1_Layer_2': 4.862850445843178e-05, 'l1_Layer_3': 0.0014227826658267909, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 105}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.58 | sMAPE for Validation Set is: 48.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.89 | sMAPE for Test Set is: 56.41% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:12:50,516]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:13:41,564]\u001b[0m Trial 683 finished with value: 53.57171807883282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012371189637844407, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37869453937001946, 'dropout_rate_Layer_2': 0.20338327811079968, 'dropout_rate_Layer_3': 0.23039939668419512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019309294156400674, 'l1_Layer_2': 4.8247406229679216e-05, 'l1_Layer_3': 0.0014400191991772796, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 110}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.57 | sMAPE for Validation Set is: 48.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.13 | sMAPE for Test Set is: 55.11% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:13:47,389]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:13:53,343]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:13:58,893]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:14:22,198]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:14:36,861]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:15:18,137]\u001b[0m Trial 689 finished with value: 57.48115304897285 and parameters: {'n_hidden': 4, 'learning_rate': 0.010068716904008138, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2848678814176398, 'dropout_rate_Layer_2': 0.18056304222157274, 'dropout_rate_Layer_3': 0.17753407773106694, 'dropout_rate_Layer_4': 0.037825523607972575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021278640326141267, 'l1_Layer_2': 1.9702215283670152e-05, 'l1_Layer_3': 0.005884875214448639, 'l1_Layer_4': 0.00035557495567567607, 'n_units_Layer_1': 140, 'n_units_Layer_2': 80, 'n_units_Layer_3': 185, 'n_units_Layer_4': 115}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.48 | sMAPE for Validation Set is: 52.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.80 | sMAPE for Test Set is: 65.47% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:15:22,801]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:16:21,018]\u001b[0m Trial 691 finished with value: 53.209930419825305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008794834801521928, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37393567523648374, 'dropout_rate_Layer_2': 0.19108391950146902, 'dropout_rate_Layer_3': 0.22955720785310574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000272583615711258, 'l1_Layer_2': 5.970080468870544e-05, 'l1_Layer_3': 0.0011352365843609416, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.21 | sMAPE for Validation Set is: 48.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.24 | sMAPE for Test Set is: 56.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:17:14,278]\u001b[0m Trial 692 finished with value: 53.80024741712604 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008968417676465694, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37704795722397494, 'dropout_rate_Layer_2': 0.19250701290094674, 'dropout_rate_Layer_3': 0.23051962245369206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002773730737421537, 'l1_Layer_2': 5.3476700084638394e-05, 'l1_Layer_3': 0.001083236314322415, 'n_units_Layer_1': 205, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.80 | sMAPE for Validation Set is: 48.62% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 55.78% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:17:20,014]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:17:43,034]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:17:49,087]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:17:53,901]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:17:59,492]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:18:14,864]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:18:37,393]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:19:36,224]\u001b[0m Trial 700 finished with value: 53.853475031607296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010124706112738583, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3931074115850764, 'dropout_rate_Layer_2': 0.2145551424855065, 'dropout_rate_Layer_3': 0.22653240978312977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028803264050906866, 'l1_Layer_2': 5.682560836470453e-05, 'l1_Layer_3': 0.0016610567622107578, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.85 | sMAPE for Validation Set is: 48.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.02 | sMAPE for Test Set is: 57.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:19:41,083]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:19:57,666]\u001b[0m Trial 702 finished with value: 53.42168183979985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035033000338207734, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15127439958091152, 'dropout_rate_Layer_2': 0.04304430827337489, 'dropout_rate_Layer_3': 0.04600050593616971, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021672595026256723, 'l1_Layer_2': 8.497719350489539e-05, 'l1_Layer_3': 0.00012909505474371948, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.42 | sMAPE for Validation Set is: 48.70% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 28.36 | sMAPE for Test Set is: 59.27% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:20:56,966]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:21:04,085]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:21:09,751]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:21:15,994]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:22:12,735]\u001b[0m Trial 707 finished with value: 53.719233172305856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010570652559189408, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3809043717569014, 'dropout_rate_Layer_2': 0.20100779700804747, 'dropout_rate_Layer_3': 0.23837649656273174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018250548071339662, 'l1_Layer_2': 4.765751376521061e-05, 'l1_Layer_3': 0.0014101493907988036, 'n_units_Layer_1': 220, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.72 | sMAPE for Validation Set is: 48.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.02 | sMAPE for Test Set is: 55.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:23:06,976]\u001b[0m Trial 708 finished with value: 53.60668014974997 and parameters: {'n_hidden': 3, 'learning_rate': 0.001032562880713145, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3842256329928604, 'dropout_rate_Layer_2': 0.19926781035343114, 'dropout_rate_Layer_3': 0.23819452692075374, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018846041669321606, 'l1_Layer_2': 5.2979011433874466e-05, 'l1_Layer_3': 0.001292241406745137, 'n_units_Layer_1': 220, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.61 | sMAPE for Validation Set is: 48.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.91 | sMAPE for Test Set is: 54.83% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:23:31,209]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:23:36,563]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:24:30,859]\u001b[0m Trial 711 finished with value: 56.762781108400226 and parameters: {'n_hidden': 4, 'learning_rate': 0.01083518221176993, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28694693080503386, 'dropout_rate_Layer_2': 0.1809374503172222, 'dropout_rate_Layer_3': 0.15357708494689196, 'dropout_rate_Layer_4': 0.03462642210592959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001904854799441612, 'l1_Layer_2': 2.0896933366184696e-05, 'l1_Layer_3': 0.00567033426079029, 'l1_Layer_4': 0.00031389723454037496, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 205, 'n_units_Layer_4': 120}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.76 | sMAPE for Validation Set is: 51.75% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.18 | sMAPE for Test Set is: 61.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:24:36,453]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:24:41,537]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:24:48,823]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:25:52,098]\u001b[0m Trial 715 finished with value: 57.02672652734059 and parameters: {'n_hidden': 4, 'learning_rate': 0.010866970400066366, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2907534450359683, 'dropout_rate_Layer_2': 0.19250421334733647, 'dropout_rate_Layer_3': 0.17836086611368798, 'dropout_rate_Layer_4': 0.03919713153604839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010312742342665815, 'l1_Layer_2': 2.039763444039734e-05, 'l1_Layer_3': 0.006108348518603342, 'l1_Layer_4': 0.0003339336950776982, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 200, 'n_units_Layer_4': 120}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.03 | sMAPE for Validation Set is: 52.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.65 | sMAPE for Test Set is: 57.47% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:25:58,121]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:26:36,268]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:26:59,012]\u001b[0m Trial 718 finished with value: 52.80742587577254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034887135585253914, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18238395476036084, 'dropout_rate_Layer_2': 0.04109318049852645, 'dropout_rate_Layer_3': 0.04809357451462804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00042772547722762623, 'l1_Layer_2': 8.872978117751366e-05, 'l1_Layer_3': 0.00012283672625181948, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.81 | sMAPE for Validation Set is: 48.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 30.01 | sMAPE for Test Set is: 60.99% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:27:04,381]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:27:14,555]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:28:43,017]\u001b[0m Trial 721 finished with value: 52.73393503636538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009610886953897163, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.373514066922478, 'dropout_rate_Layer_2': 0.20309916088916236, 'dropout_rate_Layer_3': 0.23509782215982067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015885186072307704, 'l1_Layer_2': 5.339295567987341e-05, 'l1_Layer_3': 0.0015461115577937385, 'n_units_Layer_1': 225, 'n_units_Layer_2': 205, 'n_units_Layer_3': 100}. Best is trial 653 with value: 52.64487540667784.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.73 | sMAPE for Validation Set is: 47.57% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.33 | sMAPE for Test Set is: 55.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:28:49,140]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:29:08,578]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:29:13,669]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:29:35,336]\u001b[0m Trial 725 finished with value: 52.591730412345804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034340829246424275, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16488235683481417, 'dropout_rate_Layer_2': 0.04038655464293098, 'dropout_rate_Layer_3': 0.08817754804607453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023920671157674075, 'l1_Layer_2': 4.2966092121825394e-05, 'l1_Layer_3': 6.869610771252947e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.59 | sMAPE for Validation Set is: 47.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.39 | sMAPE for Test Set is: 58.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:29:41,032]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:29:46,593]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:29:53,698]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:30:04,554]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:30:10,669]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:30:30,765]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:30:36,691]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:32:11,183]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:32:26,406]\u001b[0m Trial 734 finished with value: 57.69596485741312 and parameters: {'n_hidden': 3, 'learning_rate': 0.03255606942411694, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38405759025097236, 'dropout_rate_Layer_2': 0.0008156501244654529, 'dropout_rate_Layer_3': 0.08784905913252736, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.453990604788122e-05, 'l1_Layer_2': 0.0014533454537670827, 'l1_Layer_3': 0.011708980245438925, 'n_units_Layer_1': 245, 'n_units_Layer_2': 145, 'n_units_Layer_3': 100}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.70 | sMAPE for Validation Set is: 51.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 33.48 | sMAPE for Test Set is: 64.12% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:32:32,070]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:32:37,860]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:32:43,291]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:32:49,876]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:33:01,341]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:33:08,550]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:33:13,996]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:33:31,307]\u001b[0m Trial 742 finished with value: 56.98733016873649 and parameters: {'n_hidden': 3, 'learning_rate': 0.011505215226146092, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28813969062763634, 'dropout_rate_Layer_2': 0.025927914001175337, 'dropout_rate_Layer_3': 0.09088640111387714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003995446546748925, 'l1_Layer_2': 0.001391658057617361, 'l1_Layer_3': 0.003215006320105715, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.99 | sMAPE for Validation Set is: 51.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.17 | sMAPE for Test Set is: 57.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:33:49,140]\u001b[0m Trial 743 finished with value: 56.91607992224632 and parameters: {'n_hidden': 3, 'learning_rate': 0.011448272773730304, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28925114293030924, 'dropout_rate_Layer_2': 0.027308550225939778, 'dropout_rate_Layer_3': 0.08940311200359735, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032788308753756512, 'l1_Layer_2': 0.0014304960983410415, 'l1_Layer_3': 0.003374608190006567, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.92 | sMAPE for Validation Set is: 51.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.14 | sMAPE for Test Set is: 55.17% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:35:29,706]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:35:36,767]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:35:55,968]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:36:30,323]\u001b[0m Trial 747 finished with value: 57.15007962401881 and parameters: {'n_hidden': 4, 'learning_rate': 0.0067405996956453875, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27048394898038514, 'dropout_rate_Layer_2': 0.228733236869979, 'dropout_rate_Layer_3': 0.15398212051310145, 'dropout_rate_Layer_4': 0.026369316817541667, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021905051170285298, 'l1_Layer_2': 2.9242539307031605e-05, 'l1_Layer_3': 0.004287189894680604, 'l1_Layer_4': 0.00033554842667734506, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 215, 'n_units_Layer_4': 85}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.15 | sMAPE for Validation Set is: 52.07% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.72 | sMAPE for Test Set is: 61.83% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:36:41,885]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:36:48,032]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:37:33,241]\u001b[0m Trial 750 finished with value: 54.11926456389508 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012302615778690617, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3699373210823025, 'dropout_rate_Layer_2': 0.1994849795086729, 'dropout_rate_Layer_3': 0.22434625299646127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014542902613100438, 'l1_Layer_2': 7.172344710848938e-05, 'l1_Layer_3': 0.0014089077446808598, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 95}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.12 | sMAPE for Validation Set is: 49.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.01 | sMAPE for Test Set is: 54.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:37:45,134]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:37:51,287]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:37:56,051]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:38:02,053]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:38:10,074]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:38:16,243]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:38:48,996]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:38:54,281]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:39:42,049]\u001b[0m Trial 759 finished with value: 53.70056101987995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011654917950501352, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36274968563080245, 'dropout_rate_Layer_2': 0.19307910540788528, 'dropout_rate_Layer_3': 0.2342580426279596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001592379002108439, 'l1_Layer_2': 7.643561883443129e-05, 'l1_Layer_3': 0.0015186617014382262, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.70 | sMAPE for Validation Set is: 49.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.37 | sMAPE for Test Set is: 56.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:40:34,421]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:40:54,892]\u001b[0m Trial 761 finished with value: 56.701886246131124 and parameters: {'n_hidden': 3, 'learning_rate': 0.013000110610874378, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2708340467174226, 'dropout_rate_Layer_2': 0.018981638972989354, 'dropout_rate_Layer_3': 0.06679132288808295, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024753141333058192, 'l1_Layer_2': 0.002441238064724606, 'l1_Layer_3': 0.00023809024481867403, 'n_units_Layer_1': 260, 'n_units_Layer_2': 235, 'n_units_Layer_3': 240}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.70 | sMAPE for Validation Set is: 51.13% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 26.50 | sMAPE for Test Set is: 57.95% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:41:01,312]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:41:08,216]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:41:13,406]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:41:20,280]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:41:24,469]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:41:44,064]\u001b[0m Trial 767 finished with value: 53.74205611942901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025703234796015935, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20071005779967174, 'dropout_rate_Layer_2': 0.04294452470248422, 'dropout_rate_Layer_3': 0.10896024997473602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.271125949290656e-05, 'l1_Layer_2': 3.6052286390735853e-05, 'l1_Layer_3': 2.3452568844386683e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.74 | sMAPE for Validation Set is: 48.78% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.61 | sMAPE for Test Set is: 55.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:42:35,996]\u001b[0m Trial 768 finished with value: 53.60565620352755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010451760391187253, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3625940759790592, 'dropout_rate_Layer_2': 0.19150880451452013, 'dropout_rate_Layer_3': 0.224837064912344, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002504033865135898, 'l1_Layer_2': 3.415169678384902e-05, 'l1_Layer_3': 0.002887587761500806, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.61 | sMAPE for Validation Set is: 49.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.50 | sMAPE for Test Set is: 56.33% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:42:45,803]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:43:27,551]\u001b[0m Trial 770 finished with value: 54.011853596364915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006775000417873754, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37413804992823646, 'dropout_rate_Layer_2': 0.20547909835907927, 'dropout_rate_Layer_3': 0.24824329312229443, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023398210072990866, 'l1_Layer_2': 2.9768831399744738e-05, 'l1_Layer_3': 0.0020799619204903705, 'n_units_Layer_1': 220, 'n_units_Layer_2': 200, 'n_units_Layer_3': 110}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.01 | sMAPE for Validation Set is: 49.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.96 | sMAPE for Test Set is: 59.34% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:43:43,815]\u001b[0m Trial 771 finished with value: 56.38409923637158 and parameters: {'n_hidden': 3, 'learning_rate': 0.009775019190212432, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2845596014771083, 'dropout_rate_Layer_2': 0.03490899656198938, 'dropout_rate_Layer_3': 0.08466064238015471, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022421861332182335, 'l1_Layer_2': 0.0024285498846658834, 'l1_Layer_3': 0.0020263877447437096, 'n_units_Layer_1': 265, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.38 | sMAPE for Validation Set is: 50.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.59 | sMAPE for Test Set is: 54.87% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:43:48,390]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:44:05,050]\u001b[0m Trial 773 finished with value: 53.413198697878215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035380083278822427, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1612846135414156, 'dropout_rate_Layer_2': 0.034789796225351256, 'dropout_rate_Layer_3': 0.04211701246599751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002191620287476492, 'l1_Layer_2': 7.607361967601787e-05, 'l1_Layer_3': 0.00012006616992707966, 'n_units_Layer_1': 90, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.41 | sMAPE for Validation Set is: 48.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.63 | sMAPE for Test Set is: 56.11% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:44:28,405]\u001b[0m Trial 774 finished with value: 53.65789349461706 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030413100290336264, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16277470660331902, 'dropout_rate_Layer_2': 0.0576767346704638, 'dropout_rate_Layer_3': 0.04330650157266855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028430917087377537, 'l1_Layer_2': 0.0001367949086311296, 'l1_Layer_3': 7.664425958021379e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 180, 'n_units_Layer_3': 60}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.66 | sMAPE for Validation Set is: 48.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.27 | sMAPE for Test Set is: 58.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:44:52,878]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:44:59,551]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:45:25,171]\u001b[0m Trial 777 finished with value: 52.93151740485993 and parameters: {'n_hidden': 3, 'learning_rate': 0.003851592318465341, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12860402049974393, 'dropout_rate_Layer_2': 0.03715903121088349, 'dropout_rate_Layer_3': 0.06104537933983913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003584182218556678, 'l1_Layer_2': 7.502603482537171e-05, 'l1_Layer_3': 4.893150069119374e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 160, 'n_units_Layer_3': 295}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.93 | sMAPE for Validation Set is: 48.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.57 | sMAPE for Test Set is: 56.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:46:18,071]\u001b[0m Trial 778 finished with value: 53.489793404212755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008362337504572324, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35999015267511814, 'dropout_rate_Layer_2': 0.18360714366155992, 'dropout_rate_Layer_3': 0.22057356303660636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013462621305918184, 'l1_Layer_2': 6.917101321069459e-05, 'l1_Layer_3': 0.002989904594327414, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.49 | sMAPE for Validation Set is: 48.64% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.45 | sMAPE for Test Set is: 55.47% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:46:56,181]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:00,644]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:07,825]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:12,049]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:18,619]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:22,743]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:34,056]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:40,463]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:45,377]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:50,104]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:47:54,985]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:48:05,589]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:48:22,037]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:48:52,854]\u001b[0m Trial 792 finished with value: 57.15610493663081 and parameters: {'n_hidden': 4, 'learning_rate': 0.010464462263102143, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2281176389731732, 'dropout_rate_Layer_2': 0.19955389456278227, 'dropout_rate_Layer_3': 0.16181975150000297, 'dropout_rate_Layer_4': 0.02178809609370001, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00019338624126241384, 'l1_Layer_2': 3.2143207144523804e-05, 'l1_Layer_3': 0.007277841010099398, 'l1_Layer_4': 0.00026211331798755926, 'n_units_Layer_1': 140, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185, 'n_units_Layer_4': 140}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.16 | sMAPE for Validation Set is: 51.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 23.15 | sMAPE for Test Set is: 57.54% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:49:03,179]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:49:37,554]\u001b[0m Trial 794 finished with value: 56.977564981338354 and parameters: {'n_hidden': 4, 'learning_rate': 0.010107401294401802, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22145182676728625, 'dropout_rate_Layer_2': 0.2115893169871053, 'dropout_rate_Layer_3': 0.12836182987338354, 'dropout_rate_Layer_4': 0.043746750271972355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012369246166595824, 'l1_Layer_2': 3.263823939169231e-05, 'l1_Layer_3': 0.004606038496282923, 'l1_Layer_4': 0.0009058863965216729, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185, 'n_units_Layer_4': 140}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.98 | sMAPE for Validation Set is: 51.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 61.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:49:42,162]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:49:48,823]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:50:01,292]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:50:23,844]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:50:30,898]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:50:37,625]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:51:36,079]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:51:40,835]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:52:29,321]\u001b[0m Trial 803 finished with value: 53.65238803000091 and parameters: {'n_hidden': 3, 'learning_rate': 0.001350716562288077, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3838906105174212, 'dropout_rate_Layer_2': 0.21846192294729863, 'dropout_rate_Layer_3': 0.23483357348508466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016295613463316108, 'l1_Layer_2': 8.278459989574133e-05, 'l1_Layer_3': 0.0011362336730344285, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 110}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.65 | sMAPE for Validation Set is: 48.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.68 | sMAPE for Test Set is: 56.37% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:53:35,234]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:53:54,458]\u001b[0m Trial 805 finished with value: 56.14828340657707 and parameters: {'n_hidden': 3, 'learning_rate': 0.014500300183074664, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.141239220610321, 'dropout_rate_Layer_2': 0.025061075690682978, 'dropout_rate_Layer_3': 0.047496530998008615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016329950885580582, 'l1_Layer_2': 0.0006621649178435441, 'l1_Layer_3': 0.001678901723955514, 'n_units_Layer_1': 240, 'n_units_Layer_2': 240, 'n_units_Layer_3': 230}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.15 | sMAPE for Validation Set is: 50.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.53 | sMAPE for Test Set is: 57.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:53:59,375]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:54:19,465]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:54:25,785]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:55:25,588]\u001b[0m Trial 809 finished with value: 53.28311044448137 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010441409892827129, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37912246807739464, 'dropout_rate_Layer_2': 0.2180062953797259, 'dropout_rate_Layer_3': 0.21526509267544205, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001937337768316132, 'l1_Layer_2': 9.111787590423912e-05, 'l1_Layer_3': 0.0012056575143900962, 'n_units_Layer_1': 225, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.28 | sMAPE for Validation Set is: 48.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.67 | sMAPE for Test Set is: 55.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:55:53,893]\u001b[0m Trial 810 finished with value: 56.607852123745154 and parameters: {'n_hidden': 4, 'learning_rate': 0.007146149991147302, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19469316268843567, 'dropout_rate_Layer_2': 0.2098252506795298, 'dropout_rate_Layer_3': 0.1462642192389918, 'dropout_rate_Layer_4': 0.05974545931658992, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.993173798704812e-05, 'l1_Layer_2': 3.23929408094188e-05, 'l1_Layer_3': 0.007416082595555493, 'l1_Layer_4': 0.0004953071185631242, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 210, 'n_units_Layer_4': 110}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.61 | sMAPE for Validation Set is: 51.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.97 | sMAPE for Test Set is: 53.82% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:56:00,392]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:56:06,357]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:56:14,045]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:56:20,570]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:56:44,466]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:56:51,973]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:56:56,370]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:57:01,101]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:58:14,570]\u001b[0m Trial 819 finished with value: 53.07997290775818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007671774098662225, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3693257874455898, 'dropout_rate_Layer_2': 0.2028448106817745, 'dropout_rate_Layer_3': 0.2231545046827157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020482236870616988, 'l1_Layer_2': 9.514629700554943e-05, 'l1_Layer_3': 0.0007024624037095171, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.08 | sMAPE for Validation Set is: 48.75% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.48 | sMAPE for Test Set is: 57.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 16:58:30,742]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:58:34,905]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:58:39,111]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:58:43,885]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:58:47,947]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:58:59,187]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 16:59:19,781]\u001b[0m Trial 826 finished with value: 55.53206505642507 and parameters: {'n_hidden': 3, 'learning_rate': 0.009901656570149145, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3286235218105579, 'dropout_rate_Layer_2': 0.017992962821061734, 'dropout_rate_Layer_3': 0.030919469101816068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005583912305119278, 'l1_Layer_2': 0.0013336644068379468, 'l1_Layer_3': 0.00018713536238694747, 'n_units_Layer_1': 265, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.53 | sMAPE for Validation Set is: 50.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.26 | sMAPE for Test Set is: 54.62% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:00:04,493]\u001b[0m Trial 827 finished with value: 53.468801051771244 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009732206933344716, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36996748013227926, 'dropout_rate_Layer_2': 0.20148524505236187, 'dropout_rate_Layer_3': 0.22363514229363676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021048284498033072, 'l1_Layer_2': 9.57121073479894e-05, 'l1_Layer_3': 0.0008083911457439635, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 120}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.47 | sMAPE for Validation Set is: 49.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 59.89% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:00:36,099]\u001b[0m Trial 828 finished with value: 56.55650600615271 and parameters: {'n_hidden': 4, 'learning_rate': 0.007412139345558205, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2532955689820936, 'dropout_rate_Layer_2': 0.19749116942126865, 'dropout_rate_Layer_3': 0.14444508950296545, 'dropout_rate_Layer_4': 0.05470320904994466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013311047649561757, 'l1_Layer_2': 3.8977074804409794e-05, 'l1_Layer_3': 0.010396817277511985, 'l1_Layer_4': 0.0012211043923398173, 'n_units_Layer_1': 150, 'n_units_Layer_2': 285, 'n_units_Layer_3': 210, 'n_units_Layer_4': 165}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.56 | sMAPE for Validation Set is: 51.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.82 | sMAPE for Test Set is: 53.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:00:41,107]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:01:55,668]\u001b[0m Trial 830 finished with value: 53.035638199330094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007486948981785402, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3723571281273248, 'dropout_rate_Layer_2': 0.2009086158981701, 'dropout_rate_Layer_3': 0.2344023140949543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014607719896919566, 'l1_Layer_2': 6.158961129681947e-05, 'l1_Layer_3': 0.0006793832406763738, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.04 | sMAPE for Validation Set is: 48.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 55.75% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:02:06,155]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:02:50,049]\u001b[0m Trial 832 finished with value: 53.97202874270905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007605001941172992, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36749261100742175, 'dropout_rate_Layer_2': 0.18495401839635855, 'dropout_rate_Layer_3': 0.21987580802636814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020899844887457345, 'l1_Layer_2': 3.8343543700804094e-05, 'l1_Layer_3': 0.000836457023979299, 'n_units_Layer_1': 250, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.97 | sMAPE for Validation Set is: 49.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 24.16 | sMAPE for Test Set is: 57.34% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:03:14,162]\u001b[0m Trial 833 finished with value: 56.168780866606056 and parameters: {'n_hidden': 3, 'learning_rate': 0.011061001430362644, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07680192092420944, 'dropout_rate_Layer_2': 0.2277014041396967, 'dropout_rate_Layer_3': 0.043109319349411916, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002687082269614926, 'l1_Layer_2': 0.0017882560998786383, 'l1_Layer_3': 0.00040912684284944155, 'n_units_Layer_1': 275, 'n_units_Layer_2': 230, 'n_units_Layer_3': 290}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.17 | sMAPE for Validation Set is: 50.69% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.64 | sMAPE for Test Set is: 60.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:03:21,270]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:03:26,033]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:03:50,213]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:04:13,691]\u001b[0m Trial 837 finished with value: 55.350062861541915 and parameters: {'n_hidden': 3, 'learning_rate': 0.010771118695775806, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3219037134443677, 'dropout_rate_Layer_2': 0.26103110934789, 'dropout_rate_Layer_3': 0.03912789559749659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001803984519605384, 'l1_Layer_2': 0.002002733256997136, 'l1_Layer_3': 0.0001517929674394016, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 240}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.35 | sMAPE for Validation Set is: 50.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.93 | sMAPE for Test Set is: 57.45% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:04:26,076]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:04:30,292]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:05:09,568]\u001b[0m Trial 840 finished with value: 54.99186536226609 and parameters: {'n_hidden': 3, 'learning_rate': 0.00888844770545791, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1559155576154449, 'dropout_rate_Layer_2': 0.20789480717256098, 'dropout_rate_Layer_3': 0.04148614098311379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037861568887350284, 'l1_Layer_2': 0.0021218774038335546, 'l1_Layer_3': 0.0001675415603976296, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.99 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.88 | sMAPE for Test Set is: 55.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:06:28,072]\u001b[0m Trial 841 finished with value: 53.28245290292333 and parameters: {'n_hidden': 3, 'learning_rate': 0.000979783028886781, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3631448177470489, 'dropout_rate_Layer_2': 0.19496447485174145, 'dropout_rate_Layer_3': 0.2594644394564334, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003269495932037651, 'l1_Layer_2': 9.868797266477889e-05, 'l1_Layer_3': 0.0011931061365801046, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 95}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.28 | sMAPE for Validation Set is: 48.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.15 | sMAPE for Test Set is: 54.47% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:06:32,874]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:06:37,097]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:07:20,958]\u001b[0m Trial 844 finished with value: 57.451290450355295 and parameters: {'n_hidden': 4, 'learning_rate': 0.007181904480198077, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19913514020930578, 'dropout_rate_Layer_2': 0.21922559666252286, 'dropout_rate_Layer_3': 0.14096286069008426, 'dropout_rate_Layer_4': 0.05727552693232258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.282597338662657e-05, 'l1_Layer_2': 6.162451980188797e-05, 'l1_Layer_3': 0.002273082741512577, 'l1_Layer_4': 0.0014374945489865295, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215, 'n_units_Layer_4': 165}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.45 | sMAPE for Validation Set is: 51.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.68 | sMAPE for Test Set is: 55.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:07:27,707]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:07:37,999]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:08:06,368]\u001b[0m Trial 847 finished with value: 54.341161541772 and parameters: {'n_hidden': 4, 'learning_rate': 0.00541296601058614, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24777131399215724, 'dropout_rate_Layer_2': 0.20182281319669143, 'dropout_rate_Layer_3': 0.1512753966066521, 'dropout_rate_Layer_4': 0.0686677684982464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013235159851717558, 'l1_Layer_2': 3.587279608164343e-05, 'l1_Layer_3': 0.0041307948493138295, 'l1_Layer_4': 0.0007918978288195331, 'n_units_Layer_1': 145, 'n_units_Layer_2': 290, 'n_units_Layer_3': 240, 'n_units_Layer_4': 140}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.34 | sMAPE for Validation Set is: 49.41% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 32.61 | sMAPE for Test Set is: 62.33% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:08:30,817]\u001b[0m Trial 848 finished with value: 56.012652493535484 and parameters: {'n_hidden': 3, 'learning_rate': 0.009242954856207347, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13671465400466062, 'dropout_rate_Layer_2': 0.26512973527038436, 'dropout_rate_Layer_3': 0.038771836138240395, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001952359367278355, 'l1_Layer_2': 0.002261115633704651, 'l1_Layer_3': 0.00014816368287047635, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 290}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.01 | sMAPE for Validation Set is: 50.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.03 | sMAPE for Test Set is: 53.90% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:08:36,945]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:08:52,704]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:08:59,273]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:09:27,679]\u001b[0m Trial 852 finished with value: 55.93913513788215 and parameters: {'n_hidden': 3, 'learning_rate': 0.008093183224149515, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16032888544411367, 'dropout_rate_Layer_2': 0.24834771287006363, 'dropout_rate_Layer_3': 0.049909194191724425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028238486921731287, 'l1_Layer_2': 0.002928013355222675, 'l1_Layer_3': 0.00015572731238875696, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.94 | sMAPE for Validation Set is: 50.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 26.01 | sMAPE for Test Set is: 57.35% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:09:32,712]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:09:37,223]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:09:49,146]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:09:54,273]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:10:16,964]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:11:13,427]\u001b[0m Trial 858 finished with value: 53.66394136042651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009586070591524962, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3511184588653821, 'dropout_rate_Layer_2': 0.20807732260807357, 'dropout_rate_Layer_3': 0.20667055299051462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029386481230572476, 'l1_Layer_2': 9.77966567521968e-05, 'l1_Layer_3': 0.0008437420402815028, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.66 | sMAPE for Validation Set is: 48.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.77 | sMAPE for Test Set is: 57.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:11:22,519]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:11:27,657]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:11:43,511]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:11:49,004]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:12:09,054]\u001b[0m Trial 863 finished with value: 55.71583972556882 and parameters: {'n_hidden': 3, 'learning_rate': 0.00703913147597121, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16057091679614857, 'dropout_rate_Layer_2': 0.2232559762267054, 'dropout_rate_Layer_3': 0.06059117236499908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001893048098533578, 'l1_Layer_2': 0.002896844042660216, 'l1_Layer_3': 0.00013902747251978272, 'n_units_Layer_1': 280, 'n_units_Layer_2': 230, 'n_units_Layer_3': 300}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.72 | sMAPE for Validation Set is: 51.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 55.63% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:12:14,380]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:12:19,957]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:12:25,315]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:12:51,060]\u001b[0m Trial 867 finished with value: 55.710473171367106 and parameters: {'n_hidden': 3, 'learning_rate': 0.00836082835020118, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15403058030512573, 'dropout_rate_Layer_2': 0.2610241390529033, 'dropout_rate_Layer_3': 0.051012904629176015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014252029789562303, 'l1_Layer_2': 0.00224674376524665, 'l1_Layer_3': 0.0001469824206991951, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 295}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.71 | sMAPE for Validation Set is: 51.02% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.66 | sMAPE for Test Set is: 54.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:13:13,539]\u001b[0m Trial 868 finished with value: 55.496851688866236 and parameters: {'n_hidden': 3, 'learning_rate': 0.005998470181956061, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1642847424682199, 'dropout_rate_Layer_2': 0.2591404199869897, 'dropout_rate_Layer_3': 0.049896263563240166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014574367399190823, 'l1_Layer_2': 0.0022366297305617283, 'l1_Layer_3': 0.00013921358752545131, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.50 | sMAPE for Validation Set is: 50.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.65 | sMAPE for Test Set is: 57.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:14:23,651]\u001b[0m Trial 869 finished with value: 52.95720614685026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009439010179502787, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3474093052541896, 'dropout_rate_Layer_2': 0.2086513064604102, 'dropout_rate_Layer_3': 0.20837223942940583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003178693090020106, 'l1_Layer_2': 0.00010051578451409756, 'l1_Layer_3': 0.0008960686341490167, 'n_units_Layer_1': 235, 'n_units_Layer_2': 175, 'n_units_Layer_3': 110}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.96 | sMAPE for Validation Set is: 47.76% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.46 | sMAPE for Test Set is: 53.61% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:14:28,822]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:14:47,582]\u001b[0m Trial 871 finished with value: 55.46633856233827 and parameters: {'n_hidden': 3, 'learning_rate': 0.006707701099596146, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16379296621480996, 'dropout_rate_Layer_2': 0.24629734370130707, 'dropout_rate_Layer_3': 0.06656915134044107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001330245657440875, 'l1_Layer_2': 0.0026681657382732963, 'l1_Layer_3': 0.00012039375958081701, 'n_units_Layer_1': 280, 'n_units_Layer_2': 240, 'n_units_Layer_3': 295}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.47 | sMAPE for Validation Set is: 50.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 26.20 | sMAPE for Test Set is: 57.94% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:14:52,835]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:14:58,175]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:15:03,622]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:15:30,509]\u001b[0m Trial 875 finished with value: 55.944291916754196 and parameters: {'n_hidden': 3, 'learning_rate': 0.007683830668135356, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16152791409133108, 'dropout_rate_Layer_2': 0.25921990954941854, 'dropout_rate_Layer_3': 0.05814972254608739, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016171819050060486, 'l1_Layer_2': 0.004137570778333779, 'l1_Layer_3': 0.00017964383557307208, 'n_units_Layer_1': 295, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.94 | sMAPE for Validation Set is: 51.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.05 | sMAPE for Test Set is: 56.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:15:35,106]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:15:50,996]\u001b[0m Trial 877 finished with value: 56.762046680482065 and parameters: {'n_hidden': 3, 'learning_rate': 0.006552357552909906, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16491656709977662, 'dropout_rate_Layer_2': 0.2657492010603355, 'dropout_rate_Layer_3': 0.05791356354866896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015130398975247522, 'l1_Layer_2': 0.003961002870235744, 'l1_Layer_3': 0.00010370717412195671, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.76 | sMAPE for Validation Set is: 51.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.83 | sMAPE for Test Set is: 57.96% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:15:55,728]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:16:05,467]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:16:26,017]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:16:50,935]\u001b[0m Trial 881 finished with value: 54.364203833490045 and parameters: {'n_hidden': 4, 'learning_rate': 0.005251915038557254, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2522904643387449, 'dropout_rate_Layer_2': 0.24135311407870602, 'dropout_rate_Layer_3': 0.1354174414451099, 'dropout_rate_Layer_4': 0.07242101734074569, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001506938841861159, 'l1_Layer_2': 5.1675480159030845e-05, 'l1_Layer_3': 0.0049600094875346884, 'l1_Layer_4': 0.0007031840155168856, 'n_units_Layer_1': 165, 'n_units_Layer_2': 300, 'n_units_Layer_3': 220, 'n_units_Layer_4': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.36 | sMAPE for Validation Set is: 49.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.11 | sMAPE for Test Set is: 59.26% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:16:57,378]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:17:01,110]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:17:05,175]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:17:26,290]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:17:34,197]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:17:54,609]\u001b[0m Trial 887 finished with value: 53.54123949467081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0046467813538030485, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13516607590560267, 'dropout_rate_Layer_2': 0.028569874432455948, 'dropout_rate_Layer_3': 0.03620697813143765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044117516527108277, 'l1_Layer_2': 8.113496395951288e-05, 'l1_Layer_3': 0.00010046197394275995, 'n_units_Layer_1': 80, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.54 | sMAPE for Validation Set is: 48.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.67 | sMAPE for Test Set is: 58.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:18:06,933]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:18:19,314]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:18:23,828]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:18:46,104]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:18:52,531]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:18:58,940]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:19:09,735]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:19:14,376]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:19:18,316]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:20:13,775]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:20:17,886]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:21:20,127]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:21:35,413]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:21:40,534]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:22:03,258]\u001b[0m Trial 902 finished with value: 54.47132989262291 and parameters: {'n_hidden': 4, 'learning_rate': 0.0063779131192689305, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26994437511398306, 'dropout_rate_Layer_2': 0.2004039151354254, 'dropout_rate_Layer_3': 0.11132993016888978, 'dropout_rate_Layer_4': 0.07919909203601304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012395988068254792, 'l1_Layer_2': 2.811672420429183e-05, 'l1_Layer_3': 0.0038235308808219916, 'l1_Layer_4': 0.0009708391932134632, 'n_units_Layer_1': 135, 'n_units_Layer_2': 295, 'n_units_Layer_3': 205, 'n_units_Layer_4': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.47 | sMAPE for Validation Set is: 49.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.85 | sMAPE for Test Set is: 58.12% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:23:00,142]\u001b[0m Trial 903 finished with value: 53.76754524993385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008517385036840658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3674507769135682, 'dropout_rate_Layer_2': 0.19829165690491055, 'dropout_rate_Layer_3': 0.257405773805897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002778826655825248, 'l1_Layer_2': 8.182062309251873e-05, 'l1_Layer_3': 0.0008914992094692742, 'n_units_Layer_1': 230, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.77 | sMAPE for Validation Set is: 49.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.54 | sMAPE for Test Set is: 57.73% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:23:23,997]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:23:54,426]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:24:23,936]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:24:29,756]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:24:35,340]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:24:58,454]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:25:21,418]\u001b[0m Trial 910 finished with value: 54.54218717426007 and parameters: {'n_hidden': 4, 'learning_rate': 0.005422594713386664, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24707776549551563, 'dropout_rate_Layer_2': 0.22597516799759576, 'dropout_rate_Layer_3': 0.11592492930410356, 'dropout_rate_Layer_4': 0.07573062118455091, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00012424929080292405, 'l1_Layer_2': 8.16858778357375e-05, 'l1_Layer_3': 0.003848033801665027, 'l1_Layer_4': 0.0009896775388388125, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225, 'n_units_Layer_4': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.54 | sMAPE for Validation Set is: 49.18% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 33.37 | sMAPE for Test Set is: 62.75% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:25:43,103]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:25:48,387]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:25:53,446]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:26:17,005]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:26:22,188]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:26:31,758]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:26:48,101]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:26:52,195]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:26:57,453]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:27:16,479]\u001b[0m Trial 920 finished with value: 54.54244769581093 and parameters: {'n_hidden': 4, 'learning_rate': 0.005093311986728395, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24690429521042712, 'dropout_rate_Layer_2': 0.20986259175555202, 'dropout_rate_Layer_3': 0.11169889904987049, 'dropout_rate_Layer_4': 0.07592195406849828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00011879927771068553, 'l1_Layer_2': 8.834031974551577e-05, 'l1_Layer_3': 0.00324786139792514, 'l1_Layer_4': 0.0016425495134734253, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 225, 'n_units_Layer_4': 105}. Best is trial 725 with value: 52.591730412345804.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.54 | sMAPE for Validation Set is: 49.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.12 | sMAPE for Test Set is: 54.74% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:27:26,253]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:27:31,453]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:27:37,439]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:27:43,568]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:28:06,390]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:28:16,373]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:28:48,804]\u001b[0m Trial 927 finished with value: 52.58114527638856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035893856679918715, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1691710249823842, 'dropout_rate_Layer_2': 0.03606658967553315, 'dropout_rate_Layer_3': 0.03752925956573132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022324217306293647, 'l1_Layer_2': 7.261887986882815e-05, 'l1_Layer_3': 0.00012311580641575134, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 65}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.58 | sMAPE for Validation Set is: 48.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.34 | sMAPE for Test Set is: 58.77% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:28:53,975]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:28:58,754]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:29:04,096]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:29:09,409]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:29:41,343]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:30:08,575]\u001b[0m Trial 933 finished with value: 53.50960966335203 and parameters: {'n_hidden': 4, 'learning_rate': 0.0038974432416491976, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24411239601027, 'dropout_rate_Layer_2': 0.2203937781135931, 'dropout_rate_Layer_3': 0.10338543900864741, 'dropout_rate_Layer_4': 0.07483303747970596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.002248044416945e-05, 'l1_Layer_2': 4.307408411397268e-05, 'l1_Layer_3': 0.0021160749108485957, 'l1_Layer_4': 0.001038397324179712, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 225, 'n_units_Layer_4': 95}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.51 | sMAPE for Validation Set is: 48.57% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 30.72 | sMAPE for Test Set is: 62.04% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:30:17,277]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:30:41,474]\u001b[0m Trial 935 finished with value: 55.725862418374874 and parameters: {'n_hidden': 3, 'learning_rate': 0.007376276198390275, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18410666189152802, 'dropout_rate_Layer_2': 0.2849624625773601, 'dropout_rate_Layer_3': 0.05245030286874279, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035653181864521243, 'l1_Layer_2': 0.0021795407120527637, 'l1_Layer_3': 0.00015384798630780716, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.73 | sMAPE for Validation Set is: 50.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.30 | sMAPE for Test Set is: 55.23% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:31:33,258]\u001b[0m Trial 936 finished with value: 53.64299928980597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012343437186305194, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3687849439054819, 'dropout_rate_Layer_2': 0.2048256871451639, 'dropout_rate_Layer_3': 0.2107813975604882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011579348751956388, 'l1_Layer_2': 2.0668506568016517e-05, 'l1_Layer_3': 0.001436321542027696, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.64 | sMAPE for Validation Set is: 48.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.33 | sMAPE for Test Set is: 56.50% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:31:57,515]\u001b[0m Trial 937 finished with value: 55.15430651826538 and parameters: {'n_hidden': 3, 'learning_rate': 0.007321157196545316, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20049646779970723, 'dropout_rate_Layer_2': 0.29486089538705346, 'dropout_rate_Layer_3': 0.05118833076647785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000323394004892494, 'l1_Layer_2': 0.002888549039579802, 'l1_Layer_3': 0.00015373989451120595, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.15 | sMAPE for Validation Set is: 49.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.66 | sMAPE for Test Set is: 58.65% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:32:20,617]\u001b[0m Trial 938 finished with value: 55.75853544943201 and parameters: {'n_hidden': 3, 'learning_rate': 0.007264640408842989, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18014359294924046, 'dropout_rate_Layer_2': 0.2821780323919575, 'dropout_rate_Layer_3': 0.05134823400824135, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003249852624119522, 'l1_Layer_2': 0.0024424638375357736, 'l1_Layer_3': 0.00015354355891409734, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.76 | sMAPE for Validation Set is: 50.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 55.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:32:25,777]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:32:31,184]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:33:00,959]\u001b[0m Trial 941 finished with value: 56.00345624410628 and parameters: {'n_hidden': 3, 'learning_rate': 0.007733862368984077, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17994314930983557, 'dropout_rate_Layer_2': 0.2833916868092685, 'dropout_rate_Layer_3': 0.05898279691875594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004797816349564552, 'l1_Layer_2': 0.0033533870992278067, 'l1_Layer_3': 0.00010329381441579804, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.00 | sMAPE for Validation Set is: 51.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.98 | sMAPE for Test Set is: 60.98% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:33:11,626]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:33:16,863]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:33:23,722]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:33:29,148]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:33:33,727]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:33:56,953]\u001b[0m Trial 947 finished with value: 53.16385098704405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037402033961475385, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1752529408523892, 'dropout_rate_Layer_2': 0.05091929370206091, 'dropout_rate_Layer_3': 0.061581366836416164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002514409009802068, 'l1_Layer_2': 4.5049615128051796e-05, 'l1_Layer_3': 0.00015669591634924875, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.16 | sMAPE for Validation Set is: 48.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.50 | sMAPE for Test Set is: 55.41% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:34:10,650]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:34:16,545]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:34:21,923]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:34:26,372]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:34:47,719]\u001b[0m Trial 952 finished with value: 56.07238322668056 and parameters: {'n_hidden': 3, 'learning_rate': 0.006890247089279518, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18866398856958283, 'dropout_rate_Layer_2': 0.2892516643314575, 'dropout_rate_Layer_3': 0.16551907348657974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003970890652298861, 'l1_Layer_2': 0.002110638274892466, 'l1_Layer_3': 7.525256360524877e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.07 | sMAPE for Validation Set is: 50.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.50 | sMAPE for Test Set is: 56.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:34:53,134]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:35:19,716]\u001b[0m Trial 954 finished with value: 56.27160933487463 and parameters: {'n_hidden': 3, 'learning_rate': 0.005608945880208282, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17302745494592078, 'dropout_rate_Layer_2': 0.26968510076171925, 'dropout_rate_Layer_3': 0.29405226404867807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003236151640712077, 'l1_Layer_2': 0.0033424250399953803, 'l1_Layer_3': 9.89404865530511e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.27 | sMAPE for Validation Set is: 51.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.53 | sMAPE for Test Set is: 60.97% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:35:27,187]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:35:33,164]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:35:52,813]\u001b[0m Trial 957 finished with value: 53.73766349318654 and parameters: {'n_hidden': 4, 'learning_rate': 0.004133535471148329, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24618964856034145, 'dropout_rate_Layer_2': 0.22223431768555207, 'dropout_rate_Layer_3': 0.1019425483352461, 'dropout_rate_Layer_4': 0.07680033286476545, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 8.057811832097033e-05, 'l1_Layer_2': 5.736079298110333e-05, 'l1_Layer_3': 0.0022576553898591848, 'l1_Layer_4': 0.0009974260351421496, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 225, 'n_units_Layer_4': 120}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.74 | sMAPE for Validation Set is: 48.81% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.54 | sMAPE for Test Set is: 54.98% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:36:00,741]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:36:22,771]\u001b[0m Trial 959 finished with value: 56.24525103256385 and parameters: {'n_hidden': 3, 'learning_rate': 0.005924958993789505, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.191859394975154, 'dropout_rate_Layer_2': 0.2732573354087707, 'dropout_rate_Layer_3': 0.34829483798939065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003230474578386655, 'l1_Layer_2': 0.0034028769566240642, 'l1_Layer_3': 8.824293629503505e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.25 | sMAPE for Validation Set is: 51.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.27 | sMAPE for Test Set is: 59.51% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:36:46,542]\u001b[0m Trial 960 finished with value: 53.14193494771155 and parameters: {'n_hidden': 3, 'learning_rate': 0.002441434285732122, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1761231882948253, 'dropout_rate_Layer_2': 0.0525620397746079, 'dropout_rate_Layer_3': 0.03851895060098792, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000378309423465909, 'l1_Layer_2': 2.4128466437869072e-05, 'l1_Layer_3': 0.0001548076560319728, 'n_units_Layer_1': 60, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.14 | sMAPE for Validation Set is: 48.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.20 | sMAPE for Test Set is: 56.19% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:36:51,000]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:36:58,412]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:37:22,011]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:37:27,897]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:37:35,524]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:37:40,872]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:37:45,020]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:37:58,986]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:38:04,436]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:38:17,442]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:38:26,432]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:38:31,908]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:38:43,341]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:39:07,179]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:39:31,982]\u001b[0m Trial 975 finished with value: 55.914701520917696 and parameters: {'n_hidden': 3, 'learning_rate': 0.005963413995717084, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18872288375073265, 'dropout_rate_Layer_2': 0.2505911649562806, 'dropout_rate_Layer_3': 0.27806749996250635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003237665734480296, 'l1_Layer_2': 0.005765641705904857, 'l1_Layer_3': 7.766480075792893e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.91 | sMAPE for Validation Set is: 51.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.96 | sMAPE for Test Set is: 54.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:39:37,120]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:39:41,270]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:39:46,442]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:39:51,693]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:39:56,998]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:40:03,381]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:40:08,814]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:40:32,263]\u001b[0m Trial 983 finished with value: 52.67033272879846 and parameters: {'n_hidden': 3, 'learning_rate': 0.003107020715698266, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1175838802970832, 'dropout_rate_Layer_2': 0.06977216502667624, 'dropout_rate_Layer_3': 0.08638984787147236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036812288585068715, 'l1_Layer_2': 2.007703100001897e-05, 'l1_Layer_3': 0.00015425562446517624, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.67 | sMAPE for Validation Set is: 47.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.00 | sMAPE for Test Set is: 57.39% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:40:46,988]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:41:18,604]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:41:22,715]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:41:33,310]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:41:38,633]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:42:40,244]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:42:44,885]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:42:50,196]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:42:58,433]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:43:03,091]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:43:27,023]\u001b[0m Trial 994 finished with value: 53.629329706683926 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033278766750512033, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21623373387795092, 'dropout_rate_Layer_2': 0.23790587441118682, 'dropout_rate_Layer_3': 0.09968454449348166, 'dropout_rate_Layer_4': 0.072062848481638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014105446426354977, 'l1_Layer_2': 8.815727635516688e-05, 'l1_Layer_3': 0.0028899036399469644, 'l1_Layer_4': 0.001331582129825468, 'n_units_Layer_1': 200, 'n_units_Layer_2': 275, 'n_units_Layer_3': 225, 'n_units_Layer_4': 110}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.63 | sMAPE for Validation Set is: 49.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.81 | sMAPE for Test Set is: 55.94% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:43:34,312]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:43:40,722]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:43:46,303]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:43:51,568]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:43:57,074]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:02,640]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:08,996]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:13,441]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:18,827]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:41,276]\u001b[0m Trial 1004 finished with value: 56.255122383774385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076750195330496105, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14136317364503426, 'dropout_rate_Layer_2': 0.28722980844253315, 'dropout_rate_Layer_3': 0.20011404659897827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002867441558163948, 'l1_Layer_2': 0.005427168768925583, 'l1_Layer_3': 9.286061511575761e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.26 | sMAPE for Validation Set is: 50.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.88 | sMAPE for Test Set is: 57.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:44:49,275]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:54,694]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:44:59,659]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:45:24,754]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:45:31,015]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:45:38,165]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:01,613]\u001b[0m Trial 1011 finished with value: 53.12765865582771 and parameters: {'n_hidden': 3, 'learning_rate': 0.003043289963606811, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12541590762791371, 'dropout_rate_Layer_2': 0.06967205199417681, 'dropout_rate_Layer_3': 0.08454126891949715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003657668315262105, 'l1_Layer_2': 1.526549882432734e-05, 'l1_Layer_3': 0.000153500078100257, 'n_units_Layer_1': 60, 'n_units_Layer_2': 205, 'n_units_Layer_3': 250}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.13 | sMAPE for Validation Set is: 48.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.83 | sMAPE for Test Set is: 56.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:46:07,320]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:21,879]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:29,403]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:34,748]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:40,069]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:47,291]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:46:54,031]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:04,006]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:09,884]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:19,948]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:24,248]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:28,948]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:34,459]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:39,082]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:43,716]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:53,636]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:47:58,760]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:48:05,961]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:48:16,702]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:48:22,183]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:48:26,827]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:48:35,173]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:48:41,134]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:49:28,310]\u001b[0m Trial 1035 finished with value: 53.812027270771154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012316485813664154, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37291060203850424, 'dropout_rate_Layer_2': 0.24219118805553114, 'dropout_rate_Layer_3': 0.2308764320351047, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001556155125929029, 'l1_Layer_2': 3.1649286236610736e-05, 'l1_Layer_3': 0.0007484399754823991, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 110}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.81 | sMAPE for Validation Set is: 49.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.55 | sMAPE for Test Set is: 58.45% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:51:07,350]\u001b[0m Trial 1036 finished with value: 53.28085959266392 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006867371069881246, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3605539505522296, 'dropout_rate_Layer_2': 0.23190608064557783, 'dropout_rate_Layer_3': 0.23787249379830366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019467173576277706, 'l1_Layer_2': 6.327136328217698e-05, 'l1_Layer_3': 0.0003816870432659146, 'n_units_Layer_1': 200, 'n_units_Layer_2': 180, 'n_units_Layer_3': 105}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.28 | sMAPE for Validation Set is: 48.43% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.98 | sMAPE for Test Set is: 56.99% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:51:29,135]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:51:36,854]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:51:46,835]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:51:52,056]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:51:59,348]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:52:07,288]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:52:13,203]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:52:20,801]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:52:26,811]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:53:53,490]\u001b[0m Trial 1046 finished with value: 53.63452276511717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005868251622722668, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3350903497267127, 'dropout_rate_Layer_2': 0.21685158464617366, 'dropout_rate_Layer_3': 0.23549066947899994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022543648394073297, 'l1_Layer_2': 5.614592641166345e-05, 'l1_Layer_3': 0.00029075673857867227, 'n_units_Layer_1': 220, 'n_units_Layer_2': 180, 'n_units_Layer_3': 115}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.63 | sMAPE for Validation Set is: 48.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.01 | sMAPE for Test Set is: 54.66% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:54:15,573]\u001b[0m Trial 1047 finished with value: 53.37482551462647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025904389937886417, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12706191143744094, 'dropout_rate_Layer_2': 0.05647334129390953, 'dropout_rate_Layer_3': 0.09405334017187682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003802262499111406, 'l1_Layer_2': 2.9423236426788462e-05, 'l1_Layer_3': 3.260351868613925e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 215, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.37 | sMAPE for Validation Set is: 48.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.59 | sMAPE for Test Set is: 57.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:54:32,426]\u001b[0m Trial 1048 finished with value: 54.88778924681986 and parameters: {'n_hidden': 3, 'learning_rate': 0.003434832389334518, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10475143608389226, 'dropout_rate_Layer_2': 0.07496869245148072, 'dropout_rate_Layer_3': 0.008440901108001858, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000303757004851778, 'l1_Layer_2': 1.4659165743148826e-05, 'l1_Layer_3': 8.855102832498274e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 185, 'n_units_Layer_3': 260}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.89 | sMAPE for Validation Set is: 49.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.41 | sMAPE for Test Set is: 53.48% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:55:02,871]\u001b[0m Trial 1049 finished with value: 53.30903996030711 and parameters: {'n_hidden': 4, 'learning_rate': 0.005052681610084371, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2610332702935673, 'dropout_rate_Layer_2': 0.2538585825964176, 'dropout_rate_Layer_3': 0.11182782570138551, 'dropout_rate_Layer_4': 0.07893278609195874, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.239399127786452e-05, 'l1_Layer_2': 5.6339708702346995e-05, 'l1_Layer_3': 0.0031226169525544363, 'l1_Layer_4': 0.0010874473337952775, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250, 'n_units_Layer_4': 105}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.31 | sMAPE for Validation Set is: 48.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 29.84 | sMAPE for Test Set is: 60.40% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:55:08,228]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:55:16,447]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:55:21,695]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:55:27,353]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:56:53,776]\u001b[0m Trial 1054 finished with value: 53.601385293919286 and parameters: {'n_hidden': 3, 'learning_rate': 0.000584234091048579, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33754603190755145, 'dropout_rate_Layer_2': 0.19497085925661342, 'dropout_rate_Layer_3': 0.25109771704018136, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020789761036981954, 'l1_Layer_2': 3.973328966445208e-05, 'l1_Layer_3': 0.00029226693792605394, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.60 | sMAPE for Validation Set is: 48.72% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.31 | sMAPE for Test Set is: 54.42% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:56:58,964]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:57:06,647]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:57:13,749]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:57:39,145]\u001b[0m Trial 1058 finished with value: 54.05486333600857 and parameters: {'n_hidden': 4, 'learning_rate': 0.005068019275110003, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23811698710185486, 'dropout_rate_Layer_2': 0.26153244391612107, 'dropout_rate_Layer_3': 0.09770933753096939, 'dropout_rate_Layer_4': 0.10936259798094955, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.168859789702473e-05, 'l1_Layer_2': 9.106299236881809e-05, 'l1_Layer_3': 0.0026254258490767267, 'l1_Layer_4': 0.001824889883150239, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255, 'n_units_Layer_4': 105}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.05 | sMAPE for Validation Set is: 49.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 25.86 | sMAPE for Test Set is: 56.49% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 17:57:43,711]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 17:59:55,115]\u001b[0m Trial 1060 finished with value: 52.92786277793194 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005825883766574348, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3363383794071481, 'dropout_rate_Layer_2': 0.1936923802676754, 'dropout_rate_Layer_3': 0.2533040945323472, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002123669892185595, 'l1_Layer_2': 3.7600893646180804e-05, 'l1_Layer_3': 0.0002651699572055187, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.93 | sMAPE for Validation Set is: 48.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.81 | sMAPE for Test Set is: 56.41% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:00:22,584]\u001b[0m Trial 1061 finished with value: 55.584535453722744 and parameters: {'n_hidden': 3, 'learning_rate': 0.005955520324121094, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07513386857004833, 'dropout_rate_Layer_2': 0.29956066857628816, 'dropout_rate_Layer_3': 0.14222533910146454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001771490609893803, 'l1_Layer_2': 0.0030655111069411867, 'l1_Layer_3': 8.888110234783258e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.58 | sMAPE for Validation Set is: 50.97% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.40 | sMAPE for Test Set is: 56.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:00:39,171]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:00:59,199]\u001b[0m Trial 1063 finished with value: 54.71726711969569 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014184930276838611, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0617332181927294, 'dropout_rate_Layer_2': 0.0580616012558928, 'dropout_rate_Layer_3': 0.03357266864318207, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006889607618607683, 'l1_Layer_2': 2.2761347407208986e-05, 'l1_Layer_3': 0.00021300298529434468, 'n_units_Layer_1': 55, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.72 | sMAPE for Validation Set is: 48.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.85 | sMAPE for Test Set is: 58.13% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:01:05,466]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:01:13,022]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:01:23,293]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:01:28,706]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:01:48,013]\u001b[0m Trial 1068 finished with value: 56.3678993552113 and parameters: {'n_hidden': 3, 'learning_rate': 0.006399662126241251, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11341682821728057, 'dropout_rate_Layer_2': 0.3157846011684752, 'dropout_rate_Layer_3': 0.14901736932215082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018919294216566252, 'l1_Layer_2': 0.003248125866109392, 'l1_Layer_3': 7.933907294504691e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 290}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.37 | sMAPE for Validation Set is: 50.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.29 | sMAPE for Test Set is: 54.40% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:01:52,263]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:01:59,636]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:02:04,020]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:02:23,623]\u001b[0m Trial 1072 finished with value: 56.75618867684898 and parameters: {'n_hidden': 3, 'learning_rate': 0.006163831595060848, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3332663275060483, 'dropout_rate_Layer_2': 0.31290759227627185, 'dropout_rate_Layer_3': 0.1623525407476187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015692715165799173, 'l1_Layer_2': 0.011895794886718304, 'l1_Layer_3': 0.00010872906898041719, 'n_units_Layer_1': 300, 'n_units_Layer_2': 240, 'n_units_Layer_3': 280}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.76 | sMAPE for Validation Set is: 51.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.81 | sMAPE for Test Set is: 56.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:02:36,623]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:02:44,851]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:02:53,160]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:02:57,949]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:12,821]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:20,168]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:26,767]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:34,650]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:39,018]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:45,228]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:49,977]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:03:54,908]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:04:05,289]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:04:10,491]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:04:17,297]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:04:23,479]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:04:28,186]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:04:50,086]\u001b[0m Trial 1090 finished with value: 56.88685806155968 and parameters: {'n_hidden': 3, 'learning_rate': 0.007901204843904585, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17695752948632237, 'dropout_rate_Layer_2': 0.2890343678870682, 'dropout_rate_Layer_3': 0.25342395827081116, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001051527763288567, 'l1_Layer_2': 0.003025977596829853, 'l1_Layer_3': 4.2078160770341416e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.89 | sMAPE for Validation Set is: 50.99% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.52 | sMAPE for Test Set is: 57.69% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:05:21,671]\u001b[0m Trial 1091 finished with value: 53.52724953985997 and parameters: {'n_hidden': 4, 'learning_rate': 0.005128890852999212, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2725520067080293, 'dropout_rate_Layer_2': 0.2617258170719418, 'dropout_rate_Layer_3': 0.10971290861942014, 'dropout_rate_Layer_4': 0.07173321589897534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00014432107739558933, 'l1_Layer_2': 7.497892401750544e-05, 'l1_Layer_3': 0.0014299530347039273, 'l1_Layer_4': 0.0022764878939498167, 'n_units_Layer_1': 210, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255, 'n_units_Layer_4': 95}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.53 | sMAPE for Validation Set is: 48.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.05 | sMAPE for Test Set is: 56.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:05:30,024]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:05:37,595]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:05:42,048]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:05:48,159]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:05:53,594]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:06:33,829]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:06:39,955]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:07:35,282]\u001b[0m Trial 1099 finished with value: 53.59608478382015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007070271975983347, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32958579081342093, 'dropout_rate_Layer_2': 0.24760999322262386, 'dropout_rate_Layer_3': 0.22786189880896413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013972752437142408, 'l1_Layer_2': 7.866244006783763e-05, 'l1_Layer_3': 0.002556066388495965, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.60 | sMAPE for Validation Set is: 48.91% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.70 | sMAPE for Test Set is: 56.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:07:40,626]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:07:45,485]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:07:50,967]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:07:56,571]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:08:19,983]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:08:24,199]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:08:40,524]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:08:48,045]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:09:07,209]\u001b[0m Trial 1108 finished with value: 53.75862808582864 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029430739639948467, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15518008410455586, 'dropout_rate_Layer_2': 0.03913017547569802, 'dropout_rate_Layer_3': 0.0666376979060509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000282021695274809, 'l1_Layer_2': 4.100353112020978e-05, 'l1_Layer_3': 0.00015168678864705619, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 65}. Best is trial 927 with value: 52.58114527638856.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.76 | sMAPE for Validation Set is: 48.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.50 | sMAPE for Test Set is: 56.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:09:13,090]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:08,115]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:12,642]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:18,748]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:23,452]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:37,280]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:42,758]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:47,993]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:52,678]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:10:58,945]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:11:04,323]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:11:10,348]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:11:18,235]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:11:23,595]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:11:28,389]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:11:54,020]\u001b[0m Trial 1124 finished with value: 52.509679682234264 and parameters: {'n_hidden': 3, 'learning_rate': 0.003961563094618022, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11555987348461966, 'dropout_rate_Layer_2': 0.0722557340713798, 'dropout_rate_Layer_3': 0.08255474903221696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002328251146018696, 'l1_Layer_2': 3.1363336271664734e-05, 'l1_Layer_3': 0.0001680815570090554, 'n_units_Layer_1': 65, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.51 | sMAPE for Validation Set is: 47.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.74 | sMAPE for Test Set is: 57.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:11:58,323]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:12:17,512]\u001b[0m Trial 1126 finished with value: 53.964776560564836 and parameters: {'n_hidden': 4, 'learning_rate': 0.004327240236574028, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23734800244215207, 'dropout_rate_Layer_2': 0.28657126441527553, 'dropout_rate_Layer_3': 0.10211140440228378, 'dropout_rate_Layer_4': 0.0794119476631029, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001446163115441062, 'l1_Layer_2': 0.00010674055252144243, 'l1_Layer_3': 0.001903280315001521, 'l1_Layer_4': 0.0015952925563099429, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235, 'n_units_Layer_4': 165}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.96 | sMAPE for Validation Set is: 49.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 29.16 | sMAPE for Test Set is: 59.61% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:12:34,280]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:12:40,381]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:05,692]\u001b[0m Trial 1129 finished with value: 53.72545058491732 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031391566519293605, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23901634241712805, 'dropout_rate_Layer_2': 0.28503414118758963, 'dropout_rate_Layer_3': 0.08984342609230211, 'dropout_rate_Layer_4': 0.1090527030385198, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.177235457575987e-05, 'l1_Layer_2': 9.926116461166958e-05, 'l1_Layer_3': 0.001950861060892974, 'l1_Layer_4': 0.0017174812100798863, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260, 'n_units_Layer_4': 180}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.73 | sMAPE for Validation Set is: 48.64% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.85 | sMAPE for Test Set is: 56.27% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:13:11,197]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:15,891]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:21,118]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:25,759]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:38,588]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:44,921]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:50,528]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:13:58,092]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:14:26,047]\u001b[0m Trial 1138 finished with value: 56.11559676623683 and parameters: {'n_hidden': 3, 'learning_rate': 0.008253004117233488, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05981532463719165, 'dropout_rate_Layer_2': 0.32366588471645635, 'dropout_rate_Layer_3': 0.17409533298908675, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006395445454025304, 'l1_Layer_2': 4.055185301077007e-05, 'l1_Layer_3': 0.0002157461858307094, 'n_units_Layer_1': 285, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.12 | sMAPE for Validation Set is: 50.90% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 24.42 | sMAPE for Test Set is: 55.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:14:31,403]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:14:39,553]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:15:06,131]\u001b[0m Trial 1141 finished with value: 53.462569929773686 and parameters: {'n_hidden': 4, 'learning_rate': 0.00444882190132977, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23832225945748878, 'dropout_rate_Layer_2': 0.26418218551854034, 'dropout_rate_Layer_3': 0.090214576782717, 'dropout_rate_Layer_4': 0.08411352244263151, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010325578829965511, 'l1_Layer_2': 0.00013180340425566825, 'l1_Layer_3': 0.001431733195590947, 'l1_Layer_4': 0.0016446436089540713, 'n_units_Layer_1': 205, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260, 'n_units_Layer_4': 185}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.46 | sMAPE for Validation Set is: 48.79% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.56 | sMAPE for Test Set is: 56.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:15:12,366]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:15:18,655]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:15:45,668]\u001b[0m Trial 1144 finished with value: 55.81913810731535 and parameters: {'n_hidden': 3, 'learning_rate': 0.008651963225496002, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06111971915536851, 'dropout_rate_Layer_2': 0.33026575454019913, 'dropout_rate_Layer_3': 0.15238845924129593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008519403352023659, 'l1_Layer_2': 1.4679599992584581e-05, 'l1_Layer_3': 0.00026836652807097066, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 280}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.82 | sMAPE for Validation Set is: 50.58% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.17 | sMAPE for Test Set is: 54.22% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:15:51,021]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:16:08,752]\u001b[0m Trial 1146 finished with value: 54.25165018131609 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023798567281204564, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11507334643663417, 'dropout_rate_Layer_2': 0.06686429104734853, 'dropout_rate_Layer_3': 0.12787903046194882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033709163461028525, 'l1_Layer_2': 3.159396550615518e-05, 'l1_Layer_3': 9.889522367246005e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 210, 'n_units_Layer_3': 55}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.25 | sMAPE for Validation Set is: 49.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.76 | sMAPE for Test Set is: 57.05% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:16:14,918]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:16:20,750]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:16:26,068]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:16:31,635]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:16:44,264]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:16:52,350]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:02,761]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:12,543]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:17,847]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:23,830]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:32,612]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:39,975]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:44,754]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:49,608]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:54,299]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:17:59,379]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:04,884]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:09,562]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:14,331]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:19,040]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:23,731]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:30,111]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:53,730]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:18:59,135]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:03,880]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:10,413]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:14,851]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:20,544]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:26,976]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:33,077]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:38,342]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:19:43,887]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:01,167]\u001b[0m Trial 1179 finished with value: 53.282973328493334 and parameters: {'n_hidden': 3, 'learning_rate': 0.005021710737473754, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12965373540597366, 'dropout_rate_Layer_2': 0.07757054220957424, 'dropout_rate_Layer_3': 0.10106446920637871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005607096386692162, 'l1_Layer_2': 1.090416281684528e-05, 'l1_Layer_3': 7.685032494276041e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 200, 'n_units_Layer_3': 60}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.28 | sMAPE for Validation Set is: 48.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.34 | sMAPE for Test Set is: 56.28% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:20:05,992]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:16,762]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:22,105]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:27,091]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:34,987]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:40,577]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:45,352]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:20:57,499]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:21:01,977]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:21:07,574]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:21:29,642]\u001b[0m Trial 1190 finished with value: 56.63452918122156 and parameters: {'n_hidden': 3, 'learning_rate': 0.009065816237999442, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026049141482600957, 'dropout_rate_Layer_2': 0.2686608808246228, 'dropout_rate_Layer_3': 0.15507142389663178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.882417627893646e-05, 'l1_Layer_2': 8.592380949132733e-05, 'l1_Layer_3': 4.19190377684286e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.63 | sMAPE for Validation Set is: 50.96% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.21 | sMAPE for Test Set is: 56.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:21:34,832]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:21:39,642]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:21:45,783]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:22:01,823]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:22:07,848]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:22:12,648]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:22:20,055]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:22:28,070]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:23:17,054]\u001b[0m Trial 1199 finished with value: 54.01914303301003 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014654930720848448, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36548094803640535, 'dropout_rate_Layer_2': 0.21747480883491369, 'dropout_rate_Layer_3': 0.2630583235920682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003143574883337637, 'l1_Layer_2': 0.00010764138777563934, 'l1_Layer_3': 0.0019990214979792777, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 105}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.02 | sMAPE for Validation Set is: 49.25% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 57.45% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:23:21,758]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:23:29,801]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:23:35,017]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:23:58,939]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:04,270]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:14,650]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:31,211]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:35,944]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:40,647]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:45,299]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:24:58,534]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:25:04,000]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:25:11,727]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:25:16,922]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:25:22,410]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:25:28,486]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:25:33,312]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:26:02,929]\u001b[0m Trial 1217 finished with value: 55.36511673757553 and parameters: {'n_hidden': 3, 'learning_rate': 0.004377045311741084, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16359856255600932, 'dropout_rate_Layer_2': 0.29623388356268915, 'dropout_rate_Layer_3': 0.04431726709247192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010230716406438295, 'l1_Layer_2': 1.0235058758177244e-05, 'l1_Layer_3': 6.168350438643506e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.37 | sMAPE for Validation Set is: 50.05% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.50 | sMAPE for Test Set is: 53.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:26:08,779]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:26:16,849]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:26:21,443]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:26:28,503]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:26:33,402]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:26:54,792]\u001b[0m Trial 1223 finished with value: 53.57658393406842 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031374022463575768, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22335115425757623, 'dropout_rate_Layer_2': 0.3000225055588454, 'dropout_rate_Layer_3': 0.0898672855392531, 'dropout_rate_Layer_4': 0.06866005839500815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013974129932499977, 'l1_Layer_2': 0.00016835678024796992, 'l1_Layer_3': 0.0023934629694161826, 'l1_Layer_4': 0.001669393691720024, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 235, 'n_units_Layer_4': 120}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.58 | sMAPE for Validation Set is: 48.97% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.07 | sMAPE for Test Set is: 56.67% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:27:05,188]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:27:16,192]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:27:22,003]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:27:29,631]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:27:35,074]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:27:39,884]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:27:44,701]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:28:09,869]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:28:14,573]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:28:45,986]\u001b[0m Trial 1233 finished with value: 52.72356670079201 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037281186259086867, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1603436778926452, 'dropout_rate_Layer_2': 0.051388041014226005, 'dropout_rate_Layer_3': 0.059488089418953435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025773027478868287, 'l1_Layer_2': 5.144335884331658e-05, 'l1_Layer_3': 0.00014559543659736424, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 75}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.72 | sMAPE for Validation Set is: 48.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.09 | sMAPE for Test Set is: 57.85% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:28:59,370]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:29:05,589]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:29:13,841]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:29:19,938]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:29:38,056]\u001b[0m Trial 1238 finished with value: 54.447869760829064 and parameters: {'n_hidden': 3, 'learning_rate': 0.003073170716990663, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22033823804751498, 'dropout_rate_Layer_2': 0.290914964134889, 'dropout_rate_Layer_3': 0.07942832360043561, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.597259299938034e-05, 'l1_Layer_2': 7.070571906397168e-05, 'l1_Layer_3': 0.0024662014577508068, 'n_units_Layer_1': 215, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.45 | sMAPE for Validation Set is: 50.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.08 | sMAPE for Test Set is: 53.80% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:29:42,772]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:29:48,217]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:29:54,227]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:13,124]\u001b[0m Trial 1242 finished with value: 54.459861561639 and parameters: {'n_hidden': 3, 'learning_rate': 0.003136265661578681, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22289677112603465, 'dropout_rate_Layer_2': 0.3038632883184191, 'dropout_rate_Layer_3': 0.06476434907534054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.011129655419728e-05, 'l1_Layer_2': 0.0001676749656687463, 'l1_Layer_3': 0.0008165725662252891, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.46 | sMAPE for Validation Set is: 50.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 57.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:30:21,569]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:26,424]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:34,596]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:39,554]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:44,433]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:54,618]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:30:59,274]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:31:10,470]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:32:20,583]\u001b[0m Trial 1251 finished with value: 53.15809688635934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008368906554066439, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35532994694689823, 'dropout_rate_Layer_2': 0.17865181298345637, 'dropout_rate_Layer_3': 0.23123354986909356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010348115116641719, 'l1_Layer_2': 5.780556981813408e-05, 'l1_Layer_3': 0.0013130067399502918, 'n_units_Layer_1': 220, 'n_units_Layer_2': 185, 'n_units_Layer_3': 95}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.16 | sMAPE for Validation Set is: 48.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.71 | sMAPE for Test Set is: 55.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:32:42,950]\u001b[0m Trial 1252 finished with value: 54.122661385788284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038094064286206754, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21433776662376214, 'dropout_rate_Layer_2': 0.2925290359738898, 'dropout_rate_Layer_3': 0.08946738114521745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010340210002348099, 'l1_Layer_2': 0.00013030889581048383, 'l1_Layer_3': 0.0024112089759752557, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.12 | sMAPE for Validation Set is: 50.23% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.59 | sMAPE for Test Set is: 54.55% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:32:47,587]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:32:52,278]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:32:58,437]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:33:03,296]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:33:08,509]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:33:13,150]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:33:19,260]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:33:23,979]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:33:50,518]\u001b[0m Trial 1261 finished with value: 54.00686822070575 and parameters: {'n_hidden': 3, 'learning_rate': 0.004139102898833206, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22781259120526398, 'dropout_rate_Layer_2': 0.276878377237992, 'dropout_rate_Layer_3': 0.06412138747818899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015081175193036906, 'l1_Layer_2': 0.00013154113943217828, 'l1_Layer_3': 0.0016757873223906413, 'n_units_Layer_1': 200, 'n_units_Layer_2': 260, 'n_units_Layer_3': 300}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.01 | sMAPE for Validation Set is: 50.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.25 | sMAPE for Test Set is: 53.89% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:34:19,957]\u001b[0m Trial 1262 finished with value: 55.28538859021942 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011404115656638567, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23132954819727575, 'dropout_rate_Layer_2': 0.26220102767230624, 'dropout_rate_Layer_3': 0.04441504016808867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008231797909870095, 'l1_Layer_2': 0.00010913254241851378, 'l1_Layer_3': 1.5012278103072038e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 300}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 50.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 57.03% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:34:28,671]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:34:33,461]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:34:44,930]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:34:49,705]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:35:11,854]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:35:21,626]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:35:30,283]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:36:09,300]\u001b[0m Trial 1270 finished with value: 55.30247098872005 and parameters: {'n_hidden': 3, 'learning_rate': 0.002654987701861606, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19720253583188818, 'dropout_rate_Layer_2': 0.25658895960644185, 'dropout_rate_Layer_3': 0.03324098158962899, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001622522648522925, 'l1_Layer_2': 0.00010201088986661718, 'l1_Layer_3': 0.00030094406049527403, 'n_units_Layer_1': 300, 'n_units_Layer_2': 245, 'n_units_Layer_3': 180}. Best is trial 1124 with value: 52.509679682234264.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.30 | sMAPE for Validation Set is: 50.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.34 | sMAPE for Test Set is: 58.50% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:36:15,044]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:36:26,236]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:38:34,955]\u001b[0m Trial 1273 finished with value: 52.01575009890644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006138638419378435, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18258950175231908, 'dropout_rate_Layer_2': 0.010675609610960507, 'dropout_rate_Layer_3': 0.09997835102935158, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.983692452743883e-05, 'l1_Layer_2': 5.5206571435650656e-05, 'l1_Layer_3': 0.0017009964447739442, 'n_units_Layer_1': 230, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.02 | sMAPE for Validation Set is: 47.28% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 23.13 | sMAPE for Test Set is: 55.47% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:38:39,797]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:38:45,486]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:38:55,576]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:39:14,302]\u001b[0m Trial 1277 finished with value: 52.9409775924215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034629153546069124, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14991346640139647, 'dropout_rate_Layer_2': 0.021957817043444856, 'dropout_rate_Layer_3': 0.017547303259178793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003508068719377158, 'l1_Layer_2': 6.280774705514113e-05, 'l1_Layer_3': 0.00013781370623534267, 'n_units_Layer_1': 65, 'n_units_Layer_2': 200, 'n_units_Layer_3': 55}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.94 | sMAPE for Validation Set is: 48.42% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 23.04 | sMAPE for Test Set is: 54.58% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:39:19,698]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:39:42,267]\u001b[0m Trial 1279 finished with value: 53.175831790050175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058220906330016045, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14879977704642558, 'dropout_rate_Layer_2': 0.022396623016786788, 'dropout_rate_Layer_3': 0.005983599655882563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027925291001135036, 'l1_Layer_2': 5.764926801517436e-05, 'l1_Layer_3': 0.0002444431530838264, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.18 | sMAPE for Validation Set is: 49.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.79 | sMAPE for Test Set is: 58.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:39:48,267]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:39:58,329]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:40:06,197]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:40:11,190]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:40:16,867]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:40:21,741]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:40:26,648]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:40:44,377]\u001b[0m Trial 1287 finished with value: 54.762288202695 and parameters: {'n_hidden': 3, 'learning_rate': 0.00325551494572047, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20827797048612415, 'dropout_rate_Layer_2': 0.27875598426777937, 'dropout_rate_Layer_3': 0.10330922234937928, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014186041919667442, 'l1_Layer_2': 0.00013136479818624567, 'l1_Layer_3': 0.001415967782277373, 'n_units_Layer_1': 210, 'n_units_Layer_2': 220, 'n_units_Layer_3': 270}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.76 | sMAPE for Validation Set is: 50.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.00 | sMAPE for Test Set is: 52.83% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:40:49,184]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:41:21,142]\u001b[0m Trial 1289 finished with value: 55.17662529400662 and parameters: {'n_hidden': 3, 'learning_rate': 0.003929839517811661, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.166070352288944, 'dropout_rate_Layer_2': 0.19712071135337, 'dropout_rate_Layer_3': 0.030157755558532118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016095030343724456, 'l1_Layer_2': 0.00010446032601611384, 'l1_Layer_3': 1.0226824409563102e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.18 | sMAPE for Validation Set is: 50.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.83 | sMAPE for Test Set is: 57.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:41:25,806]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:41:31,669]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:41:44,982]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:41:49,680]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:41:54,997]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:41:59,821]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:42:18,587]\u001b[0m Trial 1296 finished with value: 55.208450237006446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035628703212437197, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15903170318261878, 'dropout_rate_Layer_2': 0.035246878291901554, 'dropout_rate_Layer_3': 0.08842210364383278, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00031408341367217024, 'l1_Layer_2': 4.702587285937012e-05, 'l1_Layer_3': 6.198228339414468e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.21 | sMAPE for Validation Set is: 50.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 21.52 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:42:24,237]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:42:47,104]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:42:59,423]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:43:04,138]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:43:10,611]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:43:20,753]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:43:25,452]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:43:53,858]\u001b[0m Trial 1304 finished with value: 55.28562986489265 and parameters: {'n_hidden': 3, 'learning_rate': 0.001213084304730789, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18935323633663292, 'dropout_rate_Layer_2': 0.07579907240409933, 'dropout_rate_Layer_3': 0.03802901479651766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008076579493844819, 'l1_Layer_2': 0.00012171489769411115, 'l1_Layer_3': 2.908971187684648e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.29 | sMAPE for Validation Set is: 50.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.93 | sMAPE for Test Set is: 55.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:43:59,343]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:44:05,377]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:44:11,292]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:44:54,536]\u001b[0m Trial 1308 finished with value: 52.294410116168045 and parameters: {'n_hidden': 3, 'learning_rate': 0.003314083206276412, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12354000776419584, 'dropout_rate_Layer_2': 0.007053875948478979, 'dropout_rate_Layer_3': 0.016945460112445108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043392569102096846, 'l1_Layer_2': 0.00010012515241159248, 'l1_Layer_3': 0.00019558989637946534, 'n_units_Layer_1': 95, 'n_units_Layer_2': 165, 'n_units_Layer_3': 65}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.29 | sMAPE for Validation Set is: 47.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 23.64 | sMAPE for Test Set is: 58.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:45:00,512]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:05,305]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:11,761]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:18,023]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:22,979]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:27,812]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:33,162]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:39,727]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:46,308]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:51,164]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:45:55,674]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:01,940]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:06,809]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:11,608]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:22,455]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:27,412]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:35,254]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:46:58,888]\u001b[0m Trial 1326 finished with value: 55.23668288065409 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015273475418583447, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18631700328229656, 'dropout_rate_Layer_2': 0.08664868755387456, 'dropout_rate_Layer_3': 0.054420167879327935, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008791394495766274, 'l1_Layer_2': 2.0685078411151025e-05, 'l1_Layer_3': 2.363921990239745e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.24 | sMAPE for Validation Set is: 50.25% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.20 | sMAPE for Test Set is: 56.61% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:47:06,442]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:47:11,404]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:47:55,960]\u001b[0m Trial 1329 finished with value: 53.613459998167826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010461415381004988, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23534459914982114, 'dropout_rate_Layer_2': 0.05812429270936677, 'dropout_rate_Layer_3': 0.22430008210024455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017705681919971992, 'l1_Layer_2': 9.514457547488866e-05, 'l1_Layer_3': 0.0014925423174834784, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 90}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.61 | sMAPE for Validation Set is: 49.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 57.00% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:48:01,860]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:48:21,858]\u001b[0m Trial 1331 finished with value: 53.87657220399246 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034857185496668997, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2371901443253275, 'dropout_rate_Layer_2': 0.29905880509324406, 'dropout_rate_Layer_3': 0.10155549879344501, 'dropout_rate_Layer_4': 0.09989221677501631, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018231811094805193, 'l1_Layer_2': 0.00015689830677796576, 'l1_Layer_3': 0.001881362302117571, 'l1_Layer_4': 0.003363658650875509, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 290, 'n_units_Layer_4': 155}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.88 | sMAPE for Validation Set is: 48.97% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.13 | sMAPE for Test Set is: 57.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:48:27,285]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:48:32,078]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:48:36,862]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:48:46,099]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:49:22,793]\u001b[0m Trial 1336 finished with value: 52.702458305852815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027654347185987614, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1469770892880278, 'dropout_rate_Layer_2': 0.01098185463075585, 'dropout_rate_Layer_3': 0.008327397076982128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006859131752331642, 'l1_Layer_2': 8.810483401400316e-05, 'l1_Layer_3': 4.396878483546695e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.70 | sMAPE for Validation Set is: 48.19% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.82 | sMAPE for Test Set is: 59.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:49:29,098]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:50:03,054]\u001b[0m Trial 1338 finished with value: 55.06053272719556 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011293533080689495, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01929041515219576, 'dropout_rate_Layer_2': 0.06209868545062637, 'dropout_rate_Layer_3': 0.12302981473161266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008133766369111231, 'l1_Layer_2': 1.229620439615585e-05, 'l1_Layer_3': 1.0232696126993322e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.06 | sMAPE for Validation Set is: 49.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.13 | sMAPE for Test Set is: 58.52% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:51:09,333]\u001b[0m Trial 1339 finished with value: 53.450284397196945 and parameters: {'n_hidden': 3, 'learning_rate': 0.002697234260830983, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14590080396078398, 'dropout_rate_Layer_2': 0.010258507555125371, 'dropout_rate_Layer_3': 0.025233089510924345, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006522369170934463, 'l1_Layer_2': 0.00010149471585505384, 'l1_Layer_3': 4.0935576601148094e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 170, 'n_units_Layer_3': 60}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.45 | sMAPE for Validation Set is: 48.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.31 | sMAPE for Test Set is: 54.98% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:51:51,031]\u001b[0m Trial 1340 finished with value: 52.888927048155324 and parameters: {'n_hidden': 3, 'learning_rate': 0.003624351486318773, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13668194820398186, 'dropout_rate_Layer_2': 0.02068238262800279, 'dropout_rate_Layer_3': 0.039364461502598445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024580246575208175, 'l1_Layer_2': 5.2130194313074695e-05, 'l1_Layer_3': 7.297839073129738e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.89 | sMAPE for Validation Set is: 47.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.18 | sMAPE for Test Set is: 57.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:52:36,653]\u001b[0m Trial 1341 finished with value: 53.401724152740655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009514464062376655, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3805385279617901, 'dropout_rate_Layer_2': 0.01986721570207194, 'dropout_rate_Layer_3': 0.031298206807821874, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016297628281295286, 'l1_Layer_2': 0.0001183828969273649, 'l1_Layer_3': 0.00017172225673329182, 'n_units_Layer_1': 255, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.40 | sMAPE for Validation Set is: 49.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.85 | sMAPE for Test Set is: 58.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:52:43,183]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:52:48,451]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:52:54,093]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:53:32,734]\u001b[0m Trial 1345 finished with value: 55.308057393801846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011476579305762019, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013521174319419904, 'dropout_rate_Layer_2': 0.06381282900826032, 'dropout_rate_Layer_3': 0.11637999579206401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007887372747000612, 'l1_Layer_2': 1.0420747492916636e-05, 'l1_Layer_3': 1.1858260967557333e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.31 | sMAPE for Validation Set is: 50.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.99 | sMAPE for Test Set is: 56.65% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:53:38,756]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:54:03,152]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:54:08,167]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:54:13,904]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:54:54,610]\u001b[0m Trial 1350 finished with value: 52.84819104698588 and parameters: {'n_hidden': 3, 'learning_rate': 0.004008013401497174, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13460094733776928, 'dropout_rate_Layer_2': 0.0373458207934073, 'dropout_rate_Layer_3': 0.042504122106694735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002491176119214919, 'l1_Layer_2': 5.227354044243675e-05, 'l1_Layer_3': 7.314601152671764e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 80}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.85 | sMAPE for Validation Set is: 47.92% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.11 | sMAPE for Test Set is: 57.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:55:37,719]\u001b[0m Trial 1351 finished with value: 53.30417283498298 and parameters: {'n_hidden': 3, 'learning_rate': 0.001182204899120487, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3832587807499798, 'dropout_rate_Layer_2': 0.010670554855807647, 'dropout_rate_Layer_3': 0.0924736570373434, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001968301157558747, 'l1_Layer_2': 0.00010366180870426653, 'l1_Layer_3': 1.4061015863671716e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 210}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.30 | sMAPE for Validation Set is: 49.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 25.13 | sMAPE for Test Set is: 59.97% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:55:45,683]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:56:43,529]\u001b[0m Trial 1353 finished with value: 52.95370792476742 and parameters: {'n_hidden': 3, 'learning_rate': 0.004411263559162192, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13796877536104768, 'dropout_rate_Layer_2': 0.011826368790844678, 'dropout_rate_Layer_3': 0.010189441201189304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023162051989764835, 'l1_Layer_2': 5.302363777675008e-05, 'l1_Layer_3': 7.56978189344148e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 80}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.95 | sMAPE for Validation Set is: 48.10% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 24.68 | sMAPE for Test Set is: 56.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:57:07,854]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:57:12,837]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:10,522]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:14,985]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:21,401]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:38,399]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:43,877]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:49,152]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:54,079]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:58:59,311]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:59:27,791]\u001b[0m Trial 1364 finished with value: 53.58364045053012 and parameters: {'n_hidden': 4, 'learning_rate': 0.00303239252143086, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25311312829566257, 'dropout_rate_Layer_2': 0.313135141996528, 'dropout_rate_Layer_3': 0.08213277433179789, 'dropout_rate_Layer_4': 0.0671184484146625, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0001434466289576008, 'l1_Layer_2': 8.780945234477471e-05, 'l1_Layer_3': 0.0015945678539964075, 'l1_Layer_4': 0.00193409154213694, 'n_units_Layer_1': 205, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240, 'n_units_Layer_4': 180}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.58 | sMAPE for Validation Set is: 48.56% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.18 | sMAPE for Test Set is: 57.40% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 18:59:32,690]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 18:59:37,635]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:00:36,220]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:00:59,156]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:01:04,186]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:01:09,472]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:01:35,425]\u001b[0m Trial 1371 finished with value: 55.45292187673835 and parameters: {'n_hidden': 3, 'learning_rate': 0.002210435068327455, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02057852375371791, 'dropout_rate_Layer_2': 0.08597924159576197, 'dropout_rate_Layer_3': 0.08016998638205192, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006092428594269497, 'l1_Layer_2': 0.0001630141472072098, 'l1_Layer_3': 3.14892906166929e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.45 | sMAPE for Validation Set is: 50.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 54.06% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:01:43,680]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:01:48,751]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:01:59,646]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:02:57,896]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:03:03,468]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:03:08,910]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:04:01,162]\u001b[0m Trial 1378 finished with value: 54.64766474043815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021753651633028997, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006819166313778435, 'dropout_rate_Layer_2': 0.08760392558473981, 'dropout_rate_Layer_3': 0.13922676382614088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006151053815573647, 'l1_Layer_2': 0.00020727564001122106, 'l1_Layer_3': 1.558386580221842e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.65 | sMAPE for Validation Set is: 48.94% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 55.10% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:04:06,151]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:04:47,135]\u001b[0m Trial 1380 finished with value: 54.638093745005314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017937902386526323, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013653539287778235, 'dropout_rate_Layer_2': 0.07428644804518969, 'dropout_rate_Layer_3': 0.14333709858479637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006995424286599915, 'l1_Layer_2': 0.0001260424070480521, 'l1_Layer_3': 2.302471122611441e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.64 | sMAPE for Validation Set is: 49.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 24.01 | sMAPE for Test Set is: 55.36% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:04:52,174]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:05:28,683]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:05:37,483]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:05:42,612]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:06:09,683]\u001b[0m Trial 1385 finished with value: 53.67919144848788 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029602003854326342, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21782328914496163, 'dropout_rate_Layer_2': 0.312873523090559, 'dropout_rate_Layer_3': 0.08464202127637457, 'dropout_rate_Layer_4': 0.11632737887866204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010599579153151612, 'l1_Layer_2': 7.169339517061627e-05, 'l1_Layer_3': 0.0016749933126542192, 'l1_Layer_4': 0.0020023740379943615, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240, 'n_units_Layer_4': 200}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.68 | sMAPE for Validation Set is: 48.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.41 | sMAPE for Test Set is: 54.64% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:06:14,677]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:06:20,485]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:06:26,834]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:06:38,651]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:08:05,400]\u001b[0m Trial 1390 finished with value: 53.729289414960355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010402558915811914, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39239364522256487, 'dropout_rate_Layer_2': 0.03617686351831631, 'dropout_rate_Layer_3': 0.08405050518506373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.372150565779342e-05, 'l1_Layer_2': 6.904282065152119e-05, 'l1_Layer_3': 0.0006209165133558714, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.73 | sMAPE for Validation Set is: 48.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 56.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:08:49,609]\u001b[0m Trial 1391 finished with value: 54.652970047855625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016554955122553147, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02653532891246152, 'dropout_rate_Layer_2': 0.07735674596073402, 'dropout_rate_Layer_3': 0.12784587013731247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00972991591632946, 'l1_Layer_2': 0.00016458093614795934, 'l1_Layer_3': 1.5623879498640243e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.65 | sMAPE for Validation Set is: 49.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 24.72 | sMAPE for Test Set is: 56.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:08:55,992]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:03,916]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:08,328]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:18,283]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:28,738]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:38,058]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:43,578]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:09:48,977]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:10:05,286]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:10:13,513]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:10:30,190]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:12:00,915]\u001b[0m Trial 1403 finished with value: 53.07637494292436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012621324530908771, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3998821165459229, 'dropout_rate_Layer_2': 0.05111684517436618, 'dropout_rate_Layer_3': 0.04317099112367065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010649471020577818, 'l1_Layer_2': 0.0012571422068255757, 'l1_Layer_3': 0.00023553364791669912, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 95}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.08 | sMAPE for Validation Set is: 48.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.22 | sMAPE for Test Set is: 54.94% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:12:09,789]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:12:17,678]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:12:31,420]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:12:52,412]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:13:42,746]\u001b[0m Trial 1408 finished with value: 53.39840038340213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015401536682451203, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39700482141976945, 'dropout_rate_Layer_2': 0.00022056373037219676, 'dropout_rate_Layer_3': 0.04019274528928454, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010091962997203308, 'l1_Layer_2': 0.00010723059571651789, 'l1_Layer_3': 0.0002451597084797477, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.40 | sMAPE for Validation Set is: 48.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.51 | sMAPE for Test Set is: 56.01% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:13:56,675]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:04,936]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:13,242]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:18,022]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:28,990]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:35,767]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:40,635]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:52,033]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:14:58,046]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:15:48,426]\u001b[0m Trial 1418 finished with value: 53.14093065034979 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014551963911926954, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3983043995188704, 'dropout_rate_Layer_2': 0.011629025316518056, 'dropout_rate_Layer_3': 0.041416696074204014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.683359809639531e-05, 'l1_Layer_2': 1.8150872258538897e-05, 'l1_Layer_3': 0.00033986416414321453, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 220}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.14 | sMAPE for Validation Set is: 47.94% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.67 | sMAPE for Test Set is: 56.92% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:16:11,141]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:16:19,217]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:16:35,127]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:16:40,174]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:17:33,948]\u001b[0m Trial 1423 finished with value: 53.20580438088314 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015376437894406123, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39354459447169665, 'dropout_rate_Layer_2': 0.009503697845027413, 'dropout_rate_Layer_3': 0.038759769967696533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.664316674347e-05, 'l1_Layer_2': 0.0011644212372420722, 'l1_Layer_3': 0.0002547906581464107, 'n_units_Layer_1': 245, 'n_units_Layer_2': 210, 'n_units_Layer_3': 225}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.21 | sMAPE for Validation Set is: 48.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.19 | sMAPE for Test Set is: 57.77% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:17:40,296]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:17:45,638]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:18:36,937]\u001b[0m Trial 1426 finished with value: 53.23775836752626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015654170573633404, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39236880394008594, 'dropout_rate_Layer_2': 0.010244450241748809, 'dropout_rate_Layer_3': 0.03270779524826406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.51417666537732e-05, 'l1_Layer_2': 1.242240200259941e-05, 'l1_Layer_3': 0.00026795720370959876, 'n_units_Layer_1': 250, 'n_units_Layer_2': 210, 'n_units_Layer_3': 220}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.24 | sMAPE for Validation Set is: 48.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.08 | sMAPE for Test Set is: 58.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:18:42,884]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:19:11,396]\u001b[0m Trial 1428 finished with value: 55.73455638518269 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017016017414382915, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018496384230148405, 'dropout_rate_Layer_2': 0.11383238535309761, 'dropout_rate_Layer_3': 0.11219979064063973, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001216495432518099, 'l1_Layer_2': 0.00010410109448332977, 'l1_Layer_3': 1.0038188573950659e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 275}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.73 | sMAPE for Validation Set is: 50.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.20 | sMAPE for Test Set is: 56.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:19:17,059]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:19:57,498]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:20:24,274]\u001b[0m Trial 1431 finished with value: 55.62028601063864 and parameters: {'n_hidden': 3, 'learning_rate': 0.001810891729886774, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017386634036761717, 'dropout_rate_Layer_2': 0.08799594629844962, 'dropout_rate_Layer_3': 0.12270311844949995, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012332771329739314, 'l1_Layer_2': 6.532185679432685e-05, 'l1_Layer_3': 1.1591291219371151e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.62 | sMAPE for Validation Set is: 49.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.52 | sMAPE for Test Set is: 54.79% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:20:29,644]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:20:34,813]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:20:51,946]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:21:02,698]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:21:27,669]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:21:56,122]\u001b[0m Trial 1437 finished with value: 55.76361974359059 and parameters: {'n_hidden': 3, 'learning_rate': 0.00186374826975732, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022272588235684055, 'dropout_rate_Layer_2': 0.10931493101834343, 'dropout_rate_Layer_3': 0.08163265280825648, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001179509191566262, 'l1_Layer_2': 0.0001221469681275874, 'l1_Layer_3': 1.17060921206315e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 275, 'n_units_Layer_3': 270}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.76 | sMAPE for Validation Set is: 50.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.02 | sMAPE for Test Set is: 53.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:22:19,000]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:22:43,448]\u001b[0m Trial 1439 finished with value: 54.16321199567264 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037671793860800883, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25855142951645993, 'dropout_rate_Layer_2': 0.27373968327326, 'dropout_rate_Layer_3': 0.10088874292796127, 'dropout_rate_Layer_4': 0.12226957719754585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00013432828224215154, 'l1_Layer_2': 5.9568564742768794e-05, 'l1_Layer_3': 0.0017033114867174598, 'l1_Layer_4': 0.0013840051658809587, 'n_units_Layer_1': 205, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255, 'n_units_Layer_4': 130}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.16 | sMAPE for Validation Set is: 48.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 24.58 | sMAPE for Test Set is: 55.49% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:22:48,529]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:22:59,558]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:23:04,350]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:06,884]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:15,433]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:20,747]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:35,238]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:44,313]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:49,346]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:24:56,249]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:25:05,401]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:25:31,338]\u001b[0m Trial 1451 finished with value: 55.49999738446636 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019220460400326542, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008637456021595939, 'dropout_rate_Layer_2': 0.10093278576407991, 'dropout_rate_Layer_3': 0.12606153713053397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011283265029790162, 'l1_Layer_2': 4.9243908178641044e-05, 'l1_Layer_3': 1.2060326492141858e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.50 | sMAPE for Validation Set is: 50.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.20 | sMAPE for Test Set is: 61.52% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:25:37,479]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:26:03,831]\u001b[0m Trial 1453 finished with value: 55.07703823624599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018839325633155373, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006284898919118989, 'dropout_rate_Layer_2': 0.10305693702962326, 'dropout_rate_Layer_3': 0.1263771887816864, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.217290658676845e-05, 'l1_Layer_2': 5.091169181246979e-05, 'l1_Layer_3': 1.2660160167776608e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.08 | sMAPE for Validation Set is: 49.90% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 25.89 | sMAPE for Test Set is: 57.36% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:27:05,822]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:27:22,547]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:27:29,014]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:27:33,928]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:27:42,570]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:28:08,404]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:28:17,132]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:28:25,123]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:28:30,029]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:28:38,396]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:29:13,276]\u001b[0m Trial 1464 finished with value: 54.42929301275291 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020390146425741675, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0018266927239068281, 'dropout_rate_Layer_2': 0.10425195987510781, 'dropout_rate_Layer_3': 0.12739905847844235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.725328211838536e-05, 'l1_Layer_2': 6.316896998627906e-05, 'l1_Layer_3': 1.5928253142481458e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.43 | sMAPE for Validation Set is: 50.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.05 | sMAPE for Test Set is: 56.42% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:29:19,135]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:29:25,449]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:29:49,961]\u001b[0m Trial 1467 finished with value: 53.857566085060995 and parameters: {'n_hidden': 4, 'learning_rate': 0.002529751378742861, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2769533362255083, 'dropout_rate_Layer_2': 0.2937050129112788, 'dropout_rate_Layer_3': 0.07604208399483611, 'dropout_rate_Layer_4': 0.12494562763332324, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00010357058456795298, 'l1_Layer_2': 9.696990179851301e-05, 'l1_Layer_3': 0.0012955937843230315, 'l1_Layer_4': 0.001391386269814919, 'n_units_Layer_1': 205, 'n_units_Layer_2': 245, 'n_units_Layer_3': 265, 'n_units_Layer_4': 130}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.86 | sMAPE for Validation Set is: 48.85% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.24 | sMAPE for Test Set is: 58.10% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:29:55,023]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:29:59,614]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:30:06,236]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:30:36,945]\u001b[0m Trial 1471 finished with value: 53.857032842043246 and parameters: {'n_hidden': 3, 'learning_rate': 0.004108830205346925, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1198714034487559, 'dropout_rate_Layer_2': 0.05999565793622573, 'dropout_rate_Layer_3': 0.05768328014189976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028839006056059107, 'l1_Layer_2': 9.057749667561835e-05, 'l1_Layer_3': 4.9495328340653826e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 55}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.86 | sMAPE for Validation Set is: 48.88% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 24.29 | sMAPE for Test Set is: 57.02% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:30:41,706]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:31:08,032]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:31:14,290]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:31:59,473]\u001b[0m Trial 1475 finished with value: 54.22872069140039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020031505616660886, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009236173631402445, 'dropout_rate_Layer_2': 0.1228215781306822, 'dropout_rate_Layer_3': 0.12988360238042004, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.997480847340471e-05, 'l1_Layer_2': 6.263650312950894e-05, 'l1_Layer_3': 2.4328864351877505e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.23 | sMAPE for Validation Set is: 50.99% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.04 | sMAPE for Test Set is: 53.52% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:32:28,145]\u001b[0m Trial 1476 finished with value: 53.10859520313335 and parameters: {'n_hidden': 3, 'learning_rate': 0.003742640567788535, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12901238644351706, 'dropout_rate_Layer_2': 0.03105914223097379, 'dropout_rate_Layer_3': 0.07277880505683075, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006904337927390522, 'l1_Layer_2': 6.692795050651673e-05, 'l1_Layer_3': 9.967039062130828e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.11 | sMAPE for Validation Set is: 48.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.53 | sMAPE for Test Set is: 55.07% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:32:33,821]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:32:39,958]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:32:45,668]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:32:52,257]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:32:57,784]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:33:04,384]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:33:09,482]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:34:40,622]\u001b[0m Trial 1484 finished with value: 52.55487944017769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013814177909208631, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.315758738960146, 'dropout_rate_Layer_2': 0.000422394215099528, 'dropout_rate_Layer_3': 0.03043241889047197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.674843133688607e-05, 'l1_Layer_2': 0.0017284441985096338, 'l1_Layer_3': 4.155758899635517e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.55 | sMAPE for Validation Set is: 47.54% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 22.99 | sMAPE for Test Set is: 55.27% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:34:45,693]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:34:50,774]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:34:57,037]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:35:32,958]\u001b[0m Trial 1488 finished with value: 54.67720260421101 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015441021598923614, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02589064710659838, 'dropout_rate_Layer_2': 0.08565224660538846, 'dropout_rate_Layer_3': 0.13139175748745238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011541198952416725, 'l1_Layer_2': 5.3505462296711996e-05, 'l1_Layer_3': 1.8361135530405908e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.68 | sMAPE for Validation Set is: 50.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.01 | sMAPE for Test Set is: 54.79% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:35:58,180]\u001b[0m Trial 1489 finished with value: 54.93272876367081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015604736051395506, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.032029437950455486, 'dropout_rate_Layer_2': 0.0844210823537052, 'dropout_rate_Layer_3': 0.13178998844144382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.573149897324433e-05, 'l1_Layer_2': 4.7195033621631166e-05, 'l1_Layer_3': 1.7991214050771575e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.93 | sMAPE for Validation Set is: 50.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.21 | sMAPE for Test Set is: 55.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:36:33,282]\u001b[0m Trial 1490 finished with value: 54.545588676068576 and parameters: {'n_hidden': 3, 'learning_rate': 0.001478471795422523, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03232433660969854, 'dropout_rate_Layer_2': 0.08472158889178198, 'dropout_rate_Layer_3': 0.13296607642204322, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.656291862641504e-05, 'l1_Layer_2': 3.65301052400183e-05, 'l1_Layer_3': 1.899143286621362e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.55 | sMAPE for Validation Set is: 51.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.58 | sMAPE for Test Set is: 54.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:36:38,377]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:36:49,744]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:37:20,230]\u001b[0m Trial 1493 finished with value: 54.63285056189591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015593695749743187, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03151667088948997, 'dropout_rate_Layer_2': 0.07148420930562853, 'dropout_rate_Layer_3': 0.13134493507052838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.78935499201603e-05, 'l1_Layer_2': 3.160832677418911e-05, 'l1_Layer_3': 2.0104495805898097e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.63 | sMAPE for Validation Set is: 50.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.27 | sMAPE for Test Set is: 53.89% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:38:04,252]\u001b[0m Trial 1494 finished with value: 54.462794816207 and parameters: {'n_hidden': 3, 'learning_rate': 0.00156821479387297, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02735692736531195, 'dropout_rate_Layer_2': 0.07106771192841313, 'dropout_rate_Layer_3': 0.13435273514406407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.112070004338189e-05, 'l1_Layer_2': 3.401706348895732e-05, 'l1_Layer_3': 1.994885626277799e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.46 | sMAPE for Validation Set is: 50.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.91 | sMAPE for Test Set is: 54.16% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:38:11,066]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:38:38,060]\u001b[0m Trial 1496 finished with value: 54.95011116107125 and parameters: {'n_hidden': 3, 'learning_rate': 0.001504999654965179, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0314097371858139, 'dropout_rate_Layer_2': 0.06697112074069672, 'dropout_rate_Layer_3': 0.12998766800248063, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.978227482727342e-05, 'l1_Layer_2': 3.969221270666849e-05, 'l1_Layer_3': 2.1589419948807506e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 270}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.95 | sMAPE for Validation Set is: 50.89% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 22.17 | sMAPE for Test Set is: 54.37% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 54.59 | sMAPE for Validation Set is: 50.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.25 | sMAPE for Test Set is: 53.25% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:39:12,365]\u001b[0m Trial 1497 finished with value: 54.59263638606465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015569188405357777, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0350439986803999, 'dropout_rate_Layer_2': 0.06640159650598285, 'dropout_rate_Layer_3': 0.13499066796792536, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.565490597219253e-05, 'l1_Layer_2': 3.1034246535352735e-05, 'l1_Layer_3': 2.3153124250247315e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 280, 'n_units_Layer_3': 265}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n",
      "\u001b[32m[I 2023-07-28 19:39:31,786]\u001b[0m Trial 1498 finished with value: 54.040092896068785 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033694871159707118, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21519612445324202, 'dropout_rate_Layer_2': 0.25906508191323324, 'dropout_rate_Layer_3': 0.06996607606064464, 'dropout_rate_Layer_4': 0.1288951332824927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.075085175932756e-05, 'l1_Layer_2': 0.00016637599014685176, 'l1_Layer_3': 0.0007838152397781371, 'l1_Layer_4': 0.0015523386215152333, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230, 'n_units_Layer_4': 80}. Best is trial 1273 with value: 52.01575009890644.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.04 | sMAPE for Validation Set is: 49.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 25.83 | sMAPE for Test Set is: 56.19% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-28 19:39:37,705]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:37.42 & sMAPE is:127.09% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :37.42 & 127.09% & 0.53\n",
      "for 2023-01-02, MAE is:37.10 & sMAPE is:56.34% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :37.26 & 91.72% & 0.48\n",
      "for 2023-01-03, MAE is:14.56 & sMAPE is:10.37% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :29.69 & 64.60% & 0.43\n",
      "for 2023-01-04, MAE is:20.96 & sMAPE is:21.74% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.51 & 53.89% & 0.47\n",
      "for 2023-01-05, MAE is:28.27 & sMAPE is:26.32% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :27.66 & 48.37% & 0.45\n",
      "for 2023-01-06, MAE is:33.72 & sMAPE is:27.82% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.67 & 44.95% & 0.43\n",
      "for 2023-01-07, MAE is:28.89 & sMAPE is:35.78% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :28.70 & 43.64% & 0.43\n",
      "for 2023-01-08, MAE is:21.59 & sMAPE is:49.54% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :27.81 & 44.38% & 0.51\n",
      "for 2023-01-09, MAE is:49.43 & sMAPE is:61.46% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :30.22 & 46.27% & 0.57\n",
      "for 2023-01-10, MAE is:25.82 & sMAPE is:27.04% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :29.78 & 44.35% & 0.62\n",
      "for 2023-01-11, MAE is:34.63 & sMAPE is:45.68% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :30.22 & 44.47% & 0.64\n",
      "for 2023-01-12, MAE is:21.74 & sMAPE is:46.40% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :29.51 & 44.63% & 0.62\n",
      "for 2023-01-13, MAE is:17.86 & sMAPE is:22.07% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :28.61 & 42.90% & 0.60\n",
      "for 2023-01-14, MAE is:16.02 & sMAPE is:29.22% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :27.72 & 41.92% & 0.62\n",
      "for 2023-01-15, MAE is:30.12 & sMAPE is:91.85% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :27.88 & 45.25% & 0.66\n",
      "for 2023-01-16, MAE is:34.71 & sMAPE is:70.38% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :28.30 & 46.82% & 0.77\n",
      "for 2023-01-17, MAE is:40.61 & sMAPE is:60.28% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :29.03 & 47.61% & 0.77\n",
      "for 2023-01-18, MAE is:19.33 & sMAPE is:35.99% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :28.49 & 46.97% & 0.77\n",
      "for 2023-01-19, MAE is:31.55 & sMAPE is:31.72% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :28.65 & 46.16% & 0.75\n",
      "for 2023-01-20, MAE is:19.05 & sMAPE is:17.69% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 44.74% & 0.73\n",
      "for 2023-01-21, MAE is:39.57 & sMAPE is:37.86% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :28.71 & 44.41% & 0.73\n",
      "for 2023-01-22, MAE is:29.16 & sMAPE is:39.19% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :28.73 & 44.17% & 0.73\n",
      "for 2023-01-23, MAE is:39.96 & sMAPE is:55.03% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :29.22 & 44.65% & 0.82\n",
      "for 2023-01-24, MAE is:70.59 & sMAPE is:70.03% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :30.94 & 45.70% & 0.83\n",
      "for 2023-01-25, MAE is:42.39 & sMAPE is:108.74% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :31.40 & 48.23% & 0.83\n",
      "for 2023-01-26, MAE is:32.69 & sMAPE is:50.49% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :31.45 & 48.31% & 0.83\n",
      "for 2023-01-27, MAE is:47.87 & sMAPE is:53.34% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :32.06 & 48.50% & 0.86\n",
      "for 2023-01-28, MAE is:33.45 & sMAPE is:78.01% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :32.11 & 49.55% & 0.85\n",
      "for 2023-01-29, MAE is:35.63 & sMAPE is:77.10% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :32.23 & 50.50% & 0.85\n",
      "for 2023-01-30, MAE is:35.42 & sMAPE is:61.98% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :32.34 & 50.89% & 0.85\n",
      "for 2023-01-31, MAE is:53.68 & sMAPE is:61.08% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 51.21% & 0.86\n",
      "for 2023-02-01, MAE is:31.97 & sMAPE is:35.19% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :32.99 & 50.71% & 0.84\n",
      "for 2023-02-02, MAE is:37.26 & sMAPE is:32.38% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :33.12 & 50.16% & 0.85\n",
      "for 2023-02-03, MAE is:43.62 & sMAPE is:37.26% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :33.43 & 49.78% & 0.87\n",
      "for 2023-02-04, MAE is:41.96 & sMAPE is:40.94% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :33.67 & 49.53% & 0.86\n",
      "for 2023-02-05, MAE is:28.09 & sMAPE is:34.07% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :33.52 & 49.10% & 0.85\n",
      "for 2023-02-06, MAE is:64.75 & sMAPE is:67.12% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :34.36 & 49.58% & 0.85\n",
      "for 2023-02-07, MAE is:20.86 & sMAPE is:27.51% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :34.01 & 49.00% & 0.85\n",
      "for 2023-02-08, MAE is:56.23 & sMAPE is:73.25% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :34.58 & 49.63% & 0.85\n",
      "for 2023-02-09, MAE is:39.99 & sMAPE is:78.81% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :34.71 & 50.35% & 0.84\n",
      "for 2023-02-10, MAE is:30.61 & sMAPE is:64.74% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :34.61 & 50.71% & 0.83\n",
      "for 2023-02-11, MAE is:23.13 & sMAPE is:57.54% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :34.34 & 50.87% & 0.82\n",
      "for 2023-02-12, MAE is:47.23 & sMAPE is:90.98% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :34.64 & 51.80% & 0.82\n",
      "for 2023-02-13, MAE is:58.62 & sMAPE is:122.81% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :35.18 & 53.42% & 0.81\n",
      "for 2023-02-14, MAE is:76.11 & sMAPE is:91.29% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :36.09 & 54.26% & 0.82\n",
      "for 2023-02-15, MAE is:26.50 & sMAPE is:24.40% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :35.89 & 53.61% & 0.81\n",
      "for 2023-02-16, MAE is:33.48 & sMAPE is:50.27% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :35.83 & 53.54% & 0.83\n",
      "for 2023-02-17, MAE is:30.79 & sMAPE is:53.40% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :35.73 & 53.53% & 0.85\n",
      "for 2023-02-18, MAE is:21.32 & sMAPE is:44.76% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :35.44 & 53.35% & 0.85\n",
      "for 2023-02-19, MAE is:12.32 & sMAPE is:18.14% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :34.97 & 52.65% & 0.84\n",
      "for 2023-02-20, MAE is:39.23 & sMAPE is:42.71% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :35.06 & 52.46% & 0.84\n",
      "for 2023-02-21, MAE is:34.86 & sMAPE is:33.73% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :35.05 & 52.10% & 0.85\n",
      "for 2023-02-22, MAE is:36.25 & sMAPE is:33.79% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :35.08 & 51.75% & 0.86\n",
      "for 2023-02-23, MAE is:30.95 & sMAPE is:44.14% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :35.00 & 51.61% & 0.86\n",
      "for 2023-02-24, MAE is:19.88 & sMAPE is:19.76% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :34.72 & 51.03% & 0.85\n",
      "for 2023-02-25, MAE is:10.18 & sMAPE is:24.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :34.29 & 50.55% & 0.85\n",
      "for 2023-02-26, MAE is:35.29 & sMAPE is:51.23% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :34.30 & 50.56% & 0.87\n",
      "for 2023-02-27, MAE is:41.33 & sMAPE is:58.27% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :34.42 & 50.70% & 0.87\n",
      "for 2023-02-28, MAE is:23.28 & sMAPE is:77.78% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :34.24 & 51.15% & 0.86\n",
      "for 2023-03-01, MAE is:41.80 & sMAPE is:60.02% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :34.36 & 51.30% & 0.86\n",
      "for 2023-03-02, MAE is:26.68 & sMAPE is:90.10% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :34.24 & 51.94% & 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-03, MAE is:49.50 & sMAPE is:86.92% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :34.48 & 52.50% & 0.87\n",
      "for 2023-03-04, MAE is:51.20 & sMAPE is:97.41% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :34.75 & 53.22% & 0.88\n",
      "for 2023-03-05, MAE is:41.29 & sMAPE is:42.27% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :34.85 & 53.04% & 0.89\n",
      "for 2023-03-06, MAE is:26.22 & sMAPE is:21.23% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :34.72 & 52.56% & 0.88\n",
      "for 2023-03-07, MAE is:21.39 & sMAPE is:18.60% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :34.52 & 52.04% & 0.87\n",
      "for 2023-03-08, MAE is:40.08 & sMAPE is:38.76% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :34.60 & 51.84% & 0.87\n",
      "for 2023-03-09, MAE is:30.62 & sMAPE is:26.46% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :34.54 & 51.47% & 0.86\n",
      "for 2023-03-10, MAE is:23.74 & sMAPE is:27.48% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :34.38 & 51.12% & 0.85\n",
      "for 2023-03-11, MAE is:15.55 & sMAPE is:16.70% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :34.11 & 50.63% & 0.85\n",
      "for 2023-03-12, MAE is:11.67 & sMAPE is:14.15% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :33.80 & 50.12% & 0.84\n",
      "for 2023-03-13, MAE is:31.04 & sMAPE is:44.11% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :33.76 & 50.03% & 0.84\n",
      "for 2023-03-14, MAE is:39.37 & sMAPE is:71.28% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :33.84 & 50.32% & 0.83\n",
      "for 2023-03-15, MAE is:19.60 & sMAPE is:21.78% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :33.64 & 49.94% & 0.83\n",
      "for 2023-03-16, MAE is:16.72 & sMAPE is:21.72% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :33.42 & 49.56% & 0.83\n",
      "for 2023-03-17, MAE is:42.58 & sMAPE is:73.17% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :33.54 & 49.87% & 0.82\n",
      "for 2023-03-18, MAE is:10.80 & sMAPE is:53.20% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :33.24 & 49.92% & 0.81\n",
      "for 2023-03-19, MAE is:30.05 & sMAPE is:58.01% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :33.20 & 50.02% & 0.82\n",
      "for 2023-03-20, MAE is:42.22 & sMAPE is:94.02% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :33.32 & 50.58% & 0.82\n",
      "for 2023-03-21, MAE is:34.52 & sMAPE is:50.01% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :33.33 & 50.57% & 0.82\n",
      "for 2023-03-22, MAE is:32.63 & sMAPE is:52.64% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :33.32 & 50.59% & 0.82\n",
      "for 2023-03-23, MAE is:9.15 & sMAPE is:36.54% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :33.03 & 50.42% & 0.81\n",
      "for 2023-03-24, MAE is:16.20 & sMAPE is:55.22% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :32.83 & 50.48% & 0.82\n",
      "for 2023-03-25, MAE is:10.17 & sMAPE is:52.59% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :32.56 & 50.51% & 0.82\n",
      "for 2023-03-26, MAE is:16.53 & sMAPE is:38.83% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :32.37 & 50.37% & 0.83\n",
      "for 2023-03-27, MAE is:21.77 & sMAPE is:50.63% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :32.24 & 50.37% & 0.83\n",
      "for 2023-03-28, MAE is:15.73 & sMAPE is:40.25% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :32.05 & 50.26% & 0.84\n",
      "for 2023-03-29, MAE is:52.72 & sMAPE is:71.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :32.29 & 50.49% & 0.84\n",
      "for 2023-03-30, MAE is:37.36 & sMAPE is:47.84% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :32.35 & 50.46% & 0.84\n",
      "for 2023-03-31, MAE is:29.99 & sMAPE is:72.66% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :32.32 & 50.71% & 0.85\n",
      "for 2023-04-01, MAE is:19.88 & sMAPE is:63.95% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :32.18 & 50.85% & 0.86\n",
      "for 2023-04-02, MAE is:21.55 & sMAPE is:57.60% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :32.07 & 50.93% & 0.86\n",
      "for 2023-04-03, MAE is:25.36 & sMAPE is:28.38% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :32.00 & 50.69% & 0.86\n",
      "for 2023-04-04, MAE is:20.60 & sMAPE is:19.63% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :31.87 & 50.35% & 0.85\n",
      "for 2023-04-05, MAE is:19.57 & sMAPE is:20.24% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :31.74 & 50.04% & 0.85\n",
      "for 2023-04-06, MAE is:29.37 & sMAPE is:38.95% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :31.72 & 49.92% & 0.86\n",
      "for 2023-04-07, MAE is:18.03 & sMAPE is:40.33% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :31.58 & 49.82% & 0.86\n",
      "for 2023-04-08, MAE is:7.16 & sMAPE is:13.00% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :31.33 & 49.45% & 0.86\n",
      "for 2023-04-09, MAE is:12.85 & sMAPE is:28.93% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :31.14 & 49.24% & 0.86\n",
      "for 2023-04-10, MAE is:20.17 & sMAPE is:68.49% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :31.03 & 49.43% & 0.85\n",
      "for 2023-04-11, MAE is:10.79 & sMAPE is:52.63% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :30.83 & 49.46% & 0.84\n",
      "for 2023-04-12, MAE is:15.14 & sMAPE is:53.90% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :30.68 & 49.51% & 0.84\n",
      "for 2023-04-13, MAE is:14.02 & sMAPE is:91.69% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :30.52 & 49.92% & 0.83\n",
      "for 2023-04-14, MAE is:20.32 & sMAPE is:89.01% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :30.42 & 50.29% & 0.83\n",
      "for 2023-04-15, MAE is:19.00 & sMAPE is:67.68% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :30.31 & 50.46% & 0.84\n",
      "for 2023-04-16, MAE is:43.66 & sMAPE is:88.01% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :30.44 & 50.81% & 0.85\n",
      "for 2023-04-17, MAE is:30.64 & sMAPE is:32.61% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :30.44 & 50.64% & 0.85\n",
      "for 2023-04-18, MAE is:35.46 & sMAPE is:53.23% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :30.48 & 50.67% & 0.85\n",
      "for 2023-04-19, MAE is:22.83 & sMAPE is:41.70% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :30.41 & 50.58% & 0.85\n",
      "for 2023-04-20, MAE is:20.57 & sMAPE is:52.87% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :30.33 & 50.61% & 0.84\n",
      "for 2023-04-21, MAE is:25.83 & sMAPE is:54.33% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :30.28 & 50.64% & 0.85\n",
      "for 2023-04-22, MAE is:22.91 & sMAPE is:92.47% & rMAE is:3.57 ||| daily mean of MAE & sMAPE & rMAE till now are :30.22 & 51.01% & 0.87\n",
      "for 2023-04-23, MAE is:17.83 & sMAPE is:66.55% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :30.11 & 51.15% & 0.87\n",
      "for 2023-04-24, MAE is:21.42 & sMAPE is:55.25% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :30.03 & 51.19% & 0.86\n",
      "for 2023-04-25, MAE is:27.69 & sMAPE is:64.53% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :30.01 & 51.30% & 0.86\n",
      "for 2023-04-26, MAE is:16.95 & sMAPE is:46.60% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.90 & 51.26% & 0.87\n",
      "for 2023-04-27, MAE is:49.64 & sMAPE is:72.06% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :30.07 & 51.44% & 0.87\n",
      "for 2023-04-28, MAE is:17.48 & sMAPE is:18.41% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :29.96 & 51.16% & 0.87\n",
      "for 2023-04-29, MAE is:29.38 & sMAPE is:47.61% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :29.96 & 51.13% & 0.87\n",
      "for 2023-04-30, MAE is:18.98 & sMAPE is:85.53% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :29.87 & 51.42% & 0.87\n",
      "for 2023-05-01, MAE is:29.62 & sMAPE is:80.21% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :29.86 & 51.65% & 0.88\n",
      "for 2023-05-02, MAE is:18.27 & sMAPE is:30.12% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :29.77 & 51.48% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-03, MAE is:11.10 & sMAPE is:28.08% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :29.62 & 51.29% & 0.88\n",
      "for 2023-05-04, MAE is:22.13 & sMAPE is:36.17% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :29.56 & 51.17% & 0.88\n",
      "for 2023-05-05, MAE is:21.36 & sMAPE is:24.64% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :29.49 & 50.95% & 0.88\n",
      "for 2023-05-06, MAE is:10.90 & sMAPE is:16.76% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 50.68% & 0.88\n",
      "for 2023-05-07, MAE is:19.01 & sMAPE is:37.55% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :29.26 & 50.58% & 0.88\n",
      "for 2023-05-08, MAE is:29.45 & sMAPE is:60.25% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :29.26 & 50.65% & 0.88\n",
      "for 2023-05-09, MAE is:27.53 & sMAPE is:98.56% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :29.25 & 51.03% & 0.88\n",
      "for 2023-05-10, MAE is:30.30 & sMAPE is:158.23% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :29.26 & 51.85% & 0.87\n",
      "for 2023-05-11, MAE is:24.90 & sMAPE is:100.27% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :29.22 & 52.22% & 0.87\n",
      "for 2023-05-12, MAE is:27.09 & sMAPE is:89.05% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :29.21 & 52.50% & 0.87\n",
      "for 2023-05-13, MAE is:12.46 & sMAPE is:50.68% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.08 & 52.49% & 0.86\n",
      "for 2023-05-14, MAE is:7.39 & sMAPE is:84.74% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :28.92 & 52.73% & 0.86\n",
      "for 2023-05-15, MAE is:29.21 & sMAPE is:112.57% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :28.92 & 53.17% & 0.86\n",
      "for 2023-05-16, MAE is:24.46 & sMAPE is:136.19% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :28.89 & 53.78% & 0.87\n",
      "for 2023-05-17, MAE is:31.34 & sMAPE is:166.40% & rMAE is:4.96 ||| daily mean of MAE & sMAPE & rMAE till now are :28.91 & 54.60% & 0.90\n",
      "for 2023-05-18, MAE is:40.82 & sMAPE is:156.27% & rMAE is:2.57 ||| daily mean of MAE & sMAPE & rMAE till now are :28.99 & 55.34% & 0.92\n",
      "for 2023-05-19, MAE is:35.00 & sMAPE is:107.74% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :29.04 & 55.72% & 0.92\n",
      "for 2023-05-20, MAE is:5.55 & sMAPE is:145.88% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :28.87 & 56.36% & 0.91\n",
      "for 2023-05-21, MAE is:14.08 & sMAPE is:159.59% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :28.76 & 57.09% & 0.92\n",
      "for 2023-05-22, MAE is:16.58 & sMAPE is:67.25% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :28.68 & 57.16% & 0.93\n",
      "for 2023-05-23, MAE is:18.63 & sMAPE is:105.57% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :28.61 & 57.50% & 0.94\n",
      "for 2023-05-24, MAE is:15.18 & sMAPE is:184.11% & rMAE is:9.37 ||| daily mean of MAE & sMAPE & rMAE till now are :28.52 & 58.38% & 1.00\n",
      "for 2023-05-25, MAE is:55.19 & sMAPE is:188.70% & rMAE is:7.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.70 & 59.28% & 1.04\n",
      "for 2023-05-26, MAE is:32.31 & sMAPE is:159.50% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :28.72 & 59.97% & 1.05\n",
      "for 2023-05-27, MAE is:18.03 & sMAPE is:149.63% & rMAE is:4.21 ||| daily mean of MAE & sMAPE & rMAE till now are :28.65 & 60.58% & 1.07\n",
      "for 2023-05-28, MAE is:12.06 & sMAPE is:142.27% & rMAE is:2.99 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 61.13% & 1.09\n",
      "for 2023-05-29, MAE is:18.36 & sMAPE is:141.15% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :28.47 & 61.67% & 1.09\n",
      "for 2023-05-30, MAE is:30.31 & sMAPE is:87.32% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.48 & 61.84% & 1.09\n",
      "for 2023-05-31, MAE is:15.24 & sMAPE is:173.75% & rMAE is:7.41 ||| daily mean of MAE & sMAPE & rMAE till now are :28.40 & 62.58% & 1.13\n",
      "for 2023-06-01, MAE is:22.94 & sMAPE is:157.28% & rMAE is:3.94 ||| daily mean of MAE & sMAPE & rMAE till now are :28.36 & 63.20% & 1.15\n",
      "for 2023-06-02, MAE is:8.18 & sMAPE is:70.91% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :28.23 & 63.25% & 1.14\n",
      "for 2023-06-03, MAE is:18.22 & sMAPE is:82.79% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :28.16 & 63.38% & 1.14\n",
      "for 2023-06-04, MAE is:6.20 & sMAPE is:61.45% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :28.02 & 63.37% & 1.14\n",
      "for 2023-06-05, MAE is:17.83 & sMAPE is:151.73% & rMAE is:4.67 ||| daily mean of MAE & sMAPE & rMAE till now are :27.96 & 63.93% & 1.16\n",
      "for 2023-06-06, MAE is:30.15 & sMAPE is:96.17% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 64.14% & 1.16\n",
      "for 2023-06-07, MAE is:20.76 & sMAPE is:64.64% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.92 & 64.14% & 1.16\n",
      "for 2023-06-08, MAE is:10.67 & sMAPE is:58.12% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :27.82 & 64.10% & 1.15\n",
      "for 2023-06-09, MAE is:21.90 & sMAPE is:70.28% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :27.78 & 64.14% & 1.16\n",
      "for 2023-06-10, MAE is:13.23 & sMAPE is:65.36% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :27.69 & 64.15% & 1.16\n",
      "for 2023-06-11, MAE is:10.57 & sMAPE is:169.37% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :27.58 & 64.80% & 1.16\n",
      "for 2023-06-12, MAE is:31.13 & sMAPE is:111.07% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :27.60 & 65.08% & 1.16\n",
      "for 2023-06-13, MAE is:28.94 & sMAPE is:112.66% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :27.61 & 65.37% & 1.16\n",
      "for 2023-06-14, MAE is:15.72 & sMAPE is:32.90% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :27.54 & 65.18% & 1.16\n",
      "for 2023-06-15, MAE is:13.02 & sMAPE is:28.74% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :27.45 & 64.96% & 1.15\n",
      "for 2023-06-16, MAE is:15.53 & sMAPE is:33.01% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :27.38 & 64.76% & 1.15\n",
      "for 2023-06-17, MAE is:29.48 & sMAPE is:86.48% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :27.39 & 64.89% & 1.15\n",
      "for 2023-06-18, MAE is:24.80 & sMAPE is:83.01% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :27.38 & 65.00% & 1.14\n",
      "for 2023-06-19, MAE is:23.21 & sMAPE is:46.46% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :27.35 & 64.89% & 1.14\n",
      "for 2023-06-20, MAE is:18.58 & sMAPE is:29.99% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :27.30 & 64.69% & 1.14\n",
      "for 2023-06-21, MAE is:8.97 & sMAPE is:16.89% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :27.20 & 64.41% & 1.14\n",
      "for 2023-06-22, MAE is:11.73 & sMAPE is:28.03% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.11 & 64.20% & 1.13\n",
      "for 2023-06-23, MAE is:26.53 & sMAPE is:109.41% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :27.10 & 64.46% & 1.13\n",
      "for 2023-06-24, MAE is:12.72 & sMAPE is:96.50% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 64.64% & 1.13\n",
      "for 2023-06-25, MAE is:26.08 & sMAPE is:104.60% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :27.02 & 64.87% & 1.13\n",
      "for 2023-06-26, MAE is:17.14 & sMAPE is:26.02% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 64.65% & 1.13\n",
      "for 2023-06-27, MAE is:19.83 & sMAPE is:28.72% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :26.92 & 64.45% & 1.13\n",
      "for 2023-06-28, MAE is:30.54 & sMAPE is:33.17% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :26.94 & 64.27% & 1.13\n",
      "for 2023-06-29, MAE is:19.91 & sMAPE is:19.80% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :26.90 & 64.03% & 1.13\n",
      "for 2023-06-30, MAE is:17.12 & sMAPE is:22.95% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :26.85 & 63.80% & 1.12\n",
      "CPU times: total: 4d 11h 18min 23s\n",
      "Wall time: 3d 8h 31min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
