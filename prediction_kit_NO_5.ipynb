{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone = 'NO_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:47:38,475]\u001b[0m A new study created in RDB with name: NO_5_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:47:54,950]\u001b[0m Trial 0 finished with value: 4.092984388589415 and parameters: {'n_hidden': 3, 'learning_rate': 0.07975453436802327, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1952755014508344, 'dropout_rate_Layer_2': 0.1439773060676491, 'dropout_rate_Layer_3': 0.08338865871217555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003828594546084357, 'l1_Layer_2': 1.2056069360230952e-05, 'l1_Layer_3': 0.006252063181303411, 'n_units_Layer_1': 225, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125}. Best is trial 0 with value: 4.092984388589415.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.09 | sMAPE for Validation Set is: 15.28% | rMAE for Validation Set is: 1.67\n",
      "MAE for Test Set is: 14.25 | sMAPE for Test Set is: 38.23% | rMAE for Test Set is: 2.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:47:58,495]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:03,803]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:11,452]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:15,712]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:22,493]\u001b[0m Trial 1 finished with value: 1.771877015369564 and parameters: {'n_hidden': 3, 'learning_rate': 0.042784254162239625, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2857966080212733, 'dropout_rate_Layer_2': 0.22081295405098073, 'dropout_rate_Layer_3': 0.3001635084173369, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004720875767308102, 'l1_Layer_2': 0.006979904068145646, 'l1_Layer_3': 0.0018183278473834997, 'n_units_Layer_1': 230, 'n_units_Layer_2': 90, 'n_units_Layer_3': 80}. Best is trial 1 with value: 1.771877015369564.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.77 | sMAPE for Validation Set is: 6.13% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:48:26,059]\u001b[0m Trial 3 finished with value: 1.5366937972891044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017396550133260097, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21581335386576878, 'dropout_rate_Layer_2': 0.3071006737186981, 'dropout_rate_Layer_3': 0.36838838946821834, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00872318710533599, 'l1_Layer_2': 0.05450319994239465, 'l1_Layer_3': 0.05234028216166857, 'n_units_Layer_1': 105, 'n_units_Layer_2': 65, 'n_units_Layer_3': 85}. Best is trial 3 with value: 1.5366937972891044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:48:26,408]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:30,507]\u001b[0m Trial 5 finished with value: 2.5796313565447786 and parameters: {'n_hidden': 4, 'learning_rate': 0.05765515660866315, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38940559732868124, 'dropout_rate_Layer_2': 0.2388805234869671, 'dropout_rate_Layer_3': 0.28127370495990694, 'dropout_rate_Layer_4': 0.38612045190046784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00036200115661044757, 'l1_Layer_2': 0.005590454342086842, 'l1_Layer_3': 4.0659849923039843e-05, 'l1_Layer_4': 0.0029271461655695726, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 115, 'n_units_Layer_4': 225}. Best is trial 3 with value: 1.5366937972891044.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 9.21% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 14.46 | sMAPE for Test Set is: 38.65% | rMAE for Test Set is: 2.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:48:33,179]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:36,613]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:40,524]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:46,024]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:49,163]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:52,604]\u001b[0m Trial 8 finished with value: 1.4600532764562686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036544969816740365, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22900407579974674, 'dropout_rate_Layer_2': 0.24176618415146903, 'dropout_rate_Layer_3': 0.1387229868545668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02914397264193343, 'l1_Layer_2': 0.0001975556104084246, 'l1_Layer_3': 0.0003013125766500766, 'n_units_Layer_1': 125, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 8 with value: 1.4600532764562686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 19.87% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:48:52,980]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:58,698]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:48:59,223]\u001b[0m Trial 12 finished with value: 1.5523062278349748 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018539848602740668, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35627305097863493, 'dropout_rate_Layer_2': 0.2862897556049939, 'dropout_rate_Layer_3': 0.1937712845780436, 'dropout_rate_Layer_4': 0.21198163531897718, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1493281978275063e-05, 'l1_Layer_2': 0.0005819771129857401, 'l1_Layer_3': 0.025029755678107692, 'l1_Layer_4': 0.08562945994598754, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95, 'n_units_Layer_4': 175}. Best is trial 8 with value: 1.4600532764562686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 3.03 | sMAPE for Test Set is: 8.54% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:49:03,419]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:06,185]\u001b[0m Trial 11 finished with value: 1.6383458999015765 and parameters: {'n_hidden': 4, 'learning_rate': 0.004122743586202766, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12388424506849804, 'dropout_rate_Layer_2': 0.007313820459331089, 'dropout_rate_Layer_3': 0.09762051393255033, 'dropout_rate_Layer_4': 0.1589716697625757, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.678210193764119e-05, 'l1_Layer_2': 2.1915706712838846e-05, 'l1_Layer_3': 0.002685150674198424, 'l1_Layer_4': 0.0004275798444633166, 'n_units_Layer_1': 265, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195, 'n_units_Layer_4': 65}. Best is trial 8 with value: 1.4600532764562686.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.28 | sMAPE for Test Set is: 23.34% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:49:06,565]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:12,077]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:12,383]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:12,587]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:19,710]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:22,886]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:26,613]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:29,276]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:32,499]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:33,476]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:36,836]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:38,628]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:41,858]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:43,456]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:44,868]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 24.11% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:49:45,861]\u001b[0m Trial 19 finished with value: 1.4118786766808793 and parameters: {'n_hidden': 3, 'learning_rate': 0.002710103247941991, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050740048707606004, 'dropout_rate_Layer_2': 0.005860245484279769, 'dropout_rate_Layer_3': 0.3153451893266692, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023006411845960754, 'l1_Layer_2': 0.0029006707403604333, 'l1_Layer_3': 1.597228031074314e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 55, 'n_units_Layer_3': 260}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:49,880]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:50,611]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:52,296]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:54,900]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:56,971]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:49:58,195]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:04,129]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:06,196]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:06,864]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:09,960]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:14,368]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:20,426]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:23,884]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:27,171]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:27,463]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:38,208]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:38,498]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:42,890]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:45,057]\u001b[0m Trial 51 finished with value: 1.4892489836779832 and parameters: {'n_hidden': 3, 'learning_rate': 0.004353745854341559, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2896447176408872, 'dropout_rate_Layer_2': 0.3353893406454547, 'dropout_rate_Layer_3': 0.02608515201889395, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.021340436365001148, 'l1_Layer_2': 0.0001865855507204932, 'l1_Layer_3': 9.361984969723522e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.39 | sMAPE for Test Set is: 18.37% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:50:48,051]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:57,130]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:50:59,982]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:04,805]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:04,940]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:11,064]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:11,211]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:21,855]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:26,254]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:26,758]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:30,349]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:33,372]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:35,952]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:37,334]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:40,720]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:43,737]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:43,959]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:48,473]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:50,867]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:51,163]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:56,623]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:51:59,891]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:02,484]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:03,986]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:08,496]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:11,014]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:13,649]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:16,556]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:16,737]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:20,510]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:24,710]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:26,619]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:30,153]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:35,435]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:38,879]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:42,536]\u001b[0m Trial 87 finished with value: 1.7020297092032826 and parameters: {'n_hidden': 4, 'learning_rate': 0.004463395808033497, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3321455260125513, 'dropout_rate_Layer_2': 0.3245468268218928, 'dropout_rate_Layer_3': 0.104453384846386, 'dropout_rate_Layer_4': 0.14418803538515018, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.0850162783104255e-05, 'l1_Layer_2': 0.0004459172379293701, 'l1_Layer_3': 0.04204304642512601, 'l1_Layer_4': 0.004410712817895445, 'n_units_Layer_1': 195, 'n_units_Layer_2': 235, 'n_units_Layer_3': 125, 'n_units_Layer_4': 125}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 5.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.30 | sMAPE for Test Set is: 31.87% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:52:47,846]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:49,998]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:52,227]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:56,620]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:52:59,073]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:01,555]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:03,566]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:06,437]\u001b[0m Trial 94 finished with value: 1.4307169171906942 and parameters: {'n_hidden': 3, 'learning_rate': 0.005275932050159309, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3418995886411104, 'dropout_rate_Layer_2': 0.1991655115780324, 'dropout_rate_Layer_3': 0.03453918848818208, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.019455371524914365, 'l1_Layer_2': 0.00012946071732582095, 'l1_Layer_3': 0.0004315626891825405, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 290}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 18.33% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:53:06,838]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:10,557]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:12,527]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:14,593]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:15,048]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:17,773]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:22,006]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:22,064]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:23,136]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:28,394]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:31,326]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:31,694]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:33,757]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:36,906]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:39,918]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:43,322]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:48,353]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:48,512]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:48,778]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:53:56,562]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:00,579]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:04,318]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:09,574]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:11,804]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:16,395]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:21,431]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:23,628]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:25,440]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:26,083]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:27,642]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:28,138]\u001b[0m Trial 65 finished with value: 1.470660988587463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007543610568075286, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05362355535492222, 'dropout_rate_Layer_2': 0.2892082845757782, 'dropout_rate_Layer_3': 0.26629942682722585, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008788883737580978, 'l1_Layer_2': 2.794444502088502e-05, 'l1_Layer_3': 0.0011249796416537689, 'n_units_Layer_1': 70, 'n_units_Layer_2': 250, 'n_units_Layer_3': 165}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.39 | sMAPE for Test Set is: 26.31% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:54:28,515]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:33,951]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:39,561]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:43,604]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:44,210]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:52,835]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:54:53,120]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:00,793]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:03,391]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:03,554]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:04,825]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:10,099]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:10,511]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:13,994]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:17,258]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:17,514]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:19,815]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:22,988]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:25,264]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:28,806]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:29,032]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:31,113]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:33,150]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:38,162]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:40,637]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:42,489]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:44,690]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:45,099]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:45,238]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:50,217]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:51,433]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:55,960]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:55:58,305]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:01,318]\u001b[0m Trial 157 finished with value: 1.803210624023522 and parameters: {'n_hidden': 3, 'learning_rate': 0.03547248274585563, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2036555793518421, 'dropout_rate_Layer_2': 0.04295528577141641, 'dropout_rate_Layer_3': 0.28749338738153474, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022200507375827253, 'l1_Layer_2': 0.0004262644691373813, 'l1_Layer_3': 1.0784431700304172e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 120, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.80 | sMAPE for Validation Set is: 6.21% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 10.69 | sMAPE for Test Set is: 27.20% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:56:03,323]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:06,391]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:08,018]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:10,757]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:14,376]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:17,546]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:22,342]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:24,354]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:26,500]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:28,905]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:32,612]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:45,829]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:48,039]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:49,620]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:52,418]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:52,632]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:55,515]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:56:59,418]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:02,647]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:06,390]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:06,823]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:09,492]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:11,704]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:12,066]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:14,050]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:17,930]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:20,434]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:22,180]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:22,594]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:28,048]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:31,063]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:32,426]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:32,998]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:43,556]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:43,616]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:47,884]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:50,170]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:52,861]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:56,055]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:57:58,209]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:00,692]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:00,949]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:02,479]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:06,637]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:07,539]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:14,680]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:14,876]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:18,285]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:25,595]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:28,754]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:30,942]\u001b[0m Trial 209 finished with value: 1.6247262717447688 and parameters: {'n_hidden': 4, 'learning_rate': 0.005514834615873896, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05480857072850373, 'dropout_rate_Layer_2': 0.17359915112379698, 'dropout_rate_Layer_3': 0.3329377117133372, 'dropout_rate_Layer_4': 0.26133394711300034, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.62142064838067e-05, 'l1_Layer_2': 0.0030512571788444296, 'l1_Layer_3': 0.0028425036400502794, 'l1_Layer_4': 0.0018730888635557577, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155, 'n_units_Layer_4': 90}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 27.67% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:58:35,031]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:35,422]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:39,149]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:42,159]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:42,709]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:46,851]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:47,455]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:53,344]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:53,762]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:58:59,809]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:03,817]\u001b[0m Trial 220 finished with value: 1.5258456118723978 and parameters: {'n_hidden': 3, 'learning_rate': 0.004520301606574384, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.323222740267311, 'dropout_rate_Layer_2': 0.032098378832354835, 'dropout_rate_Layer_3': 0.1845980625800714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009619383899980582, 'l1_Layer_2': 0.001960833103276914, 'l1_Layer_3': 1.4014974673706531e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:59:06,858]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:08,675]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:09,281]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:15,674]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:19,343]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:24,134]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:28,243]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:31,949]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:34,671]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:34,710]\u001b[0m Trial 230 finished with value: 1.6184506330632187 and parameters: {'n_hidden': 4, 'learning_rate': 0.005239393261332928, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03368445582298518, 'dropout_rate_Layer_2': 0.022660392626829617, 'dropout_rate_Layer_3': 0.3253137266870399, 'dropout_rate_Layer_4': 0.2130403544307175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.7474164496301226e-05, 'l1_Layer_2': 0.0037082774943589364, 'l1_Layer_3': 0.0022205131277325783, 'l1_Layer_4': 0.00462870748564628, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150, 'n_units_Layer_4': 85}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.66 | sMAPE for Test Set is: 24.28% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:59:39,166]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:42,081]\u001b[0m Trial 228 finished with value: 1.577426605686351 and parameters: {'n_hidden': 4, 'learning_rate': 0.0054527070794197965, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04394949191836667, 'dropout_rate_Layer_2': 0.02006567263902911, 'dropout_rate_Layer_3': 0.33270191603492993, 'dropout_rate_Layer_4': 0.19406956497025846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00014775006057496303, 'l1_Layer_2': 0.006141270823776879, 'l1_Layer_3': 0.001871443141626293, 'l1_Layer_4': 0.005231573620189366, 'n_units_Layer_1': 125, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210, 'n_units_Layer_4': 85}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 5.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 23.20% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 13:59:42,729]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:42,987]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:49,169]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:49,321]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:50,084]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:53,816]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:54,904]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:55,323]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 13:59:55,962]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:02,570]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:05,286]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:05,388]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:05,513]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:10,859]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:13,694]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:17,256]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:18,005]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:21,402]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:23,402]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:23,978]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:26,544]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:29,450]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:31,759]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:32,456]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:34,526]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:37,583]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:40,032]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:41,612]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:42,208]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:42,809]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:50,265]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:50,611]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:55,208]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:00:59,049]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:03,169]\u001b[0m Trial 268 finished with value: 1.6474027679219592 and parameters: {'n_hidden': 3, 'learning_rate': 0.012344132265880341, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00033592809240932595, 'dropout_rate_Layer_2': 0.23012566102501258, 'dropout_rate_Layer_3': 0.25879836542398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.019373076289403497, 'l1_Layer_2': 0.04130932790821235, 'l1_Layer_3': 0.0010934473159483456, 'n_units_Layer_1': 280, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.00 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:01:09,467]\u001b[0m Trial 273 finished with value: 1.6550301586360685 and parameters: {'n_hidden': 3, 'learning_rate': 0.006646368509658531, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017866495294627735, 'dropout_rate_Layer_2': 0.0013840724383512096, 'dropout_rate_Layer_3': 0.3383477986909888, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.3428158618465656e-05, 'l1_Layer_2': 0.002886811513219889, 'l1_Layer_3': 0.000559946102373742, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 220}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 20.76% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:01:11,122]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:14,764]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:16,512]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:18,453]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:21,995]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:29,737]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:32,110]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:35,113]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:40,659]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:43,953]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:49,222]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:53,618]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:01:58,629]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:03,932]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:04,608]\u001b[0m Trial 288 finished with value: 1.6557557151037887 and parameters: {'n_hidden': 3, 'learning_rate': 0.012004709514258282, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004903685122701318, 'dropout_rate_Layer_2': 0.20688109609474328, 'dropout_rate_Layer_3': 0.24982116100445448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02044597647848448, 'l1_Layer_2': 0.027323222890189774, 'l1_Layer_3': 0.0006033799720990492, 'n_units_Layer_1': 295, 'n_units_Layer_2': 100, 'n_units_Layer_3': 280}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.71 | sMAPE for Test Set is: 21.79% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:02:07,718]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:09,944]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:14,219]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:16,792]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:17,146]\u001b[0m Trial 275 finished with value: 1.4754874002911305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007489916228185678, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08859664784576587, 'dropout_rate_Layer_2': 0.25127754216228204, 'dropout_rate_Layer_3': 0.2866764438545305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010640767867378305, 'l1_Layer_2': 2.0850113889047402e-05, 'l1_Layer_3': 0.0013254725701583234, 'n_units_Layer_1': 270, 'n_units_Layer_2': 230, 'n_units_Layer_3': 130}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.58 | sMAPE for Test Set is: 24.06% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:02:19,048]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:23,966]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:24,658]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:29,723]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:29,910]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:32,439]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.59 | sMAPE for Validation Set is: 5.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 8.86 | sMAPE for Test Set is: 22.19% | rMAE for Test Set is: 1.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:02:35,776]\u001b[0m Trial 294 finished with value: 1.5896067263161004 and parameters: {'n_hidden': 3, 'learning_rate': 0.011555182964381985, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006495032002377462, 'dropout_rate_Layer_2': 0.2027513992324346, 'dropout_rate_Layer_3': 0.24896163334086194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.019836044133740918, 'l1_Layer_2': 0.046613145724975234, 'l1_Layer_3': 0.0006028956305890805, 'n_units_Layer_1': 300, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:37,549]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:38,050]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:40,100]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:42,369]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:45,567]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:47,402]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:47,922]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:51,422]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:52,770]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:57,372]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:02:57,858]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:01,061]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:02,292]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:08,057]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:09,360]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:12,236]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:15,290]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:20,959]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:25,217]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:28,786]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:29,467]\u001b[0m Trial 320 finished with value: 1.599206773555478 and parameters: {'n_hidden': 3, 'learning_rate': 0.005759455668029116, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33041904742141304, 'dropout_rate_Layer_2': 0.3433657224446321, 'dropout_rate_Layer_3': 0.22192389572390644, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025329318475758905, 'l1_Layer_2': 0.0007102982020383031, 'l1_Layer_3': 1.7107081790139217e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 205, 'n_units_Layer_3': 130}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.60 | sMAPE for Validation Set is: 5.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:03:29,988]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 21.68% | rMAE for Test Set is: 1.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:03:31,462]\u001b[0m Trial 318 finished with value: 1.425613099494238 and parameters: {'n_hidden': 3, 'learning_rate': 0.011693985801915333, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006388889387232113, 'dropout_rate_Layer_2': 0.20647736170601036, 'dropout_rate_Layer_3': 0.0519522128861606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04254398376902602, 'l1_Layer_2': 0.048171815386093726, 'l1_Layer_3': 0.0012593730635293105, 'n_units_Layer_1': 290, 'n_units_Layer_2': 100, 'n_units_Layer_3': 295}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:38,374]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:38,656]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:41,746]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:41,975]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:47,337]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:47,617]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:52,596]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:55,069]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:58,038]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:03:58,480]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:03,741]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:04,535]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:08,533]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:11,941]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:14,102]\u001b[0m Trial 328 finished with value: 1.4854012230743467 and parameters: {'n_hidden': 3, 'learning_rate': 0.012772895449117697, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01925433036297345, 'dropout_rate_Layer_2': 0.17744238420274566, 'dropout_rate_Layer_3': 0.0390999335770727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.04469035741577879, 'l1_Layer_2': 0.04664875316547652, 'l1_Layer_3': 0.0009642472804286382, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 290}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:04:15,329]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:18,959]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:25,045]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:26,815]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:28,995]\u001b[0m Trial 337 finished with value: 1.5653131418121593 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036339222955965676, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09358569370639817, 'dropout_rate_Layer_2': 0.3047928400762595, 'dropout_rate_Layer_3': 0.0865436604401132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002640527759017369, 'l1_Layer_2': 0.00044804935615853903, 'l1_Layer_3': 0.00015380101538908553, 'n_units_Layer_1': 215, 'n_units_Layer_2': 220, 'n_units_Layer_3': 130}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 5.42 | sMAPE for Test Set is: 13.56% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:04:29,271]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:33,005]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:34,914]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:38,037]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:41,021]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:44,159]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:47,890]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:49,934]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:50,136]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:55,375]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:55,575]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:55,650]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:04:59,551]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:03,275]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:05,282]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:08,043]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:08,428]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:13,692]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:13,831]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:19,286]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:23,398]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:26,806]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:28,453]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:31,737]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:35,538]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:38,154]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:38,556]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:42,157]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:42,831]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:45,230]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:46,537]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:48,126]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:50,426]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:05:54,606]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:00,063]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:00,681]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:04,044]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:04,689]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:10,111]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:13,955]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:17,948]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:18,217]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:24,301]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:24,357]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:31,187]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:31,534]\u001b[0m Trial 380 finished with value: 1.5376087372973426 and parameters: {'n_hidden': 3, 'learning_rate': 0.005441621929433291, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01198725037111719, 'dropout_rate_Layer_2': 0.2288275973417689, 'dropout_rate_Layer_3': 0.2253593853935748, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023856460820760057, 'l1_Layer_2': 0.03338963325632324, 'l1_Layer_3': 0.006554061740218723, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.87 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:06:37,091]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:39,747]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:40,523]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:45,840]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:47,488]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:54,137]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:56,125]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:58,567]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:06:58,751]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:05,014]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:05,449]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:11,529]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:14,506]\u001b[0m Trial 401 finished with value: 1.7015366421864684 and parameters: {'n_hidden': 3, 'learning_rate': 0.007091090163623416, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02130484167241497, 'dropout_rate_Layer_2': 0.020589748645808474, 'dropout_rate_Layer_3': 0.341142275297224, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.366018804070602e-05, 'l1_Layer_2': 0.003986967648096974, 'l1_Layer_3': 0.0006782122266231399, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:14,623]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 5.89% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 24.11% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:07:19,680]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:28,772]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:33,024]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:38,255]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:38,454]\u001b[0m Trial 408 finished with value: 1.7181438283636137 and parameters: {'n_hidden': 3, 'learning_rate': 0.005958334521060786, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3057882529959181, 'dropout_rate_Layer_2': 0.05741026242774672, 'dropout_rate_Layer_3': 0.35992612149634773, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.910594428102947e-05, 'l1_Layer_2': 0.007755182592570303, 'l1_Layer_3': 0.00015914182421487464, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.72 | sMAPE for Validation Set is: 5.91% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.07 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:07:44,004]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:47,213]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:51,046]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 14.44% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:07:52,580]\u001b[0m Trial 404 finished with value: 1.5101221006720202 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055659485386863935, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028035482242554345, 'dropout_rate_Layer_2': 0.1528673047605053, 'dropout_rate_Layer_3': 0.07045549299535725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0037419623293801045, 'l1_Layer_2': 2.0897630669337402e-05, 'l1_Layer_3': 0.0024041998781913878, 'n_units_Layer_1': 55, 'n_units_Layer_2': 220, 'n_units_Layer_3': 285}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:53,360]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:53,846]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:07:59,047]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:01,193]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:02,167]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:03,902]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:06,356]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:09,856]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:10,092]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:10,409]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:11,314]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:16,936]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:19,028]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:19,676]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:21,749]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:26,058]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:29,374]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:29,582]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:30,054]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:30,884]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:38,604]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:40,053]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:42,855]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:43,330]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:45,815]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:46,987]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:53,010]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:08:56,895]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:01,495]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:01,714]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:07,802]\u001b[0m Trial 439 finished with value: 1.646826477175096 and parameters: {'n_hidden': 3, 'learning_rate': 0.005431793197858713, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04811384451002165, 'dropout_rate_Layer_2': 0.025464019363030714, 'dropout_rate_Layer_3': 0.35655089178622695, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.002964857964307e-05, 'l1_Layer_2': 2.4828630182064016e-05, 'l1_Layer_3': 0.0012492094448578817, 'n_units_Layer_1': 80, 'n_units_Layer_2': 190, 'n_units_Layer_3': 165}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.65 | sMAPE for Validation Set is: 5.69% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 25.34% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:09:08,091]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:08,468]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:08,658]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:13,307]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:19,812]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:20,400]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:21,596]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:23,371]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:24,770]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:34,863]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:36,496]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:39,024]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:39,613]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:39,789]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:46,198]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:47,124]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:49,067]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:53,185]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:53,948]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:09:58,207]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:00,724]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:04,986]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:05,487]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:11,531]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:18,017]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:21,407]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:21,571]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:24,980]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:29,848]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:30,363]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:30,606]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:33,613]\u001b[0m Trial 466 finished with value: 1.4794991997589169 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017577017438523267, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3627310258272734, 'dropout_rate_Layer_2': 0.01660254551330646, 'dropout_rate_Layer_3': 0.14595300985746779, 'dropout_rate_Layer_4': 0.3619830696199179, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006613785596344925, 'l1_Layer_2': 7.995291933227605e-05, 'l1_Layer_3': 5.9424224658994775e-05, 'l1_Layer_4': 0.02216852998464941, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 115, 'n_units_Layer_4': 140}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:10:37,379]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:41,950]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:42,505]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:43,309]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:49,488]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:51,470]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:52,348]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:53,787]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:10:53,936]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:02,688]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:06,061]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:06,565]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:06,677]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:13,089]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:15,892]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:16,507]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:23,647]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:25,164]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:29,239]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:31,473]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:32,146]\u001b[0m Trial 494 finished with value: 1.6829310559871251 and parameters: {'n_hidden': 3, 'learning_rate': 0.004883035566812512, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05453572279216111, 'dropout_rate_Layer_2': 0.09656991395250175, 'dropout_rate_Layer_3': 0.3393152178913102, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.0709671187016114e-05, 'l1_Layer_2': 1.3609838004427094e-05, 'l1_Layer_3': 0.002241911218153573, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.79% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 2.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:11:34,455]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:39,725]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:40,354]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:40,821]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:48,618]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:54,376]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:11:58,361]\u001b[0m Trial 502 finished with value: 1.6592693836773351 and parameters: {'n_hidden': 3, 'learning_rate': 0.00505181534497692, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.054418647933523745, 'dropout_rate_Layer_2': 0.09185164365579451, 'dropout_rate_Layer_3': 0.34786258209375165, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.515449575284823e-05, 'l1_Layer_2': 1.3761889147139633e-05, 'l1_Layer_3': 0.002315451864735637, 'n_units_Layer_1': 75, 'n_units_Layer_2': 170, 'n_units_Layer_3': 155}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 23.18% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:12:00,244]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:04,493]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:05,540]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:07,593]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:11,546]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:14,530]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:16,938]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:20,942]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:21,165]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:25,599]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:27,510]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:30,103]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:30,733]\u001b[0m Trial 504 finished with value: 1.434554616006393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031175120894450107, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013447172806048312, 'dropout_rate_Layer_2': 0.20905022528856876, 'dropout_rate_Layer_3': 0.227747281693451, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.009795054896634637, 'l1_Layer_2': 0.0013130478780483514, 'l1_Layer_3': 0.0002613218182633794, 'n_units_Layer_1': 110, 'n_units_Layer_2': 235, 'n_units_Layer_3': 300}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.76 | sMAPE for Test Set is: 14.34% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:12:34,631]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:39,610]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:43,239]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:45,122]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:49,290]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:49,549]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:12:55,452]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:00,787]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:04,734]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:06,331]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 5.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.31 | sMAPE for Test Set is: 23.43% | rMAE for Test Set is: 1.87\n",
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 5.88% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 33.14% | rMAE for Test Set is: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:13:10,986]\u001b[0m Trial 523 finished with value: 1.6783396665832406 and parameters: {'n_hidden': 3, 'learning_rate': 0.005182987645426205, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07986812301873034, 'dropout_rate_Layer_2': 0.14899677137554304, 'dropout_rate_Layer_3': 0.3023112217243661, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010833881649183347, 'l1_Layer_2': 4.9199649752940736e-05, 'l1_Layer_3': 0.0044635031426400185, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:11,022]\u001b[0m Trial 526 finished with value: 1.7018095965980375 and parameters: {'n_hidden': 3, 'learning_rate': 0.007392612407307921, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0830894637452609, 'dropout_rate_Layer_2': 0.09200848041241512, 'dropout_rate_Layer_3': 0.3886650501056469, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.803600281651105e-05, 'l1_Layer_2': 2.502055534800241e-05, 'l1_Layer_3': 0.002464184455323326, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 190}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:11,780]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:14,900]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:21,850]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:25,212]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:25,601]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:25,823]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:32,600]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:37,619]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:38,215]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:38,518]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:46,781]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:50,412]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.66 | sMAPE for Validation Set is: 5.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 24.04% | rMAE for Test Set is: 1.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:13:52,264]\u001b[0m Trial 538 finished with value: 1.6602360102495444 and parameters: {'n_hidden': 3, 'learning_rate': 0.005316679333115516, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03118936348199835, 'dropout_rate_Layer_2': 0.17773586735304492, 'dropout_rate_Layer_3': 0.34303451447695954, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 7.195516150301026e-05, 'l1_Layer_2': 5.616371322208726e-05, 'l1_Layer_3': 0.006701462286948797, 'n_units_Layer_1': 75, 'n_units_Layer_2': 205, 'n_units_Layer_3': 155}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:55,981]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:57,437]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:13:57,927]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:03,534]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:04,382]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:09,606]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:09,850]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:10,897]\u001b[0m Trial 543 finished with value: 1.666446748357023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035993065577118425, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014915179187161835, 'dropout_rate_Layer_2': 0.1762624995502321, 'dropout_rate_Layer_3': 0.35468595596735725, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014492839070582892, 'l1_Layer_2': 1.0176375172625826e-05, 'l1_Layer_3': 0.0006257503092100308, 'n_units_Layer_1': 75, 'n_units_Layer_2': 195, 'n_units_Layer_3': 205}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 5.72% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 19.84% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:14:18,415]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:21,428]\u001b[0m Trial 546 finished with value: 1.6187478748957316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035322641818523923, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05802604865344882, 'dropout_rate_Layer_2': 0.1675565560174182, 'dropout_rate_Layer_3': 0.35894590257790776, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001438973500256987, 'l1_Layer_2': 6.36878124501143e-05, 'l1_Layer_3': 0.006353863329285342, 'n_units_Layer_1': 75, 'n_units_Layer_2': 210, 'n_units_Layer_3': 205}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.62 | sMAPE for Validation Set is: 5.61% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 24.56% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:14:23,263]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:24,303]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:25,670]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:31,488]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:32,882]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:37,653]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:40,973]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:41,099]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:42,161]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:48,771]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:48,976]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:49,836]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:50,147]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:14:57,479]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:00,747]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:03,930]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:05,982]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:10,753]\u001b[0m Trial 567 finished with value: 1.5414438727270514 and parameters: {'n_hidden': 3, 'learning_rate': 0.002778409225477943, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013929119340779304, 'dropout_rate_Layer_2': 0.1637632731590768, 'dropout_rate_Layer_3': 0.351784797078598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014246848809959615, 'l1_Layer_2': 1.621117204337081e-05, 'l1_Layer_3': 0.001787079033599153, 'n_units_Layer_1': 200, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 2.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:15:10,968]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:11,105]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:16,490]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:20,942]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:21,243]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:21,346]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:28,265]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:29,096]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:34,673]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:37,842]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:43,583]\u001b[0m Trial 579 finished with value: 1.5431977597916813 and parameters: {'n_hidden': 3, 'learning_rate': 0.004208537591189774, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014951751880669144, 'dropout_rate_Layer_2': 0.17871856663434932, 'dropout_rate_Layer_3': 0.3763596107875173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00023990635148383955, 'l1_Layer_2': 3.228755687429096e-05, 'l1_Layer_3': 0.0036128318672049944, 'n_units_Layer_1': 190, 'n_units_Layer_2': 200, 'n_units_Layer_3': 205}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.82 | sMAPE for Test Set is: 33.42% | rMAE for Test Set is: 2.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:15:47,421]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.02 | sMAPE for Test Set is: 25.36% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:15:49,995]\u001b[0m Trial 574 finished with value: 1.4873908340997535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029134208675340736, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026612662863882513, 'dropout_rate_Layer_2': 0.11664547309321033, 'dropout_rate_Layer_3': 0.1257617932107048, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 6.634098732945775e-05, 'l1_Layer_2': 1.577652890778669e-05, 'l1_Layer_3': 0.0035613371682144254, 'n_units_Layer_1': 190, 'n_units_Layer_2': 210, 'n_units_Layer_3': 195}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:53,517]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:15:56,352]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:00,451]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:03,518]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:04,117]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:08,685]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:10,238]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:12,673]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:16,074]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:19,893]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:23,220]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:26,870]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:27,171]\u001b[0m Trial 587 finished with value: 1.6081459244225502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031149674701852494, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04813823995673701, 'dropout_rate_Layer_2': 0.19925245988247173, 'dropout_rate_Layer_3': 0.13474410855810173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 8.823277558404533e-05, 'l1_Layer_2': 1.568125818309384e-05, 'l1_Layer_3': 0.0033212562028031027, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.61 | sMAPE for Validation Set is: 5.51% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 26.39% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:16:27,341]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:33,795]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:34,534]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:34,764]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:41,244]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:45,942]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:46,462]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:51,624]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:16:55,581]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:00,210]\u001b[0m Trial 602 finished with value: 1.5045739172646009 and parameters: {'n_hidden': 3, 'learning_rate': 0.005044710808156503, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22441256838134588, 'dropout_rate_Layer_2': 0.05556550504242462, 'dropout_rate_Layer_3': 0.18403907201573222, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002121040793643183, 'l1_Layer_2': 0.00046401853894074274, 'l1_Layer_3': 4.814961091906571e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 17.22% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:17:00,661]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:02,611]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:02,718]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:06,718]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:07,691]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:09,217]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:14,734]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:18,225]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:20,966]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:21,656]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:22,128]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:24,015]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:28,587]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:30,198]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:32,633]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:36,626]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:39,144]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:43,245]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:44,160]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:44,269]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:51,208]\u001b[0m Trial 618 finished with value: 1.4351764937352869 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036464088190391016, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20470271587319266, 'dropout_rate_Layer_2': 0.06872150349881025, 'dropout_rate_Layer_3': 0.18787833228451725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002816301114307209, 'l1_Layer_2': 0.0006689887176836673, 'l1_Layer_3': 3.2278264127444056e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:17:51,512]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:51,661]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:58,856]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:59,055]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:17:59,235]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:06,873]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:09,865]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:10,175]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:15,507]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:15,722]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:20,686]\u001b[0m Trial 631 finished with value: 1.5141807161540737 and parameters: {'n_hidden': 3, 'learning_rate': 0.003928230086343414, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07145730538774747, 'dropout_rate_Layer_2': 0.1315211307288687, 'dropout_rate_Layer_3': 0.14338875227553108, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.1542784450273898e-05, 'l1_Layer_2': 3.364244236091753e-05, 'l1_Layer_3': 0.008515710771967902, 'n_units_Layer_1': 175, 'n_units_Layer_2': 215, 'n_units_Layer_3': 195}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 10.79 | sMAPE for Test Set is: 27.49% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:18:23,606]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:24,445]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:26,081]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:27,459]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:33,015]\u001b[0m Trial 634 finished with value: 1.4412320043521223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026547843018805977, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19308605014097768, 'dropout_rate_Layer_2': 0.32369022812598336, 'dropout_rate_Layer_3': 0.358396311478233, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004878036232567412, 'l1_Layer_2': 0.0009415823418157472, 'l1_Layer_3': 5.8208312121266525e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 22.52% | rMAE for Test Set is: 1.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:18:33,279]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:33,489]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:33,985]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:37,934]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:41,756]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:42,532]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:43,262]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:48,586]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:50,250]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:56,218]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:18:56,369]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:01,366]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:04,010]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:07,511]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:08,120]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:10,751]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:13,548]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:17,270]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:17,434]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:21,662]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:24,721]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:24,929]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:25,095]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:30,939]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:31,034]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:37,537]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:39,675]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:43,412]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:46,916]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:49,554]\u001b[0m Trial 667 finished with value: 1.4919193558897164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031328900449514056, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20344620206476235, 'dropout_rate_Layer_2': 0.08566097959785007, 'dropout_rate_Layer_3': 0.3249384898468851, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032587737254691925, 'l1_Layer_2': 0.0014124845023993538, 'l1_Layer_3': 5.6503749856391685e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 225, 'n_units_Layer_3': 270}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 15.92% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:19:50,501]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:50,521]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:19:54,265]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:00,039]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:02,958]\u001b[0m Trial 672 finished with value: 1.4775927040519221 and parameters: {'n_hidden': 3, 'learning_rate': 0.012861707876548514, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013124320975481509, 'dropout_rate_Layer_2': 0.18346253800942475, 'dropout_rate_Layer_3': 0.24924898778305488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.013450266380979618, 'l1_Layer_2': 0.03410906764981744, 'l1_Layer_3': 0.004843203245543004, 'n_units_Layer_1': 290, 'n_units_Layer_2': 250, 'n_units_Layer_3': 290}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 25.08% | rMAE for Test Set is: 2.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:20:03,492]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:04,756]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:11,383]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:18,140]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:18,495]\u001b[0m Trial 681 finished with value: 1.4991675096916754 and parameters: {'n_hidden': 3, 'learning_rate': 0.013509953965075872, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00010592962324055752, 'dropout_rate_Layer_2': 0.19723691029451007, 'dropout_rate_Layer_3': 0.26571253762593056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.024102201809605896, 'l1_Layer_2': 0.02534985415400187, 'l1_Layer_3': 0.006534520695985594, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.84 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:20:21,405]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:26,330]\u001b[0m Trial 683 finished with value: 1.4338325862422778 and parameters: {'n_hidden': 3, 'learning_rate': 0.013159144619957036, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00039622022932527597, 'dropout_rate_Layer_2': 0.18810436341622663, 'dropout_rate_Layer_3': 0.2672489876912007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.022179559730658858, 'l1_Layer_2': 0.0391733016974909, 'l1_Layer_3': 0.0059333630596505454, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.70 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:20:30,038]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:30,402]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:36,107]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:36,347]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:41,367]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:41,576]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:41,671]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:47,754]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:48,229]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:52,637]\u001b[0m Trial 690 finished with value: 1.6356660980974047 and parameters: {'n_hidden': 3, 'learning_rate': 0.003858402798436577, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02699287228660956, 'dropout_rate_Layer_2': 0.014197633724881326, 'dropout_rate_Layer_3': 0.3660413280660286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001004849881717669, 'l1_Layer_2': 2.9413084648906805e-05, 'l1_Layer_3': 0.0034788740423123614, 'n_units_Layer_1': 150, 'n_units_Layer_2': 185, 'n_units_Layer_3': 170}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.64 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 13.09 | sMAPE for Test Set is: 34.28% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:20:54,653]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:56,058]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:58,792]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:20:59,626]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:02,483]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:05,684]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:06,166]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:06,614]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:14,912]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:15,130]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:20,246]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:23,173]\u001b[0m Trial 698 finished with value: 1.5034520091690833 and parameters: {'n_hidden': 3, 'learning_rate': 0.013049874936570598, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024413565901506895, 'dropout_rate_Layer_2': 0.18600105488767563, 'dropout_rate_Layer_3': 0.2786961915474258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.018074534072545487, 'l1_Layer_2': 0.045418496743940044, 'l1_Layer_3': 0.007617144100392196, 'n_units_Layer_1': 280, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.90 | sMAPE for Test Set is: 24.98% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:21:27,346]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:27,721]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:27,812]\u001b[0m Trial 704 finished with value: 1.4571283121748344 and parameters: {'n_hidden': 3, 'learning_rate': 0.015465649384654324, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008714780107570042, 'dropout_rate_Layer_2': 0.1853249641819969, 'dropout_rate_Layer_3': 0.2870900972982803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.027517554211841308, 'l1_Layer_2': 0.03763764223513933, 'l1_Layer_3': 0.008562083973588557, 'n_units_Layer_1': 280, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.24 | sMAPE for Test Set is: 25.90% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:21:32,358]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:33,566]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:33,735]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:35,744]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:40,633]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:41,095]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:41,658]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:44,996]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:48,363]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:49,489]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:50,181]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:55,431]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:56,052]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:59,282]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:21:59,863]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:03,340]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:07,892]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:10,115]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:12,327]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:12,867]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:17,604]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:18,428]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:22,778]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:22,867]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:27,727]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:29,271]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.09 | sMAPE for Test Set is: 25.48% | rMAE for Test Set is: 2.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:22:31,791]\u001b[0m Trial 730 finished with value: 1.4145150239152393 and parameters: {'n_hidden': 3, 'learning_rate': 0.01312299351521837, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009637602809624892, 'dropout_rate_Layer_2': 0.18460007957103525, 'dropout_rate_Layer_3': 0.2814811922093612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.02868124198158096, 'l1_Layer_2': 0.05390636438344425, 'l1_Layer_3': 0.006274263151662692, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:33,537]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:35,897]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:36,527]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:39,502]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:39,979]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:43,794]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:44,476]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:50,678]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:54,059]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:22:55,474]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:01,353]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:03,926]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:05,534]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:07,938]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:08,447]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:08,527]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:08,997]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:14,643]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:14,840]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:15,485]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:19,906]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:21,833]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:22,564]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:26,467]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:27,000]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:30,789]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:31,053]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:35,927]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:38,009]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:38,210]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:38,988]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:43,462]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:45,197]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:47,384]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:49,632]\u001b[0m Trial 756 finished with value: 1.4333632864676822 and parameters: {'n_hidden': 3, 'learning_rate': 0.021753812588277455, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0010298493841056347, 'dropout_rate_Layer_2': 0.19551410276783276, 'dropout_rate_Layer_3': 0.3364593297943847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.020164660062013083, 'l1_Layer_2': 0.07614214537448226, 'l1_Layer_3': 0.005424467814402895, 'n_units_Layer_1': 270, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:23:51,429]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:53,153]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:54,832]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:55,414]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:23:56,427]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:00,686]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:01,406]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.58 | sMAPE for Validation Set is: 5.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.81 | sMAPE for Test Set is: 19.52% | rMAE for Test Set is: 1.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:24:03,086]\u001b[0m Trial 771 finished with value: 1.578159187377276 and parameters: {'n_hidden': 3, 'learning_rate': 0.003993752895116452, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05059667758252692, 'dropout_rate_Layer_2': 0.20247208020825003, 'dropout_rate_Layer_3': 0.3673132298935956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000191592333102292, 'l1_Layer_2': 0.004840056700796908, 'l1_Layer_3': 0.0015262332252854135, 'n_units_Layer_1': 110, 'n_units_Layer_2': 175, 'n_units_Layer_3': 170}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:06,862]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:07,266]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:07,775]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:12,322]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:13,074]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:14,754]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:16,711]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:17,031]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:18,102]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:19,170]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:23,302]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:23,844]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:25,423]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:27,644]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:31,682]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:32,441]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:33,380]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:38,594]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:38,688]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:42,783]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:42,929]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:43,471]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:49,749]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:50,063]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:54,061]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:56,197]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:24:58,078]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:00,384]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:00,853]\u001b[0m Trial 798 finished with value: 1.513015106661138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025179494934177574, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005702125974529834, 'dropout_rate_Layer_2': 0.18392492031952606, 'dropout_rate_Layer_3': 0.3774950919343744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00039583692237244675, 'l1_Layer_2': 0.006343103892193775, 'l1_Layer_3': 0.001614313870858674, 'n_units_Layer_1': 115, 'n_units_Layer_2': 205, 'n_units_Layer_3': 165}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 20.31% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:25:04,728]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:05,227]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:14,889]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:15,454]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:17,335]\u001b[0m Trial 807 finished with value: 1.5344126404330716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021054281895357585, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005460812364102676, 'dropout_rate_Layer_2': 0.22796411827302035, 'dropout_rate_Layer_3': 0.057818184042852494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002766187726189361, 'l1_Layer_2': 0.006684377409107648, 'l1_Layer_3': 0.0011899743807843592, 'n_units_Layer_1': 115, 'n_units_Layer_2': 180, 'n_units_Layer_3': 185}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:25:19,030]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:20,744]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:22,747]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:26,595]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:28,696]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:32,221]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:32,703]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:34,457]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:35,038]\u001b[0m Trial 813 finished with value: 1.5373461298347628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029240731197063483, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010380991956561232, 'dropout_rate_Layer_2': 0.22426740425342387, 'dropout_rate_Layer_3': 0.36156501493294585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003543883917753212, 'l1_Layer_2': 0.004620787650703308, 'l1_Layer_3': 0.0010359958283812714, 'n_units_Layer_1': 115, 'n_units_Layer_2': 195, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 21.60% | rMAE for Test Set is: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:25:40,735]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:40,879]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:41,138]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:46,870]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:47,037]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:50,775]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:52,314]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:55,859]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:25:59,417]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:01,435]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:02,102]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:09,379]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:16,099]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:19,511]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:26,837]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.54 | sMAPE for Validation Set is: 5.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 19.07% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:26:28,017]\u001b[0m Trial 832 finished with value: 1.5374225364717027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019423269278398565, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005800822741479983, 'dropout_rate_Layer_2': 0.24618302841328701, 'dropout_rate_Layer_3': 0.38569937852491315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00038925875195223157, 'l1_Layer_2': 0.009343604489890816, 'l1_Layer_3': 0.0009527763782222813, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:31,558]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:34,108]\u001b[0m Trial 830 finished with value: 1.4567779201280253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019687989142852212, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005641175793275386, 'dropout_rate_Layer_2': 0.24868927009022318, 'dropout_rate_Layer_3': 0.046961653162620035, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003775541259576717, 'l1_Layer_2': 0.010055882777585462, 'l1_Layer_3': 0.0009767021096390512, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:26:36,242]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:37,244]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:41,141]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:41,524]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:47,035]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:48,913]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:51,959]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:52,585]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:55,206]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:26:58,626]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:00,971]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:03,249]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:05,495]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:07,512]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:08,071]\u001b[0m Trial 842 finished with value: 1.5287655912076072 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018125351963866783, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006891901790585138, 'dropout_rate_Layer_2': 0.2447194823733534, 'dropout_rate_Layer_3': 0.3990937755616684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00039203598809458553, 'l1_Layer_2': 0.009931372442916381, 'l1_Layer_3': 0.0015832478217183642, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 20.32% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:27:09,000]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:13,388]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:13,732]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:14,496]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:14,938]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:21,003]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:23,158]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:23,674]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:24,141]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:25,901]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:30,056]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:33,451]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:34,079]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:34,649]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:34,830]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:37,364]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:43,971]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:44,708]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:45,346]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:50,125]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:51,252]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:53,442]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:55,010]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:27:56,702]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:04,370]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:06,489]\u001b[0m Trial 873 finished with value: 1.5323318068364038 and parameters: {'n_hidden': 3, 'learning_rate': 0.001925103703784741, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008916695134996058, 'dropout_rate_Layer_2': 0.28119309685994914, 'dropout_rate_Layer_3': 0.38255800034959886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00033383020885852734, 'l1_Layer_2': 0.004882085971742564, 'l1_Layer_3': 0.0010079801384145727, 'n_units_Layer_1': 105, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 21.36% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:28:07,712]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:10,666]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:10,799]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:11,557]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:13,757]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:18,986]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:21,339]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:23,735]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:26,378]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:28,224]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:28,496]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:32,282]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:33,168]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:34,357]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:36,929]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:38,810]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:39,436]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:42,911]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:47,916]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:48,157]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:52,737]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:28:55,909]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:00,505]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:03,485]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:05,045]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:08,442]\u001b[0m Trial 887 finished with value: 1.474411700584369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017385237437087175, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01693189326846392, 'dropout_rate_Layer_2': 0.25482581562249434, 'dropout_rate_Layer_3': 0.3808104597151091, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0006268890824673555, 'l1_Layer_2': 0.006532673832960372, 'l1_Layer_3': 0.0008863534845247514, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:08,556]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:29:09,013]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:13,661]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:16,580]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:16,983]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:20,626]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:23,511]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:26,168]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:27,526]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:27,876]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:29,612]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:35,512]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:35,721]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:36,184]\u001b[0m Trial 902 finished with value: 1.435645210649714 and parameters: {'n_hidden': 3, 'learning_rate': 0.002182778753965853, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00021277614369924827, 'dropout_rate_Layer_2': 0.3228993420262581, 'dropout_rate_Layer_3': 0.009599980435734012, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003062011958750092, 'l1_Layer_2': 0.0130480222657346, 'l1_Layer_3': 0.0007760720605971095, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 16.76% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:29:36,357]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:42,450]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:45,499]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:48,226]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:48,870]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:49,111]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:55,052]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:59,295]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:29:59,751]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:00,051]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:04,482]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:06,341]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:07,744]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:08,023]\u001b[0m Trial 924 finished with value: 1.498971325689632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060291903572941416, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2055277128980722, 'dropout_rate_Layer_2': 0.012436577416169936, 'dropout_rate_Layer_3': 0.216330761403223, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002537350709173708, 'l1_Layer_2': 0.0005615999523549181, 'l1_Layer_3': 0.0004268225087918959, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.00% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:30:13,799]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:16,076]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:16,380]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:17,348]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:21,667]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:22,175]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:22,947]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:28,823]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:31,084]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:31,860]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:33,565]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:37,708]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:41,472]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:44,530]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:47,868]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:51,413]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:54,966]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:30:59,937]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:02,905]\u001b[0m Trial 936 finished with value: 1.4620425062428195 and parameters: {'n_hidden': 3, 'learning_rate': 0.001596587610925763, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011229485520243655, 'dropout_rate_Layer_2': 0.2617320368796339, 'dropout_rate_Layer_3': 0.009222391712590913, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000880603932984031, 'l1_Layer_2': 0.012272459189474094, 'l1_Layer_3': 0.0007750651600494549, 'n_units_Layer_1': 110, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 14.44% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:31:03,390]\u001b[0m Trial 948 finished with value: 1.5305079738343454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021355571359216296, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008352620396852048, 'dropout_rate_Layer_2': 0.26282697294585816, 'dropout_rate_Layer_3': 0.07272111842714009, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00024880879955502467, 'l1_Layer_2': 0.026135866958742614, 'l1_Layer_3': 0.0006864195932943298, 'n_units_Layer_1': 110, 'n_units_Layer_2': 235, 'n_units_Layer_3': 175}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 17.38% | rMAE for Test Set is: 1.40\n",
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 16.67% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:31:03,481]\u001b[0m Trial 950 finished with value: 1.441645499581065 and parameters: {'n_hidden': 3, 'learning_rate': 0.004520719836097467, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19387261474180684, 'dropout_rate_Layer_2': 0.3303776536755159, 'dropout_rate_Layer_3': 0.21193621390356523, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023267884995971763, 'l1_Layer_2': 0.0006850720591151179, 'l1_Layer_3': 0.0006639564629979615, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 95}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:10,394]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:13,583]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:13,664]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:14,214]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:17,685]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:21,874]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:27,110]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:27,520]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:28,483]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:28,561]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:36,793]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:37,184]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:37,872]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:39,671]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:44,770]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:47,866]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:52,645]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:31:58,360]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:01,202]\u001b[0m Trial 973 finished with value: 1.5112032160235074 and parameters: {'n_hidden': 3, 'learning_rate': 0.003964205654196041, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22153585085288408, 'dropout_rate_Layer_2': 0.3080955453617263, 'dropout_rate_Layer_3': 0.05023747969625571, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008386770356198997, 'l1_Layer_2': 0.000717517847671681, 'l1_Layer_3': 0.0006982000276426543, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 140}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.25% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.13 | sMAPE for Test Set is: 20.23% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:32:03,809]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:06,067]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:07,460]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:11,297]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:12,070]\u001b[0m Trial 971 finished with value: 1.5296710586281463 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015435560395863684, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011609351796615914, 'dropout_rate_Layer_2': 0.23758566258716493, 'dropout_rate_Layer_3': 0.012726165066790182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000380078370352575, 'l1_Layer_2': 0.04614910316762256, 'l1_Layer_3': 0.0004322560043188507, 'n_units_Layer_1': 110, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 19.91% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:32:16,298]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:18,671]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:18,819]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:18,923]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:22,910]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:27,880]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:31,242]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:32,469]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:34,451]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:36,352]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:38,242]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:42,418]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:45,427]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:48,594]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:52,625]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:32:56,012]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:00,282]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:00,929]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:06,590]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:11,652]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:27,036]\u001b[0m Trial 994 finished with value: 1.498906300232175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015630188501748114, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0067370351791882915, 'dropout_rate_Layer_2': 0.2636369727432524, 'dropout_rate_Layer_3': 0.01035944174086024, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003898791255376701, 'l1_Layer_2': 0.058746697324778954, 'l1_Layer_3': 0.0005297268259112398, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 165}. Best is trial 19 with value: 1.4118786766808793.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 15.96% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:33:30,279]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:34,880]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:38,079]\u001b[0m Trial 1004 finished with value: 1.3904600655077999 and parameters: {'n_hidden': 3, 'learning_rate': 0.006976144480195489, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00022395358749827793, 'dropout_rate_Layer_2': 0.1908008236301957, 'dropout_rate_Layer_3': 0.28708142121417785, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.021647955615631678, 'l1_Layer_2': 0.04513048569598196, 'l1_Layer_3': 0.0007887823130139127, 'n_units_Layer_1': 295, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:33:42,870]\u001b[0m Trial 1002 finished with value: 1.4882784624206284 and parameters: {'n_hidden': 3, 'learning_rate': 0.016749810867590777, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04545308601273949, 'dropout_rate_Layer_2': 0.21288056143657497, 'dropout_rate_Layer_3': 0.010775304898184693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.051851430572997965, 'l1_Layer_2': 0.053383836615584636, 'l1_Layer_3': 0.000799534418497226, 'n_units_Layer_1': 275, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.49 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:33:45,161]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:46,838]\u001b[0m Trial 992 finished with value: 1.4627363072382893 and parameters: {'n_hidden': 3, 'learning_rate': 0.004207429886609259, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2967578768413893, 'dropout_rate_Layer_2': 0.20763395440618992, 'dropout_rate_Layer_3': 0.26045205923536235, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.021943764555419885, 'l1_Layer_2': 0.06097774196006154, 'l1_Layer_3': 0.0009691419050352001, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 285}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 9.05 | sMAPE for Test Set is: 22.64% | rMAE for Test Set is: 1.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:33:48,745]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:56,636]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:57,198]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:33:58,530]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:01,113]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:02,066]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:08,517]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:11,990]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:12,731]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:13,973]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:18,663]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:22,281]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:28,480]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:29,677]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:34,455]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:34,854]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:41,369]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:43,581]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:48,685]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:49,185]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:54,678]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:34:55,432]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:00,110]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:04,931]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:08,290]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:11,546]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:13,808]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:15,264]\u001b[0m Trial 1026 finished with value: 1.4780734156052715 and parameters: {'n_hidden': 3, 'learning_rate': 0.001833566360266209, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00012698467533293553, 'dropout_rate_Layer_2': 0.3119640258447922, 'dropout_rate_Layer_3': 0.017829818800573605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00029930947349356835, 'l1_Layer_2': 0.016988572409790646, 'l1_Layer_3': 0.0005792857137029688, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 18.76% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:35:15,895]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:20,339]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:25,983]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:26,579]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:31,803]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:33,543]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:38,644]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:38,967]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:44,328]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:46,635]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:48,838]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:52,685]\u001b[0m Trial 1032 finished with value: 1.4974818653589743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018843830503138313, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00013919619562483725, 'dropout_rate_Layer_2': 0.24443049199839179, 'dropout_rate_Layer_3': 0.014893701052869704, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0003038769958156607, 'l1_Layer_2': 0.09855909644817136, 'l1_Layer_3': 0.0005710627358207154, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 5.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 15.85% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:35:55,087]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:58,482]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:35:59,658]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:05,996]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:09,580]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:26,152]\u001b[0m Trial 1039 finished with value: 1.4187588875253774 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016014645679195123, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0004722151122571476, 'dropout_rate_Layer_2': 0.3228254353271044, 'dropout_rate_Layer_3': 0.03971589414271215, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004258516349908932, 'l1_Layer_2': 0.06123404509171762, 'l1_Layer_3': 0.00036353121932720066, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.86 | sMAPE for Test Set is: 14.65% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:36:28,749]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:32,367]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:33,139]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:37,531]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:41,956]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:44,804]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:50,022]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:53,824]\u001b[0m Trial 1053 finished with value: 1.4307317774344648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018006506576954237, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013177657127623503, 'dropout_rate_Layer_2': 0.3152039498839308, 'dropout_rate_Layer_3': 0.042095406658299514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009232816541324958, 'l1_Layer_2': 0.09319374003414106, 'l1_Layer_3': 0.0005817532091195667, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 14.83% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:36:56,199]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:36:59,254]\u001b[0m Trial 1056 finished with value: 1.4158051209831595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017829812247994424, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006996666404257617, 'dropout_rate_Layer_2': 0.32277898279577627, 'dropout_rate_Layer_3': 0.01158891845393251, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012263972522841369, 'l1_Layer_2': 0.09835436301753651, 'l1_Layer_3': 0.0005277317038644506, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 165}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.16 | sMAPE for Test Set is: 15.39% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:37:01,306]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:05,025]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:06,038]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:10,599]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:12,925]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:16,522]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:21,842]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:22,461]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:27,514]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:29,839]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:31,456]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:35,748]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:40,935]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:44,808]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:50,106]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:37:58,453]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:03,787]\u001b[0m Trial 1072 finished with value: 1.426136604767272 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047082659325842595, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020649986135139846, 'dropout_rate_Layer_2': 0.18999717677718117, 'dropout_rate_Layer_3': 0.02925577489873349, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.029728875732123995, 'l1_Layer_2': 0.039451784010446675, 'l1_Layer_3': 0.001680787726060904, 'n_units_Layer_1': 290, 'n_units_Layer_2': 235, 'n_units_Layer_3': 275}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:38:04,220]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:11,036]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:14,740]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:15,318]\u001b[0m Trial 1066 finished with value: 1.4096150805475105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016104588535436717, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 7.555374896545321e-05, 'dropout_rate_Layer_2': 0.33847817202662456, 'dropout_rate_Layer_3': 0.037198095308943094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001281857434679485, 'l1_Layer_2': 0.05995490491871602, 'l1_Layer_3': 0.00036438544322200023, 'n_units_Layer_1': 100, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 14.27% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:38:25,542]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:25,696]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:35,241]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:35,508]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:41,931]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:42,702]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:48,979]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:56,736]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:38:59,189]\u001b[0m Trial 1077 finished with value: 1.414467384917332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012371610295566198, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02296472555108839, 'dropout_rate_Layer_2': 0.31099120613166864, 'dropout_rate_Layer_3': 0.04498194758744495, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0011506126097789284, 'l1_Layer_2': 0.09128603824187376, 'l1_Layer_3': 0.0005960132475654191, 'n_units_Layer_1': 100, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.01 | sMAPE for Test Set is: 15.03% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:39:09,012]\u001b[0m Trial 1093 finished with value: 1.3948934676971294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038055925011784603, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34956306799713727, 'dropout_rate_Layer_2': 0.041232689305516615, 'dropout_rate_Layer_3': 0.1819403021864337, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009977934204920965, 'l1_Layer_2': 0.001379842925703493, 'l1_Layer_3': 0.0003116737423633705, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 205}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:39:12,844]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:39:24,757]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:39:31,636]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:39:39,775]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:39:43,893]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:39:47,165]\u001b[0m Trial 1084 finished with value: 1.4101929280833378 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012943804802924251, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020802202049332117, 'dropout_rate_Layer_2': 0.31337539524637803, 'dropout_rate_Layer_3': 0.0703722375967458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0005679351243259906, 'l1_Layer_2': 0.09941839454072184, 'l1_Layer_3': 0.0005654072268724057, 'n_units_Layer_1': 100, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.15 | sMAPE for Test Set is: 15.36% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:40:02,717]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:06,805]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:11,311]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:15,825]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:31,284]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:34,619]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:37,120]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:40,631]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:45,222]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:40:56,528]\u001b[0m Trial 1099 finished with value: 1.4001207793624708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012490333764962622, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022291977354410547, 'dropout_rate_Layer_2': 0.3520048569390712, 'dropout_rate_Layer_3': 0.042341951217187625, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0012292519881852032, 'l1_Layer_2': 0.09102274715244478, 'l1_Layer_3': 0.00027777188640496793, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.71 | sMAPE for Test Set is: 14.31% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:41:01,435]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:02,402]\u001b[0m Trial 1096 finished with value: 1.411427126135018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013054429142537523, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02106576619231036, 'dropout_rate_Layer_2': 0.3099588064526421, 'dropout_rate_Layer_3': 0.03966825966926842, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0011005362494145477, 'l1_Layer_2': 0.08840365914749475, 'l1_Layer_3': 0.00021144402790120834, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.13 | sMAPE for Test Set is: 15.33% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:41:06,924]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:08,058]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:11,596]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:12,318]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:14,922]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:19,070]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:24,790]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:25,807]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:31,612]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:33,612]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:36,055]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:38,281]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:40,619]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:41,288]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:41,289]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:41,803]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:49,936]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:52,345]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:53,200]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:58,748]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:41:59,734]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:01,551]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:06,359]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:09,542]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:12,412]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:13,627]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:26,240]\u001b[0m Trial 1129 finished with value: 1.4837140595402352 and parameters: {'n_hidden': 3, 'learning_rate': 0.010395770877885867, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04330837243254356, 'dropout_rate_Layer_2': 0.20803755271343807, 'dropout_rate_Layer_3': 0.24304661251479348, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.011822356164346208, 'l1_Layer_2': 0.02955584222267254, 'l1_Layer_3': 0.0016521526072685105, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 5.16% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 8.48 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:42:37,777]\u001b[0m Trial 1137 finished with value: 1.472799697002219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017864112198397832, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0012323383482211042, 'dropout_rate_Layer_2': 0.3666862222997735, 'dropout_rate_Layer_3': 0.01960397240087184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0028126371725295096, 'l1_Layer_2': 0.06061432701287991, 'l1_Layer_3': 0.0002816323007342026, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.47 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 18.54% | rMAE for Test Set is: 1.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:42:42,541]\u001b[0m Trial 1143 finished with value: 1.42415188350713 and parameters: {'n_hidden': 3, 'learning_rate': 0.010382998555177003, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04166358481742294, 'dropout_rate_Layer_2': 0.19696088967720085, 'dropout_rate_Layer_3': 0.2227440093077316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.009820001304853202, 'l1_Layer_2': 0.026095714060107335, 'l1_Layer_3': 0.0013530704122442878, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.52 | sMAPE for Test Set is: 21.21% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:42:45,939]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:49,067]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:42:55,778]\u001b[0m Trial 1141 finished with value: 1.4472302022592978 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017590201495829348, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0001279403457523098, 'dropout_rate_Layer_2': 0.3218022587140802, 'dropout_rate_Layer_3': 0.019999894636765207, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008766208303196153, 'l1_Layer_2': 0.08005833735251973, 'l1_Layer_3': 0.00028618856822457903, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 17.64% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:43:00,192]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:04,338]\u001b[0m Trial 1146 finished with value: 1.5583403595244192 and parameters: {'n_hidden': 3, 'learning_rate': 0.006250273456345761, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2070176356870623, 'dropout_rate_Layer_2': 0.31038173665566277, 'dropout_rate_Layer_3': 0.08232342050269943, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002202229705615567, 'l1_Layer_2': 0.0011286257022300734, 'l1_Layer_3': 0.00028096233177107166, 'n_units_Layer_1': 200, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.56 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 16.30% | rMAE for Test Set is: 1.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:43:08,663]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:13,557]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:19,854]\u001b[0m Trial 1148 finished with value: 1.4166179938911283 and parameters: {'n_hidden': 3, 'learning_rate': 0.008519768758159503, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03825959652799724, 'dropout_rate_Layer_2': 0.1848749866061487, 'dropout_rate_Layer_3': 0.23293008925389055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010040454147212944, 'l1_Layer_2': 0.02507981388133302, 'l1_Layer_3': 0.0013719026667735003, 'n_units_Layer_1': 280, 'n_units_Layer_2': 210, 'n_units_Layer_3': 300}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 20.60% | rMAE for Test Set is: 1.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:43:24,364]\u001b[0m Trial 1149 finished with value: 1.445686453867225 and parameters: {'n_hidden': 3, 'learning_rate': 0.010921340333298614, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04834859304927205, 'dropout_rate_Layer_2': 0.1848980337193866, 'dropout_rate_Layer_3': 0.21868118686095556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.008320778202149076, 'l1_Layer_2': 0.026099237437510144, 'l1_Layer_3': 0.0013759790571478716, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.56 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:43:34,204]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:37,901]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:44,456]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:47,338]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:49,798]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:43:54,100]\u001b[0m Trial 1147 finished with value: 1.408904249148662 and parameters: {'n_hidden': 3, 'learning_rate': 0.001056803638574981, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017626923808293005, 'dropout_rate_Layer_2': 0.32288394282019317, 'dropout_rate_Layer_3': 0.03002116664239577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.003571209432737886, 'l1_Layer_2': 0.056068962725729185, 'l1_Layer_3': 0.0005706079007652847, 'n_units_Layer_1': 100, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.98 | sMAPE for Test Set is: 14.93% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:43:59,342]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:02,027]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:14,183]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:24,017]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:34,593]\u001b[0m Trial 1152 finished with value: 1.4428228575779294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013186509558386946, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002061161728840013, 'dropout_rate_Layer_2': 0.37410746630270986, 'dropout_rate_Layer_3': 0.017550968246804136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.002079634107544961, 'l1_Layer_2': 0.061667559831171004, 'l1_Layer_3': 0.0003940488295336613, 'n_units_Layer_1': 105, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.31 | sMAPE for Test Set is: 13.34% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:44:45,974]\u001b[0m Trial 1161 finished with value: 1.443581221010432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016323858022458029, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016161111279786606, 'dropout_rate_Layer_2': 0.3212812356591675, 'dropout_rate_Layer_3': 0.05209251887306586, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0014234404078751035, 'l1_Layer_2': 0.08436937187864385, 'l1_Layer_3': 0.0005701764042903182, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 15.99% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:44:48,891]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:51,885]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:53,224]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:44:55,407]\u001b[0m Trial 1165 finished with value: 1.410121438507705 and parameters: {'n_hidden': 3, 'learning_rate': 0.009907357364735726, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05570826827289698, 'dropout_rate_Layer_2': 0.1920707759071636, 'dropout_rate_Layer_3': 0.2165527052013835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01149677766194375, 'l1_Layer_2': 0.028281244097208155, 'l1_Layer_3': 0.0014745754796503115, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 21.85% | rMAE for Test Set is: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:44:59,183]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:00,034]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:01,484]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:06,526]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:07,637]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:17,010]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:18,131]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:19,153]\u001b[0m Trial 1172 finished with value: 1.4490339055496444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0095389194106342, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05277858429468295, 'dropout_rate_Layer_2': 0.1895514121420767, 'dropout_rate_Layer_3': 0.2284375875810358, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0069283641563716945, 'l1_Layer_2': 0.013298876941250183, 'l1_Layer_3': 0.0017524816693484959, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.59 | sMAPE for Test Set is: 24.09% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:45:24,125]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:24,426]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:28,942]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:29,139]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:34,613]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:37,453]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:40,408]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:45,699]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:46,133]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:51,096]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:57,290]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:45:58,177]\u001b[0m Trial 1162 finished with value: 1.3968708144441884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012692420253253415, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025209739365774468, 'dropout_rate_Layer_2': 0.3729037207287797, 'dropout_rate_Layer_3': 0.05162243076447202, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004033368803815616, 'l1_Layer_2': 0.08487282429849255, 'l1_Layer_3': 0.0001476324960627681, 'n_units_Layer_1': 100, 'n_units_Layer_2': 260, 'n_units_Layer_3': 160}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.18 | sMAPE for Test Set is: 13.00% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:46:02,793]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:06,039]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:10,614]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:13,184]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:14,548]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:20,011]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:23,944]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:24,488]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:29,281]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:32,679]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 18.17% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:46:34,457]\u001b[0m Trial 1180 finished with value: 1.4104890757654853 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013629407065181335, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01502780909618582, 'dropout_rate_Layer_2': 0.32179598064667575, 'dropout_rate_Layer_3': 0.03579204828626798, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0023612489361723708, 'l1_Layer_2': 0.09693967373512068, 'l1_Layer_3': 0.00016208406777566548, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1004 with value: 1.3904600655077999.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:35,135]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:41,481]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:43,506]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:46,938]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:49,787]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:50,890]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:46:55,950]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:01,873]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:10,724]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:13,954]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:17,081]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:20,609]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:21,637]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:24,355]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:26,968]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:28,566]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:31,923]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:32,176]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:43,384]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:47:57,603]\u001b[0m Trial 1220 finished with value: 1.3899595485364038 and parameters: {'n_hidden': 3, 'learning_rate': 0.009175732719338171, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06358371848407275, 'dropout_rate_Layer_2': 0.19305024112356273, 'dropout_rate_Layer_3': 0.2304615736942156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.012864817908669323, 'l1_Layer_2': 0.016317160169423518, 'l1_Layer_3': 0.0011652978224411888, 'n_units_Layer_1': 285, 'n_units_Layer_2': 295, 'n_units_Layer_3': 300}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.81% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.27 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 1.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:48:04,584]\u001b[0m Trial 1216 finished with value: 1.5527418860554476 and parameters: {'n_hidden': 3, 'learning_rate': 0.003274701534940712, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21079357502788015, 'dropout_rate_Layer_2': 0.009630106803877445, 'dropout_rate_Layer_3': 0.21810209701369926, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014531434124258607, 'l1_Layer_2': 0.000877428341198521, 'l1_Layer_3': 0.010275425081301328, 'n_units_Layer_1': 195, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 11.36 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 2.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:48:06,952]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:08,862]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:14,154]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:14,734]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:21,497]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:26,360]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:27,223]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:31,636]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:33,350]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:34,689]\u001b[0m Trial 1219 finished with value: 1.4262808765290613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016774279525422476, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010349441658482651, 'dropout_rate_Layer_2': 0.3185785035496991, 'dropout_rate_Layer_3': 0.03801125176873703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0025639392277962752, 'l1_Layer_2': 0.06352570328975772, 'l1_Layer_3': 8.695814797569561e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 18.09% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:48:39,229]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:42,241]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:45,358]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:48,353]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:51,133]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:48:56,040]\u001b[0m Trial 1231 finished with value: 1.4003078407415466 and parameters: {'n_hidden': 3, 'learning_rate': 0.008806597495906723, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08515523764154097, 'dropout_rate_Layer_2': 0.1919983939968625, 'dropout_rate_Layer_3': 0.2367231276282337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.01183549687357969, 'l1_Layer_2': 0.010048412615915958, 'l1_Layer_3': 0.0010303037155040729, 'n_units_Layer_1': 285, 'n_units_Layer_2': 290, 'n_units_Layer_3': 295}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.21 | sMAPE for Test Set is: 23.05% | rMAE for Test Set is: 1.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:48:59,252]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:02,541]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:04,724]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:09,689]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:13,627]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:15,667]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:19,787]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:25,807]\u001b[0m Trial 1225 finished with value: 1.4085131585531396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016700757883816998, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008565844515460969, 'dropout_rate_Layer_2': 0.3874247846567019, 'dropout_rate_Layer_3': 0.030203202439745367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001280346522404969, 'l1_Layer_2': 0.08557838323590802, 'l1_Layer_3': 0.00025930511272756403, 'n_units_Layer_1': 95, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.06 | sMAPE for Test Set is: 15.09% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:49:33,054]\u001b[0m Trial 1243 finished with value: 1.4051005981310343 and parameters: {'n_hidden': 3, 'learning_rate': 0.007420882178126282, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09170722510634279, 'dropout_rate_Layer_2': 0.31413842774116846, 'dropout_rate_Layer_3': 0.2395248192682305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010476777895756814, 'l1_Layer_2': 0.00948156684101543, 'l1_Layer_3': 0.0010590696811578826, 'n_units_Layer_1': 290, 'n_units_Layer_2': 285, 'n_units_Layer_3': 300}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 22.23% | rMAE for Test Set is: 1.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:49:42,982]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:49,856]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:53,070]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:53,365]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:59,130]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:49:59,954]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:02,442]\u001b[0m Trial 1244 finished with value: 1.4446849108541482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016956818002535265, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035185565649382036, 'dropout_rate_Layer_2': 0.38402608003782857, 'dropout_rate_Layer_3': 0.019362992887128144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0014263386511710863, 'l1_Layer_2': 0.07787448383617362, 'l1_Layer_3': 0.0007712321388011591, 'n_units_Layer_1': 110, 'n_units_Layer_2': 240, 'n_units_Layer_3': 135}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 17.54% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:50:07,264]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:07,474]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:12,328]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:12,463]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:16,864]\u001b[0m Trial 1253 finished with value: 1.3969617749681242 and parameters: {'n_hidden': 3, 'learning_rate': 0.008229756598253849, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07640809081295344, 'dropout_rate_Layer_2': 0.17949262733431542, 'dropout_rate_Layer_3': 0.2419965772514419, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.006707418630032839, 'l1_Layer_2': 0.008438700606420274, 'l1_Layer_3': 0.0010227024490736267, 'n_units_Layer_1': 275, 'n_units_Layer_2': 295, 'n_units_Layer_3': 290}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.83% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 20.99% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:50:18,993]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:19,583]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:26,717]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:27,555]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:31,363]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:31,869]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:32,231]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:38,974]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:41,186]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:43,077]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:45,244]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:47,317]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:50,763]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:53,139]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:54,066]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:58,436]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:50:58,693]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:05,756]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:10,265]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:13,471]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:18,361]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:21,282]\u001b[0m Trial 1259 finished with value: 1.4251666015220088 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012983563427932973, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02463928279821031, 'dropout_rate_Layer_2': 0.3841165161540663, 'dropout_rate_Layer_3': 0.04274487596433244, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0008706083990884104, 'l1_Layer_2': 0.09766562615821482, 'l1_Layer_3': 0.0007779083505746796, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 130}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:51:24,984]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:29,222]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:41,300]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:42,148]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:49,776]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:52,801]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:51:59,154]\u001b[0m Trial 1275 finished with value: 1.4618874817320755 and parameters: {'n_hidden': 3, 'learning_rate': 0.001452148519555364, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03509049482457481, 'dropout_rate_Layer_2': 0.39875982152502615, 'dropout_rate_Layer_3': 0.03462975452740419, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0011089649067228462, 'l1_Layer_2': 0.08493794976059761, 'l1_Layer_3': 0.0007105981260120589, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 140}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 1.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:52:00,049]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:03,619]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:05,841]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:09,051]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:09,508]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:14,062]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:14,199]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:16,156]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:20,667]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:20,805]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:21,446]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:27,532]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:28,557]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:33,280]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:33,556]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:39,472]\u001b[0m Trial 1283 finished with value: 1.4136092059261527 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014676495956724692, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03398056224923098, 'dropout_rate_Layer_2': 0.39833214927110305, 'dropout_rate_Layer_3': 0.03197735151647789, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001099143911862212, 'l1_Layer_2': 0.09876173943107669, 'l1_Layer_3': 0.0004807337889461741, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 16.42% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:52:42,487]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:45,421]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:49,150]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:52,052]\u001b[0m Trial 1303 finished with value: 1.4081977852407561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0080185656809423, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08965498328998531, 'dropout_rate_Layer_2': 0.18686149234026778, 'dropout_rate_Layer_3': 0.2052888299259526, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.010931030728535329, 'l1_Layer_2': 0.01225572974586994, 'l1_Layer_3': 0.0008643789535432534, 'n_units_Layer_1': 285, 'n_units_Layer_2': 285, 'n_units_Layer_3': 285}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.46 | sMAPE for Test Set is: 21.04% | rMAE for Test Set is: 1.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:52:54,247]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:54,495]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:58,835]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:59,666]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:52:59,800]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:06,311]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:09,208]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:12,086]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:14,660]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:21,181]\u001b[0m Trial 1311 finished with value: 1.5260792879907334 and parameters: {'n_hidden': 3, 'learning_rate': 0.003537436031356484, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19789911516471909, 'dropout_rate_Layer_2': 0.2938868108612677, 'dropout_rate_Layer_3': 0.19782684989689617, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031286199823999227, 'l1_Layer_2': 0.0004677885432357688, 'l1_Layer_3': 0.00012016757694571362, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 14.67% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:53:22,179]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:27,984]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:29,970]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:33,403]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:37,201]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:40,410]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:40,573]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:46,192]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:53:49,712]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:01,867]\u001b[0m Trial 1326 finished with value: 1.4292052998178721 and parameters: {'n_hidden': 3, 'learning_rate': 0.007736380271130686, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06405152959828456, 'dropout_rate_Layer_2': 0.3191371434482916, 'dropout_rate_Layer_3': 0.19734300264055774, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008930694461497954, 'l1_Layer_2': 0.02123871803010631, 'l1_Layer_3': 0.002302067134449421, 'n_units_Layer_1': 270, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 24.74% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:54:04,830]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:09,507]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:14,842]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:18,077]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:18,937]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:37,736]\u001b[0m Trial 1324 finished with value: 1.4396452297445113 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014637010289600431, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031059350728695756, 'dropout_rate_Layer_2': 0.29099667890657405, 'dropout_rate_Layer_3': 0.04840669195779772, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0007968042514187925, 'l1_Layer_2': 0.08565447149370849, 'l1_Layer_3': 0.0004981034397608565, 'n_units_Layer_1': 120, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 17.28% | rMAE for Test Set is: 1.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:54:40,873]\u001b[0m Trial 1302 finished with value: 1.392645322242041 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013053449814959962, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007758540530021127, 'dropout_rate_Layer_2': 0.36594795640231054, 'dropout_rate_Layer_3': 0.04163263433137585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0073509991390029025, 'l1_Layer_2': 0.08180137917607794, 'l1_Layer_3': 0.0006740648737635828, 'n_units_Layer_1': 90, 'n_units_Layer_2': 255, 'n_units_Layer_3': 130}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 4.82% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 5.20 | sMAPE for Test Set is: 13.06% | rMAE for Test Set is: 1.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:54:41,146]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:42,003]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:42,302]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:48,492]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:51,797]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:52,952]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:54,127]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:54:55,624]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:01,260]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:01,706]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:06,607]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:08,926]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:09,854]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:11,301]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:22,251]\u001b[0m Trial 1338 finished with value: 1.4310375050947874 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015957150777642897, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15438923342382588, 'dropout_rate_Layer_2': 0.07831499630008774, 'dropout_rate_Layer_3': 0.21809502713644185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0025739451802207765, 'l1_Layer_2': 0.00025877928611160283, 'l1_Layer_3': 1.4619566699778233e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 225, 'n_units_Layer_3': 160}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.57 | sMAPE for Test Set is: 13.91% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:55:25,955]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:36,850]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:39,733]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:43,333]\u001b[0m Trial 1350 finished with value: 1.429548704042559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016018273839753009, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12083536748615763, 'dropout_rate_Layer_2': 0.08026642655259736, 'dropout_rate_Layer_3': 0.2330181673001995, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0024053880780772912, 'l1_Layer_2': 0.0002507053992884582, 'l1_Layer_3': 1.105859651397456e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 220, 'n_units_Layer_3': 160}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.74 | sMAPE for Test Set is: 14.35% | rMAE for Test Set is: 1.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:55:49,772]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:55:59,326]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:02,397]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:05,452]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:09,118]\u001b[0m Trial 1355 finished with value: 1.5121041719518338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014417755178773458, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16014358419052094, 'dropout_rate_Layer_2': 0.08574837805523551, 'dropout_rate_Layer_3': 0.23724778665486124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003291582424617849, 'l1_Layer_2': 0.0001179630475342869, 'l1_Layer_3': 1.4660762701896918e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 105}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.51 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.79 | sMAPE for Test Set is: 14.46% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:56:15,416]\u001b[0m Trial 1349 finished with value: 1.4315026069619803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015075966821869163, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03870925043950511, 'dropout_rate_Layer_2': 0.3040718972774027, 'dropout_rate_Layer_3': 0.058640366380418696, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0015851539534475643, 'l1_Layer_2': 0.08129524366651279, 'l1_Layer_3': 0.0005211485642560638, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 130}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 15.52% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:56:18,263]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:26,275]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:30,878]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:36,535]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:52,759]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:53,282]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:56:57,601]\u001b[0m Trial 1351 finished with value: 1.4252594682846211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014829027991951692, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028259731895948128, 'dropout_rate_Layer_2': 0.29128499337112723, 'dropout_rate_Layer_3': 0.02815188517508807, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0011190225616897944, 'l1_Layer_2': 0.08124143875612813, 'l1_Layer_3': 0.00035073066034151573, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 125}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.97 | sMAPE for Test Set is: 14.87% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:56:57,784]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:03,308]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:06,416]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:06,760]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:11,638]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:15,050]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:18,340]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:18,809]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:21,235]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:25,767]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:27,507]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:28,254]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:33,471]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:36,346]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:39,220]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:39,666]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:44,715]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:47,020]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:51,392]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:57:54,635]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:00,485]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:03,711]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:06,708]\u001b[0m Trial 1378 finished with value: 1.4300694311131312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016287627053720134, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04371200522506201, 'dropout_rate_Layer_2': 0.2942561530800408, 'dropout_rate_Layer_3': 0.02277377376320981, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009665647477801144, 'l1_Layer_2': 0.06291106137514534, 'l1_Layer_3': 0.0002663620521222143, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.43 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.26 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 1.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:58:07,495]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:10,964]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:14,158]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:16,560]\u001b[0m Trial 1366 finished with value: 1.4181527379371601 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015953127018194604, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018669973019823517, 'dropout_rate_Layer_2': 0.30734895139026874, 'dropout_rate_Layer_3': 0.02807277759954214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.004190729862589842, 'l1_Layer_2': 0.06189485536522346, 'l1_Layer_3': 0.0005078344777885748, 'n_units_Layer_1': 110, 'n_units_Layer_2': 250, 'n_units_Layer_3': 120}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.54 | sMAPE for Test Set is: 13.86% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:58:17,490]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:17,956]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:17,957]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:26,304]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:26,711]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:27,155]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:28,336]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:35,411]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:37,555]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:38,574]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:39,089]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:39,227]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:41,635]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:46,304]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:47,805]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:49,245]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:55,422]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:59,072]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:58:59,549]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:04,316]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:07,356]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:07,539]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:12,962]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:13,202]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:18,789]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:21,711]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:25,145]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:26,031]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:32,940]\u001b[0m Trial 1415 finished with value: 1.5316683035589465 and parameters: {'n_hidden': 3, 'learning_rate': 0.001658548495385539, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08788816904530647, 'dropout_rate_Layer_2': 0.06945885918976435, 'dropout_rate_Layer_3': 0.21946887308229182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029252800605125123, 'l1_Layer_2': 0.0004801738002498617, 'l1_Layer_3': 1.7652136655661023e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.53 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.93 | sMAPE for Test Set is: 14.85% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 14:59:36,150]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:39,922]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 14:59:55,760]\u001b[0m Trial 1424 finished with value: 1.4085937446455716 and parameters: {'n_hidden': 3, 'learning_rate': 0.01022143360373344, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03128147485973859, 'dropout_rate_Layer_2': 0.17510227471420414, 'dropout_rate_Layer_3': 0.24696910177072584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.012333143776797683, 'l1_Layer_2': 0.014154023410651887, 'l1_Layer_3': 0.0016428714703908996, 'n_units_Layer_1': 290, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.41 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 1.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:00:00,663]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:05,664]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:06,869]\u001b[0m Trial 1421 finished with value: 1.4372719786198225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016909999916329167, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02463638458321336, 'dropout_rate_Layer_2': 0.2991630225983818, 'dropout_rate_Layer_3': 0.03503129204368599, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0011437251849888812, 'l1_Layer_2': 0.08782478217261065, 'l1_Layer_3': 0.00044532121376380417, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:00:11,343]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:16,724]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:19,963]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:22,955]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:23,156]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:24,791]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:29,882]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:31,566]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:37,662]\u001b[0m Trial 1414 finished with value: 1.4438192344910608 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008959932730784946, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016080414328460618, 'dropout_rate_Layer_2': 0.29894108939346153, 'dropout_rate_Layer_3': 0.06773919588798819, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001157745759051877, 'l1_Layer_2': 0.09900188029912756, 'l1_Layer_3': 0.0006356270905463773, 'n_units_Layer_1': 85, 'n_units_Layer_2': 270, 'n_units_Layer_3': 130}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.44 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 15.73% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:00:38,599]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:45,234]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:54,547]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:00:56,278]\u001b[0m Trial 1436 finished with value: 1.5153451958626123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015656608634617864, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22522252219541503, 'dropout_rate_Layer_2': 0.046882354536719004, 'dropout_rate_Layer_3': 0.22100507917067486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002646837283614753, 'l1_Layer_2': 0.00038620814215052076, 'l1_Layer_3': 1.9736601659122807e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.52 | sMAPE for Validation Set is: 5.27% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 5.90 | sMAPE for Test Set is: 14.74% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:00:59,706]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:00,468]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:04,736]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:07,799]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:08,091]\u001b[0m Trial 1435 finished with value: 1.4505182857442394 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015754469893247722, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09914036608388647, 'dropout_rate_Layer_2': 0.06962341343255896, 'dropout_rate_Layer_3': 0.2516458835014992, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005106960737018708, 'l1_Layer_2': 0.00033009986225032955, 'l1_Layer_3': 1.075480355042019e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.45 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 5.80 | sMAPE for Test Set is: 14.48% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:01:10,321]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:14,649]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:18,240]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:18,402]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:22,495]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:26,095]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:29,928]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:30,289]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:34,803]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:39,226]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:41,990]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:46,291]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:49,431]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:52,827]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:53,261]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:01:53,321]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:01,193]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:07,804]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:11,216]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:11,288]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:14,749]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:18,876]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:22,045]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:22,509]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:23,281]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:29,192]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:30,477]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:30,890]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:38,562]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:38,848]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:44,812]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:44,950]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:02:53,261]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:02,408]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:03,887]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:08,188]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:08,723]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:13,485]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:13,943]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:17,527]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:18,219]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:18,954]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:24,786]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:29,121]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:29,461]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:35,095]\u001b[0m Trial 1461 finished with value: 1.401689316484959 and parameters: {'n_hidden': 3, 'learning_rate': 0.002135544434330219, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007477199080936302, 'dropout_rate_Layer_2': 0.2928823716228993, 'dropout_rate_Layer_3': 0.0407863911436231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00201954998649497, 'l1_Layer_2': 0.0748504568517897, 'l1_Layer_3': 0.00025301166190973447, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 110}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.40 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.25 | sMAPE for Test Set is: 15.51% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:03:38,091]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:38,860]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:43,985]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:45,405]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:49,003]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:49,746]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:54,784]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:03:54,967]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:04:01,250]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:04:06,988]\u001b[0m Trial 1492 finished with value: 1.420764241316243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018606812715949053, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006826722220019335, 'dropout_rate_Layer_2': 0.3259844340945787, 'dropout_rate_Layer_3': 0.03901174496862025, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.001654279054423258, 'l1_Layer_2': 0.056507394109125614, 'l1_Layer_3': 0.0005449603864634821, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 1220 with value: 1.3899595485364038.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.42 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 5.89 | sMAPE for Test Set is: 14.72% | rMAE for Test Set is: 1.18\n",
      "for 2018-01-01, MAE is:0.76 & sMAPE is:2.96% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :0.76 & 2.96% & 2.31\n",
      "for 2018-01-02, MAE is:4.75 & sMAPE is:14.92% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 8.94% & 1.57\n",
      "for 2018-01-03, MAE is:0.88 & sMAPE is:3.02% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 6.97% & 1.16\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000016278271820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:3.87 & sMAPE is:12.03% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 8.23% & 1.52\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000161ACB1FC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:1.99 & sMAPE is:6.36% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 7.86% & 1.37\n",
      "for 2018-01-06, MAE is:1.28 & sMAPE is:3.98% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 7.21% & 1.19\n",
      "for 2018-01-07, MAE is:1.54 & sMAPE is:5.29% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 6.94% & 1.14\n",
      "for 2018-01-08, MAE is:3.95 & sMAPE is:11.85% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 7.55% & 1.08\n",
      "for 2018-01-09, MAE is:1.21 & sMAPE is:3.94% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 7.15% & 1.01\n",
      "for 2018-01-10, MAE is:9.80 & sMAPE is:25.42% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 8.98% & 0.99\n",
      "for 2018-01-11, MAE is:10.80 & sMAPE is:25.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.71 & 10.47% & 0.99\n",
      "for 2018-01-12, MAE is:4.69 & sMAPE is:12.89% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 10.67% & 0.99\n",
      "for 2018-01-13, MAE is:1.06 & sMAPE is:3.26% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 10.10% & 1.03\n",
      "for 2018-01-14, MAE is:1.05 & sMAPE is:3.48% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :3.40 & 9.63% & 1.01\n",
      "for 2018-01-15, MAE is:0.98 & sMAPE is:3.24% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 9.20% & 0.96\n",
      "for 2018-01-16, MAE is:3.06 & sMAPE is:9.24% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 9.20% & 1.01\n",
      "for 2018-01-17, MAE is:3.77 & sMAPE is:10.90% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 9.30% & 0.99\n",
      "for 2018-01-18, MAE is:5.04 & sMAPE is:14.18% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 9.57% & 0.97\n",
      "for 2018-01-19, MAE is:7.64 & sMAPE is:19.51% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 10.10% & 1.02\n",
      "for 2018-01-20, MAE is:2.73 & sMAPE is:8.35% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 10.01% & 1.07\n",
      "for 2018-01-21, MAE is:0.92 & sMAPE is:2.89% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 9.67% & 1.05\n",
      "for 2018-01-22, MAE is:8.16 & sMAPE is:21.36% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 10.20% & 1.04\n",
      "for 2018-01-23, MAE is:3.67 & sMAPE is:10.25% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 10.20% & 1.03\n",
      "for 2018-01-24, MAE is:1.71 & sMAPE is:5.87% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 10.02% & 1.00\n",
      "for 2018-01-25, MAE is:2.04 & sMAPE is:6.92% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 9.90% & 0.98\n",
      "for 2018-01-26, MAE is:2.33 & sMAPE is:7.22% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :3.45 & 9.80% & 0.95\n",
      "for 2018-01-27, MAE is:1.06 & sMAPE is:3.44% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 9.56% & 0.95\n",
      "for 2018-01-28, MAE is:1.12 & sMAPE is:3.91% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 9.36% & 0.92\n",
      "for 2018-01-29, MAE is:1.22 & sMAPE is:4.13% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.21 & 9.18% & 0.90\n",
      "for 2018-01-30, MAE is:2.97 & sMAPE is:9.01% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 9.17% & 0.89\n",
      "for 2018-01-31, MAE is:2.23 & sMAPE is:7.28% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 9.11% & 0.92\n",
      "for 2018-02-01, MAE is:1.44 & sMAPE is:4.70% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.97% & 0.93\n",
      "for 2018-02-02, MAE is:4.86 & sMAPE is:13.80% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.17 & 9.12% & 0.95\n",
      "for 2018-02-03, MAE is:2.63 & sMAPE is:7.70% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 9.08% & 0.94\n",
      "for 2018-02-04, MAE is:1.84 & sMAPE is:5.27% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 8.97% & 0.93\n",
      "for 2018-02-05, MAE is:11.62 & sMAPE is:26.95% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :3.35 & 9.47% & 0.92\n",
      "for 2018-02-06, MAE is:12.03 & sMAPE is:26.38% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.59 & 9.93% & 0.92\n",
      "for 2018-02-07, MAE is:10.38 & sMAPE is:23.11% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 10.27% & 0.91\n",
      "for 2018-02-08, MAE is:6.01 & sMAPE is:13.44% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.82 & 10.35% & 0.91\n",
      "for 2018-02-09, MAE is:0.61 & sMAPE is:1.89% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :3.74 & 10.14% & 0.89\n",
      "for 2018-02-10, MAE is:1.20 & sMAPE is:3.80% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 9.99% & 0.88\n",
      "for 2018-02-11, MAE is:1.36 & sMAPE is:4.46% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 9.86% & 0.87\n",
      "for 2018-02-12, MAE is:0.96 & sMAPE is:3.04% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :3.56 & 9.70% & 0.85\n",
      "for 2018-02-13, MAE is:5.66 & sMAPE is:15.02% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 9.82% & 0.84\n",
      "for 2018-02-14, MAE is:3.66 & sMAPE is:9.62% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.61 & 9.81% & 0.83\n",
      "for 2018-02-15, MAE is:0.83 & sMAPE is:2.50% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.66% & 0.82\n",
      "for 2018-02-16, MAE is:3.01 & sMAPE is:8.15% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 9.62% & 0.82\n",
      "for 2018-02-17, MAE is:5.36 & sMAPE is:14.59% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.73% & 0.82\n",
      "for 2018-02-18, MAE is:2.14 & sMAPE is:5.71% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :3.55 & 9.64% & 0.81\n",
      "for 2018-02-19, MAE is:5.30 & sMAPE is:12.75% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 9.71% & 0.80\n",
      "for 2018-02-20, MAE is:10.90 & sMAPE is:26.65% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 10.04% & 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-21, MAE is:6.83 & sMAPE is:16.65% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :3.79 & 10.17% & 0.82\n",
      "for 2018-02-22, MAE is:8.85 & sMAPE is:21.19% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :3.88 & 10.37% & 0.82\n",
      "for 2018-02-23, MAE is:6.50 & sMAPE is:15.91% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.93 & 10.48% & 0.82\n",
      "for 2018-02-24, MAE is:2.49 & sMAPE is:6.72% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 10.41% & 0.82\n",
      "for 2018-02-25, MAE is:3.57 & sMAPE is:9.58% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 10.39% & 0.83\n",
      "for 2018-02-26, MAE is:10.18 & sMAPE is:22.75% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 10.61% & 0.84\n",
      "for 2018-02-27, MAE is:5.13 & sMAPE is:13.11% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :4.03 & 10.65% & 0.85\n",
      "for 2018-02-28, MAE is:5.29 & sMAPE is:13.57% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.05 & 10.70% & 0.86\n",
      "for 2018-03-01, MAE is:5.65 & sMAPE is:14.95% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 10.77% & 0.87\n",
      "for 2018-03-02, MAE is:8.01 & sMAPE is:18.34% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.14 & 10.90% & 0.87\n",
      "for 2018-03-03, MAE is:5.87 & sMAPE is:14.97% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :4.17 & 10.96% & 0.89\n",
      "for 2018-03-04, MAE is:4.87 & sMAPE is:12.59% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.18 & 10.99% & 0.90\n",
      "for 2018-03-05, MAE is:16.17 & sMAPE is:33.65% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.37 & 11.34% & 0.92\n",
      "for 2018-03-06, MAE is:11.54 & sMAPE is:25.13% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.56% & 0.93\n",
      "for 2018-03-07, MAE is:10.78 & sMAPE is:24.40% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.75% & 0.94\n",
      "for 2018-03-08, MAE is:4.10 & sMAPE is:10.37% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.73% & 0.95\n",
      "for 2018-03-09, MAE is:5.04 & sMAPE is:12.87% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.57 & 11.75% & 0.95\n",
      "for 2018-03-10, MAE is:1.68 & sMAPE is:4.57% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 11.64% & 0.94\n",
      "for 2018-03-11, MAE is:1.54 & sMAPE is:4.35% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 11.54% & 0.94\n",
      "for 2018-03-12, MAE is:7.64 & sMAPE is:18.97% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 11.64% & 0.93\n",
      "for 2018-03-13, MAE is:5.43 & sMAPE is:13.78% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.67% & 0.93\n",
      "for 2018-03-14, MAE is:11.25 & sMAPE is:25.06% & rMAE is:7.81 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 11.86% & 1.02\n",
      "for 2018-03-15, MAE is:3.89 & sMAPE is:10.24% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 11.83% & 1.03\n",
      "for 2018-03-16, MAE is:5.00 & sMAPE is:12.56% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 11.84% & 1.04\n",
      "for 2018-03-17, MAE is:2.76 & sMAPE is:7.58% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.79% & 1.06\n",
      "for 2018-03-18, MAE is:2.51 & sMAPE is:6.92% & rMAE is:2.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 11.72% & 1.07\n",
      "for 2018-03-19, MAE is:6.79 & sMAPE is:16.54% & rMAE is:3.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.79% & 1.10\n",
      "for 2018-03-20, MAE is:6.97 & sMAPE is:16.39% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 11.84% & 1.12\n",
      "for 2018-03-21, MAE is:5.41 & sMAPE is:13.43% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :4.65 & 11.86% & 1.12\n",
      "for 2018-03-22, MAE is:5.50 & sMAPE is:14.27% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 11.89% & 1.14\n",
      "for 2018-03-23, MAE is:7.37 & sMAPE is:17.44% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 11.96% & 1.16\n",
      "for 2018-03-24, MAE is:4.44 & sMAPE is:11.63% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 11.96% & 1.17\n",
      "for 2018-03-25, MAE is:3.98 & sMAPE is:10.49% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 11.94% & 1.18\n",
      "for 2018-03-26, MAE is:10.82 & sMAPE is:24.32% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 12.09% & 1.19\n",
      "for 2018-03-27, MAE is:9.37 & sMAPE is:21.62% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.20% & 1.19\n",
      "for 2018-03-28, MAE is:9.47 & sMAPE is:21.95% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 12.31% & 1.20\n",
      "for 2018-03-29, MAE is:3.93 & sMAPE is:10.06% & rMAE is:4.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 12.28% & 1.24\n",
      "for 2018-03-30, MAE is:4.55 & sMAPE is:11.75% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 12.28% & 1.24\n",
      "for 2018-03-31, MAE is:3.85 & sMAPE is:10.14% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 12.25% & 1.26\n",
      "for 2018-04-01, MAE is:2.84 & sMAPE is:7.56% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.20% & 1.28\n",
      "for 2018-04-02, MAE is:4.31 & sMAPE is:11.43% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.19% & 1.27\n",
      "for 2018-04-03, MAE is:6.95 & sMAPE is:17.06% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 12.25% & 1.28\n",
      "for 2018-04-04, MAE is:5.53 & sMAPE is:13.62% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 12.26% & 1.28\n",
      "for 2018-04-05, MAE is:6.74 & sMAPE is:16.75% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 12.31% & 1.29\n",
      "for 2018-04-06, MAE is:3.47 & sMAPE is:8.73% & rMAE is:3.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 12.27% & 1.31\n",
      "for 2018-04-07, MAE is:3.53 & sMAPE is:9.37% & rMAE is:4.19 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 12.24% & 1.34\n",
      "for 2018-04-08, MAE is:3.95 & sMAPE is:10.56% & rMAE is:6.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 12.22% & 1.39\n",
      "for 2018-04-09, MAE is:6.99 & sMAPE is:16.99% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 12.27% & 1.40\n",
      "for 2018-04-10, MAE is:4.15 & sMAPE is:10.60% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 12.25% & 1.40\n",
      "for 2018-04-11, MAE is:4.80 & sMAPE is:12.33% & rMAE is:3.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 12.26% & 1.42\n",
      "for 2018-04-12, MAE is:3.90 & sMAPE is:10.15% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.83 & 12.23% & 1.42\n",
      "for 2018-04-13, MAE is:3.50 & sMAPE is:9.26% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.21% & 1.43\n",
      "for 2018-04-14, MAE is:3.14 & sMAPE is:8.34% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.17% & 1.45\n",
      "for 2018-04-15, MAE is:3.19 & sMAPE is:8.35% & rMAE is:9.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.78 & 12.13% & 1.52\n",
      "for 2018-04-16, MAE is:7.35 & sMAPE is:17.54% & rMAE is:4.44 ||| daily mean of MAE & sMAPE & rMAE till now are :4.81 & 12.18% & 1.55\n",
      "for 2018-04-17, MAE is:3.96 & sMAPE is:9.80% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.16% & 1.56\n",
      "for 2018-04-18, MAE is:4.98 & sMAPE is:12.22% & rMAE is:3.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 12.16% & 1.58\n",
      "for 2018-04-19, MAE is:3.54 & sMAPE is:8.83% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 12.13% & 1.57\n",
      "for 2018-04-20, MAE is:1.91 & sMAPE is:5.29% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 12.07% & 1.57\n",
      "for 2018-04-21, MAE is:2.96 & sMAPE is:9.35% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 12.04% & 1.56\n",
      "for 2018-04-22, MAE is:1.36 & sMAPE is:3.93% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 11.97% & 1.54\n",
      "for 2018-04-23, MAE is:3.30 & sMAPE is:10.03% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 11.95% & 1.53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-24, MAE is:2.01 & sMAPE is:6.03% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 11.90% & 1.52\n",
      "for 2018-04-25, MAE is:1.91 & sMAPE is:5.21% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.66 & 11.84% & 1.51\n",
      "for 2018-04-26, MAE is:1.86 & sMAPE is:5.11% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 11.79% & 1.50\n",
      "for 2018-04-27, MAE is:1.89 & sMAPE is:5.11% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :4.61 & 11.73% & 1.51\n",
      "for 2018-04-28, MAE is:0.87 & sMAPE is:2.47% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.58 & 11.65% & 1.50\n",
      "for 2018-04-29, MAE is:0.75 & sMAPE is:2.19% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :4.54 & 11.57% & 1.49\n",
      "for 2018-04-30, MAE is:1.62 & sMAPE is:5.01% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 11.52% & 1.48\n",
      "for 2018-05-01, MAE is:2.91 & sMAPE is:9.08% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 11.50% & 1.48\n",
      "for 2018-05-02, MAE is:4.48 & sMAPE is:12.68% & rMAE is:4.60 ||| daily mean of MAE & sMAPE & rMAE till now are :4.51 & 11.51% & 1.50\n",
      "for 2018-05-03, MAE is:2.00 & sMAPE is:5.55% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 11.46% & 1.51\n",
      "for 2018-05-04, MAE is:1.35 & sMAPE is:3.66% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.46 & 11.40% & 1.52\n",
      "for 2018-05-05, MAE is:2.79 & sMAPE is:8.71% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :4.45 & 11.37% & 1.51\n",
      "for 2018-05-06, MAE is:9.01 & sMAPE is:34.25% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.48 & 11.56% & 1.51\n",
      "for 2018-05-07, MAE is:5.22 & sMAPE is:18.95% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :4.49 & 11.61% & 1.50\n",
      "for 2018-05-08, MAE is:5.59 & sMAPE is:20.79% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.50 & 11.69% & 1.50\n",
      "for 2018-05-09, MAE is:7.13 & sMAPE is:32.15% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.52 & 11.84% & 1.49\n",
      "for 2018-05-10, MAE is:8.23 & sMAPE is:61.38% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :4.55 & 12.22% & 1.48\n",
      "for 2018-05-11, MAE is:13.90 & sMAPE is:70.18% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :4.62 & 12.67% & 1.48\n",
      "for 2018-05-12, MAE is:2.29 & sMAPE is:7.75% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :4.60 & 12.63% & 1.48\n",
      "for 2018-05-13, MAE is:10.38 & sMAPE is:46.23% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 12.88% & 1.48\n",
      "for 2018-05-14, MAE is:12.43 & sMAPE is:44.19% & rMAE is:4.98 ||| daily mean of MAE & sMAPE & rMAE till now are :4.70 & 13.12% & 1.51\n",
      "for 2018-05-15, MAE is:2.18 & sMAPE is:6.38% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.07% & 1.50\n",
      "for 2018-05-16, MAE is:2.35 & sMAPE is:7.13% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :4.67 & 13.02% & 1.49\n",
      "for 2018-05-17, MAE is:7.23 & sMAPE is:32.38% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.16% & 1.49\n",
      "for 2018-05-18, MAE is:7.62 & sMAPE is:31.56% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.30% & 1.49\n",
      "for 2018-05-19, MAE is:1.77 & sMAPE is:5.14% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.24% & 1.48\n",
      "for 2018-05-20, MAE is:7.90 & sMAPE is:28.62% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.35% & 1.48\n",
      "for 2018-05-21, MAE is:10.06 & sMAPE is:37.65% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.52% & 1.49\n",
      "for 2018-05-22, MAE is:6.85 & sMAPE is:19.17% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.76 & 13.56% & 1.49\n",
      "for 2018-05-23, MAE is:3.67 & sMAPE is:9.55% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.53% & 1.49\n",
      "for 2018-05-24, MAE is:3.63 & sMAPE is:9.59% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.51% & 1.48\n",
      "for 2018-05-25, MAE is:2.84 & sMAPE is:7.42% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.46% & 1.47\n",
      "for 2018-05-26, MAE is:2.05 & sMAPE is:5.26% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.41% & 1.46\n",
      "for 2018-05-27, MAE is:1.85 & sMAPE is:4.92% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.35% & 1.46\n",
      "for 2018-05-28, MAE is:4.52 & sMAPE is:11.86% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.34% & 1.45\n",
      "for 2018-05-29, MAE is:4.04 & sMAPE is:10.44% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.32% & 1.45\n",
      "for 2018-05-30, MAE is:4.66 & sMAPE is:11.85% & rMAE is:3.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.31% & 1.46\n",
      "for 2018-05-31, MAE is:4.61 & sMAPE is:11.54% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.30% & 1.46\n",
      "for 2018-06-01, MAE is:5.11 & sMAPE is:12.71% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.29% & 1.46\n",
      "for 2018-06-02, MAE is:2.97 & sMAPE is:7.34% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.26% & 1.46\n",
      "for 2018-06-03, MAE is:4.86 & sMAPE is:12.10% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :4.68 & 13.25% & 1.46\n",
      "for 2018-06-04, MAE is:6.11 & sMAPE is:15.01% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :4.69 & 13.26% & 1.46\n",
      "for 2018-06-05, MAE is:7.83 & sMAPE is:18.80% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :4.71 & 13.29% & 1.46\n",
      "for 2018-06-06, MAE is:7.99 & sMAPE is:18.75% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.73 & 13.33% & 1.46\n",
      "for 2018-06-07, MAE is:8.28 & sMAPE is:19.11% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.75 & 13.37% & 1.46\n",
      "for 2018-06-08, MAE is:10.51 & sMAPE is:24.64% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :4.79 & 13.44% & 1.47\n",
      "for 2018-06-09, MAE is:6.69 & sMAPE is:15.68% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :4.80 & 13.45% & 1.47\n",
      "for 2018-06-10, MAE is:7.51 & sMAPE is:17.76% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.82 & 13.48% & 1.47\n",
      "for 2018-06-11, MAE is:8.05 & sMAPE is:18.90% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.84 & 13.51% & 1.48\n",
      "for 2018-06-12, MAE is:8.48 & sMAPE is:19.92% & rMAE is:7.64 ||| daily mean of MAE & sMAPE & rMAE till now are :4.86 & 13.55% & 1.51\n",
      "for 2018-06-13, MAE is:8.80 & sMAPE is:20.71% & rMAE is:12.79 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 13.59% & 1.58\n",
      "for 2018-06-14, MAE is:8.47 & sMAPE is:20.15% & rMAE is:4.06 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 13.63% & 1.60\n",
      "for 2018-06-15, MAE is:6.94 & sMAPE is:16.57% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.65% & 1.60\n",
      "for 2018-06-16, MAE is:5.43 & sMAPE is:13.27% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.65% & 1.60\n",
      "for 2018-06-17, MAE is:4.77 & sMAPE is:11.78% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.64% & 1.60\n",
      "for 2018-06-18, MAE is:5.32 & sMAPE is:12.73% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.63% & 1.61\n",
      "for 2018-06-19, MAE is:4.61 & sMAPE is:11.43% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.62% & 1.60\n",
      "for 2018-06-20, MAE is:4.43 & sMAPE is:10.82% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.60% & 1.60\n",
      "for 2018-06-21, MAE is:5.08 & sMAPE is:12.75% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.60% & 1.60\n",
      "for 2018-06-22, MAE is:3.41 & sMAPE is:8.58% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 13.57% & 1.59\n",
      "for 2018-06-23, MAE is:4.09 & sMAPE is:10.47% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 13.55% & 1.59\n",
      "for 2018-06-24, MAE is:5.10 & sMAPE is:12.59% & rMAE is:3.72 ||| daily mean of MAE & sMAPE & rMAE till now are :4.91 & 13.55% & 1.61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-25, MAE is:6.97 & sMAPE is:16.69% & rMAE is:5.22 ||| daily mean of MAE & sMAPE & rMAE till now are :4.92 & 13.56% & 1.63\n",
      "for 2018-06-26, MAE is:8.47 & sMAPE is:20.26% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :4.94 & 13.60% & 1.63\n",
      "for 2018-06-27, MAE is:8.32 & sMAPE is:19.67% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :4.96 & 13.64% & 1.63\n",
      "for 2018-06-28, MAE is:7.42 & sMAPE is:17.50% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :4.97 & 13.66% & 1.64\n",
      "for 2018-06-29, MAE is:8.40 & sMAPE is:19.80% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :4.99 & 13.69% & 1.64\n",
      "for 2018-06-30, MAE is:8.01 & sMAPE is:18.94% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.01 & 13.72% & 1.64\n",
      "for 2018-07-01, MAE is:7.60 & sMAPE is:18.16% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :5.02 & 13.74% & 1.64\n",
      "for 2018-07-02, MAE is:10.97 & sMAPE is:24.93% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.05 & 13.81% & 1.65\n",
      "for 2018-07-03, MAE is:11.14 & sMAPE is:25.04% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :5.09 & 13.87% & 1.65\n",
      "for 2018-07-04, MAE is:11.65 & sMAPE is:26.03% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :5.12 & 13.93% & 1.66\n",
      "for 2018-07-05, MAE is:11.22 & sMAPE is:24.69% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :5.16 & 13.99% & 1.66\n",
      "for 2018-07-06, MAE is:9.88 & sMAPE is:22.11% & rMAE is:3.12 ||| daily mean of MAE & sMAPE & rMAE till now are :5.18 & 14.03% & 1.67\n",
      "for 2018-07-07, MAE is:8.85 & sMAPE is:20.28% & rMAE is:4.81 ||| daily mean of MAE & sMAPE & rMAE till now are :5.20 & 14.07% & 1.68\n",
      "for 2018-07-08, MAE is:10.72 & sMAPE is:24.46% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :5.23 & 14.12% & 1.69\n",
      "for 2018-07-09, MAE is:10.66 & sMAPE is:23.80% & rMAE is:16.06 ||| daily mean of MAE & sMAPE & rMAE till now are :5.26 & 14.17% & 1.77\n",
      "for 2018-07-10, MAE is:11.87 & sMAPE is:26.72% & rMAE is:25.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.29 & 14.24% & 1.89\n",
      "for 2018-07-11, MAE is:11.95 & sMAPE is:26.47% & rMAE is:18.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 14.30% & 1.98\n",
      "for 2018-07-12, MAE is:13.56 & sMAPE is:30.00% & rMAE is:14.24 ||| daily mean of MAE & sMAPE & rMAE till now are :5.37 & 14.38% & 2.04\n",
      "for 2018-07-13, MAE is:13.89 & sMAPE is:30.25% & rMAE is:4.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 14.47% & 2.05\n",
      "for 2018-07-14, MAE is:12.72 & sMAPE is:28.04% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :5.45 & 14.54% & 2.06\n",
      "for 2018-07-15, MAE is:11.79 & sMAPE is:25.74% & rMAE is:4.85 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 14.59% & 2.08\n",
      "for 2018-07-16, MAE is:13.67 & sMAPE is:29.61% & rMAE is:4.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.53 & 14.67% & 2.09\n",
      "for 2018-07-17, MAE is:13.24 & sMAPE is:28.82% & rMAE is:6.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.56 & 14.74% & 2.11\n",
      "for 2018-07-18, MAE is:12.52 & sMAPE is:27.29% & rMAE is:8.53 ||| daily mean of MAE & sMAPE & rMAE till now are :5.60 & 14.80% & 2.14\n",
      "for 2018-07-19, MAE is:12.85 & sMAPE is:28.03% & rMAE is:10.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 14.87% & 2.19\n",
      "for 2018-07-20, MAE is:14.23 & sMAPE is:30.85% & rMAE is:20.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.68 & 14.95% & 2.28\n",
      "for 2018-07-21, MAE is:13.84 & sMAPE is:30.11% & rMAE is:11.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.72 & 15.02% & 2.32\n",
      "for 2018-07-22, MAE is:13.92 & sMAPE is:30.45% & rMAE is:13.30 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 15.10% & 2.38\n",
      "for 2018-07-23, MAE is:15.12 & sMAPE is:32.47% & rMAE is:13.05 ||| daily mean of MAE & sMAPE & rMAE till now are :5.80 & 15.19% & 2.43\n",
      "for 2018-07-24, MAE is:15.02 & sMAPE is:32.23% & rMAE is:9.56 ||| daily mean of MAE & sMAPE & rMAE till now are :5.85 & 15.27% & 2.46\n",
      "for 2018-07-25, MAE is:14.76 & sMAPE is:31.67% & rMAE is:7.17 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 15.35% & 2.49\n",
      "for 2018-07-26, MAE is:13.85 & sMAPE is:29.82% & rMAE is:10.39 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 15.42% & 2.52\n",
      "for 2018-07-27, MAE is:14.07 & sMAPE is:30.56% & rMAE is:31.83 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 15.49% & 2.67\n",
      "for 2018-07-28, MAE is:11.19 & sMAPE is:24.79% & rMAE is:5.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.00 & 15.54% & 2.68\n",
      "for 2018-07-29, MAE is:11.40 & sMAPE is:25.42% & rMAE is:4.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.02 & 15.58% & 2.69\n",
      "for 2018-07-30, MAE is:12.59 & sMAPE is:27.17% & rMAE is:8.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.05 & 15.64% & 2.71\n",
      "for 2018-07-31, MAE is:14.47 & sMAPE is:31.62% & rMAE is:13.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.09 & 15.71% & 2.76\n",
      "for 2018-08-01, MAE is:14.94 & sMAPE is:32.52% & rMAE is:22.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 15.79% & 2.86\n",
      "for 2018-08-02, MAE is:13.67 & sMAPE is:29.52% & rMAE is:24.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 15.86% & 2.96\n",
      "for 2018-08-03, MAE is:13.64 & sMAPE is:29.54% & rMAE is:12.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 15.92% & 3.00\n",
      "for 2018-08-04, MAE is:12.68 & sMAPE is:27.98% & rMAE is:9.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 15.98% & 3.03\n",
      "for 2018-08-05, MAE is:10.39 & sMAPE is:23.38% & rMAE is:5.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 16.01% & 3.05\n",
      "for 2018-08-06, MAE is:12.46 & sMAPE is:27.04% & rMAE is:23.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 16.06% & 3.14\n",
      "for 2018-08-07, MAE is:13.07 & sMAPE is:28.49% & rMAE is:11.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 16.12% & 3.17\n",
      "for 2018-08-08, MAE is:12.12 & sMAPE is:27.02% & rMAE is:4.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 16.17% & 3.18\n",
      "for 2018-08-09, MAE is:11.55 & sMAPE is:25.72% & rMAE is:4.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 16.21% & 3.19\n",
      "for 2018-08-10, MAE is:8.93 & sMAPE is:20.46% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.37 & 16.23% & 3.18\n",
      "for 2018-08-11, MAE is:7.48 & sMAPE is:17.02% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 16.23% & 3.17\n",
      "for 2018-08-12, MAE is:6.15 & sMAPE is:14.31% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 16.22% & 3.17\n",
      "for 2018-08-13, MAE is:10.33 & sMAPE is:23.40% & rMAE is:3.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 16.26% & 3.17\n",
      "for 2018-08-14, MAE is:10.84 & sMAPE is:24.41% & rMAE is:4.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 16.29% & 3.17\n",
      "for 2018-08-15, MAE is:10.69 & sMAPE is:23.92% & rMAE is:7.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 16.33% & 3.19\n",
      "for 2018-08-16, MAE is:11.54 & sMAPE is:26.02% & rMAE is:10.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 16.37% & 3.23\n",
      "for 2018-08-17, MAE is:8.52 & sMAPE is:19.14% & rMAE is:4.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.38% & 3.23\n",
      "for 2018-08-18, MAE is:8.45 & sMAPE is:19.54% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 16.39% & 3.23\n",
      "for 2018-08-19, MAE is:6.88 & sMAPE is:16.22% & rMAE is:3.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 16.39% & 3.23\n",
      "for 2018-08-20, MAE is:9.36 & sMAPE is:21.37% & rMAE is:10.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 16.41% & 3.26\n",
      "for 2018-08-21, MAE is:9.89 & sMAPE is:22.21% & rMAE is:12.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 16.44% & 3.30\n",
      "for 2018-08-22, MAE is:10.94 & sMAPE is:24.87% & rMAE is:8.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 16.48% & 3.32\n",
      "for 2018-08-23, MAE is:10.45 & sMAPE is:23.42% & rMAE is:15.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 16.50% & 3.37\n",
      "for 2018-08-24, MAE is:11.71 & sMAPE is:26.42% & rMAE is:6.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 16.55% & 3.39\n",
      "for 2018-08-25, MAE is:11.36 & sMAPE is:25.27% & rMAE is:3.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 16.58% & 3.39\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-26, MAE is:11.43 & sMAPE is:25.51% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 16.62% & 3.38\n",
      "for 2018-08-27, MAE is:11.91 & sMAPE is:26.12% & rMAE is:3.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 16.66% & 3.39\n",
      "for 2018-08-28, MAE is:15.63 & sMAPE is:33.44% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 16.73% & 3.39\n",
      "for 2018-08-29, MAE is:16.40 & sMAPE is:34.34% & rMAE is:2.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 16.80% & 3.38\n",
      "for 2018-08-30, MAE is:15.36 & sMAPE is:32.61% & rMAE is:3.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 16.87% & 3.38\n",
      "for 2018-08-31, MAE is:17.71 & sMAPE is:36.52% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 16.95% & 3.38\n",
      "for 2018-09-01, MAE is:17.70 & sMAPE is:36.57% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 17.03% & 3.37\n",
      "for 2018-09-02, MAE is:17.34 & sMAPE is:36.23% & rMAE is:2.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 17.11% & 3.37\n",
      "for 2018-09-03, MAE is:19.57 & sMAPE is:40.32% & rMAE is:2.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.20% & 3.37\n",
      "for 2018-09-04, MAE is:18.88 & sMAPE is:39.00% & rMAE is:5.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.29% & 3.38\n",
      "for 2018-09-05, MAE is:19.36 & sMAPE is:39.44% & rMAE is:7.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 17.38% & 3.40\n",
      "for 2018-09-06, MAE is:18.42 & sMAPE is:37.54% & rMAE is:5.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 17.46% & 3.40\n",
      "for 2018-09-07, MAE is:17.92 & sMAPE is:37.11% & rMAE is:17.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 17.54% & 3.46\n",
      "for 2018-09-08, MAE is:15.63 & sMAPE is:33.58% & rMAE is:5.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 17.60% & 3.47\n",
      "for 2018-09-09, MAE is:12.99 & sMAPE is:27.48% & rMAE is:4.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 17.64% & 3.47\n",
      "for 2018-09-10, MAE is:15.85 & sMAPE is:33.21% & rMAE is:5.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 17.70% & 3.48\n",
      "for 2018-09-11, MAE is:12.73 & sMAPE is:27.68% & rMAE is:2.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 17.74% & 3.48\n",
      "for 2018-09-12, MAE is:13.21 & sMAPE is:28.88% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 17.79% & 3.47\n",
      "for 2018-09-13, MAE is:13.54 & sMAPE is:29.39% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 17.83% & 3.47\n",
      "for 2018-09-14, MAE is:13.74 & sMAPE is:30.06% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 17.88% & 3.47\n",
      "for 2018-09-15, MAE is:8.76 & sMAPE is:19.79% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 17.89% & 3.46\n",
      "for 2018-09-16, MAE is:6.96 & sMAPE is:16.50% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 17.88% & 3.45\n",
      "for 2018-09-17, MAE is:8.20 & sMAPE is:18.75% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 17.89% & 3.44\n",
      "for 2018-09-18, MAE is:5.06 & sMAPE is:11.85% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 17.86% & 3.43\n",
      "for 2018-09-19, MAE is:5.07 & sMAPE is:12.38% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 17.84% & 3.42\n",
      "for 2018-09-20, MAE is:5.04 & sMAPE is:12.58% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 17.82% & 3.41\n",
      "for 2018-09-21, MAE is:5.93 & sMAPE is:19.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 17.83% & 3.40\n",
      "for 2018-09-22, MAE is:8.80 & sMAPE is:53.43% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 17.96% & 3.38\n",
      "for 2018-09-23, MAE is:10.91 & sMAPE is:37.30% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 18.04% & 3.37\n",
      "for 2018-09-24, MAE is:6.95 & sMAPE is:26.88% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 18.07% & 3.36\n",
      "for 2018-09-25, MAE is:1.00 & sMAPE is:2.61% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.01% & 3.35\n",
      "for 2018-09-26, MAE is:7.43 & sMAPE is:30.29% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.06% & 3.34\n",
      "for 2018-09-27, MAE is:8.06 & sMAPE is:25.97% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.09% & 3.33\n",
      "for 2018-09-28, MAE is:6.02 & sMAPE is:16.08% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.08% & 3.33\n",
      "for 2018-09-29, MAE is:4.79 & sMAPE is:13.39% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 18.06% & 3.31\n",
      "for 2018-09-30, MAE is:6.07 & sMAPE is:18.30% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 18.06% & 3.31\n",
      "for 2018-10-01, MAE is:6.80 & sMAPE is:16.20% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 18.06% & 3.30\n",
      "for 2018-10-02, MAE is:6.06 & sMAPE is:14.06% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 18.04% & 3.29\n",
      "for 2018-10-03, MAE is:5.85 & sMAPE is:13.73% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 18.03% & 3.28\n",
      "for 2018-10-04, MAE is:7.78 & sMAPE is:17.75% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 18.02% & 3.27\n",
      "for 2018-10-05, MAE is:6.17 & sMAPE is:14.26% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 18.01% & 3.26\n",
      "for 2018-10-06, MAE is:6.57 & sMAPE is:15.23% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 18.00% & 3.25\n",
      "for 2018-10-07, MAE is:5.87 & sMAPE is:13.53% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 17.99% & 3.24\n",
      "for 2018-10-08, MAE is:5.75 & sMAPE is:13.27% & rMAE is:4.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 17.97% & 3.25\n",
      "for 2018-10-09, MAE is:3.31 & sMAPE is:7.78% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 17.93% & 3.24\n",
      "for 2018-10-10, MAE is:3.71 & sMAPE is:8.93% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 17.90% & 3.23\n",
      "for 2018-10-11, MAE is:2.83 & sMAPE is:7.29% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 17.86% & 3.22\n",
      "for 2018-10-12, MAE is:2.57 & sMAPE is:6.35% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 17.82% & 3.21\n",
      "for 2018-10-13, MAE is:5.42 & sMAPE is:16.73% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 17.82% & 3.20\n",
      "for 2018-10-14, MAE is:11.89 & sMAPE is:68.68% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 18.00% & 3.19\n",
      "for 2018-10-15, MAE is:15.67 & sMAPE is:114.35% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 18.33% & 3.18\n",
      "for 2018-10-16, MAE is:9.69 & sMAPE is:86.74% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 18.57% & 3.17\n",
      "for 2018-10-17, MAE is:23.71 & sMAPE is:84.72% & rMAE is:6.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 18.80% & 3.18\n",
      "for 2018-10-18, MAE is:2.30 & sMAPE is:5.84% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 18.75% & 3.18\n",
      "for 2018-10-19, MAE is:1.00 & sMAPE is:2.54% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 18.70% & 3.17\n",
      "for 2018-10-20, MAE is:1.73 & sMAPE is:4.43% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 18.65% & 3.16\n",
      "for 2018-10-21, MAE is:1.71 & sMAPE is:4.36% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.20 & 18.60% & 3.15\n",
      "for 2018-10-22, MAE is:5.33 & sMAPE is:15.92% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 18.59% & 3.14\n",
      "for 2018-10-23, MAE is:5.75 & sMAPE is:19.41% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 18.59% & 3.13\n",
      "for 2018-10-24, MAE is:6.41 & sMAPE is:15.94% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 18.58% & 3.12\n",
      "for 2018-10-25, MAE is:3.54 & sMAPE is:8.18% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 18.55% & 3.11\n",
      "for 2018-10-26, MAE is:5.78 & sMAPE is:13.16% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 18.53% & 3.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-27, MAE is:3.55 & sMAPE is:8.28% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 18.50% & 3.10\n",
      "for 2018-10-28, MAE is:2.70 & sMAPE is:6.33% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 18.46% & 3.09\n",
      "for 2018-10-29, MAE is:3.97 & sMAPE is:9.14% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 18.42% & 3.08\n",
      "for 2018-10-30, MAE is:2.73 & sMAPE is:6.55% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.12 & 18.39% & 3.07\n",
      "for 2018-10-31, MAE is:2.89 & sMAPE is:6.86% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 18.35% & 3.07\n",
      "for 2018-11-01, MAE is:3.35 & sMAPE is:7.81% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 18.31% & 3.07\n",
      "for 2018-11-02, MAE is:3.20 & sMAPE is:7.56% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 18.28% & 3.06\n",
      "for 2018-11-03, MAE is:2.99 & sMAPE is:7.15% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 18.24% & 3.06\n",
      "for 2018-11-04, MAE is:3.31 & sMAPE is:7.94% & rMAE is:3.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 18.21% & 3.06\n",
      "for 2018-11-05, MAE is:3.89 & sMAPE is:9.02% & rMAE is:3.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 18.18% & 3.06\n",
      "for 2018-11-06, MAE is:6.15 & sMAPE is:13.85% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 18.16% & 3.05\n",
      "for 2018-11-07, MAE is:3.92 & sMAPE is:8.99% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 18.13% & 3.05\n",
      "for 2018-11-08, MAE is:4.94 & sMAPE is:11.25% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 18.11% & 3.05\n",
      "for 2018-11-09, MAE is:3.81 & sMAPE is:8.67% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 18.08% & 3.05\n",
      "for 2018-11-10, MAE is:1.36 & sMAPE is:3.25% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 18.04% & 3.04\n",
      "for 2018-11-11, MAE is:1.69 & sMAPE is:4.20% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 17.99% & 3.03\n",
      "for 2018-11-12, MAE is:4.88 & sMAPE is:11.16% & rMAE is:3.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.97% & 3.03\n",
      "for 2018-11-13, MAE is:5.61 & sMAPE is:12.31% & rMAE is:5.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 17.95% & 3.04\n",
      "for 2018-11-14, MAE is:5.82 & sMAPE is:12.58% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 17.94% & 3.04\n",
      "for 2018-11-15, MAE is:4.46 & sMAPE is:9.94% & rMAE is:5.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.91% & 3.04\n",
      "for 2018-11-16, MAE is:4.38 & sMAPE is:9.87% & rMAE is:5.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.88% & 3.05\n",
      "for 2018-11-17, MAE is:3.83 & sMAPE is:8.64% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.86% & 3.04\n",
      "for 2018-11-18, MAE is:4.95 & sMAPE is:11.04% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.84% & 3.04\n",
      "for 2018-11-19, MAE is:6.19 & sMAPE is:13.15% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.82% & 3.03\n",
      "for 2018-11-20, MAE is:5.31 & sMAPE is:11.58% & rMAE is:5.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.80% & 3.04\n",
      "for 2018-11-21, MAE is:6.66 & sMAPE is:13.76% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.79% & 3.04\n",
      "for 2018-11-22, MAE is:8.01 & sMAPE is:16.70% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.79% & 3.03\n",
      "for 2018-11-23, MAE is:8.00 & sMAPE is:16.88% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.78% & 3.03\n",
      "for 2018-11-24, MAE is:6.33 & sMAPE is:13.89% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.77% & 3.03\n",
      "for 2018-11-25, MAE is:6.41 & sMAPE is:13.90% & rMAE is:2.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.76% & 3.03\n",
      "for 2018-11-26, MAE is:7.02 & sMAPE is:14.95% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.75% & 3.03\n",
      "for 2018-11-27, MAE is:13.36 & sMAPE is:26.00% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.78% & 3.02\n",
      "for 2018-11-28, MAE is:7.00 & sMAPE is:14.41% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.77% & 3.02\n",
      "for 2018-11-29, MAE is:4.69 & sMAPE is:10.51% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 17.74% & 3.01\n",
      "for 2018-11-30, MAE is:3.92 & sMAPE is:8.76% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.72% & 3.00\n",
      "for 2018-12-01, MAE is:3.56 & sMAPE is:8.03% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 17.69% & 3.00\n",
      "for 2018-12-02, MAE is:3.04 & sMAPE is:6.99% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 17.66% & 2.99\n",
      "for 2018-12-03, MAE is:5.24 & sMAPE is:11.54% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.64% & 2.99\n",
      "for 2018-12-04, MAE is:4.12 & sMAPE is:9.24% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.61% & 2.98\n",
      "for 2018-12-05, MAE is:8.12 & sMAPE is:17.24% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.61% & 2.98\n",
      "for 2018-12-06, MAE is:10.10 & sMAPE is:21.13% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 17.62% & 2.98\n",
      "for 2018-12-07, MAE is:5.37 & sMAPE is:11.64% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.60% & 2.98\n",
      "for 2018-12-08, MAE is:3.37 & sMAPE is:7.72% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 17.58% & 2.98\n",
      "for 2018-12-09, MAE is:2.91 & sMAPE is:6.74% & rMAE is:4.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 17.54% & 2.98\n",
      "for 2018-12-10, MAE is:4.44 & sMAPE is:9.70% & rMAE is:5.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 17.52% & 2.99\n",
      "for 2018-12-11, MAE is:8.06 & sMAPE is:17.20% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 17.52% & 2.99\n",
      "for 2018-12-12, MAE is:16.19 & sMAPE is:30.93% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 17.56% & 2.98\n",
      "for 2018-12-13, MAE is:14.48 & sMAPE is:27.29% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 17.59% & 2.98\n",
      "for 2018-12-14, MAE is:13.75 & sMAPE is:26.89% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.61% & 2.98\n",
      "for 2018-12-15, MAE is:9.17 & sMAPE is:19.32% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.62% & 2.97\n",
      "for 2018-12-16, MAE is:7.65 & sMAPE is:16.54% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 17.62% & 2.97\n",
      "for 2018-12-17, MAE is:23.01 & sMAPE is:40.14% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 17.68% & 2.96\n",
      "for 2018-12-18, MAE is:15.50 & sMAPE is:28.97% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 17.71% & 2.96\n",
      "for 2018-12-19, MAE is:9.27 & sMAPE is:19.09% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 17.72% & 2.96\n",
      "for 2018-12-20, MAE is:9.61 & sMAPE is:19.63% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 17.72% & 2.95\n",
      "for 2018-12-21, MAE is:9.55 & sMAPE is:19.95% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 17.73% & 2.95\n",
      "for 2018-12-22, MAE is:8.59 & sMAPE is:18.13% & rMAE is:3.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 17.73% & 2.95\n",
      "for 2018-12-23, MAE is:10.17 & sMAPE is:21.00% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.74% & 2.95\n",
      "for 2018-12-24, MAE is:7.98 & sMAPE is:16.96% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.74% & 2.95\n",
      "for 2018-12-25, MAE is:6.58 & sMAPE is:14.09% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.73% & 2.94\n",
      "for 2018-12-26, MAE is:7.47 & sMAPE is:15.82% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.72% & 2.94\n",
      "for 2018-12-27, MAE is:8.35 & sMAPE is:17.48% & rMAE is:3.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 17.72% & 2.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-28, MAE is:9.79 & sMAPE is:20.10% & rMAE is:4.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 17.73% & 2.95\n",
      "for 2018-12-29, MAE is:7.44 & sMAPE is:15.93% & rMAE is:4.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 17.72% & 2.95\n",
      "for 2018-12-30, MAE is:9.26 & sMAPE is:19.77% & rMAE is:5.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 17.73% & 2.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:49:15,278]\u001b[0m A new study created in RDB with name: NO_5_2019\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-31, MAE is:6.61 & sMAPE is:14.28% & rMAE is:5.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 17.72% & 2.96\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:49:35,711]\u001b[0m Trial 3 finished with value: 5.521998787592245 and parameters: {'n_hidden': 4, 'learning_rate': 0.003494139516372769, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3375399132814017, 'dropout_rate_Layer_2': 0.2225330778612168, 'dropout_rate_Layer_3': 0.25925546990159415, 'dropout_rate_Layer_4': 0.3264276204911536, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.0500843105911763e-05, 'l1_Layer_2': 0.0011436878893242863, 'l1_Layer_3': 0.0061838335287448636, 'l1_Layer_4': 0.004795545336409357, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280, 'n_units_Layer_4': 140}. Best is trial 3 with value: 5.521998787592245.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.52 | sMAPE for Validation Set is: 13.89% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 3.39 | sMAPE for Test Set is: 8.48% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:49:35,979]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 44.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:49:41,927]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:49:42,076]\u001b[0m Trial 1 finished with value: 15.169864873690756 and parameters: {'n_hidden': 3, 'learning_rate': 0.06339010252833353, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29629364715263634, 'dropout_rate_Layer_2': 0.1860608702438237, 'dropout_rate_Layer_3': 0.06544112646168587, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012307405762341454, 'l1_Layer_2': 0.0005320450802315862, 'l1_Layer_3': 7.510696005774519e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140}. Best is trial 3 with value: 5.521998787592245.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.17 | sMAPE for Validation Set is: 40.79% | rMAE for Validation Set is: 3.05\n",
      "MAE for Test Set is: 10.46 | sMAPE for Test Set is: 29.06% | rMAE for Test Set is: 3.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:49:49,313]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:49:51,827]\u001b[0m Trial 5 finished with value: 9.484409886871637 and parameters: {'n_hidden': 4, 'learning_rate': 0.016426094288473844, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35944046759821385, 'dropout_rate_Layer_2': 0.12378168811755788, 'dropout_rate_Layer_3': 0.35846497085606055, 'dropout_rate_Layer_4': 0.3370081317735678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.095201117743948e-05, 'l1_Layer_2': 0.00022367894546894263, 'l1_Layer_3': 0.0002015191951868262, 'l1_Layer_4': 0.00026272351009745817, 'n_units_Layer_1': 220, 'n_units_Layer_2': 260, 'n_units_Layer_3': 295, 'n_units_Layer_4': 90}. Best is trial 3 with value: 5.521998787592245.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 23.82% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 5.32 | sMAPE for Test Set is: 13.41% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:49:54,600]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.71 | sMAPE for Validation Set is: 9.74% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 2.34 | sMAPE for Test Set is: 6.01% | rMAE for Test Set is: 0.71\n",
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 23.17% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 5.60 | sMAPE for Test Set is: 14.30% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:49:57,653]\u001b[0m Trial 2 finished with value: 3.710095411821007 and parameters: {'n_hidden': 3, 'learning_rate': 0.000621037548687308, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3439606261814703, 'dropout_rate_Layer_2': 0.39622663317275825, 'dropout_rate_Layer_3': 0.36305922633665527, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003629563951251158, 'l1_Layer_2': 0.020789711402028788, 'l1_Layer_3': 0.0022957393660183105, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 175}. Best is trial 2 with value: 3.710095411821007.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:49:57,748]\u001b[0m Trial 6 finished with value: 9.283052955002313 and parameters: {'n_hidden': 3, 'learning_rate': 0.025825780408514545, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02727635041534975, 'dropout_rate_Layer_2': 0.006839887414478341, 'dropout_rate_Layer_3': 0.340395957241414, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006438825343585829, 'l1_Layer_2': 0.00029372160067771025, 'l1_Layer_3': 2.2301856574599044e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 2 with value: 3.710095411821007.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:49:59,632]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:04,442]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:06,771]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:07,128]\u001b[0m Trial 9 finished with value: 8.94523344340049 and parameters: {'n_hidden': 4, 'learning_rate': 0.019601173240136736, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31393195716682604, 'dropout_rate_Layer_2': 0.3802620459888862, 'dropout_rate_Layer_3': 0.15340014116508055, 'dropout_rate_Layer_4': 0.2956097113792131, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 9.3209515780642e-05, 'l1_Layer_2': 0.0009655158339636786, 'l1_Layer_3': 0.0004605083994214115, 'l1_Layer_4': 3.599510176367463e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130, 'n_units_Layer_4': 140}. Best is trial 2 with value: 3.710095411821007.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.95 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 5.00 | sMAPE for Test Set is: 12.69% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:50:09,640]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:10,805]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:12,492]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:14,416]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:17,453]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:20,228]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:22,371]\u001b[0m Trial 15 finished with value: 16.585421646604768 and parameters: {'n_hidden': 4, 'learning_rate': 0.013207287873666172, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28172404330192846, 'dropout_rate_Layer_2': 0.1431440090274114, 'dropout_rate_Layer_3': 0.08481800304943446, 'dropout_rate_Layer_4': 0.12624016715743733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.01588047968257703, 'l1_Layer_2': 0.0009977871608200298, 'l1_Layer_3': 1.0820065992675717e-05, 'l1_Layer_4': 0.09220103433562271, 'n_units_Layer_1': 90, 'n_units_Layer_2': 85, 'n_units_Layer_3': 75, 'n_units_Layer_4': 60}. Best is trial 2 with value: 3.710095411821007.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.59 | sMAPE for Validation Set is: 45.55% | rMAE for Validation Set is: 3.34\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 33.84% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:50:26,121]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:30,062]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:34,066]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:36,941]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:39,640]\u001b[0m Trial 21 finished with value: 5.2267577045723055 and parameters: {'n_hidden': 3, 'learning_rate': 0.08444350915815012, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3760228623549581, 'dropout_rate_Layer_2': 0.33628934558900914, 'dropout_rate_Layer_3': 0.32188400304637405, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0281367142854158e-05, 'l1_Layer_2': 2.046668669085541e-05, 'l1_Layer_3': 0.00028621269904223197, 'n_units_Layer_1': 75, 'n_units_Layer_2': 115, 'n_units_Layer_3': 55}. Best is trial 2 with value: 3.710095411821007.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.28% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 4.04 | sMAPE for Test Set is: 10.48% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:50:47,002]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:47,822]\u001b[0m Trial 23 finished with value: 3.121801994117723 and parameters: {'n_hidden': 3, 'learning_rate': 0.06603093569580913, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24798097713098707, 'dropout_rate_Layer_2': 0.20534314429180345, 'dropout_rate_Layer_3': 0.008956021962118088, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001635385109124365, 'l1_Layer_2': 0.01050926741712373, 'l1_Layer_3': 0.016815039502631503, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 23 with value: 3.121801994117723.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 8.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.29 | sMAPE for Test Set is: 5.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:50:50,110]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:52,872]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:54,380]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:56,584]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:50:58,078]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:02,346]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:02,812]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:03,890]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:07,655]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:08,553]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:11,955]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:15,182]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:17,276]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:18,103]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:21,185]\u001b[0m Trial 18 finished with value: 2.9235922610959526 and parameters: {'n_hidden': 3, 'learning_rate': 0.004187916349859791, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13590878819562166, 'dropout_rate_Layer_2': 0.3142989026301637, 'dropout_rate_Layer_3': 0.09867706969987218, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004059430859862998, 'l1_Layer_2': 3.0211849596748103e-05, 'l1_Layer_3': 0.0024601265014636427, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 275}. Best is trial 18 with value: 2.9235922610959526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 8.16% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.01 | sMAPE for Test Set is: 5.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:51:24,446]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:31,412]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:49,063]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:51:54,719]\u001b[0m Trial 43 finished with value: 2.998656348409599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005770000785207485, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18199812296040793, 'dropout_rate_Layer_2': 0.18350343319095486, 'dropout_rate_Layer_3': 0.02651294478779742, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024266547973298192, 'l1_Layer_2': 0.0095759378630273, 'l1_Layer_3': 0.00036687478954768873, 'n_units_Layer_1': 145, 'n_units_Layer_2': 180, 'n_units_Layer_3': 55}. Best is trial 18 with value: 2.9235922610959526.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 8.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.10 | sMAPE for Test Set is: 5.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:52:02,467]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:07,388]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:11,178]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.85% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:52:13,496]\u001b[0m Trial 47 finished with value: 2.8239476870469318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019236215700163667, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04202888594056255, 'dropout_rate_Layer_2': 0.3722629167035519, 'dropout_rate_Layer_3': 0.1303356938329664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00784518324640239, 'l1_Layer_2': 2.7978751535640688e-05, 'l1_Layer_3': 0.0026240540209699556, 'n_units_Layer_1': 260, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270}. Best is trial 47 with value: 2.8239476870469318.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:18,743]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:22,922]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:29,730]\u001b[0m Trial 55 finished with value: 13.89916124548104 and parameters: {'n_hidden': 3, 'learning_rate': 0.09220063481288303, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3165444759132575, 'dropout_rate_Layer_2': 0.11492321209543582, 'dropout_rate_Layer_3': 0.07905304906789952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0008876271230778851, 'l1_Layer_2': 1.4992250584964155e-05, 'l1_Layer_3': 0.0099255705661622, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 300}. Best is trial 47 with value: 2.8239476870469318.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.90 | sMAPE for Validation Set is: 36.85% | rMAE for Validation Set is: 2.80\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 26.18% | rMAE for Test Set is: 2.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:52:35,932]\u001b[0m Trial 48 finished with value: 2.8151028396785818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020126757849166306, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050368669398421294, 'dropout_rate_Layer_2': 0.34579644819890837, 'dropout_rate_Layer_3': 0.13196423537659968, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0063949213571528, 'l1_Layer_2': 3.454790994978636e-05, 'l1_Layer_3': 0.0030482012095803092, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 48 with value: 2.8151028396785818.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.90% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:52:36,303]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:42,397]\u001b[0m Trial 49 finished with value: 2.749713184895684 and parameters: {'n_hidden': 3, 'learning_rate': 0.002100686047965798, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04709647347399641, 'dropout_rate_Layer_2': 0.3460072798960719, 'dropout_rate_Layer_3': 0.12270395624957282, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006135437516644695, 'l1_Layer_2': 1.0842915584998758e-05, 'l1_Layer_3': 0.004261694110197799, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 270}. Best is trial 49 with value: 2.749713184895684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:52:42,735]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:45,020]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:51,312]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:52:52,853]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:01,898]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:02,207]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:04,125]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:14,452]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:17,957]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:18,069]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:24,007]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:30,974]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:34,603]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:39,197]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:43,447]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:48,911]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:49,378]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:54,149]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:55,411]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:53:59,263]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:02,704]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:07,386]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:24,927]\u001b[0m Trial 79 finished with value: 8.496906162720151 and parameters: {'n_hidden': 4, 'learning_rate': 0.09176802464068051, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03282205006942949, 'dropout_rate_Layer_2': 0.0431105784052809, 'dropout_rate_Layer_3': 0.07231154847540071, 'dropout_rate_Layer_4': 0.3406604707336722, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0002524813850988608, 'l1_Layer_2': 7.354797852055518e-05, 'l1_Layer_3': 0.0013965195595304124, 'l1_Layer_4': 0.014207575416595817, 'n_units_Layer_1': 265, 'n_units_Layer_2': 255, 'n_units_Layer_3': 245, 'n_units_Layer_4': 175}. Best is trial 49 with value: 2.749713184895684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 1.71\n",
      "MAE for Test Set is: 5.24 | sMAPE for Test Set is: 13.36% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:54:27,135]\u001b[0m Trial 52 finished with value: 12.829870180373307 and parameters: {'n_hidden': 4, 'learning_rate': 0.07596735955296904, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2887527087261889, 'dropout_rate_Layer_2': 0.3268905091427076, 'dropout_rate_Layer_3': 0.24067448266850616, 'dropout_rate_Layer_4': 0.24367990925079336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.046903901569172644, 'l1_Layer_2': 0.00013491171130009148, 'l1_Layer_3': 0.002956076246340804, 'l1_Layer_4': 0.0015225761679825076, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 285}. Best is trial 49 with value: 2.749713184895684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.83 | sMAPE for Validation Set is: 33.69% | rMAE for Validation Set is: 2.58\n",
      "MAE for Test Set is: 8.57 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:54:29,985]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:33,167]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:33,559]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:38,733]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:43,016]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:44,576]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:50,388]\u001b[0m Trial 86 finished with value: 4.658664782899719 and parameters: {'n_hidden': 4, 'learning_rate': 0.0056371004888813225, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00914152555486889, 'dropout_rate_Layer_2': 0.38836485376392926, 'dropout_rate_Layer_3': 0.00481347223480495, 'dropout_rate_Layer_4': 0.28388927541514847, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008172582404462141, 'l1_Layer_2': 0.0026163044286129974, 'l1_Layer_3': 0.00022299752399074506, 'l1_Layer_4': 0.03003877197181277, 'n_units_Layer_1': 295, 'n_units_Layer_2': 125, 'n_units_Layer_3': 180, 'n_units_Layer_4': 130}. Best is trial 49 with value: 2.749713184895684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.94\n",
      "MAE for Test Set is: 3.23 | sMAPE for Test Set is: 8.21% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:54:53,336]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:54:53,893]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:03,139]\u001b[0m Trial 90 finished with value: 6.371586884564304 and parameters: {'n_hidden': 3, 'learning_rate': 0.018923286050401406, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2115410130221677, 'dropout_rate_Layer_2': 0.32731329860259484, 'dropout_rate_Layer_3': 0.2891356193178727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.1403670740840877e-05, 'l1_Layer_2': 5.9676530406858547e-05, 'l1_Layer_3': 1.265203839236887e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 250, 'n_units_Layer_3': 110}. Best is trial 49 with value: 2.749713184895684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 15.76% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 18.15% | rMAE for Test Set is: 2.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:55:05,309]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:05,450]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:11,630]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:11,825]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:16,739]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:18,804]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:20,095]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:23,006]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:23,815]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:27,117]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:28,772]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:31,045]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:32,326]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:35,236]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:39,893]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:44,441]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:48,009]\u001b[0m Trial 64 finished with value: 2.7245882004643724 and parameters: {'n_hidden': 3, 'learning_rate': 0.000540051431225333, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11499735483974448, 'dropout_rate_Layer_2': 0.35718094351522944, 'dropout_rate_Layer_3': 0.09682311276936818, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002145172325205256, 'l1_Layer_2': 0.0001178949597836591, 'l1_Layer_3': 0.02297701460214664, 'n_units_Layer_1': 185, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.70% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.82 | sMAPE for Test Set is: 4.80% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:55:48,343]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:50,200]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:55,553]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:55:55,919]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:02,056]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:02,484]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:06,835]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:07,623]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:13,141]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:16,130]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:21,802]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:34,391]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:36,848]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:39,990]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:41,363]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:43,771]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:43,947]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:44,771]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:49,790]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:50,110]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:54,480]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:55,092]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:55,616]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:56:56,789]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:02,650]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:04,897]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:06,216]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:07,427]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:09,658]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:13,881]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:15,475]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:16,091]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:22,632]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:27,740]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:29,820]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:31,816]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:34,530]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:37,069]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:38,016]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:41,468]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:42,822]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:45,521]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:50,318]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:50,834]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:50,947]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:58,137]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:57:58,425]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:02,458]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:04,269]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:05,121]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:05,157]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:12,147]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:12,275]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:12,760]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:18,907]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:18,972]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:24,315]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:27,188]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:29,994]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:33,828]\u001b[0m Trial 165 finished with value: 10.539336202042506 and parameters: {'n_hidden': 3, 'learning_rate': 0.016300917805204436, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0067124173111851315, 'dropout_rate_Layer_2': 0.22574662127854458, 'dropout_rate_Layer_3': 0.015613188712956184, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001538882218919077, 'l1_Layer_2': 0.005243770656709219, 'l1_Layer_3': 0.00011803089099387588, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.54 | sMAPE for Validation Set is: 26.75% | rMAE for Validation Set is: 2.12\n",
      "MAE for Test Set is: 6.40 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 1.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:58:37,792]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:38,110]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:43,548]\u001b[0m Trial 168 finished with value: 6.266043214522704 and parameters: {'n_hidden': 3, 'learning_rate': 0.046188816887084816, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1690080401103591, 'dropout_rate_Layer_2': 0.20806218920559078, 'dropout_rate_Layer_3': 0.2867972187130829, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9882992592445666e-05, 'l1_Layer_2': 4.160588210074174e-05, 'l1_Layer_3': 3.163327257377175e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 85}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 15.66% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 4.21 | sMAPE for Test Set is: 10.69% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:58:48,160]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:48,347]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:54,423]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:57,336]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:58:57,611]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:02,506]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:12,416]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:17,312]\u001b[0m Trial 160 finished with value: 2.817686515156339 and parameters: {'n_hidden': 4, 'learning_rate': 0.014682037798166086, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3529079514062475, 'dropout_rate_Layer_2': 0.23245366135163717, 'dropout_rate_Layer_3': 0.2845349108060405, 'dropout_rate_Layer_4': 0.07684517737745111, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.115751113193391e-05, 'l1_Layer_2': 0.08936245475330443, 'l1_Layer_3': 0.00158034977145373, 'l1_Layer_4': 9.642747447375133e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 200, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:59:21,566]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:25,507]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:30,754]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:36,905]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:43,018]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 15:59:46,372]\u001b[0m Trial 183 finished with value: 5.225561552780301 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005317363835321705, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10475200821773988, 'dropout_rate_Layer_2': 0.26034452896950167, 'dropout_rate_Layer_3': 0.0066741654524654906, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0039516342828453755, 'l1_Layer_2': 0.006569635090050618, 'l1_Layer_3': 0.0001062354862272526, 'n_units_Layer_1': 250, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.23 | sMAPE for Validation Set is: 13.10% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 2.86 | sMAPE for Test Set is: 7.12% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:59:48,931]\u001b[0m Trial 185 finished with value: 7.596632631264584 and parameters: {'n_hidden': 4, 'learning_rate': 0.00449703143151286, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36586255877824453, 'dropout_rate_Layer_2': 0.36840903144435116, 'dropout_rate_Layer_3': 0.3008297665938565, 'dropout_rate_Layer_4': 0.02221093513659772, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1460372932267101e-05, 'l1_Layer_2': 0.00022193242805047865, 'l1_Layer_3': 0.0066393930289534156, 'l1_Layer_4': 0.00021255617914441447, 'n_units_Layer_1': 85, 'n_units_Layer_2': 250, 'n_units_Layer_3': 140, 'n_units_Layer_4': 50}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.60 | sMAPE for Validation Set is: 18.83% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 5.11 | sMAPE for Test Set is: 13.35% | rMAE for Test Set is: 1.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 15:59:57,009]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:00,393]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:00,665]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:02,210]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:11,248]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:14,101]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:14,343]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:18,559]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:20,299]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:22,033]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:25,386]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:25,747]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:26,061]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:32,884]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:34,565]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:35,168]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:39,920]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:42,055]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:44,935]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:46,063]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:49,224]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:51,692]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:54,786]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:00:56,219]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:01,168]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:03,198]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:07,433]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:10,373]\u001b[0m Trial 208 finished with value: 6.32834193640803 and parameters: {'n_hidden': 4, 'learning_rate': 0.004523103033996547, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09662021000794681, 'dropout_rate_Layer_2': 0.39797104311010917, 'dropout_rate_Layer_3': 0.13453810158889412, 'dropout_rate_Layer_4': 0.027056004309491205, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017029748967582652, 'l1_Layer_2': 0.006234812884002416, 'l1_Layer_3': 0.0003074475986530338, 'l1_Layer_4': 0.0019213714189510423, 'n_units_Layer_1': 160, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140, 'n_units_Layer_4': 85}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 15.77% | rMAE for Validation Set is: 1.27\n",
      "MAE for Test Set is: 4.25 | sMAPE for Test Set is: 10.76% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:01:11,112]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:15,676]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:16,318]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:16,455]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:20,635]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:26,605]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:29,980]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:30,024]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:38,255]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:40,840]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:50,062]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:54,800]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:01:58,601]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:02:04,460]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:02:08,378]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:02:27,640]\u001b[0m Trial 229 finished with value: 2.917225233163247 and parameters: {'n_hidden': 4, 'learning_rate': 0.02773168727873601, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2926540891879092, 'dropout_rate_Layer_2': 0.3577746933738463, 'dropout_rate_Layer_3': 0.25950566492478494, 'dropout_rate_Layer_4': 0.2065686988655695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012881196508276348, 'l1_Layer_2': 0.012639258139111292, 'l1_Layer_3': 0.005411649865567239, 'l1_Layer_4': 0.0037912871815587133, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110, 'n_units_Layer_4': 185}. Best is trial 64 with value: 2.7245882004643724.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.92 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:02:31,660]\u001b[0m Trial 220 finished with value: 2.58062621120634 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006133696532365114, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01731855147048365, 'dropout_rate_Layer_2': 0.03908133663448175, 'dropout_rate_Layer_3': 0.11644428524053593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032803940283011466, 'l1_Layer_2': 1.8291450220694606e-05, 'l1_Layer_3': 0.0027810221329337375, 'n_units_Layer_1': 230, 'n_units_Layer_2': 230, 'n_units_Layer_3': 275}. Best is trial 220 with value: 2.58062621120634.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 7.28% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:02:53,263]\u001b[0m Trial 213 finished with value: 2.516937764938539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014648111909021761, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017809828429276246, 'dropout_rate_Layer_2': 0.013068409157884528, 'dropout_rate_Layer_3': 0.1080505846639848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003352651056381953, 'l1_Layer_2': 0.013591644098073199, 'l1_Layer_3': 0.024531119776761413, 'n_units_Layer_1': 260, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.52 | sMAPE for Validation Set is: 7.15% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.74 | sMAPE for Test Set is: 4.62% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:02:56,620]\u001b[0m Trial 232 finished with value: 2.8198947787617836 and parameters: {'n_hidden': 3, 'learning_rate': 0.006978193774807874, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31231904484290074, 'dropout_rate_Layer_2': 0.15721139925257063, 'dropout_rate_Layer_3': 0.2198538321162701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.537591163187385e-05, 'l1_Layer_2': 0.00012708344552570303, 'l1_Layer_3': 0.007145148472461783, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.99% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.11 | sMAPE for Test Set is: 5.74% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:03:04,082]\u001b[0m Trial 234 finished with value: 3.032672165126108 and parameters: {'n_hidden': 3, 'learning_rate': 0.0072137460702525824, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30836903026272966, 'dropout_rate_Layer_2': 0.29434294737624533, 'dropout_rate_Layer_3': 0.19006339761643773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.31552751602795e-05, 'l1_Layer_2': 0.00012743100541361233, 'l1_Layer_3': 0.007250876163660019, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 8.43% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.27 | sMAPE for Test Set is: 6.08% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:03:11,109]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:11,472]\u001b[0m Trial 231 finished with value: 2.9301892968729217 and parameters: {'n_hidden': 3, 'learning_rate': 0.006932204058270013, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2862223009668789, 'dropout_rate_Layer_2': 0.11994506719700732, 'dropout_rate_Layer_3': 0.34489531832933107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004971019913314045, 'l1_Layer_2': 0.00012299381316107556, 'l1_Layer_3': 0.05040114383501427, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.10% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:03:17,667]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:20,461]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:27,272]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:32,650]\u001b[0m Trial 236 finished with value: 2.788257533118711 and parameters: {'n_hidden': 3, 'learning_rate': 0.007581592743203197, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3102471247002119, 'dropout_rate_Layer_2': 0.13574033809593705, 'dropout_rate_Layer_3': 0.21934198329337845, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.641034380880979e-05, 'l1_Layer_2': 0.004551972971318997, 'l1_Layer_3': 0.04853694687685652, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.79 | sMAPE for Validation Set is: 7.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.89 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:03:34,701]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:35,564]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:40,990]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:41,591]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:46,616]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:48,368]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:49,292]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:03:56,004]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:00,290]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:04,140]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:06,634]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:09,549]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:10,026]\u001b[0m Trial 247 finished with value: 2.764123468026103 and parameters: {'n_hidden': 3, 'learning_rate': 0.009000272604032288, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29079597418032277, 'dropout_rate_Layer_2': 0.06563959527385353, 'dropout_rate_Layer_3': 0.21809542603729723, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.258620823448041e-05, 'l1_Layer_2': 0.005061960663305433, 'l1_Layer_3': 0.0807310666768817, 'n_units_Layer_1': 140, 'n_units_Layer_2': 120, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.97% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:04:15,128]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:15,862]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:16,836]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:20,662]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:24,289]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:26,645]\u001b[0m Trial 248 finished with value: 2.770086720387141 and parameters: {'n_hidden': 3, 'learning_rate': 0.005814971205059818, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2882824090351516, 'dropout_rate_Layer_2': 0.0725371610005251, 'dropout_rate_Layer_3': 0.3537216863315194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022482002620204502, 'l1_Layer_2': 0.005298142062773654, 'l1_Layer_3': 0.047501028918899686, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.90% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:04:26,997]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:27,809]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:31,068]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:35,687]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:39,542]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:42,989]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:50,190]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:51,114]\u001b[0m Trial 264 finished with value: 4.533501451925636 and parameters: {'n_hidden': 4, 'learning_rate': 0.026664279354739223, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038901068171799495, 'dropout_rate_Layer_2': 0.17180119650219303, 'dropout_rate_Layer_3': 0.12675322050397464, 'dropout_rate_Layer_4': 0.38513267620758623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.041231001093543e-05, 'l1_Layer_2': 0.07268959133620047, 'l1_Layer_3': 0.0003403351478135111, 'l1_Layer_4': 1.0307504344853618e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 140, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.53 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 4.67 | sMAPE for Test Set is: 11.77% | rMAE for Test Set is: 1.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:04:56,098]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:04:57,730]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:02,909]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:02,929]\u001b[0m Trial 262 finished with value: 2.763288017149522 and parameters: {'n_hidden': 3, 'learning_rate': 0.006355656522607049, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29499030425296896, 'dropout_rate_Layer_2': 0.050710650264609226, 'dropout_rate_Layer_3': 0.1924238048782367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002442074597660787, 'l1_Layer_2': 0.006714518264004745, 'l1_Layer_3': 0.04787589301934535, 'n_units_Layer_1': 160, 'n_units_Layer_2': 125, 'n_units_Layer_3': 75}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.87% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:05:03,408]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:13,240]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:14,434]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:15,710]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:18,169]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:24,027]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:29,291]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:32,441]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:34,216]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:37,984]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:38,409]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:39,205]\u001b[0m Trial 273 finished with value: 2.7351710348577694 and parameters: {'n_hidden': 3, 'learning_rate': 0.004910563449683288, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2446439861988226, 'dropout_rate_Layer_2': 0.036651930590115324, 'dropout_rate_Layer_3': 0.22294885818989035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.38125985638527e-05, 'l1_Layer_2': 0.0034687135983092424, 'l1_Layer_3': 0.0181300987814963, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.74 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:05:43,125]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:48,128]\u001b[0m Trial 281 finished with value: 4.63125545123436 and parameters: {'n_hidden': 3, 'learning_rate': 0.03143229341545879, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1490720572204002, 'dropout_rate_Layer_2': 0.17633092273552672, 'dropout_rate_Layer_3': 0.12096025902037601, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.4763764988628674e-05, 'l1_Layer_2': 0.08060486010538544, 'l1_Layer_3': 0.0008445016376119984, 'n_units_Layer_1': 50, 'n_units_Layer_2': 150, 'n_units_Layer_3': 100}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.63 | sMAPE for Validation Set is: 11.82% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 3.20 | sMAPE for Test Set is: 8.06% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:05:50,965]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:51,183]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:05:56,866]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:00,348]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:02,008]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:05,068]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:09,182]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:09,416]\u001b[0m Trial 289 finished with value: 2.907415753099061 and parameters: {'n_hidden': 3, 'learning_rate': 0.005726208929803605, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2776577059508108, 'dropout_rate_Layer_2': 0.1539631756768822, 'dropout_rate_Layer_3': 0.22313554186553025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.700501684894582e-05, 'l1_Layer_2': 0.0029947707321192987, 'l1_Layer_3': 0.07206703485141941, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 75}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 8.16% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:06:10,758]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:17,219]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:23,209]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:26,892]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:31,418]\u001b[0m Trial 292 finished with value: 2.836730875631506 and parameters: {'n_hidden': 3, 'learning_rate': 0.005601207048982744, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3104248693345581, 'dropout_rate_Layer_2': 0.08437519083083542, 'dropout_rate_Layer_3': 0.24885932817453332, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.092139269965066e-05, 'l1_Layer_2': 0.012537885591946185, 'l1_Layer_3': 0.020574917045313574, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 80}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.84 | sMAPE for Validation Set is: 8.03% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.17% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:06:32,506]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:35,787]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:36,904]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:41,786]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:44,414]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:44,581]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:50,373]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:50,596]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.23 | sMAPE for Test Set is: 5.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:06:53,040]\u001b[0m Trial 300 finished with value: 2.911412006259186 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020957166465578655, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14734568482509136, 'dropout_rate_Layer_2': 0.33662047533117667, 'dropout_rate_Layer_3': 0.15364459003022266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4065238362872607e-05, 'l1_Layer_2': 0.0001756140213399212, 'l1_Layer_3': 4.426968762258687e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:56,278]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:06:59,590]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:00,198]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:05,211]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:05,366]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:05,503]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:07:11,423]\u001b[0m Trial 306 finished with value: 2.810398581072383 and parameters: {'n_hidden': 3, 'learning_rate': 0.004956810065342054, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2844032399148304, 'dropout_rate_Layer_2': 0.11480910265829544, 'dropout_rate_Layer_3': 0.26560188146057273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.915745280060188e-05, 'l1_Layer_2': 0.006226512079565405, 'l1_Layer_3': 0.07068671624423797, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:13,436]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:17,521]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:18,067]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:20,251]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:23,872]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:24,458]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:25,222]\u001b[0m Trial 314 finished with value: 2.889264394806306 and parameters: {'n_hidden': 3, 'learning_rate': 0.003993951243349227, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2698432134977549, 'dropout_rate_Layer_2': 0.05272775759864695, 'dropout_rate_Layer_3': 0.2753811609232506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.2941493964292464e-05, 'l1_Layer_2': 0.006549787950667371, 'l1_Layer_3': 0.0663198526332491, 'n_units_Layer_1': 195, 'n_units_Layer_2': 140, 'n_units_Layer_3': 75}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.89 | sMAPE for Validation Set is: 8.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.25 | sMAPE for Test Set is: 5.90% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:07:30,138]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:30,986]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:31,523]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:38,045]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:43,706]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:44,227]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:46,831]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:51,846]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:56,005]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:07:58,688]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:08:01,897]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:08:08,118]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:08:11,918]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:08:15,617]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:08:48,752]\u001b[0m Trial 329 finished with value: 5.814686922081357 and parameters: {'n_hidden': 4, 'learning_rate': 0.011740053173931071, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.060035435118054425, 'dropout_rate_Layer_2': 0.08219762047121373, 'dropout_rate_Layer_3': 0.18492888614626662, 'dropout_rate_Layer_4': 0.39944512825963346, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.362778415104338e-05, 'l1_Layer_2': 0.017721052066491157, 'l1_Layer_3': 0.057796537115572866, 'l1_Layer_4': 1.0847597775757672e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 75, 'n_units_Layer_4': 225}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 14.47% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 3.09 | sMAPE for Test Set is: 7.62% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:08:52,826]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:08:56,425]\u001b[0m Trial 328 finished with value: 6.279953040290811 and parameters: {'n_hidden': 4, 'learning_rate': 0.011726785312079987, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2262043143783066, 'dropout_rate_Layer_2': 0.08998758180230755, 'dropout_rate_Layer_3': 0.1901034187172336, 'dropout_rate_Layer_4': 0.39962814147577225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.050535365012232e-05, 'l1_Layer_2': 0.018208121867203067, 'l1_Layer_3': 0.031069389659203774, 'l1_Layer_4': 1.4718641195411562e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80, 'n_units_Layer_4': 210}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 15.60% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 3.42 | sMAPE for Test Set is: 8.48% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:09:02,506]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:02,533]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:07,435]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:10,111]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:12,669]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:15,375]\u001b[0m Trial 340 finished with value: 2.8178351399974004 and parameters: {'n_hidden': 3, 'learning_rate': 0.006036375167624131, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3117771739135236, 'dropout_rate_Layer_2': 0.041429561368433454, 'dropout_rate_Layer_3': 0.24031757822508223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011943209681244333, 'l1_Layer_2': 0.0027014753949933276, 'l1_Layer_3': 0.030639730766105926, 'n_units_Layer_1': 135, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.04% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:09:18,277]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:18,798]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:23,219]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:25,950]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:28,135]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:29,656]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:36,086]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:37,554]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:42,510]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:46,340]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.76 | sMAPE for Validation Set is: 7.78% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.88 | sMAPE for Test Set is: 4.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:09:48,653]\u001b[0m Trial 349 finished with value: 2.7553433168067607 and parameters: {'n_hidden': 3, 'learning_rate': 0.012709157705645967, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3563859310087769, 'dropout_rate_Layer_2': 0.06610728050169952, 'dropout_rate_Layer_3': 0.2606689010619676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011516275086141877, 'l1_Layer_2': 0.009878175601918138, 'l1_Layer_3': 0.030320891784241327, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 110}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:51,421]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:52,161]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:52,277]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:09:58,670]\u001b[0m Trial 354 finished with value: 6.198781205129357 and parameters: {'n_hidden': 3, 'learning_rate': 0.028861895127018183, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14518841890906412, 'dropout_rate_Layer_2': 0.1993197024433616, 'dropout_rate_Layer_3': 0.11470636875602953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.510870221463535e-05, 'l1_Layer_2': 0.09189354608464775, 'l1_Layer_3': 0.0015350212483255159, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 105}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 15.37% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 3.43 | sMAPE for Test Set is: 8.52% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:09:59,830]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:01,495]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:02,100]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:03,505]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:10,629]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:10,889]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:10,965]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:17,642]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:20,281]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:20,550]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:26,386]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:30,032]\u001b[0m Trial 364 finished with value: 2.913803914281465 and parameters: {'n_hidden': 3, 'learning_rate': 0.04268212770939571, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16719277327895365, 'dropout_rate_Layer_2': 0.15366749192618562, 'dropout_rate_Layer_3': 0.045144130927722216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00042436930532055065, 'l1_Layer_2': 0.04658326582977785, 'l1_Layer_3': 9.716461587896619e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 85, 'n_units_Layer_3': 140}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 8.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.58% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:10:30,280]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:34,873]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:35,556]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:40,348]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:40,573]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:45,245]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:47,593]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:49,981]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:53,087]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:53,513]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:10:55,755]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:01,038]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:01,790]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:06,350]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:08,586]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:12,179]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:12,970]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:16,275]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:19,932]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:20,177]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:20,362]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:20,669]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:28,938]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:32,163]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:32,635]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:33,358]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:38,518]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:40,607]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:41,830]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 8.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:11:44,748]\u001b[0m Trial 394 finished with value: 2.955996624912851 and parameters: {'n_hidden': 3, 'learning_rate': 0.021062540268723264, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04582116530502815, 'dropout_rate_Layer_2': 0.2513928036582402, 'dropout_rate_Layer_3': 0.04618322789554432, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00432092712114416, 'l1_Layer_2': 0.008219479041127641, 'l1_Layer_3': 0.0001358823858965431, 'n_units_Layer_1': 100, 'n_units_Layer_2': 65, 'n_units_Layer_3': 150}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:47,008]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:48,632]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:50,691]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:52,583]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:11:59,960]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:00,169]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:08,467]\u001b[0m Trial 405 finished with value: 3.29626102693476 and parameters: {'n_hidden': 3, 'learning_rate': 0.019221853210308226, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10010778607016052, 'dropout_rate_Layer_2': 0.25803582262364033, 'dropout_rate_Layer_3': 0.04165352491216101, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003099871247429841, 'l1_Layer_2': 0.00246185055369408, 'l1_Layer_3': 1.6489320300002305e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 155}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.30 | sMAPE for Validation Set is: 8.94% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.00% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:12:15,364]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:15,686]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:23,648]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:27,886]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:47,517]\u001b[0m Trial 409 finished with value: 2.7065374072525983 and parameters: {'n_hidden': 3, 'learning_rate': 0.00212820345500753, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0449518128593278, 'dropout_rate_Layer_2': 0.028099652469321102, 'dropout_rate_Layer_3': 0.14332541640116364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004019614381427991, 'l1_Layer_2': 3.999368084900684e-05, 'l1_Layer_3': 0.004006486237498773, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 280}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 7.65% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:12:48,290]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:50,438]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:12:50,594]\u001b[0m Trial 408 finished with value: 2.823790802735856 and parameters: {'n_hidden': 4, 'learning_rate': 0.016498908593997975, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29809900146634244, 'dropout_rate_Layer_2': 0.16948623730108464, 'dropout_rate_Layer_3': 0.29435899099703033, 'dropout_rate_Layer_4': 0.04728794282252585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.216879162793133e-05, 'l1_Layer_2': 0.08870868488373933, 'l1_Layer_3': 0.007388567317870765, 'l1_Layer_4': 7.377240103077685e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 140, 'n_units_Layer_4': 155}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.82 | sMAPE for Validation Set is: 7.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:12:53,599]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:00,607]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:04,395]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:05,192]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:07,033]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:11,605]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:14,416]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:14,934]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:19,996]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:23,753]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:30,924]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:33,719]\u001b[0m Trial 420 finished with value: 3.8639885740706386 and parameters: {'n_hidden': 4, 'learning_rate': 0.04192402211988998, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2080935814801268, 'dropout_rate_Layer_2': 0.20735961857763874, 'dropout_rate_Layer_3': 0.2573610801276512, 'dropout_rate_Layer_4': 0.03203428831699144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09996601392688624, 'l1_Layer_2': 0.03419464343570107, 'l1_Layer_3': 0.0002641892850419345, 'l1_Layer_4': 0.0001862861861544448, 'n_units_Layer_1': 205, 'n_units_Layer_2': 230, 'n_units_Layer_3': 120, 'n_units_Layer_4': 185}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.86 | sMAPE for Validation Set is: 10.25% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.03% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:13:34,483]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:40,783]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:53,386]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:13:57,266]\u001b[0m Trial 429 finished with value: 2.7997970898413342 and parameters: {'n_hidden': 3, 'learning_rate': 0.004152072705941905, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26148162360146665, 'dropout_rate_Layer_2': 0.07895878118278966, 'dropout_rate_Layer_3': 0.16461583715463132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.807883375947577e-05, 'l1_Layer_2': 0.008928746569610117, 'l1_Layer_3': 0.028784745032232693, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 80}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.80 | sMAPE for Validation Set is: 7.93% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:14:02,309]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:04,999]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:06,188]\u001b[0m Trial 432 finished with value: 4.344024220827127 and parameters: {'n_hidden': 3, 'learning_rate': 0.05117142139542717, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3351871891273729, 'dropout_rate_Layer_2': 0.23899884865498427, 'dropout_rate_Layer_3': 0.0895365321242656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01084560919934328, 'l1_Layer_2': 0.008651015494316027, 'l1_Layer_3': 4.5878685699709466e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.34 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.87\n",
      "MAE for Test Set is: 2.71 | sMAPE for Test Set is: 7.04% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 3.17 | sMAPE for Validation Set is: 8.66% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.11 | sMAPE for Test Set is: 5.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:14:06,269]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:06,363]\u001b[0m Trial 428 finished with value: 3.1717185008725637 and parameters: {'n_hidden': 4, 'learning_rate': 0.047582418038126115, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20800697784712363, 'dropout_rate_Layer_2': 0.08644466766432374, 'dropout_rate_Layer_3': 0.2520504921760633, 'dropout_rate_Layer_4': 0.32749652500022847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00046408016693698584, 'l1_Layer_2': 0.032597624934433335, 'l1_Layer_3': 0.02257641017742983, 'l1_Layer_4': 1.842709962484263e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 235, 'n_units_Layer_3': 115, 'n_units_Layer_4': 185}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:11,141]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:14,762]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:17,038]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:17,218]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:17,822]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:24,365]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:27,831]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:28,297]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:32,838]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:34,011]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:38,642]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:42,028]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:42,715]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:46,306]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:46,841]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:46,880]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:49,629]\u001b[0m Trial 444 finished with value: 3.8987265810620193 and parameters: {'n_hidden': 3, 'learning_rate': 0.07424715814656434, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14637659425107227, 'dropout_rate_Layer_2': 0.06637277722409622, 'dropout_rate_Layer_3': 0.29786040943279546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005917169934453906, 'l1_Layer_2': 0.009130872832919258, 'l1_Layer_3': 0.06075632488065072, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 95}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.90 | sMAPE for Validation Set is: 10.33% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 2.77 | sMAPE for Test Set is: 7.49% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:14:54,899]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:55,918]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:55,989]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:14:56,834]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:06,552]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:10,404]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:10,937]\u001b[0m Trial 460 finished with value: 13.483468021494048 and parameters: {'n_hidden': 3, 'learning_rate': 0.050434665745026204, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28239944390586313, 'dropout_rate_Layer_2': 0.19827402959040372, 'dropout_rate_Layer_3': 0.1625702330662503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005701788909916459, 'l1_Layer_2': 0.0010149752777637686, 'l1_Layer_3': 1.051464433060473e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.48 | sMAPE for Validation Set is: 35.52% | rMAE for Validation Set is: 2.71\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:15:11,396]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:19,872]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:20,563]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:23,841]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:26,440]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:33,209]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:36,114]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:36,823]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:39,011]\u001b[0m Trial 459 finished with value: 4.437856275444813 and parameters: {'n_hidden': 4, 'learning_rate': 0.05325895207002349, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24236574196052024, 'dropout_rate_Layer_2': 0.17417194525568172, 'dropout_rate_Layer_3': 0.22320047424527167, 'dropout_rate_Layer_4': 0.1851198658450861, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00018674122211278935, 'l1_Layer_2': 0.06302411621993252, 'l1_Layer_3': 0.00829868944455972, 'l1_Layer_4': 1.861201361159038e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300, 'n_units_Layer_4': 270}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.44 | sMAPE for Validation Set is: 11.47% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 2.87 | sMAPE for Test Set is: 7.30% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:15:45,676]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:46,111]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:46,269]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:46,310]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:55,120]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:55,371]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:15:57,787]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:03,809]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:08,354]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:12,418]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:18,157]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:22,122]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 8.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:16:27,982]\u001b[0m Trial 476 finished with value: 2.874406070340722 and parameters: {'n_hidden': 4, 'learning_rate': 0.023752125108946174, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2631501638202305, 'dropout_rate_Layer_2': 0.22524529827412326, 'dropout_rate_Layer_3': 0.3028880856930652, 'dropout_rate_Layer_4': 0.29124949442323195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00025850852196498145, 'l1_Layer_2': 0.014375882468888473, 'l1_Layer_3': 0.017686725609811136, 'l1_Layer_4': 7.984020312521819e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160, 'n_units_Layer_4': 180}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:30,523]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:32,758]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:32,860]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:34,249]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:40,814]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:43,838]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:44,377]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:44,549]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:50,161]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:55,624]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:16:59,662]\u001b[0m Trial 491 finished with value: 3.321650325466134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0180563962780106, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11369070410236148, 'dropout_rate_Layer_2': 0.24544718161852958, 'dropout_rate_Layer_3': 0.03980256606638446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005424234953475484, 'l1_Layer_2': 0.0016154968672312318, 'l1_Layer_3': 1.8959681295484634e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 155}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.32 | sMAPE for Validation Set is: 9.00% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.30 | sMAPE for Test Set is: 6.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:17:03,253]\u001b[0m Trial 493 finished with value: 2.9622457989989264 and parameters: {'n_hidden': 3, 'learning_rate': 0.01647246706539523, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11054977795569923, 'dropout_rate_Layer_2': 0.2505295759135884, 'dropout_rate_Layer_3': 0.041240517623100915, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008930520898574858, 'l1_Layer_2': 0.002728641877647375, 'l1_Layer_3': 2.1009498943793465e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 50, 'n_units_Layer_3': 160}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.96 | sMAPE for Validation Set is: 8.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:17:03,460]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:04,542]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:11,354]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:11,746]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:16,350]\u001b[0m Trial 499 finished with value: 4.704990287626257 and parameters: {'n_hidden': 3, 'learning_rate': 0.04221303234321881, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07933056775234165, 'dropout_rate_Layer_2': 0.3113400699288813, 'dropout_rate_Layer_3': 0.09315618828378452, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017160120616152256, 'l1_Layer_2': 0.0004187902391084975, 'l1_Layer_3': 0.00018221013994680605, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 195}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 12.64% | rMAE for Validation Set is: 0.95\n",
      "MAE for Test Set is: 5.37 | sMAPE for Test Set is: 15.18% | rMAE for Test Set is: 1.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:17:18,745]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:18,848]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.60 | sMAPE for Validation Set is: 7.29% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.79 | sMAPE for Test Set is: 4.71% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:17:21,483]\u001b[0m Trial 478 finished with value: 2.5958682398378734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008370664449757986, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08393302665959863, 'dropout_rate_Layer_2': 0.17076176246774688, 'dropout_rate_Layer_3': 0.062258958805732297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006356764917229387, 'l1_Layer_2': 2.4215448331575062e-05, 'l1_Layer_3': 0.00011104468456888198, 'n_units_Layer_1': 160, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:25,996]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:26,732]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:31,280]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:34,941]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:37,646]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:37,778]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:45,529]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:45,783]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:49,719]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:51,141]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:55,570]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:58,652]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:59,527]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:17:59,587]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:01,070]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:07,565]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:08,271]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:08,271]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:11,197]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:11,986]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:17,511]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:17,709]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:22,099]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:24,142]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:26,956]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:28,271]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:32,634]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:33,300]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:35,227]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:39,663]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:39,947]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:44,496]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:44,985]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:50,328]\u001b[0m Trial 534 finished with value: 11.11568587798646 and parameters: {'n_hidden': 3, 'learning_rate': 0.06455520367853552, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20594323789603983, 'dropout_rate_Layer_2': 0.16132830357593214, 'dropout_rate_Layer_3': 0.01228686301566912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013887580770146008, 'l1_Layer_2': 0.0004984624273437734, 'l1_Layer_3': 2.76448346150882e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.12 | sMAPE for Validation Set is: 28.47% | rMAE for Validation Set is: 2.24\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 18.34% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:18:52,412]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:55,049]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:57,424]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:18:57,964]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:03,970]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:04,180]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:09,567]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:14,657]\u001b[0m Trial 540 finished with value: 2.9278005806871406 and parameters: {'n_hidden': 3, 'learning_rate': 0.014814073708800505, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08322870051755915, 'dropout_rate_Layer_2': 0.26013583291630127, 'dropout_rate_Layer_3': 0.04132483060720375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0028257969889611354, 'l1_Layer_2': 0.0010577276020854324, 'l1_Layer_3': 1.8338261282827168e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 125}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.93 | sMAPE for Validation Set is: 8.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.15 | sMAPE for Test Set is: 5.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:19:21,727]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:23,958]\u001b[0m Trial 545 finished with value: 2.9992239033487693 and parameters: {'n_hidden': 3, 'learning_rate': 0.015624826999946488, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08218689263979698, 'dropout_rate_Layer_2': 0.25758786705505654, 'dropout_rate_Layer_3': 0.044275564941147316, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0030908906252263054, 'l1_Layer_2': 0.0014649308769628157, 'l1_Layer_3': 1.5759882402873375e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 130}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 8.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:19:24,250]\u001b[0m Trial 546 finished with value: 3.0843288222460328 and parameters: {'n_hidden': 3, 'learning_rate': 0.013773699942111672, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0838830637205275, 'dropout_rate_Layer_2': 0.25929623013411607, 'dropout_rate_Layer_3': 0.04359465553610593, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002934364486544868, 'l1_Layer_2': 0.001562212649947966, 'l1_Layer_3': 1.5870801677685094e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.08 | sMAPE for Validation Set is: 8.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.40 | sMAPE for Test Set is: 6.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:19:29,571]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:29,995]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:30,809]\u001b[0m Trial 542 finished with value: 3.0081555209612723 and parameters: {'n_hidden': 4, 'learning_rate': 0.0340303011731288, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2855524214728916, 'dropout_rate_Layer_2': 0.19287395769944482, 'dropout_rate_Layer_3': 0.38076915420307456, 'dropout_rate_Layer_4': 0.3041191829806134, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00034533758950378745, 'l1_Layer_2': 0.00781106608412067, 'l1_Layer_3': 0.010737289552901489, 'l1_Layer_4': 1.2031422294683614e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270, 'n_units_Layer_4': 205}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.01 | sMAPE for Validation Set is: 8.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:19:32,879]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:39,133]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:44,101]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:45,692]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:47,955]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:51,920]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:19:55,303]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:00,049]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:00,472]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:00,816]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:04,741]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:06,382]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:09,106]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:10,590]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:17,053]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:17,758]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:23,313]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:26,234]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:26,969]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:28,060]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:32,953]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:36,729]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:37,550]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:39,231]\u001b[0m Trial 565 finished with value: 2.732947939598805 and parameters: {'n_hidden': 3, 'learning_rate': 0.005353929186921145, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29936275609091395, 'dropout_rate_Layer_2': 0.07925484552358433, 'dropout_rate_Layer_3': 0.22066206604771582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010274127747309528, 'l1_Layer_2': 0.017926929865851007, 'l1_Layer_3': 0.009869638954519666, 'n_units_Layer_1': 145, 'n_units_Layer_2': 165, 'n_units_Layer_3': 95}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 7.68% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.98% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:20:45,698]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:47,817]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:50,461]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:54,884]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:55,062]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:20:55,185]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:02,127]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:02,258]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:02,754]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:10,287]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:10,923]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:11,306]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:11,485]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:19,342]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:22,859]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:23,199]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:23,677]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:29,247]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:31,227]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:34,710]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:37,187]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:37,622]\u001b[0m Trial 590 finished with value: 3.1236975892207255 and parameters: {'n_hidden': 3, 'learning_rate': 0.006134047922482699, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06247077034719567, 'dropout_rate_Layer_2': 0.2767398662823776, 'dropout_rate_Layer_3': 0.026293957695302766, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011255344935572795, 'l1_Layer_2': 0.0002683846772079645, 'l1_Layer_3': 7.93955781001317e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 115}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.12 | sMAPE for Validation Set is: 8.58% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.91 | sMAPE for Test Set is: 7.95% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:21:39,622]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:40,163]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:43,902]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:46,305]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:50,322]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:50,730]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:50,877]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:51,129]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:21:55,026]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:01,851]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:02,197]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:07,824]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:11,379]\u001b[0m Trial 607 finished with value: 2.8140910912448027 and parameters: {'n_hidden': 3, 'learning_rate': 0.006836633381852491, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3011954598719251, 'dropout_rate_Layer_2': 0.14842909022045192, 'dropout_rate_Layer_3': 0.19019988181810912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.505036777018763e-05, 'l1_Layer_2': 0.0001395237254812412, 'l1_Layer_3': 0.009643623488826643, 'n_units_Layer_1': 125, 'n_units_Layer_2': 175, 'n_units_Layer_3': 75}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.81 | sMAPE for Validation Set is: 7.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 2.06 | sMAPE for Test Set is: 5.49% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:22:13,619]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:15,388]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:16,990]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:19,152]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:23,783]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:26,642]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:29,979]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:30,302]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:36,146]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:36,371]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:41,429]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:42,993]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:44,476]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:46,101]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:46,415]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:47,078]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:56,579]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:22:58,817]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:02,434]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:04,067]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:06,841]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:08,834]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:13,296]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:16,698]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:19,790]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:22,132]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:23,112]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:24,283]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:25,323]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:33,205]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:36,249]\u001b[0m Trial 639 finished with value: 7.6299317837027845 and parameters: {'n_hidden': 3, 'learning_rate': 0.02339150110065501, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023763943150154537, 'dropout_rate_Layer_2': 0.3476677767156533, 'dropout_rate_Layer_3': 0.020774108563244412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012210350016326978, 'l1_Layer_2': 3.2900832597226034e-05, 'l1_Layer_3': 0.0002531797778242381, 'n_units_Layer_1': 145, 'n_units_Layer_2': 75, 'n_units_Layer_3': 225}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 21.01% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 25.58% | rMAE for Test Set is: 2.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:23:39,676]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:48,120]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:51,910]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:54,370]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:56,886]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:23:59,360]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:01,656]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:02,628]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:02,870]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:06,587]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:10,000]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:12,573]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:15,432]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:17,388]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:22,310]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:29,068]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:32,324]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:32,564]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:32,919]\u001b[0m Trial 652 finished with value: 2.9135995242937534 and parameters: {'n_hidden': 3, 'learning_rate': 0.01570771782415583, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08068342778056307, 'dropout_rate_Layer_2': 0.26835116337131454, 'dropout_rate_Layer_3': 0.061234680868554714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004834926381680778, 'l1_Layer_2': 0.0013436543119247923, 'l1_Layer_3': 2.1730792727434796e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 135}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 8.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.96 | sMAPE for Test Set is: 5.14% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:24:41,947]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:43,372]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:47,464]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.81 | sMAPE for Test Set is: 4.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:24:48,986]\u001b[0m Trial 638 finished with value: 2.616940210393909 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006755993624622782, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15859543956790584, 'dropout_rate_Layer_2': 0.19653281037597164, 'dropout_rate_Layer_3': 0.22484116262259254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01109687248766998, 'l1_Layer_2': 0.00015277008262874387, 'l1_Layer_3': 0.00012108222786629973, 'n_units_Layer_1': 145, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:53,881]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:54,132]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:24:54,283]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:02,105]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:04,823]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:08,347]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:08,941]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:12,511]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:12,943]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:15,689]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:18,110]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:23,474]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:23,797]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:25,120]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:28,602]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:29,142]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:35,449]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:35,974]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:36,446]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:36,686]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:39,413]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:44,735]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:46,809]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:46,849]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:47,187]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:54,383]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:54,468]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:54,540]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:25:59,227]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:03,423]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:03,622]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:04,220]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:10,789]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:11,483]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:16,915]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:19,132]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:21,649]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:24,096]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:28,073]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:31,748]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:32,286]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:37,848]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:41,028]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:43,147]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:45,421]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.67 | sMAPE for Validation Set is: 7.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:26:48,718]\u001b[0m Trial 688 finished with value: 2.6679070135468215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007220976297224917, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15649897882808664, 'dropout_rate_Layer_2': 0.27366592741475215, 'dropout_rate_Layer_3': 0.24385043804239487, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007242254894555685, 'l1_Layer_2': 0.0020334985669320763, 'l1_Layer_3': 2.8614811325199712e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:49,594]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:54,114]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:54,643]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:26:55,437]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 7.57% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.81 | sMAPE for Test Set is: 4.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:27:01,067]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:01,611]\u001b[0m Trial 696 finished with value: 2.660813132344678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009150851276558419, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15743852169784145, 'dropout_rate_Layer_2': 0.27540179255401903, 'dropout_rate_Layer_3': 0.2576141081092843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008538395819397377, 'l1_Layer_2': 5.921877822318311e-05, 'l1_Layer_3': 2.6961397569010287e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 80, 'n_units_Layer_3': 150}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:02,225]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:09,934]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:14,605]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:15,126]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:17,618]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:20,523]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:21,336]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:23,027]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:27,516]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:27,985]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:28,936]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:34,359]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:35,639]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:38,316]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:43,518]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:44,066]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:50,992]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:55,147]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:55,777]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:27:57,674]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:03,037]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:07,302]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:07,921]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:11,396]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:14,525]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:15,394]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:17,121]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:21,988]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:23,200]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:24,630]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:26,643]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:31,713]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:32,167]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:32,791]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:39,777]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:41,596]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:44,476]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:49,526]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:57,159]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:57,463]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:28:58,057]\u001b[0m Trial 750 finished with value: 3.048214048535686 and parameters: {'n_hidden': 3, 'learning_rate': 0.047925201922206985, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07950597947808835, 'dropout_rate_Layer_2': 0.19133956046133985, 'dropout_rate_Layer_3': 0.2864924783955517, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008678544227338641, 'l1_Layer_2': 0.013304769835875545, 'l1_Layer_3': 0.004860091177956717, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 90}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.05 | sMAPE for Validation Set is: 8.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 5.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:29:02,955]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:04,722]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:04,894]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:06,344]\u001b[0m Trial 751 finished with value: 2.6796722486565234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008131906269294007, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15256124380206693, 'dropout_rate_Layer_2': 0.2740558174853045, 'dropout_rate_Layer_3': 0.28905573744375546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0074516744054931635, 'l1_Layer_2': 5.3143609771721224e-05, 'l1_Layer_3': 8.81895104374652e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 5.00% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:29:13,579]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:14,566]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:14,880]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:15,277]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:22,212]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:23,630]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:24,992]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:29,136]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:30,680]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:32,088]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:37,996]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:38,191]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:43,692]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:45,791]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:46,718]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:50,489]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:53,939]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:54,121]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:29:59,442]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:01,052]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:02,520]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:06,534]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:10,154]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:13,293]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:18,355]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:21,179]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:21,582]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:25,369]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:25,873]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:31,495]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:32,322]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:36,461]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:38,021]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:51,870]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:55,325]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:30:59,574]\u001b[0m Trial 784 finished with value: 2.5505861660266502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006340122722887389, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09228557019617063, 'dropout_rate_Layer_2': 0.36815097348996734, 'dropout_rate_Layer_3': 0.30303758742474873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004713461568149893, 'l1_Layer_2': 1.2092197757114409e-05, 'l1_Layer_3': 3.1016700007938986e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 275, 'n_units_Layer_3': 110}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.55 | sMAPE for Validation Set is: 7.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.75 | sMAPE for Test Set is: 4.65% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:31:08,034]\u001b[0m Trial 790 finished with value: 2.6659197082466255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006247297844586962, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20006750526751538, 'dropout_rate_Layer_2': 0.37343305757836875, 'dropout_rate_Layer_3': 0.30769216685180656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00510312336595196, 'l1_Layer_2': 4.689408105725319e-05, 'l1_Layer_3': 3.342834163726211e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 215, 'n_units_Layer_3': 150}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.67 | sMAPE for Validation Set is: 7.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:31:13,493]\u001b[0m Trial 796 finished with value: 3.097214781789584 and parameters: {'n_hidden': 4, 'learning_rate': 0.03684200820545921, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.251551649056694, 'dropout_rate_Layer_2': 0.2174787955518777, 'dropout_rate_Layer_3': 0.346189937980766, 'dropout_rate_Layer_4': 0.23899099651196726, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.0559530165737384e-05, 'l1_Layer_2': 0.027729670554462748, 'l1_Layer_3': 0.004818199021379796, 'l1_Layer_4': 9.033123933641662e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140, 'n_units_Layer_4': 230}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.10 | sMAPE for Validation Set is: 8.50% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.17 | sMAPE for Test Set is: 5.64% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:31:13,807]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:21,009]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:23,291]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:28,511]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:30,927]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:33,870]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:36,858]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:38,686]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:39,742]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:46,830]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:47,097]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:50,134]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:55,303]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:31:59,971]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:03,129]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:03,382]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:03,790]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:12,132]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:12,345]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:13,968]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:21,307]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:21,672]\u001b[0m Trial 811 finished with value: 2.8826910780439605 and parameters: {'n_hidden': 4, 'learning_rate': 0.060495210513679946, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24189952285593283, 'dropout_rate_Layer_2': 0.1920994335729091, 'dropout_rate_Layer_3': 0.31769038053123755, 'dropout_rate_Layer_4': 0.21253300111689152, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.807873620435133e-05, 'l1_Layer_2': 0.02720989896099472, 'l1_Layer_3': 0.007563164446100031, 'l1_Layer_4': 0.000212193412450459, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 110, 'n_units_Layer_4': 175}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 8.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.00 | sMAPE for Test Set is: 5.29% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:32:22,227]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:26,361]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:27,440]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:34,183]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:34,834]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:41,720]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:44,588]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:47,727]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:49,399]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:55,168]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:32:57,496]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:03,365]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:03,545]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:10,985]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:11,563]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:17,503]\u001b[0m Trial 827 finished with value: 3.128041778037002 and parameters: {'n_hidden': 4, 'learning_rate': 0.024373284465226182, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3006066652431115, 'dropout_rate_Layer_2': 0.18150777494155093, 'dropout_rate_Layer_3': 0.34521689905007, 'dropout_rate_Layer_4': 0.21103563075046702, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1071126648904278e-05, 'l1_Layer_2': 0.01201945571904226, 'l1_Layer_3': 0.007769213892757262, 'l1_Layer_4': 6.377193002683905e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110, 'n_units_Layer_4': 140}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.13 | sMAPE for Validation Set is: 8.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 2.03 | sMAPE for Test Set is: 5.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:33:21,073]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:25,431]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:28,530]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:35,158]\u001b[0m Trial 838 finished with value: 2.5656441169089224 and parameters: {'n_hidden': 3, 'learning_rate': 0.005760305456774035, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15081041214831928, 'dropout_rate_Layer_2': 0.06646417063886242, 'dropout_rate_Layer_3': 0.2271136220206124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.682382045081577e-05, 'l1_Layer_2': 9.05669419902765e-05, 'l1_Layer_3': 0.012876969812249952, 'n_units_Layer_1': 145, 'n_units_Layer_2': 190, 'n_units_Layer_3': 90}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.57 | sMAPE for Validation Set is: 7.39% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 5.03% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:33:41,773]\u001b[0m Trial 836 finished with value: 3.163005752075096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0496987904797088, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30006340740940657, 'dropout_rate_Layer_2': 0.23125958205401748, 'dropout_rate_Layer_3': 0.3073138022259961, 'dropout_rate_Layer_4': 0.283101786995455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00045279137460392006, 'l1_Layer_2': 0.026728949204839373, 'l1_Layer_3': 0.010812090271171167, 'l1_Layer_4': 0.0004230442748753972, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120, 'n_units_Layer_4': 190}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 8.70% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 2.59 | sMAPE for Test Set is: 6.77% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:33:46,842]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:51,243]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:33:55,756]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:00,016]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:03,837]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:06,735]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:10,161]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:10,237]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:12,296]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 7.50% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.88% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:34:15,708]\u001b[0m Trial 837 finished with value: 2.655096285436407 and parameters: {'n_hidden': 3, 'learning_rate': 0.001920524942940978, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19956445938108855, 'dropout_rate_Layer_2': 0.3975510670779506, 'dropout_rate_Layer_3': 0.2897827426308871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.010651393705202628, 'l1_Layer_2': 1.026123265199008e-05, 'l1_Layer_3': 1.4710688443629044e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:16,526]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:22,098]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:23,279]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:24,363]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:26,586]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:26,951]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:29,282]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:33,083]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:35,050]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:39,433]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:44,009]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:44,473]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:50,408]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:51,038]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:34:55,327]\u001b[0m Trial 863 finished with value: 3.31976600791711 and parameters: {'n_hidden': 4, 'learning_rate': 0.01898183261631758, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28152299189040997, 'dropout_rate_Layer_2': 0.16208784939617177, 'dropout_rate_Layer_3': 0.32137234987783686, 'dropout_rate_Layer_4': 0.2489633287253292, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.153289868269275e-05, 'l1_Layer_2': 0.028371972602338813, 'l1_Layer_3': 0.010472268333086093, 'l1_Layer_4': 0.0004445876333711382, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 280, 'n_units_Layer_4': 145}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.32 | sMAPE for Validation Set is: 9.08% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 2.37 | sMAPE for Test Set is: 6.41% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:34:58,954]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:02,378]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:02,638]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:03,504]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:05,101]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:08,292]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:12,238]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:13,163]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:14,983]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:22,063]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:24,371]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:25,524]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:27,503]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:31,016]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:34,914]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:39,668]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:42,182]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:44,773]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:45,031]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:48,047]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:53,547]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:35:54,373]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:00,330]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:03,133]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:03,787]\u001b[0m Trial 881 finished with value: 2.7179804328478028 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008952972170557759, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13701599290618055, 'dropout_rate_Layer_2': 0.34805643087111016, 'dropout_rate_Layer_3': 0.3539419947926399, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.031334689222833, 'l1_Layer_2': 6.189592150104502e-05, 'l1_Layer_3': 1.9145647666869063e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.63% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.90 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:36:09,776]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:12,462]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:15,837]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:20,990]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:22,836]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:27,446]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:27,852]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:36,384]\u001b[0m Trial 887 finished with value: 2.6045626391156875 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005903006559380167, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1419838302337898, 'dropout_rate_Layer_2': 0.36353287978628446, 'dropout_rate_Layer_3': 0.23506262011504042, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005643564680765741, 'l1_Layer_2': 4.342193591059992e-05, 'l1_Layer_3': 2.0008312464362478e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.60 | sMAPE for Validation Set is: 7.40% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.99 | sMAPE for Test Set is: 5.39% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:36:39,916]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:40,005]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:46,310]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:48,925]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:49,144]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:56,675]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:36:57,035]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:00,413]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:01,918]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:06,223]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:06,705]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:07,396]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:14,519]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:15,497]\u001b[0m Trial 892 finished with value: 2.564034424058996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006247007312043846, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12481381787422269, 'dropout_rate_Layer_2': 0.3594179000956492, 'dropout_rate_Layer_3': 0.23083524057096338, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006296161341568198, 'l1_Layer_2': 3.686298757700266e-05, 'l1_Layer_3': 2.1007435523127505e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.56 | sMAPE for Validation Set is: 7.33% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.95 | sMAPE for Test Set is: 5.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:37:19,792]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:22,283]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:26,415]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:26,689]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:30,253]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:34,495]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:34,670]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:36,038]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:41,419]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:41,880]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:44,684]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:49,471]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:49,723]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:56,194]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:37:56,427]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:02,090]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:03,060]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:08,878]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:11,746]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:14,525]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:14,554]\u001b[0m Trial 913 finished with value: 2.9991876514530715 and parameters: {'n_hidden': 4, 'learning_rate': 0.01557061324958631, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33744968644280854, 'dropout_rate_Layer_2': 0.19386115007997579, 'dropout_rate_Layer_3': 0.295962037278849, 'dropout_rate_Layer_4': 0.30509878672151813, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.303763766482395e-05, 'l1_Layer_2': 0.09995520949880131, 'l1_Layer_3': 0.01465579971987786, 'l1_Layer_4': 4.7015088505727e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100, 'n_units_Layer_4': 120}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 8.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.12 | sMAPE for Test Set is: 5.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:38:15,892]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:23,620]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:27,108]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:31,301]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:32,211]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:39,097]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:46,209]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:54,888]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:57,347]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:38:59,272]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.53 | sMAPE for Validation Set is: 7.25% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.75 | sMAPE for Test Set is: 4.62% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:39:02,519]\u001b[0m Trial 926 finished with value: 2.5346682819973823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006849301724606135, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1482069204943584, 'dropout_rate_Layer_2': 0.3724373131574328, 'dropout_rate_Layer_3': 0.21314587751861364, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008158634929128904, 'l1_Layer_2': 4.326646623749682e-05, 'l1_Layer_3': 4.7530127753304775e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:07,818]\u001b[0m Trial 937 finished with value: 2.9129242462863245 and parameters: {'n_hidden': 4, 'learning_rate': 0.013394023281686504, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.339302801046404, 'dropout_rate_Layer_2': 0.19237553021679957, 'dropout_rate_Layer_3': 0.29598200489773857, 'dropout_rate_Layer_4': 0.303357204711338, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.30207387802132e-05, 'l1_Layer_2': 0.044008938409403654, 'l1_Layer_3': 0.01847705911654558, 'l1_Layer_4': 4.5793145228729243e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 190, 'n_units_Layer_3': 100, 'n_units_Layer_4': 100}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 8.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.09 | sMAPE for Test Set is: 5.54% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:39:12,438]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:13,287]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:17,576]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:20,257]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:24,512]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:27,651]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:32,217]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:32,396]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:37,548]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:38,790]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:40,374]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:43,125]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:47,562]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:48,154]\u001b[0m Trial 948 finished with value: 2.594638931240672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007337937900869048, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1009746823039251, 'dropout_rate_Layer_2': 0.3726902837341807, 'dropout_rate_Layer_3': 0.19805827739902812, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003748846301494569, 'l1_Layer_2': 0.0001082008421903046, 'l1_Layer_3': 3.905211847661326e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 225, 'n_units_Layer_3': 110}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.59 | sMAPE for Validation Set is: 7.39% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.83 | sMAPE for Test Set is: 4.84% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:39:51,987]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:54,006]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:55,078]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:39:57,131]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:02,828]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:04,196]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:10,609]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:10,939]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:16,874]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:18,320]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:21,773]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:25,576]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:25,875]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:26,437]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:32,707]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:33,448]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:34,242]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:35,604]\u001b[0m Trial 961 finished with value: 2.7108484576267906 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007132213402354235, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14771481550567905, 'dropout_rate_Layer_2': 0.3883672482477644, 'dropout_rate_Layer_3': 0.210799684123724, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015076934537302064, 'l1_Layer_2': 2.511982314558787e-05, 'l1_Layer_3': 3.699886087847817e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 195, 'n_units_Layer_3': 105}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.71 | sMAPE for Validation Set is: 7.64% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.91% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:40:37,012]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:42,602]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:46,015]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:48,044]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:50,177]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:54,419]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:40:54,677]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:01,587]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:01,803]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:04,132]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:08,832]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:10,822]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:16,423]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:16,469]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:23,963]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:26,604]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:26,928]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:27,129]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:34,129]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:34,871]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:35,295]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:43,917]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:47,536]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:49,486]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:52,711]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:41:57,295]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:00,298]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:04,045]\u001b[0m Trial 998 finished with value: 2.7513723626549687 and parameters: {'n_hidden': 3, 'learning_rate': 0.004620739536208121, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2094497694936298, 'dropout_rate_Layer_2': 0.17409818919824732, 'dropout_rate_Layer_3': 0.19186028584036327, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007492130412094103, 'l1_Layer_2': 0.00013790841437954016, 'l1_Layer_3': 0.04891107709198685, 'n_units_Layer_1': 100, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 7.75% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.94% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:42:04,214]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:05,949]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:12,504]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:12,589]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:12,795]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:20,113]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:22,707]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:27,295]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:32,430]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:36,515]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:36,659]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:43,355]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:45,891]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:47,120]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:49,734]\u001b[0m Trial 1005 finished with value: 2.6568387581693833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010599532592326742, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11186806927774495, 'dropout_rate_Layer_2': 0.39057580676589265, 'dropout_rate_Layer_3': 0.17491202627210783, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00919799845422672, 'l1_Layer_2': 0.0001546706132287474, 'l1_Layer_3': 2.252547407307407e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.66 | sMAPE for Validation Set is: 7.51% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.78 | sMAPE for Test Set is: 4.69% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:42:55,938]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:42:56,527]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:01,486]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:01,741]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:07,651]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:07,827]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:14,137]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:14,407]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:19,943]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:23,485]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:27,291]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:33,016]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:37,246]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:41,966]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:47,304]\u001b[0m Trial 1015 finished with value: 2.743265964429916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011347446420527738, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11635879923154566, 'dropout_rate_Layer_2': 0.38587173596631685, 'dropout_rate_Layer_3': 0.17382416172469492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0088837521377274, 'l1_Layer_2': 0.00017406936915863297, 'l1_Layer_3': 2.4191457735622425e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 110}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.74 | sMAPE for Validation Set is: 7.72% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.87 | sMAPE for Test Set is: 4.91% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:43:50,814]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:50,974]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:57,757]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:43:58,009]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:04,558]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:04,955]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:10,305]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:11,370]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:17,394]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:17,769]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:22,571]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:26,675]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:29,528]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:33,013]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:33,765]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:38,854]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:39,715]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:43,855]\u001b[0m Trial 1041 finished with value: 2.9418181209191263 and parameters: {'n_hidden': 4, 'learning_rate': 0.046876198220918326, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3347736342732013, 'dropout_rate_Layer_2': 0.20962875798182595, 'dropout_rate_Layer_3': 0.36292308358318737, 'dropout_rate_Layer_4': 0.2506591444495451, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.664735770346373e-05, 'l1_Layer_2': 0.017136576389681475, 'l1_Layer_3': 0.019918706967691012, 'l1_Layer_4': 4.948190833644496e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 215, 'n_units_Layer_3': 120, 'n_units_Layer_4': 155}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 8.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.98 | sMAPE for Test Set is: 5.20% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:44:48,416]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:51,194]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:52,279]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:59,302]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:44:59,835]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:03,535]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:08,074]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:09,220]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:14,174]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:16,269]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:17,387]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:19,304]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:24,447]\u001b[0m Trial 1042 finished with value: 2.9370079634620265 and parameters: {'n_hidden': 4, 'learning_rate': 0.042400497246079374, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26993340020734435, 'dropout_rate_Layer_2': 0.21493498259220062, 'dropout_rate_Layer_3': 0.29658675391923545, 'dropout_rate_Layer_4': 0.25130799695566514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.005992689243016e-05, 'l1_Layer_2': 0.07794353085417394, 'l1_Layer_3': 0.013320548566956384, 'l1_Layer_4': 4.92384083973974e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 220, 'n_units_Layer_3': 105, 'n_units_Layer_4': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 8.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.37% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:45:27,543]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:30,177]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:30,921]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:37,454]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:41,536]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:45,493]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:45,942]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:51,036]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:54,272]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:45:58,645]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:02,783]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:06,607]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:12,164]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:12,630]\u001b[0m Trial 1072 finished with value: 3.0261365850011734 and parameters: {'n_hidden': 4, 'learning_rate': 0.043883639909479605, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2529865707887758, 'dropout_rate_Layer_2': 0.17340696082410575, 'dropout_rate_Layer_3': 0.36850334624295056, 'dropout_rate_Layer_4': 0.24343604777148636, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.9013908068558253e-05, 'l1_Layer_2': 0.0994670079882286, 'l1_Layer_3': 0.01761000736336793, 'l1_Layer_4': 3.4842594233670214e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 105, 'n_units_Layer_4': 55}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 8.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:46:24,068]\u001b[0m Trial 1084 finished with value: 2.8601376607164988 and parameters: {'n_hidden': 3, 'learning_rate': 0.004239601548579266, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1891505125346086, 'dropout_rate_Layer_2': 0.18736483417463595, 'dropout_rate_Layer_3': 0.2656063414272062, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013751292222255471, 'l1_Layer_2': 0.011113737610399453, 'l1_Layer_3': 1.564697580009413e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 120, 'n_units_Layer_3': 70}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.86 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.21% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:46:27,738]\u001b[0m Trial 1081 finished with value: 2.75172483871325 and parameters: {'n_hidden': 3, 'learning_rate': 0.005452618551154211, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2830950919537066, 'dropout_rate_Layer_2': 0.07904382806448478, 'dropout_rate_Layer_3': 0.1605850351345755, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5741040060545445e-05, 'l1_Layer_2': 0.0009228280913593319, 'l1_Layer_3': 0.02980168060148286, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 70}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.75 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:46:28,301]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:33,203]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:37,125]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:37,560]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:45,032]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:52,445]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:56,107]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:46:59,799]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:01,470]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:04,844]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:12,717]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:20,348]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:23,745]\u001b[0m Trial 1090 finished with value: 2.904881482799182 and parameters: {'n_hidden': 4, 'learning_rate': 0.040785078395433036, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2544087009878876, 'dropout_rate_Layer_2': 0.20461643233575008, 'dropout_rate_Layer_3': 0.3749705737146506, 'dropout_rate_Layer_4': 0.25334025559933043, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.691993943300151e-05, 'l1_Layer_2': 0.06449743733977246, 'l1_Layer_3': 0.01802793734616646, 'l1_Layer_4': 2.42555561325478e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 265, 'n_units_Layer_3': 90, 'n_units_Layer_4': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:23,855]\u001b[0m Trial 1095 finished with value: 2.6810711764445743 and parameters: {'n_hidden': 3, 'learning_rate': 0.005628884806341053, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.273778601643543, 'dropout_rate_Layer_2': 0.0962128141553868, 'dropout_rate_Layer_3': 0.22794737553947314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.986532747108353e-05, 'l1_Layer_2': 0.002239741374804652, 'l1_Layer_3': 1.5631434945248488e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:23,944]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.02% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.61% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.97 | sMAPE for Test Set is: 5.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:47:24,064]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:35,557]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:38,909]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:47,960]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:50,992]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:55,336]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:59,349]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:47:59,491]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:00,654]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:05,755]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:07,926]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:13,234]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:13,664]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:14,060]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:21,637]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:22,860]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:26,738]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:31,821]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:32,440]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:37,146]\u001b[0m Trial 1106 finished with value: 2.723428682042234 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005591340484725817, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055741921243018015, 'dropout_rate_Layer_2': 0.13401013420353408, 'dropout_rate_Layer_3': 0.0864178071472339, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020091331144024037, 'l1_Layer_2': 1.3933284374190237e-05, 'l1_Layer_3': 1.939019211090271e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 275, 'n_units_Layer_3': 290}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.54% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.94 | sMAPE for Test Set is: 5.16% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:48:37,939]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:40,190]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:41,657]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:48,518]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:49,278]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:50,851]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:48:57,541]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:01,059]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:03,817]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:05,457]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:07,685]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:09,277]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:09,391]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:12,052]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:20,170]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:23,921]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:24,755]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:24,864]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:26,044]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:30,863]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:32,994]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:34,510]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:35,586]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:45,247]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:46,650]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:48,327]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:48,831]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:49,565]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:56,838]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:59,008]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:49:59,334]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:02,939]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:09,688]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:12,449]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:13,998]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:18,438]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:20,864]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:21,041]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:22,668]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:27,762]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:34,685]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:39,200]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:39,651]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:41,022]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:43,712]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:51,175]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:51,779]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:52,497]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:50:57,206]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:00,088]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:02,299]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:05,739]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:12,978]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:13,309]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:21,303]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:21,569]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:26,638]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:28,124]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:34,202]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:39,665]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:42,897]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:43,378]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:46,098]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:48,838]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:50,505]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:53,196]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:51:59,643]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:03,980]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:10,604]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:14,477]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:16,735]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:20,225]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:22,576]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:23,130]\u001b[0m Trial 1180 finished with value: 3.063958141284282 and parameters: {'n_hidden': 4, 'learning_rate': 0.03859339204929594, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24045364782115594, 'dropout_rate_Layer_2': 0.23779841902072832, 'dropout_rate_Layer_3': 0.3554459648746755, 'dropout_rate_Layer_4': 0.06533175828815388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.362162473803665e-05, 'l1_Layer_2': 0.038092436299411114, 'l1_Layer_3': 0.01624480042883042, 'l1_Layer_4': 3.4529042173609515e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 255, 'n_units_Layer_3': 100, 'n_units_Layer_4': 55}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.06 | sMAPE for Validation Set is: 8.47% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 2.10 | sMAPE for Test Set is: 5.57% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:52:23,900]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:31,395]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:31,417]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:36,744]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:41,953]\u001b[0m Trial 1187 finished with value: 2.878182361392335 and parameters: {'n_hidden': 4, 'learning_rate': 0.04653118368339766, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23798125356525904, 'dropout_rate_Layer_2': 0.2374255804761546, 'dropout_rate_Layer_3': 0.352722422187272, 'dropout_rate_Layer_4': 0.2031383321094497, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.626711740745491e-05, 'l1_Layer_2': 0.059000727352692545, 'l1_Layer_3': 0.015940021540772294, 'l1_Layer_4': 3.711416214992715e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 200, 'n_units_Layer_3': 100, 'n_units_Layer_4': 55}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 8.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:52:46,227]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:49,265]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:54,438]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:52:55,188]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:04,408]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:06,840]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:07,212]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:13,555]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:17,575]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:20,004]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:24,003]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:44,179]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:48,332]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:55,344]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:53:57,810]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:03,297]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:12,325]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:16,119]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:17,278]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:23,268]\u001b[0m Trial 1211 finished with value: 2.882701533448985 and parameters: {'n_hidden': 4, 'learning_rate': 0.0322912884749987, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28920086314955, 'dropout_rate_Layer_2': 0.2124819227399159, 'dropout_rate_Layer_3': 0.36643332259488853, 'dropout_rate_Layer_4': 0.06315252218991091, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8504213901666684e-05, 'l1_Layer_2': 0.049049669814915514, 'l1_Layer_3': 0.03906072005251973, 'l1_Layer_4': 2.117734081795351e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 270, 'n_units_Layer_3': 105, 'n_units_Layer_4': 70}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.88 | sMAPE for Validation Set is: 8.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 5.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:54:26,663]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:30,826]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:34,184]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:37,047]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:40,491]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:43,708]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:47,869]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:48,384]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:48,533]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:52,317]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:54:58,305]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:00,167]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:04,232]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:04,308]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:13,930]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:19,590]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:22,666]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:25,979]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:27,787]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:28,406]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:32,285]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:32,658]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:36,594]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:41,283]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:45,862]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:51,058]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:55,637]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:55:59,138]\u001b[0m Trial 1239 finished with value: 2.900761703690115 and parameters: {'n_hidden': 3, 'learning_rate': 0.004417414957698729, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19976791622585008, 'dropout_rate_Layer_2': 0.19120233414590482, 'dropout_rate_Layer_3': 0.32204683885125185, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008270212546839847, 'l1_Layer_2': 0.00011915128475829513, 'l1_Layer_3': 7.19839446792816e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 275, 'n_units_Layer_3': 155}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 8.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 2.24 | sMAPE for Test Set is: 5.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:56:01,465]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:02,199]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:03,642]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:10,487]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:13,759]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:17,640]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:20,696]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:21,968]\u001b[0m Trial 1245 finished with value: 2.9102551519315782 and parameters: {'n_hidden': 3, 'learning_rate': 0.004580296314034112, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1963944551190889, 'dropout_rate_Layer_2': 0.3723327530554404, 'dropout_rate_Layer_3': 0.19379038260008769, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.007967418234890026, 'l1_Layer_2': 1.3309151670983162e-05, 'l1_Layer_3': 2.498130557603023e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.91 | sMAPE for Validation Set is: 8.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.19 | sMAPE for Test Set is: 5.80% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:56:22,258]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:24,615]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:30,237]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:30,278]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:36,008]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:36,791]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:37,066]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:42,732]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:45,683]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:51,567]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:52,092]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:57,005]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:56:57,616]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:03,975]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:04,606]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:09,759]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:10,288]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:16,965]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:17,140]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:23,110]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:23,341]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:24,733]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:32,545]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:32,664]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:39,128]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:42,538]\u001b[0m Trial 1266 finished with value: 2.8653006748114223 and parameters: {'n_hidden': 4, 'learning_rate': 0.021460267305736122, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2229771198639826, 'dropout_rate_Layer_2': 0.19750995741289668, 'dropout_rate_Layer_3': 0.33530368382275416, 'dropout_rate_Layer_4': 0.06316500731274387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.6566762695684585e-05, 'l1_Layer_2': 0.03465542178737549, 'l1_Layer_3': 0.0490944190654253, 'l1_Layer_4': 3.410311521417806e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 255, 'n_units_Layer_3': 110, 'n_units_Layer_4': 70}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.87 | sMAPE for Validation Set is: 8.01% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.92 | sMAPE for Test Set is: 5.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:57:42,916]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:48,669]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:52,361]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:57:58,984]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:02,006]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:05,787]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:13,063]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:23,230]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:23,634]\u001b[0m Trial 1279 finished with value: 2.9406892070068777 and parameters: {'n_hidden': 4, 'learning_rate': 0.04051348139645283, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22714853462988277, 'dropout_rate_Layer_2': 0.25651205456706333, 'dropout_rate_Layer_3': 0.37633587152167186, 'dropout_rate_Layer_4': 0.06497420365971639, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.6302051885991664e-05, 'l1_Layer_2': 0.08390187273787006, 'l1_Layer_3': 0.013427122516285087, 'l1_Layer_4': 3.331726912315966e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 110, 'n_units_Layer_4': 70}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.94 | sMAPE for Validation Set is: 8.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 2.05 | sMAPE for Test Set is: 5.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:58:29,600]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:29,999]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:37,628]\u001b[0m Trial 1283 finished with value: 2.5407060540188624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007952327537731715, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15488628387463607, 'dropout_rate_Layer_2': 0.3790954088540636, 'dropout_rate_Layer_3': 0.28252578992790894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004609023280738073, 'l1_Layer_2': 5.698083863536006e-05, 'l1_Layer_3': 4.509919784927944e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.54 | sMAPE for Validation Set is: 7.22% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.75 | sMAPE for Test Set is: 4.67% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:58:38,350]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:44,733]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:48,526]\u001b[0m Trial 1288 finished with value: 2.7337616343693583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006390629628330333, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16522650680816708, 'dropout_rate_Layer_2': 0.3793143845907569, 'dropout_rate_Layer_3': 0.1541782898553788, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015534674051974855, 'l1_Layer_2': 5.9596192305399134e-05, 'l1_Layer_3': 4.597520816576884e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 7.69% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.90% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:58:49,077]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:49,343]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:58:56,563]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:00,111]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:04,089]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:06,389]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:09,756]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:09,928]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:11,020]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:18,512]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:21,337]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:21,905]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:25,849]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:30,246]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:30,695]\u001b[0m Trial 1299 finished with value: 2.971844948128394 and parameters: {'n_hidden': 3, 'learning_rate': 0.001010403028696114, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14818867049251622, 'dropout_rate_Layer_2': 0.13316256235120402, 'dropout_rate_Layer_3': 0.2518679310235775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004343423042194562, 'l1_Layer_2': 3.54495110637038e-05, 'l1_Layer_3': 1.9036843395445685e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 8.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.93 | sMAPE for Test Set is: 5.22% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 16:59:35,656]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:37,608]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:42,807]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:45,232]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:46,700]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:54,997]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 16:59:59,058]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:07,978]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:11,734]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:18,743]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:22,779]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:22,907]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:23,311]\u001b[0m Trial 1315 finished with value: 3.01758501039093 and parameters: {'n_hidden': 4, 'learning_rate': 0.032011461914045934, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1995368349255306, 'dropout_rate_Layer_2': 0.19385250984945468, 'dropout_rate_Layer_3': 0.376232273307032, 'dropout_rate_Layer_4': 0.06145388946841663, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.2513918664476954e-05, 'l1_Layer_2': 0.019208208975093934, 'l1_Layer_3': 0.05341054625708112, 'l1_Layer_4': 1.4115739207376779e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 270, 'n_units_Layer_3': 90, 'n_units_Layer_4': 80}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.02 | sMAPE for Validation Set is: 8.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 2.35 | sMAPE for Test Set is: 6.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:00:31,435]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:32,358]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:32,976]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:41,620]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:41,748]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:46,667]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:52,313]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:55,948]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:00:56,347]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:03,154]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:04,432]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:08,039]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:11,705]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:12,316]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:17,156]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:26,067]\u001b[0m Trial 1316 finished with value: 2.6891876468711726 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005440684817082754, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17238953434119952, 'dropout_rate_Layer_2': 0.39985625058539714, 'dropout_rate_Layer_3': 0.26263270490211166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003090962540999807, 'l1_Layer_2': 0.0036103291021360195, 'l1_Layer_3': 2.2556935943116306e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.69 | sMAPE for Validation Set is: 7.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.86% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:01:32,258]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:36,948]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:41,590]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:45,107]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:49,914]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:53,007]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:53,152]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:01:54,129]\u001b[0m Trial 1329 finished with value: 2.732933982413131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006271814454279983, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028549297509877867, 'dropout_rate_Layer_2': 0.13116750424430249, 'dropout_rate_Layer_3': 0.02272829977924546, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001364340426528041, 'l1_Layer_2': 0.0005331267003656535, 'l1_Layer_3': 0.0030878557512173306, 'n_units_Layer_1': 90, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.73 | sMAPE for Validation Set is: 7.72% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:02:02,265]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:02,472]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:02,811]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:07,390]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:16,386]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:16,588]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:17,716]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:28,978]\u001b[0m Trial 1339 finished with value: 2.629304012768318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005572851575650979, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12687220196620333, 'dropout_rate_Layer_2': 0.37061912344188497, 'dropout_rate_Layer_3': 0.2098041939377721, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031384730508961585, 'l1_Layer_2': 0.00014964374854617893, 'l1_Layer_3': 0.0022363888313815306, 'n_units_Layer_1': 100, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.63 | sMAPE for Validation Set is: 7.48% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.93% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:02:29,540]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:29,788]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:37,636]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:39,844]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:45,618]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:46,800]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:49,556]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:56,186]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:02:59,673]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:04,704]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:10,331]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:11,243]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:14,014]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:21,048]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:21,508]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:23,252]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:25,858]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:28,033]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:32,469]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:36,549]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:40,112]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:42,464]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:43,140]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:45,668]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:48,353]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:53,992]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:03:55,202]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:00,367]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:00,501]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:07,320]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:09,653]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:09,764]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:11,704]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:14,442]\u001b[0m Trial 1354 finished with value: 2.625671280220678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006627942141542312, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029376458236012017, 'dropout_rate_Layer_2': 0.11505379877298162, 'dropout_rate_Layer_3': 0.010115566842052554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002718589047057507, 'l1_Layer_2': 0.0004268605342985498, 'l1_Layer_3': 0.004016376428211886, 'n_units_Layer_1': 95, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.63 | sMAPE for Validation Set is: 7.47% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 4.90% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:04:15,091]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:15,137]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:25,773]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:26,433]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:32,819]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:34,953]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:36,184]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:42,242]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:47,616]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:51,071]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:52,006]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:04:59,036]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:06,791]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:16,221]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:16,582]\u001b[0m Trial 1404 finished with value: 4.497057858641144 and parameters: {'n_hidden': 4, 'learning_rate': 0.03376123157281227, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24915971452693697, 'dropout_rate_Layer_2': 0.2191444044627777, 'dropout_rate_Layer_3': 0.3935968347859674, 'dropout_rate_Layer_4': 0.29160833468224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.7190631955637886e-05, 'l1_Layer_2': 0.0822879628912719, 'l1_Layer_3': 0.048389168097381315, 'l1_Layer_4': 5.481360646332407e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 210, 'n_units_Layer_3': 110, 'n_units_Layer_4': 150}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.50 | sMAPE for Validation Set is: 12.10% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 3.23 | sMAPE for Test Set is: 8.80% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:05:23,562]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:25,215]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:35,781]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:44,178]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:51,768]\u001b[0m Trial 1406 finished with value: 2.7653918587739685 and parameters: {'n_hidden': 4, 'learning_rate': 0.04866241341289957, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08161368658339684, 'dropout_rate_Layer_2': 0.19544896674402915, 'dropout_rate_Layer_3': 0.30003410539013503, 'dropout_rate_Layer_4': 0.056577211365524065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002063886653342931, 'l1_Layer_2': 0.014082447175045499, 'l1_Layer_3': 0.008309941237962568, 'l1_Layer_4': 1.2291466149845435e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 265, 'n_units_Layer_3': 85, 'n_units_Layer_4': 60}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.77 | sMAPE for Validation Set is: 7.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.31 | sMAPE for Test Set is: 6.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:05:56,321]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:56,471]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:05:56,849]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:07,097]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:10,345]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:13,754]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:15,063]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:22,365]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:22,579]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:27,160]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:32,500]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:34,516]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:37,747]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:06:52,135]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:15,409]\u001b[0m Trial 1422 finished with value: 2.7244282650636786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005327004669086137, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10658418894384596, 'dropout_rate_Layer_2': 0.39232953204413873, 'dropout_rate_Layer_3': 0.30313769841248006, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001936775187742039, 'l1_Layer_2': 2.1902700201580377e-05, 'l1_Layer_3': 0.004532297465969962, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 7.67% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 1.86 | sMAPE for Test Set is: 4.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:07:19,182]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:22,445]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:28,684]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:32,323]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:35,476]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:39,132]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:42,080]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:42,255]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:44,324]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:51,620]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:54,477]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:07:55,232]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:03,378]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:05,905]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:08,322]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:11,172]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:14,991]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:20,973]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:21,626]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:24,099]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:29,302]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:31,300]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:35,402]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:35,636]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:40,762]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:42,457]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:46,860]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:47,904]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:08:52,806]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:11,399]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:15,027]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:18,491]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:23,497]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:27,961]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:33,530]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:33,693]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:42,685]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:46,734]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:47,343]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:48,227]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:09:57,643]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:02,322]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:04,915]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:12,567]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:23,322]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:25,819]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:30,631]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:33,723]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:36,917]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:46,486]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:53,187]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:10:59,090]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:03,076]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:08,775]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:09,223]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 7.42% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.82 | sMAPE for Test Set is: 4.87% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:11:12,224]\u001b[0m Trial 1445 finished with value: 2.623428369252153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006937453253134539, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005657463301392043, 'dropout_rate_Layer_2': 0.07711747008042687, 'dropout_rate_Layer_3': 0.013095120519307375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003202775648350714, 'l1_Layer_2': 0.0006148834210229731, 'l1_Layer_3': 0.00352527055871828, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 260}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:17,299]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:21,963]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:26,167]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:31,710]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:37,199]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:43,083]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:46,829]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:51,943]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:11:56,954]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:03,535]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:10,092]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:15,642]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:21,493]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:23,274]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 7.58% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 1.85 | sMAPE for Test Set is: 4.95% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:12:24,028]\u001b[0m Trial 1488 finished with value: 2.680585801707966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006715874318246986, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1532018968455037, 'dropout_rate_Layer_2': 0.17486447100842092, 'dropout_rate_Layer_3': 0.2937855343448149, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006323153702636307, 'l1_Layer_2': 7.075072478001613e-05, 'l1_Layer_3': 5.170455658392495e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 255, 'n_units_Layer_3': 125}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:31,107]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:34,313]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:35,238]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:44,678]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 17:12:56,435]\u001b[0m Trial 1498 finished with value: 3.0040932990008447 and parameters: {'n_hidden': 4, 'learning_rate': 0.034526013147988206, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33835167564363555, 'dropout_rate_Layer_2': 0.21254470877889098, 'dropout_rate_Layer_3': 0.2944546092409784, 'dropout_rate_Layer_4': 0.21818149837665352, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010669721823914994, 'l1_Layer_2': 0.018067370122340172, 'l1_Layer_3': 0.01485381493609333, 'l1_Layer_4': 4.2524389597820484e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 225, 'n_units_Layer_3': 105, 'n_units_Layer_4': 50}. Best is trial 213 with value: 2.516937764938539.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 8.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 2.08 | sMAPE for Test Set is: 5.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 17:13:08,316]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:1.37 & sMAPE is:2.86% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :1.37 & 2.86% & 0.89\n",
      "for 2019-01-02, MAE is:2.85 & sMAPE is:5.76% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 4.31% & 1.40\n",
      "for 2019-01-03, MAE is:3.20 & sMAPE is:6.05% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 4.89% & 1.40\n",
      "for 2019-01-04, MAE is:1.13 & sMAPE is:2.23% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 4.22% & 1.17\n",
      "for 2019-01-05, MAE is:2.84 & sMAPE is:5.67% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 4.51% & 1.27\n",
      "for 2019-01-06, MAE is:2.36 & sMAPE is:4.75% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.55% & 1.33\n",
      "for 2019-01-07, MAE is:2.70 & sMAPE is:5.21% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 4.65% & 1.29\n",
      "for 2019-01-08, MAE is:1.91 & sMAPE is:3.91% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.55% & 1.26\n",
      "for 2019-01-09, MAE is:2.25 & sMAPE is:4.54% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 4.55% & 1.43\n",
      "for 2019-01-10, MAE is:9.15 & sMAPE is:15.30% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.98 & 5.63% & 1.43\n",
      "for 2019-01-11, MAE is:1.72 & sMAPE is:3.39% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 5.42% & 1.42\n",
      "for 2019-01-12, MAE is:3.35 & sMAPE is:7.03% & rMAE is:2.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.90 & 5.56% & 1.50\n",
      "for 2019-01-13, MAE is:1.89 & sMAPE is:3.85% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 5.43% & 1.46\n",
      "for 2019-01-14, MAE is:1.29 & sMAPE is:2.69% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.71 & 5.23% & 1.39\n",
      "for 2019-01-15, MAE is:3.05 & sMAPE is:5.96% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 5.28% & 1.38\n",
      "for 2019-01-16, MAE is:3.63 & sMAPE is:7.16% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.79 & 5.40% & 1.38\n",
      "for 2019-01-17, MAE is:3.11 & sMAPE is:5.99% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.81 & 5.43% & 1.32\n",
      "for 2019-01-18, MAE is:11.25 & sMAPE is:19.34% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 6.21% & 1.30\n",
      "for 2019-01-19, MAE is:2.03 & sMAPE is:3.66% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :3.22 & 6.07% & 1.25\n",
      "for 2019-01-20, MAE is:3.64 & sMAPE is:6.55% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :3.24 & 6.10% & 1.22\n",
      "for 2019-01-21, MAE is:12.94 & sMAPE is:19.38% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :3.70 & 6.73% & 1.20\n",
      "for 2019-01-22, MAE is:5.91 & sMAPE is:9.11% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.80 & 6.84% & 1.17\n",
      "for 2019-01-23, MAE is:14.06 & sMAPE is:21.19% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :4.24 & 7.46% & 1.16\n",
      "for 2019-01-24, MAE is:19.39 & sMAPE is:24.83% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :4.88 & 8.18% & 1.14\n",
      "for 2019-01-25, MAE is:7.42 & sMAPE is:10.95% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.98 & 8.29% & 1.14\n",
      "for 2019-01-26, MAE is:1.54 & sMAPE is:2.90% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :4.85 & 8.09% & 1.14\n",
      "for 2019-01-27, MAE is:1.55 & sMAPE is:3.01% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 7.90% & 1.11\n",
      "for 2019-01-28, MAE is:2.04 & sMAPE is:3.58% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.63 & 7.74% & 1.08\n",
      "for 2019-01-29, MAE is:7.35 & sMAPE is:11.94% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :4.72 & 7.89% & 1.12\n",
      "for 2019-01-30, MAE is:2.21 & sMAPE is:3.87% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :4.64 & 7.76% & 1.09\n",
      "for 2019-01-31, MAE is:1.30 & sMAPE is:2.42% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :4.53 & 7.58% & 1.06\n",
      "for 2019-02-01, MAE is:1.51 & sMAPE is:2.74% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :4.44 & 7.43% & 1.03\n",
      "for 2019-02-02, MAE is:1.25 & sMAPE is:2.45% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :4.34 & 7.28% & 1.01\n",
      "for 2019-02-03, MAE is:1.86 & sMAPE is:3.75% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :4.27 & 7.18% & 1.01\n",
      "for 2019-02-04, MAE is:2.03 & sMAPE is:3.93% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :4.20 & 7.08% & 1.00\n",
      "for 2019-02-05, MAE is:1.54 & sMAPE is:2.96% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :4.13 & 6.97% & 0.97\n",
      "for 2019-02-06, MAE is:2.51 & sMAPE is:4.77% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :4.08 & 6.91% & 0.97\n",
      "for 2019-02-07, MAE is:1.08 & sMAPE is:2.18% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :4.01 & 6.79% & 0.95\n",
      "for 2019-02-08, MAE is:2.00 & sMAPE is:4.16% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.95 & 6.72% & 0.94\n",
      "for 2019-02-09, MAE is:1.61 & sMAPE is:3.50% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :3.90 & 6.64% & 0.93\n",
      "for 2019-02-10, MAE is:1.45 & sMAPE is:3.13% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.84 & 6.55% & 0.91\n",
      "for 2019-02-11, MAE is:1.21 & sMAPE is:2.60% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.77 & 6.46% & 0.90\n",
      "for 2019-02-12, MAE is:2.06 & sMAPE is:4.32% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :3.73 & 6.41% & 0.89\n",
      "for 2019-02-13, MAE is:1.51 & sMAPE is:3.34% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :3.68 & 6.34% & 0.88\n",
      "for 2019-02-14, MAE is:1.33 & sMAPE is:2.99% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.63 & 6.26% & 0.86\n",
      "for 2019-02-15, MAE is:1.32 & sMAPE is:3.09% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.58 & 6.20% & 0.85\n",
      "for 2019-02-16, MAE is:1.51 & sMAPE is:3.69% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :3.54 & 6.14% & 0.84\n",
      "for 2019-02-17, MAE is:1.80 & sMAPE is:4.30% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :3.50 & 6.10% & 0.83\n",
      "for 2019-02-18, MAE is:2.77 & sMAPE is:6.45% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :3.49 & 6.11% & 0.83\n",
      "for 2019-02-19, MAE is:1.40 & sMAPE is:3.33% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :3.44 & 6.05% & 0.82\n",
      "for 2019-02-20, MAE is:2.21 & sMAPE is:5.16% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :3.42 & 6.04% & 0.82\n",
      "for 2019-02-21, MAE is:1.90 & sMAPE is:4.41% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :3.39 & 6.01% & 0.83\n",
      "for 2019-02-22, MAE is:2.03 & sMAPE is:4.76% & rMAE is:3.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.36 & 5.98% & 0.88\n",
      "for 2019-02-23, MAE is:1.54 & sMAPE is:3.87% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :3.33 & 5.94% & 0.89\n",
      "for 2019-02-24, MAE is:2.38 & sMAPE is:5.93% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.31 & 5.94% & 0.91\n",
      "for 2019-02-25, MAE is:1.41 & sMAPE is:3.41% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :3.28 & 5.90% & 0.90\n",
      "for 2019-02-26, MAE is:2.27 & sMAPE is:5.56% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :3.26 & 5.89% & 0.93\n",
      "for 2019-02-27, MAE is:2.39 & sMAPE is:5.90% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :3.25 & 5.89% & 0.94\n",
      "for 2019-02-28, MAE is:2.50 & sMAPE is:6.11% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 5.90% & 0.94\n",
      "for 2019-03-01, MAE is:3.26 & sMAPE is:7.48% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :3.23 & 5.92% & 0.97\n",
      "for 2019-03-02, MAE is:1.41 & sMAPE is:3.35% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :3.20 & 5.88% & 0.96\n",
      "for 2019-03-03, MAE is:1.61 & sMAPE is:4.01% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :3.18 & 5.85% & 1.00\n",
      "for 2019-03-04, MAE is:1.16 & sMAPE is:2.82% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :3.15 & 5.80% & 1.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-05, MAE is:2.48 & sMAPE is:5.73% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :3.14 & 5.80% & 1.01\n",
      "for 2019-03-06, MAE is:1.85 & sMAPE is:4.20% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :3.12 & 5.78% & 1.01\n",
      "for 2019-03-07, MAE is:1.88 & sMAPE is:4.31% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :3.10 & 5.75% & 1.00\n",
      "for 2019-03-08, MAE is:1.33 & sMAPE is:3.22% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :3.07 & 5.72% & 1.00\n",
      "for 2019-03-09, MAE is:1.03 & sMAPE is:2.45% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :3.04 & 5.67% & 1.00\n",
      "for 2019-03-10, MAE is:1.31 & sMAPE is:3.12% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 5.63% & 1.00\n",
      "for 2019-03-11, MAE is:3.09 & sMAPE is:6.97% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :3.02 & 5.65% & 1.00\n",
      "for 2019-03-12, MAE is:2.06 & sMAPE is:4.54% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :3.00 & 5.63% & 0.99\n",
      "for 2019-03-13, MAE is:0.85 & sMAPE is:2.06% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.97 & 5.58% & 0.98\n",
      "for 2019-03-14, MAE is:0.85 & sMAPE is:2.03% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.94 & 5.54% & 0.98\n",
      "for 2019-03-15, MAE is:1.24 & sMAPE is:2.96% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.92 & 5.50% & 0.98\n",
      "for 2019-03-16, MAE is:1.66 & sMAPE is:4.17% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.90 & 5.48% & 0.98\n",
      "for 2019-03-17, MAE is:0.80 & sMAPE is:1.99% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.88 & 5.44% & 0.97\n",
      "for 2019-03-18, MAE is:0.92 & sMAPE is:2.17% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.85 & 5.39% & 0.96\n",
      "for 2019-03-19, MAE is:3.64 & sMAPE is:7.80% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.86 & 5.43% & 0.97\n",
      "for 2019-03-20, MAE is:1.66 & sMAPE is:3.86% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.85 & 5.41% & 0.98\n",
      "for 2019-03-21, MAE is:1.41 & sMAPE is:3.44% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.83 & 5.38% & 0.98\n",
      "for 2019-03-22, MAE is:1.98 & sMAPE is:4.77% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.82 & 5.37% & 0.97\n",
      "for 2019-03-23, MAE is:1.04 & sMAPE is:2.77% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.80 & 5.34% & 0.97\n",
      "for 2019-03-24, MAE is:1.44 & sMAPE is:3.75% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.78 & 5.32% & 0.96\n",
      "for 2019-03-25, MAE is:0.94 & sMAPE is:2.36% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.76 & 5.29% & 0.96\n",
      "for 2019-03-26, MAE is:1.05 & sMAPE is:2.59% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.74 & 5.26% & 0.95\n",
      "for 2019-03-27, MAE is:1.30 & sMAPE is:3.23% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.72 & 5.23% & 0.95\n",
      "for 2019-03-28, MAE is:1.94 & sMAPE is:4.93% & rMAE is:2.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.71 & 5.23% & 0.96\n",
      "for 2019-03-29, MAE is:1.29 & sMAPE is:3.28% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.70 & 5.21% & 0.96\n",
      "for 2019-03-30, MAE is:1.15 & sMAPE is:3.09% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.68 & 5.18% & 0.98\n",
      "for 2019-03-31, MAE is:1.37 & sMAPE is:3.66% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 5.17% & 1.00\n",
      "for 2019-04-01, MAE is:1.85 & sMAPE is:4.56% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.66 & 5.16% & 1.00\n",
      "for 2019-04-02, MAE is:1.09 & sMAPE is:2.84% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.64 & 5.13% & 1.00\n",
      "for 2019-04-03, MAE is:2.66 & sMAPE is:6.48% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.64 & 5.15% & 1.01\n",
      "for 2019-04-04, MAE is:1.61 & sMAPE is:3.88% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.63 & 5.13% & 1.01\n",
      "for 2019-04-05, MAE is:1.35 & sMAPE is:3.41% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 5.12% & 1.01\n",
      "for 2019-04-06, MAE is:1.87 & sMAPE is:4.82% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.61 & 5.11% & 1.01\n",
      "for 2019-04-07, MAE is:1.43 & sMAPE is:3.62% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.59 & 5.10% & 1.01\n",
      "for 2019-04-08, MAE is:2.24 & sMAPE is:5.28% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.59 & 5.10% & 1.01\n",
      "for 2019-04-09, MAE is:1.62 & sMAPE is:3.74% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.58 & 5.09% & 1.01\n",
      "for 2019-04-10, MAE is:1.84 & sMAPE is:4.08% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 5.08% & 1.00\n",
      "for 2019-04-11, MAE is:2.13 & sMAPE is:4.46% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 5.07% & 1.00\n",
      "for 2019-04-12, MAE is:2.93 & sMAPE is:6.11% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.57 & 5.08% & 0.99\n",
      "for 2019-04-13, MAE is:1.46 & sMAPE is:3.36% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.56 & 5.06% & 0.98\n",
      "for 2019-04-14, MAE is:1.32 & sMAPE is:3.10% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 5.04% & 0.98\n",
      "for 2019-04-15, MAE is:2.69 & sMAPE is:5.82% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 5.05% & 0.98\n",
      "for 2019-04-16, MAE is:1.91 & sMAPE is:4.22% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 5.04% & 0.97\n",
      "for 2019-04-17, MAE is:2.87 & sMAPE is:6.32% & rMAE is:2.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.55 & 5.06% & 0.99\n",
      "for 2019-04-18, MAE is:1.65 & sMAPE is:3.87% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 5.05% & 0.98\n",
      "for 2019-04-19, MAE is:1.08 & sMAPE is:2.59% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 5.02% & 0.98\n",
      "for 2019-04-20, MAE is:1.23 & sMAPE is:2.97% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 5.00% & 0.97\n",
      "for 2019-04-21, MAE is:1.42 & sMAPE is:3.50% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 4.99% & 0.97\n",
      "for 2019-04-22, MAE is:1.99 & sMAPE is:4.81% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 4.99% & 0.97\n",
      "for 2019-04-23, MAE is:1.29 & sMAPE is:3.14% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 4.97% & 0.96\n",
      "for 2019-04-24, MAE is:2.26 & sMAPE is:5.60% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 4.98% & 0.96\n",
      "for 2019-04-25, MAE is:2.04 & sMAPE is:5.15% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.98% & 0.95\n",
      "for 2019-04-26, MAE is:1.99 & sMAPE is:4.97% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 4.98% & 0.95\n",
      "for 2019-04-27, MAE is:5.41 & sMAPE is:15.48% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.07% & 0.95\n",
      "for 2019-04-28, MAE is:3.09 & sMAPE is:8.86% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 5.10% & 0.95\n",
      "for 2019-04-29, MAE is:1.90 & sMAPE is:4.74% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.10% & 0.95\n",
      "for 2019-04-30, MAE is:2.72 & sMAPE is:6.98% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 5.11% & 0.95\n",
      "for 2019-05-01, MAE is:1.71 & sMAPE is:4.91% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.11% & 0.95\n",
      "for 2019-05-02, MAE is:2.29 & sMAPE is:6.27% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.12% & 0.95\n",
      "for 2019-05-03, MAE is:1.67 & sMAPE is:4.20% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.11% & 0.95\n",
      "for 2019-05-04, MAE is:2.86 & sMAPE is:7.15% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.13% & 0.94\n",
      "for 2019-05-05, MAE is:1.05 & sMAPE is:2.64% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 5.11% & 0.93\n",
      "for 2019-05-06, MAE is:2.44 & sMAPE is:5.81% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 5.12% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-07, MAE is:0.74 & sMAPE is:1.73% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.09% & 0.93\n",
      "for 2019-05-08, MAE is:2.13 & sMAPE is:4.93% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.09% & 0.92\n",
      "for 2019-05-09, MAE is:2.96 & sMAPE is:7.06% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.10% & 0.92\n",
      "for 2019-05-10, MAE is:1.44 & sMAPE is:3.32% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.09% & 0.92\n",
      "for 2019-05-11, MAE is:1.21 & sMAPE is:2.91% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 5.07% & 0.91\n",
      "for 2019-05-12, MAE is:1.19 & sMAPE is:2.93% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.06% & 0.92\n",
      "for 2019-05-13, MAE is:1.38 & sMAPE is:3.27% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.04% & 0.92\n",
      "for 2019-05-14, MAE is:0.99 & sMAPE is:2.31% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 5.02% & 0.92\n",
      "for 2019-05-15, MAE is:1.13 & sMAPE is:2.74% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.01% & 0.92\n",
      "for 2019-05-16, MAE is:1.65 & sMAPE is:4.20% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.00% & 0.92\n",
      "for 2019-05-17, MAE is:1.61 & sMAPE is:4.08% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 4.99% & 0.92\n",
      "for 2019-05-18, MAE is:2.83 & sMAPE is:7.40% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.01% & 0.91\n",
      "for 2019-05-19, MAE is:1.85 & sMAPE is:4.93% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 5.01% & 0.91\n",
      "for 2019-05-20, MAE is:3.51 & sMAPE is:8.62% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.04% & 0.91\n",
      "for 2019-05-21, MAE is:2.25 & sMAPE is:5.88% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.04% & 0.91\n",
      "for 2019-05-22, MAE is:2.93 & sMAPE is:7.89% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.06% & 0.91\n",
      "for 2019-05-23, MAE is:2.23 & sMAPE is:5.95% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.07% & 0.91\n",
      "for 2019-05-24, MAE is:2.22 & sMAPE is:5.75% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.07% & 0.91\n",
      "for 2019-05-25, MAE is:1.91 & sMAPE is:5.28% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.07% & 0.91\n",
      "for 2019-05-26, MAE is:5.61 & sMAPE is:19.13% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.17% & 0.91\n",
      "for 2019-05-27, MAE is:4.97 & sMAPE is:14.08% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 5.23% & 0.91\n",
      "for 2019-05-28, MAE is:1.32 & sMAPE is:3.54% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.22% & 0.91\n",
      "for 2019-05-29, MAE is:1.42 & sMAPE is:3.80% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 5.21% & 0.91\n",
      "for 2019-05-30, MAE is:4.43 & sMAPE is:13.53% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.27% & 0.91\n",
      "for 2019-05-31, MAE is:2.30 & sMAPE is:6.48% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 5.27% & 0.91\n",
      "for 2019-06-01, MAE is:3.59 & sMAPE is:10.48% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 5.31% & 0.91\n",
      "for 2019-06-02, MAE is:3.93 & sMAPE is:12.46% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.36% & 0.91\n",
      "for 2019-06-03, MAE is:4.33 & sMAPE is:13.75% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.41% & 0.92\n",
      "for 2019-06-04, MAE is:1.32 & sMAPE is:3.81% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 5.40% & 0.91\n",
      "for 2019-06-05, MAE is:2.26 & sMAPE is:7.68% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.41% & 0.91\n",
      "for 2019-06-06, MAE is:2.40 & sMAPE is:7.92% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.43% & 0.91\n",
      "for 2019-06-07, MAE is:1.78 & sMAPE is:5.83% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 5.43% & 0.91\n",
      "for 2019-06-08, MAE is:12.34 & sMAPE is:64.00% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 5.80% & 0.90\n",
      "for 2019-06-09, MAE is:5.30 & sMAPE is:21.71% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 5.90% & 0.91\n",
      "for 2019-06-10, MAE is:1.77 & sMAPE is:5.90% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 5.90% & 0.90\n",
      "for 2019-06-11, MAE is:2.74 & sMAPE is:8.76% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :2.54 & 5.92% & 0.90\n",
      "for 2019-06-12, MAE is:1.71 & sMAPE is:5.33% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 5.91% & 0.90\n",
      "for 2019-06-13, MAE is:2.04 & sMAPE is:6.84% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.53 & 5.92% & 0.91\n",
      "for 2019-06-14, MAE is:1.53 & sMAPE is:4.87% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 5.91% & 0.91\n",
      "for 2019-06-15, MAE is:1.74 & sMAPE is:6.34% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.52 & 5.92% & 0.90\n",
      "for 2019-06-16, MAE is:2.16 & sMAPE is:7.75% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 5.93% & 0.90\n",
      "for 2019-06-17, MAE is:1.81 & sMAPE is:5.83% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 5.93% & 0.90\n",
      "for 2019-06-18, MAE is:1.53 & sMAPE is:4.76% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.92% & 0.90\n",
      "for 2019-06-19, MAE is:3.04 & sMAPE is:9.67% & rMAE is:3.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.51 & 5.94% & 0.92\n",
      "for 2019-06-20, MAE is:1.01 & sMAPE is:3.27% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.93% & 0.92\n",
      "for 2019-06-21, MAE is:2.35 & sMAPE is:7.82% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 5.94% & 0.92\n",
      "for 2019-06-22, MAE is:0.86 & sMAPE is:2.85% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.92% & 0.91\n",
      "for 2019-06-23, MAE is:3.20 & sMAPE is:11.75% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.95% & 0.92\n",
      "for 2019-06-24, MAE is:2.57 & sMAPE is:8.39% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.97% & 0.92\n",
      "for 2019-06-25, MAE is:2.59 & sMAPE is:8.55% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.98% & 0.92\n",
      "for 2019-06-26, MAE is:1.87 & sMAPE is:5.93% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 5.98% & 0.93\n",
      "for 2019-06-27, MAE is:2.63 & sMAPE is:9.96% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 6.00% & 0.93\n",
      "for 2019-06-28, MAE is:2.35 & sMAPE is:7.81% & rMAE is:2.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 6.01% & 0.94\n",
      "for 2019-06-29, MAE is:1.95 & sMAPE is:7.02% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 6.02% & 0.93\n",
      "for 2019-06-30, MAE is:4.44 & sMAPE is:19.75% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :2.50 & 6.10% & 0.94\n",
      "for 2019-07-01, MAE is:1.26 & sMAPE is:4.48% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 6.09% & 0.93\n",
      "for 2019-07-02, MAE is:2.02 & sMAPE is:7.69% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 6.09% & 0.93\n",
      "for 2019-07-03, MAE is:1.96 & sMAPE is:6.78% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.49 & 6.10% & 0.93\n",
      "for 2019-07-04, MAE is:0.59 & sMAPE is:2.03% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.48 & 6.08% & 0.92\n",
      "for 2019-07-05, MAE is:2.19 & sMAPE is:7.65% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 6.09% & 0.93\n",
      "for 2019-07-06, MAE is:1.31 & sMAPE is:4.68% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :2.47 & 6.08% & 0.93\n",
      "for 2019-07-07, MAE is:1.52 & sMAPE is:5.43% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 6.07% & 0.92\n",
      "for 2019-07-08, MAE is:0.65 & sMAPE is:2.04% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.05% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-09, MAE is:2.87 & sMAPE is:8.91% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.46 & 6.07% & 0.92\n",
      "for 2019-07-10, MAE is:1.73 & sMAPE is:5.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.06% & 0.91\n",
      "for 2019-07-11, MAE is:1.61 & sMAPE is:4.71% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.06% & 0.91\n",
      "for 2019-07-12, MAE is:3.07 & sMAPE is:8.78% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.07% & 0.91\n",
      "for 2019-07-13, MAE is:2.08 & sMAPE is:5.86% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.45 & 6.07% & 0.90\n",
      "for 2019-07-14, MAE is:1.51 & sMAPE is:4.18% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.44 & 6.06% & 0.90\n",
      "for 2019-07-15, MAE is:0.60 & sMAPE is:1.59% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.43 & 6.04% & 0.90\n",
      "for 2019-07-16, MAE is:0.61 & sMAPE is:1.64% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.02% & 0.89\n",
      "for 2019-07-17, MAE is:1.17 & sMAPE is:3.12% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.42 & 6.00% & 0.89\n",
      "for 2019-07-18, MAE is:0.86 & sMAPE is:2.31% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.41 & 5.98% & 0.89\n",
      "for 2019-07-19, MAE is:0.84 & sMAPE is:2.27% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 5.96% & 0.88\n",
      "for 2019-07-20, MAE is:1.49 & sMAPE is:4.08% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.40 & 5.95% & 0.89\n",
      "for 2019-07-21, MAE is:1.66 & sMAPE is:4.72% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.95% & 0.89\n",
      "for 2019-07-22, MAE is:0.65 & sMAPE is:1.76% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.39 & 5.93% & 0.89\n",
      "for 2019-07-23, MAE is:0.93 & sMAPE is:2.53% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 5.91% & 0.89\n",
      "for 2019-07-24, MAE is:1.68 & sMAPE is:4.52% & rMAE is:3.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.38 & 5.90% & 0.91\n",
      "for 2019-07-25, MAE is:1.82 & sMAPE is:4.81% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.37 & 5.90% & 0.92\n",
      "for 2019-07-26, MAE is:0.65 & sMAPE is:1.72% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.88% & 0.92\n",
      "for 2019-07-27, MAE is:1.67 & sMAPE is:4.43% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.87% & 0.92\n",
      "for 2019-07-28, MAE is:2.66 & sMAPE is:7.78% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.88% & 0.92\n",
      "for 2019-07-29, MAE is:2.11 & sMAPE is:5.44% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.88% & 0.92\n",
      "for 2019-07-30, MAE is:1.08 & sMAPE is:2.76% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.36 & 5.86% & 0.92\n",
      "for 2019-07-31, MAE is:0.38 & sMAPE is:1.00% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.35 & 5.84% & 0.91\n",
      "for 2019-08-01, MAE is:0.99 & sMAPE is:2.57% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.34 & 5.83% & 0.92\n",
      "for 2019-08-02, MAE is:0.76 & sMAPE is:1.91% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 5.81% & 0.91\n",
      "for 2019-08-03, MAE is:0.83 & sMAPE is:2.20% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.33 & 5.79% & 0.91\n",
      "for 2019-08-04, MAE is:1.02 & sMAPE is:2.64% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.32 & 5.78% & 0.91\n",
      "for 2019-08-05, MAE is:0.84 & sMAPE is:2.10% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 5.76% & 0.91\n",
      "for 2019-08-06, MAE is:0.84 & sMAPE is:2.14% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.31 & 5.74% & 0.91\n",
      "for 2019-08-07, MAE is:0.95 & sMAPE is:2.44% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.73% & 0.92\n",
      "for 2019-08-08, MAE is:0.73 & sMAPE is:1.94% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.71% & 0.91\n",
      "for 2019-08-09, MAE is:0.90 & sMAPE is:2.46% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.70% & 0.91\n",
      "for 2019-08-10, MAE is:0.85 & sMAPE is:2.50% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.68% & 0.91\n",
      "for 2019-08-11, MAE is:5.82 & sMAPE is:22.83% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.76% & 0.91\n",
      "for 2019-08-12, MAE is:3.01 & sMAPE is:8.64% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :2.30 & 5.77% & 0.90\n",
      "for 2019-08-13, MAE is:0.86 & sMAPE is:2.39% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.76% & 0.90\n",
      "for 2019-08-14, MAE is:1.26 & sMAPE is:3.82% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.75% & 0.90\n",
      "for 2019-08-15, MAE is:2.20 & sMAPE is:6.74% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.75% & 0.90\n",
      "for 2019-08-16, MAE is:1.46 & sMAPE is:4.42% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.75% & 0.89\n",
      "for 2019-08-17, MAE is:3.31 & sMAPE is:12.85% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.78% & 0.89\n",
      "for 2019-08-18, MAE is:1.90 & sMAPE is:5.75% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.78% & 0.89\n",
      "for 2019-08-19, MAE is:2.06 & sMAPE is:6.38% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.29 & 5.78% & 0.89\n",
      "for 2019-08-20, MAE is:1.37 & sMAPE is:4.12% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :2.28 & 5.77% & 0.89\n",
      "for 2019-08-21, MAE is:0.57 & sMAPE is:1.67% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 5.75% & 0.89\n",
      "for 2019-08-22, MAE is:1.02 & sMAPE is:3.12% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.27 & 5.74% & 0.89\n",
      "for 2019-08-23, MAE is:0.69 & sMAPE is:2.15% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.73% & 0.89\n",
      "for 2019-08-24, MAE is:0.66 & sMAPE is:2.08% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :2.26 & 5.71% & 0.88\n",
      "for 2019-08-25, MAE is:1.28 & sMAPE is:3.93% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :2.25 & 5.70% & 0.88\n",
      "for 2019-08-26, MAE is:0.43 & sMAPE is:1.28% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.69% & 0.88\n",
      "for 2019-08-27, MAE is:2.30 & sMAPE is:6.83% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.69% & 0.88\n",
      "for 2019-08-28, MAE is:0.80 & sMAPE is:2.44% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.24 & 5.68% & 0.89\n",
      "for 2019-08-29, MAE is:1.35 & sMAPE is:4.04% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.67% & 0.89\n",
      "for 2019-08-30, MAE is:0.64 & sMAPE is:2.04% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.23 & 5.66% & 0.88\n",
      "for 2019-08-31, MAE is:0.91 & sMAPE is:3.11% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.65% & 0.88\n",
      "for 2019-09-01, MAE is:1.50 & sMAPE is:5.01% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.22 & 5.64% & 0.88\n",
      "for 2019-09-02, MAE is:1.09 & sMAPE is:3.73% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.63% & 0.88\n",
      "for 2019-09-03, MAE is:0.97 & sMAPE is:3.41% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.63% & 0.88\n",
      "for 2019-09-04, MAE is:1.45 & sMAPE is:4.82% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.21 & 5.62% & 0.87\n",
      "for 2019-09-05, MAE is:1.37 & sMAPE is:4.85% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.62% & 0.87\n",
      "for 2019-09-06, MAE is:1.07 & sMAPE is:3.80% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.61% & 0.87\n",
      "for 2019-09-07, MAE is:0.73 & sMAPE is:2.51% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.60% & 0.87\n",
      "for 2019-09-08, MAE is:2.36 & sMAPE is:7.86% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.61% & 0.87\n",
      "for 2019-09-09, MAE is:1.44 & sMAPE is:4.55% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.60% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-10, MAE is:0.93 & sMAPE is:2.95% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.59% & 0.87\n",
      "for 2019-09-11, MAE is:1.69 & sMAPE is:5.53% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.59% & 0.87\n",
      "for 2019-09-12, MAE is:0.61 & sMAPE is:2.12% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.58% & 0.87\n",
      "for 2019-09-13, MAE is:0.95 & sMAPE is:3.19% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.57% & 0.87\n",
      "for 2019-09-14, MAE is:0.90 & sMAPE is:3.23% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.56% & 0.87\n",
      "for 2019-09-15, MAE is:4.84 & sMAPE is:21.55% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.62% & 0.87\n",
      "for 2019-09-16, MAE is:5.88 & sMAPE is:27.78% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.71% & 0.87\n",
      "for 2019-09-17, MAE is:3.42 & sMAPE is:12.27% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.20 & 5.73% & 0.87\n",
      "for 2019-09-18, MAE is:0.87 & sMAPE is:3.11% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.72% & 0.87\n",
      "for 2019-09-19, MAE is:0.96 & sMAPE is:3.36% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.19 & 5.72% & 0.87\n",
      "for 2019-09-20, MAE is:0.89 & sMAPE is:3.10% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.71% & 0.87\n",
      "for 2019-09-21, MAE is:1.87 & sMAPE is:6.42% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.71% & 0.87\n",
      "for 2019-09-22, MAE is:1.75 & sMAPE is:5.95% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.18 & 5.71% & 0.87\n",
      "for 2019-09-23, MAE is:0.73 & sMAPE is:2.46% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.70% & 0.87\n",
      "for 2019-09-24, MAE is:1.35 & sMAPE is:4.34% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.17 & 5.69% & 0.86\n",
      "for 2019-09-25, MAE is:0.58 & sMAPE is:1.87% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.68% & 0.86\n",
      "for 2019-09-26, MAE is:0.77 & sMAPE is:2.47% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.67% & 0.86\n",
      "for 2019-09-27, MAE is:1.78 & sMAPE is:5.55% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.67% & 0.86\n",
      "for 2019-09-28, MAE is:1.37 & sMAPE is:4.45% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :2.16 & 5.66% & 0.86\n",
      "for 2019-09-29, MAE is:1.04 & sMAPE is:3.35% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.65% & 0.86\n",
      "for 2019-09-30, MAE is:1.98 & sMAPE is:6.21% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.65% & 0.86\n",
      "for 2019-10-01, MAE is:1.54 & sMAPE is:4.59% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.65% & 0.86\n",
      "for 2019-10-02, MAE is:1.28 & sMAPE is:3.66% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.15 & 5.64% & 0.86\n",
      "for 2019-10-03, MAE is:1.44 & sMAPE is:4.09% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.64% & 0.85\n",
      "for 2019-10-04, MAE is:1.03 & sMAPE is:2.82% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.63% & 0.85\n",
      "for 2019-10-05, MAE is:0.71 & sMAPE is:1.96% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.61% & 0.85\n",
      "for 2019-10-06, MAE is:0.91 & sMAPE is:2.53% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.60% & 0.85\n",
      "for 2019-10-07, MAE is:4.22 & sMAPE is:9.94% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.62% & 0.85\n",
      "for 2019-10-08, MAE is:1.98 & sMAPE is:5.21% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.62% & 0.85\n",
      "for 2019-10-09, MAE is:2.01 & sMAPE is:5.07% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :2.14 & 5.62% & 0.84\n",
      "for 2019-10-10, MAE is:1.76 & sMAPE is:4.87% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.61% & 0.85\n",
      "for 2019-10-11, MAE is:1.33 & sMAPE is:3.90% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.61% & 0.84\n",
      "for 2019-10-12, MAE is:0.75 & sMAPE is:2.28% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.13 & 5.59% & 0.84\n",
      "for 2019-10-13, MAE is:0.56 & sMAPE is:1.69% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.58% & 0.84\n",
      "for 2019-10-14, MAE is:1.33 & sMAPE is:3.85% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :2.12 & 5.58% & 0.84\n",
      "for 2019-10-15, MAE is:0.63 & sMAPE is:1.82% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.56% & 0.84\n",
      "for 2019-10-16, MAE is:1.00 & sMAPE is:2.78% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.11 & 5.55% & 0.84\n",
      "for 2019-10-17, MAE is:0.77 & sMAPE is:2.14% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.54% & 0.84\n",
      "for 2019-10-18, MAE is:1.46 & sMAPE is:3.97% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.54% & 0.83\n",
      "for 2019-10-19, MAE is:0.90 & sMAPE is:2.56% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.53% & 0.83\n",
      "for 2019-10-20, MAE is:1.21 & sMAPE is:3.33% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.52% & 0.83\n",
      "for 2019-10-21, MAE is:0.62 & sMAPE is:1.63% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.50% & 0.83\n",
      "for 2019-10-22, MAE is:0.92 & sMAPE is:2.41% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.49% & 0.83\n",
      "for 2019-10-23, MAE is:1.27 & sMAPE is:3.29% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.49% & 0.83\n",
      "for 2019-10-24, MAE is:1.72 & sMAPE is:4.76% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.48% & 0.83\n",
      "for 2019-10-25, MAE is:1.28 & sMAPE is:3.53% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.48% & 0.83\n",
      "for 2019-10-26, MAE is:1.06 & sMAPE is:2.95% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.47% & 0.83\n",
      "for 2019-10-27, MAE is:1.47 & sMAPE is:3.95% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.46% & 0.83\n",
      "for 2019-10-28, MAE is:1.09 & sMAPE is:2.78% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.45% & 0.83\n",
      "for 2019-10-29, MAE is:1.16 & sMAPE is:2.93% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.45% & 0.83\n",
      "for 2019-10-30, MAE is:1.02 & sMAPE is:2.55% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.44% & 0.83\n",
      "for 2019-10-31, MAE is:1.16 & sMAPE is:3.02% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.43% & 0.83\n",
      "for 2019-11-01, MAE is:1.00 & sMAPE is:2.66% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.42% & 0.83\n",
      "for 2019-11-02, MAE is:1.36 & sMAPE is:3.72% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.41% & 0.83\n",
      "for 2019-11-03, MAE is:1.15 & sMAPE is:2.95% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.41% & 0.83\n",
      "for 2019-11-04, MAE is:1.45 & sMAPE is:3.55% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.40% & 0.83\n",
      "for 2019-11-05, MAE is:1.38 & sMAPE is:3.23% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.39% & 0.83\n",
      "for 2019-11-06, MAE is:10.87 & sMAPE is:20.74% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.44% & 0.83\n",
      "for 2019-11-07, MAE is:3.19 & sMAPE is:6.77% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.45% & 0.83\n",
      "for 2019-11-08, MAE is:4.24 & sMAPE is:8.98% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.46% & 0.83\n",
      "for 2019-11-09, MAE is:1.30 & sMAPE is:3.07% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.45% & 0.83\n",
      "for 2019-11-10, MAE is:2.25 & sMAPE is:5.15% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.45% & 0.83\n",
      "for 2019-11-11, MAE is:1.95 & sMAPE is:4.44% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.45% & 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-12, MAE is:1.70 & sMAPE is:3.91% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.44% & 0.83\n",
      "for 2019-11-13, MAE is:4.24 & sMAPE is:9.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.45% & 0.83\n",
      "for 2019-11-14, MAE is:3.69 & sMAPE is:7.88% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.46% & 0.83\n",
      "for 2019-11-15, MAE is:2.23 & sMAPE is:5.27% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.10 & 5.46% & 0.83\n",
      "for 2019-11-16, MAE is:1.39 & sMAPE is:3.42% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.45% & 0.83\n",
      "for 2019-11-17, MAE is:1.15 & sMAPE is:2.82% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.45% & 0.83\n",
      "for 2019-11-18, MAE is:1.30 & sMAPE is:3.10% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.44% & 0.83\n",
      "for 2019-11-19, MAE is:1.04 & sMAPE is:2.57% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.43% & 0.83\n",
      "for 2019-11-20, MAE is:3.14 & sMAPE is:6.95% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.43% & 0.83\n",
      "for 2019-11-21, MAE is:1.59 & sMAPE is:3.86% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.43% & 0.83\n",
      "for 2019-11-22, MAE is:1.53 & sMAPE is:3.81% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :2.09 & 5.42% & 0.83\n",
      "for 2019-11-23, MAE is:1.19 & sMAPE is:3.12% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.42% & 0.83\n",
      "for 2019-11-24, MAE is:1.40 & sMAPE is:3.47% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.41% & 0.83\n",
      "for 2019-11-25, MAE is:1.17 & sMAPE is:2.75% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.40% & 0.83\n",
      "for 2019-11-26, MAE is:2.50 & sMAPE is:5.52% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.40% & 0.83\n",
      "for 2019-11-27, MAE is:1.64 & sMAPE is:3.84% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.40% & 0.83\n",
      "for 2019-11-28, MAE is:0.92 & sMAPE is:2.23% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.39% & 0.83\n",
      "for 2019-11-29, MAE is:1.09 & sMAPE is:2.64% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.38% & 0.83\n",
      "for 2019-11-30, MAE is:1.40 & sMAPE is:3.31% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.37% & 0.83\n",
      "for 2019-12-01, MAE is:1.11 & sMAPE is:2.66% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.37% & 0.83\n",
      "for 2019-12-02, MAE is:2.29 & sMAPE is:5.09% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.37% & 0.83\n",
      "for 2019-12-03, MAE is:7.18 & sMAPE is:13.91% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.39% & 0.83\n",
      "for 2019-12-04, MAE is:1.46 & sMAPE is:3.50% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.39% & 0.84\n",
      "for 2019-12-05, MAE is:1.80 & sMAPE is:4.53% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.38% & 0.84\n",
      "for 2019-12-06, MAE is:1.10 & sMAPE is:2.89% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 5.38% & 0.83\n",
      "for 2019-12-07, MAE is:1.21 & sMAPE is:3.18% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.37% & 0.83\n",
      "for 2019-12-08, MAE is:0.75 & sMAPE is:2.01% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.36% & 0.83\n",
      "for 2019-12-09, MAE is:1.07 & sMAPE is:2.78% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.35% & 0.83\n",
      "for 2019-12-10, MAE is:3.31 & sMAPE is:7.65% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.36% & 0.83\n",
      "for 2019-12-11, MAE is:0.73 & sMAPE is:1.91% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.35% & 0.83\n",
      "for 2019-12-12, MAE is:1.42 & sMAPE is:3.66% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :2.07 & 5.34% & 0.83\n",
      "for 2019-12-13, MAE is:0.74 & sMAPE is:1.98% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.33% & 0.83\n",
      "for 2019-12-14, MAE is:1.08 & sMAPE is:3.01% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.33% & 0.83\n",
      "for 2019-12-15, MAE is:1.39 & sMAPE is:3.74% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.32% & 0.83\n",
      "for 2019-12-16, MAE is:1.93 & sMAPE is:4.86% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.06 & 5.32% & 0.83\n",
      "for 2019-12-17, MAE is:1.41 & sMAPE is:3.59% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.32% & 0.83\n",
      "for 2019-12-18, MAE is:1.71 & sMAPE is:4.46% & rMAE is:2.92 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.31% & 0.84\n",
      "for 2019-12-19, MAE is:1.05 & sMAPE is:2.77% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.31% & 0.84\n",
      "for 2019-12-20, MAE is:1.21 & sMAPE is:3.35% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.30% & 0.84\n",
      "for 2019-12-21, MAE is:1.18 & sMAPE is:3.31% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :2.05 & 5.30% & 0.84\n",
      "for 2019-12-22, MAE is:1.68 & sMAPE is:4.69% & rMAE is:3.42 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 5.29% & 0.85\n",
      "for 2019-12-23, MAE is:0.95 & sMAPE is:2.56% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 5.29% & 0.85\n",
      "for 2019-12-24, MAE is:1.08 & sMAPE is:2.94% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 5.28% & 0.85\n",
      "for 2019-12-25, MAE is:1.24 & sMAPE is:3.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 5.27% & 0.84\n",
      "for 2019-12-26, MAE is:1.46 & sMAPE is:3.99% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 5.27% & 0.85\n",
      "for 2019-12-27, MAE is:2.07 & sMAPE is:5.53% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :2.04 & 5.27% & 0.85\n",
      "for 2019-12-28, MAE is:0.91 & sMAPE is:2.60% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 5.26% & 0.85\n",
      "for 2019-12-29, MAE is:1.30 & sMAPE is:3.87% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 5.26% & 0.85\n",
      "for 2019-12-30, MAE is:0.67 & sMAPE is:2.02% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :2.03 & 5.25% & 0.84\n",
      "for 2019-12-31, MAE is:1.27 & sMAPE is:3.80% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :2.02 & 5.25% & 0.84\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:36:11,311]\u001b[0m A new study created in RDB with name: NO_5_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:36:38,244]\u001b[0m Trial 1 finished with value: 1.9583788097548531 and parameters: {'n_hidden': 4, 'learning_rate': 0.0022605918116814254, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2922429395191769, 'dropout_rate_Layer_2': 0.2750067281119361, 'dropout_rate_Layer_3': 0.14639931237942952, 'dropout_rate_Layer_4': 0.21126708137803307, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.025095104775817705, 'l1_Layer_2': 1.273322683502114e-05, 'l1_Layer_3': 0.007769300438869099, 'l1_Layer_4': 4.111009047906116e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 230, 'n_units_Layer_3': 115, 'n_units_Layer_4': 245}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.58 | sMAPE for Test Set is: 83.17% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:36:39,793]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 14.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:36:44,172]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:36:48,432]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:36:52,179]\u001b[0m Trial 3 finished with value: 2.6470043209811163 and parameters: {'n_hidden': 4, 'learning_rate': 0.037868856247322585, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3255474694481705, 'dropout_rate_Layer_2': 0.07221573629625998, 'dropout_rate_Layer_3': 0.029974831833009266, 'dropout_rate_Layer_4': 0.28266135092493805, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.08122609062512577, 'l1_Layer_2': 0.00012359298363794944, 'l1_Layer_3': 0.003298548727741384, 'l1_Layer_4': 0.008284471617131438, 'n_units_Layer_1': 95, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140, 'n_units_Layer_4': 80}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.65 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 17.05 | sMAPE for Test Set is: 111.97% | rMAE for Test Set is: 5.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:36:53,421]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:36:55,569]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:36:58,012]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:01,297]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:03,080]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:06,087]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:08,534]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:11,009]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:16,807]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:22,392]\u001b[0m Trial 2 finished with value: 2.2515605070337905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011398786808635324, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12907646357014166, 'dropout_rate_Layer_2': 0.29581537011163545, 'dropout_rate_Layer_3': 0.13492478840965091, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.137566111637009e-05, 'l1_Layer_2': 5.16749728323817e-05, 'l1_Layer_3': 0.0015895643088183337, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 240}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.25 | sMAPE for Validation Set is: 5.79% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 19.24 | sMAPE for Test Set is: 116.82% | rMAE for Test Set is: 6.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:37:27,530]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:28,367]\u001b[0m Trial 6 finished with value: 2.4227766378498607 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019735956059034197, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38883212341189005, 'dropout_rate_Layer_2': 0.2627146556825701, 'dropout_rate_Layer_3': 0.17943739517942114, 'dropout_rate_Layer_4': 0.13446681195643803, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008567852728819274, 'l1_Layer_2': 2.2261496648294653e-05, 'l1_Layer_3': 0.0003175165369178403, 'l1_Layer_4': 0.04071120612882267, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 205, 'n_units_Layer_4': 245}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.42 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 12.86 | sMAPE for Test Set is: 101.60% | rMAE for Test Set is: 4.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:37:31,797]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:33,768]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:37,598]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:49,606]\u001b[0m Trial 17 finished with value: 2.4913259690211915 and parameters: {'n_hidden': 3, 'learning_rate': 0.01921752237563825, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21686780206427275, 'dropout_rate_Layer_2': 0.3005164427636089, 'dropout_rate_Layer_3': 0.08249338894751963, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009605314330488581, 'l1_Layer_2': 2.4039389878982433e-05, 'l1_Layer_3': 0.0017570894421006901, 'n_units_Layer_1': 95, 'n_units_Layer_2': 300, 'n_units_Layer_3': 205}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.49 | sMAPE for Validation Set is: 6.54% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 117.19% | rMAE for Test Set is: 6.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:37:50,093]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:37:55,608]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:00,040]\u001b[0m Trial 21 finished with value: 3.1619065749223445 and parameters: {'n_hidden': 3, 'learning_rate': 0.07096393295145784, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042559426358328704, 'dropout_rate_Layer_2': 0.3165783792998543, 'dropout_rate_Layer_3': 0.20622416998955911, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008949646468822604, 'l1_Layer_2': 0.0002580368927283144, 'l1_Layer_3': 0.020423121871078313, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 210}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.16 | sMAPE for Validation Set is: 7.98% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 117.71% | rMAE for Test Set is: 6.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:38:05,085]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:05,389]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:09,625]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:12,171]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:12,663]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:14,375]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:18,899]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:19,207]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:24,328]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:27,778]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:30,272]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:34,431]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:43,415]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:47,989]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:51,865]\u001b[0m Trial 32 finished with value: 2.162173491012673 and parameters: {'n_hidden': 3, 'learning_rate': 0.021479824120496253, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3685013166658288, 'dropout_rate_Layer_2': 0.31571363990710594, 'dropout_rate_Layer_3': 0.21494309387327226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3922860432780173e-05, 'l1_Layer_2': 0.06851925399973814, 'l1_Layer_3': 0.002342684594416557, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 145}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:38:52,004]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 5.55% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 14.32 | sMAPE for Test Set is: 105.99% | rMAE for Test Set is: 4.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:38:58,120]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:00,748]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:04,554]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:04,679]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:09,406]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:12,591]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:16,533]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:18,628]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:21,502]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:24,884]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:25,337]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:29,657]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:31,087]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:34,178]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:34,275]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:38,176]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:41,488]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:41,681]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:42,566]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:47,740]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:48,134]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:53,277]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 9.84% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 18.36 | sMAPE for Test Set is: 113.80% | rMAE for Test Set is: 6.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:39:54,102]\u001b[0m Trial 60 finished with value: 3.8811959442923634 and parameters: {'n_hidden': 4, 'learning_rate': 0.04346684267819378, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3999672521860842, 'dropout_rate_Layer_2': 0.22967267786762247, 'dropout_rate_Layer_3': 0.169224505071952, 'dropout_rate_Layer_4': 0.27259896964317254, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0004193126388626893, 'l1_Layer_2': 0.00036385395710586096, 'l1_Layer_3': 0.00030463458428582824, 'l1_Layer_4': 6.486030803388221e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 195, 'n_units_Layer_3': 145, 'n_units_Layer_4': 230}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:56,642]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:39:59,087]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:02,493]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:02,893]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:04,923]\u001b[0m Trial 59 finished with value: 3.847743596844167 and parameters: {'n_hidden': 4, 'learning_rate': 0.01462656826425956, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37838889384690044, 'dropout_rate_Layer_2': 0.12854125877596775, 'dropout_rate_Layer_3': 0.018021172146301636, 'dropout_rate_Layer_4': 0.36532852096188617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00996081976752569, 'l1_Layer_2': 0.009401058554202238, 'l1_Layer_3': 0.0004056882090373615, 'l1_Layer_4': 3.5196963700340475e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 220, 'n_units_Layer_3': 60, 'n_units_Layer_4': 70}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.85 | sMAPE for Validation Set is: 9.86% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 21.39 | sMAPE for Test Set is: 119.54% | rMAE for Test Set is: 7.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:40:09,245]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:11,159]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:13,913]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:15,821]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:18,047]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:18,215]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:18,756]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:23,567]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:26,653]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:26,808]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:26,895]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:27,055]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:34,530]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:34,945]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:38,215]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:38,784]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:42,672]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:45,375]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:45,644]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:46,068]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:52,328]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:55,070]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:57,302]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:57,784]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:40:59,343]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:02,076]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:03,194]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:08,490]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:08,550]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:10,770]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:14,840]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:16,144]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:16,930]\u001b[0m Trial 96 finished with value: 2.6148221898833683 and parameters: {'n_hidden': 3, 'learning_rate': 0.007480761429274887, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043541098843833975, 'dropout_rate_Layer_2': 0.2940093815685911, 'dropout_rate_Layer_3': 0.20623784104986662, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001592338055792462, 'l1_Layer_2': 0.0009149191826450181, 'l1_Layer_3': 5.619374292415279e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.61 | sMAPE for Validation Set is: 6.80% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 17.33 | sMAPE for Test Set is: 112.67% | rMAE for Test Set is: 5.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:41:18,598]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:18,755]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:20,580]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:21,009]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:26,168]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:28,632]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:30,766]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:34,805]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:37,639]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:49,027]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:53,131]\u001b[0m Trial 105 finished with value: 1.9722519141202532 and parameters: {'n_hidden': 3, 'learning_rate': 0.002741899265492013, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27211366696216865, 'dropout_rate_Layer_2': 0.2531252684560266, 'dropout_rate_Layer_3': 0.19762038876415117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002750946113829142, 'l1_Layer_2': 0.030120503966014716, 'l1_Layer_3': 0.000115944107368484, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.29% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 65.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:41:55,480]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:41:55,832]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:01,381]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:05,870]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:10,126]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:13,087]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.19 | sMAPE for Validation Set is: 10.85% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 124.16% | rMAE for Test Set is: 7.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:42:14,444]\u001b[0m Trial 118 finished with value: 4.186619611079467 and parameters: {'n_hidden': 3, 'learning_rate': 0.03274317745643609, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3588726955210995, 'dropout_rate_Layer_2': 0.2779797679143526, 'dropout_rate_Layer_3': 0.20357473971911602, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004751303469014601, 'l1_Layer_2': 1.1178102991876304e-05, 'l1_Layer_3': 2.9896635426524603e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:19,092]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:22,867]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:26,786]\u001b[0m Trial 117 finished with value: 2.105753319698561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036118763678042883, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3477972813084803, 'dropout_rate_Layer_2': 0.09131540630402492, 'dropout_rate_Layer_3': 0.26123344424322814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005195807585223628, 'l1_Layer_2': 0.02755251619248331, 'l1_Layer_3': 5.178647773526617e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 4.61 | sMAPE for Test Set is: 67.06% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:42:27,259]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:33,649]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:36,483]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:36,815]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:40,970]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:43,011]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:43,582]\u001b[0m Trial 125 finished with value: 3.8816392021427837 and parameters: {'n_hidden': 3, 'learning_rate': 0.013869351737334059, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3234944654509635, 'dropout_rate_Layer_2': 0.2687130360387445, 'dropout_rate_Layer_3': 0.2104534596475913, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0010123054907938253, 'l1_Layer_2': 0.0007178309109707834, 'l1_Layer_3': 2.5530896451996844e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 1 with value: 1.9583788097548531.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.88 | sMAPE for Validation Set is: 10.28% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 20.05 | sMAPE for Test Set is: 117.57% | rMAE for Test Set is: 6.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:42:47,643]\u001b[0m Trial 122 finished with value: 1.9192655381410482 and parameters: {'n_hidden': 3, 'learning_rate': 0.012791649265073002, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11095390559728918, 'dropout_rate_Layer_2': 0.14643601811463974, 'dropout_rate_Layer_3': 0.013453007178676132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09562294769001228, 'l1_Layer_2': 0.011949385444539329, 'l1_Layer_3': 0.0008380201462784232, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.86 | sMAPE for Test Set is: 95.57% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:42:47,902]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:48,616]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:51,978]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:57,535]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:42:58,858]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:01,108]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:02,934]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:04,667]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:06,623]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:09,214]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:10,758]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:10,942]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:12,809]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:18,343]\u001b[0m Trial 133 finished with value: 2.4472691304901235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0066605375623545885, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39661536951367754, 'dropout_rate_Layer_2': 0.3082289989457473, 'dropout_rate_Layer_3': 0.28437009532695057, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010518255670171047, 'l1_Layer_2': 0.0021088202854423472, 'l1_Layer_3': 0.0001397777481084851, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:18,347]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 6.41% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 17.37 | sMAPE for Test Set is: 112.61% | rMAE for Test Set is: 5.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:43:18,783]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:26,947]\u001b[0m Trial 145 finished with value: 2.5829986676157515 and parameters: {'n_hidden': 3, 'learning_rate': 0.006555788180706412, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2721855214945321, 'dropout_rate_Layer_2': 0.3537719176098934, 'dropout_rate_Layer_3': 0.24423110394777728, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2032954343193646e-05, 'l1_Layer_2': 0.007292062550251304, 'l1_Layer_3': 0.0001581313047917331, 'n_units_Layer_1': 125, 'n_units_Layer_2': 245, 'n_units_Layer_3': 275}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.58 | sMAPE for Validation Set is: 6.72% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 16.86 | sMAPE for Test Set is: 110.83% | rMAE for Test Set is: 5.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:43:29,230]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:29,624]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:34,998]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:40,417]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:43,826]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:49,394]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:55,942]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:43:56,298]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:00,820]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:03,169]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:05,706]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:06,489]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:10,602]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:13,145]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:17,883]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:24,603]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:29,199]\u001b[0m Trial 152 finished with value: 2.619845514031096 and parameters: {'n_hidden': 4, 'learning_rate': 0.018001073036635774, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2226413479081074, 'dropout_rate_Layer_2': 0.04726295861612582, 'dropout_rate_Layer_3': 0.12169162901781583, 'dropout_rate_Layer_4': 0.09651209241548094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0002669567251028921, 'l1_Layer_2': 0.00032900085707109224, 'l1_Layer_3': 0.002786108821560576, 'l1_Layer_4': 0.05169349593083206, 'n_units_Layer_1': 145, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235, 'n_units_Layer_4': 205}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 6.70% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 21.21 | sMAPE for Test Set is: 119.90% | rMAE for Test Set is: 6.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:44:32,893]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:37,341]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:41,971]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:44,552]\u001b[0m Trial 166 finished with value: 2.425203252007397 and parameters: {'n_hidden': 3, 'learning_rate': 0.007014018123335408, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2984787429355622, 'dropout_rate_Layer_2': 0.3051114123370773, 'dropout_rate_Layer_3': 0.2012399813102174, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.1933828486878515e-05, 'l1_Layer_2': 0.025826595499402968, 'l1_Layer_3': 0.00017169628527269744, 'n_units_Layer_1': 140, 'n_units_Layer_2': 270, 'n_units_Layer_3': 260}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.43 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 17.72 | sMAPE for Test Set is: 112.78% | rMAE for Test Set is: 5.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:44:45,929]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:46,659]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:49,509]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:53,557]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:54,915]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:44:55,138]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:01,727]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:04,456]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:07,041]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:08,760]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:24,642]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:33,465]\u001b[0m Trial 173 finished with value: 2.092714942740328 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013547797290013523, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07489372926668048, 'dropout_rate_Layer_2': 0.36297981310674454, 'dropout_rate_Layer_3': 0.36986515570454037, 'dropout_rate_Layer_4': 0.29779355546851755, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.3184846808189751e-05, 'l1_Layer_2': 0.0011783010974526942, 'l1_Layer_3': 6.57022925910933e-05, 'l1_Layer_4': 0.0003237704076925302, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 60, 'n_units_Layer_4': 115}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.27 | sMAPE for Test Set is: 102.25% | rMAE for Test Set is: 4.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:45:35,308]\u001b[0m Trial 177 finished with value: 2.0350590816867196 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008519414075836719, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2948145966293851, 'dropout_rate_Layer_2': 0.14607820269538357, 'dropout_rate_Layer_3': 0.36363460387721863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015476380401759646, 'l1_Layer_2': 0.0006671930087688159, 'l1_Layer_3': 0.0005263939948165222, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.49 | sMAPE for Test Set is: 103.99% | rMAE for Test Set is: 4.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:45:43,829]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:45:59,659]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:02,294]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:08,816]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:10,747]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:14,069]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:18,122]\u001b[0m Trial 182 finished with value: 2.1281771216756584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009194572244508247, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29458752239893393, 'dropout_rate_Layer_2': 0.14712058240123368, 'dropout_rate_Layer_3': 0.1540307657780267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.011596598603647782, 'l1_Layer_2': 0.0001368234406409105, 'l1_Layer_3': 0.00047055150674216916, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.13 | sMAPE for Validation Set is: 5.58% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.53 | sMAPE for Test Set is: 101.50% | rMAE for Test Set is: 4.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:46:24,308]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:28,728]\u001b[0m Trial 188 finished with value: 2.2955323384549584 and parameters: {'n_hidden': 3, 'learning_rate': 0.007776458243248802, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1731696324342435, 'dropout_rate_Layer_2': 0.1907676469598943, 'dropout_rate_Layer_3': 0.34519868080943283, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00014925560077669724, 'l1_Layer_2': 0.07505156513278943, 'l1_Layer_3': 0.0014954147508774134, 'n_units_Layer_1': 125, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.30 | sMAPE for Validation Set is: 5.85% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 102.67% | rMAE for Test Set is: 4.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:46:32,134]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:46:56,979]\u001b[0m Trial 190 finished with value: 2.202779801127187 and parameters: {'n_hidden': 3, 'learning_rate': 0.002783782200692842, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2885639105545507, 'dropout_rate_Layer_2': 0.3006235735983357, 'dropout_rate_Layer_3': 0.18916226782351309, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.535014346112184e-05, 'l1_Layer_2': 0.02140514982690078, 'l1_Layer_3': 7.823367954427493e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 250}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 5.72% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 17.76 | sMAPE for Test Set is: 112.58% | rMAE for Test Set is: 5.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:47:05,286]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:47:12,980]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:47:18,350]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:47:22,901]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:47:33,025]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:47:41,564]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:47:52,955]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:48:11,319]\u001b[0m Trial 199 finished with value: 2.047852781365038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005563805488770664, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27128141222186347, 'dropout_rate_Layer_2': 0.14934400421641622, 'dropout_rate_Layer_3': 0.12410552654390077, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01571151586457599, 'l1_Layer_2': 0.00115074011071613, 'l1_Layer_3': 0.0005572698249514914, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.82 | sMAPE for Test Set is: 104.75% | rMAE for Test Set is: 4.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:48:17,214]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:48:48,849]\u001b[0m Trial 196 finished with value: 2.074831477206069 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006251868250619472, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2727402246206987, 'dropout_rate_Layer_2': 0.15575105219055957, 'dropout_rate_Layer_3': 0.14279213663321563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01577806374400045, 'l1_Layer_2': 0.0003346747428915239, 'l1_Layer_3': 0.000532634193560132, 'n_units_Layer_1': 245, 'n_units_Layer_2': 295, 'n_units_Layer_3': 175}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.21 | sMAPE for Test Set is: 103.43% | rMAE for Test Set is: 4.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:49:41,497]\u001b[0m Trial 197 finished with value: 2.0606264968424535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006297221939303095, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2569996252518042, 'dropout_rate_Layer_2': 0.16085275403874316, 'dropout_rate_Layer_3': 0.15284529403098274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.014436095386074084, 'l1_Layer_2': 0.0015471943809695747, 'l1_Layer_3': 0.0027306771740918724, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 175}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.28 | sMAPE for Test Set is: 108.18% | rMAE for Test Set is: 5.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:49:53,076]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:50:14,354]\u001b[0m Trial 202 finished with value: 2.85051519037847 and parameters: {'n_hidden': 4, 'learning_rate': 0.012568781532997874, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2918237709224787, 'dropout_rate_Layer_2': 0.26219173520173905, 'dropout_rate_Layer_3': 0.15957897379701494, 'dropout_rate_Layer_4': 0.16485593380003266, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0027536219909461038, 'l1_Layer_2': 0.0018226615984184799, 'l1_Layer_3': 0.0009860352382878614, 'l1_Layer_4': 0.000538445151819582, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275, 'n_units_Layer_4': 205}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.85 | sMAPE for Validation Set is: 7.21% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 118.71% | rMAE for Test Set is: 6.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:50:17,002]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:50:56,235]\u001b[0m Trial 206 finished with value: 2.0312683786893024 and parameters: {'n_hidden': 3, 'learning_rate': 0.000511176428476551, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26234629953155053, 'dropout_rate_Layer_2': 0.16352642456234454, 'dropout_rate_Layer_3': 0.1513436615600959, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025160577823875388, 'l1_Layer_2': 0.0005171827985675638, 'l1_Layer_3': 0.0006802495938040819, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.88 | sMAPE for Test Set is: 104.72% | rMAE for Test Set is: 4.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:51:29,120]\u001b[0m Trial 204 finished with value: 2.0550259853608117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007162838825413763, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2714917957572339, 'dropout_rate_Layer_2': 0.17534560140579838, 'dropout_rate_Layer_3': 0.14710820572563232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.021928677221245675, 'l1_Layer_2': 0.0012729569216007968, 'l1_Layer_3': 0.0006951544300787758, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 160}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.30% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.55 | sMAPE for Test Set is: 106.53% | rMAE for Test Set is: 4.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:51:32,721]\u001b[0m Trial 207 finished with value: 2.0058970731330317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007850002309061488, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2464712016015841, 'dropout_rate_Layer_2': 0.15791581514314595, 'dropout_rate_Layer_3': 0.15378835643387861, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02348859805313066, 'l1_Layer_2': 0.0004950375105668142, 'l1_Layer_3': 0.0009817617647128831, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.47 | sMAPE for Test Set is: 106.50% | rMAE for Test Set is: 4.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:51:39,317]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:51:42,370]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:51:47,777]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:51:51,103]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:51:51,395]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:51:59,705]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:03,916]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:07,789]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:10,522]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:10,668]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:13,979]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:21,648]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:29,485]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:34,304]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:52:34,322]\u001b[0m Trial 209 finished with value: 2.1025017711348153 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005273972739355597, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2504199929544209, 'dropout_rate_Layer_2': 0.1642055521012636, 'dropout_rate_Layer_3': 0.15297916874952536, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029589442069301013, 'l1_Layer_2': 0.0008536397100799565, 'l1_Layer_3': 0.0007647494223662595, 'n_units_Layer_1': 260, 'n_units_Layer_2': 275, 'n_units_Layer_3': 190}. Best is trial 122 with value: 1.9192655381410482.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 5.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 15.02 | sMAPE for Test Set is: 107.75% | rMAE for Test Set is: 4.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:52:45,732]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:53:13,624]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:53:49,085]\u001b[0m Trial 223 finished with value: 1.7569906623803035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005071762896042669, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1440274273668359, 'dropout_rate_Layer_2': 0.09743194518182369, 'dropout_rate_Layer_3': 0.16613603091456608, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003377547104026101, 'l1_Layer_2': 0.004528160435946684, 'l1_Layer_3': 2.69281890253459e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 230, 'n_units_Layer_3': 240}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.76 | sMAPE for Validation Set is: 4.65% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 2.23 | sMAPE for Test Set is: 43.50% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:53:53,394]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:53:55,658]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:08,934]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:17,659]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:32,702]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:34,980]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:37,612]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:41,093]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:46,731]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:50,203]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:54:52,378]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:01,914]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:12,716]\u001b[0m Trial 221 finished with value: 2.0409853539031757 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006980544480386716, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2646356903113785, 'dropout_rate_Layer_2': 0.11118598006656717, 'dropout_rate_Layer_3': 0.11579738215996174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.015880153770754843, 'l1_Layer_2': 0.001199612368299963, 'l1_Layer_3': 0.0009012576738780471, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 170}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.54 | sMAPE for Test Set is: 100.88% | rMAE for Test Set is: 4.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:55:15,277]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:23,647]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:30,559]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:37,180]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:42,487]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:44,966]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:52,316]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:52,465]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:57,479]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:55:58,976]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:01,129]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:02,459]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:04,640]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:09,355]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:11,151]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:14,251]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:18,226]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:18,511]\u001b[0m Trial 250 finished with value: 2.0683027003908063 and parameters: {'n_hidden': 3, 'learning_rate': 0.005742670500044706, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3773469864482924, 'dropout_rate_Layer_2': 0.3408978409450516, 'dropout_rate_Layer_3': 0.11730045452816502, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00023783623504759673, 'l1_Layer_2': 0.04790461308349289, 'l1_Layer_3': 8.33758168037768e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 210, 'n_units_Layer_3': 260}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 18.40 | sMAPE for Test Set is: 114.03% | rMAE for Test Set is: 6.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:56:22,073]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:22,227]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:24,249]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:31,954]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:32,584]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:35,974]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:36,187]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:40,751]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:41,170]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:44,938]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:51,089]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:52,389]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:52,668]\u001b[0m Trial 247 finished with value: 2.0154749099901936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008309363954391328, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21390808322126717, 'dropout_rate_Layer_2': 0.09185841225569305, 'dropout_rate_Layer_3': 0.1232214045408395, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009329391019380169, 'l1_Layer_2': 0.001380867077115965, 'l1_Layer_3': 0.0006199105415772702, 'n_units_Layer_1': 80, 'n_units_Layer_2': 290, 'n_units_Layer_3': 170}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.50 | sMAPE for Test Set is: 100.93% | rMAE for Test Set is: 4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:56:53,809]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:58,030]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:59,381]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:56:59,681]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:03,255]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:05,760]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:07,795]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:09,780]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:11,396]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:11,984]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:16,353]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:16,412]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:16,694]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:22,637]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:25,202]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:28,079]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:30,119]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:32,194]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:37,245]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:40,440]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:44,882]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:48,200]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:50,283]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:53,912]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:54,416]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:57:57,937]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:03,039]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:05,735]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:08,810]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:21,025]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:26,758]\u001b[0m Trial 302 finished with value: 2.0633182390308913 and parameters: {'n_hidden': 3, 'learning_rate': 0.034259125343045434, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001934590050968854, 'dropout_rate_Layer_2': 0.2965836692133843, 'dropout_rate_Layer_3': 0.1544575434422469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023130032490676536, 'l1_Layer_2': 0.0017169104441206316, 'l1_Layer_3': 0.08475739945421645, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 16.76 | sMAPE for Test Set is: 111.70% | rMAE for Test Set is: 5.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:58:31,534]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:34,150]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:37,065]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:40,328]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:40,874]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:47,786]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:58:51,252]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:04,044]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:06,239]\u001b[0m Trial 312 finished with value: 4.700507950258877 and parameters: {'n_hidden': 4, 'learning_rate': 0.09231077735423004, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3126167053035936, 'dropout_rate_Layer_2': 0.37505584853894974, 'dropout_rate_Layer_3': 0.26858544814008617, 'dropout_rate_Layer_4': 0.09948104410138559, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020595845296748064, 'l1_Layer_2': 0.011443002744747967, 'l1_Layer_3': 0.0038329192773622484, 'l1_Layer_4': 0.04282137507134413, 'n_units_Layer_1': 165, 'n_units_Layer_2': 285, 'n_units_Layer_3': 120, 'n_units_Layer_4': 245}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.70 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 115.98% | rMAE for Test Set is: 6.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:59:07,454]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:10,766]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:15,655]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:17,814]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:20,494]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:22,620]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:24,736]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:28,886]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:29,053]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:33,803]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:36,195]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:39,384]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:42,075]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:42,242]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:46,201]\u001b[0m Trial 320 finished with value: 2.0099504187830775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034514878542328026, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03620487125187333, 'dropout_rate_Layer_2': 0.1471639708833538, 'dropout_rate_Layer_3': 0.02737390820342167, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.000764965426793204, 'l1_Layer_2': 1.0650602512078523e-05, 'l1_Layer_3': 0.0003585490675407002, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 250}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.55 | sMAPE for Test Set is: 100.81% | rMAE for Test Set is: 4.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 19:59:48,097]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:51,157]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 19:59:59,237]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:09,940]\u001b[0m Trial 329 finished with value: 2.622552078902388 and parameters: {'n_hidden': 4, 'learning_rate': 0.006027726548024685, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30414544173970776, 'dropout_rate_Layer_2': 0.21520103279818714, 'dropout_rate_Layer_3': 0.24509744911729647, 'dropout_rate_Layer_4': 0.02241526087796233, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06885061826540559, 'l1_Layer_2': 0.0001478094980737485, 'l1_Layer_3': 2.107540959807044e-05, 'l1_Layer_4': 0.02282793953423959, 'n_units_Layer_1': 65, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240, 'n_units_Layer_4': 265}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 6.68% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 18.68 | sMAPE for Test Set is: 115.24% | rMAE for Test Set is: 6.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:00:13,182]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:13,204]\u001b[0m Trial 330 finished with value: 2.0078804271935975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024035702955661274, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06821818090020951, 'dropout_rate_Layer_2': 0.08768353824568048, 'dropout_rate_Layer_3': 0.1224054466454355, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017972079274930178, 'l1_Layer_2': 8.585025014221709e-05, 'l1_Layer_3': 0.024409468334091217, 'n_units_Layer_1': 250, 'n_units_Layer_2': 65, 'n_units_Layer_3': 75}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.67 | sMAPE for Test Set is: 100.32% | rMAE for Test Set is: 4.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:00:17,978]\u001b[0m Trial 303 finished with value: 1.906013471400937 and parameters: {'n_hidden': 3, 'learning_rate': 0.000654411349328308, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3797301975765652, 'dropout_rate_Layer_2': 0.11993978602651309, 'dropout_rate_Layer_3': 0.16896116786145252, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009683654137695173, 'l1_Layer_2': 1.4666618079915369e-05, 'l1_Layer_3': 0.00040690466393220666, 'n_units_Layer_1': 250, 'n_units_Layer_2': 185, 'n_units_Layer_3': 170}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.42 | sMAPE for Test Set is: 93.91% | rMAE for Test Set is: 3.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:00:19,641]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:23,520]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:26,275]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:29,807]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:32,017]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:37,964]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:46,763]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:49,868]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:52,673]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:53,081]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:00:58,796]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:00,324]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:00,927]\u001b[0m Trial 336 finished with value: 3.176513435063637 and parameters: {'n_hidden': 4, 'learning_rate': 0.03569611789914149, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013088364592742941, 'dropout_rate_Layer_2': 0.1261777123078312, 'dropout_rate_Layer_3': 0.17632288206476204, 'dropout_rate_Layer_4': 0.22246327409081118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013053836110690057, 'l1_Layer_2': 0.021586271246140373, 'l1_Layer_3': 0.053185918526277375, 'l1_Layer_4': 0.09583360098711577, 'n_units_Layer_1': 220, 'n_units_Layer_2': 110, 'n_units_Layer_3': 250, 'n_units_Layer_4': 55}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.18 | sMAPE for Validation Set is: 8.18% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 22.14 | sMAPE for Test Set is: 121.64% | rMAE for Test Set is: 7.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:01:05,875]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:08,359]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:09,931]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:20,033]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:26,748]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:28,221]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:32,345]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:32,826]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:41,965]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:42,361]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:42,904]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:48,425]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:50,536]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:52,425]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:01:57,450]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:02:02,238]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:02:06,766]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:02:08,499]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:02:47,180]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:02:51,263]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:02:59,148]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:09,540]\u001b[0m Trial 369 finished with value: 2.3325213678899868 and parameters: {'n_hidden': 3, 'learning_rate': 0.005615778749605342, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1824537416438711, 'dropout_rate_Layer_2': 0.28544815044118155, 'dropout_rate_Layer_3': 0.36187222283191234, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00010534117061556759, 'l1_Layer_2': 0.09801983698951747, 'l1_Layer_3': 0.0025407273680640176, 'n_units_Layer_1': 95, 'n_units_Layer_2': 255, 'n_units_Layer_3': 240}. Best is trial 223 with value: 1.7569906623803035.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.33 | sMAPE for Validation Set is: 5.92% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 16.29 | sMAPE for Test Set is: 109.54% | rMAE for Test Set is: 5.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:03:12,349]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:15,037]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:20,543]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:23,594]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:32,189]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:34,416]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:38,962]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.67 | sMAPE for Validation Set is: 4.47% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.15 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:03:49,234]\u001b[0m Trial 367 finished with value: 1.673526230653127 and parameters: {'n_hidden': 3, 'learning_rate': 0.000996634956970711, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13179101032560553, 'dropout_rate_Layer_2': 0.19641603408297603, 'dropout_rate_Layer_3': 0.09139527835653949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004344943924536399, 'l1_Layer_2': 0.0006868190006691838, 'l1_Layer_3': 0.0009163194210900606, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:03:52,545]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:15,412]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:17,934]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:18,607]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:24,421]\u001b[0m Trial 352 finished with value: 1.9627878465421595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006663938955563, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27747329139646276, 'dropout_rate_Layer_2': 0.16307286640287869, 'dropout_rate_Layer_3': 0.05373484894971363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01711221867517406, 'l1_Layer_2': 0.0010472794693130562, 'l1_Layer_3': 0.0021943705540758518, 'n_units_Layer_1': 250, 'n_units_Layer_2': 285, 'n_units_Layer_3': 180}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.62 | sMAPE for Test Set is: 90.94% | rMAE for Test Set is: 3.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:04:26,328]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:28,529]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:30,943]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:33,757]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:37,090]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:37,269]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:37,662]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:42,976]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:43,282]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:47,415]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:50,756]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:50,961]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:53,737]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:56,326]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:57,993]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:04:58,048]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:01,118]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:04,793]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:05,200]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:05,216]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:08,654]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:12,407]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:12,553]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:18,687]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:19,072]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:23,302]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:27,056]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:35,575]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:48,064]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:50,888]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:53,618]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:05:58,450]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:01,803]\u001b[0m Trial 408 finished with value: 2.0297704976719406 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013488884532215518, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16239596649569688, 'dropout_rate_Layer_2': 0.2156846014621867, 'dropout_rate_Layer_3': 0.14350843457015888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.8433976639899474e-05, 'l1_Layer_2': 0.008404854661696094, 'l1_Layer_3': 0.0006386531380870178, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.03 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 105.28% | rMAE for Test Set is: 4.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:06:09,458]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:17,338]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:26,121]\u001b[0m Trial 412 finished with value: 2.0734767737646123 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006333270856476487, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26504818387927465, 'dropout_rate_Layer_2': 0.10402156907756827, 'dropout_rate_Layer_3': 0.167789818819649, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.029513599136898088, 'l1_Layer_2': 0.0004772396158925181, 'l1_Layer_3': 2.4324899739611564e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 270, 'n_units_Layer_3': 180}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 5.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.67 | sMAPE for Test Set is: 104.54% | rMAE for Test Set is: 4.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:06:33,824]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:37,105]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:40,532]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:45,382]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:46,755]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:48,795]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:50,121]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:53,198]\u001b[0m Trial 405 finished with value: 1.9688575159371233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007805497384431707, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2732398491783953, 'dropout_rate_Layer_2': 0.10055394053456895, 'dropout_rate_Layer_3': 0.179715013797874, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02120447719439635, 'l1_Layer_2': 0.00020103611582082394, 'l1_Layer_3': 0.0020306543663525245, 'n_units_Layer_1': 255, 'n_units_Layer_2': 300, 'n_units_Layer_3': 160}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 100.27% | rMAE for Test Set is: 4.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:06:53,455]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:06:58,087]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:00,260]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:29,315]\u001b[0m Trial 428 finished with value: 2.020849955557001 and parameters: {'n_hidden': 3, 'learning_rate': 0.002709681922004046, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1634797511695682, 'dropout_rate_Layer_2': 0.12922958252407685, 'dropout_rate_Layer_3': 0.0004649098585569056, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003240447161670314, 'l1_Layer_2': 0.06693283754320575, 'l1_Layer_3': 0.008451081632699564, 'n_units_Layer_1': 220, 'n_units_Layer_2': 50, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.07 | sMAPE for Test Set is: 106.69% | rMAE for Test Set is: 4.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:07:34,648]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:36,724]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:45,009]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:46,479]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:50,457]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:52,901]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:07:58,201]\u001b[0m Trial 419 finished with value: 2.267257127957193 and parameters: {'n_hidden': 3, 'learning_rate': 0.002128311726049088, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12655846406732185, 'dropout_rate_Layer_2': 0.24344772043623786, 'dropout_rate_Layer_3': 0.08923800319730683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.792199864257768e-05, 'l1_Layer_2': 0.01648692566016351, 'l1_Layer_3': 0.0017637414756543582, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 5.88% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 99.85% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:07:59,569]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:00,219]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:00,498]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:05,861]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:10,280]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:10,574]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:10,740]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:18,462]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:21,206]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:29,003]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:33,246]\u001b[0m Trial 439 finished with value: 2.0623666421705558 and parameters: {'n_hidden': 3, 'learning_rate': 0.001021916360600536, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26896440860467974, 'dropout_rate_Layer_2': 0.038304799012675236, 'dropout_rate_Layer_3': 0.1186914753986231, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.626206135735522e-05, 'l1_Layer_2': 0.0007234724659605876, 'l1_Layer_3': 0.0038142122515391922, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.87 | sMAPE for Test Set is: 108.65% | rMAE for Test Set is: 5.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:08:36,867]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:38,481]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:43,229]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:47,729]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:51,334]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:55,094]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:57,320]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:08:58,105]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:01,643]\u001b[0m Trial 449 finished with value: 1.962030350038681 and parameters: {'n_hidden': 3, 'learning_rate': 0.003073984726359541, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08895978428591203, 'dropout_rate_Layer_2': 0.19689432126932663, 'dropout_rate_Layer_3': 0.15064955652034517, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006752777227572401, 'l1_Layer_2': 6.384267382377856e-05, 'l1_Layer_3': 0.01812543862689437, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 195}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.32 | sMAPE for Test Set is: 89.57% | rMAE for Test Set is: 3.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:09:04,667]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:07,120]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:10,946]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:14,216]\u001b[0m Trial 453 finished with value: 1.9379446220131562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025011480886747003, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09154609815658907, 'dropout_rate_Layer_2': 0.19960740122344442, 'dropout_rate_Layer_3': 0.1562345973737593, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000590216008145243, 'l1_Layer_2': 4.936802954938259e-05, 'l1_Layer_3': 0.014854849001455391, 'n_units_Layer_1': 245, 'n_units_Layer_2': 140, 'n_units_Layer_3': 200}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.69 | sMAPE for Test Set is: 87.19% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:09:18,000]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:18,343]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:20,753]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:22,604]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:23,972]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:25,048]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:32,453]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:39,733]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:43,223]\u001b[0m Trial 467 finished with value: 2.437588357765581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036533799017444326, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2441794008484329, 'dropout_rate_Layer_2': 0.31796662402694154, 'dropout_rate_Layer_3': 0.15697790899125694, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 2.5985219190966504e-05, 'l1_Layer_2': 0.002306322432438146, 'l1_Layer_3': 5.1254523605091164e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 260, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.44 | sMAPE for Validation Set is: 6.36% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 17.73 | sMAPE for Test Set is: 112.90% | rMAE for Test Set is: 5.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:09:47,809]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:50,822]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:51,145]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:55,939]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:57,650]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:09:59,918]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:03,800]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:06,084]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:12,905]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:14,468]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:15,350]\u001b[0m Trial 468 finished with value: 2.038460094888783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009135565732896961, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23145457537084047, 'dropout_rate_Layer_2': 0.025269655090586568, 'dropout_rate_Layer_3': 0.00244921484728039, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.6870966117826084e-05, 'l1_Layer_2': 0.0002799126690301777, 'l1_Layer_3': 0.008292719123846728, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 16.35 | sMAPE for Test Set is: 109.59% | rMAE for Test Set is: 5.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:10:20,712]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:22,397]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:25,053]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:27,761]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:34,262]\u001b[0m Trial 469 finished with value: 1.9506801763992734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008256783089723214, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2845908448393717, 'dropout_rate_Layer_2': 0.0039038973738550475, 'dropout_rate_Layer_3': 0.15282737837052404, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0022497405272220014, 'l1_Layer_2': 0.0001757312044524154, 'l1_Layer_3': 0.007158301643210681, 'n_units_Layer_1': 250, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.86 | sMAPE for Test Set is: 101.02% | rMAE for Test Set is: 4.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:10:37,427]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:40,241]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:43,279]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:48,688]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:10:57,429]\u001b[0m Trial 485 finished with value: 2.1176527137951697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009461302848449169, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2794260835875787, 'dropout_rate_Layer_2': 0.023696897713138224, 'dropout_rate_Layer_3': 0.0023877656481318846, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00011926956188029405, 'l1_Layer_2': 0.00026823505689182813, 'l1_Layer_3': 0.06799400391233183, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 5.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 17.14 | sMAPE for Test Set is: 111.22% | rMAE for Test Set is: 5.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:11:00,906]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:05,551]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:10,053]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:10,673]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:16,774]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:17,065]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:34,302]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:37,763]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:41,565]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.84 | sMAPE for Test Set is: 100.92% | rMAE for Test Set is: 4.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:11:51,583]\u001b[0m Trial 492 finished with value: 1.9268738617710561 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008602144959373743, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31406947295854926, 'dropout_rate_Layer_2': 0.006534456658048526, 'dropout_rate_Layer_3': 0.00954655812928361, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002198158389284302, 'l1_Layer_2': 0.00024462733427772077, 'l1_Layer_3': 0.030792674393150952, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 295}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:11:59,412]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:03,287]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:06,718]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:10,454]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:13,506]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:16,108]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:18,828]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:23,392]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:27,460]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:30,801]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:41,884]\u001b[0m Trial 490 finished with value: 1.9008183003182293 and parameters: {'n_hidden': 3, 'learning_rate': 0.00085777088597709, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3072947954999248, 'dropout_rate_Layer_2': 0.0016671344723884311, 'dropout_rate_Layer_3': 0.0005833148680621583, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0023067753794664496, 'l1_Layer_2': 0.00019630856114678083, 'l1_Layer_3': 0.08994302467173926, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 295}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 13.06 | sMAPE for Test Set is: 101.60% | rMAE for Test Set is: 4.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:12:46,674]\u001b[0m Trial 513 finished with value: 2.423574644777806 and parameters: {'n_hidden': 3, 'learning_rate': 0.06474315162183095, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20742849255251555, 'dropout_rate_Layer_2': 0.35756841185097654, 'dropout_rate_Layer_3': 0.18473502437591904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019265408738401038, 'l1_Layer_2': 0.005512930446314767, 'l1_Layer_3': 0.0008671270718491627, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.42 | sMAPE for Validation Set is: 6.25% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 80.59% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:12:47,200]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:47,503]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 98.85% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:12:48,768]\u001b[0m Trial 499 finished with value: 1.9191654084647833 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006157382039588616, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3118581008300595, 'dropout_rate_Layer_2': 0.0014413040021682639, 'dropout_rate_Layer_3': 0.15353543590611865, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002200761107068893, 'l1_Layer_2': 0.0001368463409593952, 'l1_Layer_3': 0.0074663860716930545, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:51,996]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:54,997]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:55,628]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:55,716]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:12:59,860]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:00,980]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:03,769]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:06,015]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:06,204]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:06,515]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:13,044]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:15,523]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:17,502]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:17,548]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:19,832]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:23,259]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:26,872]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:27,945]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:33,056]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:35,474]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:38,799]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:44,619]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:46,696]\u001b[0m Trial 539 finished with value: 3.8364225977093143 and parameters: {'n_hidden': 3, 'learning_rate': 0.08607530311701306, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19390926769967085, 'dropout_rate_Layer_2': 0.3786516067667455, 'dropout_rate_Layer_3': 0.17507924456639046, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.400616285911843e-05, 'l1_Layer_2': 0.002032090967461801, 'l1_Layer_3': 0.00040639103845201824, 'n_units_Layer_1': 60, 'n_units_Layer_2': 125, 'n_units_Layer_3': 100}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 10.01% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 18.86 | sMAPE for Test Set is: 114.94% | rMAE for Test Set is: 6.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:13:49,501]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:50,916]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:54,300]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:13:57,185]\u001b[0m Trial 536 finished with value: 2.419217685738533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029842360328156967, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3093855610514496, 'dropout_rate_Layer_2': 0.2974491144384001, 'dropout_rate_Layer_3': 0.14695818046166764, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.4048721668732497e-05, 'l1_Layer_2': 0.0017435222024237403, 'l1_Layer_3': 9.96093795525886e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.42 | sMAPE for Validation Set is: 6.33% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 16.90 | sMAPE for Test Set is: 111.20% | rMAE for Test Set is: 5.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:13:59,030]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:03,139]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:07,241]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:10,876]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:13,519]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:14,450]\u001b[0m Trial 537 finished with value: 2.40294861641676 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031235686446401366, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30947135208390847, 'dropout_rate_Layer_2': 0.30102525385967105, 'dropout_rate_Layer_3': 0.1728313309876567, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.37743561299091e-05, 'l1_Layer_2': 0.0009425473919303722, 'l1_Layer_3': 6.743541111649632e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.40 | sMAPE for Validation Set is: 6.26% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 16.29 | sMAPE for Test Set is: 109.78% | rMAE for Test Set is: 5.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:14:15,955]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:18,167]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:19,064]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:20,259]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:24,693]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:26,274]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:27,883]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:31,789]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:34,142]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:36,459]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:36,809]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:41,868]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:42,365]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:45,305]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:47,241]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:51,300]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:54,054]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:54,184]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:54,443]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:14:59,783]\u001b[0m Trial 558 finished with value: 2.265261367321902 and parameters: {'n_hidden': 3, 'learning_rate': 0.04691837123175857, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06197318007599641, 'dropout_rate_Layer_2': 0.3279542184834343, 'dropout_rate_Layer_3': 0.17894654991356215, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003692573562872735, 'l1_Layer_2': 0.0075830356594545, 'l1_Layer_3': 0.0008918742724619002, 'n_units_Layer_1': 80, 'n_units_Layer_2': 85, 'n_units_Layer_3': 50}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 5.93% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 9.64 | sMAPE for Test Set is: 92.31% | rMAE for Test Set is: 3.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:15:01,564]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:05,688]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:10,460]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:10,763]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:15,631]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:28,077]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:30,067]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:33,841]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:37,556]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:40,531]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:41,067]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:43,107]\u001b[0m Trial 574 finished with value: 2.0786302511030517 and parameters: {'n_hidden': 3, 'learning_rate': 0.031165433044969455, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030651931773008904, 'dropout_rate_Layer_2': 0.3177116393380555, 'dropout_rate_Layer_3': 0.14427568713795608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5222436714904657e-05, 'l1_Layer_2': 0.011351951904402335, 'l1_Layer_3': 0.00022616236597087965, 'n_units_Layer_1': 75, 'n_units_Layer_2': 90, 'n_units_Layer_3': 55}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.47% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 16.33 | sMAPE for Test Set is: 110.75% | rMAE for Test Set is: 5.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:15:48,357]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:50,116]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:53,551]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:15:58,875]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:01,260]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:05,321]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:07,275]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:08,820]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:11,034]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:11,806]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:16,037]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:18,747]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:20,992]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:24,518]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:26,484]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:29,948]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:32,003]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:37,848]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:39,408]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:43,689]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:43,830]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:44,399]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:48,980]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:50,262]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:53,211]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:16:55,468]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:02,374]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:05,308]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:13,092]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:18,013]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:20,515]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:23,401]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:23,623]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:27,156]\u001b[0m Trial 608 finished with value: 2.0593071130933707 and parameters: {'n_hidden': 3, 'learning_rate': 0.016685299221120553, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0755989664270813, 'dropout_rate_Layer_2': 0.27048368086208435, 'dropout_rate_Layer_3': 0.15132528747773635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.544569177978527e-05, 'l1_Layer_2': 0.029453317946743628, 'l1_Layer_3': 5.352872243171891e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 90, 'n_units_Layer_3': 75}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.83 | sMAPE for Test Set is: 98.94% | rMAE for Test Set is: 3.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:17:30,903]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:34,925]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:35,602]\u001b[0m Trial 582 finished with value: 1.7102283545046542 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010645078924974992, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1716337719495277, 'dropout_rate_Layer_2': 0.2904606105541647, 'dropout_rate_Layer_3': 0.05912428796941967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0356925266532144e-05, 'l1_Layer_2': 0.00032945796070297134, 'l1_Layer_3': 0.002274181440947975, 'n_units_Layer_1': 200, 'n_units_Layer_2': 230, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.71 | sMAPE for Validation Set is: 4.56% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 1.36 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:17:39,806]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:40,320]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:40,592]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:47,834]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:17:57,043]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:18:01,937]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:18:32,350]\u001b[0m Trial 624 finished with value: 1.9634719735861268 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008090911326977865, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3004119082110841, 'dropout_rate_Layer_2': 0.2772778714976479, 'dropout_rate_Layer_3': 0.1329709671285669, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028622248483393693, 'l1_Layer_2': 0.0009464131653184431, 'l1_Layer_3': 0.000614247526959387, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.95 | sMAPE for Test Set is: 84.58% | rMAE for Test Set is: 2.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:18:47,591]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:18:51,818]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:18:55,283]\u001b[0m Trial 625 finished with value: 1.9404154169803671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008002891074773338, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24157994362240742, 'dropout_rate_Layer_2': 0.2607105900089655, 'dropout_rate_Layer_3': 0.1363085773348729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028622706120358107, 'l1_Layer_2': 0.0006082263119298432, 'l1_Layer_3': 0.000625196825638624, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 84.77% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:19:01,373]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:02,269]\u001b[0m Trial 622 finished with value: 2.009293555973628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006590625595981713, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3997644571720061, 'dropout_rate_Layer_2': 0.014785986876473867, 'dropout_rate_Layer_3': 0.13291009572427295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02987791967838508, 'l1_Layer_2': 0.0016159145394118886, 'l1_Layer_3': 0.0005881067581847842, 'n_units_Layer_1': 240, 'n_units_Layer_2': 235, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 10.94 | sMAPE for Test Set is: 95.22% | rMAE for Test Set is: 3.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:19:05,996]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:10,282]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:10,734]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:16,672]\u001b[0m Trial 626 finished with value: 1.960436561405104 and parameters: {'n_hidden': 3, 'learning_rate': 0.000830505683704069, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30375418953718325, 'dropout_rate_Layer_2': 0.275866250719119, 'dropout_rate_Layer_3': 0.13368177798767564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03088380072663013, 'l1_Layer_2': 0.0006049191369434112, 'l1_Layer_3': 0.0005812694057987965, 'n_units_Layer_1': 240, 'n_units_Layer_2': 235, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.94 | sMAPE for Test Set is: 88.63% | rMAE for Test Set is: 2.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:19:30,706]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:32,990]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:36,115]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:36,587]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:44,869]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:51,898]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:19:53,119]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:10,440]\u001b[0m Trial 634 finished with value: 2.0077220451099245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009601846451852903, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3894479693364782, 'dropout_rate_Layer_2': 0.26043722889919696, 'dropout_rate_Layer_3': 0.013442874307172718, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07669490389160806, 'l1_Layer_2': 0.0021148790624610637, 'l1_Layer_3': 0.0003459348598828804, 'n_units_Layer_1': 225, 'n_units_Layer_2': 235, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.23 | sMAPE for Test Set is: 102.33% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:20:15,063]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:31,485]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:34,274]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:38,323]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:42,260]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:55,909]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:20:59,213]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:13,211]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:17,977]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:32,544]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:40,744]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:47,151]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:47,315]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:51,549]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:51,842]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:57,515]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:21:59,113]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:03,382]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:07,853]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:21,873]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:24,103]\u001b[0m Trial 661 finished with value: 2.1195045517365583 and parameters: {'n_hidden': 3, 'learning_rate': 0.028467383222618343, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04743029759443875, 'dropout_rate_Layer_2': 0.27715767521272494, 'dropout_rate_Layer_3': 0.09518603389331026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7543346421472732e-05, 'l1_Layer_2': 0.047650886332278646, 'l1_Layer_3': 0.00012888246442866916, 'n_units_Layer_1': 115, 'n_units_Layer_2': 95, 'n_units_Layer_3': 85}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 5.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.62 | sMAPE for Test Set is: 101.86% | rMAE for Test Set is: 4.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:22:29,900]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:34,517]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:39,364]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:44,506]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:47,140]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:51,253]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:54,628]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:22:58,016]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:02,587]\u001b[0m Trial 642 finished with value: 1.781954068631433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005435703720671473, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25502529615973796, 'dropout_rate_Layer_2': 0.3219009039193261, 'dropout_rate_Layer_3': 0.05148102629660599, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.592603237910156e-05, 'l1_Layer_2': 0.0037023230080800865, 'l1_Layer_3': 0.00032546094562815875, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 280}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.78 | sMAPE for Validation Set is: 4.76% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 5.03 | sMAPE for Test Set is: 69.28% | rMAE for Test Set is: 1.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:23:04,870]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:09,197]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:13,756]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:16,197]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:22,917]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:25,906]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:31,246]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:34,860]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:42,640]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:42,785]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:47,899]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:51,241]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:51,823]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:23:56,172]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:01,266]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:03,013]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:10,792]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:12,091]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:17,269]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:19,443]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:20,655]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:24,166]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:26,962]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:31,217]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:48,808]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:52,599]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:24:55,794]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:01,495]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:05,248]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:08,431]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:13,446]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:16,313]\u001b[0m Trial 699 finished with value: 1.9626409591598442 and parameters: {'n_hidden': 3, 'learning_rate': 0.004854289946168881, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.265835242520805, 'dropout_rate_Layer_2': 0.24144723229349693, 'dropout_rate_Layer_3': 0.01760827727998917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001505144381882943, 'l1_Layer_2': 0.05086156339962465, 'l1_Layer_3': 0.007120089132677192, 'n_units_Layer_1': 100, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 1.40 | sMAPE for Test Set is: 35.08% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:25:17,791]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:20,498]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:20,696]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:25,635]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:25,790]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:26,383]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:33,117]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:33,588]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:35,653]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:38,646]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:40,542]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:43,283]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:46,135]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:48,117]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:50,668]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:54,244]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:25:57,043]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:00,885]\u001b[0m Trial 665 finished with value: 1.8766052652071308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007975533935899451, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27362608424743146, 'dropout_rate_Layer_2': 0.030591261208797085, 'dropout_rate_Layer_3': 0.030233439147646354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0031132515697312717, 'l1_Layer_2': 0.00281378708407807, 'l1_Layer_3': 0.0007260487243621738, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 125}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 95.35% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:26:01,948]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:04,533]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:10,666]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:12,784]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:14,120]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:18,187]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:26,724]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:29,183]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:32,940]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:36,414]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:39,885]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:45,106]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:47,210]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:26:56,466]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:02,055]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:11,354]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:18,210]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:18,722]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:27,811]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:32,803]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:33,406]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:36,428]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:37,169]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:42,210]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:45,773]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:47,563]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:51,351]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:27:54,829]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:10,638]\u001b[0m Trial 750 finished with value: 2.2771082093950983 and parameters: {'n_hidden': 3, 'learning_rate': 0.00352228358944402, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28056737483036154, 'dropout_rate_Layer_2': 0.2635587672541512, 'dropout_rate_Layer_3': 0.19735131798060998, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001280512005513409, 'l1_Layer_2': 0.0012790904293052384, 'l1_Layer_3': 0.0011708432602039963, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 185}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.28 | sMAPE for Validation Set is: 5.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 16.83 | sMAPE for Test Set is: 111.19% | rMAE for Test Set is: 5.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:28:17,551]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:22,625]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:29,787]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:33,474]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:40,541]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:53,874]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:28:59,698]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:04,874]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:13,442]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:13,764]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:20,234]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:25,573]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:32,957]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:29:35,689]\u001b[0m Trial 730 finished with value: 1.890193662030737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008214301205708268, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31748381270388343, 'dropout_rate_Layer_2': 0.0022324339395867997, 'dropout_rate_Layer_3': 0.007066547719227546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005867626707315229, 'l1_Layer_2': 0.0038907661455638703, 'l1_Layer_3': 0.0011748173259579129, 'n_units_Layer_1': 245, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 95.40% | rMAE for Test Set is: 3.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:29:41,669]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:30:01,426]\u001b[0m Trial 765 finished with value: 2.124813650138329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017574069407884192, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21797888947362065, 'dropout_rate_Layer_2': 0.16503449351904825, 'dropout_rate_Layer_3': 0.3250635676581209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012560419553684548, 'l1_Layer_2': 0.023827474951117006, 'l1_Layer_3': 0.00019646757550134176, 'n_units_Layer_1': 190, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 5.64% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.60 | sMAPE for Test Set is: 95.68% | rMAE for Test Set is: 3.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:30:09,475]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:30:26,206]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:30:34,183]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:30:38,136]\u001b[0m Trial 769 finished with value: 2.421356926372819 and parameters: {'n_hidden': 3, 'learning_rate': 0.002705433342981847, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3055391206475178, 'dropout_rate_Layer_2': 0.23901904455192524, 'dropout_rate_Layer_3': 0.19573496193553472, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001834951757056853, 'l1_Layer_2': 0.0009821163220702757, 'l1_Layer_3': 0.0012347992286921954, 'n_units_Layer_1': 220, 'n_units_Layer_2': 290, 'n_units_Layer_3': 185}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.42 | sMAPE for Validation Set is: 6.35% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 17.00 | sMAPE for Test Set is: 111.42% | rMAE for Test Set is: 5.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:30:40,387]\u001b[0m Trial 739 finished with value: 1.8957108574694985 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006793526938672131, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26410942345849764, 'dropout_rate_Layer_2': 0.013266929417898615, 'dropout_rate_Layer_3': 0.030525123587530234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008304409148662293, 'l1_Layer_2': 0.003691219423798279, 'l1_Layer_3': 0.000640440656666712, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 97.82% | rMAE for Test Set is: 3.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:30:45,994]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:30:52,077]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:30:56,820]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:31:07,299]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:31:34,218]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:31:51,165]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:32:00,490]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:32:10,637]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:32:15,837]\u001b[0m Trial 767 finished with value: 1.9147268478031265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007406199388901564, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31415698449962737, 'dropout_rate_Layer_2': 0.01450376336061163, 'dropout_rate_Layer_3': 0.015938207249148722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00541598478528221, 'l1_Layer_2': 0.032963203404621624, 'l1_Layer_3': 0.001452316038346085, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.36 | sMAPE for Test Set is: 99.68% | rMAE for Test Set is: 4.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:32:23,699]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:32:28,157]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:32:45,269]\u001b[0m Trial 785 finished with value: 2.4953540893817525 and parameters: {'n_hidden': 3, 'learning_rate': 0.003171603123808547, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3287530479904405, 'dropout_rate_Layer_2': 0.28309860245687374, 'dropout_rate_Layer_3': 0.18934742218897085, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001173329671337251, 'l1_Layer_2': 0.0005299544017001133, 'l1_Layer_3': 0.0020788937954179494, 'n_units_Layer_1': 220, 'n_units_Layer_2': 280, 'n_units_Layer_3': 180}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.50 | sMAPE for Validation Set is: 6.49% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 18.00 | sMAPE for Test Set is: 113.59% | rMAE for Test Set is: 5.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:34:35,216]\u001b[0m Trial 778 finished with value: 1.8980168929712733 and parameters: {'n_hidden': 3, 'learning_rate': 0.000592755477484539, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33196920960436543, 'dropout_rate_Layer_2': 0.01969849947159002, 'dropout_rate_Layer_3': 0.03824642976468921, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006121154349676666, 'l1_Layer_2': 0.0038153847495472014, 'l1_Layer_3': 0.00011401681614242876, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 99.48% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:34:43,856]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:36:04,492]\u001b[0m Trial 775 finished with value: 1.9391976557186419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006054550007988311, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33608859860886453, 'dropout_rate_Layer_2': 0.013416626186723315, 'dropout_rate_Layer_3': 0.011594066733913208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00634262245355683, 'l1_Layer_2': 0.006021602842095165, 'l1_Layer_3': 0.0010005560566937078, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 99.81% | rMAE for Test Set is: 4.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:36:27,901]\u001b[0m Trial 782 finished with value: 1.9016088506851336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006136462307633006, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2543953211537306, 'dropout_rate_Layer_2': 0.015063980521515438, 'dropout_rate_Layer_3': 0.03288950410455936, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004267604625233317, 'l1_Layer_2': 0.004267319622928621, 'l1_Layer_3': 0.0016317426570495123, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 12.09 | sMAPE for Test Set is: 99.03% | rMAE for Test Set is: 3.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:36:28,155]\u001b[0m Trial 786 finished with value: 1.916915096712734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007107270437825354, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30864762582020466, 'dropout_rate_Layer_2': 0.0026129283751209625, 'dropout_rate_Layer_3': 0.028589868735680576, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005431182160159504, 'l1_Layer_2': 0.005109793623180935, 'l1_Layer_3': 0.0015903503107390184, 'n_units_Layer_1': 255, 'n_units_Layer_2': 150, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.16 | sMAPE for Test Set is: 96.02% | rMAE for Test Set is: 3.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:36:42,062]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:37:20,882]\u001b[0m Trial 788 finished with value: 1.8980239634718086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007217303918216366, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32431187617588897, 'dropout_rate_Layer_2': 0.0004414770712695155, 'dropout_rate_Layer_3': 0.04252979692054984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00556357463563742, 'l1_Layer_2': 0.0037963728671863567, 'l1_Layer_3': 0.0014717834975615724, 'n_units_Layer_1': 285, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.53 | sMAPE for Test Set is: 94.09% | rMAE for Test Set is: 3.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:38:15,826]\u001b[0m Trial 790 finished with value: 1.8905111577124571 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007138643755507366, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.328995444834054, 'dropout_rate_Layer_2': 0.009193370085470672, 'dropout_rate_Layer_3': 0.03354739130862053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005056011537400826, 'l1_Layer_2': 0.006145705129214777, 'l1_Layer_3': 0.0001183619670934161, 'n_units_Layer_1': 300, 'n_units_Layer_2': 150, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 96.09% | rMAE for Test Set is: 3.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:38:31,294]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:38:48,329]\u001b[0m Trial 793 finished with value: 1.9103983436971628 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008033025217913618, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3237106739614932, 'dropout_rate_Layer_2': 0.0008981166284812176, 'dropout_rate_Layer_3': 0.03978636809423642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004359478110794221, 'l1_Layer_2': 0.005731287807243687, 'l1_Layer_3': 0.0014364966859346374, 'n_units_Layer_1': 285, 'n_units_Layer_2': 150, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 91.55% | rMAE for Test Set is: 3.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:38:48,880]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:38:58,885]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:39:26,247]\u001b[0m Trial 797 finished with value: 2.284207020134455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027471287412057853, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29636552082714895, 'dropout_rate_Layer_2': 0.2830648159864282, 'dropout_rate_Layer_3': 0.18296156275676853, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001832632846248718, 'l1_Layer_2': 0.000572926687771485, 'l1_Layer_3': 0.0021739275020045455, 'n_units_Layer_1': 225, 'n_units_Layer_2': 295, 'n_units_Layer_3': 185}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.28 | sMAPE for Validation Set is: 5.97% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 16.37 | sMAPE for Test Set is: 110.08% | rMAE for Test Set is: 5.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:39:36,236]\u001b[0m Trial 799 finished with value: 3.1816974362403543 and parameters: {'n_hidden': 3, 'learning_rate': 0.036249348200370346, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.143049162289332, 'dropout_rate_Layer_2': 0.3544883477174952, 'dropout_rate_Layer_3': 0.07544241084497384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0004274362944053475, 'l1_Layer_2': 0.00014443661236306698, 'l1_Layer_3': 0.0008302324748868318, 'n_units_Layer_1': 50, 'n_units_Layer_2': 165, 'n_units_Layer_3': 300}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.18 | sMAPE for Validation Set is: 8.11% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 14.44 | sMAPE for Test Set is: 138.10% | rMAE for Test Set is: 4.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:39:38,192]\u001b[0m Trial 791 finished with value: 1.9318224078538921 and parameters: {'n_hidden': 3, 'learning_rate': 0.000723564729583816, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3157120241575118, 'dropout_rate_Layer_2': 0.00906308360539887, 'dropout_rate_Layer_3': 0.032394470902588714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00536038880528439, 'l1_Layer_2': 0.004916736293002308, 'l1_Layer_3': 0.0015394767156534665, 'n_units_Layer_1': 285, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 96.99% | rMAE for Test Set is: 3.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:39:42,289]\u001b[0m Trial 796 finished with value: 1.92088327026012 and parameters: {'n_hidden': 3, 'learning_rate': 0.002683491176468899, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07524173403037607, 'dropout_rate_Layer_2': 0.014913861489627145, 'dropout_rate_Layer_3': 0.0474128324492015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00029911341958238554, 'l1_Layer_2': 0.00046433501303229765, 'l1_Layer_3': 0.0031035771179577292, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 4.13 | sMAPE for Test Set is: 63.57% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:39:49,593]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:41:23,222]\u001b[0m Trial 798 finished with value: 1.9174599434943171 and parameters: {'n_hidden': 3, 'learning_rate': 0.000888143484991822, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32259639034390714, 'dropout_rate_Layer_2': 0.01993192251413625, 'dropout_rate_Layer_3': 0.034990888124065575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006044173404074497, 'l1_Layer_2': 0.003954890662508214, 'l1_Layer_3': 0.00010878207628981736, 'n_units_Layer_1': 280, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 99.81% | rMAE for Test Set is: 4.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:41:25,435]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:41:30,325]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:41:37,421]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:41:44,086]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:41:48,469]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:42:05,030]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:42:10,151]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:43:09,493]\u001b[0m Trial 802 finished with value: 1.956063370527058 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008536992674647536, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34076725537020264, 'dropout_rate_Layer_2': 0.02068677262556634, 'dropout_rate_Layer_3': 0.031742963991726644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005300322070894856, 'l1_Layer_2': 0.0039015265596646187, 'l1_Layer_3': 0.0015632179787931177, 'n_units_Layer_1': 290, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.25 | sMAPE for Test Set is: 99.31% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:43:17,119]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:43:22,717]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:43:30,599]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:43:52,821]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:01,931]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:06,631]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:12,223]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:16,713]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:32,462]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:38,354]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:42,715]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:50,366]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:44:50,377]\u001b[0m Trial 806 finished with value: 1.951011793742189 and parameters: {'n_hidden': 3, 'learning_rate': 0.000782223796195977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3428009767779899, 'dropout_rate_Layer_2': 0.011164575791948747, 'dropout_rate_Layer_3': 0.03276802323517466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0052286363215436425, 'l1_Layer_2': 0.004567530690665327, 'l1_Layer_3': 0.001851017598016428, 'n_units_Layer_1': 285, 'n_units_Layer_2': 145, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.62 | sMAPE for Test Set is: 97.37% | rMAE for Test Set is: 3.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:45:18,635]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:45:27,490]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:45:32,702]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:45:36,188]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:45:38,522]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:45:42,972]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:46:18,356]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:46:21,733]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:46:27,368]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:46:30,292]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:46:46,691]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:08,209]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:12,869]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:18,358]\u001b[0m Trial 818 finished with value: 1.931341771422374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007129979742049246, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32646262914434737, 'dropout_rate_Layer_2': 0.030636507140750807, 'dropout_rate_Layer_3': 0.01888096820118888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004581546753136295, 'l1_Layer_2': 0.004588206558479655, 'l1_Layer_3': 0.002162417397794369, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 98.36% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:47:20,365]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:25,692]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:28,056]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:32,743]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:37,691]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:42,353]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:46,905]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:51,619]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:47:59,116]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:48:03,816]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:48:25,399]\u001b[0m Trial 835 finished with value: 1.8798911999146586 and parameters: {'n_hidden': 3, 'learning_rate': 0.000735913917029946, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3200916541103616, 'dropout_rate_Layer_2': 0.006568642185822898, 'dropout_rate_Layer_3': 0.009492208112056335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0040458785501928185, 'l1_Layer_2': 0.0034939455933874555, 'l1_Layer_3': 0.00010206216429518116, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 91.49% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:48:52,701]\u001b[0m Trial 836 finished with value: 1.8901765903813879 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007429154852890083, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32396115891113, 'dropout_rate_Layer_2': 0.007845389559191477, 'dropout_rate_Layer_3': 0.008569974592048578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0039778765705862805, 'l1_Layer_2': 0.005523214424061698, 'l1_Layer_3': 0.00014199699102698658, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 94.80% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:49:04,839]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:49:40,909]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:49:47,999]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:49:51,413]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:49:53,615]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:50:15,451]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:50:18,811]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:50:27,085]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:50:36,291]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:50:56,292]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:04,297]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:06,697]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:10,977]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:16,275]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:45,150]\u001b[0m Trial 849 finished with value: 1.9463884549433959 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008492539431386962, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32247870431654396, 'dropout_rate_Layer_2': 0.019568209036354707, 'dropout_rate_Layer_3': 0.0323959237425957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027124527207011287, 'l1_Layer_2': 0.007054060801682559, 'l1_Layer_3': 0.0012346507628116007, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 99.41% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:51:49,106]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:52,914]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:51:59,576]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:52:04,079]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:52:38,470]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:52:44,184]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:00,168]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:14,624]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:29,229]\u001b[0m Trial 870 finished with value: 1.7025419802417077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007458816239394869, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16863340956059536, 'dropout_rate_Layer_2': 0.2800821068006145, 'dropout_rate_Layer_3': 0.034996899773741125, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.841159155144866e-05, 'l1_Layer_2': 0.0021648118320659973, 'l1_Layer_3': 3.3288960651617415e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.70 | sMAPE for Validation Set is: 4.55% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 1.91 | sMAPE for Test Set is: 35.19% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:53:41,589]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:45,866]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:46,023]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:53,306]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:53:58,100]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:02,690]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:07,773]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:11,066]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.45 | sMAPE for Validation Set is: 6.48% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 16.44 | sMAPE for Test Set is: 110.33% | rMAE for Test Set is: 5.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:54:26,547]\u001b[0m Trial 881 finished with value: 2.4546454809409055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038365613785939783, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3402544276695859, 'dropout_rate_Layer_2': 0.26332908103300695, 'dropout_rate_Layer_3': 0.20811509982256998, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00024946460534956406, 'l1_Layer_2': 0.0004636522291817187, 'l1_Layer_3': 0.00013231846789427132, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:34,255]\u001b[0m Trial 882 finished with value: 2.37993238340765 and parameters: {'n_hidden': 3, 'learning_rate': 0.00324806216635658, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37375026606004264, 'dropout_rate_Layer_2': 0.2623795121264494, 'dropout_rate_Layer_3': 0.2036934149854157, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00023743623590479374, 'l1_Layer_2': 0.0013346573225252762, 'l1_Layer_3': 7.395066659151167e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 285, 'n_units_Layer_3': 190}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.38 | sMAPE for Validation Set is: 6.28% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 15.66 | sMAPE for Test Set is: 108.36% | rMAE for Test Set is: 5.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:54:38,485]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:43,101]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:49,406]\u001b[0m Trial 884 finished with value: 2.0860118540616455 and parameters: {'n_hidden': 3, 'learning_rate': 0.01526376885806656, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11780769046040471, 'dropout_rate_Layer_2': 0.3026367800257039, 'dropout_rate_Layer_3': 0.06635356302287632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3046748629745993e-05, 'l1_Layer_2': 0.018263546475193695, 'l1_Layer_3': 1.7803188751657556e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 12.80 | sMAPE for Test Set is: 101.26% | rMAE for Test Set is: 4.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:54:50,060]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:51,054]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:54:57,397]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:33,881]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:37,361]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:40,477]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:45,231]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:49,834]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:53,600]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:56:58,218]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:57:12,488]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.01 | sMAPE for Test Set is: 95.78% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:57:21,086]\u001b[0m Trial 889 finished with value: 1.8957208059264736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006011074380977269, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3264653363912776, 'dropout_rate_Layer_2': 0.0080190879092907, 'dropout_rate_Layer_3': 0.013985332199365656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037232804226310966, 'l1_Layer_2': 0.00448474845255086, 'l1_Layer_3': 7.194710682689956e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:57:33,082]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 20:57:53,275]\u001b[0m Trial 901 finished with value: 2.359641201278573 and parameters: {'n_hidden': 3, 'learning_rate': 0.004713469496033637, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34446018770110715, 'dropout_rate_Layer_2': 0.24152495034587212, 'dropout_rate_Layer_3': 0.21238179844395752, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002174693837411219, 'l1_Layer_2': 0.00027601587359438607, 'l1_Layer_3': 5.6879795983072554e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.36 | sMAPE for Validation Set is: 6.12% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 16.77 | sMAPE for Test Set is: 110.59% | rMAE for Test Set is: 5.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:58:58,782]\u001b[0m Trial 902 finished with value: 1.9715184070544536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022677666689433916, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0873969900283171, 'dropout_rate_Layer_2': 0.04035453050716695, 'dropout_rate_Layer_3': 0.020767939432553135, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0004856073572913748, 'l1_Layer_2': 0.000581410892587179, 'l1_Layer_3': 0.013835374312673706, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.84 | sMAPE for Test Set is: 105.91% | rMAE for Test Set is: 4.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:59:24,939]\u001b[0m Trial 903 finished with value: 2.1997605125864124 and parameters: {'n_hidden': 3, 'learning_rate': 0.01409449203314141, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11114477892771298, 'dropout_rate_Layer_2': 0.30822153956547155, 'dropout_rate_Layer_3': 0.030928830340752028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9439983627938354e-05, 'l1_Layer_2': 0.018687184924414044, 'l1_Layer_3': 1.727962451413283e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 5.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 99.14% | rMAE for Test Set is: 3.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 20:59:34,188]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:00:47,277]\u001b[0m Trial 899 finished with value: 1.9467515936732516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008632635746731973, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33558110296966004, 'dropout_rate_Layer_2': 0.03476311636496679, 'dropout_rate_Layer_3': 0.014111544682602064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006520869809887734, 'l1_Layer_2': 0.006112411991437047, 'l1_Layer_3': 0.002509111547165931, 'n_units_Layer_1': 285, 'n_units_Layer_2': 145, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.05% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.29 | sMAPE for Test Set is: 102.07% | rMAE for Test Set is: 4.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:01:13,326]\u001b[0m Trial 906 finished with value: 1.8648871625690708 and parameters: {'n_hidden': 3, 'learning_rate': 0.009239835080355807, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03994221112582633, 'dropout_rate_Layer_2': 0.19422453009285537, 'dropout_rate_Layer_3': 0.06181642589754763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.017695614767065e-05, 'l1_Layer_2': 0.004204360295710161, 'l1_Layer_3': 1.5769339916571576e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.23 | sMAPE for Test Set is: 102.47% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:01:18,984]\u001b[0m Trial 891 finished with value: 1.909147654032574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005926044046245585, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3044362850573599, 'dropout_rate_Layer_2': 0.00014401626213554966, 'dropout_rate_Layer_3': 0.011628477703098616, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008082522772859353, 'l1_Layer_2': 0.007922664081337738, 'l1_Layer_3': 0.001137924944880277, 'n_units_Layer_1': 285, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 97.56% | rMAE for Test Set is: 3.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:01:25,687]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:01:52,933]\u001b[0m Trial 896 finished with value: 1.947330630025384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007346074973758316, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35402787621745874, 'dropout_rate_Layer_2': 0.012405449362241552, 'dropout_rate_Layer_3': 0.023353654361131668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006066425183755301, 'l1_Layer_2': 0.0047414853923269966, 'l1_Layer_3': 0.0020125052107763898, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.06 | sMAPE for Test Set is: 101.45% | rMAE for Test Set is: 4.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:01:59,852]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:02:01,883]\u001b[0m Trial 905 finished with value: 1.8894226604511395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005881561131315167, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3505055352408685, 'dropout_rate_Layer_2': 0.014473358354196013, 'dropout_rate_Layer_3': 0.014133173868442952, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029167833006935105, 'l1_Layer_2': 0.011140461555682435, 'l1_Layer_3': 7.081974863748176e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.92 | sMAPE for Test Set is: 95.40% | rMAE for Test Set is: 3.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:02:09,981]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:01,059]\u001b[0m Trial 913 finished with value: 1.9609057659454627 and parameters: {'n_hidden': 3, 'learning_rate': 0.004752067730029294, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17474204437207874, 'dropout_rate_Layer_2': 0.22615741465348535, 'dropout_rate_Layer_3': 0.00535586933135257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010968386928203944, 'l1_Layer_2': 0.001964611558296731, 'l1_Layer_3': 1.3778629739302227e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 3.73 | sMAPE for Test Set is: 58.49% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:03:05,496]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:06,064]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:17,694]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:21,530]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:26,919]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:31,054]\u001b[0m Trial 916 finished with value: 2.149733498864556 and parameters: {'n_hidden': 3, 'learning_rate': 0.004098185509221855, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3518627575025492, 'dropout_rate_Layer_2': 0.21442746101405236, 'dropout_rate_Layer_3': 0.028114351449624878, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00032563023363357785, 'l1_Layer_2': 0.0002684341466532482, 'l1_Layer_3': 4.965686757519432e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 5.56% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 16.54 | sMAPE for Test Set is: 109.74% | rMAE for Test Set is: 5.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:03:37,124]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:41,566]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:48,369]\u001b[0m Trial 917 finished with value: 2.18664718820618 and parameters: {'n_hidden': 3, 'learning_rate': 0.004151001274332161, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.357668325202449, 'dropout_rate_Layer_2': 0.2183365532651245, 'dropout_rate_Layer_3': 0.20709176507270904, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00020324406478819854, 'l1_Layer_2': 0.00047120812246000793, 'l1_Layer_3': 3.049418644489831e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.19 | sMAPE for Validation Set is: 5.68% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 16.47 | sMAPE for Test Set is: 109.75% | rMAE for Test Set is: 5.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:03:54,005]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:03:57,639]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:10,518]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:15,199]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:19,742]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:21,531]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:26,925]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:33,121]\u001b[0m Trial 925 finished with value: 2.2632945726526073 and parameters: {'n_hidden': 3, 'learning_rate': 0.003602175148954511, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3707617388441251, 'dropout_rate_Layer_2': 0.20788379683946756, 'dropout_rate_Layer_3': 0.0253563757849365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00022819069860703935, 'l1_Layer_2': 0.0002783855775866293, 'l1_Layer_3': 5.863522403295478e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 285, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.26 | sMAPE for Validation Set is: 5.98% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 14.88 | sMAPE for Test Set is: 105.91% | rMAE for Test Set is: 4.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:04:37,294]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:04:59,235]\u001b[0m Trial 928 finished with value: 1.9494028022968573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076948411880332825, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2433266604980446, 'dropout_rate_Layer_2': 0.1941133075790911, 'dropout_rate_Layer_3': 0.056540791208715385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010745712746689024, 'l1_Layer_2': 0.004260904513508125, 'l1_Layer_3': 1.6667323903656214e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 165, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 98.01% | rMAE for Test Set is: 3.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:05:14,391]\u001b[0m Trial 933 finished with value: 2.312245421001143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034031013342284686, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3518708222065996, 'dropout_rate_Layer_2': 0.21444715192314523, 'dropout_rate_Layer_3': 0.207741968756858, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00032450348724618163, 'l1_Layer_2': 0.00022575290048968628, 'l1_Layer_3': 2.418011951997631e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.31 | sMAPE for Validation Set is: 6.01% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 15.88 | sMAPE for Test Set is: 108.58% | rMAE for Test Set is: 5.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:05:16,649]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:05:24,521]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:05:35,395]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:05:42,127]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:05:44,360]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:05:44,486]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:05:52,623]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:09,895]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:13,619]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:15,391]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:18,862]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:22,518]\u001b[0m Trial 938 finished with value: 2.0586266197350214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009729853129007977, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31914296656431945, 'dropout_rate_Layer_2': 0.01728635395970242, 'dropout_rate_Layer_3': 0.00995255901282495, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00043286449942412855, 'l1_Layer_2': 0.0002226499700698231, 'l1_Layer_3': 0.006864095168612082, 'n_units_Layer_1': 245, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.36 | sMAPE for Test Set is: 107.22% | rMAE for Test Set is: 5.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:06:35,237]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:38,089]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:06:42,974]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:07:04,333]\u001b[0m Trial 930 finished with value: 1.9094408478017624 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006497074009383917, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.324575550180204, 'dropout_rate_Layer_2': 0.024013013440483122, 'dropout_rate_Layer_3': 0.02224125475292739, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00485511111902714, 'l1_Layer_2': 0.0046780507037685855, 'l1_Layer_3': 7.713193213442658e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.20 | sMAPE for Test Set is: 96.24% | rMAE for Test Set is: 3.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:07:28,256]\u001b[0m Trial 948 finished with value: 2.2023477707228847 and parameters: {'n_hidden': 3, 'learning_rate': 0.003618821880302414, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35341547322826516, 'dropout_rate_Layer_2': 0.20516359730118605, 'dropout_rate_Layer_3': 0.03966837277465869, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00027160438779538245, 'l1_Layer_2': 0.00040821094365223057, 'l1_Layer_3': 2.5145530700336924e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 15.61 | sMAPE for Test Set is: 107.43% | rMAE for Test Set is: 5.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:07:33,003]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:07:37,049]\u001b[0m Trial 950 finished with value: 1.9316135406494137 and parameters: {'n_hidden': 3, 'learning_rate': 0.008916814377779785, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23315060761576598, 'dropout_rate_Layer_2': 0.1886547572813831, 'dropout_rate_Layer_3': 0.061511295541876676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.731803312553245e-05, 'l1_Layer_2': 0.003932261361019305, 'l1_Layer_3': 1.5133149443700455e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.34 | sMAPE for Test Set is: 93.33% | rMAE for Test Set is: 3.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:07:37,541]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:07:42,849]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:07:45,248]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:07:52,218]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:07:54,137]\u001b[0m Trial 954 finished with value: 2.082459266856174 and parameters: {'n_hidden': 3, 'learning_rate': 0.00884719710059256, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2191704374102723, 'dropout_rate_Layer_2': 0.15368940426170039, 'dropout_rate_Layer_3': 0.030675864109828033, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.5043662514934164e-05, 'l1_Layer_2': 0.004644392556500386, 'l1_Layer_3': 1.4953696961289863e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.42 | sMAPE for Test Set is: 89.10% | rMAE for Test Set is: 3.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:08:01,208]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:08:30,518]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:08:53,127]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:09:17,158]\u001b[0m Trial 961 finished with value: 2.2069795184872447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028676855919588366, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3586768282208781, 'dropout_rate_Layer_2': 0.19915948727364702, 'dropout_rate_Layer_3': 0.0402266134271561, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015714786444736284, 'l1_Layer_2': 0.00030029090128486167, 'l1_Layer_3': 1.4562002149076194e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 230}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.21 | sMAPE for Validation Set is: 5.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 16.21 | sMAPE for Test Set is: 109.59% | rMAE for Test Set is: 5.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:09:33,294]\u001b[0m Trial 944 finished with value: 1.9420461081392937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005517921728086303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3379369353886541, 'dropout_rate_Layer_2': 0.02448509092612917, 'dropout_rate_Layer_3': 0.010903142454688916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006340685357094183, 'l1_Layer_2': 0.008065717231152786, 'l1_Layer_3': 0.0019119134013230552, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 90}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.11 | sMAPE for Test Set is: 95.85% | rMAE for Test Set is: 3.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:09:40,506]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:09:45,111]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 94.74% | rMAE for Test Set is: 3.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:09:51,632]\u001b[0m Trial 958 finished with value: 1.9039589916261213 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005903393412180791, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31773524984929596, 'dropout_rate_Layer_2': 0.007878628491971516, 'dropout_rate_Layer_3': 0.013821443316926918, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006390721359411636, 'l1_Layer_2': 0.0058262844709102745, 'l1_Layer_3': 8.05915557595729e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 165, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:09:53,368]\u001b[0m Trial 959 finished with value: 1.883125945283048 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005889722567849119, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.318957648125591, 'dropout_rate_Layer_2': 0.040271144545611814, 'dropout_rate_Layer_3': 0.014250766109157797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006272797463048974, 'l1_Layer_2': 0.005406468391569419, 'l1_Layer_3': 8.240688921009024e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 165, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.82 | sMAPE for Test Set is: 95.20% | rMAE for Test Set is: 3.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:09:56,451]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:10:01,941]\u001b[0m Trial 965 finished with value: 2.0214075805532645 and parameters: {'n_hidden': 3, 'learning_rate': 0.010947475317249607, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10640029548631427, 'dropout_rate_Layer_2': 0.03835215147260869, 'dropout_rate_Layer_3': 7.582717839689848e-05, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002234623796935968, 'l1_Layer_2': 0.00012863312075629707, 'l1_Layer_3': 0.008837202044466952, 'n_units_Layer_1': 120, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.23 | sMAPE for Test Set is: 104.34% | rMAE for Test Set is: 4.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:10:16,468]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:10:33,851]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:10:39,068]\u001b[0m Trial 970 finished with value: 2.281785106845408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029422966761043206, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36671206623825314, 'dropout_rate_Layer_2': 0.22701804091829056, 'dropout_rate_Layer_3': 0.04898352112516844, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019594285814805492, 'l1_Layer_2': 0.0003523845307074463, 'l1_Layer_3': 3.914631992462615e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 290, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.28 | sMAPE for Validation Set is: 5.94% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 16.00 | sMAPE for Test Set is: 109.26% | rMAE for Test Set is: 5.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:10:39,292]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:10:57,080]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:11:44,386]\u001b[0m Trial 968 finished with value: 1.8783698130097912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005529730004488828, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3133030594823399, 'dropout_rate_Layer_2': 0.007853186955937324, 'dropout_rate_Layer_3': 0.006201279771035078, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007871665986656472, 'l1_Layer_2': 0.008280680243221164, 'l1_Layer_3': 6.758324839982102e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.29 | sMAPE for Test Set is: 93.36% | rMAE for Test Set is: 3.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:11:45,064]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:12:26,074]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:12:31,442]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:12:34,635]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:13:34,989]\u001b[0m Trial 976 finished with value: 1.926209179009805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006173266176427933, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3183100099855302, 'dropout_rate_Layer_2': 0.015332858205655699, 'dropout_rate_Layer_3': 0.01860133709081537, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005248057577100853, 'l1_Layer_2': 0.002674428940886261, 'l1_Layer_3': 9.137600881804356e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.04 | sMAPE for Test Set is: 92.66% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:14:16,362]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:14:22,149]\u001b[0m Trial 974 finished with value: 1.8999488812363126 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005632897912944448, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3164010151695998, 'dropout_rate_Layer_2': 0.025058128921339032, 'dropout_rate_Layer_3': 0.015880402821906437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004680741508322914, 'l1_Layer_2': 0.005308816065078594, 'l1_Layer_3': 8.436838603092492e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 98.14% | rMAE for Test Set is: 3.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:14:25,248]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:14:25,818]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:14:33,388]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:14:53,721]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:14:58,030]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:15:13,565]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:15:53,093]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:09,855]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:15,807]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:17,040]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:23,980]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:27,768]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:29,554]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:30,850]\u001b[0m Trial 992 finished with value: 3.356926490385883 and parameters: {'n_hidden': 3, 'learning_rate': 0.009568701100878502, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19103642583691047, 'dropout_rate_Layer_2': 0.19884164139145238, 'dropout_rate_Layer_3': 0.11613477704564773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019849595197031906, 'l1_Layer_2': 0.0038076148168161923, 'l1_Layer_3': 6.763456448294723e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 205, 'n_units_Layer_3': 160}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.36 | sMAPE for Validation Set is: 8.42% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 19.68 | sMAPE for Test Set is: 117.29% | rMAE for Test Set is: 6.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:16:34,538]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:37,196]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:37,723]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:44,008]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:55,259]\u001b[0m Trial 997 finished with value: 2.1816158226570828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0067436569649870735, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2306050216481416, 'dropout_rate_Layer_2': 0.22775308634506775, 'dropout_rate_Layer_3': 0.010587775981675734, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4508621499788493e-05, 'l1_Layer_2': 0.0017054604231620018, 'l1_Layer_3': 1.3023048982756228e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 115}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:16:55,381]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.18 | sMAPE for Validation Set is: 5.78% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 13.86 | sMAPE for Test Set is: 104.03% | rMAE for Test Set is: 4.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:17:01,663]\u001b[0m Trial 989 finished with value: 1.991408427112373 and parameters: {'n_hidden': 3, 'learning_rate': 0.002818230209311032, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38880175384275883, 'dropout_rate_Layer_2': 0.19899780850916068, 'dropout_rate_Layer_3': 0.03979342348640706, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021934652809460958, 'l1_Layer_2': 0.0003262235255456777, 'l1_Layer_3': 4.1039120744360946e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.83 | sMAPE for Test Set is: 108.34% | rMAE for Test Set is: 5.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:17:02,928]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:17:07,468]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:17:41,496]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:18:17,733]\u001b[0m Trial 1006 finished with value: 2.0032634322114937 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028743669804737327, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39344848131373955, 'dropout_rate_Layer_2': 0.19706098647869033, 'dropout_rate_Layer_3': 0.03323878578976082, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023698320239485984, 'l1_Layer_2': 0.00031907658849532106, 'l1_Layer_3': 5.3821306796438554e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 300, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.97 | sMAPE for Test Set is: 106.51% | rMAE for Test Set is: 4.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:18:25,332]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:18:39,661]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:18:53,483]\u001b[0m Trial 1001 finished with value: 1.900933246452715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005935624153123628, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3135716095737765, 'dropout_rate_Layer_2': 0.009653662702675677, 'dropout_rate_Layer_3': 0.007145728360667788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009285539176904854, 'l1_Layer_2': 0.0035827135004214724, 'l1_Layer_3': 0.00013555069123933524, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 125}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.90 | sMAPE for Validation Set is: 4.97% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.63 | sMAPE for Test Set is: 94.69% | rMAE for Test Set is: 3.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:18:58,261]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:19:02,786]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:19:30,611]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:19:35,647]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:19:41,266]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:20:02,870]\u001b[0m Trial 1000 finished with value: 1.8892436536685935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005033524760362506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3108843114228539, 'dropout_rate_Layer_2': 0.030243906988128275, 'dropout_rate_Layer_3': 0.03259244468027871, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003111376800137576, 'l1_Layer_2': 0.006249929279339538, 'l1_Layer_3': 7.101349006783305e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.85 | sMAPE for Test Set is: 95.13% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:20:07,635]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:20:22,225]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:20:32,060]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:20:46,936]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:21:00,594]\u001b[0m Trial 1018 finished with value: 1.9616827845617824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024966571563510118, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39312663130975045, 'dropout_rate_Layer_2': 0.20425487936963166, 'dropout_rate_Layer_3': 0.04024896290181893, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002049739573863173, 'l1_Layer_2': 0.00035308466285084554, 'l1_Layer_3': 4.580675437739539e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.86 | sMAPE for Test Set is: 106.05% | rMAE for Test Set is: 4.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:21:11,889]\u001b[0m Trial 1009 finished with value: 1.8780648701683766 and parameters: {'n_hidden': 3, 'learning_rate': 0.000505435496119924, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3092848045285033, 'dropout_rate_Layer_2': 0.016244687403993176, 'dropout_rate_Layer_3': 0.007977549132776478, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004396573919261454, 'l1_Layer_2': 0.00546625295883474, 'l1_Layer_3': 7.490265290066196e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.91 | sMAPE for Test Set is: 91.95% | rMAE for Test Set is: 3.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:21:18,257]\u001b[0m Trial 1021 finished with value: 2.26994458409883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0043276281769299004, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1713502400853099, 'dropout_rate_Layer_2': 0.18602443897457036, 'dropout_rate_Layer_3': 0.027507155332087828, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0329927848632579e-05, 'l1_Layer_2': 0.0008728384559247702, 'l1_Layer_3': 1.0810381123578187e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 200}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.27 | sMAPE for Validation Set is: 5.95% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 11.18 | sMAPE for Test Set is: 95.48% | rMAE for Test Set is: 3.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:21:21,325]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:21:25,164]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:21:30,872]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:21:42,352]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:21:49,574]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:22:03,757]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:22:16,361]\u001b[0m Trial 1026 finished with value: 1.8607718238883848 and parameters: {'n_hidden': 3, 'learning_rate': 0.002229823027659455, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39372842046039974, 'dropout_rate_Layer_2': 0.1853466494915409, 'dropout_rate_Layer_3': 0.04509269190750827, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026169722365088945, 'l1_Layer_2': 0.00021516081841348232, 'l1_Layer_3': 5.1269851177423154e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.22 | sMAPE for Test Set is: 104.49% | rMAE for Test Set is: 4.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:22:21,201]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:22:24,463]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:22:25,299]\u001b[0m Trial 1010 finished with value: 1.910719559854191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005379630398102536, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3088645439115671, 'dropout_rate_Layer_2': 0.02613631253731096, 'dropout_rate_Layer_3': 0.008167413314001618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009423952369288165, 'l1_Layer_2': 0.0032730473667476664, 'l1_Layer_3': 0.00016500410857332455, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.46 | sMAPE for Test Set is: 97.05% | rMAE for Test Set is: 3.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:22:33,747]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:22:44,039]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:23:11,357]\u001b[0m Trial 1023 finished with value: 1.890245064294982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005121301389411328, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2995056305377645, 'dropout_rate_Layer_2': 0.025527798690720624, 'dropout_rate_Layer_3': 0.006896357468211816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003952827314925461, 'l1_Layer_2': 0.007735341754693176, 'l1_Layer_3': 7.384956615391989e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 91.33% | rMAE for Test Set is: 3.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:23:19,106]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:23:34,157]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:23:49,594]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:24:16,014]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:24:54,040]\u001b[0m Trial 1032 finished with value: 1.8892088908278966 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005691241005778856, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29925439957576655, 'dropout_rate_Layer_2': 0.03819070172804698, 'dropout_rate_Layer_3': 0.005262613851264301, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009079907789782739, 'l1_Layer_2': 0.009767807809426954, 'l1_Layer_3': 0.0001923540367340994, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 130}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.37 | sMAPE for Test Set is: 96.67% | rMAE for Test Set is: 3.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:24:57,955]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:25:17,383]\u001b[0m Trial 1035 finished with value: 1.911406963515326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005564945694890855, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29874151171556285, 'dropout_rate_Layer_2': 0.033684895392902814, 'dropout_rate_Layer_3': 0.007193670428892151, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010288253385165423, 'l1_Layer_2': 0.010252535195115193, 'l1_Layer_3': 0.0001526666509584923, 'n_units_Layer_1': 270, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.72 | sMAPE for Test Set is: 100.92% | rMAE for Test Set is: 4.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:25:28,705]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:25:38,264]\u001b[0m Trial 1039 finished with value: 1.880706273315117 and parameters: {'n_hidden': 3, 'learning_rate': 0.000510276039111923, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31562052347343755, 'dropout_rate_Layer_2': 0.04261194877064106, 'dropout_rate_Layer_3': 0.00010553181247491532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00819334051838016, 'l1_Layer_2': 0.00804175227700264, 'l1_Layer_3': 4.4462186626902e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.04 | sMAPE for Test Set is: 92.41% | rMAE for Test Set is: 3.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:25:44,150]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:25:53,324]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:25:57,186]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:26:23,293]\u001b[0m Trial 1047 finished with value: 1.964603657349528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017795065793722083, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3998696671200484, 'dropout_rate_Layer_2': 0.20770925759205672, 'dropout_rate_Layer_3': 0.039155343995689276, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003682102566033626, 'l1_Layer_2': 0.0002977073460665565, 'l1_Layer_3': 4.959199065952383e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 235}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.09% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.76 | sMAPE for Test Set is: 100.62% | rMAE for Test Set is: 4.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:26:49,734]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:27:05,155]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:27:33,945]\u001b[0m Trial 1042 finished with value: 1.8713138628982742 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005066712950259742, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047993020073438336, 'dropout_rate_Layer_2': 0.04229230915623449, 'dropout_rate_Layer_3': 0.0006537572725058369, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007911573217061974, 'l1_Layer_2': 0.011714588957735238, 'l1_Layer_3': 0.00019846628646596798, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 135}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 88.38% | rMAE for Test Set is: 2.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:27:38,906]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:27:48,752]\u001b[0m Trial 1051 finished with value: 1.9998838708121018 and parameters: {'n_hidden': 3, 'learning_rate': 0.002829427776080348, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38184270319749525, 'dropout_rate_Layer_2': 0.19515555803766577, 'dropout_rate_Layer_3': 0.049673684436407246, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031900452708550676, 'l1_Layer_2': 0.00021391529586432343, 'l1_Layer_3': 6.34935238671355e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.83 | sMAPE for Test Set is: 105.91% | rMAE for Test Set is: 4.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:28:31,652]\u001b[0m Trial 1048 finished with value: 1.936012763262239 and parameters: {'n_hidden': 3, 'learning_rate': 0.001081749555240416, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1882115070405249, 'dropout_rate_Layer_2': 0.16792385156768697, 'dropout_rate_Layer_3': 0.1370994313496944, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000297993209500142, 'l1_Layer_2': 0.0002116475866191078, 'l1_Layer_3': 0.00030312696090830716, 'n_units_Layer_1': 275, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 1.84 | sMAPE for Test Set is: 57.28% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:28:51,810]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:28:57,456]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:28:59,515]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:29:05,695]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:29:17,370]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:29:21,486]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:29:25,257]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:29:39,646]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:29:47,516]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:30:04,735]\u001b[0m Trial 1061 finished with value: 1.911036037022397 and parameters: {'n_hidden': 3, 'learning_rate': 0.001489429349110579, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36847231464151275, 'dropout_rate_Layer_2': 0.22362285778994273, 'dropout_rate_Layer_3': 0.05734344707413677, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005712131849871095, 'l1_Layer_2': 0.0003454860851858309, 'l1_Layer_3': 4.40871026090298e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.91 | sMAPE for Validation Set is: 4.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.00 | sMAPE for Test Set is: 101.43% | rMAE for Test Set is: 4.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:30:41,079]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:30:55,335]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:11,165]\u001b[0m Trial 1053 finished with value: 1.8757847528528682 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005863630798214506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.049019055513057685, 'dropout_rate_Layer_2': 0.04416901807027348, 'dropout_rate_Layer_3': 0.011912546102702676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010657701907337978, 'l1_Layer_2': 0.00841035034481889, 'l1_Layer_3': 0.00021043560953076283, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 225}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 92.44% | rMAE for Test Set is: 3.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:31:13,862]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:17,833]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:23,432]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:31,378]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:31,776]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:36,567]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:31:42,013]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:32:14,502]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:32:21,832]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:33:31,965]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:33:36,959]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:33:51,750]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:34:00,763]\u001b[0m Trial 1064 finished with value: 1.8615791690815764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005459175163143916, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07252244478795668, 'dropout_rate_Layer_2': 0.05050445660027278, 'dropout_rate_Layer_3': 0.008121240761305997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006682823529208525, 'l1_Layer_2': 0.007694153371962875, 'l1_Layer_3': 0.00012189024776290577, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 11.03 | sMAPE for Test Set is: 95.72% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:34:14,368]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:34:26,199]\u001b[0m Trial 1073 finished with value: 1.857608353998408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006132608321821741, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02144104428303833, 'dropout_rate_Layer_2': 0.041900170365693046, 'dropout_rate_Layer_3': 0.0069765765560610565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009753262871409391, 'l1_Layer_2': 0.011487649263732627, 'l1_Layer_3': 0.0002388875653476014, 'n_units_Layer_1': 295, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 88.14% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:34:29,873]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:34:33,372]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:34:35,616]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:34:41,658]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:34:50,325]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:00,407]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:00,422]\u001b[0m Trial 1081 finished with value: 1.9214443013388347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024414856878311234, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3907781894340126, 'dropout_rate_Layer_2': 0.19800439174564133, 'dropout_rate_Layer_3': 0.05302356164900084, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000495746633782832, 'l1_Layer_2': 0.00038157919986192725, 'l1_Layer_3': 4.215121367161665e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.59 | sMAPE for Test Set is: 107.74% | rMAE for Test Set is: 5.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:35:11,065]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:11,936]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:20,934]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:28,791]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:45,983]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:35:46,005]\u001b[0m Trial 1086 finished with value: 1.8798406908898382 and parameters: {'n_hidden': 3, 'learning_rate': 0.002358598952411957, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.381802626002139, 'dropout_rate_Layer_2': 0.20019720797572632, 'dropout_rate_Layer_3': 0.054486056294277226, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044642918648988585, 'l1_Layer_2': 0.00039182277207581875, 'l1_Layer_3': 4.437608607397458e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.65 | sMAPE for Test Set is: 107.94% | rMAE for Test Set is: 5.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:35:56,394]\u001b[0m Trial 1096 finished with value: 6.19779445255713 and parameters: {'n_hidden': 4, 'learning_rate': 0.00931977959909301, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047800758118367204, 'dropout_rate_Layer_2': 0.3813065011157698, 'dropout_rate_Layer_3': 0.1755133630941996, 'dropout_rate_Layer_4': 0.3890993325599922, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.878564521163882e-05, 'l1_Layer_2': 0.0010232978843802846, 'l1_Layer_3': 0.001560324128544816, 'l1_Layer_4': 1.1505411738188473e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280, 'n_units_Layer_4': 135}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 15.93% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 27.08 | sMAPE for Test Set is: 129.38% | rMAE for Test Set is: 8.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:36:30,946]\u001b[0m Trial 1095 finished with value: 1.9548093799417023 and parameters: {'n_hidden': 3, 'learning_rate': 0.00225853207806452, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38905569248346306, 'dropout_rate_Layer_2': 0.21314263978705467, 'dropout_rate_Layer_3': 0.05772837981837497, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047146080197274124, 'l1_Layer_2': 0.00042368833331047544, 'l1_Layer_3': 3.3632553154999e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 265}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.76 | sMAPE for Test Set is: 106.03% | rMAE for Test Set is: 4.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:36:47,494]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:36:54,679]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:36:59,300]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:37:20,173]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:37:34,873]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:37:48,590]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:37:50,018]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:37:51,346]\u001b[0m Trial 1093 finished with value: 1.890497965990276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005677672854835754, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07174144921539057, 'dropout_rate_Layer_2': 0.03730042170285075, 'dropout_rate_Layer_3': 0.00113849452338445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005828993238581064, 'l1_Layer_2': 0.009980220547701023, 'l1_Layer_3': 0.000218688770928287, 'n_units_Layer_1': 300, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.89 | sMAPE for Validation Set is: 4.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 92.23% | rMAE for Test Set is: 3.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:38:02,720]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:38:08,126]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:38:15,947]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:38:25,645]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:38:36,365]\u001b[0m Trial 1094 finished with value: 1.856308327298369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005503564862783468, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021851901503895557, 'dropout_rate_Layer_2': 0.047369335972928014, 'dropout_rate_Layer_3': 0.02031022444890492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005964934930048882, 'l1_Layer_2': 0.009391652101963324, 'l1_Layer_3': 0.00018146309980773335, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.81 | sMAPE for Test Set is: 88.15% | rMAE for Test Set is: 2.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:38:46,228]\u001b[0m Trial 1109 finished with value: 1.8611721593441246 and parameters: {'n_hidden': 3, 'learning_rate': 0.00913419400042721, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21559382823337425, 'dropout_rate_Layer_2': 0.16589998220662505, 'dropout_rate_Layer_3': 0.02814855381666452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.231772777387988e-05, 'l1_Layer_2': 0.0019509654154205704, 'l1_Layer_3': 1.570527704397738e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 11.98 | sMAPE for Test Set is: 98.79% | rMAE for Test Set is: 3.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:38:59,371]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:39:00,942]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:39:22,705]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:39:53,842]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:40:06,801]\u001b[0m Trial 1111 finished with value: 2.1095280261634675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036749165721906597, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10261656674598278, 'dropout_rate_Layer_2': 0.272835082400337, 'dropout_rate_Layer_3': 0.024609325607788512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008014469803056209, 'l1_Layer_2': 0.002742364506112484, 'l1_Layer_3': 0.0031124979787463796, 'n_units_Layer_1': 280, 'n_units_Layer_2': 85, 'n_units_Layer_3': 215}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.11 | sMAPE for Validation Set is: 5.61% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 95.91% | rMAE for Test Set is: 3.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:40:21,498]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:41:36,485]\u001b[0m Trial 1114 finished with value: 1.8483567102972132 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501858145911687, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01101545735330832, 'dropout_rate_Layer_2': 0.052723956288371086, 'dropout_rate_Layer_3': 0.007260532958080959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006927093258978143, 'l1_Layer_2': 0.009398766241378446, 'l1_Layer_3': 0.00022818414093013416, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.08 | sMAPE for Test Set is: 85.34% | rMAE for Test Set is: 2.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:41:44,716]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:41:47,349]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:41:59,307]\u001b[0m Trial 1115 finished with value: 1.8569618991944152 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005532440818398951, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007038825497429832, 'dropout_rate_Layer_2': 0.05702299620271268, 'dropout_rate_Layer_3': 0.007319590317514124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007320187018813483, 'l1_Layer_2': 0.008805928460111844, 'l1_Layer_3': 0.00019815169099250048, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 79.90% | rMAE for Test Set is: 2.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:42:14,778]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:42:21,943]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.15 | sMAPE for Validation Set is: 5.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 16.08 | sMAPE for Test Set is: 108.73% | rMAE for Test Set is: 5.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:42:24,361]\u001b[0m Trial 1118 finished with value: 2.1533618427699284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007250112040980766, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23486207112723936, 'dropout_rate_Layer_2': 0.23300608718470522, 'dropout_rate_Layer_3': 0.2111247543142083, 'dropout_rate_Layer_4': 0.0029071988365686197, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.4463396065692224e-05, 'l1_Layer_2': 0.001323275881412054, 'l1_Layer_3': 8.140306081631893e-05, 'l1_Layer_4': 0.0038370621974500017, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235, 'n_units_Layer_4': 300}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:42:27,855]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:42:29,903]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:43:07,001]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:44:35,936]\u001b[0m Trial 1128 finished with value: 1.9698630931523928 and parameters: {'n_hidden': 3, 'learning_rate': 0.002140481906244986, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38260346024270514, 'dropout_rate_Layer_2': 0.1761959906417888, 'dropout_rate_Layer_3': 0.01915947542009199, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002475037271997965, 'l1_Layer_2': 0.00018398636243036453, 'l1_Layer_3': 5.165176521600503e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 290, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.11 | sMAPE for Test Set is: 109.15% | rMAE for Test Set is: 5.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:44:52,746]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:45:03,569]\u001b[0m Trial 1120 finished with value: 1.8548395648437725 and parameters: {'n_hidden': 3, 'learning_rate': 0.000542445635554154, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02067580353770533, 'dropout_rate_Layer_2': 0.05626997789819617, 'dropout_rate_Layer_3': 0.020146154640404597, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005932192472264718, 'l1_Layer_2': 0.008773098128109526, 'l1_Layer_3': 0.0002520305873053529, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 89.30% | rMAE for Test Set is: 3.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:45:28,737]\u001b[0m Trial 1127 finished with value: 1.8660537812252507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005014667261632734, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025598420673864614, 'dropout_rate_Layer_2': 0.05320492910936261, 'dropout_rate_Layer_3': 0.022407491140349643, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006067689877285981, 'l1_Layer_2': 0.008799286333095024, 'l1_Layer_3': 0.00021897369990880487, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 89.78% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:45:35,546]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:45:49,102]\u001b[0m Trial 1121 finished with value: 1.8361647110855557 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005496978614949727, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024179819814395796, 'dropout_rate_Layer_2': 0.04752162694087918, 'dropout_rate_Layer_3': 0.025014020311914978, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005830337622677112, 'l1_Layer_2': 0.014358954131181087, 'l1_Layer_3': 0.0002526157656744955, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 230}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.82% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 9.98 | sMAPE for Test Set is: 92.35% | rMAE for Test Set is: 3.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:46:03,430]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:47:20,467]\u001b[0m Trial 1130 finished with value: 1.856310680654018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005578540349797421, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023111130945628312, 'dropout_rate_Layer_2': 0.05113855159091183, 'dropout_rate_Layer_3': 0.021199023575103903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005767312149160531, 'l1_Layer_2': 0.01363156509074529, 'l1_Layer_3': 0.00016168791975047816, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.04 | sMAPE for Test Set is: 89.10% | rMAE for Test Set is: 2.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:47:29,230]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:47:49,781]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:47:59,591]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:05,473]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:06,649]\u001b[0m Trial 1131 finished with value: 1.8394660856293124 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005045323616880467, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024086675903483897, 'dropout_rate_Layer_2': 0.0692256477748182, 'dropout_rate_Layer_3': 0.021107183278559753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00724138219759876, 'l1_Layer_2': 0.008965243039836245, 'l1_Layer_3': 0.00021339026164948256, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 89.85% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:48:06,916]\u001b[0m Trial 1133 finished with value: 1.852605692971796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005423421795268232, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02126119446817184, 'dropout_rate_Layer_2': 0.0559478581004418, 'dropout_rate_Layer_3': 0.012642971761935337, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009131033376977618, 'l1_Layer_2': 0.009221492934809922, 'l1_Layer_3': 0.00027506783984413053, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.68 | sMAPE for Test Set is: 87.76% | rMAE for Test Set is: 2.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:48:16,861]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:26,423]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:28,411]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:42,707]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:51,078]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:48:56,838]\u001b[0m Trial 1135 finished with value: 1.8696548772524189 and parameters: {'n_hidden': 3, 'learning_rate': 0.000501468363290788, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02027296433146416, 'dropout_rate_Layer_2': 0.07071848733331573, 'dropout_rate_Layer_3': 0.008275836168619363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006912926206313802, 'l1_Layer_2': 0.009942627941821117, 'l1_Layer_3': 0.0002809885131949705, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 85.67% | rMAE for Test Set is: 2.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:48:58,786]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:49:04,319]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:49:11,816]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:49:27,096]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:49:43,961]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:50:32,685]\u001b[0m Trial 1148 finished with value: 1.8106454708234336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008968717465470433, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38139645255891896, 'dropout_rate_Layer_2': 0.18105017803833365, 'dropout_rate_Layer_3': 0.032757339921378394, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023359115739828351, 'l1_Layer_2': 0.0002092701508961445, 'l1_Layer_3': 3.259142520974434e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.81 | sMAPE for Validation Set is: 4.73% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 14.99 | sMAPE for Test Set is: 106.55% | rMAE for Test Set is: 4.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:50:42,632]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:50:46,047]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:50:53,416]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:50:58,919]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:51:35,460]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:51:56,355]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:52:10,189]\u001b[0m Trial 1160 finished with value: 2.1713634465393405 and parameters: {'n_hidden': 3, 'learning_rate': 0.009684653288792549, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20701791951243123, 'dropout_rate_Layer_2': 0.1922467885237986, 'dropout_rate_Layer_3': 0.06194290329696346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9210472398690374e-05, 'l1_Layer_2': 0.001882184596127495, 'l1_Layer_3': 1.0297124753565818e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.17 | sMAPE for Validation Set is: 5.65% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 10.89 | sMAPE for Test Set is: 94.80% | rMAE for Test Set is: 3.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:52:25,321]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:52:55,975]\u001b[0m Trial 1162 finished with value: 1.9402338664269756 and parameters: {'n_hidden': 3, 'learning_rate': 0.007715976181883296, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2659738025319053, 'dropout_rate_Layer_2': 0.17064963096537925, 'dropout_rate_Layer_3': 0.03735749023571081, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.5498020053131015e-05, 'l1_Layer_2': 0.0006629235450553418, 'l1_Layer_3': 1.5789394673397463e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.81 | sMAPE for Test Set is: 106.45% | rMAE for Test Set is: 4.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:53:26,568]\u001b[0m Trial 1157 finished with value: 1.8702349113752057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005498466992002258, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03219184828241815, 'dropout_rate_Layer_2': 0.058684524075330605, 'dropout_rate_Layer_3': 0.022193152292153212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008687694258886958, 'l1_Layer_2': 0.010051932365239153, 'l1_Layer_3': 0.0001891760638854913, 'n_units_Layer_1': 295, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.26 | sMAPE for Test Set is: 89.74% | rMAE for Test Set is: 3.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:53:41,274]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:53:46,062]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:53:55,827]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:53:55,994]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:54:05,079]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:54:06,995]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:54:29,496]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:54:53,515]\u001b[0m Trial 1163 finished with value: 1.882910371634769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007083924045636816, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.389138931455747, 'dropout_rate_Layer_2': 0.20345885935897132, 'dropout_rate_Layer_3': 0.029210768667176014, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027360411379108093, 'l1_Layer_2': 0.000365615425408377, 'l1_Layer_3': 2.944087496898231e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 13.99 | sMAPE for Test Set is: 103.71% | rMAE for Test Set is: 4.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:55:08,519]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:56:09,465]\u001b[0m Trial 1158 finished with value: 1.8425354770841544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005479263533530588, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01835959186082196, 'dropout_rate_Layer_2': 0.05657567127903448, 'dropout_rate_Layer_3': 0.01995614779090966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009016022511306331, 'l1_Layer_2': 0.009737810136216623, 'l1_Layer_3': 0.0002208296961843866, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.84% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.55 | sMAPE for Test Set is: 90.89% | rMAE for Test Set is: 3.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:56:15,995]\u001b[0m Trial 1169 finished with value: 1.8781727973575697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005940972668320877, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029429451637446327, 'dropout_rate_Layer_2': 0.059265844341860247, 'dropout_rate_Layer_3': 0.016627992574752698, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0071659823317582125, 'l1_Layer_2': 0.008841785019806045, 'l1_Layer_3': 0.00016508468173695123, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 220}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.88 | sMAPE for Validation Set is: 4.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 86.55% | rMAE for Test Set is: 2.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:56:18,671]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:56:25,090]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:56:34,357]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:56:41,979]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:56:47,933]\u001b[0m Trial 1173 finished with value: 1.94787890640273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009969933192725301, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3265265967217488, 'dropout_rate_Layer_2': 0.018315366067175782, 'dropout_rate_Layer_3': 0.007727737318525659, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00025160577160415797, 'l1_Layer_2': 0.00021765826293431519, 'l1_Layer_3': 0.006118954507420597, 'n_units_Layer_1': 265, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 105.55% | rMAE for Test Set is: 4.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:57:02,742]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:57:10,008]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:57:24,551]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:57:30,722]\u001b[0m Trial 1178 finished with value: 1.9230954632856772 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006772131450763326, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3786002755592765, 'dropout_rate_Layer_2': 0.19575324325384136, 'dropout_rate_Layer_3': 0.04036882509744582, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002491046778928827, 'l1_Layer_2': 0.0003184758188884923, 'l1_Layer_3': 3.7824728629101284e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.63 | sMAPE for Test Set is: 103.14% | rMAE for Test Set is: 4.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:57:47,314]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:57:52,975]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:57:58,146]\u001b[0m Trial 1172 finished with value: 1.8691027437330845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005541936544627307, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027101225179098756, 'dropout_rate_Layer_2': 0.05713644045110795, 'dropout_rate_Layer_3': 0.016880547304259794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006985403153397424, 'l1_Layer_2': 0.00862321686806616, 'l1_Layer_3': 0.0001685018182974995, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.17 | sMAPE for Test Set is: 89.56% | rMAE for Test Set is: 3.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 21:58:06,498]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:58:09,808]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:58:46,459]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:59:19,363]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 21:59:27,890]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:00:16,881]\u001b[0m Trial 1179 finished with value: 1.8419215169299246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006136188466786891, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020365378873091276, 'dropout_rate_Layer_2': 0.0682579775861989, 'dropout_rate_Layer_3': 0.019780096461672607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008621683716977408, 'l1_Layer_2': 0.008056635914860869, 'l1_Layer_3': 0.00020589781774856805, 'n_units_Layer_1': 295, 'n_units_Layer_2': 185, 'n_units_Layer_3': 220}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.19 | sMAPE for Test Set is: 89.56% | rMAE for Test Set is: 3.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:00:25,948]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:00:33,399]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:18,196]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:23,670]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:23,693]\u001b[0m Trial 1190 finished with value: 1.8647348189575936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005685287962813834, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3993706451264334, 'dropout_rate_Layer_2': 0.18686882395157825, 'dropout_rate_Layer_3': 0.03984274590304624, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002071219769173529, 'l1_Layer_2': 0.0004202565562522119, 'l1_Layer_3': 3.9371104021864926e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 295, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.87 | sMAPE for Test Set is: 103.65% | rMAE for Test Set is: 4.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:01:33,707]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:43,406]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:48,856]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:52,233]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:01:59,618]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:02:07,727]\u001b[0m Trial 1201 finished with value: 2.2575420924849126 and parameters: {'n_hidden': 3, 'learning_rate': 0.006059742201416117, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2607734001820872, 'dropout_rate_Layer_2': 0.1399128114766694, 'dropout_rate_Layer_3': 0.07744678265602833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.749140011807112e-05, 'l1_Layer_2': 0.0005219394086852875, 'l1_Layer_3': 1.4669897304223928e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 145, 'n_units_Layer_3': 165}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.26 | sMAPE for Validation Set is: 6.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 13.73 | sMAPE for Test Set is: 103.43% | rMAE for Test Set is: 4.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:02:12,463]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:02:19,883]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:02:25,880]\u001b[0m Trial 1186 finished with value: 1.8741507185948405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006210955849715445, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042391941620670004, 'dropout_rate_Layer_2': 0.052959638677474635, 'dropout_rate_Layer_3': 0.008132582500217951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009805575896777925, 'l1_Layer_2': 0.009878548001117132, 'l1_Layer_3': 0.0002509288227212508, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 230}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 95.17% | rMAE for Test Set is: 3.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:02:32,498]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:02:35,983]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:02:43,429]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:02:51,528]\u001b[0m Trial 1208 finished with value: 2.090022929900185 and parameters: {'n_hidden': 3, 'learning_rate': 0.004418731451968598, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2494840076346438, 'dropout_rate_Layer_2': 0.23329312214702871, 'dropout_rate_Layer_3': 0.01751921139296883, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.413384115844883e-05, 'l1_Layer_2': 0.0003913143622023104, 'l1_Layer_3': 3.392775754255614e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 105.67% | rMAE for Test Set is: 4.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:02:54,882]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:03:01,654]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:03:07,771]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:03:12,640]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:03:18,113]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:03:34,686]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:03:58,526]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:04:05,826]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:04:20,828]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:04:24,586]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:04:31,489]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:04:36,816]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:05,359]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:17,372]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:20,906]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:25,757]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:29,113]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:35,628]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:36,228]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:52,783]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:05:57,575]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:04,427]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:13,693]\u001b[0m Trial 1225 finished with value: 1.9516484214118517 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011963459536069759, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34499568292205823, 'dropout_rate_Layer_2': 0.021757272701126568, 'dropout_rate_Layer_3': 0.016796896709775626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00024100996675800143, 'l1_Layer_2': 0.007662088320518104, 'l1_Layer_3': 0.0004528629540981548, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.56 | sMAPE for Test Set is: 105.17% | rMAE for Test Set is: 4.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:06:20,016]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:20,770]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:31,947]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:36,578]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:44,372]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:06:51,807]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:07:24,032]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:07:28,849]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:07:29,510]\u001b[0m Trial 1237 finished with value: 1.977299970044326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016004688826417798, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3248754041546075, 'dropout_rate_Layer_2': 0.035210341902377595, 'dropout_rate_Layer_3': 1.3339221903980233e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015154528339620174, 'l1_Layer_2': 0.018263484525044015, 'l1_Layer_3': 0.00046348455256697884, 'n_units_Layer_1': 270, 'n_units_Layer_2': 130, 'n_units_Layer_3': 290}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.11 | sMAPE for Test Set is: 106.44% | rMAE for Test Set is: 4.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:07:50,992]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:08:15,906]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:08:32,576]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:08:47,680]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:08:56,248]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:00,720]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:01,391]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:10,434]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:17,680]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:26,354]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:46,279]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:09:54,579]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:04,817]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:14,665]\u001b[0m Trial 1253 finished with value: 1.9427018120568558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007533080539362128, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39990319504943583, 'dropout_rate_Layer_2': 0.18631673447785066, 'dropout_rate_Layer_3': 0.0330602801740497, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016936243112235485, 'l1_Layer_2': 0.00043379585735718005, 'l1_Layer_3': 3.259078074821197e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.06% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.96 | sMAPE for Test Set is: 104.15% | rMAE for Test Set is: 4.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:10:20,777]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:22,625]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:26,924]\u001b[0m Trial 1250 finished with value: 1.8356016565923141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006303005496490916, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37958197885741324, 'dropout_rate_Layer_2': 0.1832836632450396, 'dropout_rate_Layer_3': 0.06578989350680434, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016232441619783101, 'l1_Layer_2': 0.00042033686711881425, 'l1_Layer_3': 2.7298259650084397e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.81% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 13.17 | sMAPE for Test Set is: 101.81% | rMAE for Test Set is: 4.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:10:37,798]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:42,661]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:50,058]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:54,617]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:10:55,177]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:04,054]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:04,631]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:11,286]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:21,885]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:36,789]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:42,485]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:43,246]\u001b[0m Trial 1268 finished with value: 2.0151595694170763 and parameters: {'n_hidden': 3, 'learning_rate': 0.007978317637349026, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21216204734508176, 'dropout_rate_Layer_2': 0.14105508629348518, 'dropout_rate_Layer_3': 0.144960028051691, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9311345705598112e-05, 'l1_Layer_2': 0.007819593776086221, 'l1_Layer_3': 8.382607691259403e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 175, 'n_units_Layer_3': 145}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 99.02% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:11:47,689]\u001b[0m Trial 1243 finished with value: 1.8449066362079076 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500320344157749, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026901881305661138, 'dropout_rate_Layer_2': 0.05257910011260518, 'dropout_rate_Layer_3': 0.015487351931443353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010455669536314745, 'l1_Layer_2': 0.010528849091425731, 'l1_Layer_3': 0.0002663709294018287, 'n_units_Layer_1': 290, 'n_units_Layer_2': 175, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.99 | sMAPE for Test Set is: 88.83% | rMAE for Test Set is: 2.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:11:47,869]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:54,698]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:11:58,431]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:03,395]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:07,073]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:08,305]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:09,301]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:09,639]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:16,787]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:21,880]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:23,907]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:12:31,517]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:13:22,433]\u001b[0m Trial 1280 finished with value: 1.9971450661991337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010871293928891538, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3465896897694935, 'dropout_rate_Layer_2': 0.060891520906991486, 'dropout_rate_Layer_3': 0.03899354812119214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0003787441557582419, 'l1_Layer_2': 0.00745578045566085, 'l1_Layer_3': 0.0010456785339397752, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 16.09 | sMAPE for Test Set is: 108.81% | rMAE for Test Set is: 5.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:13:29,158]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:13:31,823]\u001b[0m Trial 1284 finished with value: 2.0891014926881986 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012147421605505733, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3869672156573403, 'dropout_rate_Layer_2': 0.06423058505288384, 'dropout_rate_Layer_3': 0.043621429236328585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.003783369367904957, 'l1_Layer_2': 0.007631536245120127, 'l1_Layer_3': 0.001241591804573396, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.09 | sMAPE for Validation Set is: 5.43% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.59 | sMAPE for Test Set is: 112.11% | rMAE for Test Set is: 5.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:13:36,046]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:13:53,023]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:13:57,991]\u001b[0m Trial 1279 finished with value: 1.8526807706848871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006628824492230927, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007288012110638984, 'dropout_rate_Layer_2': 0.052977718680879325, 'dropout_rate_Layer_3': 0.02110565571375157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005126608450605858, 'l1_Layer_2': 0.009610751856669847, 'l1_Layer_3': 0.0002988424933994206, 'n_units_Layer_1': 295, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 80.61% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:14:06,986]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:14:09,037]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:14:09,448]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:14:15,178]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:15:27,573]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:15:37,998]\u001b[0m Trial 1294 finished with value: 1.9724230619870973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007453745501063149, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38481127420303474, 'dropout_rate_Layer_2': 0.17267711597210497, 'dropout_rate_Layer_3': 0.06306770987449835, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002260936837570529, 'l1_Layer_2': 0.0001890384681700926, 'l1_Layer_3': 6.358306304114738e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.58 | sMAPE for Test Set is: 102.46% | rMAE for Test Set is: 4.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:15:43,811]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:15:48,562]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:16:03,245]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:16:08,826]\u001b[0m Trial 1295 finished with value: 1.8591390314670473 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006007556722500227, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015369046826344521, 'dropout_rate_Layer_2': 0.043084436881933634, 'dropout_rate_Layer_3': 0.03744896202097573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013161811646049853, 'l1_Layer_2': 0.00929667798913323, 'l1_Layer_3': 0.000244071681004971, 'n_units_Layer_1': 300, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.59 | sMAPE for Test Set is: 87.37% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:16:17,737]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:16:38,202]\u001b[0m Trial 1292 finished with value: 1.8398551791651065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005107845809244568, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38217417478634447, 'dropout_rate_Layer_2': 0.20201660949071262, 'dropout_rate_Layer_3': 0.04111281276048177, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001549311200797932, 'l1_Layer_2': 0.0002456899971081741, 'l1_Layer_3': 3.269783932416176e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 295, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.81% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.71 | sMAPE for Test Set is: 103.28% | rMAE for Test Set is: 4.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:16:43,013]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:16:52,584]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:17:08,198]\u001b[0m Trial 1296 finished with value: 1.9680291622044652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006703011687905886, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39980575578214517, 'dropout_rate_Layer_2': 0.2010551014666445, 'dropout_rate_Layer_3': 0.043099541780359275, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023691115761891062, 'l1_Layer_2': 0.0002414590506303482, 'l1_Layer_3': 5.8128961795115254e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 265}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.43 | sMAPE for Test Set is: 104.78% | rMAE for Test Set is: 4.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:17:12,455]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:17:17,990]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:17:52,806]\u001b[0m Trial 1308 finished with value: 2.004279171261707 and parameters: {'n_hidden': 3, 'learning_rate': 0.007747760615781616, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21073506474347378, 'dropout_rate_Layer_2': 0.13002075904132626, 'dropout_rate_Layer_3': 0.020082740729162413, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.038547802636735e-05, 'l1_Layer_2': 0.007404179807203353, 'l1_Layer_3': 2.5203939045695992e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.23% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 98.93% | rMAE for Test Set is: 3.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:17:58,003]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:18:03,077]\u001b[0m Trial 1302 finished with value: 1.8688932452921094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007589404604918033, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3758099589145222, 'dropout_rate_Layer_2': 0.16987071839158865, 'dropout_rate_Layer_3': 0.07820444008453029, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022812096879655457, 'l1_Layer_2': 0.00024141993709159615, 'l1_Layer_3': 6.157061707545677e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.97 | sMAPE for Test Set is: 103.89% | rMAE for Test Set is: 4.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:18:23,305]\u001b[0m Trial 1300 finished with value: 1.8566088769866547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005545538403783773, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01695430771367599, 'dropout_rate_Layer_2': 0.040049818114796965, 'dropout_rate_Layer_3': 0.028463819097201137, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005583875259429409, 'l1_Layer_2': 0.01081533827345316, 'l1_Layer_3': 0.00019313732212180882, 'n_units_Layer_1': 290, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.61 | sMAPE for Test Set is: 83.23% | rMAE for Test Set is: 2.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:18:26,509]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:18:34,374]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:20:08,702]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:20:27,534]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:20:35,730]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:20:48,174]\u001b[0m Trial 1314 finished with value: 1.8567771217010538 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010376255409797678, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18020914782799144, 'dropout_rate_Layer_2': 0.1638177330951565, 'dropout_rate_Layer_3': 0.1372037202172772, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003394943865225243, 'l1_Layer_2': 0.00019592074602920313, 'l1_Layer_3': 0.0002748138975107124, 'n_units_Layer_1': 280, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 2.04 | sMAPE for Test Set is: 39.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:20:51,033]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:20:58,873]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:21:02,058]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:21:15,444]\u001b[0m Trial 1310 finished with value: 1.864249023458811 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016132463234421, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05600416641032609, 'dropout_rate_Layer_2': 0.05256745839126697, 'dropout_rate_Layer_3': 0.02653270557289588, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010483085898198461, 'l1_Layer_2': 0.012358542293625948, 'l1_Layer_3': 0.00017986911843289295, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.40 | sMAPE for Test Set is: 93.75% | rMAE for Test Set is: 3.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:21:20,016]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:21:20,622]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:21:50,348]\u001b[0m Trial 1305 finished with value: 1.8398380055241077 and parameters: {'n_hidden': 3, 'learning_rate': 0.001003923405856207, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17492660147271535, 'dropout_rate_Layer_2': 0.16409828940738713, 'dropout_rate_Layer_3': 0.1440040174995329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003978134758212386, 'l1_Layer_2': 0.00020172818071146416, 'l1_Layer_3': 0.0002570489926011182, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 1.74 | sMAPE for Test Set is: 31.88% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:22:03,185]\u001b[0m Trial 1324 finished with value: 1.9831434748381431 and parameters: {'n_hidden': 3, 'learning_rate': 0.007669652214195609, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20674529441547806, 'dropout_rate_Layer_2': 0.14414439041926266, 'dropout_rate_Layer_3': 0.023329168462045052, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0010197283417663e-05, 'l1_Layer_2': 0.008175916624327382, 'l1_Layer_3': 7.160512398717443e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 145}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 17.27 | sMAPE for Test Set is: 112.24% | rMAE for Test Set is: 5.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:22:07,928]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:22:23,864]\u001b[0m Trial 1325 finished with value: 2.0589191862635547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007809958165285166, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3794467673407183, 'dropout_rate_Layer_2': 0.14093499636633616, 'dropout_rate_Layer_3': 0.05642429766247482, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024674138222607005, 'l1_Layer_2': 0.00022797644853506503, 'l1_Layer_3': 4.429834488534721e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 175, 'n_units_Layer_3': 50}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 13.77 | sMAPE for Test Set is: 103.49% | rMAE for Test Set is: 4.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:22:24,341]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:22:29,947]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:22:41,228]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:22:48,417]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:00,477]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:10,734]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:26,942]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:32,599]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:37,413]\u001b[0m Trial 1333 finished with value: 1.9304134710230196 and parameters: {'n_hidden': 3, 'learning_rate': 0.008000543694988538, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19848120531533917, 'dropout_rate_Layer_2': 0.11538584762946211, 'dropout_rate_Layer_3': 0.005783055841797266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2861203561401863e-05, 'l1_Layer_2': 0.005838563704752357, 'l1_Layer_3': 2.771418072112567e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.04% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 15.42 | sMAPE for Test Set is: 108.37% | rMAE for Test Set is: 5.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:23:45,213]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:48,335]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:23:52,308]\u001b[0m Trial 1331 finished with value: 2.0361835297259536 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005631327598842213, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3997784526121699, 'dropout_rate_Layer_2': 0.140613964803475, 'dropout_rate_Layer_3': 0.04718912473265226, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020219006351489976, 'l1_Layer_2': 0.00017177230821831686, 'l1_Layer_3': 5.281907625148875e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 5.31% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 15.41 | sMAPE for Test Set is: 107.19% | rMAE for Test Set is: 5.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:23:54,569]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:02,983]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:06,947]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:11,470]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:19,286]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:29,877]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:34,941]\u001b[0m Trial 1330 finished with value: 1.8744768921978203 and parameters: {'n_hidden': 3, 'learning_rate': 0.001843247774438642, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12512486912968865, 'dropout_rate_Layer_2': 0.11460284608597693, 'dropout_rate_Layer_3': 0.39086499971952765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014257560604770273, 'l1_Layer_2': 0.0004374729268298327, 'l1_Layer_3': 0.0006037859635370225, 'n_units_Layer_1': 265, 'n_units_Layer_2': 240, 'n_units_Layer_3': 285}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 3.59 | sMAPE for Test Set is: 55.63% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:24:38,319]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:43,260]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:46,865]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:52,127]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:24:58,060]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:25:03,137]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:25:03,183]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:25:10,084]\u001b[0m Trial 1343 finished with value: 1.9345062224247824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013700604467327447, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33204910171332, 'dropout_rate_Layer_2': 0.01799181952806764, 'dropout_rate_Layer_3': 0.023453965057149934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0018050889070190864, 'l1_Layer_2': 0.023601748330048227, 'l1_Layer_3': 0.00028728553589205423, 'n_units_Layer_1': 265, 'n_units_Layer_2': 90, 'n_units_Layer_3': 285}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.01% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.23 | sMAPE for Test Set is: 101.87% | rMAE for Test Set is: 4.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:25:20,764]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:25:44,956]\u001b[0m Trial 1354 finished with value: 2.003141651162444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012947826893775541, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3585518259976846, 'dropout_rate_Layer_2': 0.015372623347859032, 'dropout_rate_Layer_3': 0.032907883343983056, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0018516224938457853, 'l1_Layer_2': 0.006367813456300222, 'l1_Layer_3': 0.00029413183979110714, 'n_units_Layer_1': 255, 'n_units_Layer_2': 145, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 12.30 | sMAPE for Test Set is: 99.22% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:25:49,634]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:25:54,655]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:26:02,611]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:26:07,563]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:26:29,870]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:26:38,215]\u001b[0m Trial 1341 finished with value: 1.8557449449773606 and parameters: {'n_hidden': 3, 'learning_rate': 0.000551894298041696, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02356366314208523, 'dropout_rate_Layer_2': 0.03858245858311429, 'dropout_rate_Layer_3': 0.03277510882130109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007895554923309435, 'l1_Layer_2': 0.010281673501434298, 'l1_Layer_3': 0.00019063140933223285, 'n_units_Layer_1': 290, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 87.13% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:26:47,332]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:26:52,891]\u001b[0m Trial 1356 finished with value: 1.9867513253924125 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006906842623104315, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38806736247418433, 'dropout_rate_Layer_2': 0.13440744680982142, 'dropout_rate_Layer_3': 0.04624830545692819, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003174430723252759, 'l1_Layer_2': 0.00025357461642668, 'l1_Layer_3': 3.568940417912437e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 80}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.92 | sMAPE for Test Set is: 106.09% | rMAE for Test Set is: 4.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:26:57,897]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:27:08,272]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:27:21,497]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:27:30,990]\u001b[0m Trial 1365 finished with value: 1.9532401289664614 and parameters: {'n_hidden': 3, 'learning_rate': 0.008984549262002355, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16031796258861508, 'dropout_rate_Layer_2': 0.08290624736226186, 'dropout_rate_Layer_3': 0.03728917655703343, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3135052543402436e-05, 'l1_Layer_2': 0.01442372122594019, 'l1_Layer_3': 2.7798293400124837e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.08% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 16.60 | sMAPE for Test Set is: 110.28% | rMAE for Test Set is: 5.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:27:34,929]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:27:35,827]\u001b[0m Trial 1359 finished with value: 1.956968090840558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006810440426773016, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3854823444969625, 'dropout_rate_Layer_2': 0.14396520336063215, 'dropout_rate_Layer_3': 0.045496158095909976, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026500160784991353, 'l1_Layer_2': 0.000248542683590947, 'l1_Layer_3': 7.466069343735096e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 95}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 15.46 | sMAPE for Test Set is: 107.32% | rMAE for Test Set is: 5.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:27:44,619]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:27:45,106]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:27:50,727]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:28:43,271]\u001b[0m Trial 1367 finished with value: 2.124973225495891 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007367350407595346, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1595501243577986, 'dropout_rate_Layer_2': 0.1358235780841052, 'dropout_rate_Layer_3': 0.10946715798550229, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001027614077858398, 'l1_Layer_2': 0.00010839824756788834, 'l1_Layer_3': 9.341154190579022e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 5.52% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 104.68% | rMAE for Test Set is: 4.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:28:48,672]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:28:59,563]\u001b[0m Trial 1368 finished with value: 1.9761679273388681 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006904579688308969, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39155292928176993, 'dropout_rate_Layer_2': 0.13362777997712852, 'dropout_rate_Layer_3': 0.06064295898809796, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002569047839415249, 'l1_Layer_2': 0.0001095959200728404, 'l1_Layer_3': 3.701351665775763e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 65}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 104.45% | rMAE for Test Set is: 4.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:29:05,523]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:29:27,428]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:29:35,023]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:30:29,898]\u001b[0m Trial 1374 finished with value: 1.8703294779779303 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006034557245151255, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04460595808109818, 'dropout_rate_Layer_2': 0.04309219208079601, 'dropout_rate_Layer_3': 0.021707474286097896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011207588011676692, 'l1_Layer_2': 0.0133710490819754, 'l1_Layer_3': 0.00016583831137667642, 'n_units_Layer_1': 295, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.16 | sMAPE for Test Set is: 93.01% | rMAE for Test Set is: 3.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:30:37,461]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:30:47,040]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:30:54,833]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:30:55,592]\u001b[0m Trial 1377 finished with value: 1.9749108200410668 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006710572122961093, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3910414967468049, 'dropout_rate_Layer_2': 0.13655988129806237, 'dropout_rate_Layer_3': 0.044626733725174, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001776508271192574, 'l1_Layer_2': 7.374085090676335e-05, 'l1_Layer_3': 3.489904277695466e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 135, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.82 | sMAPE for Test Set is: 105.60% | rMAE for Test Set is: 4.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:31:04,701]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:31:12,783]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:31:17,909]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:31:21,273]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:31:28,106]\u001b[0m Trial 1378 finished with value: 1.99034991929429 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006651685885345628, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3997869323770856, 'dropout_rate_Layer_2': 0.13367766679142537, 'dropout_rate_Layer_3': 0.07129681847834876, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041259353202268806, 'l1_Layer_2': 8.800080755251105e-05, 'l1_Layer_3': 3.227087285607169e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 80}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.21% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.82 | sMAPE for Test Set is: 103.17% | rMAE for Test Set is: 4.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:31:30,119]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.08 | sMAPE for Test Set is: 103.80% | rMAE for Test Set is: 4.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:31:31,755]\u001b[0m Trial 1380 finished with value: 2.002070803944181 and parameters: {'n_hidden': 3, 'learning_rate': 0.000660252282955052, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3927917639338772, 'dropout_rate_Layer_2': 0.1294153960913831, 'dropout_rate_Layer_3': 0.0738829202312287, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003532770689157016, 'l1_Layer_2': 0.0001532893553516081, 'l1_Layer_3': 3.313755078583378e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 105}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:31:37,429]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:32:48,531]\u001b[0m Trial 1388 finished with value: 1.966523480903725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006632781549906173, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38713250202586874, 'dropout_rate_Layer_2': 0.12349367471487056, 'dropout_rate_Layer_3': 0.07163429920693358, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004074057754979451, 'l1_Layer_2': 6.759243833164938e-05, 'l1_Layer_3': 3.175648084339318e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 65}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.10% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.74 | sMAPE for Test Set is: 105.76% | rMAE for Test Set is: 4.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:33:04,141]\u001b[0m Trial 1391 finished with value: 2.0613029762353308 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006966971321887412, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38658882838833647, 'dropout_rate_Layer_2': 0.14941735877348358, 'dropout_rate_Layer_3': 0.0716927656905704, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004459815808233903, 'l1_Layer_2': 8.340715109955099e-05, 'l1_Layer_3': 3.15017895442512e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 85}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.74 | sMAPE for Test Set is: 105.57% | rMAE for Test Set is: 4.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:33:09,199]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:33:24,285]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:33:30,073]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:33:35,038]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:34:01,976]\u001b[0m Trial 1399 finished with value: 1.9336923350169009 and parameters: {'n_hidden': 3, 'learning_rate': 0.008818331466772585, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1568617187507298, 'dropout_rate_Layer_2': 0.08279699165619273, 'dropout_rate_Layer_3': 0.025154686804929268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4026680151343982e-05, 'l1_Layer_2': 0.006203753687503131, 'l1_Layer_3': 2.7041593562933732e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 170, 'n_units_Layer_3': 130}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 5.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 16.50 | sMAPE for Test Set is: 111.21% | rMAE for Test Set is: 5.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:34:05,693]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:34:07,882]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:34:08,490]\u001b[0m Trial 1392 finished with value: 1.8549151853032175 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006112681619620526, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0254124785925585, 'dropout_rate_Layer_2': 0.054450534128172356, 'dropout_rate_Layer_3': 0.014308325234975446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008843318555507912, 'l1_Layer_2': 0.010686169338153133, 'l1_Layer_3': 0.00020843193601552425, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.85% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.24 | sMAPE for Test Set is: 89.79% | rMAE for Test Set is: 3.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:34:15,024]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:34:38,167]\u001b[0m Trial 1394 finished with value: 1.9986299102843583 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007077407296593941, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3866613096851522, 'dropout_rate_Layer_2': 0.13405674186025118, 'dropout_rate_Layer_3': 0.08561598230202809, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004180229463797227, 'l1_Layer_2': 7.031192919873628e-05, 'l1_Layer_3': 2.6601724858815266e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 135, 'n_units_Layer_3': 80}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.00 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.10 | sMAPE for Test Set is: 103.84% | rMAE for Test Set is: 4.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:34:47,152]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:35:02,054]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:35:09,178]\u001b[0m Trial 1403 finished with value: 1.9796635392524677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008746050984288656, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3996823970401445, 'dropout_rate_Layer_2': 0.11837134339343292, 'dropout_rate_Layer_3': 0.08507568895449134, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005906712747398633, 'l1_Layer_2': 6.161186772018446e-05, 'l1_Layer_3': 2.579231003740265e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 80}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.52 | sMAPE for Test Set is: 105.24% | rMAE for Test Set is: 4.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:35:19,080]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:35:24,439]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:35:27,673]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:35:57,660]\u001b[0m Trial 1405 finished with value: 1.9636500835063515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008792159088008937, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39993389940459756, 'dropout_rate_Layer_2': 0.11021641114604046, 'dropout_rate_Layer_3': 0.061280935502825915, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000614461218889899, 'l1_Layer_2': 0.00010261600289003818, 'l1_Layer_3': 3.46157500124628e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 80}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.96 | sMAPE for Validation Set is: 5.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.75 | sMAPE for Test Set is: 105.63% | rMAE for Test Set is: 4.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:36:05,089]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:07,553]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:11,255]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:15,956]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:23,250]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:26,255]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:32,787]\u001b[0m Trial 1404 finished with value: 1.8632862970593695 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005565795252102048, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007234025029246574, 'dropout_rate_Layer_2': 0.07949397535456831, 'dropout_rate_Layer_3': 0.029918383630304014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007648865489738444, 'l1_Layer_2': 0.0169135866111057, 'l1_Layer_3': 0.00016114223162939993, 'n_units_Layer_1': 300, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.60 | sMAPE for Test Set is: 87.30% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:36:41,022]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:41,976]\u001b[0m Trial 1417 finished with value: 2.0768528778548565 and parameters: {'n_hidden': 3, 'learning_rate': 0.008951731527540094, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15145157610714025, 'dropout_rate_Layer_2': 0.08470396961302569, 'dropout_rate_Layer_3': 0.05518650381354214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3053342380410151e-05, 'l1_Layer_2': 0.00609839292502679, 'l1_Layer_3': 3.3641196558573595e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 130}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 15.86 | sMAPE for Test Set is: 110.39% | rMAE for Test Set is: 5.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:36:44,958]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:50,652]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:36:56,944]\u001b[0m Trial 1411 finished with value: 1.8580249108326943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006639619218310275, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006770084392893845, 'dropout_rate_Layer_2': 0.07845594150890295, 'dropout_rate_Layer_3': 0.024945738567201635, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004951654981597869, 'l1_Layer_2': 0.009154581637457582, 'l1_Layer_3': 0.00012676590556665932, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 4.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 82.21% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:37:04,515]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:06,510]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:07,441]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:13,527]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:13,630]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:19,645]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:19,702]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:37:49,413]\u001b[0m Trial 1425 finished with value: 1.9702158869134205 and parameters: {'n_hidden': 3, 'learning_rate': 0.000607754060721099, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28617256677321656, 'dropout_rate_Layer_2': 0.1888540357962399, 'dropout_rate_Layer_3': 0.08281549671252267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005352083163047759, 'l1_Layer_2': 0.0014716444893640294, 'l1_Layer_3': 2.3072525224676433e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 190, 'n_units_Layer_3': 225}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.32 | sMAPE for Test Set is: 107.95% | rMAE for Test Set is: 5.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:37:55,039]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:38:30,353]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:38:34,988]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:38:39,137]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:38:39,779]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:38:45,921]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:22,421]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:26,467]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:30,378]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:34,629]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:38,067]\u001b[0m Trial 1423 finished with value: 1.8668196164651507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005573074317204862, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021787480792501018, 'dropout_rate_Layer_2': 0.06945972154692759, 'dropout_rate_Layer_3': 0.03126550403364975, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006986961573505114, 'l1_Layer_2': 0.01485174515321976, 'l1_Layer_3': 0.0001394668669143027, 'n_units_Layer_1': 295, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 4.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.56 | sMAPE for Test Set is: 87.09% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:39:43,563]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:46,908]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:52,099]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:54,720]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:39:59,574]\u001b[0m Trial 1436 finished with value: 1.9868601188180168 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012619844804893701, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3219632064894916, 'dropout_rate_Layer_2': 0.03727872460395697, 'dropout_rate_Layer_3': 0.01754161337867863, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00210031799045512, 'l1_Layer_2': 0.021819569706250933, 'l1_Layer_3': 0.0001382976506019167, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 13.56 | sMAPE for Test Set is: 103.05% | rMAE for Test Set is: 4.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:40:04,001]\u001b[0m Trial 1430 finished with value: 1.8480645679406387 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005499591547494795, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0171773997624325, 'dropout_rate_Layer_2': 0.06715144613398416, 'dropout_rate_Layer_3': 0.0297799974404617, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004923035812943141, 'l1_Layer_2': 0.011226298910449874, 'l1_Layer_3': 0.00022190008682627517, 'n_units_Layer_1': 285, 'n_units_Layer_2': 190, 'n_units_Layer_3': 250}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.40 | sMAPE for Test Set is: 86.43% | rMAE for Test Set is: 2.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:40:06,105]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:40:07,131]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:40:12,805]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:40:23,504]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:40:33,316]\u001b[0m Trial 1451 finished with value: 2.052445719370851 and parameters: {'n_hidden': 3, 'learning_rate': 0.005287597930928011, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1951012779687548, 'dropout_rate_Layer_2': 0.055602986797553225, 'dropout_rate_Layer_3': 0.024072855226489064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.533391897668961e-05, 'l1_Layer_2': 0.004238419030079957, 'l1_Layer_3': 1.2630132706959916e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 155}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.05 | sMAPE for Validation Set is: 5.36% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.30 | sMAPE for Test Set is: 99.76% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:41:06,800]\u001b[0m Trial 1448 finished with value: 1.9807065381328932 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007668537015075362, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39979049005136824, 'dropout_rate_Layer_2': 0.13043521800460384, 'dropout_rate_Layer_3': 0.05253223123872849, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006372200948706496, 'l1_Layer_2': 9.879570745489944e-05, 'l1_Layer_3': 3.74792468315349e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.98 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 15.01 | sMAPE for Test Set is: 106.40% | rMAE for Test Set is: 4.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:41:12,021]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:41:40,264]\u001b[0m Trial 1453 finished with value: 1.8436943406987678 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007035802904925228, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 6.406923477288856e-05, 'dropout_rate_Layer_2': 0.06450371349145594, 'dropout_rate_Layer_3': 0.06079891250832267, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005911779382447542, 'l1_Layer_2': 0.015452847383834768, 'l1_Layer_3': 0.00021155921803520255, 'n_units_Layer_1': 285, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 4.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.65 | sMAPE for Test Set is: 83.36% | rMAE for Test Set is: 2.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:41:44,831]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:41:48,023]\u001b[0m Trial 1452 finished with value: 1.9370143784357847 and parameters: {'n_hidden': 3, 'learning_rate': 0.001168529256664317, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3997014079655828, 'dropout_rate_Layer_2': 0.08718596487504209, 'dropout_rate_Layer_3': 0.07428543108945597, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005051308243621017, 'l1_Layer_2': 9.755974395925373e-05, 'l1_Layer_3': 3.704773171287652e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 5.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 14.67 | sMAPE for Test Set is: 105.67% | rMAE for Test Set is: 4.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:41:49,309]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:41:54,240]\u001b[0m Trial 1454 finished with value: 2.005482745064038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007661417988849379, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3990954461226349, 'dropout_rate_Layer_2': 0.11385820668013798, 'dropout_rate_Layer_3': 0.052854411755180936, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005184412188037986, 'l1_Layer_2': 5.7251928834936534e-05, 'l1_Layer_3': 3.498147981044615e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 14.31 | sMAPE for Test Set is: 104.67% | rMAE for Test Set is: 4.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:41:54,679]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:42:01,166]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:42:46,767]\u001b[0m Trial 1462 finished with value: 2.062485071231977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010896554261166447, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39099930753218776, 'dropout_rate_Layer_2': 0.09265444463325644, 'dropout_rate_Layer_3': 0.08092746220466163, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012036802448413396, 'l1_Layer_2': 0.0001125858244624536, 'l1_Layer_3': 2.333839068512268e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 160, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.06 | sMAPE for Validation Set is: 5.37% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 14.51 | sMAPE for Test Set is: 105.35% | rMAE for Test Set is: 4.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:43:00,640]\u001b[0m Trial 1456 finished with value: 1.9670680574953445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007756579555823574, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39394137833951287, 'dropout_rate_Layer_2': 0.12437410381709739, 'dropout_rate_Layer_3': 0.05458391963366789, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007493895692450194, 'l1_Layer_2': 9.428289193136469e-05, 'l1_Layer_3': 4.099561348824704e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.97 | sMAPE for Validation Set is: 5.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.65 | sMAPE for Test Set is: 102.94% | rMAE for Test Set is: 4.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:43:06,004]\u001b[0m Trial 1460 finished with value: 1.7469959260986723 and parameters: {'n_hidden': 3, 'learning_rate': 0.002089195901197874, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1374872848072087, 'dropout_rate_Layer_2': 0.22449314987239033, 'dropout_rate_Layer_3': 0.13402716023035732, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024252350456978937, 'l1_Layer_2': 0.0002738633419741607, 'l1_Layer_3': 0.0006733786810801736, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 260}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.75 | sMAPE for Validation Set is: 4.69% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 1.15 | sMAPE for Test Set is: 26.65% | rMAE for Test Set is: 0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:43:09,903]\u001b[0m Trial 1463 finished with value: 2.006487572819161 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014847067459358126, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3919299929186479, 'dropout_rate_Layer_2': 0.09812903646159848, 'dropout_rate_Layer_3': 0.08412908797554768, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000804185532341452, 'l1_Layer_2': 6.386744627477919e-05, 'l1_Layer_3': 2.337007738246563e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.01 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.33 | sMAPE for Test Set is: 107.27% | rMAE for Test Set is: 5.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:43:10,471]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:16,410]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:16,966]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:19,776]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:24,254]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:27,881]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:28,459]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:28,581]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:36,017]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:39,296]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:42,989]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:43,419]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:48,835]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:52,703]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:43:57,713]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:01,221]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:05,115]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:11,708]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:15,921]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:19,095]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:26,506]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:35,871]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:44:54,270]\u001b[0m Trial 1489 finished with value: 1.9548932206120126 and parameters: {'n_hidden': 3, 'learning_rate': 0.012960874249130302, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2242212744257817, 'dropout_rate_Layer_2': 0.14862429226583557, 'dropout_rate_Layer_3': 0.05521546129321315, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.7835475680705246e-05, 'l1_Layer_2': 0.006004620433249743, 'l1_Layer_3': 6.545400887313267e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 185, 'n_units_Layer_3': 100}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 5.13% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 101.48% | rMAE for Test Set is: 4.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:44:57,389]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:03,892]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:13,810]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:25,094]\u001b[0m Trial 1479 finished with value: 1.9926117431118502 and parameters: {'n_hidden': 3, 'learning_rate': 0.00118274745140747, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30789523266544994, 'dropout_rate_Layer_2': 0.09176533300425706, 'dropout_rate_Layer_3': 0.029214496818877753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0012620718441517956, 'l1_Layer_2': 0.04306681550490008, 'l1_Layer_3': 0.0001513137642713519, 'n_units_Layer_1': 190, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.99 | sMAPE for Validation Set is: 5.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 98.08% | rMAE for Test Set is: 3.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:45:28,008]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:42,752]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:43,082]\u001b[0m Trial 1492 finished with value: 2.0848561929280085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013084548528840914, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38331648181011846, 'dropout_rate_Layer_2': 0.0636879634703924, 'dropout_rate_Layer_3': 0.05917000595874353, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016681735139669452, 'l1_Layer_2': 8.535903069430787e-05, 'l1_Layer_3': 4.080106101704136e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 65}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.08 | sMAPE for Validation Set is: 5.41% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 13.91 | sMAPE for Test Set is: 103.69% | rMAE for Test Set is: 4.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:45:48,254]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:52,287]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:45:57,625]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-10 22:46:27,760]\u001b[0m Trial 1496 finished with value: 2.0204186923455034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012336647260147895, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39120365877126023, 'dropout_rate_Layer_2': 0.07978347382287594, 'dropout_rate_Layer_3': 0.06957441703527292, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013485410658914366, 'l1_Layer_2': 9.124368614166124e-05, 'l1_Layer_3': 3.206430119964375e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 15.22 | sMAPE for Test Set is: 106.91% | rMAE for Test Set is: 5.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:46:35,502]\u001b[0m Trial 1497 finished with value: 2.017036739567805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006487253851917977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3918217255321166, 'dropout_rate_Layer_2': 0.08804820760202842, 'dropout_rate_Layer_3': 0.051508590966939015, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006825509625051287, 'l1_Layer_2': 9.681166028532333e-05, 'l1_Layer_3': 2.9891584837819295e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 75}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.02 | sMAPE for Validation Set is: 5.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 13.11 | sMAPE for Test Set is: 101.47% | rMAE for Test Set is: 4.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-10 22:46:37,012]\u001b[0m Trial 1488 finished with value: 1.826731596596858 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006121250478853207, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03108700577865657, 'dropout_rate_Layer_2': 0.035468717842121904, 'dropout_rate_Layer_3': 0.023470885936319658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008732147887344601, 'l1_Layer_2': 0.010865061005193815, 'l1_Layer_3': 0.00021927948406982026, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245}. Best is trial 367 with value: 1.673526230653127.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.83 | sMAPE for Validation Set is: 4.80% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 90.60% | rMAE for Test Set is: 3.14\n",
      "for 2020-01-01, MAE is:2.08 & sMAPE is:6.47% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :2.08 & 6.47% & 0.40\n",
      "for 2020-01-02, MAE is:1.67 & sMAPE is:5.28% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :1.87 & 5.87% & 0.34\n",
      "for 2020-01-03, MAE is:1.58 & sMAPE is:5.17% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :1.78 & 5.64% & 0.29\n",
      "for 2020-01-04, MAE is:1.19 & sMAPE is:4.00% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :1.63 & 5.23% & 0.27\n",
      "for 2020-01-05, MAE is:0.86 & sMAPE is:2.82% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.47 & 4.75% & 0.27\n",
      "for 2020-01-06, MAE is:1.03 & sMAPE is:3.31% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.40 & 4.51% & 0.28\n",
      "for 2020-01-07, MAE is:1.33 & sMAPE is:4.39% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :1.39 & 4.49% & 0.30\n",
      "for 2020-01-08, MAE is:3.21 & sMAPE is:11.82% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :1.62 & 5.41% & 0.36\n",
      "for 2020-01-09, MAE is:2.17 & sMAPE is:7.44% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :1.68 & 5.63% & 0.39\n",
      "for 2020-01-10, MAE is:0.78 & sMAPE is:2.82% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :1.59 & 5.35% & 0.41\n",
      "for 2020-01-11, MAE is:0.95 & sMAPE is:3.75% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.53 & 5.21% & 0.40\n",
      "for 2020-01-12, MAE is:0.61 & sMAPE is:2.47% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.45 & 4.98% & 0.37\n",
      "for 2020-01-13, MAE is:0.91 & sMAPE is:3.42% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.41 & 4.86% & 0.36\n",
      "for 2020-01-14, MAE is:1.25 & sMAPE is:5.18% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.40 & 4.88% & 0.35\n",
      "for 2020-01-15, MAE is:1.02 & sMAPE is:4.00% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :1.38 & 4.82% & 0.36\n",
      "for 2020-01-16, MAE is:1.24 & sMAPE is:4.83% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :1.37 & 4.82% & 0.36\n",
      "for 2020-01-17, MAE is:1.39 & sMAPE is:5.38% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.37 & 4.86% & 0.36\n",
      "for 2020-01-18, MAE is:0.97 & sMAPE is:4.07% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :1.35 & 4.81% & 0.37\n",
      "for 2020-01-19, MAE is:0.72 & sMAPE is:3.09% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :1.31 & 4.72% & 0.37\n",
      "for 2020-01-20, MAE is:2.08 & sMAPE is:8.57% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :1.35 & 4.91% & 0.38\n",
      "for 2020-01-21, MAE is:1.40 & sMAPE is:6.45% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :1.35 & 4.99% & 0.38\n",
      "for 2020-01-22, MAE is:1.12 & sMAPE is:5.16% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :1.34 & 4.99% & 0.38\n",
      "for 2020-01-23, MAE is:2.10 & sMAPE is:9.62% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.38 & 5.20% & 0.39\n",
      "for 2020-01-24, MAE is:0.62 & sMAPE is:3.24% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :1.34 & 5.11% & 0.38\n",
      "for 2020-01-25, MAE is:0.68 & sMAPE is:3.41% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.32 & 5.05% & 0.37\n",
      "for 2020-01-26, MAE is:2.02 & sMAPE is:9.68% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :1.35 & 5.22% & 0.39\n",
      "for 2020-01-27, MAE is:0.63 & sMAPE is:2.90% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.32 & 5.14% & 0.38\n",
      "for 2020-01-28, MAE is:0.83 & sMAPE is:4.04% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :1.30 & 5.10% & 0.41\n",
      "for 2020-01-29, MAE is:0.61 & sMAPE is:2.90% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :1.28 & 5.02% & 0.42\n",
      "for 2020-01-30, MAE is:0.77 & sMAPE is:3.66% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :1.26 & 4.98% & 0.43\n",
      "for 2020-01-31, MAE is:1.97 & sMAPE is:9.81% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :1.28 & 5.13% & 0.48\n",
      "for 2020-02-01, MAE is:0.44 & sMAPE is:2.68% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.26 & 5.06% & 0.46\n",
      "for 2020-02-02, MAE is:0.82 & sMAPE is:4.73% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.24 & 5.05% & 0.46\n",
      "for 2020-02-03, MAE is:1.19 & sMAPE is:6.63% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :1.24 & 5.09% & 0.46\n",
      "for 2020-02-04, MAE is:2.17 & sMAPE is:12.19% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :1.27 & 5.30% & 0.48\n",
      "for 2020-02-05, MAE is:1.11 & sMAPE is:6.29% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.26 & 5.32% & 0.47\n",
      "for 2020-02-06, MAE is:0.74 & sMAPE is:4.42% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.25 & 5.30% & 0.46\n",
      "for 2020-02-07, MAE is:0.73 & sMAPE is:4.54% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.24 & 5.28% & 0.46\n",
      "for 2020-02-08, MAE is:1.02 & sMAPE is:7.12% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :1.23 & 5.33% & 0.46\n",
      "for 2020-02-09, MAE is:1.66 & sMAPE is:13.90% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.24 & 5.54% & 0.45\n",
      "for 2020-02-10, MAE is:1.46 & sMAPE is:10.95% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :1.25 & 5.67% & 0.45\n",
      "for 2020-02-11, MAE is:1.04 & sMAPE is:8.29% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.24 & 5.74% & 0.44\n",
      "for 2020-02-12, MAE is:0.62 & sMAPE is:4.85% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.23 & 5.71% & 0.43\n",
      "for 2020-02-13, MAE is:0.46 & sMAPE is:3.37% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.21 & 5.66% & 0.43\n",
      "for 2020-02-14, MAE is:0.64 & sMAPE is:4.64% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :1.20 & 5.64% & 0.42\n",
      "for 2020-02-15, MAE is:0.71 & sMAPE is:6.30% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.19 & 5.65% & 0.42\n",
      "for 2020-02-16, MAE is:0.72 & sMAPE is:8.10% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.18 & 5.71% & 0.42\n",
      "for 2020-02-17, MAE is:0.56 & sMAPE is:5.32% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.16 & 5.70% & 0.42\n",
      "for 2020-02-18, MAE is:0.68 & sMAPE is:6.17% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :1.15 & 5.71% & 0.42\n",
      "for 2020-02-19, MAE is:0.82 & sMAPE is:6.99% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.15 & 5.73% & 0.42\n",
      "for 2020-02-20, MAE is:1.18 & sMAPE is:11.02% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.15 & 5.84% & 0.42\n",
      "for 2020-02-21, MAE is:0.46 & sMAPE is:5.11% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :1.13 & 5.82% & 0.41\n",
      "for 2020-02-22, MAE is:0.77 & sMAPE is:10.02% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :1.13 & 5.90% & 0.41\n",
      "for 2020-02-23, MAE is:1.51 & sMAPE is:19.34% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :1.13 & 6.15% & 0.43\n",
      "for 2020-02-24, MAE is:0.89 & sMAPE is:8.60% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :1.13 & 6.19% & 0.44\n",
      "for 2020-02-25, MAE is:0.53 & sMAPE is:5.12% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :1.12 & 6.18% & 0.45\n",
      "for 2020-02-26, MAE is:0.28 & sMAPE is:2.80% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.10 & 6.12% & 0.44\n",
      "for 2020-02-27, MAE is:1.16 & sMAPE is:11.06% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :1.11 & 6.20% & 0.46\n",
      "for 2020-02-28, MAE is:0.53 & sMAPE is:5.02% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :1.10 & 6.18% & 0.45\n",
      "for 2020-02-29, MAE is:1.30 & sMAPE is:13.80% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :1.10 & 6.31% & 0.46\n",
      "for 2020-03-01, MAE is:0.79 & sMAPE is:8.07% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 6.34% & 0.46\n",
      "for 2020-03-02, MAE is:1.33 & sMAPE is:11.83% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :1.10 & 6.43% & 0.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-03, MAE is:0.48 & sMAPE is:4.79% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 6.40% & 0.51\n",
      "for 2020-03-04, MAE is:0.72 & sMAPE is:7.65% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.42% & 0.54\n",
      "for 2020-03-05, MAE is:0.80 & sMAPE is:7.71% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.44% & 0.54\n",
      "for 2020-03-06, MAE is:1.34 & sMAPE is:9.91% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.49% & 0.55\n",
      "for 2020-03-07, MAE is:1.85 & sMAPE is:19.67% & rMAE is:5.30 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 6.69% & 0.62\n",
      "for 2020-03-08, MAE is:0.71 & sMAPE is:7.74% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 6.70% & 0.64\n",
      "for 2020-03-09, MAE is:0.74 & sMAPE is:6.97% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.71% & 0.66\n",
      "for 2020-03-10, MAE is:0.81 & sMAPE is:8.32% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.73% & 0.67\n",
      "for 2020-03-11, MAE is:0.87 & sMAPE is:10.47% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.78% & 0.68\n",
      "for 2020-03-12, MAE is:1.70 & sMAPE is:17.97% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 6.94% & 0.68\n",
      "for 2020-03-13, MAE is:1.12 & sMAPE is:12.56% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 7.02% & 0.68\n",
      "for 2020-03-14, MAE is:1.15 & sMAPE is:12.92% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 7.10% & 0.68\n",
      "for 2020-03-15, MAE is:0.59 & sMAPE is:8.55% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 7.12% & 0.67\n",
      "for 2020-03-16, MAE is:1.34 & sMAPE is:17.54% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 7.25% & 0.67\n",
      "for 2020-03-17, MAE is:0.55 & sMAPE is:7.05% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 7.25% & 0.67\n",
      "for 2020-03-18, MAE is:0.83 & sMAPE is:12.72% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 7.32% & 0.66\n",
      "for 2020-03-19, MAE is:0.38 & sMAPE is:5.72% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 7.30% & 0.66\n",
      "for 2020-03-20, MAE is:1.32 & sMAPE is:19.01% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 7.45% & 0.67\n",
      "for 2020-03-21, MAE is:0.99 & sMAPE is:14.07% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 7.53% & 0.68\n",
      "for 2020-03-22, MAE is:0.77 & sMAPE is:11.39% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 7.58% & 0.69\n",
      "for 2020-03-23, MAE is:0.76 & sMAPE is:9.48% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 7.60% & 0.69\n",
      "for 2020-03-24, MAE is:1.08 & sMAPE is:14.80% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 7.68% & 0.70\n",
      "for 2020-03-25, MAE is:0.43 & sMAPE is:6.67% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 7.67% & 0.72\n",
      "for 2020-03-26, MAE is:0.36 & sMAPE is:5.35% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 7.64% & 0.72\n",
      "for 2020-03-27, MAE is:0.28 & sMAPE is:4.63% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 7.61% & 0.71\n",
      "for 2020-03-28, MAE is:0.58 & sMAPE is:11.06% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 7.65% & 0.71\n",
      "for 2020-03-29, MAE is:0.95 & sMAPE is:19.97% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 7.79% & 0.71\n",
      "for 2020-03-30, MAE is:2.40 & sMAPE is:31.91% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 8.06% & 0.72\n",
      "for 2020-03-31, MAE is:1.54 & sMAPE is:25.01% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 8.24% & 0.72\n",
      "for 2020-04-01, MAE is:1.09 & sMAPE is:25.31% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 8.43% & 0.72\n",
      "for 2020-04-02, MAE is:0.46 & sMAPE is:9.39% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 8.44% & 0.72\n",
      "for 2020-04-03, MAE is:0.97 & sMAPE is:21.66% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 8.58% & 0.71\n",
      "for 2020-04-04, MAE is:0.77 & sMAPE is:19.32% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 8.69% & 0.72\n",
      "for 2020-04-05, MAE is:1.62 & sMAPE is:47.15% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 9.09% & 0.73\n",
      "for 2020-04-06, MAE is:0.45 & sMAPE is:9.96% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 9.10% & 0.72\n",
      "for 2020-04-07, MAE is:0.38 & sMAPE is:8.16% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 9.09% & 0.72\n",
      "for 2020-04-08, MAE is:0.61 & sMAPE is:15.33% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 9.15% & 0.73\n",
      "for 2020-04-09, MAE is:2.17 & sMAPE is:62.65% & rMAE is:16.76 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 9.69% & 0.89\n",
      "for 2020-04-10, MAE is:1.08 & sMAPE is:24.50% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 9.84% & 0.89\n",
      "for 2020-04-11, MAE is:0.47 & sMAPE is:9.54% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 9.83% & 0.89\n",
      "for 2020-04-12, MAE is:0.58 & sMAPE is:15.78% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 9.89% & 0.89\n",
      "for 2020-04-13, MAE is:2.30 & sMAPE is:69.08% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 10.46% & 0.90\n",
      "for 2020-04-14, MAE is:0.57 & sMAPE is:11.28% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 10.47% & 0.91\n",
      "for 2020-04-15, MAE is:0.42 & sMAPE is:9.24% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 10.46% & 0.92\n",
      "for 2020-04-16, MAE is:0.74 & sMAPE is:20.19% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 10.55% & 0.93\n",
      "for 2020-04-17, MAE is:0.82 & sMAPE is:15.34% & rMAE is:8.87 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 10.59% & 1.00\n",
      "for 2020-04-18, MAE is:0.81 & sMAPE is:17.61% & rMAE is:5.99 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 10.66% & 1.05\n",
      "for 2020-04-19, MAE is:1.34 & sMAPE is:33.37% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 10.86% & 1.05\n",
      "for 2020-04-20, MAE is:0.99 & sMAPE is:20.68% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 10.95% & 1.04\n",
      "for 2020-04-21, MAE is:0.92 & sMAPE is:18.35% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 11.02% & 1.06\n",
      "for 2020-04-22, MAE is:0.80 & sMAPE is:14.72% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 11.05% & 1.06\n",
      "for 2020-04-23, MAE is:1.04 & sMAPE is:26.11% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 11.18% & 1.07\n",
      "for 2020-04-24, MAE is:0.40 & sMAPE is:7.82% & rMAE is:4.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 11.15% & 1.10\n",
      "for 2020-04-25, MAE is:0.91 & sMAPE is:21.18% & rMAE is:4.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 11.24% & 1.13\n",
      "for 2020-04-26, MAE is:0.58 & sMAPE is:12.86% & rMAE is:3.90 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 11.25% & 1.15\n",
      "for 2020-04-27, MAE is:1.06 & sMAPE is:18.16% & rMAE is:1.87 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 11.31% & 1.16\n",
      "for 2020-04-28, MAE is:0.73 & sMAPE is:14.99% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 11.34% & 1.15\n",
      "for 2020-04-29, MAE is:0.87 & sMAPE is:14.80% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 11.37% & 1.16\n",
      "for 2020-04-30, MAE is:0.48 & sMAPE is:10.11% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 11.36% & 1.16\n",
      "for 2020-05-01, MAE is:0.26 & sMAPE is:5.12% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 11.31% & 1.16\n",
      "for 2020-05-02, MAE is:0.40 & sMAPE is:6.99% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 11.27% & 1.15\n",
      "for 2020-05-03, MAE is:0.53 & sMAPE is:9.63% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.26% & 1.15\n",
      "for 2020-05-04, MAE is:0.52 & sMAPE is:8.22% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.24% & 1.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-05, MAE is:0.98 & sMAPE is:13.20% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.25% & 1.14\n",
      "for 2020-05-06, MAE is:0.57 & sMAPE is:8.28% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.23% & 1.13\n",
      "for 2020-05-07, MAE is:1.62 & sMAPE is:22.67% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.32% & 1.13\n",
      "for 2020-05-08, MAE is:0.70 & sMAPE is:8.55% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.30% & 1.12\n",
      "for 2020-05-09, MAE is:1.80 & sMAPE is:24.98% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 11.40% & 1.12\n",
      "for 2020-05-10, MAE is:0.65 & sMAPE is:9.09% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 11.38% & 1.11\n",
      "for 2020-05-11, MAE is:1.81 & sMAPE is:20.63% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 11.45% & 1.11\n",
      "for 2020-05-12, MAE is:1.04 & sMAPE is:10.59% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 11.45% & 1.11\n",
      "for 2020-05-13, MAE is:4.33 & sMAPE is:35.31% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 11.63% & 1.10\n",
      "for 2020-05-14, MAE is:1.67 & sMAPE is:12.18% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 11.63% & 1.10\n",
      "for 2020-05-15, MAE is:1.73 & sMAPE is:13.09% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 11.64% & 1.09\n",
      "for 2020-05-16, MAE is:2.13 & sMAPE is:20.56% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 11.71% & 1.10\n",
      "for 2020-05-17, MAE is:1.29 & sMAPE is:12.74% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 11.71% & 1.09\n",
      "for 2020-05-18, MAE is:1.29 & sMAPE is:10.57% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 11.71% & 1.09\n",
      "for 2020-05-19, MAE is:0.52 & sMAPE is:4.09% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 11.65% & 1.08\n",
      "for 2020-05-20, MAE is:2.57 & sMAPE is:22.09% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 11.73% & 1.08\n",
      "for 2020-05-21, MAE is:2.64 & sMAPE is:26.54% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 11.83% & 1.07\n",
      "for 2020-05-22, MAE is:2.29 & sMAPE is:27.17% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 11.94% & 1.07\n",
      "for 2020-05-23, MAE is:1.36 & sMAPE is:32.08% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 12.08% & 1.06\n",
      "for 2020-05-24, MAE is:1.83 & sMAPE is:69.15% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 12.47% & 1.06\n",
      "for 2020-05-25, MAE is:1.16 & sMAPE is:20.52% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 12.53% & 1.05\n",
      "for 2020-05-26, MAE is:2.94 & sMAPE is:97.34% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 13.10% & 1.04\n",
      "for 2020-05-27, MAE is:0.52 & sMAPE is:28.28% & rMAE is:0.06 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 13.20% & 1.04\n",
      "for 2020-05-28, MAE is:0.32 & sMAPE is:14.84% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 13.22% & 1.03\n",
      "for 2020-05-29, MAE is:0.60 & sMAPE is:29.04% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 13.32% & 1.03\n",
      "for 2020-05-30, MAE is:0.64 & sMAPE is:24.68% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 13.40% & 1.02\n",
      "for 2020-05-31, MAE is:0.68 & sMAPE is:50.43% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 13.64% & 1.02\n",
      "for 2020-06-01, MAE is:0.25 & sMAPE is:14.30% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 13.64% & 1.01\n",
      "for 2020-06-02, MAE is:1.36 & sMAPE is:57.52% & rMAE is:38.76 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 13.93% & 1.26\n",
      "for 2020-06-03, MAE is:0.41 & sMAPE is:25.62% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 14.00% & 1.26\n",
      "for 2020-06-04, MAE is:0.52 & sMAPE is:45.28% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 14.21% & 1.26\n",
      "for 2020-06-05, MAE is:1.09 & sMAPE is:48.66% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 14.42% & 1.26\n",
      "for 2020-06-06, MAE is:0.67 & sMAPE is:68.66% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 14.77% & 1.25\n",
      "for 2020-06-07, MAE is:0.26 & sMAPE is:16.78% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 14.78% & 1.25\n",
      "for 2020-06-08, MAE is:0.32 & sMAPE is:20.98% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 14.82% & 1.25\n",
      "for 2020-06-09, MAE is:0.69 & sMAPE is:37.53% & rMAE is:3.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 14.96% & 1.26\n",
      "for 2020-06-10, MAE is:0.33 & sMAPE is:20.77% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 15.00% & 1.25\n",
      "for 2020-06-11, MAE is:0.56 & sMAPE is:36.94% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 15.13% & 1.27\n",
      "for 2020-06-12, MAE is:0.31 & sMAPE is:21.36% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 15.17% & 1.27\n",
      "for 2020-06-13, MAE is:0.82 & sMAPE is:99.32% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 15.68% & 1.28\n",
      "for 2020-06-14, MAE is:1.09 & sMAPE is:128.16% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 16.36% & 1.28\n",
      "for 2020-06-15, MAE is:0.44 & sMAPE is:31.57% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 16.45% & 1.29\n",
      "for 2020-06-16, MAE is:0.67 & sMAPE is:60.93% & rMAE is:2.77 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 16.71% & 1.29\n",
      "for 2020-06-17, MAE is:0.49 & sMAPE is:34.63% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 16.82% & 1.30\n",
      "for 2020-06-18, MAE is:0.37 & sMAPE is:30.17% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 16.90% & 1.30\n",
      "for 2020-06-19, MAE is:0.53 & sMAPE is:53.16% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 17.11% & 1.31\n",
      "for 2020-06-20, MAE is:0.46 & sMAPE is:41.90% & rMAE is:4.61 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 17.25% & 1.33\n",
      "for 2020-06-21, MAE is:0.25 & sMAPE is:17.22% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 17.25% & 1.34\n",
      "for 2020-06-22, MAE is:0.91 & sMAPE is:56.61% & rMAE is:13.09 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 17.48% & 1.40\n",
      "for 2020-06-23, MAE is:0.26 & sMAPE is:16.29% & rMAE is:6.43 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 17.47% & 1.43\n",
      "for 2020-06-24, MAE is:0.72 & sMAPE is:72.56% & rMAE is:3.66 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 17.79% & 1.44\n",
      "for 2020-06-25, MAE is:0.28 & sMAPE is:22.45% & rMAE is:3.46 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 17.81% & 1.46\n",
      "for 2020-06-26, MAE is:0.46 & sMAPE is:40.54% & rMAE is:12.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 17.94% & 1.52\n",
      "for 2020-06-27, MAE is:0.42 & sMAPE is:51.90% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 18.13% & 1.51\n",
      "for 2020-06-28, MAE is:0.44 & sMAPE is:59.46% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 18.36% & 1.51\n",
      "for 2020-06-29, MAE is:0.55 & sMAPE is:76.80% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 18.68% & 1.51\n",
      "for 2020-06-30, MAE is:0.46 & sMAPE is:52.76% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 18.87% & 1.51\n",
      "for 2020-07-01, MAE is:0.31 & sMAPE is:28.94% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 18.92% & 1.51\n",
      "for 2020-07-02, MAE is:0.53 & sMAPE is:32.41% & rMAE is:5.88 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 19.00% & 1.53\n",
      "for 2020-07-03, MAE is:0.45 & sMAPE is:31.90% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 19.07% & 1.54\n",
      "for 2020-07-04, MAE is:0.75 & sMAPE is:84.21% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 19.42% & 1.54\n",
      "for 2020-07-05, MAE is:0.36 & sMAPE is:50.30% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 19.58% & 1.54\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-06, MAE is:1.47 & sMAPE is:103.58% & rMAE is:4.49 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 20.03% & 1.56\n",
      "for 2020-07-07, MAE is:0.93 & sMAPE is:73.12% & rMAE is:3.29 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 20.31% & 1.56\n",
      "for 2020-07-08, MAE is:0.35 & sMAPE is:24.39% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 20.33% & 1.56\n",
      "for 2020-07-09, MAE is:0.82 & sMAPE is:80.46% & rMAE is:4.18 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 20.65% & 1.58\n",
      "for 2020-07-10, MAE is:0.35 & sMAPE is:18.93% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 20.64% & 1.58\n",
      "for 2020-07-11, MAE is:0.77 & sMAPE is:74.91% & rMAE is:3.03 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 20.92% & 1.58\n",
      "for 2020-07-12, MAE is:0.57 & sMAPE is:49.21% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 21.06% & 1.58\n",
      "for 2020-07-13, MAE is:0.35 & sMAPE is:23.04% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 21.07% & 1.57\n",
      "for 2020-07-14, MAE is:1.43 & sMAPE is:164.27% & rMAE is:2.82 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 21.81% & 1.58\n",
      "for 2020-07-15, MAE is:0.26 & sMAPE is:15.30% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 21.77% & 1.58\n",
      "for 2020-07-16, MAE is:0.48 & sMAPE is:25.96% & rMAE is:17.98 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 21.79% & 1.66\n",
      "for 2020-07-17, MAE is:0.76 & sMAPE is:38.60% & rMAE is:19.85 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 21.88% & 1.75\n",
      "for 2020-07-18, MAE is:0.56 & sMAPE is:50.01% & rMAE is:6.32 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 22.02% & 1.78\n",
      "for 2020-07-19, MAE is:0.25 & sMAPE is:16.27% & rMAE is:5.12 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 21.99% & 1.79\n",
      "for 2020-07-20, MAE is:0.38 & sMAPE is:26.40% & rMAE is:5.31 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 22.01% & 1.81\n",
      "for 2020-07-21, MAE is:0.32 & sMAPE is:20.93% & rMAE is:6.90 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 22.01% & 1.84\n",
      "for 2020-07-22, MAE is:0.99 & sMAPE is:47.93% & rMAE is:26.33 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 22.13% & 1.96\n",
      "for 2020-07-23, MAE is:0.40 & sMAPE is:25.50% & rMAE is:12.98 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 22.15% & 2.01\n",
      "for 2020-07-24, MAE is:0.23 & sMAPE is:15.36% & rMAE is:14.44 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 22.12% & 2.07\n",
      "for 2020-07-25, MAE is:0.94 & sMAPE is:93.35% & rMAE is:13.95 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 22.46% & 2.13\n",
      "for 2020-07-26, MAE is:0.26 & sMAPE is:18.24% & rMAE is:3.93 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 22.44% & 2.14\n",
      "for 2020-07-27, MAE is:0.40 & sMAPE is:33.98% & rMAE is:45.82 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 22.50% & 2.34\n",
      "for 2020-07-28, MAE is:0.26 & sMAPE is:16.51% & rMAE is:2.80 ||| daily mean of MAE & sMAPE & rMAE till now are :0.93 & 22.47% & 2.35\n",
      "for 2020-07-29, MAE is:0.47 & sMAPE is:35.70% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :0.93 & 22.53% & 2.34\n",
      "for 2020-07-30, MAE is:0.31 & sMAPE is:31.44% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :0.93 & 22.57% & 2.34\n",
      "for 2020-07-31, MAE is:0.51 & sMAPE is:44.16% & rMAE is:2.42 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 22.67% & 2.34\n",
      "for 2020-08-01, MAE is:0.49 & sMAPE is:73.78% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 22.91% & 2.33\n",
      "for 2020-08-02, MAE is:0.50 & sMAPE is:36.11% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 22.97% & 2.32\n",
      "for 2020-08-03, MAE is:0.68 & sMAPE is:38.51% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 23.05% & 2.33\n",
      "for 2020-08-04, MAE is:0.48 & sMAPE is:29.59% & rMAE is:3.35 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 23.08% & 2.33\n",
      "for 2020-08-05, MAE is:0.31 & sMAPE is:31.07% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 23.11% & 2.33\n",
      "for 2020-08-06, MAE is:0.31 & sMAPE is:29.23% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 23.14% & 2.33\n",
      "for 2020-08-07, MAE is:0.44 & sMAPE is:43.66% & rMAE is:6.00 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 23.23% & 2.35\n",
      "for 2020-08-08, MAE is:1.24 & sMAPE is:159.11% & rMAE is:4.94 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 23.85% & 2.36\n",
      "for 2020-08-09, MAE is:0.48 & sMAPE is:80.43% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 24.10% & 2.36\n",
      "for 2020-08-10, MAE is:0.69 & sMAPE is:50.47% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 24.22% & 2.36\n",
      "for 2020-08-11, MAE is:0.48 & sMAPE is:41.17% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 24.30% & 2.36\n",
      "for 2020-08-12, MAE is:0.27 & sMAPE is:19.14% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.27% & 2.35\n",
      "for 2020-08-13, MAE is:0.86 & sMAPE is:39.87% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.34% & 2.35\n",
      "for 2020-08-14, MAE is:0.66 & sMAPE is:46.05% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.44% & 2.35\n",
      "for 2020-08-15, MAE is:0.49 & sMAPE is:44.18% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.53% & 2.35\n",
      "for 2020-08-16, MAE is:0.28 & sMAPE is:15.86% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.49% & 2.34\n",
      "for 2020-08-17, MAE is:1.01 & sMAPE is:40.71% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.56% & 2.33\n",
      "for 2020-08-18, MAE is:0.76 & sMAPE is:31.62% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.59% & 2.33\n",
      "for 2020-08-19, MAE is:0.38 & sMAPE is:10.36% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.53% & 2.32\n",
      "for 2020-08-20, MAE is:1.11 & sMAPE is:37.72% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.58% & 2.31\n",
      "for 2020-08-21, MAE is:1.18 & sMAPE is:35.97% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.63% & 2.30\n",
      "for 2020-08-22, MAE is:0.70 & sMAPE is:23.95% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.63% & 2.30\n",
      "for 2020-08-23, MAE is:0.55 & sMAPE is:18.66% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.60% & 2.29\n",
      "for 2020-08-24, MAE is:1.37 & sMAPE is:48.53% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.71% & 2.28\n",
      "for 2020-08-25, MAE is:1.50 & sMAPE is:46.67% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.80% & 2.27\n",
      "for 2020-08-26, MAE is:0.52 & sMAPE is:13.25% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.75% & 2.27\n",
      "for 2020-08-27, MAE is:2.05 & sMAPE is:45.23% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :0.90 & 24.83% & 2.26\n",
      "for 2020-08-28, MAE is:2.46 & sMAPE is:34.90% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :0.91 & 24.88% & 2.26\n",
      "for 2020-08-29, MAE is:3.07 & sMAPE is:37.19% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 24.93% & 2.25\n",
      "for 2020-08-30, MAE is:2.26 & sMAPE is:20.50% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :0.92 & 24.91% & 2.24\n",
      "for 2020-08-31, MAE is:2.72 & sMAPE is:20.06% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :0.93 & 24.89% & 2.23\n",
      "for 2020-09-01, MAE is:3.45 & sMAPE is:21.63% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.88% & 2.23\n",
      "for 2020-09-02, MAE is:1.40 & sMAPE is:8.16% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.81% & 2.22\n",
      "for 2020-09-03, MAE is:0.44 & sMAPE is:2.59% & rMAE is:0.04 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.72% & 2.21\n",
      "for 2020-09-04, MAE is:1.01 & sMAPE is:5.98% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.64% & 2.20\n",
      "for 2020-09-05, MAE is:1.30 & sMAPE is:8.82% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.58% & 2.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-06, MAE is:0.54 & sMAPE is:4.16% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.50% & 2.19\n",
      "for 2020-09-07, MAE is:1.39 & sMAPE is:10.36% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.44% & 2.18\n",
      "for 2020-09-08, MAE is:1.14 & sMAPE is:9.37% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.38% & 2.17\n",
      "for 2020-09-09, MAE is:0.49 & sMAPE is:4.09% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.30% & 2.16\n",
      "for 2020-09-10, MAE is:0.42 & sMAPE is:3.68% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.22% & 2.16\n",
      "for 2020-09-11, MAE is:0.75 & sMAPE is:6.64% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.15% & 2.15\n",
      "for 2020-09-12, MAE is:0.88 & sMAPE is:7.84% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.09% & 2.14\n",
      "for 2020-09-13, MAE is:1.57 & sMAPE is:17.27% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 24.06% & 2.14\n",
      "for 2020-09-14, MAE is:0.72 & sMAPE is:6.26% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 23.99% & 2.13\n",
      "for 2020-09-15, MAE is:0.61 & sMAPE is:5.28% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 23.92% & 2.13\n",
      "for 2020-09-16, MAE is:0.62 & sMAPE is:5.25% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 23.85% & 2.13\n",
      "for 2020-09-17, MAE is:1.73 & sMAPE is:15.11% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :0.94 & 23.81% & 2.12\n",
      "for 2020-09-18, MAE is:2.31 & sMAPE is:23.57% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.81% & 2.12\n",
      "for 2020-09-19, MAE is:1.77 & sMAPE is:23.06% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.81% & 2.11\n",
      "for 2020-09-20, MAE is:1.17 & sMAPE is:17.42% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.79% & 2.10\n",
      "for 2020-09-21, MAE is:0.58 & sMAPE is:8.82% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.73% & 2.10\n",
      "for 2020-09-22, MAE is:0.41 & sMAPE is:6.62% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.67% & 2.09\n",
      "for 2020-09-23, MAE is:0.86 & sMAPE is:13.96% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.63% & 2.08\n",
      "for 2020-09-24, MAE is:1.35 & sMAPE is:23.50% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.63% & 2.08\n",
      "for 2020-09-25, MAE is:0.54 & sMAPE is:12.51% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.59% & 2.07\n",
      "for 2020-09-26, MAE is:1.69 & sMAPE is:44.69% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.67% & 2.06\n",
      "for 2020-09-27, MAE is:0.58 & sMAPE is:24.13% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.67% & 2.05\n",
      "for 2020-09-28, MAE is:1.19 & sMAPE is:46.27% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.75% & 2.05\n",
      "for 2020-09-29, MAE is:0.36 & sMAPE is:17.56% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.73% & 2.04\n",
      "for 2020-09-30, MAE is:0.55 & sMAPE is:42.41% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.80% & 2.03\n",
      "for 2020-10-01, MAE is:0.77 & sMAPE is:42.37% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.86% & 2.03\n",
      "for 2020-10-02, MAE is:1.25 & sMAPE is:47.40% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.95% & 2.02\n",
      "for 2020-10-03, MAE is:0.95 & sMAPE is:32.09% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.98% & 2.02\n",
      "for 2020-10-04, MAE is:1.16 & sMAPE is:32.74% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 24.01% & 2.02\n",
      "for 2020-10-05, MAE is:0.95 & sMAPE is:16.04% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.98% & 2.01\n",
      "for 2020-10-06, MAE is:0.63 & sMAPE is:12.29% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.94% & 2.00\n",
      "for 2020-10-07, MAE is:1.35 & sMAPE is:24.51% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.94% & 2.00\n",
      "for 2020-10-08, MAE is:1.98 & sMAPE is:31.37% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :0.95 & 23.97% & 1.99\n",
      "for 2020-10-09, MAE is:2.77 & sMAPE is:32.55% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 24.00% & 1.99\n",
      "for 2020-10-10, MAE is:3.85 & sMAPE is:36.93% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :0.97 & 24.04% & 1.98\n",
      "for 2020-10-11, MAE is:4.96 & sMAPE is:35.36% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 24.08% & 1.98\n",
      "for 2020-10-12, MAE is:0.65 & sMAPE is:3.79% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 24.01% & 1.97\n",
      "for 2020-10-13, MAE is:2.13 & sMAPE is:12.25% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 23.97% & 1.96\n",
      "for 2020-10-14, MAE is:0.91 & sMAPE is:4.67% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :0.98 & 23.90% & 1.96\n",
      "for 2020-10-15, MAE is:1.38 & sMAPE is:7.35% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.85% & 1.95\n",
      "for 2020-10-16, MAE is:1.01 & sMAPE is:5.07% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.78% & 1.94\n",
      "for 2020-10-17, MAE is:0.83 & sMAPE is:4.43% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.72% & 1.94\n",
      "for 2020-10-18, MAE is:1.54 & sMAPE is:8.68% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.66% & 1.93\n",
      "for 2020-10-19, MAE is:0.53 & sMAPE is:2.68% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.59% & 1.93\n",
      "for 2020-10-20, MAE is:0.94 & sMAPE is:4.79% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.53% & 1.92\n",
      "for 2020-10-21, MAE is:2.44 & sMAPE is:13.06% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.49% & 1.92\n",
      "for 2020-10-22, MAE is:1.56 & sMAPE is:11.61% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :0.99 & 23.45% & 1.92\n",
      "for 2020-10-23, MAE is:3.05 & sMAPE is:16.73% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 23.43% & 1.91\n",
      "for 2020-10-24, MAE is:0.63 & sMAPE is:4.34% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 23.37% & 1.91\n",
      "for 2020-10-25, MAE is:2.93 & sMAPE is:28.05% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.00 & 23.38% & 1.90\n",
      "for 2020-10-26, MAE is:1.84 & sMAPE is:13.41% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 23.35% & 1.90\n",
      "for 2020-10-27, MAE is:1.32 & sMAPE is:10.64% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 23.31% & 1.89\n",
      "for 2020-10-28, MAE is:1.97 & sMAPE is:23.87% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 23.31% & 1.89\n",
      "for 2020-10-29, MAE is:1.21 & sMAPE is:12.44% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 23.27% & 1.88\n",
      "for 2020-10-30, MAE is:1.79 & sMAPE is:15.78% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 23.25% & 1.87\n",
      "for 2020-10-31, MAE is:1.13 & sMAPE is:13.37% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :1.01 & 23.22% & 1.87\n",
      "for 2020-11-01, MAE is:1.52 & sMAPE is:29.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 23.24% & 1.86\n",
      "for 2020-11-02, MAE is:1.76 & sMAPE is:52.09% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 23.33% & 1.86\n",
      "for 2020-11-03, MAE is:1.51 & sMAPE is:38.89% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :1.02 & 23.38% & 1.85\n",
      "for 2020-11-04, MAE is:2.99 & sMAPE is:58.05% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 23.49% & 1.85\n",
      "for 2020-11-05, MAE is:2.27 & sMAPE is:66.41% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 23.63% & 1.84\n",
      "for 2020-11-06, MAE is:2.51 & sMAPE is:53.13% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.73% & 1.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-07, MAE is:0.77 & sMAPE is:20.53% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 23.72% & 1.83\n",
      "for 2020-11-08, MAE is:1.37 & sMAPE is:28.28% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.73% & 1.83\n",
      "for 2020-11-09, MAE is:1.09 & sMAPE is:18.69% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.71% & 1.83\n",
      "for 2020-11-10, MAE is:1.21 & sMAPE is:16.15% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.69% & 1.82\n",
      "for 2020-11-11, MAE is:1.34 & sMAPE is:15.25% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.66% & 1.82\n",
      "for 2020-11-12, MAE is:0.93 & sMAPE is:13.27% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.63% & 1.81\n",
      "for 2020-11-13, MAE is:2.93 & sMAPE is:53.98% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.73% & 1.81\n",
      "for 2020-11-14, MAE is:0.75 & sMAPE is:23.90% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.73% & 1.81\n",
      "for 2020-11-15, MAE is:1.07 & sMAPE is:49.34% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.81% & 1.80\n",
      "for 2020-11-16, MAE is:1.71 & sMAPE is:79.01% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 23.98% & 1.80\n",
      "for 2020-11-17, MAE is:1.14 & sMAPE is:66.65% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 24.11% & 1.79\n",
      "for 2020-11-18, MAE is:1.33 & sMAPE is:80.55% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 24.29% & 1.79\n",
      "for 2020-11-19, MAE is:0.26 & sMAPE is:54.27% & rMAE is:0.05 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 24.38% & 1.78\n",
      "for 2020-11-20, MAE is:0.49 & sMAPE is:37.35% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 24.42% & 1.78\n",
      "for 2020-11-21, MAE is:0.39 & sMAPE is:35.80% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 24.45% & 1.77\n",
      "for 2020-11-22, MAE is:1.21 & sMAPE is:182.32% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 24.94% & 1.77\n",
      "for 2020-11-23, MAE is:1.53 & sMAPE is:59.36% & rMAE is:2.55 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 25.04% & 1.78\n",
      "for 2020-11-24, MAE is:0.63 & sMAPE is:37.76% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 25.08% & 1.77\n",
      "for 2020-11-25, MAE is:0.66 & sMAPE is:28.67% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 25.09% & 1.77\n",
      "for 2020-11-26, MAE is:1.35 & sMAPE is:43.81% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :1.04 & 25.15% & 1.77\n",
      "for 2020-11-27, MAE is:3.61 & sMAPE is:65.04% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 25.27% & 1.76\n",
      "for 2020-11-28, MAE is:6.22 & sMAPE is:79.61% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :1.06 & 25.43% & 1.76\n",
      "for 2020-11-29, MAE is:3.92 & sMAPE is:34.91% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 25.46% & 1.75\n",
      "for 2020-11-30, MAE is:0.79 & sMAPE is:5.87% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 25.40% & 1.75\n",
      "for 2020-12-01, MAE is:1.22 & sMAPE is:8.68% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 25.35% & 1.74\n",
      "for 2020-12-02, MAE is:1.34 & sMAPE is:8.77% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :1.07 & 25.30% & 1.74\n",
      "for 2020-12-03, MAE is:3.52 & sMAPE is:22.71% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 25.29% & 1.74\n",
      "for 2020-12-04, MAE is:2.85 & sMAPE is:16.74% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :1.08 & 25.27% & 1.73\n",
      "for 2020-12-05, MAE is:1.36 & sMAPE is:7.09% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 25.21% & 1.73\n",
      "for 2020-12-06, MAE is:1.01 & sMAPE is:5.31% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 25.16% & 1.72\n",
      "for 2020-12-07, MAE is:1.63 & sMAPE is:10.39% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 25.11% & 1.72\n",
      "for 2020-12-08, MAE is:2.95 & sMAPE is:15.07% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :1.09 & 25.08% & 1.71\n",
      "for 2020-12-09, MAE is:10.91 & sMAPE is:23.82% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :1.12 & 25.08% & 1.71\n",
      "for 2020-12-10, MAE is:6.92 & sMAPE is:24.55% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 25.08% & 1.71\n",
      "for 2020-12-11, MAE is:1.97 & sMAPE is:8.32% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 25.03% & 1.71\n",
      "for 2020-12-12, MAE is:1.89 & sMAPE is:8.66% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.98% & 1.70\n",
      "for 2020-12-13, MAE is:0.67 & sMAPE is:2.91% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.92% & 1.70\n",
      "for 2020-12-14, MAE is:0.50 & sMAPE is:2.21% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.85% & 1.69\n",
      "for 2020-12-15, MAE is:0.77 & sMAPE is:3.43% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.79% & 1.69\n",
      "for 2020-12-16, MAE is:0.94 & sMAPE is:4.02% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.73% & 1.69\n",
      "for 2020-12-17, MAE is:0.83 & sMAPE is:3.93% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.68% & 1.68\n",
      "for 2020-12-18, MAE is:1.47 & sMAPE is:7.21% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.63% & 1.68\n",
      "for 2020-12-19, MAE is:1.41 & sMAPE is:8.07% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.58% & 1.68\n",
      "for 2020-12-20, MAE is:2.55 & sMAPE is:16.70% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.14 & 24.56% & 1.67\n",
      "for 2020-12-21, MAE is:2.75 & sMAPE is:16.52% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :1.15 & 24.53% & 1.67\n",
      "for 2020-12-22, MAE is:3.03 & sMAPE is:23.65% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :1.15 & 24.53% & 1.66\n",
      "for 2020-12-23, MAE is:1.72 & sMAPE is:9.16% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :1.15 & 24.49% & 1.66\n",
      "for 2020-12-24, MAE is:2.74 & sMAPE is:17.82% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :1.16 & 24.47% & 1.66\n",
      "for 2020-12-25, MAE is:3.04 & sMAPE is:16.35% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :1.16 & 24.45% & 1.66\n",
      "for 2020-12-26, MAE is:3.09 & sMAPE is:18.24% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :1.17 & 24.43% & 1.65\n",
      "for 2020-12-27, MAE is:4.43 & sMAPE is:49.19% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :1.18 & 24.50% & 1.65\n",
      "for 2020-12-28, MAE is:6.65 & sMAPE is:41.69% & rMAE is:3.58 ||| daily mean of MAE & sMAPE & rMAE till now are :1.19 & 24.55% & 1.66\n",
      "for 2020-12-29, MAE is:1.72 & sMAPE is:8.43% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :1.19 & 24.50% & 1.65\n",
      "for 2020-12-30, MAE is:2.82 & sMAPE is:12.65% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :1.20 & 24.47% & 1.65\n",
      "for 2020-12-31, MAE is:2.31 & sMAPE is:9.45% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :1.20 & 24.43% & 1.65\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:34:03,314]\u001b[0m A new study created in RDB with name: NO_5_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:34:21,588]\u001b[0m Trial 2 finished with value: 6.1978980620768525 and parameters: {'n_hidden': 4, 'learning_rate': 0.004735856862720095, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3369191679670255, 'dropout_rate_Layer_2': 0.3844863086064964, 'dropout_rate_Layer_3': 0.3124646418753077, 'dropout_rate_Layer_4': 0.2697423657057476, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0002319785504455829, 'l1_Layer_2': 0.00026617236699307006, 'l1_Layer_3': 0.011837862825203731, 'l1_Layer_4': 1.6304720608086326e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 125, 'n_units_Layer_3': 135, 'n_units_Layer_4': 75}. Best is trial 2 with value: 6.1978980620768525.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 82.81% | rMAE for Validation Set is: 2.04\n",
      "MAE for Test Set is: 70.60 | sMAPE for Test Set is: 170.41% | rMAE for Test Set is: 4.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:34:25,530]\u001b[0m Trial 1 finished with value: 4.402403348900737 and parameters: {'n_hidden': 3, 'learning_rate': 0.001222429405187489, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12139142399889638, 'dropout_rate_Layer_2': 0.1928608305764831, 'dropout_rate_Layer_3': 0.11289204834522325, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.028327376284663145, 'l1_Layer_2': 0.0004695556487965469, 'l1_Layer_3': 1.0303313026960117e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215}. Best is trial 1 with value: 4.402403348900737.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.40 | sMAPE for Validation Set is: 75.62% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 26.87 | sMAPE for Test Set is: 31.77% | rMAE for Test Set is: 1.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:34:27,599]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:34:32,595]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:34:35,365]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:34:38,989]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:34:49,148]\u001b[0m Trial 6 finished with value: 17.232498951693213 and parameters: {'n_hidden': 4, 'learning_rate': 0.0571826639724914, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025902390288252343, 'dropout_rate_Layer_2': 0.06624217258876648, 'dropout_rate_Layer_3': 0.06946166906512996, 'dropout_rate_Layer_4': 0.26074206890931545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.006038288815655014, 'l1_Layer_2': 0.04685524077163858, 'l1_Layer_3': 0.00020939930359739544, 'l1_Layer_4': 0.00029809459547479854, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280, 'n_units_Layer_4': 225}. Best is trial 1 with value: 4.402403348900737.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.23 | sMAPE for Validation Set is: 112.21% | rMAE for Validation Set is: 5.68\n",
      "MAE for Test Set is: 28.10 | sMAPE for Test Set is: 33.74% | rMAE for Test Set is: 1.65\n",
      "MAE for Validation Set is: 4.29 | sMAPE for Validation Set is: 97.96% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 35.19 | sMAPE for Test Set is: 47.02% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:34:49,931]\u001b[0m Trial 9 finished with value: 4.292636497622847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008017248954040079, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08350208706352978, 'dropout_rate_Layer_2': 0.08465118477368457, 'dropout_rate_Layer_3': 0.3775003090106943, 'dropout_rate_Layer_4': 0.16635856331253548, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'relu', 'l1_Layer_1': 3.7792956124165545e-05, 'l1_Layer_2': 0.00159808341573651, 'l1_Layer_3': 0.0010129960980643931, 'l1_Layer_4': 0.0002627008503681065, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 100, 'n_units_Layer_4': 80}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:34:57,684]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:03,688]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:07,545]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:10,961]\u001b[0m Trial 3 finished with value: 17.104481812222975 and parameters: {'n_hidden': 3, 'learning_rate': 0.07541027446089553, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10263223354756566, 'dropout_rate_Layer_2': 0.05952771687881571, 'dropout_rate_Layer_3': 0.19943110937782837, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02582324783983058, 'l1_Layer_2': 0.00021003861367847578, 'l1_Layer_3': 0.01825389031150225, 'n_units_Layer_1': 255, 'n_units_Layer_2': 165, 'n_units_Layer_3': 210}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 17.10 | sMAPE for Validation Set is: 109.09% | rMAE for Validation Set is: 5.63\n",
      "MAE for Test Set is: 36.15 | sMAPE for Test Set is: 51.66% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:35:14,197]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:14,439]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:14,616]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:16,561]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:23,586]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:23,690]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 78.12% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 69.29 | sMAPE for Test Set is: 163.22% | rMAE for Test Set is: 4.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:35:26,034]\u001b[0m Trial 16 finished with value: 5.911966498818459 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007669020191545619, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2810569924594728, 'dropout_rate_Layer_2': 0.06008718834706209, 'dropout_rate_Layer_3': 0.07497817387697396, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007374643489046865, 'l1_Layer_2': 0.0024737810570179715, 'l1_Layer_3': 0.015731684382962706, 'n_units_Layer_1': 85, 'n_units_Layer_2': 50, 'n_units_Layer_3': 115}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:31,196]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:31,711]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:34,065]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:38,099]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:38,234]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:40,988]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:45,767]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:49,632]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:35:57,272]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:01,123]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:05,716]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:09,755]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:16,815]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:20,491]\u001b[0m Trial 28 finished with value: 6.356998690801466 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011791662120427373, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12709514887703088, 'dropout_rate_Layer_2': 0.13494486533507502, 'dropout_rate_Layer_3': 0.04522943434476337, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00016672255730766953, 'l1_Layer_2': 0.003079227591780165, 'l1_Layer_3': 0.00011671292704638341, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 90}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 94.44% | rMAE for Validation Set is: 2.09\n",
      "MAE for Test Set is: 60.11 | sMAPE for Test Set is: 123.75% | rMAE for Test Set is: 3.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:36:29,263]\u001b[0m Trial 24 finished with value: 5.956104746608683 and parameters: {'n_hidden': 3, 'learning_rate': 0.001200605201814724, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3027394298913007, 'dropout_rate_Layer_2': 0.11501958003915927, 'dropout_rate_Layer_3': 0.06277483582429598, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0359684118055623, 'l1_Layer_2': 0.017463061785481206, 'l1_Layer_3': 6.103574579512e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 77.19% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 66.13 | sMAPE for Test Set is: 149.95% | rMAE for Test Set is: 3.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:36:32,514]\u001b[0m Trial 34 finished with value: 6.129877744504668 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018399440688319127, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03182578175498074, 'dropout_rate_Layer_2': 0.3928284006400109, 'dropout_rate_Layer_3': 0.061926329619587245, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.8940797996836046e-05, 'l1_Layer_2': 0.0002933168336408209, 'l1_Layer_3': 0.0019059419945557706, 'n_units_Layer_1': 95, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 75.83% | rMAE for Validation Set is: 2.02\n",
      "MAE for Test Set is: 61.69 | sMAPE for Test Set is: 127.75% | rMAE for Test Set is: 3.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:36:35,852]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:38,191]\u001b[0m Trial 36 finished with value: 5.871414949911663 and parameters: {'n_hidden': 4, 'learning_rate': 0.0023030231008084982, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2209495712074646, 'dropout_rate_Layer_2': 0.22937216262053473, 'dropout_rate_Layer_3': 0.1791542297300764, 'dropout_rate_Layer_4': 0.03450107042892064, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 9.273104734713814e-05, 'l1_Layer_2': 0.00598475454234487, 'l1_Layer_3': 0.01180915704802172, 'l1_Layer_4': 0.01947341527974511, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210, 'n_units_Layer_4': 160}. Best is trial 9 with value: 4.292636497622847.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 76.79% | rMAE for Validation Set is: 1.93\n",
      "MAE for Test Set is: 68.62 | sMAPE for Test Set is: 159.48% | rMAE for Test Set is: 4.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:36:40,134]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:42,707]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:44,872]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:48,781]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:36:56,676]\u001b[0m Trial 35 finished with value: 3.5192966731692366 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011672507661581034, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39645620421369254, 'dropout_rate_Layer_2': 0.2550407847373304, 'dropout_rate_Layer_3': 0.3700750248239731, 'dropout_rate_Layer_4': 0.0058758711925827045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0013667602318726026, 'l1_Layer_2': 0.002886789549062205, 'l1_Layer_3': 0.012868661395652039, 'l1_Layer_4': 2.0182644808300945e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 105, 'n_units_Layer_4': 50}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 72.82% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 36.57 | sMAPE for Test Set is: 54.08% | rMAE for Test Set is: 2.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:36:59,987]\u001b[0m Trial 41 finished with value: 9.683921297116756 and parameters: {'n_hidden': 4, 'learning_rate': 0.000597759574672941, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11568093113911353, 'dropout_rate_Layer_2': 0.22829652231751177, 'dropout_rate_Layer_3': 0.3350889920313786, 'dropout_rate_Layer_4': 0.367302814298228, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.5988141231068656e-05, 'l1_Layer_2': 0.007630247356936722, 'l1_Layer_3': 0.09692582716913357, 'l1_Layer_4': 0.0007065216624756545, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190, 'n_units_Layer_4': 150}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.68 | sMAPE for Validation Set is: 91.66% | rMAE for Validation Set is: 3.19\n",
      "MAE for Test Set is: 29.29 | sMAPE for Test Set is: 35.89% | rMAE for Test Set is: 1.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:37:00,261]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:04,938]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:06,625]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:09,198]\u001b[0m Trial 44 finished with value: 4.231338459103885 and parameters: {'n_hidden': 3, 'learning_rate': 0.001601266555824602, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22229856444615376, 'dropout_rate_Layer_2': 0.029919309228642263, 'dropout_rate_Layer_3': 0.0013201437132755733, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027479087652498396, 'l1_Layer_2': 0.010287125140623818, 'l1_Layer_3': 2.0632632165715762e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 100}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.23 | sMAPE for Validation Set is: 61.26% | rMAE for Validation Set is: 1.39\n",
      "MAE for Test Set is: 54.28 | sMAPE for Test Set is: 101.23% | rMAE for Test Set is: 3.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:37:10,711]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:14,801]\u001b[0m Trial 42 finished with value: 9.40786329257898 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005437436175907631, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11786652753382695, 'dropout_rate_Layer_2': 0.21977174060739096, 'dropout_rate_Layer_3': 0.3379876274168302, 'dropout_rate_Layer_4': 0.376851860374845, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.3987108797095167e-05, 'l1_Layer_2': 0.00520929929820515, 'l1_Layer_3': 0.006277399678598996, 'l1_Layer_4': 0.0006612638955562726, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 205, 'n_units_Layer_4': 145}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.41 | sMAPE for Validation Set is: 90.38% | rMAE for Validation Set is: 3.10\n",
      "MAE for Test Set is: 27.32 | sMAPE for Test Set is: 32.77% | rMAE for Test Set is: 1.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:37:16,734]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:18,739]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:19,141]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:22,368]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:27,197]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:29,050]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:29,383]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:30,440]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:36,532]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:37,938]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:40,130]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:40,477]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:41,231]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:44,335]\u001b[0m Trial 57 finished with value: 5.814182876369525 and parameters: {'n_hidden': 3, 'learning_rate': 0.004383376744427095, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22601675865836118, 'dropout_rate_Layer_2': 0.05336460095589559, 'dropout_rate_Layer_3': 0.1374424057490017, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.2165949507824484e-05, 'l1_Layer_2': 0.003691342096726955, 'l1_Layer_3': 0.0005443064148205906, 'n_units_Layer_1': 135, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 74.85% | rMAE for Validation Set is: 1.92\n",
      "MAE for Test Set is: 62.66 | sMAPE for Test Set is: 132.64% | rMAE for Test Set is: 3.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:37:47,519]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:48,653]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:53,451]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:56,174]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:56,412]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:56,568]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:37:56,814]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:02,539]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:04,718]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:05,571]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:09,298]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:09,613]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:10,313]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:15,825]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:16,599]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:16,753]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:16,783]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:21,174]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:24,243]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:24,781]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:24,865]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:28,098]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:33,882]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:34,347]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:36,979]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:38,716]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:39,080]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:41,208]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:42,800]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:45,863]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:49,368]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:49,609]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:38:56,539]\u001b[0m Trial 96 finished with value: 5.99680240648592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010458011807291405, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2350643070780935, 'dropout_rate_Layer_2': 0.17448165078468192, 'dropout_rate_Layer_3': 0.3991623993473628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0023616049471610035, 'l1_Layer_2': 0.0004223503522665134, 'l1_Layer_3': 1.7896037552515428e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 50, 'n_units_Layer_3': 130}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 77.14% | rMAE for Validation Set is: 1.98\n",
      "MAE for Test Set is: 67.86 | sMAPE for Test Set is: 155.58% | rMAE for Test Set is: 4.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:05,603]\u001b[0m Trial 93 finished with value: 9.512773165791371 and parameters: {'n_hidden': 4, 'learning_rate': 0.017519672597118882, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0020498817327926633, 'dropout_rate_Layer_2': 0.30236661288048844, 'dropout_rate_Layer_3': 0.3998235341968196, 'dropout_rate_Layer_4': 0.1883188399342945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0016809796400715942, 'l1_Layer_2': 0.032915152204866106, 'l1_Layer_3': 0.0004838499809709791, 'l1_Layer_4': 0.01563591564282108, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 170, 'n_units_Layer_4': 105}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.51 | sMAPE for Validation Set is: 90.33% | rMAE for Validation Set is: 3.13\n",
      "MAE for Test Set is: 26.35 | sMAPE for Test Set is: 30.92% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:05,850]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:09,210]\u001b[0m Trial 98 finished with value: 4.13279896251539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027051358870299916, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16066061657205638, 'dropout_rate_Layer_2': 0.07980000177660254, 'dropout_rate_Layer_3': 0.034567600936462155, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010227803391739836, 'l1_Layer_2': 0.0007087851757143305, 'l1_Layer_3': 0.0004602090812657307, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 85}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.13 | sMAPE for Validation Set is: 61.34% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 58.19 | sMAPE for Test Set is: 117.44% | rMAE for Test Set is: 3.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:13,509]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:14,125]\u001b[0m Trial 99 finished with value: 4.112957574974334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024387223067242223, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1693319943434519, 'dropout_rate_Layer_2': 0.07938742400202664, 'dropout_rate_Layer_3': 0.03577560649324296, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.210278860543729e-05, 'l1_Layer_2': 0.0006426295933671515, 'l1_Layer_3': 0.0005858341280031397, 'n_units_Layer_1': 155, 'n_units_Layer_2': 130, 'n_units_Layer_3': 80}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.11 | sMAPE for Validation Set is: 62.69% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 24.09 | sMAPE for Test Set is: 29.52% | rMAE for Test Set is: 1.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:18,206]\u001b[0m Trial 100 finished with value: 6.8905659551585074 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009273030951905314, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2484668861612808, 'dropout_rate_Layer_2': 0.17355382967585675, 'dropout_rate_Layer_3': 0.3448054225242133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006957708206806981, 'l1_Layer_2': 0.00033175282358654374, 'l1_Layer_3': 1.8685427081341027e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 79.93% | rMAE for Validation Set is: 2.27\n",
      "MAE for Test Set is: 64.00 | sMAPE for Test Set is: 136.85% | rMAE for Test Set is: 3.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:23,849]\u001b[0m Trial 103 finished with value: 6.453234205965434 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010078347674761046, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2527984054423617, 'dropout_rate_Layer_2': 0.16863168850609297, 'dropout_rate_Layer_3': 0.3492172169090604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.006617267025118553, 'l1_Layer_2': 0.0003701504581083421, 'l1_Layer_3': 1.0720813897324075e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:23,855]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 78.13% | rMAE for Validation Set is: 2.13\n",
      "MAE for Test Set is: 65.25 | sMAPE for Test Set is: 142.66% | rMAE for Test Set is: 3.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:24,172]\u001b[0m Trial 104 finished with value: 6.079702726862668 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008785902155750251, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2511543703118106, 'dropout_rate_Layer_2': 0.16134275221384664, 'dropout_rate_Layer_3': 0.34310646477236895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0019503804459359258, 'l1_Layer_2': 0.000428174212508597, 'l1_Layer_3': 1.0009284928058168e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.08 | sMAPE for Validation Set is: 76.80% | rMAE for Validation Set is: 2.00\n",
      "MAE for Test Set is: 66.81 | sMAPE for Test Set is: 150.22% | rMAE for Test Set is: 3.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:39:30,741]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:33,797]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:34,180]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:34,876]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:37,348]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:41,633]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:44,835]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:45,135]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:45,189]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:47,041]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:52,823]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:55,491]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:55,556]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:56,124]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:39:58,795]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:03,417]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:08,219]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:08,725]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:10,589]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:11,376]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:18,006]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:21,604]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:21,781]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:25,456]\u001b[0m Trial 125 finished with value: 4.943383560642503 and parameters: {'n_hidden': 3, 'learning_rate': 0.005050934913720316, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22164939246631832, 'dropout_rate_Layer_2': 0.07156614981616741, 'dropout_rate_Layer_3': 0.14560807258529762, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.853347781492473e-05, 'l1_Layer_2': 0.001457259827349827, 'l1_Layer_3': 0.0017069722758641286, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60}. Best is trial 35 with value: 3.5192966731692366.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.94 | sMAPE for Validation Set is: 65.35% | rMAE for Validation Set is: 1.63\n",
      "MAE for Test Set is: 64.64 | sMAPE for Test Set is: 141.96% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:40:25,686]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:29,597]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:32,899]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:33,279]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:35,262]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:39,259]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:39,927]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:43,999]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:47,739]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:50,629]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:50,955]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:54,054]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:40:59,337]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:01,075]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:04,425]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:06,511]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:11,074]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:14,756]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:17,264]\u001b[0m Trial 137 finished with value: 2.7246759156529947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007345791507712035, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3334601653406619, 'dropout_rate_Layer_2': 0.11298596197966583, 'dropout_rate_Layer_3': 0.3760410310719895, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02008838854601424, 'l1_Layer_2': 0.00012141066145519506, 'l1_Layer_3': 0.0007464580652244082, 'n_units_Layer_1': 150, 'n_units_Layer_2': 235, 'n_units_Layer_3': 180}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 52.05% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 12.46 | sMAPE for Test Set is: 14.12% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:41:17,470]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:19,280]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:20,821]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:28,578]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:28,876]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:35,521]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:35,561]\u001b[0m Trial 152 finished with value: 5.930157342154115 and parameters: {'n_hidden': 4, 'learning_rate': 0.004031963612682262, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33270556377501753, 'dropout_rate_Layer_2': 0.07670533968371435, 'dropout_rate_Layer_3': 0.2325498384713231, 'dropout_rate_Layer_4': 0.1967308057880548, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.020526245027150867, 'l1_Layer_2': 0.00012576987723153497, 'l1_Layer_3': 0.00023761741589938047, 'l1_Layer_4': 0.001417404559796872, 'n_units_Layer_1': 90, 'n_units_Layer_2': 195, 'n_units_Layer_3': 115, 'n_units_Layer_4': 130}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 75.44% | rMAE for Validation Set is: 1.95\n",
      "MAE for Test Set is: 65.33 | sMAPE for Test Set is: 143.77% | rMAE for Test Set is: 3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:41:37,563]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:38,509]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:45,460]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:46,930]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:46,965]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:52,612]\u001b[0m Trial 157 finished with value: 5.875086122542039 and parameters: {'n_hidden': 4, 'learning_rate': 0.004016090597861714, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31962030474111097, 'dropout_rate_Layer_2': 0.06205620428753836, 'dropout_rate_Layer_3': 0.2255326032572978, 'dropout_rate_Layer_4': 0.19946415799279785, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.05079350389161638, 'l1_Layer_2': 5.470780528634657e-05, 'l1_Layer_3': 0.00025720267743106523, 'l1_Layer_4': 0.00114778832701832, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 190, 'n_units_Layer_4': 130}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 75.19% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 66.04 | sMAPE for Test Set is: 146.83% | rMAE for Test Set is: 3.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:41:55,188]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:55,843]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:41:56,098]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:02,289]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:05,756]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:06,452]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:10,363]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:13,905]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:14,041]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:16,636]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:18,793]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:20,688]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.75 | sMAPE for Validation Set is: 65.55% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 59.79 | sMAPE for Test Set is: 121.24% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:42:23,649]\u001b[0m Trial 170 finished with value: 4.753686129831006 and parameters: {'n_hidden': 3, 'learning_rate': 0.004533006162977656, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21246115643149246, 'dropout_rate_Layer_2': 0.05929026182583269, 'dropout_rate_Layer_3': 0.16126268229084081, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.979486605246764e-05, 'l1_Layer_2': 0.0037004987488123715, 'l1_Layer_3': 0.0006291566779961943, 'n_units_Layer_1': 150, 'n_units_Layer_2': 135, 'n_units_Layer_3': 85}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:26,629]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:26,769]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:26,973]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:27,474]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:35,607]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:36,153]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:37,816]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:38,210]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:41,861]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:46,636]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:47,430]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:48,637]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:50,620]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:42:58,988]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:02,061]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:03,855]\u001b[0m Trial 184 finished with value: 4.262030439371158 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019088638328413558, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38969648275907925, 'dropout_rate_Layer_2': 0.06654131428840286, 'dropout_rate_Layer_3': 0.11744874406418974, 'dropout_rate_Layer_4': 0.1757659569906152, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.08730604697670472, 'l1_Layer_2': 6.84857774897694e-05, 'l1_Layer_3': 0.00013882198458377125, 'l1_Layer_4': 0.0003465072588501627, 'n_units_Layer_1': 115, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255, 'n_units_Layer_4': 85}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.26 | sMAPE for Validation Set is: 61.51% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 47.87 | sMAPE for Test Set is: 80.23% | rMAE for Test Set is: 2.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:43:04,049]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:04,939]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:07,742]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:12,861]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:15,463]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:18,227]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:18,694]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:29,210]\u001b[0m Trial 193 finished with value: 3.2404071043293396 and parameters: {'n_hidden': 4, 'learning_rate': 0.001902311792095687, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35954052901465117, 'dropout_rate_Layer_2': 0.09132998274906408, 'dropout_rate_Layer_3': 0.12174000403157809, 'dropout_rate_Layer_4': 0.05632158417286226, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.026980916673771265, 'l1_Layer_2': 0.0006095087402563608, 'l1_Layer_3': 4.418439992899537e-05, 'l1_Layer_4': 7.443784287810914e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265, 'n_units_Layer_4': 80}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.24 | sMAPE for Validation Set is: 53.23% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 36.11 | sMAPE for Test Set is: 49.99% | rMAE for Test Set is: 2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:43:36,627]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:42,988]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:46,292]\u001b[0m Trial 197 finished with value: 3.3908569900174044 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007118434870959916, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3406769485023472, 'dropout_rate_Layer_2': 0.023425341325731715, 'dropout_rate_Layer_3': 0.12650846139705385, 'dropout_rate_Layer_4': 0.15874377563683525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09914941590945668, 'l1_Layer_2': 0.00021115127330700436, 'l1_Layer_3': 4.840620713216057e-05, 'l1_Layer_4': 9.226190530250298e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 170, 'n_units_Layer_3': 300, 'n_units_Layer_4': 85}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.39 | sMAPE for Validation Set is: 62.89% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 33.49 | sMAPE for Test Set is: 46.39% | rMAE for Test Set is: 1.97\n",
      "MAE for Validation Set is: 4.66 | sMAPE for Validation Set is: 65.26% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 51.05 | sMAPE for Test Set is: 92.06% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:43:47,830]\u001b[0m Trial 200 finished with value: 4.6577767095258915 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006994374912382837, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1468365227552651, 'dropout_rate_Layer_2': 0.1969976122776471, 'dropout_rate_Layer_3': 0.11695749245126295, 'dropout_rate_Layer_4': 0.15067144141909422, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.028069647621137943, 'l1_Layer_2': 0.000199611553234223, 'l1_Layer_3': 5.5122315231921585e-05, 'l1_Layer_4': 0.00012959175302583797, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270, 'n_units_Layer_4': 80}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:51,623]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:56,690]\u001b[0m Trial 199 finished with value: 3.9949434435000932 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006988064910757568, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34814607757620597, 'dropout_rate_Layer_2': 0.14683694103706468, 'dropout_rate_Layer_3': 0.09142235553898284, 'dropout_rate_Layer_4': 0.15766234359819548, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.0489294183266696e-05, 'l1_Layer_2': 0.00058987383714109, 'l1_Layer_3': 7.144055141003046e-05, 'l1_Layer_4': 7.541093574486206e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 270, 'n_units_Layer_4': 80}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.99 | sMAPE for Validation Set is: 64.29% | rMAE for Validation Set is: 1.32\n",
      "MAE for Test Set is: 36.35 | sMAPE for Test Set is: 52.23% | rMAE for Test Set is: 2.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:43:57,016]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:43:57,967]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:05,156]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:06,503]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:08,896]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:09,308]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:11,109]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:16,990]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:20,232]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:22,693]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:25,636]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:28,120]\u001b[0m Trial 212 finished with value: 10.05490354459598 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006490664598265509, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05363536410440017, 'dropout_rate_Layer_2': 0.14172807503686996, 'dropout_rate_Layer_3': 0.2555001596187845, 'dropout_rate_Layer_4': 0.3648628541215663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.00020402208406460108, 'l1_Layer_2': 0.0005762190270625041, 'l1_Layer_3': 0.004432215999874076, 'l1_Layer_4': 0.024335878909152415, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 295, 'n_units_Layer_4': 285}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.05 | sMAPE for Validation Set is: 91.96% | rMAE for Validation Set is: 3.31\n",
      "MAE for Test Set is: 39.08 | sMAPE for Test Set is: 55.43% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:44:33,077]\u001b[0m Trial 206 finished with value: 3.7858260858505823 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006682486581619538, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34803241261957907, 'dropout_rate_Layer_2': 0.02476624206815645, 'dropout_rate_Layer_3': 0.0885383361565053, 'dropout_rate_Layer_4': 0.1579798572362936, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0593412092434061, 'l1_Layer_2': 8.524180962327071e-05, 'l1_Layer_3': 4.210056810118234e-05, 'l1_Layer_4': 5.420559777810913e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 295, 'n_units_Layer_4': 70}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.79 | sMAPE for Validation Set is: 66.34% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 36.07 | sMAPE for Test Set is: 52.20% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:44:33,706]\u001b[0m Trial 216 finished with value: 5.704775468077831 and parameters: {'n_hidden': 3, 'learning_rate': 0.007063677548211912, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25221200672033084, 'dropout_rate_Layer_2': 0.09057867623457443, 'dropout_rate_Layer_3': 0.014580610820467084, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.123304082586817e-05, 'l1_Layer_2': 0.0011752508775589655, 'l1_Layer_3': 0.0031592125818755627, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 75.36% | rMAE for Validation Set is: 1.88\n",
      "MAE for Test Set is: 60.60 | sMAPE for Test Set is: 125.05% | rMAE for Test Set is: 3.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:44:41,871]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:42,995]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:46,231]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:46,878]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:47,759]\u001b[0m Trial 220 finished with value: 9.44657925078907 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006259859338535617, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01994938481466607, 'dropout_rate_Layer_2': 0.09950934025076613, 'dropout_rate_Layer_3': 0.21679672831144794, 'dropout_rate_Layer_4': 0.36174416643614976, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.950919711317329e-05, 'l1_Layer_2': 0.0007275495133736301, 'l1_Layer_3': 0.0027881297586978544, 'l1_Layer_4': 0.014311979447405799, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 300, 'n_units_Layer_4': 265}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.45 | sMAPE for Validation Set is: 90.12% | rMAE for Validation Set is: 3.11\n",
      "MAE for Test Set is: 38.69 | sMAPE for Test Set is: 54.53% | rMAE for Test Set is: 2.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:44:49,769]\u001b[0m Trial 221 finished with value: 8.935561858259536 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006071060518115846, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02176234170441381, 'dropout_rate_Layer_2': 0.12972911233749906, 'dropout_rate_Layer_3': 0.21976189470660154, 'dropout_rate_Layer_4': 0.32994135472705993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.428279980115211e-05, 'l1_Layer_2': 0.000809792009465665, 'l1_Layer_3': 0.0027684850931234115, 'l1_Layer_4': 0.014246978001817744, 'n_units_Layer_1': 190, 'n_units_Layer_2': 195, 'n_units_Layer_3': 300, 'n_units_Layer_4': 265}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.94 | sMAPE for Validation Set is: 87.90% | rMAE for Validation Set is: 2.94\n",
      "MAE for Test Set is: 37.03 | sMAPE for Test Set is: 50.81% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:44:55,633]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:57,934]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:44:58,582]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:05,474]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:09,414]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:11,959]\u001b[0m Trial 229 finished with value: 7.553596539670049 and parameters: {'n_hidden': 4, 'learning_rate': 0.000500977965799294, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055116573138963634, 'dropout_rate_Layer_2': 0.10220063749618766, 'dropout_rate_Layer_3': 0.19466461195351478, 'dropout_rate_Layer_4': 0.33233645365742565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.3284279815142974e-05, 'l1_Layer_2': 0.0009366562116349557, 'l1_Layer_3': 0.0012608233442420313, 'l1_Layer_4': 0.009977632345720185, 'n_units_Layer_1': 205, 'n_units_Layer_2': 170, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.55 | sMAPE for Validation Set is: 80.31% | rMAE for Validation Set is: 2.49\n",
      "MAE for Test Set is: 39.73 | sMAPE for Test Set is: 56.97% | rMAE for Test Set is: 2.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:45:12,713]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:21,656]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:24,345]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:26,174]\u001b[0m Trial 233 finished with value: 7.381548857033643 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006115158297875159, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0539680394719315, 'dropout_rate_Layer_2': 0.08348307817367559, 'dropout_rate_Layer_3': 0.22083592369454008, 'dropout_rate_Layer_4': 0.3210184086229733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 4.0730137591609314e-05, 'l1_Layer_2': 0.0011290605815642088, 'l1_Layer_3': 0.0012415278182016263, 'l1_Layer_4': 0.009680568203540765, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 275, 'n_units_Layer_4': 270}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 79.99% | rMAE for Validation Set is: 2.43\n",
      "MAE for Test Set is: 39.21 | sMAPE for Test Set is: 55.72% | rMAE for Test Set is: 2.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:45:26,778]\u001b[0m Trial 225 finished with value: 4.798676165970545 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005025925532154004, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34133574766736846, 'dropout_rate_Layer_2': 0.027350411509621662, 'dropout_rate_Layer_3': 0.13673944510049052, 'dropout_rate_Layer_4': 0.07739687004797813, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04961847737133346, 'l1_Layer_2': 0.0005687606297844577, 'l1_Layer_3': 3.5349197581994646e-05, 'l1_Layer_4': 1.1095565144326263e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275, 'n_units_Layer_4': 65}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.80 | sMAPE for Validation Set is: 65.03% | rMAE for Validation Set is: 1.58\n",
      "MAE for Test Set is: 65.42 | sMAPE for Test Set is: 142.30% | rMAE for Test Set is: 3.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:45:31,950]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:34,414]\u001b[0m Trial 224 finished with value: 3.58608214638636 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006844076004243904, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2886843733873427, 'dropout_rate_Layer_2': 0.10116950914126126, 'dropout_rate_Layer_3': 0.13729306553865095, 'dropout_rate_Layer_4': 0.07175225243471693, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.058029639401417386, 'l1_Layer_2': 0.0005590223281943412, 'l1_Layer_3': 3.54979755429867e-05, 'l1_Layer_4': 7.725047204582419e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 120, 'n_units_Layer_3': 275, 'n_units_Layer_4': 65}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.59 | sMAPE for Validation Set is: 54.55% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 33.42 | sMAPE for Test Set is: 44.17% | rMAE for Test Set is: 1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:45:37,669]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:40,920]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:43,418]\u001b[0m Trial 236 finished with value: 8.882894376818518 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005576037321561798, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05206883266588347, 'dropout_rate_Layer_2': 0.0901696155389415, 'dropout_rate_Layer_3': 0.1952578486635755, 'dropout_rate_Layer_4': 0.358202968385765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.4637082293206838e-05, 'l1_Layer_2': 0.0015903834176056464, 'l1_Layer_3': 0.0009857910666461716, 'l1_Layer_4': 0.00522407068812469, 'n_units_Layer_1': 195, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290, 'n_units_Layer_4': 255}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.88 | sMAPE for Validation Set is: 87.83% | rMAE for Validation Set is: 2.93\n",
      "MAE for Test Set is: 38.62 | sMAPE for Test Set is: 54.36% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:45:43,870]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:49,866]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:45:54,209]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:00,458]\u001b[0m Trial 237 finished with value: 5.402722831349284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005096234793301945, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27349077347765, 'dropout_rate_Layer_2': 0.1009130803772629, 'dropout_rate_Layer_3': 0.04094611884686516, 'dropout_rate_Layer_4': 0.15046207498084369, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011768696758008948, 'l1_Layer_2': 0.00011412786004573504, 'l1_Layer_3': 4.17470971585672e-05, 'l1_Layer_4': 8.022226404494488e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280, 'n_units_Layer_4': 115}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 75.14% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 65.00 | sMAPE for Test Set is: 141.92% | rMAE for Test Set is: 3.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:46:03,544]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:04,455]\u001b[0m Trial 244 finished with value: 10.561176405590556 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005642462107101166, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07378968506316526, 'dropout_rate_Layer_2': 0.08161634438964474, 'dropout_rate_Layer_3': 0.17351111573122965, 'dropout_rate_Layer_4': 0.3209629993330993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.854826400505645e-05, 'l1_Layer_2': 0.0018522629496993566, 'l1_Layer_3': 0.0015572670667684308, 'l1_Layer_4': 0.004651594722984911, 'n_units_Layer_1': 200, 'n_units_Layer_2': 155, 'n_units_Layer_3': 300, 'n_units_Layer_4': 245}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.56 | sMAPE for Validation Set is: 93.62% | rMAE for Validation Set is: 3.48\n",
      "MAE for Test Set is: 37.03 | sMAPE for Test Set is: 50.81% | rMAE for Test Set is: 2.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:46:09,912]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:10,118]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:18,828]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:21,292]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:27,725]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:30,353]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:34,316]\u001b[0m Trial 252 finished with value: 9.058900435818716 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005028211333943163, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029410298559597533, 'dropout_rate_Layer_2': 0.07338416192777587, 'dropout_rate_Layer_3': 0.19580996849776594, 'dropout_rate_Layer_4': 0.29815006166842795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.1182069321784574e-05, 'l1_Layer_2': 0.0024531953247001166, 'l1_Layer_3': 0.0014319242606556277, 'l1_Layer_4': 0.004143769583349649, 'n_units_Layer_1': 215, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290, 'n_units_Layer_4': 275}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 88.13% | rMAE for Validation Set is: 2.98\n",
      "MAE for Test Set is: 39.97 | sMAPE for Test Set is: 57.53% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:46:37,876]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:41,470]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:44,551]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:46,551]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:46,780]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:48,838]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:52,796]\u001b[0m Trial 249 finished with value: 4.45045117557201 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006834189747897875, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33012523905739494, 'dropout_rate_Layer_2': 0.14083187592682142, 'dropout_rate_Layer_3': 0.07422558685467921, 'dropout_rate_Layer_4': 0.12295425731551705, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.05772063241831916, 'l1_Layer_2': 0.00022319655854539876, 'l1_Layer_3': 9.008944581202786e-05, 'l1_Layer_4': 6.51050530942137e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 300, 'n_units_Layer_4': 70}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.45 | sMAPE for Validation Set is: 64.38% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 28.70 | sMAPE for Test Set is: 36.55% | rMAE for Test Set is: 1.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:46:53,135]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:56,416]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:46:59,920]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:16,327]\u001b[0m Trial 266 finished with value: 8.161041768936505 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006201820594031716, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056096122216143955, 'dropout_rate_Layer_2': 0.048400152372347245, 'dropout_rate_Layer_3': 0.11125979287270193, 'dropout_rate_Layer_4': 0.27812336286213557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.5152259309696245e-05, 'l1_Layer_2': 0.0031284958967732765, 'l1_Layer_3': 0.00110900436791459, 'l1_Layer_4': 0.005800897256351853, 'n_units_Layer_1': 205, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280, 'n_units_Layer_4': 240}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.16 | sMAPE for Validation Set is: 84.44% | rMAE for Validation Set is: 2.69\n",
      "MAE for Test Set is: 37.82 | sMAPE for Test Set is: 52.56% | rMAE for Test Set is: 2.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:47:24,363]\u001b[0m Trial 260 finished with value: 3.3979095595619864 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007125623560774077, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32174297464910784, 'dropout_rate_Layer_2': 0.14205571344970944, 'dropout_rate_Layer_3': 0.06762535348782095, 'dropout_rate_Layer_4': 0.12342474930457867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004154656186701207, 'l1_Layer_2': 0.0005618066335827549, 'l1_Layer_3': 8.473766649622832e-05, 'l1_Layer_4': 7.872200298024223e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 180, 'n_units_Layer_3': 265, 'n_units_Layer_4': 75}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.40 | sMAPE for Validation Set is: 54.98% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 53.05 | sMAPE for Test Set is: 100.23% | rMAE for Test Set is: 3.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:47:24,665]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:30,276]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:32,464]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:34,709]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:35,294]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:39,604]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:40,009]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:40,719]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:45,539]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:49,953]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:53,471]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:47:59,561]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:02,380]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:06,181]\u001b[0m Trial 272 finished with value: 3.6629415775286227 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009708513395851168, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3206236510649199, 'dropout_rate_Layer_2': 0.11961653371404775, 'dropout_rate_Layer_3': 0.15423869143921756, 'dropout_rate_Layer_4': 0.13436594499566112, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004144445063926634, 'l1_Layer_2': 0.0013810569028574254, 'l1_Layer_3': 4.759166461785609e-05, 'l1_Layer_4': 3.324023087243482e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 290, 'n_units_Layer_4': 65}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.66 | sMAPE for Validation Set is: 54.88% | rMAE for Validation Set is: 1.21\n",
      "MAE for Test Set is: 47.97 | sMAPE for Test Set is: 82.80% | rMAE for Test Set is: 2.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:48:10,638]\u001b[0m Trial 278 finished with value: 5.805423730520968 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009698039416304123, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29658542613329547, 'dropout_rate_Layer_2': 0.12508726092124678, 'dropout_rate_Layer_3': 0.15873156120904294, 'dropout_rate_Layer_4': 0.02614350651957842, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009023470249751067, 'l1_Layer_2': 0.00033434210540481325, 'l1_Layer_3': 4.8951916279670484e-05, 'l1_Layer_4': 9.401789957617125e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 175, 'n_units_Layer_3': 230, 'n_units_Layer_4': 100}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 83.77% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 64.91 | sMAPE for Test Set is: 150.56% | rMAE for Test Set is: 3.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:48:12,921]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:13,725]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:18,932]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:19,061]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:21,388]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:24,457]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:28,048]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:28,269]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:28,621]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:28,742]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:36,505]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:38,669]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:39,684]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:47,620]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:52,022]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:55,811]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:48:56,258]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:00,274]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:00,607]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:06,249]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:06,702]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:07,329]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:13,119]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:17,885]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:18,099]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:21,517]\u001b[0m Trial 297 finished with value: 4.269779060606395 and parameters: {'n_hidden': 4, 'learning_rate': 0.001116651777136133, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34109739179649423, 'dropout_rate_Layer_2': 0.1820732883854344, 'dropout_rate_Layer_3': 0.18224695858956785, 'dropout_rate_Layer_4': 0.12055214660829867, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012717167604078873, 'l1_Layer_2': 0.003606532669379204, 'l1_Layer_3': 0.00010046540016240735, 'l1_Layer_4': 1.3715976999949684e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275, 'n_units_Layer_4': 60}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.27 | sMAPE for Validation Set is: 62.41% | rMAE for Validation Set is: 1.41\n",
      "MAE for Test Set is: 37.96 | sMAPE for Test Set is: 56.80% | rMAE for Test Set is: 2.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:49:24,809]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:27,328]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:31,123]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:31,506]\u001b[0m Trial 304 finished with value: 5.022148287139397 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005722162986425651, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3427394293397212, 'dropout_rate_Layer_2': 0.3712552342811364, 'dropout_rate_Layer_3': 0.18549236002225442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0012264150322109774, 'l1_Layer_2': 0.0008409136559102782, 'l1_Layer_3': 2.7486881224253752e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.02 | sMAPE for Validation Set is: 67.00% | rMAE for Validation Set is: 1.65\n",
      "MAE for Test Set is: 57.54 | sMAPE for Test Set is: 114.52% | rMAE for Test Set is: 3.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:49:40,159]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:44,506]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:44,627]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:48,588]\u001b[0m Trial 307 finished with value: 4.967434248848158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005591826916523138, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34321624960836483, 'dropout_rate_Layer_2': 0.015101100431176573, 'dropout_rate_Layer_3': 0.18087908528349156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0014392965941122675, 'l1_Layer_2': 0.00047731568094400964, 'l1_Layer_3': 2.510340559605847e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 260}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.97 | sMAPE for Validation Set is: 67.98% | rMAE for Validation Set is: 1.64\n",
      "MAE for Test Set is: 35.02 | sMAPE for Test Set is: 49.54% | rMAE for Test Set is: 2.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:49:49,560]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:49,664]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:53,580]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:56,734]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:56,932]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:49:57,662]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:05,530]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:05,770]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:09,649]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:10,428]\u001b[0m Trial 313 finished with value: 4.579088441765104 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007701936611432545, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34897227262830016, 'dropout_rate_Layer_2': 0.14135365637391695, 'dropout_rate_Layer_3': 0.0837400106400018, 'dropout_rate_Layer_4': 0.15466235970526715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1547895554531716e-05, 'l1_Layer_2': 0.0005028878115963754, 'l1_Layer_3': 6.739116630395993e-05, 'l1_Layer_4': 7.219770716733452e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 230, 'n_units_Layer_3': 270, 'n_units_Layer_4': 95}. Best is trial 137 with value: 2.7246759156529947.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.58 | sMAPE for Validation Set is: 67.32% | rMAE for Validation Set is: 1.51\n",
      "MAE for Test Set is: 27.25 | sMAPE for Test Set is: 32.99% | rMAE for Test Set is: 1.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:50:11,057]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:17,255]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:17,953]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:19,947]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:22,140]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:23,774]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:24,319]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:31,235]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:31,669]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:32,172]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:38,551]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:41,071]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:41,416]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:44,463]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:45,363]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:46,679]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:49,398]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:56,471]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:50:56,627]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:01,477]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:03,072]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:05,923]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:11,711]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:14,472]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.48 | sMAPE for Validation Set is: 66.09% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 10.38 | sMAPE for Test Set is: 12.71% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:51:16,249]\u001b[0m Trial 334 finished with value: 2.4793780098585696 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007194015556887737, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38236166243408476, 'dropout_rate_Layer_2': 0.10862629974174069, 'dropout_rate_Layer_3': 0.029370964316309076, 'dropout_rate_Layer_4': 0.20804401708337156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06732939272474442, 'l1_Layer_2': 0.0002765605857423959, 'l1_Layer_3': 3.782474222669992e-05, 'l1_Layer_4': 0.00016399848706014048, 'n_units_Layer_1': 115, 'n_units_Layer_2': 295, 'n_units_Layer_3': 85, 'n_units_Layer_4': 115}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:18,358]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:18,805]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:31,261]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:33,323]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:36,486]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:37,101]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:41,317]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:41,478]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:48,443]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:51,275]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:51:51,493]\u001b[0m Trial 350 finished with value: 5.877228493097211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008281050190932966, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.348039234283289, 'dropout_rate_Layer_2': 0.09287359312393961, 'dropout_rate_Layer_3': 0.17621955387043692, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008368475062705322, 'l1_Layer_2': 0.05988105109221126, 'l1_Layer_3': 3.2067401593668865e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 175, 'n_units_Layer_3': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 77.35% | rMAE for Validation Set is: 1.94\n",
      "MAE for Test Set is: 68.78 | sMAPE for Test Set is: 160.65% | rMAE for Test Set is: 4.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:51:54,610]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:03,203]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:07,122]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:10,456]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:13,199]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:21,731]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:26,365]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:27,331]\u001b[0m Trial 359 finished with value: 3.4605072632044585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008475848420291893, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3877825633747106, 'dropout_rate_Layer_2': 0.07552352830648651, 'dropout_rate_Layer_3': 0.21462860066743722, 'dropout_rate_Layer_4': 0.21297748461588423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09809344275627385, 'l1_Layer_2': 0.00015357112742744956, 'l1_Layer_3': 0.0016866152184332568, 'l1_Layer_4': 0.00016062840475357905, 'n_units_Layer_1': 50, 'n_units_Layer_2': 185, 'n_units_Layer_3': 90, 'n_units_Layer_4': 135}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.46 | sMAPE for Validation Set is: 70.94% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 14.98 | sMAPE for Test Set is: 18.44% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:52:34,355]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:37,890]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:42,551]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:43,210]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:47,474]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:48,299]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:50,043]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:51,422]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:53,223]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:53,496]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:52:59,228]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:00,347]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:01,298]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:05,480]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:08,824]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:12,931]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:15,153]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:22,290]\u001b[0m Trial 382 finished with value: 5.962686830966032 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013671886449619498, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.398160415026653, 'dropout_rate_Layer_2': 0.07342308490234084, 'dropout_rate_Layer_3': 0.12605605863621805, 'dropout_rate_Layer_4': 0.19625962755209142, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.09693948084585312, 'l1_Layer_2': 0.00011287900218161135, 'l1_Layer_3': 0.008019336345425796, 'l1_Layer_4': 0.0003190225181788689, 'n_units_Layer_1': 55, 'n_units_Layer_2': 155, 'n_units_Layer_3': 70, 'n_units_Layer_4': 165}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 79.14% | rMAE for Validation Set is: 1.96\n",
      "MAE for Test Set is: 69.95 | sMAPE for Test Set is: 166.84% | rMAE for Test Set is: 4.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:53:23,065]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:23,928]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:28,765]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:31,541]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:34,069]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:35,927]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:38,033]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:40,058]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:40,118]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:41,358]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:41,424]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:46,143]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:46,960]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:48,954]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:53,146]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:55,042]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:55,505]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:55,754]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:53:58,837]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:01,358]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:05,971]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:06,226]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:06,362]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:13,671]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:14,105]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:19,485]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:22,082]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:25,255]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:27,317]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:34,976]\u001b[0m Trial 409 finished with value: 4.0615304541189365 and parameters: {'n_hidden': 4, 'learning_rate': 0.000680870332160172, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3356540149117856, 'dropout_rate_Layer_2': 0.10012864768862252, 'dropout_rate_Layer_3': 0.1439533487895397, 'dropout_rate_Layer_4': 0.06379942407271605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.056446501146511084, 'l1_Layer_2': 0.0002473496130224114, 'l1_Layer_3': 8.486264218815194e-05, 'l1_Layer_4': 5.933364335790086e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 270, 'n_units_Layer_4': 80}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.06 | sMAPE for Validation Set is: 54.59% | rMAE for Validation Set is: 1.34\n",
      "MAE for Test Set is: 59.84 | sMAPE for Test Set is: 120.48% | rMAE for Test Set is: 3.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:54:36,170]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:36,991]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:42,294]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:46,408]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:49,215]\u001b[0m Trial 413 finished with value: 3.7448058088839797 and parameters: {'n_hidden': 4, 'learning_rate': 0.000699233699164912, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3344567647602497, 'dropout_rate_Layer_2': 0.09716397626102122, 'dropout_rate_Layer_3': 0.38728312476765314, 'dropout_rate_Layer_4': 0.10669877071578068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07620516737319082, 'l1_Layer_2': 0.0005065977932262672, 'l1_Layer_3': 3.275098071500984e-05, 'l1_Layer_4': 1.7148162109419373e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165, 'n_units_Layer_4': 80}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.74 | sMAPE for Validation Set is: 53.57% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 51.09 | sMAPE for Test Set is: 90.76% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:54:49,881]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:55,646]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:57,427]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:59,431]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:54:59,660]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:04,734]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:07,128]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:08,498]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:09,579]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:12,643]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:17,553]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:21,258]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:21,374]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:21,540]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:22,065]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:30,799]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:39,320]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:42,631]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:46,169]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:48,028]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:52,973]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:53,513]\u001b[0m Trial 437 finished with value: 5.094632498708275 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007411029369393749, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3161080950757866, 'dropout_rate_Layer_2': 0.11539706745273824, 'dropout_rate_Layer_3': 0.3851771351278098, 'dropout_rate_Layer_4': 0.08749462746908143, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017382418973040756, 'l1_Layer_2': 0.0007220510254178445, 'l1_Layer_3': 2.334626500359336e-05, 'l1_Layer_4': 1.3925488412534342e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 120, 'n_units_Layer_3': 50, 'n_units_Layer_4': 70}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.09 | sMAPE for Validation Set is: 68.31% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 66.10 | sMAPE for Test Set is: 146.74% | rMAE for Test Set is: 3.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:55:58,048]\u001b[0m Trial 436 finished with value: 5.487518645663613 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007680733938662182, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05279546125657894, 'dropout_rate_Layer_2': 0.11434620958484173, 'dropout_rate_Layer_3': 0.3913600613595285, 'dropout_rate_Layer_4': 0.0832331006287537, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.033181680454798565, 'l1_Layer_2': 0.0004525359707272487, 'l1_Layer_3': 0.0005613318312786351, 'l1_Layer_4': 1.8977116403526413e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 50, 'n_units_Layer_4': 70}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.49 | sMAPE for Validation Set is: 75.81% | rMAE for Validation Set is: 1.81\n",
      "MAE for Test Set is: 49.42 | sMAPE for Test Set is: 88.43% | rMAE for Test Set is: 2.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:55:58,532]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:55:58,834]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:05,032]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:05,854]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:09,359]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:12,396]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:12,735]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:17,925]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:18,254]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:23,872]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:26,551]\u001b[0m Trial 447 finished with value: 3.5505761945846737 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009151814179340206, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3461495294195335, 'dropout_rate_Layer_2': 0.1309399884953831, 'dropout_rate_Layer_3': 0.11728629484747703, 'dropout_rate_Layer_4': 0.11362846464222473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.06128272015523461, 'l1_Layer_2': 0.000536933200348425, 'l1_Layer_3': 3.142540493482229e-05, 'l1_Layer_4': 8.186740686114645e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285, 'n_units_Layer_4': 95}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 51.16% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 51.19 | sMAPE for Test Set is: 91.41% | rMAE for Test Set is: 3.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:56:27,125]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:27,786]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:30,383]\u001b[0m Trial 454 finished with value: 5.693151940835662 and parameters: {'n_hidden': 3, 'learning_rate': 0.003523371588590914, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1934311116538676, 'dropout_rate_Layer_2': 0.03140803652199188, 'dropout_rate_Layer_3': 0.10847323220836236, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.2251735702270087e-05, 'l1_Layer_2': 0.0012756605018084633, 'l1_Layer_3': 0.0004997481281266873, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.69 | sMAPE for Validation Set is: 74.97% | rMAE for Validation Set is: 1.88\n",
      "MAE for Test Set is: 67.38 | sMAPE for Test Set is: 153.32% | rMAE for Test Set is: 3.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:56:33,393]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:36,753]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:40,920]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:41,092]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:45,654]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:45,684]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:49,976]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:50,565]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:53,258]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:55,438]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:56:57,343]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:00,730]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:01,226]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:07,153]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:09,022]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:12,994]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:14,297]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:17,691]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:20,866]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:24,464]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:27,308]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:30,369]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:30,857]\u001b[0m Trial 470 finished with value: 2.991008908721509 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008935640648716344, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3800130769761682, 'dropout_rate_Layer_2': 0.06812396480454058, 'dropout_rate_Layer_3': 0.27697277674547965, 'dropout_rate_Layer_4': 0.09868513668682752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.07789644222498844, 'l1_Layer_2': 0.00039321508296650284, 'l1_Layer_3': 4.5202090330411586e-05, 'l1_Layer_4': 0.00012167677518127295, 'n_units_Layer_1': 115, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.99 | sMAPE for Validation Set is: 49.89% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 38.97 | sMAPE for Test Set is: 58.73% | rMAE for Test Set is: 2.30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:57:31,489]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:36,751]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:39,089]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:39,986]\u001b[0m Trial 474 finished with value: 2.720011992075013 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009061987559993162, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3765447663954918, 'dropout_rate_Layer_2': 0.12940405015701173, 'dropout_rate_Layer_3': 0.12067119448037683, 'dropout_rate_Layer_4': 0.04242088900781027, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.022245939565720133, 'l1_Layer_2': 0.0003916313881421615, 'l1_Layer_3': 4.1994449551698566e-05, 'l1_Layer_4': 3.754602323287295e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 275, 'n_units_Layer_3': 285, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.72 | sMAPE for Validation Set is: 45.52% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 35.55 | sMAPE for Test Set is: 54.27% | rMAE for Test Set is: 2.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:57:40,503]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:41,003]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:44,768]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:48,769]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:52,404]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:53,992]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:56,556]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:57:58,184]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:01,877]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:03,452]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:08,874]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:11,469]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:17,094]\u001b[0m Trial 496 finished with value: 4.552107700850942 and parameters: {'n_hidden': 3, 'learning_rate': 0.005216091414122123, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27652052032721347, 'dropout_rate_Layer_2': 0.0692439954430673, 'dropout_rate_Layer_3': 0.14690385903549863, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016872892315086454, 'l1_Layer_2': 0.0010049470721961102, 'l1_Layer_3': 2.234769665955871e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 145, 'n_units_Layer_3': 85}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.55 | sMAPE for Validation Set is: 67.59% | rMAE for Validation Set is: 1.50\n",
      "MAE for Test Set is: 23.16 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:58:22,407]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:25,287]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:25,515]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:25,670]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:31,224]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:32,211]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:35,856]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:36,808]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:41,002]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:42,532]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:45,282]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:48,186]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:51,071]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:58:55,776]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:00,189]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:00,804]\u001b[0m Trial 512 finished with value: 5.396049758481449 and parameters: {'n_hidden': 3, 'learning_rate': 0.00467358924242099, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2677028449683854, 'dropout_rate_Layer_2': 0.05685449252045507, 'dropout_rate_Layer_3': 0.13793500907287903, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.013647090695985265, 'l1_Layer_2': 0.0018536354688759547, 'l1_Layer_3': 1.5043974890639919e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 130, 'n_units_Layer_3': 80}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.40 | sMAPE for Validation Set is: 70.95% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 63.82 | sMAPE for Test Set is: 138.67% | rMAE for Test Set is: 3.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:59:04,569]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:07,772]\u001b[0m Trial 504 finished with value: 3.0324720856180707 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008953376194504662, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37331158776756873, 'dropout_rate_Layer_2': 0.10821031106266062, 'dropout_rate_Layer_3': 0.15129209985030073, 'dropout_rate_Layer_4': 0.05975529756335041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08225360729076779, 'l1_Layer_2': 0.00020910217813261022, 'l1_Layer_3': 2.657484057978819e-05, 'l1_Layer_4': 8.718695201436491e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 260, 'n_units_Layer_3': 110, 'n_units_Layer_4': 95}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.03 | sMAPE for Validation Set is: 48.70% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 33.84 | sMAPE for Test Set is: 49.72% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:59:11,109]\u001b[0m Trial 507 finished with value: 3.2013919989737025 and parameters: {'n_hidden': 4, 'learning_rate': 0.000900756426232609, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3681208342042416, 'dropout_rate_Layer_2': 0.10824425313054567, 'dropout_rate_Layer_3': 0.1128531371685324, 'dropout_rate_Layer_4': 0.11265626406623813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0749512617660725, 'l1_Layer_2': 0.00021755752455137665, 'l1_Layer_3': 5.667037976368103e-05, 'l1_Layer_4': 0.0001292029337117972, 'n_units_Layer_1': 105, 'n_units_Layer_2': 265, 'n_units_Layer_3': 195, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.20 | sMAPE for Validation Set is: 51.75% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 25.19 | sMAPE for Test Set is: 31.80% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:59:11,814]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:16,043]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:17,400]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:22,022]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:25,150]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:25,506]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:30,717]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:33,592]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:38,741]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:40,727]\u001b[0m Trial 517 finished with value: 2.678597627584594 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009091537984880287, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37265431297720025, 'dropout_rate_Layer_2': 0.10985735320841063, 'dropout_rate_Layer_3': 0.15443789978408584, 'dropout_rate_Layer_4': 0.11556549485111331, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05192644680639309, 'l1_Layer_2': 0.0004122512650043551, 'l1_Layer_3': 2.2898952074872848e-05, 'l1_Layer_4': 0.00012008440240928356, 'n_units_Layer_1': 120, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.68 | sMAPE for Validation Set is: 45.39% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 18.97 | sMAPE for Test Set is: 21.18% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:59:42,532]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:44,572]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:45,070]\u001b[0m Trial 519 finished with value: 3.1322397533869903 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009144274068697771, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3690693808525035, 'dropout_rate_Layer_2': 0.11042911252495512, 'dropout_rate_Layer_3': 0.1940651272308408, 'dropout_rate_Layer_4': 0.05803347608440426, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08271820230452268, 'l1_Layer_2': 0.0001336328190701261, 'l1_Layer_3': 2.1602903360855783e-05, 'l1_Layer_4': 0.00012554289963180693, 'n_units_Layer_1': 110, 'n_units_Layer_2': 265, 'n_units_Layer_3': 110, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.13 | sMAPE for Validation Set is: 48.73% | rMAE for Validation Set is: 1.03\n",
      "MAE for Test Set is: 35.73 | sMAPE for Test Set is: 53.47% | rMAE for Test Set is: 2.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 01:59:51,974]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:53,882]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 01:59:56,929]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:00,488]\u001b[0m Trial 531 finished with value: 5.663263309471232 and parameters: {'n_hidden': 3, 'learning_rate': 0.003647659612276222, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22716821448649116, 'dropout_rate_Layer_2': 0.0545191960110436, 'dropout_rate_Layer_3': 0.1165310142718111, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.041901192942462265, 'l1_Layer_2': 0.0016375196466901657, 'l1_Layer_3': 0.00036269735464437093, 'n_units_Layer_1': 95, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.66 | sMAPE for Validation Set is: 73.94% | rMAE for Validation Set is: 1.87\n",
      "MAE for Test Set is: 68.11 | sMAPE for Test Set is: 156.69% | rMAE for Test Set is: 4.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:00:01,040]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:03,344]\u001b[0m Trial 525 finished with value: 3.181703047063357 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008748703295724724, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3703557402339347, 'dropout_rate_Layer_2': 0.14588990302425875, 'dropout_rate_Layer_3': 0.21664322436046538, 'dropout_rate_Layer_4': 0.011985678216017488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.051500785180174195, 'l1_Layer_2': 0.00020149656404798026, 'l1_Layer_3': 2.1044672508763528e-05, 'l1_Layer_4': 0.00022419727988140338, 'n_units_Layer_1': 115, 'n_units_Layer_2': 255, 'n_units_Layer_3': 195, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.18 | sMAPE for Validation Set is: 52.26% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 29.26 | sMAPE for Test Set is: 39.00% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:00:03,840]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:07,906]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:08,016]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:08,898]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:15,097]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:15,331]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:18,176]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:21,217]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:21,677]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:26,831]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:30,000]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:32,630]\u001b[0m Trial 540 finished with value: 3.2322293295536255 and parameters: {'n_hidden': 4, 'learning_rate': 0.001149478942727813, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3656801064906652, 'dropout_rate_Layer_2': 0.13924714605496918, 'dropout_rate_Layer_3': 0.20008035253266915, 'dropout_rate_Layer_4': 0.00662941155066607, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02220466860451795, 'l1_Layer_2': 0.00021289529647925301, 'l1_Layer_3': 2.1481309046208173e-05, 'l1_Layer_4': 0.00012406019355778506, 'n_units_Layer_1': 140, 'n_units_Layer_2': 250, 'n_units_Layer_3': 200, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.23 | sMAPE for Validation Set is: 63.10% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 33.57 | sMAPE for Test Set is: 50.05% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:00:37,009]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:39,863]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:47,568]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:50,306]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:52,749]\u001b[0m Trial 546 finished with value: 3.377553117396163 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010898394354130901, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3668539630275683, 'dropout_rate_Layer_2': 0.1431253522853011, 'dropout_rate_Layer_3': 0.1884884394340235, 'dropout_rate_Layer_4': 0.005697784434996336, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023149400914569344, 'l1_Layer_2': 0.0002079849988556116, 'l1_Layer_3': 2.117716653276444e-05, 'l1_Layer_4': 0.00013174760550060065, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 200, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.38 | sMAPE for Validation Set is: 54.19% | rMAE for Validation Set is: 1.11\n",
      "MAE for Test Set is: 28.49 | sMAPE for Test Set is: 37.25% | rMAE for Test Set is: 1.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:00:53,444]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:00:53,947]\u001b[0m Trial 548 finished with value: 3.218199678854109 and parameters: {'n_hidden': 4, 'learning_rate': 0.001111234237866325, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09859872089979434, 'dropout_rate_Layer_2': 0.15044214556494137, 'dropout_rate_Layer_3': 0.1881096513294394, 'dropout_rate_Layer_4': 0.00414259177056703, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.046691141360326385, 'l1_Layer_2': 0.000211720734750128, 'l1_Layer_3': 2.2899082609364413e-05, 'l1_Layer_4': 0.00014027640784595525, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.22 | sMAPE for Validation Set is: 51.05% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 19.58 | sMAPE for Test Set is: 21.89% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:00:59,238]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:00,182]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:02,648]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:04,078]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:07,713]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:11,316]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:11,813]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:13,723]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:18,030]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:21,318]\u001b[0m Trial 554 finished with value: 3.523877744146708 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011327143899451239, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37527693931444417, 'dropout_rate_Layer_2': 0.13859223608375745, 'dropout_rate_Layer_3': 0.19798532195994867, 'dropout_rate_Layer_4': 0.008127214787497748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02480672060696849, 'l1_Layer_2': 0.00021235043774116578, 'l1_Layer_3': 2.3410138782014087e-05, 'l1_Layer_4': 0.00012747918672366664, 'n_units_Layer_1': 140, 'n_units_Layer_2': 245, 'n_units_Layer_3': 195, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.52 | sMAPE for Validation Set is: 55.10% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:01:21,762]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:23,253]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:26,882]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:26,983]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:31,038]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:32,823]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:35,264]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:38,404]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:41,707]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:43,531]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:49,022]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:50,788]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:50,976]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:51,469]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:57,754]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:58,161]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:01:59,988]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:03,457]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:06,561]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:07,643]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:09,230]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:10,394]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:13,441]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:15,254]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:18,246]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:20,832]\u001b[0m Trial 579 finished with value: 3.451338404899077 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012106778858163442, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02132314172760791, 'dropout_rate_Layer_2': 0.12365761186942668, 'dropout_rate_Layer_3': 0.22141352884070714, 'dropout_rate_Layer_4': 0.02367882965632742, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.031100903579283565, 'l1_Layer_2': 0.0002485429859984943, 'l1_Layer_3': 1.6118230264695316e-05, 'l1_Layer_4': 0.00014811579585006097, 'n_units_Layer_1': 155, 'n_units_Layer_2': 240, 'n_units_Layer_3': 210, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 54.59% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 34.36 | sMAPE for Test Set is: 50.26% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:02:32,820]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:34,903]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:38,086]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:39,837]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:41,678]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:45,085]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.27 | sMAPE for Validation Set is: 51.07% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 19.98 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:02:46,859]\u001b[0m Trial 590 finished with value: 3.271386947943972 and parameters: {'n_hidden': 4, 'learning_rate': 0.001010864930314772, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3650929778032793, 'dropout_rate_Layer_2': 0.16890050908743323, 'dropout_rate_Layer_3': 0.1730858053473717, 'dropout_rate_Layer_4': 0.033076710666978204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04092816105380137, 'l1_Layer_2': 0.00039506492455929006, 'l1_Layer_3': 1.4552600922080097e-05, 'l1_Layer_4': 0.00014870520953855408, 'n_units_Layer_1': 135, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:50,377]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:54,989]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:02:55,212]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:00,350]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:01,233]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:03,205]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:07,439]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:08,066]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:12,746]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:16,647]\u001b[0m Trial 598 finished with value: 3.8360602951377714 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008963240057756322, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3925854794351528, 'dropout_rate_Layer_2': 0.16814331712945824, 'dropout_rate_Layer_3': 0.20406388051170693, 'dropout_rate_Layer_4': 0.04351202546415402, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.037834092372364174, 'l1_Layer_2': 0.00039934090045720455, 'l1_Layer_3': 1.0159756207468965e-05, 'l1_Layer_4': 0.00027996297530058056, 'n_units_Layer_1': 145, 'n_units_Layer_2': 260, 'n_units_Layer_3': 175, 'n_units_Layer_4': 90}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:16,783]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.84 | sMAPE for Validation Set is: 63.99% | rMAE for Validation Set is: 1.26\n",
      "MAE for Test Set is: 22.62 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 1.33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:03:22,294]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:22,457]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:25,628]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:28,949]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:29,664]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:33,353]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:36,056]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:41,463]\u001b[0m Trial 609 finished with value: 2.9667835166831753 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010349130996516684, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37883922369687417, 'dropout_rate_Layer_2': 0.148832707675598, 'dropout_rate_Layer_3': 0.162491300433292, 'dropout_rate_Layer_4': 0.008494354583411821, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0684543773044511, 'l1_Layer_2': 0.0002986719530178142, 'l1_Layer_3': 2.618760682986631e-05, 'l1_Layer_4': 0.00029462665373619564, 'n_units_Layer_1': 125, 'n_units_Layer_2': 230, 'n_units_Layer_3': 185, 'n_units_Layer_4': 90}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.97 | sMAPE for Validation Set is: 55.72% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 18.09 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:03:43,870]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:45,092]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:49,111]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:51,212]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:53,478]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:53,966]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:03:55,471]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:00,515]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:04,029]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:04,558]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:04,680]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:10,895]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:11,097]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:16,341]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:19,545]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:19,906]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:25,364]\u001b[0m Trial 626 finished with value: 4.90477424165222 and parameters: {'n_hidden': 3, 'learning_rate': 0.006802585841970286, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23427897219068594, 'dropout_rate_Layer_2': 0.05307929164523662, 'dropout_rate_Layer_3': 0.08997504059098205, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02944235759687873, 'l1_Layer_2': 0.01056986011042051, 'l1_Layer_3': 2.7353494047133282e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 90, 'n_units_Layer_3': 70}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.90 | sMAPE for Validation Set is: 65.88% | rMAE for Validation Set is: 1.62\n",
      "MAE for Test Set is: 20.99 | sMAPE for Test Set is: 24.68% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:04:26,034]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:26,333]\u001b[0m Trial 632 finished with value: 4.52347401586471 and parameters: {'n_hidden': 3, 'learning_rate': 0.006350115580840247, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2598627213033265, 'dropout_rate_Layer_2': 0.04470176582216534, 'dropout_rate_Layer_3': 0.13977649665970365, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001244716947101047, 'l1_Layer_2': 0.0028155341187944063, 'l1_Layer_3': 0.00026988376158219645, 'n_units_Layer_1': 145, 'n_units_Layer_2': 140, 'n_units_Layer_3': 110}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.52 | sMAPE for Validation Set is: 71.92% | rMAE for Validation Set is: 1.49\n",
      "MAE for Test Set is: 24.64 | sMAPE for Test Set is: 31.06% | rMAE for Test Set is: 1.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:04:33,168]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:33,526]\u001b[0m Trial 635 finished with value: 5.13253649343023 and parameters: {'n_hidden': 3, 'learning_rate': 0.004125899120533398, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.257167646535157, 'dropout_rate_Layer_2': 0.04225619178100515, 'dropout_rate_Layer_3': 0.14289802198275256, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012627749381650198, 'l1_Layer_2': 0.004992750785318802, 'l1_Layer_3': 0.00033329314770514767, 'n_units_Layer_1': 145, 'n_units_Layer_2': 140, 'n_units_Layer_3': 120}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.13 | sMAPE for Validation Set is: 68.82% | rMAE for Validation Set is: 1.69\n",
      "MAE for Test Set is: 61.72 | sMAPE for Test Set is: 128.52% | rMAE for Test Set is: 3.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:04:33,700]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:34,134]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:43,270]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:43,536]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:48,349]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:51,431]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:53,433]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:55,238]\u001b[0m Trial 641 finished with value: 2.586651123045851 and parameters: {'n_hidden': 3, 'learning_rate': 0.006831783870113288, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24575400571614137, 'dropout_rate_Layer_2': 0.05301399285990545, 'dropout_rate_Layer_3': 0.07547235200794195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027934755586622118, 'l1_Layer_2': 0.004959281218091563, 'l1_Layer_3': 0.00027110609823428894, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 135}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.59 | sMAPE for Validation Set is: 68.51% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 14.91 | sMAPE for Test Set is: 18.00% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:04:56,545]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:04:58,982]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:02,465]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:02,957]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:03,257]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:04,916]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:07,649]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:12,024]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:12,583]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:13,486]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:13,804]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:17,985]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:22,185]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:22,615]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:23,191]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:27,213]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:29,404]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:30,463]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:32,595]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:35,401]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:39,033]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:41,326]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:44,872]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:47,537]\u001b[0m Trial 658 finished with value: 2.7766618554981743 and parameters: {'n_hidden': 3, 'learning_rate': 0.005675028782133165, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26367196752701816, 'dropout_rate_Layer_2': 0.05032907419319068, 'dropout_rate_Layer_3': 0.06413446584192403, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02746997215506934, 'l1_Layer_2': 0.0043563172996872205, 'l1_Layer_3': 0.0002721022161347621, 'n_units_Layer_1': 255, 'n_units_Layer_2': 155, 'n_units_Layer_3': 115}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.78 | sMAPE for Validation Set is: 65.16% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 14.39 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:05:50,335]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:53,071]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:56,454]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:05:57,085]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:01,137]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:01,279]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:03,111]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:05,125]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:05,488]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:10,525]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:11,677]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:19,627]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:30,724]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:35,820]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.03 | sMAPE for Validation Set is: 59.69% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 21.31 | sMAPE for Test Set is: 24.58% | rMAE for Test Set is: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:06:41,416]\u001b[0m Trial 684 finished with value: 4.028302028582067 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010610980339012298, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36455066497573374, 'dropout_rate_Layer_2': 0.12089739598643065, 'dropout_rate_Layer_3': 0.18238366167008707, 'dropout_rate_Layer_4': 0.00315602584638733, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0264333305602505, 'l1_Layer_2': 0.00017977358102038327, 'l1_Layer_3': 2.5043779189099934e-05, 'l1_Layer_4': 0.00012551698387299555, 'n_units_Layer_1': 105, 'n_units_Layer_2': 245, 'n_units_Layer_3': 200, 'n_units_Layer_4': 105}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:42,136]\u001b[0m Trial 682 finished with value: 3.3920286206531642 and parameters: {'n_hidden': 3, 'learning_rate': 0.005429703629543098, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28922428685083945, 'dropout_rate_Layer_2': 0.056634223685629474, 'dropout_rate_Layer_3': 0.09063421465911559, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025915747466869657, 'l1_Layer_2': 0.004356351981773258, 'l1_Layer_3': 0.0003897212203388772, 'n_units_Layer_1': 255, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.39 | sMAPE for Validation Set is: 73.76% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 12.85 | sMAPE for Test Set is: 15.39% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:06:43,857]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.24 | sMAPE for Validation Set is: 57.13% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 34.13 | sMAPE for Test Set is: 51.31% | rMAE for Test Set is: 2.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:06:46,060]\u001b[0m Trial 685 finished with value: 3.2400706157807746 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010568312782666747, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3650123680180845, 'dropout_rate_Layer_2': 0.14575053556338088, 'dropout_rate_Layer_3': 0.19274478337658663, 'dropout_rate_Layer_4': 0.028397862956168647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.026534102730791542, 'l1_Layer_2': 0.00016859267190938817, 'l1_Layer_3': 2.5213563532559037e-05, 'l1_Layer_4': 0.00011893269280189091, 'n_units_Layer_1': 120, 'n_units_Layer_2': 270, 'n_units_Layer_3': 190, 'n_units_Layer_4': 85}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:48,249]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:49,204]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:52,886]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:55,178]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:06:57,375]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:00,731]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:03,258]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:07,543]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:09,948]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:11,780]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:15,013]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:17,901]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:22,623]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:25,736]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:29,964]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:32,218]\u001b[0m Trial 692 finished with value: 2.995593512656518 and parameters: {'n_hidden': 4, 'learning_rate': 0.000795561677712362, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22017732025575065, 'dropout_rate_Layer_2': 0.10760790892078279, 'dropout_rate_Layer_3': 0.285418559925892, 'dropout_rate_Layer_4': 0.07647918422303217, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.043263419307261644, 'l1_Layer_2': 0.00035718629039785475, 'l1_Layer_3': 4.177102799545236e-05, 'l1_Layer_4': 6.405149224465324e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 270, 'n_units_Layer_3': 160, 'n_units_Layer_4': 115}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.00 | sMAPE for Validation Set is: 46.88% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 19.19 | sMAPE for Test Set is: 21.62% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:07:38,622]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:44,684]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:53,405]\u001b[0m Trial 701 finished with value: 3.774483418951681 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008000003266526393, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3561961239007951, 'dropout_rate_Layer_2': 0.1197458313500098, 'dropout_rate_Layer_3': 0.15149646185153584, 'dropout_rate_Layer_4': 0.06136532320632867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07232697003117686, 'l1_Layer_2': 0.0003040621061987679, 'l1_Layer_3': 3.545793648083601e-05, 'l1_Layer_4': 9.375086170110885e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170, 'n_units_Layer_4': 85}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.77 | sMAPE for Validation Set is: 59.24% | rMAE for Validation Set is: 1.24\n",
      "MAE for Test Set is: 20.91 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:07:56,214]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:07:59,006]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:01,283]\u001b[0m Trial 703 finished with value: 3.672699049665846 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009496318459272459, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3549341242754948, 'dropout_rate_Layer_2': 0.10780487714778902, 'dropout_rate_Layer_3': 0.15185002179252788, 'dropout_rate_Layer_4': 0.05724167772377024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.018995714941725906, 'l1_Layer_2': 0.00035236580040953476, 'l1_Layer_3': 3.951635771140697e-05, 'l1_Layer_4': 8.405069002841177e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 190, 'n_units_Layer_4': 85}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.67 | sMAPE for Validation Set is: 56.39% | rMAE for Validation Set is: 1.21\n",
      "MAE for Test Set is: 20.98 | sMAPE for Test Set is: 24.47% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:08:02,974]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:07,180]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:07,257]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:07,273]\u001b[0m Trial 707 finished with value: 2.6218712484537727 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008305476755070987, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23538835652952284, 'dropout_rate_Layer_2': 0.10390078985579569, 'dropout_rate_Layer_3': 0.16195782140806442, 'dropout_rate_Layer_4': 0.05988998469590626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.07082749161044143, 'l1_Layer_2': 0.00013956303627923221, 'l1_Layer_3': 5.0571478352907457e-05, 'l1_Layer_4': 5.632676913008183e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 265, 'n_units_Layer_3': 125, 'n_units_Layer_4': 85}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 45.69% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 33.79 | sMAPE for Test Set is: 50.57% | rMAE for Test Set is: 1.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:08:08,769]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:14,909]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:15,225]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:16,641]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:20,450]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:21,904]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:22,396]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:31,364]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:35,862]\u001b[0m Trial 722 finished with value: 6.32868362727825 and parameters: {'n_hidden': 4, 'learning_rate': 0.001728850027155499, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037274429680588604, 'dropout_rate_Layer_2': 0.06988678796751507, 'dropout_rate_Layer_3': 0.1969950172845292, 'dropout_rate_Layer_4': 0.3152509374145821, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 3.477748303852467e-05, 'l1_Layer_2': 0.0002756334565312224, 'l1_Layer_3': 0.001249085460728154, 'l1_Layer_4': 0.0010566649159117366, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285, 'n_units_Layer_4': 65}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 77.56% | rMAE for Validation Set is: 2.08\n",
      "MAE for Test Set is: 65.52 | sMAPE for Test Set is: 144.04% | rMAE for Test Set is: 3.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:08:37,948]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:41,330]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:45,100]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:45,564]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:45,668]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:52,003]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:53,301]\u001b[0m Trial 721 finished with value: 3.5536093513728466 and parameters: {'n_hidden': 4, 'learning_rate': 0.000857750984430038, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18625480209115033, 'dropout_rate_Layer_2': 0.10093811941381647, 'dropout_rate_Layer_3': 0.21278529456294942, 'dropout_rate_Layer_4': 0.06964110281421676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08775204160134613, 'l1_Layer_2': 9.595771488019377e-05, 'l1_Layer_3': 5.206465180484573e-05, 'l1_Layer_4': 5.050086946006567e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 110, 'n_units_Layer_4': 90}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.55 | sMAPE for Validation Set is: 73.59% | rMAE for Validation Set is: 1.17\n",
      "MAE for Test Set is: 34.23 | sMAPE for Test Set is: 50.83% | rMAE for Test Set is: 2.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:08:53,451]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:57,134]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:08:59,699]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:00,345]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:04,058]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:07,617]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:08,289]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:11,970]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:15,822]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:17,618]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:21,715]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:22,236]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:22,462]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:29,564]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:30,071]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:30,216]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:31,250]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:39,035]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:41,669]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:44,272]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:47,438]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:52,650]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:55,179]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:56,200]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:09:59,576]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:09,900]\u001b[0m Trial 750 finished with value: 3.5830148440516427 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009994099872089402, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3842022189767013, 'dropout_rate_Layer_2': 0.1630277886610043, 'dropout_rate_Layer_3': 0.1751113364764227, 'dropout_rate_Layer_4': 0.027603787812942697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06353992292067466, 'l1_Layer_2': 0.00025680436266336984, 'l1_Layer_3': 3.15622589130082e-05, 'l1_Layer_4': 0.00021252435374344191, 'n_units_Layer_1': 135, 'n_units_Layer_2': 250, 'n_units_Layer_3': 185, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 56.30% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 22.55% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:10:13,349]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:13,710]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:13,977]\u001b[0m Trial 751 finished with value: 3.580773682525674 and parameters: {'n_hidden': 4, 'learning_rate': 0.001006741982283817, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38427641259201617, 'dropout_rate_Layer_2': 0.14031219338822798, 'dropout_rate_Layer_3': 0.1752007175828878, 'dropout_rate_Layer_4': 0.027732086577454962, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06807403657615338, 'l1_Layer_2': 0.00027546321788774245, 'l1_Layer_3': 3.18082348816515e-05, 'l1_Layer_4': 0.00014605116396236136, 'n_units_Layer_1': 135, 'n_units_Layer_2': 250, 'n_units_Layer_3': 170, 'n_units_Layer_4': 100}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.58 | sMAPE for Validation Set is: 56.10% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 20.08 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:10:19,512]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:21,331]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:21,642]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:24,130]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:26,627]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:30,031]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:30,222]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:32,768]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:38,332]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:39,011]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:42,188]\u001b[0m Trial 766 finished with value: 4.71342935348924 and parameters: {'n_hidden': 3, 'learning_rate': 0.005709836813666636, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21044969186366386, 'dropout_rate_Layer_2': 0.0320749033886455, 'dropout_rate_Layer_3': 0.10465434493722808, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.8381390920195435e-05, 'l1_Layer_2': 0.001740545161213063, 'l1_Layer_3': 0.0004630081728016741, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 65}. Best is trial 334 with value: 2.4793780098585696.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 4.71 | sMAPE for Validation Set is: 108.77% | rMAE for Validation Set is: 1.55\n",
      "MAE for Test Set is: 49.11 | sMAPE for Test Set is: 89.17% | rMAE for Test Set is: 2.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:10:45,097]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:45,353]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:45,548]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:46,004]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:53,347]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:53,488]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:53,791]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:10:54,358]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:01,461]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:01,657]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:02,197]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:03,105]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:10,191]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:12,388]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:13,408]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:15,634]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:15,700]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:20,646]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:23,797]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:27,232]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:31,458]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:31,569]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:36,547]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:39,404]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:42,082]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:42,366]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:44,602]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:49,318]\u001b[0m Trial 787 finished with value: 1.8459829569574076 and parameters: {'n_hidden': 3, 'learning_rate': 0.003902923433626292, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25229389271347435, 'dropout_rate_Layer_2': 0.0564774060991346, 'dropout_rate_Layer_3': 0.13408864135471799, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030738453832439273, 'l1_Layer_2': 0.0045045073930728985, 'l1_Layer_3': 2.0849139472793144e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 145, 'n_units_Layer_3': 215}. Best is trial 787 with value: 1.8459829569574076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.85 | sMAPE for Validation Set is: 39.01% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.93 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:11:49,817]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:50,611]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:56,609]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:11:57,559]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:02,498]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:02,963]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:03,602]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:04,335]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:10,639]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:12,272]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:14,577]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:15,141]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:16,995]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:21,675]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:22,582]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:26,265]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:26,654]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:31,481]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:36,043]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:41,887]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:44,496]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:48,371]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:48,970]\u001b[0m Trial 812 finished with value: 3.421292985170775 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010969197069536838, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.361094897876159, 'dropout_rate_Layer_2': 0.146954861825196, 'dropout_rate_Layer_3': 0.148436674733807, 'dropout_rate_Layer_4': 0.009789321171487493, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.02320353048530791, 'l1_Layer_2': 0.00012849791341349912, 'l1_Layer_3': 2.0622206932837544e-05, 'l1_Layer_4': 0.0001298822280904331, 'n_units_Layer_1': 140, 'n_units_Layer_2': 250, 'n_units_Layer_3': 200, 'n_units_Layer_4': 100}. Best is trial 787 with value: 1.8459829569574076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.42 | sMAPE for Validation Set is: 55.38% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 20.63 | sMAPE for Test Set is: 23.68% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:12:54,592]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:12:58,083]\u001b[0m Trial 817 finished with value: 3.4494513207502457 and parameters: {'n_hidden': 4, 'learning_rate': 0.000901646701241854, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34841945571840827, 'dropout_rate_Layer_2': 0.14861382453757987, 'dropout_rate_Layer_3': 0.14790047788579835, 'dropout_rate_Layer_4': 0.0012314604664005763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.023815941634789634, 'l1_Layer_2': 8.375495742957506e-05, 'l1_Layer_3': 2.1666463655671778e-05, 'l1_Layer_4': 9.127524743850066e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 275, 'n_units_Layer_3': 195, 'n_units_Layer_4': 115}. Best is trial 787 with value: 1.8459829569574076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.45 | sMAPE for Validation Set is: 53.96% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 20.92 | sMAPE for Test Set is: 24.24% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:13:00,883]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:01,001]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:02,042]\u001b[0m Trial 820 finished with value: 3.7198111020194617 and parameters: {'n_hidden': 4, 'learning_rate': 0.00094499277172746, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3590254049544692, 'dropout_rate_Layer_2': 0.14583257605428082, 'dropout_rate_Layer_3': 0.15793939627723036, 'dropout_rate_Layer_4': 0.005652777933304634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.022975746904559204, 'l1_Layer_2': 7.532295567194465e-05, 'l1_Layer_3': 2.135791912781414e-05, 'l1_Layer_4': 0.00017606437050808323, 'n_units_Layer_1': 130, 'n_units_Layer_2': 275, 'n_units_Layer_3': 180, 'n_units_Layer_4': 115}. Best is trial 787 with value: 1.8459829569574076.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.72 | sMAPE for Validation Set is: 81.81% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 33.55 | sMAPE for Test Set is: 50.06% | rMAE for Test Set is: 1.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:13:09,322]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:10,772]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:15,809]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:16,776]\u001b[0m Trial 823 finished with value: 1.6846976840410282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036372316335367967, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2725427122524462, 'dropout_rate_Layer_2': 0.05171025595395468, 'dropout_rate_Layer_3': 0.11755050488167565, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026721141136916333, 'l1_Layer_2': 0.005584768519370861, 'l1_Layer_3': 1.3447226299412826e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 823 with value: 1.6846976840410282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.68 | sMAPE for Validation Set is: 46.81% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 11.87% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:13:16,847]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:21,690]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:27,820]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:28,316]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:30,030]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:36,815]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:36,898]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:42,462]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:45,677]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:48,165]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:48,557]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:53,099]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:13:54,093]\u001b[0m Trial 830 finished with value: 1.843041581792918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035745191988590585, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2414809344172458, 'dropout_rate_Layer_2': 0.0896724032610245, 'dropout_rate_Layer_3': 0.05388299008435298, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.024219819297614114, 'l1_Layer_2': 0.005489011902923529, 'l1_Layer_3': 1.4579678713785046e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 160, 'n_units_Layer_3': 205}. Best is trial 823 with value: 1.6846976840410282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 41.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.93 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:13:57,948]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:02,257]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:04,920]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:08,948]\u001b[0m Trial 839 finished with value: 1.73668048760104 and parameters: {'n_hidden': 3, 'learning_rate': 0.004753301115932633, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2566720271238422, 'dropout_rate_Layer_2': 0.06987957113503847, 'dropout_rate_Layer_3': 0.1107665310146991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03305388426186083, 'l1_Layer_2': 0.0042029928149653825, 'l1_Layer_3': 2.1328143649390583e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210}. Best is trial 823 with value: 1.6846976840410282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 43.66% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 12.21% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:14:11,935]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:17,117]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:19,920]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:23,908]\u001b[0m Trial 846 finished with value: 1.8669870516660596 and parameters: {'n_hidden': 3, 'learning_rate': 0.003213984452585904, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2559100490136316, 'dropout_rate_Layer_2': 0.10091452494376701, 'dropout_rate_Layer_3': 0.053113983093085314, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023242381884699546, 'l1_Layer_2': 0.0042949739137691486, 'l1_Layer_3': 1.5866206892804535e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 225}. Best is trial 823 with value: 1.6846976840410282.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.87 | sMAPE for Validation Set is: 38.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 9.69 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:14:25,730]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:28,951]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:30,876]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:33,087]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:37,943]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:40,838]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:42,833]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:43,545]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:46,510]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:50,952]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:14:57,204]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:03,795]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:07,448]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 33.72% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:15:13,210]\u001b[0m Trial 861 finished with value: 1.5682813148921355 and parameters: {'n_hidden': 3, 'learning_rate': 0.004011642101389275, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24190143159260627, 'dropout_rate_Layer_2': 0.09327812773771524, 'dropout_rate_Layer_3': 0.03865019926833808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030706393427303996, 'l1_Layer_2': 0.0048222247728606105, 'l1_Layer_3': 1.4116049358776545e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 220}. Best is trial 861 with value: 1.5682813148921355.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:13,359]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:13,496]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:14,417]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:24,149]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:24,432]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:25,567]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:33,843]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:35,812]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:38,997]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:46,874]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:47,402]\u001b[0m Trial 870 finished with value: 1.9406624328540838 and parameters: {'n_hidden': 3, 'learning_rate': 0.003984782296909969, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24206355909569938, 'dropout_rate_Layer_2': 0.19013105736807556, 'dropout_rate_Layer_3': 0.03616389718377086, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0430671523557462, 'l1_Layer_2': 0.006897922308569764, 'l1_Layer_3': 2.0354310043633167e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 861 with value: 1.5682813148921355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 42.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 12.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:15:51,720]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:53,551]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:57,540]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:15:58,668]\u001b[0m Trial 875 finished with value: 1.9166473466186966 and parameters: {'n_hidden': 3, 'learning_rate': 0.005407334122594847, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2649334584212906, 'dropout_rate_Layer_2': 0.07322228051352583, 'dropout_rate_Layer_3': 0.04930331666932242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04449683475523656, 'l1_Layer_2': 0.0038417668443942897, 'l1_Layer_3': 1.4492360202461894e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 215}. Best is trial 861 with value: 1.5682813148921355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.92 | sMAPE for Validation Set is: 46.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.89 | sMAPE for Test Set is: 12.27% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:15:59,112]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:03,166]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:07,832]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:08,322]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:12,937]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:13,226]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:13,402]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:19,397]\u001b[0m Trial 885 finished with value: 3.9076576811512425 and parameters: {'n_hidden': 3, 'learning_rate': 0.005424576600083839, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.264230446496861, 'dropout_rate_Layer_2': 0.22345959204189927, 'dropout_rate_Layer_3': 0.042026790482444225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04510973740070365, 'l1_Layer_2': 0.008119073995169644, 'l1_Layer_3': 1.4143323139721732e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 90, 'n_units_Layer_3': 215}. Best is trial 861 with value: 1.5682813148921355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.91 | sMAPE for Validation Set is: 58.41% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 44.59 | sMAPE for Test Set is: 78.65% | rMAE for Test Set is: 2.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:16:22,023]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:25,736]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:26,021]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:26,064]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:36,198]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:40,730]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:41,481]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:46,131]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:48,947]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:51,595]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:51,977]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:54,081]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:56,261]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:16:56,506]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:01,080]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:02,966]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:03,091]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:05,753]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:06,093]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:10,675]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:14,786]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:15,296]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:15,404]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:15,782]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:23,979]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:24,580]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:25,162]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:32,707]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:33,751]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:33,794]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:36,626]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:36,878]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:40,193]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:40,672]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:45,350]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:45,881]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:53,377]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:56,187]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:58,263]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:17:59,835]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:03,829]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:06,013]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:08,470]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:11,862]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:15,974]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:18,920]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:24,881]\u001b[0m Trial 936 finished with value: 6.660595586913099 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005003560789784243, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06751869289912779, 'dropout_rate_Layer_2': 0.09024842803780862, 'dropout_rate_Layer_3': 0.2380654770897131, 'dropout_rate_Layer_4': 0.3008411573383503, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.0926333348894895e-05, 'l1_Layer_2': 0.0009382907858432901, 'l1_Layer_3': 0.0011778716639076663, 'l1_Layer_4': 0.0014750472215645247, 'n_units_Layer_1': 235, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300, 'n_units_Layer_4': 250}. Best is trial 861 with value: 1.5682813148921355.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 78.95% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 64.49 | sMAPE for Test Set is: 139.09% | rMAE for Test Set is: 3.80\n",
      "MAE for Validation Set is: 1.48 | sMAPE for Validation Set is: 34.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 11.67% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:18:25,006]\u001b[0m Trial 927 finished with value: 1.475933903673095 and parameters: {'n_hidden': 3, 'learning_rate': 0.006540061946190753, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24263583569323025, 'dropout_rate_Layer_2': 0.39604614482998035, 'dropout_rate_Layer_3': 0.05407646217389132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05319046648091635, 'l1_Layer_2': 0.0038144459544488503, 'l1_Layer_3': 1.593944727950232e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 210}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:25,513]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:32,101]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:32,973]\u001b[0m Trial 932 finished with value: 3.3489817712820567 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010591854580347625, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3619238208142464, 'dropout_rate_Layer_2': 0.16965668206431186, 'dropout_rate_Layer_3': 0.0446363027098379, 'dropout_rate_Layer_4': 0.03875513516681993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0202498681209358, 'l1_Layer_2': 0.0005162136708505507, 'l1_Layer_3': 8.716012983519068e-05, 'l1_Layer_4': 6.17823838365172e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 270, 'n_units_Layer_3': 275, 'n_units_Layer_4': 100}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.35 | sMAPE for Validation Set is: 50.63% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 19.90 | sMAPE for Test Set is: 22.83% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:18:33,173]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:38,478]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:39,642]\u001b[0m Trial 938 finished with value: 6.651675115357757 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005028161367971615, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07472157919450428, 'dropout_rate_Layer_2': 0.09990433807521057, 'dropout_rate_Layer_3': 0.24046166419108406, 'dropout_rate_Layer_4': 0.2985584751346124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.0273681860759934e-05, 'l1_Layer_2': 0.0008538492565539407, 'l1_Layer_3': 0.0012431937531830067, 'l1_Layer_4': 0.0009264955052775104, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300, 'n_units_Layer_4': 245}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 78.89% | rMAE for Validation Set is: 2.19\n",
      "MAE for Test Set is: 64.48 | sMAPE for Test Set is: 139.07% | rMAE for Test Set is: 3.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:18:39,791]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:42,395]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:44,518]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:47,583]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:49,063]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:50,488]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:52,456]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:18:57,803]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:00,118]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:00,758]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:02,534]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:08,066]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:08,190]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:08,400]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:14,413]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:15,767]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:16,649]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:18,559]\u001b[0m Trial 949 finished with value: 3.8064742046533744 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009076681277200324, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35463394750708593, 'dropout_rate_Layer_2': 0.17732168137261492, 'dropout_rate_Layer_3': 0.0346096688331964, 'dropout_rate_Layer_4': 0.028957338312442498, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.015416778976588285, 'l1_Layer_2': 0.000188065338355261, 'l1_Layer_3': 3.860249136650596e-05, 'l1_Layer_4': 5.456457389475215e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295, 'n_units_Layer_4': 105}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.81 | sMAPE for Validation Set is: 56.31% | rMAE for Validation Set is: 1.25\n",
      "MAE for Test Set is: 33.05 | sMAPE for Test Set is: 46.21% | rMAE for Test Set is: 1.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:19:26,562]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:32,819]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:37,455]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:38,011]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:41,597]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:43,779]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:50,137]\u001b[0m Trial 963 finished with value: 2.458886897324436 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010453911562543652, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3676858257979316, 'dropout_rate_Layer_2': 0.2171998203073193, 'dropout_rate_Layer_3': 0.16655228395972657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020465415332677702, 'l1_Layer_2': 0.00029108635655927204, 'l1_Layer_3': 2.43248013582578e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.46 | sMAPE for Validation Set is: 60.35% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 10.62 | sMAPE for Test Set is: 12.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:19:53,122]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:19:55,996]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:00,537]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:03,689]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:06,575]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:07,328]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:11,997]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:12,848]\u001b[0m Trial 964 finished with value: 2.6088177925467266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010297939388184347, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36875403984960026, 'dropout_rate_Layer_2': 0.22149605230764552, 'dropout_rate_Layer_3': 0.17873186260528887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020791016828894122, 'l1_Layer_2': 0.00030316069044264155, 'l1_Layer_3': 2.4171278286613245e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.61 | sMAPE for Validation Set is: 56.85% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 10.15 | sMAPE for Test Set is: 12.32% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:20:18,548]\u001b[0m Trial 968 finished with value: 3.346505713695271 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008240789454188048, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36677477068982745, 'dropout_rate_Layer_2': 0.16570905909655187, 'dropout_rate_Layer_3': 0.060607072249971264, 'dropout_rate_Layer_4': 0.04636629827695752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007308617580831579, 'l1_Layer_2': 0.0009135476051334216, 'l1_Layer_3': 8.407241197154254e-05, 'l1_Layer_4': 8.207804525914692e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270, 'n_units_Layer_4': 110}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 3.35 | sMAPE for Validation Set is: 54.66% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 19.81 | sMAPE for Test Set is: 22.27% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:20:20,334]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:21,235]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:21,607]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:21,734]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:28,703]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:29,018]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:29,310]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:29,567]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:38,122]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:38,799]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:39,504]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:39,674]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:42,635]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:47,863]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:49,752]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:49,864]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:49,928]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:54,280]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:20:57,079]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:00,718]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:01,511]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:05,262]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:10,545]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:12,060]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:14,054]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:18,287]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:18,420]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:20,213]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:22,427]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:23,362]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:23,448]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:32,543]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:32,889]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:33,048]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:33,576]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:39,847]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:41,977]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:42,457]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:43,682]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:51,589]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:56,582]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:21:59,905]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:03,442]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:08,466]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:13,866]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:19,035]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:23,204]\u001b[0m Trial 1018 finished with value: 1.5713954798419272 and parameters: {'n_hidden': 3, 'learning_rate': 0.006291770627794701, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26659928912201647, 'dropout_rate_Layer_2': 0.26668655386390183, 'dropout_rate_Layer_3': 0.04845433665569469, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09253104852704916, 'l1_Layer_2': 0.0029450291296348944, 'l1_Layer_3': 1.6981134449123434e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.57 | sMAPE for Validation Set is: 35.18% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 12.05% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:22:26,733]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:26,861]\u001b[0m Trial 1015 finished with value: 2.9028215862001225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010368598324321302, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36927012825405037, 'dropout_rate_Layer_2': 0.2189705068680399, 'dropout_rate_Layer_3': 0.1545824011213357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02761773764892987, 'l1_Layer_2': 0.0006143111757736388, 'l1_Layer_3': 3.1935872645920075e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.90 | sMAPE for Validation Set is: 60.20% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 10.98 | sMAPE for Test Set is: 13.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:22:30,400]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:32,048]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:34,483]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:39,887]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:41,886]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:43,122]\u001b[0m Trial 1017 finished with value: 2.6197526202113575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010354179976175897, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37024224695046765, 'dropout_rate_Layer_2': 0.20553775052734835, 'dropout_rate_Layer_3': 0.1670972893947211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02827013017737521, 'l1_Layer_2': 1.1670757771443935e-05, 'l1_Layer_3': 3.175350110236517e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 255, 'n_units_Layer_3': 270}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.62 | sMAPE for Validation Set is: 58.84% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:22:43,682]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:45,271]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:50,334]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:53,401]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:54,895]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:56,360]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:22:57,220]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:03,031]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:03,431]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:03,750]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:11,606]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:14,331]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:16,335]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:19,339]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:24,210]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:24,498]\u001b[0m Trial 1038 finished with value: 2.3112625712029007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0054394268297823095, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24861946693655296, 'dropout_rate_Layer_2': 0.19209683297652208, 'dropout_rate_Layer_3': 0.021312119302148068, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0231283169929149, 'l1_Layer_2': 0.004955764352439328, 'l1_Layer_3': 1.098368514422828e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 225}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.31 | sMAPE for Validation Set is: 43.24% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 14.10% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:23:31,085]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:31,601]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:33,953]\u001b[0m Trial 1044 finished with value: 1.8023064716882526 and parameters: {'n_hidden': 3, 'learning_rate': 0.005210661229897306, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25446283398664654, 'dropout_rate_Layer_2': 0.26466317002593404, 'dropout_rate_Layer_3': 0.01844802714177096, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03162248600975257, 'l1_Layer_2': 0.004301650505333127, 'l1_Layer_3': 1.3066888633691823e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.80 | sMAPE for Validation Set is: 35.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 12.17% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:23:39,414]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:39,617]\u001b[0m Trial 1048 finished with value: 1.842263590135614 and parameters: {'n_hidden': 3, 'learning_rate': 0.005212991996397727, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2846445371142635, 'dropout_rate_Layer_2': 0.1767305848538174, 'dropout_rate_Layer_3': 0.03216036539678056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03279838025683623, 'l1_Layer_2': 0.008393746423123185, 'l1_Layer_3': 2.1212525472646145e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.84 | sMAPE for Validation Set is: 55.09% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.85 | sMAPE for Test Set is: 12.11% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:23:40,563]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:41,293]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:50,898]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:51,213]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:54,804]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:55,925]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:23:56,237]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:00,411]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:04,150]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:04,933]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:05,043]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:06,406]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:14,815]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:15,008]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:15,872]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:16,887]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:24,415]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:25,057]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:25,534]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:26,150]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:35,170]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:35,593]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:41,571]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:47,256]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:50,906]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:51,489]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:57,028]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:24:58,597]\u001b[0m Trial 1075 finished with value: 2.1156347741623827 and parameters: {'n_hidden': 3, 'learning_rate': 0.005111032518619341, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2989182325761163, 'dropout_rate_Layer_2': 0.1939688649346234, 'dropout_rate_Layer_3': 0.028192441640558317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03420537964765465, 'l1_Layer_2': 0.00047835735015020186, 'l1_Layer_3': 1.9246298661053796e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 55.74% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 14.29% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:25:00,221]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:00,304]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:00,856]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:07,707]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:12,906]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:13,776]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:13,859]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:14,142]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:19,234]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:24,413]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:25,170]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:26,616]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:35,683]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:36,606]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:41,776]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:42,314]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:43,148]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:49,385]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:50,881]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:55,399]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:59,139]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:25:59,908]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:02,074]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:09,148]\u001b[0m Trial 1093 finished with value: 2.0713420121259674 and parameters: {'n_hidden': 3, 'learning_rate': 0.005938217554182702, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3156218618815285, 'dropout_rate_Layer_2': 0.2616586570096755, 'dropout_rate_Layer_3': 1.2570582524056712e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04664541682141093, 'l1_Layer_2': 0.004139874850519758, 'l1_Layer_3': 1.1355093538272272e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.07 | sMAPE for Validation Set is: 57.39% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 10.44 | sMAPE for Test Set is: 12.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:26:12,423]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:16,027]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:18,818]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:19,312]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:21,916]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:26,378]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:26,664]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:32,795]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:33,020]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:38,488]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:39,787]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:43,999]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:44,659]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:44,947]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:46,294]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:48,322]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:52,633]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:55,263]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:26:55,682]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:02,016]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:05,421]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:06,971]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:08,066]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:15,697]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:16,252]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:23,286]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:26,291]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:27,247]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:30,010]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:35,650]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:36,260]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:40,798]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:42,002]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:43,344]\u001b[0m Trial 1127 finished with value: 1.7358242158476909 and parameters: {'n_hidden': 3, 'learning_rate': 0.006151607072443889, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25983366105339845, 'dropout_rate_Layer_2': 0.2781928004076732, 'dropout_rate_Layer_3': 0.04033803978841878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018858799108883675, 'l1_Layer_2': 0.006129342895593195, 'l1_Layer_3': 1.2651894855074514e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 230}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.74 | sMAPE for Validation Set is: 41.28% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.58 | sMAPE for Test Set is: 11.76% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:27:49,128]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:49,351]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:52,537]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:55,371]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:56,246]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:27:58,012]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:04,385]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:05,987]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:06,868]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:13,479]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:14,109]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:20,544]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:20,734]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:23,076]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:27,244]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:28,953]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:29,925]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:37,621]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:37,851]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:38,500]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:46,183]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.86 | sMAPE for Validation Set is: 36.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 12.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:28:46,274]\u001b[0m Trial 1151 finished with value: 1.8634436343988003 and parameters: {'n_hidden': 3, 'learning_rate': 0.006350385205798924, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30971852811949563, 'dropout_rate_Layer_2': 0.24166854574254792, 'dropout_rate_Layer_3': 0.046613636880499215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02070946178197692, 'l1_Layer_2': 0.007623386368395094, 'l1_Layer_3': 1.1786849497485375e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 110, 'n_units_Layer_3': 225}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:53,009]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:58,643]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:28:59,856]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:03,964]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:06,079]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:06,807]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:07,683]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:14,373]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:16,868]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:20,104]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:20,540]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:21,700]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:27,312]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:28,244]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:29,617]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:38,651]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:39,197]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:39,317]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:45,580]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:47,830]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:50,770]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:56,296]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:56,445]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:56,797]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:29:57,370]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:06,914]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:07,125]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:07,431]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:08,440]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:16,161]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:17,656]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:17,979]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:18,281]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:20,680]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:26,884]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:29,531]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:31,544]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:38,429]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:43,470]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:49,405]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:30:55,670]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:00,194]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:10,364]\u001b[0m Trial 1198 finished with value: 1.9288284734608183 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010802914929746812, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3577649016560406, 'dropout_rate_Layer_2': 0.1550657264705998, 'dropout_rate_Layer_3': 0.16258333753516818, 'dropout_rate_Layer_4': 0.0007443083673755839, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04833186266222045, 'l1_Layer_2': 0.00015127285866529003, 'l1_Layer_3': 4.420549298768282e-05, 'l1_Layer_4': 0.00011534103626631386, 'n_units_Layer_1': 100, 'n_units_Layer_2': 265, 'n_units_Layer_3': 285, 'n_units_Layer_4': 105}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.93 | sMAPE for Validation Set is: 43.02% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 10.66 | sMAPE for Test Set is: 12.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:31:10,881]\u001b[0m Trial 1196 finished with value: 2.0426460782796174 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010783812575358605, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3662500567945514, 'dropout_rate_Layer_2': 0.15896447817694112, 'dropout_rate_Layer_3': 0.13325480448753163, 'dropout_rate_Layer_4': 0.0702994436760425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.045037044169722956, 'l1_Layer_2': 2.1430731373857063e-05, 'l1_Layer_3': 6.639232332774999e-05, 'l1_Layer_4': 0.00010695236926144881, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285, 'n_units_Layer_4': 105}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 43.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 12.10% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:31:19,083]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:23,753]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:26,288]\u001b[0m Trial 1201 finished with value: 2.0374446201573506 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010951482970542191, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08401781980793913, 'dropout_rate_Layer_2': 0.08991131512978229, 'dropout_rate_Layer_3': 0.061396303401988955, 'dropout_rate_Layer_4': 0.07220726634273854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04697394285962597, 'l1_Layer_2': 0.00015313733479813122, 'l1_Layer_3': 4.359834125402594e-05, 'l1_Layer_4': 0.00011340231810930322, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 90, 'n_units_Layer_4': 105}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.04 | sMAPE for Validation Set is: 51.98% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 9.82 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:31:28,515]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:29,979]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:35,165]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:44,224]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:48,348]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:52,115]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:54,952]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:55,585]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:31:58,208]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:00,540]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:02,261]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:09,094]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:09,637]\u001b[0m Trial 1207 finished with value: 2.428940956291631 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010595850444794523, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3594901448435748, 'dropout_rate_Layer_2': 0.15830204475469498, 'dropout_rate_Layer_3': 0.15121078885612524, 'dropout_rate_Layer_4': 0.07055344787873029, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05146735283936143, 'l1_Layer_2': 1.6683148068888665e-05, 'l1_Layer_3': 7.884129784090714e-05, 'l1_Layer_4': 8.92138020889284e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285, 'n_units_Layer_4': 105}. Best is trial 927 with value: 1.475933903673095.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.43 | sMAPE for Validation Set is: 56.41% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 13.96% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:32:15,793]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:16,628]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:22,910]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:23,123]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:23,410]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:31,806]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:32,200]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:33,521]\u001b[0m Trial 1220 finished with value: 1.2376338800751954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034852457160552764, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3190161665117791, 'dropout_rate_Layer_2': 0.3782340821188409, 'dropout_rate_Layer_3': 0.0729274186752821, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03457035901942046, 'l1_Layer_2': 0.011363842984334347, 'l1_Layer_3': 1.024043735059095e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205}. Best is trial 1220 with value: 1.2376338800751954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.24 | sMAPE for Validation Set is: 23.16% | rMAE for Validation Set is: 0.41\n",
      "MAE for Test Set is: 9.67 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:32:39,360]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:44,137]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:47,972]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:50,185]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:50,246]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:51,023]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:32:52,284]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:00,769]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:01,157]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:01,251]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:09,584]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:09,802]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:16,685]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:16,692]\u001b[0m Trial 1239 finished with value: 2.3392236585404547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038329990050246757, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3073552368231671, 'dropout_rate_Layer_2': 0.38146124270538895, 'dropout_rate_Layer_3': 0.02610584960224769, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023798807179009656, 'l1_Layer_2': 0.01055485907397962, 'l1_Layer_3': 2.6904897396654622e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 1220 with value: 1.2376338800751954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.34 | sMAPE for Validation Set is: 45.88% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 13.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:33:22,196]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:22,880]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:24,166]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:26,731]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:29,716]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:32,447]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:35,369]\u001b[0m Trial 1235 finished with value: 1.392181772490481 and parameters: {'n_hidden': 3, 'learning_rate': 0.002940822591809132, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3182279074109924, 'dropout_rate_Layer_2': 0.3975849683258068, 'dropout_rate_Layer_3': 0.07369715495249357, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03290978274086565, 'l1_Layer_2': 0.011249844421925004, 'l1_Layer_3': 1.3649615594007138e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 1220 with value: 1.2376338800751954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.39 | sMAPE for Validation Set is: 31.62% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 9.73 | sMAPE for Test Set is: 11.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:33:36,597]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:39,276]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:41,670]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:46,989]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:52,812]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:53,068]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:33:54,091]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:01,737]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:04,557]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:07,272]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:10,773]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:20,023]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:20,611]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:25,910]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:26,349]\u001b[0m Trial 1261 finished with value: 1.2977479747148057 and parameters: {'n_hidden': 3, 'learning_rate': 0.003952061133801905, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32519080581944515, 'dropout_rate_Layer_2': 0.18782717671124755, 'dropout_rate_Layer_3': 0.07441770526662382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030015755160988908, 'l1_Layer_2': 0.011644844550238348, 'l1_Layer_3': 1.6890167593660513e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 1220 with value: 1.2376338800751954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.30 | sMAPE for Validation Set is: 23.71% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 10.19 | sMAPE for Test Set is: 12.83% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:34:27,345]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:34,179]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:36,886]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:40,120]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:42,277]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:44,766]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:48,275]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:49,263]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:53,510]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:56,621]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:57,517]\u001b[0m Trial 1256 finished with value: 2.3208118454792372 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013010803025476226, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37420809030803176, 'dropout_rate_Layer_2': 0.15478178061392886, 'dropout_rate_Layer_3': 0.1511414249909368, 'dropout_rate_Layer_4': 0.06209940889771824, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.037384088079256375, 'l1_Layer_2': 0.00014332137886730452, 'l1_Layer_3': 3.2911580727853525e-05, 'l1_Layer_4': 0.000141885987623254, 'n_units_Layer_1': 100, 'n_units_Layer_2': 235, 'n_units_Layer_3': 75, 'n_units_Layer_4': 105}. Best is trial 1220 with value: 1.2376338800751954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.32 | sMAPE for Validation Set is: 57.08% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 10.65 | sMAPE for Test Set is: 12.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:34:57,727]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:34:58,682]\u001b[0m Trial 1266 finished with value: 1.3802186763198734 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029998837455292595, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3265891591533771, 'dropout_rate_Layer_2': 0.3912739802723343, 'dropout_rate_Layer_3': 0.07561599814155522, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.028019999176355614, 'l1_Layer_2': 0.010253130107507303, 'l1_Layer_3': 1.6463814825976262e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 1220 with value: 1.2376338800751954.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.38 | sMAPE for Validation Set is: 34.84% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.54 | sMAPE for Test Set is: 13.40% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:35:03,765]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:03,989]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:10,038]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:13,051]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:16,650]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:17,351]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:22,945]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:24,133]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:24,762]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:28,125]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:33,676]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:34,558]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:36,966]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:40,808]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:42,790]\u001b[0m Trial 1284 finished with value: 1.1238227707258286 and parameters: {'n_hidden': 3, 'learning_rate': 0.002904075426942006, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33856153194102706, 'dropout_rate_Layer_2': 0.3861727976160483, 'dropout_rate_Layer_3': 0.08405091882363272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020071875758757116, 'l1_Layer_2': 0.015705105022746337, 'l1_Layer_3': 1.2216180212994558e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 210}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.12 | sMAPE for Validation Set is: 18.97% | rMAE for Validation Set is: 0.37\n",
      "MAE for Test Set is: 9.60 | sMAPE for Test Set is: 11.86% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:35:43,523]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:50,472]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:50,998]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:56,794]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:35:57,821]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:02,836]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:06,208]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:09,423]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:13,775]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:20,939]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:21,455]\u001b[0m Trial 1294 finished with value: 1.5469051785892987 and parameters: {'n_hidden': 3, 'learning_rate': 0.003844242084633925, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3333741771665167, 'dropout_rate_Layer_2': 0.36810739790373015, 'dropout_rate_Layer_3': 0.06369752373954131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02693649826892023, 'l1_Layer_2': 0.014720968893519409, 'l1_Layer_3': 1.2240863539103842e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.55 | sMAPE for Validation Set is: 44.46% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 12.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:36:29,381]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:33,965]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:37,026]\u001b[0m Trial 1292 finished with value: 2.2032161983699576 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009322276250262445, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.387167360393613, 'dropout_rate_Layer_2': 0.09534850002498191, 'dropout_rate_Layer_3': 0.16102768180189894, 'dropout_rate_Layer_4': 0.05461210999239427, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03474395295173084, 'l1_Layer_2': 0.00015224173413686687, 'l1_Layer_3': 5.778366760878734e-05, 'l1_Layer_4': 0.00011822923827414825, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 95, 'n_units_Layer_4': 120}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.20 | sMAPE for Validation Set is: 57.04% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 12.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:36:38,488]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:38,895]\u001b[0m Trial 1305 finished with value: 1.3739936304067502 and parameters: {'n_hidden': 3, 'learning_rate': 0.003261632169662945, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33571008196119595, 'dropout_rate_Layer_2': 0.37903105714437957, 'dropout_rate_Layer_3': 0.07586644058282326, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015838564462983044, 'l1_Layer_2': 0.01354792379658257, 'l1_Layer_3': 1.4686772215447336e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.37 | sMAPE for Validation Set is: 26.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 10.31 | sMAPE for Test Set is: 12.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:36:40,390]\u001b[0m Trial 1304 finished with value: 1.2188852207953442 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029499965797868, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33509851324301065, 'dropout_rate_Layer_2': 0.3696253219411439, 'dropout_rate_Layer_3': 0.06284614922970347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01476275774793271, 'l1_Layer_2': 0.016585835111777907, 'l1_Layer_3': 1.2196180252718804e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.22 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.40\n",
      "MAE for Test Set is: 9.87 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:36:43,730]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:49,899]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:50,854]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:56,581]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:56,709]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:36:59,515]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:05,302]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:08,876]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:10,320]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:15,102]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:16,048]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:20,286]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:20,812]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:21,397]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:21,978]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:31,493]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:31,933]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:37,721]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:38,749]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:43,808]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:45,110]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:49,299]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:51,156]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:55,888]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:37:57,419]\u001b[0m Trial 1324 finished with value: 1.4575581448732036 and parameters: {'n_hidden': 3, 'learning_rate': 0.003032694846374079, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33800965060572097, 'dropout_rate_Layer_2': 0.35232045411962315, 'dropout_rate_Layer_3': 0.08509594122600043, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015450420448525947, 'l1_Layer_2': 0.019618596339158183, 'l1_Layer_3': 1.0159100158454402e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 180}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.46 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 9.75 | sMAPE for Test Set is: 12.07% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:38:01,354]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:02,153]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:06,444]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:06,883]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:08,040]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:12,753]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:15,519]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:17,660]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:20,849]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:21,119]\u001b[0m Trial 1333 finished with value: 1.299230562706539 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031993000217117556, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3325679337486506, 'dropout_rate_Layer_2': 0.38880480055600625, 'dropout_rate_Layer_3': 0.05580662065655726, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017392715311598767, 'l1_Layer_2': 0.013702367959613238, 'l1_Layer_3': 1.0118978533919294e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 105, 'n_units_Layer_3': 210}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.30 | sMAPE for Validation Set is: 24.28% | rMAE for Validation Set is: 0.43\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 12.00% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:38:29,594]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:29,911]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:30,395]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:42,615]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:45,652]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:46,202]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:46,298]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:46,572]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:52,739]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:53,411]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:58,104]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:38:58,798]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:03,091]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:07,989]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:11,627]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:15,404]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:15,864]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:21,860]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:28,973]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:30,130]\u001b[0m Trial 1356 finished with value: 1.227010606679799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028936809968686974, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3242778264118831, 'dropout_rate_Layer_2': 0.38978106424014924, 'dropout_rate_Layer_3': 0.07555005330749448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018832453060302547, 'l1_Layer_2': 0.01758954507914418, 'l1_Layer_3': 1.3360845073394772e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.23 | sMAPE for Validation Set is: 28.04% | rMAE for Validation Set is: 0.40\n",
      "MAE for Test Set is: 9.81 | sMAPE for Test Set is: 12.04% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:39:30,602]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:35,245]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:38,022]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:42,208]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:42,630]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:43,834]\u001b[0m Trial 1361 finished with value: 1.5039856922908743 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034876086415366503, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3495384384757098, 'dropout_rate_Layer_2': 0.39890844031071626, 'dropout_rate_Layer_3': 0.09372820362952197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009759976413377959, 'l1_Layer_2': 0.014312812789472102, 'l1_Layer_3': 1.2070956293450168e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 100, 'n_units_Layer_3': 210}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.50 | sMAPE for Validation Set is: 34.11% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 9.87 | sMAPE for Test Set is: 12.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:39:49,259]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:49,822]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:53,459]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:57,163]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:39:58,332]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:00,030]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:03,636]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:05,670]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:05,801]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:07,557]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:15,485]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:17,303]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:18,356]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:19,535]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:25,983]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:27,278]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:33,788]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:37,664]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:39,479]\u001b[0m Trial 1383 finished with value: 1.1624585747544482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033644336202539983, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3362446061048604, 'dropout_rate_Layer_2': 0.376423937815563, 'dropout_rate_Layer_3': 0.08306245168789039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02131613450466447, 'l1_Layer_2': 0.014294320533267669, 'l1_Layer_3': 1.6421791685750682e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.16 | sMAPE for Validation Set is: 28.42% | rMAE for Validation Set is: 0.38\n",
      "MAE for Test Set is: 9.91 | sMAPE for Test Set is: 12.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:40:42,614]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:46,506]\u001b[0m Trial 1387 finished with value: 1.2137037341209507 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022882988729727815, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3241844588559387, 'dropout_rate_Layer_2': 0.3726340979370881, 'dropout_rate_Layer_3': 0.08353602085906874, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020726165252032625, 'l1_Layer_2': 0.014814985527855361, 'l1_Layer_3': 1.64504169629825e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 205}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.21 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.40\n",
      "MAE for Test Set is: 9.97 | sMAPE for Test Set is: 12.22% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:40:46,676]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:52,312]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:40:59,427]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:03,453]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:12,695]\u001b[0m Trial 1394 finished with value: 1.187797373960568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021918035754758527, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.337272352324007, 'dropout_rate_Layer_2': 0.3785173628251526, 'dropout_rate_Layer_3': 0.09509088432529512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015036960866716033, 'l1_Layer_2': 0.012477738551490187, 'l1_Layer_3': 1.8496380680096675e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.19 | sMAPE for Validation Set is: 26.12% | rMAE for Validation Set is: 0.39\n",
      "MAE for Test Set is: 9.96 | sMAPE for Test Set is: 12.39% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:41:23,000]\u001b[0m Trial 1388 finished with value: 1.9398589248919276 and parameters: {'n_hidden': 4, 'learning_rate': 0.001033664729217445, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3563493660214218, 'dropout_rate_Layer_2': 0.1311535216088381, 'dropout_rate_Layer_3': 0.17421694173557858, 'dropout_rate_Layer_4': 0.052841329173042934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05360129043613668, 'l1_Layer_2': 0.00021221726941570457, 'l1_Layer_3': 2.278518425288519e-05, 'l1_Layer_4': 6.996888756294589e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295, 'n_units_Layer_4': 105}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.94 | sMAPE for Validation Set is: 38.57% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 12.03% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:41:23,911]\u001b[0m Trial 1392 finished with value: 1.949450667960675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010366197068389282, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000963847761647485, 'dropout_rate_Layer_2': 0.12260826813289036, 'dropout_rate_Layer_3': 0.37697562671372903, 'dropout_rate_Layer_4': 0.015549668551455242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05320551918940557, 'l1_Layer_2': 0.00021241243017636175, 'l1_Layer_3': 2.3164242638801904e-05, 'l1_Layer_4': 0.00011490800499647683, 'n_units_Layer_1': 105, 'n_units_Layer_2': 250, 'n_units_Layer_3': 80, 'n_units_Layer_4': 105}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.95 | sMAPE for Validation Set is: 42.41% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 11.99% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:41:31,372]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:35,744]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:38,115]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:42,301]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:49,024]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:49,791]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:55,327]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:56,893]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:41:59,605]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:04,847]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:05,675]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:06,082]\u001b[0m Trial 1399 finished with value: 2.1202028393825674 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010536086550292307, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22870012357741942, 'dropout_rate_Layer_2': 0.12228044060613616, 'dropout_rate_Layer_3': 0.3455424593159476, 'dropout_rate_Layer_4': 0.05025028127687808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05037088157689875, 'l1_Layer_2': 0.0002283045952483476, 'l1_Layer_3': 3.9883631375123445e-05, 'l1_Layer_4': 0.00010900251152404858, 'n_units_Layer_1': 90, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 110}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.12 | sMAPE for Validation Set is: 47.45% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 9.78 | sMAPE for Test Set is: 12.01% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 1.29 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 11.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:42:11,504]\u001b[0m Trial 1403 finished with value: 1.286630225860295 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020451397886500876, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3701650657288151, 'dropout_rate_Layer_2': 0.36865441377109354, 'dropout_rate_Layer_3': 0.09517652320533174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014988730343102583, 'l1_Layer_2': 0.02750079437246743, 'l1_Layer_3': 1.988468565981132e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:12,768]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:17,787]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:22,415]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:22,625]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:28,223]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:28,741]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:30,462]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:41,757]\u001b[0m Trial 1412 finished with value: 1.3458153927377399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024998330736939007, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3792244036721259, 'dropout_rate_Layer_2': 0.3694283521120766, 'dropout_rate_Layer_3': 0.09910483227005132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010332606750550616, 'l1_Layer_2': 0.016231178077271837, 'l1_Layer_3': 2.0208141595477805e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.35 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.44\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 12.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:42:45,195]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:50,840]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:54,211]\u001b[0m Trial 1419 finished with value: 1.220271721320467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022325467299834957, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3692425957635822, 'dropout_rate_Layer_2': 0.3643215206467231, 'dropout_rate_Layer_3': 0.0963615604152586, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010729505212638317, 'l1_Layer_2': 0.022475877989211752, 'l1_Layer_3': 1.8475617285927026e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.22 | sMAPE for Validation Set is: 31.72% | rMAE for Validation Set is: 0.40\n",
      "MAE for Test Set is: 9.94 | sMAPE for Test Set is: 12.30% | rMAE for Test Set is: 0.59\n",
      "MAE for Validation Set is: 1.27 | sMAPE for Validation Set is: 29.73% | rMAE for Validation Set is: 0.42\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 12.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:42:54,278]\u001b[0m Trial 1421 finished with value: 1.2656849115883575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016505742258438555, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38155025528677194, 'dropout_rate_Layer_2': 0.37309800085360095, 'dropout_rate_Layer_3': 0.10052806166514015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009316997792113856, 'l1_Layer_2': 0.024623881355374896, 'l1_Layer_3': 1.8064458256147325e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:54,674]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:42:55,286]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:01,487]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:04,683]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:06,014]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:07,070]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:13,827]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:17,396]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:22,613]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:26,995]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:32,635]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:35,701]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:39,804]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:41,159]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:43,140]\u001b[0m Trial 1433 finished with value: 1.2212791044660738 and parameters: {'n_hidden': 3, 'learning_rate': 0.002412433607255928, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38792445325352776, 'dropout_rate_Layer_2': 0.3793217327823953, 'dropout_rate_Layer_3': 0.09982194345939187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005593583843611403, 'l1_Layer_2': 0.037522472839703974, 'l1_Layer_3': 1.789485224335912e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.22 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.40\n",
      "MAE for Test Set is: 9.77 | sMAPE for Test Set is: 11.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:43:47,975]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:49,493]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:50,384]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:58,281]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:43:58,816]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:04,622]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:04,858]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:12,161]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:12,670]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:18,623]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:23,531]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:26,662]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:29,472]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:29,777]\u001b[0m Trial 1437 finished with value: 2.155836496127765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010126086201645487, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23832732143226337, 'dropout_rate_Layer_2': 0.12392549047868723, 'dropout_rate_Layer_3': 0.3929144463624616, 'dropout_rate_Layer_4': 0.07048163121061696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08669521205092987, 'l1_Layer_2': 0.00019604331191149717, 'l1_Layer_3': 5.971488399239796e-05, 'l1_Layer_4': 4.7109624206607056e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.16 | sMAPE for Validation Set is: 46.45% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 9.74 | sMAPE for Test Set is: 11.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:44:37,511]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:45,987]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:50,001]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:53,492]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:44:56,569]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.36 | sMAPE for Validation Set is: 50.12% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 9.92 | sMAPE for Test Set is: 12.43% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:44:57,991]\u001b[0m Trial 1443 finished with value: 2.3586386215376876 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010126619300697495, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19995649902951002, 'dropout_rate_Layer_2': 0.12442840600813437, 'dropout_rate_Layer_3': 0.37762640628622324, 'dropout_rate_Layer_4': 0.08562750273826966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08042571953824221, 'l1_Layer_2': 0.0002848773629325632, 'l1_Layer_3': 5.631007563433606e-05, 'l1_Layer_4': 5.7978288539178125e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90, 'n_units_Layer_4': 140}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:02,003]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:02,305]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:08,497]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:09,791]\u001b[0m Trial 1460 finished with value: 6.6190490919810925 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005005036280695323, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.059048796148773036, 'dropout_rate_Layer_2': 0.12234349395944834, 'dropout_rate_Layer_3': 0.1852304309896442, 'dropout_rate_Layer_4': 0.29013699800926673, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.1611194464060947e-05, 'l1_Layer_2': 0.0007716448388204982, 'l1_Layer_3': 0.0013095604115239455, 'l1_Layer_4': 0.0006901200334399101, 'n_units_Layer_1': 175, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295, 'n_units_Layer_4': 245}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 78.79% | rMAE for Validation Set is: 2.18\n",
      "MAE for Test Set is: 64.66 | sMAPE for Test Set is: 139.90% | rMAE for Test Set is: 3.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:45:11,032]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:18,469]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:19,365]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:20,965]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:26,793]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:28,157]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:34,143]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:37,751]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:39,988]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:42,451]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:45,308]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:52,278]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:45:56,023]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:04,272]\u001b[0m Trial 1464 finished with value: 2.103670759541549 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012598032874523509, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24962021823736028, 'dropout_rate_Layer_2': 0.06209945344023437, 'dropout_rate_Layer_3': 0.39297382052559815, 'dropout_rate_Layer_4': 0.08497397919856825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.08550548292438255, 'l1_Layer_2': 9.80301418654728e-05, 'l1_Layer_3': 7.424621567585965e-05, 'l1_Layer_4': 3.350199334881195e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 285, 'n_units_Layer_3': 90, 'n_units_Layer_4': 155}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 2.10 | sMAPE for Validation Set is: 61.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 10.01 | sMAPE for Test Set is: 12.08% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:46:05,014]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:05,222]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:10,653]\u001b[0m Trial 1475 finished with value: 1.1354787619078504 and parameters: {'n_hidden': 3, 'learning_rate': 0.002102773840877094, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3266474961588655, 'dropout_rate_Layer_2': 0.3998122340108207, 'dropout_rate_Layer_3': 0.07854750450176377, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011856659449817328, 'l1_Layer_2': 0.030271725187739247, 'l1_Layer_3': 3.089697084159195e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 205}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.14 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.37\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 12.58% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:46:16,089]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:16,954]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:21,023]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:27,022]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:29,421]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:30,188]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:32,973]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:33,151]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:41,486]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:41,674]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:47,965]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:51,894]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:55,600]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:46:58,271]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:47:01,808]\u001b[0m Trial 1488 finished with value: 1.3820049354191888 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018552221346753847, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36622748720863046, 'dropout_rate_Layer_2': 0.39057788369978286, 'dropout_rate_Layer_3': 0.09004807913602722, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.012215352514925136, 'l1_Layer_2': 0.020157066270439297, 'l1_Layer_3': 2.1718383115988127e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 95, 'n_units_Layer_3': 180}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.38 | sMAPE for Validation Set is: 27.03% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 10.08 | sMAPE for Test Set is: 12.42% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:47:05,256]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:47:05,807]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:47:10,413]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:47:14,008]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 02:47:23,908]\u001b[0m Trial 1498 finished with value: 1.230837832125338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017771907527256458, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37348064795702457, 'dropout_rate_Layer_2': 0.3830366583439671, 'dropout_rate_Layer_3': 0.080573479028141, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01040635998856426, 'l1_Layer_2': 0.022658366530150555, 'l1_Layer_3': 2.518823091287021e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.23 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.41\n",
      "MAE for Test Set is: 9.68 | sMAPE for Test Set is: 11.90% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 02:47:25,120]\u001b[0m Trial 1499 finished with value: 1.1449561765279446 and parameters: {'n_hidden': 3, 'learning_rate': 0.001648700716416888, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3674089225827468, 'dropout_rate_Layer_2': 0.38518820319595526, 'dropout_rate_Layer_3': 0.08012776467100441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004894629964864172, 'l1_Layer_2': 0.02443806217923776, 'l1_Layer_3': 2.451652113081103e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 190}. Best is trial 1284 with value: 1.1238227707258286.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 1.14 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.38\n",
      "MAE for Test Set is: 9.91 | sMAPE for Test Set is: 12.28% | rMAE for Test Set is: 0.58\n",
      "for 2021-01-01, MAE is:1.05 & sMAPE is:3.92% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :1.05 & 3.92% & 0.15\n",
      "for 2021-01-02, MAE is:1.02 & sMAPE is:3.75% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :1.03 & 3.83% & 0.13\n",
      "for 2021-01-03, MAE is:0.80 & sMAPE is:3.05% & rMAE is:0.04 ||| daily mean of MAE & sMAPE & rMAE till now are :0.96 & 3.57% & 0.10\n",
      "for 2021-01-04, MAE is:16.10 & sMAPE is:40.85% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :4.74 & 12.89% & 0.25\n",
      "for 2021-01-05, MAE is:14.08 & sMAPE is:31.37% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 16.59% & 0.32\n",
      "for 2021-01-06, MAE is:7.78 & sMAPE is:19.22% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 17.03% & 0.34\n",
      "for 2021-01-07, MAE is:25.20 & sMAPE is:41.24% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 20.49% & 0.37\n",
      "for 2021-01-08, MAE is:23.27 & sMAPE is:30.98% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :11.16 & 21.80% & 0.39\n",
      "for 2021-01-09, MAE is:8.04 & sMAPE is:14.71% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.82 & 21.01% & 0.37\n",
      "for 2021-01-10, MAE is:9.58 & sMAPE is:21.38% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 21.05% & 0.40\n",
      "for 2021-01-11, MAE is:4.61 & sMAPE is:11.08% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 20.14% & 0.40\n",
      "for 2021-01-12, MAE is:10.28 & sMAPE is:24.04% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 20.47% & 0.52\n",
      "for 2021-01-13, MAE is:4.85 & sMAPE is:11.56% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 19.78% & 0.55\n",
      "for 2021-01-14, MAE is:28.65 & sMAPE is:45.60% & rMAE is:6.10 ||| daily mean of MAE & sMAPE & rMAE till now are :11.09 & 21.63% & 0.94\n",
      "for 2021-01-15, MAE is:15.36 & sMAPE is:21.76% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :11.38 & 21.63% & 1.00\n",
      "for 2021-01-16, MAE is:10.76 & sMAPE is:18.45% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :11.34 & 21.44% & 1.09\n",
      "for 2021-01-17, MAE is:5.91 & sMAPE is:11.04% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 20.82% & 1.06\n",
      "for 2021-01-18, MAE is:8.16 & sMAPE is:14.63% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.86 & 20.48% & 1.03\n",
      "for 2021-01-19, MAE is:6.36 & sMAPE is:14.49% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 20.16% & 1.05\n",
      "for 2021-01-20, MAE is:5.64 & sMAPE is:15.83% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 19.95% & 1.03\n",
      "for 2021-01-21, MAE is:5.12 & sMAPE is:17.05% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 19.81% & 0.99\n",
      "for 2021-01-22, MAE is:4.79 & sMAPE is:16.12% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.88 & 19.64% & 0.95\n",
      "for 2021-01-23, MAE is:6.42 & sMAPE is:15.27% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.73 & 19.45% & 0.93\n",
      "for 2021-01-24, MAE is:8.23 & sMAPE is:17.28% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.67 & 19.36% & 0.96\n",
      "for 2021-01-25, MAE is:14.63 & sMAPE is:25.36% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 19.60% & 1.00\n",
      "for 2021-01-26, MAE is:9.64 & sMAPE is:16.55% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.86 & 19.48% & 0.99\n",
      "for 2021-01-27, MAE is:8.04 & sMAPE is:14.22% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.79 & 19.29% & 0.96\n",
      "for 2021-01-28, MAE is:6.55 & sMAPE is:11.78% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 19.02% & 0.94\n",
      "for 2021-01-29, MAE is:6.25 & sMAPE is:12.03% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 18.78% & 0.92\n",
      "for 2021-01-30, MAE is:5.35 & sMAPE is:10.91% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.42 & 18.52% & 0.91\n",
      "for 2021-01-31, MAE is:4.86 & sMAPE is:9.87% & rMAE is:2.86 ||| daily mean of MAE & sMAPE & rMAE till now are :9.27 & 18.24% & 0.97\n",
      "for 2021-02-01, MAE is:36.00 & sMAPE is:40.66% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 18.94% & 0.98\n",
      "for 2021-02-02, MAE is:22.93 & sMAPE is:32.28% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 19.34% & 1.01\n",
      "for 2021-02-03, MAE is:14.84 & sMAPE is:27.33% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 19.58% & 1.03\n",
      "for 2021-02-04, MAE is:15.48 & sMAPE is:26.63% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.76 & 19.78% & 1.05\n",
      "for 2021-02-05, MAE is:30.48 & sMAPE is:33.17% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 20.15% & 1.05\n",
      "for 2021-02-06, MAE is:11.65 & sMAPE is:23.42% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :11.32 & 20.24% & 1.11\n",
      "for 2021-02-07, MAE is:5.56 & sMAPE is:12.87% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.17 & 20.05% & 1.10\n",
      "for 2021-02-08, MAE is:11.85 & sMAPE is:21.14% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 20.07% & 1.08\n",
      "for 2021-02-09, MAE is:17.74 & sMAPE is:25.41% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 20.21% & 1.09\n",
      "for 2021-02-10, MAE is:15.30 & sMAPE is:21.47% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :11.44 & 20.24% & 1.08\n",
      "for 2021-02-11, MAE is:38.49 & sMAPE is:36.39% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 20.62% & 1.08\n",
      "for 2021-02-12, MAE is:36.40 & sMAPE is:40.36% & rMAE is:3.39 ||| daily mean of MAE & sMAPE & rMAE till now are :12.65 & 21.08% & 1.13\n",
      "for 2021-02-13, MAE is:15.29 & sMAPE is:26.05% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :12.71 & 21.19% & 1.15\n",
      "for 2021-02-14, MAE is:8.26 & sMAPE is:16.65% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :12.61 & 21.09% & 1.16\n",
      "for 2021-02-15, MAE is:19.05 & sMAPE is:25.79% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :12.75 & 21.20% & 1.18\n",
      "for 2021-02-16, MAE is:8.16 & sMAPE is:14.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 21.05% & 1.16\n",
      "for 2021-02-17, MAE is:7.01 & sMAPE is:14.01% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 20.91% & 1.14\n",
      "for 2021-02-18, MAE is:12.77 & sMAPE is:25.75% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 21.00% & 1.13\n",
      "for 2021-02-19, MAE is:5.89 & sMAPE is:12.54% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :12.41 & 20.84% & 1.11\n",
      "for 2021-02-20, MAE is:8.70 & sMAPE is:21.43% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.34 & 20.85% & 1.10\n",
      "for 2021-02-21, MAE is:5.23 & sMAPE is:14.73% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.20 & 20.73% & 1.08\n",
      "for 2021-02-22, MAE is:2.08 & sMAPE is:4.93% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 20.43% & 1.06\n",
      "for 2021-02-23, MAE is:3.18 & sMAPE is:7.93% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.85 & 20.20% & 1.05\n",
      "for 2021-02-24, MAE is:5.88 & sMAPE is:17.57% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :11.74 & 20.15% & 1.04\n",
      "for 2021-02-25, MAE is:2.81 & sMAPE is:9.10% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.58 & 19.95% & 1.02\n",
      "for 2021-02-26, MAE is:3.25 & sMAPE is:10.56% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :11.43 & 19.79% & 1.01\n",
      "for 2021-02-27, MAE is:4.35 & sMAPE is:13.04% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :11.31 & 19.67% & 1.02\n",
      "for 2021-02-28, MAE is:1.83 & sMAPE is:5.45% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :11.15 & 19.43% & 1.01\n",
      "for 2021-03-01, MAE is:1.77 & sMAPE is:4.66% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 19.19% & 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-02, MAE is:6.40 & sMAPE is:15.13% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.92 & 19.12% & 1.01\n",
      "for 2021-03-03, MAE is:3.76 & sMAPE is:8.33% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.80 & 18.95% & 1.00\n",
      "for 2021-03-04, MAE is:3.83 & sMAPE is:9.29% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.69 & 18.79% & 0.99\n",
      "for 2021-03-05, MAE is:8.75 & sMAPE is:17.97% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.66 & 18.78% & 0.99\n",
      "for 2021-03-06, MAE is:4.46 & sMAPE is:11.46% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 18.67% & 1.00\n",
      "for 2021-03-07, MAE is:2.21 & sMAPE is:5.79% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 18.47% & 1.00\n",
      "for 2021-03-08, MAE is:18.16 & sMAPE is:33.35% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 18.69% & 1.00\n",
      "for 2021-03-09, MAE is:10.27 & sMAPE is:18.17% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 18.69% & 0.99\n",
      "for 2021-03-10, MAE is:12.10 & sMAPE is:25.21% & rMAE is:5.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.57 & 18.78% & 1.06\n",
      "for 2021-03-11, MAE is:2.23 & sMAPE is:6.42% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 18.60% & 1.05\n",
      "for 2021-03-12, MAE is:1.98 & sMAPE is:5.43% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 18.42% & 1.04\n",
      "for 2021-03-13, MAE is:0.76 & sMAPE is:2.05% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 18.19% & 1.03\n",
      "for 2021-03-14, MAE is:2.87 & sMAPE is:7.67% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 18.05% & 1.04\n",
      "for 2021-03-15, MAE is:3.50 & sMAPE is:7.73% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 17.91% & 1.03\n",
      "for 2021-03-16, MAE is:6.51 & sMAPE is:13.34% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.97 & 17.85% & 1.02\n",
      "for 2021-03-17, MAE is:7.22 & sMAPE is:13.85% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 17.79% & 1.02\n",
      "for 2021-03-18, MAE is:3.78 & sMAPE is:7.74% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.85 & 17.66% & 1.01\n",
      "for 2021-03-19, MAE is:0.95 & sMAPE is:2.30% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 17.47% & 1.00\n",
      "for 2021-03-20, MAE is:2.80 & sMAPE is:7.35% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.65 & 17.34% & 1.00\n",
      "for 2021-03-21, MAE is:2.73 & sMAPE is:7.65% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 17.22% & 1.01\n",
      "for 2021-03-22, MAE is:3.20 & sMAPE is:7.52% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 17.10% & 1.02\n",
      "for 2021-03-23, MAE is:3.67 & sMAPE is:8.02% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 16.99% & 1.02\n",
      "for 2021-03-24, MAE is:1.94 & sMAPE is:4.75% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 16.84% & 1.01\n",
      "for 2021-03-25, MAE is:1.74 & sMAPE is:4.43% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.23 & 16.69% & 1.00\n",
      "for 2021-03-26, MAE is:2.15 & sMAPE is:5.63% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 16.56% & 0.99\n",
      "for 2021-03-27, MAE is:1.77 & sMAPE is:4.85% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 16.43% & 0.99\n",
      "for 2021-03-28, MAE is:1.74 & sMAPE is:4.69% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 16.29% & 0.99\n",
      "for 2021-03-29, MAE is:1.99 & sMAPE is:5.28% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 16.17% & 0.98\n",
      "for 2021-03-30, MAE is:1.61 & sMAPE is:4.20% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.82 & 16.03% & 0.97\n",
      "for 2021-03-31, MAE is:1.64 & sMAPE is:4.19% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.74 & 15.90% & 0.98\n",
      "for 2021-04-01, MAE is:1.66 & sMAPE is:4.27% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 15.77% & 0.99\n",
      "for 2021-04-02, MAE is:6.50 & sMAPE is:19.28% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 15.81% & 1.00\n",
      "for 2021-04-03, MAE is:4.69 & sMAPE is:13.51% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 15.79% & 1.01\n",
      "for 2021-04-04, MAE is:8.09 & sMAPE is:25.85% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 15.89% & 1.01\n",
      "for 2021-04-05, MAE is:9.78 & sMAPE is:40.64% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 16.15% & 1.00\n",
      "for 2021-04-06, MAE is:8.03 & sMAPE is:23.94% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 16.23% & 1.02\n",
      "for 2021-04-07, MAE is:2.11 & sMAPE is:5.28% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.53 & 16.12% & 1.03\n",
      "for 2021-04-08, MAE is:3.53 & sMAPE is:8.12% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 16.04% & 1.03\n",
      "for 2021-04-09, MAE is:2.14 & sMAPE is:5.60% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 15.93% & 1.02\n",
      "for 2021-04-10, MAE is:5.20 & sMAPE is:13.64% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 15.91% & 1.02\n",
      "for 2021-04-11, MAE is:2.77 & sMAPE is:7.02% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 15.82% & 1.02\n",
      "for 2021-04-12, MAE is:5.67 & sMAPE is:13.18% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 15.80% & 1.01\n",
      "for 2021-04-13, MAE is:2.84 & sMAPE is:6.51% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.25 & 15.71% & 1.00\n",
      "for 2021-04-14, MAE is:6.99 & sMAPE is:15.03% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.23 & 15.70% & 1.00\n",
      "for 2021-04-15, MAE is:9.16 & sMAPE is:16.91% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 15.71% & 1.00\n",
      "for 2021-04-16, MAE is:2.75 & sMAPE is:5.76% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 15.62% & 0.99\n",
      "for 2021-04-17, MAE is:2.01 & sMAPE is:4.23% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.13 & 15.51% & 0.99\n",
      "for 2021-04-18, MAE is:2.20 & sMAPE is:4.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 15.41% & 0.98\n",
      "for 2021-04-19, MAE is:2.56 & sMAPE is:5.28% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 15.32% & 0.98\n",
      "for 2021-04-20, MAE is:2.39 & sMAPE is:5.07% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.98 & 15.22% & 0.97\n",
      "for 2021-04-21, MAE is:4.54 & sMAPE is:10.48% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 15.18% & 0.97\n",
      "for 2021-04-22, MAE is:2.73 & sMAPE is:6.82% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 15.11% & 0.96\n",
      "for 2021-04-23, MAE is:2.90 & sMAPE is:6.53% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 15.03% & 0.96\n",
      "for 2021-04-24, MAE is:3.78 & sMAPE is:8.50% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 14.97% & 0.97\n",
      "for 2021-04-25, MAE is:4.66 & sMAPE is:10.74% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 14.94% & 0.97\n",
      "for 2021-04-26, MAE is:10.66 & sMAPE is:18.66% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 14.97% & 0.97\n",
      "for 2021-04-27, MAE is:6.04 & sMAPE is:10.66% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 14.93% & 0.97\n",
      "for 2021-04-28, MAE is:8.24 & sMAPE is:13.88% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 14.92% & 0.96\n",
      "for 2021-04-29, MAE is:6.70 & sMAPE is:11.86% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 14.90% & 0.96\n",
      "for 2021-04-30, MAE is:6.67 & sMAPE is:11.24% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 14.87% & 0.96\n",
      "for 2021-05-01, MAE is:3.06 & sMAPE is:6.16% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 14.80% & 0.95\n",
      "for 2021-05-02, MAE is:5.43 & sMAPE is:12.03% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 14.77% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-03, MAE is:14.34 & sMAPE is:25.09% & rMAE is:3.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 14.86% & 0.98\n",
      "for 2021-05-04, MAE is:8.32 & sMAPE is:16.95% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 14.87% & 0.98\n",
      "for 2021-05-05, MAE is:4.77 & sMAPE is:9.60% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 14.83% & 0.98\n",
      "for 2021-05-06, MAE is:15.24 & sMAPE is:26.31% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 14.92% & 0.98\n",
      "for 2021-05-07, MAE is:9.34 & sMAPE is:13.92% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 14.91% & 0.98\n",
      "for 2021-05-08, MAE is:7.14 & sMAPE is:13.43% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 14.90% & 0.98\n",
      "for 2021-05-09, MAE is:8.81 & sMAPE is:17.91% & rMAE is:2.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 14.93% & 1.00\n",
      "for 2021-05-10, MAE is:3.58 & sMAPE is:7.20% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 14.87% & 0.99\n",
      "for 2021-05-11, MAE is:4.72 & sMAPE is:9.13% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 14.82% & 0.99\n",
      "for 2021-05-12, MAE is:1.12 & sMAPE is:2.12% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 14.73% & 0.98\n",
      "for 2021-05-13, MAE is:1.99 & sMAPE is:3.99% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 14.65% & 0.97\n",
      "for 2021-05-14, MAE is:1.81 & sMAPE is:3.62% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 14.56% & 0.97\n",
      "for 2021-05-15, MAE is:1.80 & sMAPE is:3.72% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 14.48% & 0.96\n",
      "for 2021-05-16, MAE is:13.81 & sMAPE is:38.23% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 14.66% & 0.97\n",
      "for 2021-05-17, MAE is:11.10 & sMAPE is:23.16% & rMAE is:2.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 14.72% & 0.98\n",
      "for 2021-05-18, MAE is:6.18 & sMAPE is:11.74% & rMAE is:2.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 14.70% & 0.99\n",
      "for 2021-05-19, MAE is:2.09 & sMAPE is:3.90% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 14.62% & 1.00\n",
      "for 2021-05-20, MAE is:1.85 & sMAPE is:3.54% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 14.54% & 0.99\n",
      "for 2021-05-21, MAE is:16.48 & sMAPE is:48.85% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 14.78% & 0.99\n",
      "for 2021-05-22, MAE is:22.97 & sMAPE is:96.62% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 15.36% & 0.99\n",
      "for 2021-05-23, MAE is:17.48 & sMAPE is:64.19% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 15.70% & 1.00\n",
      "for 2021-05-24, MAE is:10.62 & sMAPE is:27.65% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 15.79% & 0.99\n",
      "for 2021-05-25, MAE is:4.99 & sMAPE is:10.22% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 15.75% & 0.99\n",
      "for 2021-05-26, MAE is:4.50 & sMAPE is:9.25% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 15.70% & 0.99\n",
      "for 2021-05-27, MAE is:2.57 & sMAPE is:5.09% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 15.63% & 1.00\n",
      "for 2021-05-28, MAE is:1.98 & sMAPE is:3.88% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 15.55% & 0.99\n",
      "for 2021-05-29, MAE is:6.50 & sMAPE is:15.38% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 15.55% & 0.99\n",
      "for 2021-05-30, MAE is:12.51 & sMAPE is:35.42% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 15.68% & 0.99\n",
      "for 2021-05-31, MAE is:10.67 & sMAPE is:22.39% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 15.73% & 0.98\n",
      "for 2021-06-01, MAE is:4.56 & sMAPE is:9.65% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 15.69% & 0.99\n",
      "for 2021-06-02, MAE is:4.19 & sMAPE is:8.72% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 15.64% & 0.99\n",
      "for 2021-06-03, MAE is:3.83 & sMAPE is:7.86% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 15.59% & 0.99\n",
      "for 2021-06-04, MAE is:3.85 & sMAPE is:7.55% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 15.54% & 0.99\n",
      "for 2021-06-05, MAE is:1.12 & sMAPE is:2.38% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 15.45% & 0.99\n",
      "for 2021-06-06, MAE is:1.63 & sMAPE is:3.68% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 15.38% & 0.98\n",
      "for 2021-06-07, MAE is:6.94 & sMAPE is:13.64% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 15.37% & 0.99\n",
      "for 2021-06-08, MAE is:4.34 & sMAPE is:8.07% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 15.32% & 0.99\n",
      "for 2021-06-09, MAE is:3.13 & sMAPE is:5.75% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 15.26% & 0.99\n",
      "for 2021-06-10, MAE is:3.00 & sMAPE is:5.56% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 15.20% & 0.98\n",
      "for 2021-06-11, MAE is:2.49 & sMAPE is:4.79% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 15.14% & 0.98\n",
      "for 2021-06-12, MAE is:13.33 & sMAPE is:43.74% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 15.31% & 0.98\n",
      "for 2021-06-13, MAE is:22.57 & sMAPE is:106.43% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 15.87% & 0.98\n",
      "for 2021-06-14, MAE is:12.89 & sMAPE is:31.68% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 15.97% & 0.99\n",
      "for 2021-06-15, MAE is:0.99 & sMAPE is:2.12% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 15.88% & 0.99\n",
      "for 2021-06-16, MAE is:2.60 & sMAPE is:5.72% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 15.82% & 0.98\n",
      "for 2021-06-17, MAE is:4.34 & sMAPE is:9.94% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 15.79% & 0.98\n",
      "for 2021-06-18, MAE is:1.05 & sMAPE is:2.59% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 15.71% & 0.97\n",
      "for 2021-06-19, MAE is:1.22 & sMAPE is:3.07% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 15.63% & 0.97\n",
      "for 2021-06-20, MAE is:2.44 & sMAPE is:6.76% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 15.58% & 0.96\n",
      "for 2021-06-21, MAE is:1.67 & sMAPE is:3.93% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 15.51% & 0.96\n",
      "for 2021-06-22, MAE is:0.56 & sMAPE is:1.27% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 15.43% & 0.95\n",
      "for 2021-06-23, MAE is:1.84 & sMAPE is:4.08% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 15.37% & 0.95\n",
      "for 2021-06-24, MAE is:1.40 & sMAPE is:2.97% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 15.30% & 0.95\n",
      "for 2021-06-25, MAE is:2.43 & sMAPE is:5.37% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 15.24% & 0.95\n",
      "for 2021-06-26, MAE is:1.78 & sMAPE is:3.87% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 15.17% & 0.94\n",
      "for 2021-06-27, MAE is:4.23 & sMAPE is:9.47% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 15.14% & 0.94\n",
      "for 2021-06-28, MAE is:3.61 & sMAPE is:7.25% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 15.10% & 0.94\n",
      "for 2021-06-29, MAE is:1.32 & sMAPE is:2.61% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 15.03% & 0.93\n",
      "for 2021-06-30, MAE is:1.65 & sMAPE is:3.38% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 14.97% & 0.93\n",
      "for 2021-07-01, MAE is:1.31 & sMAPE is:2.67% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 14.90% & 0.93\n",
      "for 2021-07-02, MAE is:2.09 & sMAPE is:4.10% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 14.84% & 0.93\n",
      "for 2021-07-03, MAE is:1.41 & sMAPE is:2.79% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 14.77% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-04, MAE is:3.27 & sMAPE is:6.17% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 14.73% & 0.92\n",
      "for 2021-07-05, MAE is:5.54 & sMAPE is:10.16% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 14.70% & 0.92\n",
      "for 2021-07-06, MAE is:1.25 & sMAPE is:2.23% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 14.64% & 0.92\n",
      "for 2021-07-07, MAE is:3.76 & sMAPE is:6.85% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 14.59% & 0.92\n",
      "for 2021-07-08, MAE is:2.60 & sMAPE is:4.58% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 14.54% & 0.91\n",
      "for 2021-07-09, MAE is:2.77 & sMAPE is:4.99% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 14.49% & 0.91\n",
      "for 2021-07-10, MAE is:1.94 & sMAPE is:3.59% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 14.43% & 0.91\n",
      "for 2021-07-11, MAE is:3.20 & sMAPE is:5.79% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 14.39% & 0.91\n",
      "for 2021-07-12, MAE is:4.13 & sMAPE is:7.41% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 14.35% & 0.92\n",
      "for 2021-07-13, MAE is:2.16 & sMAPE is:3.79% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 14.30% & 0.92\n",
      "for 2021-07-14, MAE is:4.24 & sMAPE is:7.33% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 14.26% & 0.92\n",
      "for 2021-07-15, MAE is:3.05 & sMAPE is:5.18% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 14.22% & 0.92\n",
      "for 2021-07-16, MAE is:2.04 & sMAPE is:3.40% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 14.16% & 0.92\n",
      "for 2021-07-17, MAE is:5.05 & sMAPE is:9.60% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.14% & 0.92\n",
      "for 2021-07-18, MAE is:16.63 & sMAPE is:45.85% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 14.30% & 0.92\n",
      "for 2021-07-19, MAE is:12.00 & sMAPE is:22.54% & rMAE is:3.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 14.34% & 0.93\n",
      "for 2021-07-20, MAE is:3.00 & sMAPE is:5.20% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 14.29% & 0.94\n",
      "for 2021-07-21, MAE is:1.30 & sMAPE is:2.19% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 14.23% & 0.93\n",
      "for 2021-07-22, MAE is:1.23 & sMAPE is:2.13% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 14.17% & 0.93\n",
      "for 2021-07-23, MAE is:1.36 & sMAPE is:2.34% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 14.12% & 0.93\n",
      "for 2021-07-24, MAE is:1.07 & sMAPE is:1.87% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 14.06% & 0.93\n",
      "for 2021-07-25, MAE is:3.11 & sMAPE is:5.71% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 14.02% & 0.92\n",
      "for 2021-07-26, MAE is:3.69 & sMAPE is:6.51% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 13.98% & 0.93\n",
      "for 2021-07-27, MAE is:1.00 & sMAPE is:1.75% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.67 & 13.92% & 0.93\n",
      "for 2021-07-28, MAE is:0.69 & sMAPE is:1.23% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 13.86% & 0.92\n",
      "for 2021-07-29, MAE is:7.84 & sMAPE is:15.18% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 13.87% & 0.92\n",
      "for 2021-07-30, MAE is:2.80 & sMAPE is:5.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 13.82% & 0.92\n",
      "for 2021-07-31, MAE is:10.12 & sMAPE is:21.68% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 13.86% & 0.92\n",
      "for 2021-08-01, MAE is:3.77 & sMAPE is:6.95% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 13.83% & 0.92\n",
      "for 2021-08-02, MAE is:3.01 & sMAPE is:5.43% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 13.79% & 0.93\n",
      "for 2021-08-03, MAE is:1.37 & sMAPE is:2.40% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.74% & 0.93\n",
      "for 2021-08-04, MAE is:2.25 & sMAPE is:3.81% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 13.69% & 0.93\n",
      "for 2021-08-05, MAE is:1.94 & sMAPE is:3.25% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 13.64% & 0.93\n",
      "for 2021-08-06, MAE is:2.65 & sMAPE is:4.50% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.53 & 13.60% & 0.93\n",
      "for 2021-08-07, MAE is:2.91 & sMAPE is:4.90% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 13.56% & 0.92\n",
      "for 2021-08-08, MAE is:17.95 & sMAPE is:46.52% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 13.71% & 0.93\n",
      "for 2021-08-09, MAE is:9.86 & sMAPE is:16.99% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 13.73% & 0.93\n",
      "for 2021-08-10, MAE is:7.57 & sMAPE is:11.58% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.72% & 0.93\n",
      "for 2021-08-11, MAE is:6.50 & sMAPE is:9.52% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 13.70% & 0.92\n",
      "for 2021-08-12, MAE is:4.87 & sMAPE is:7.00% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 13.67% & 0.92\n",
      "for 2021-08-13, MAE is:2.37 & sMAPE is:3.38% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.62% & 0.92\n",
      "for 2021-08-14, MAE is:5.58 & sMAPE is:8.39% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 13.60% & 0.92\n",
      "for 2021-08-15, MAE is:7.64 & sMAPE is:11.62% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 13.59% & 0.92\n",
      "for 2021-08-16, MAE is:2.97 & sMAPE is:4.22% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 13.55% & 0.91\n",
      "for 2021-08-17, MAE is:5.59 & sMAPE is:9.61% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 13.53% & 0.91\n",
      "for 2021-08-18, MAE is:2.47 & sMAPE is:3.47% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.49% & 0.91\n",
      "for 2021-08-19, MAE is:6.30 & sMAPE is:8.73% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.47% & 0.92\n",
      "for 2021-08-20, MAE is:5.85 & sMAPE is:7.73% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 13.44% & 0.91\n",
      "for 2021-08-21, MAE is:3.01 & sMAPE is:3.95% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.40% & 0.91\n",
      "for 2021-08-22, MAE is:5.11 & sMAPE is:6.70% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 13.37% & 0.91\n",
      "for 2021-08-23, MAE is:1.70 & sMAPE is:2.17% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.33% & 0.91\n",
      "for 2021-08-24, MAE is:4.12 & sMAPE is:5.29% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.29% & 0.90\n",
      "for 2021-08-25, MAE is:3.92 & sMAPE is:5.08% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 13.26% & 0.90\n",
      "for 2021-08-26, MAE is:5.52 & sMAPE is:6.77% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 13.23% & 0.90\n",
      "for 2021-08-27, MAE is:2.83 & sMAPE is:3.25% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 13.19% & 0.90\n",
      "for 2021-08-28, MAE is:2.94 & sMAPE is:3.55% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.15% & 0.90\n",
      "for 2021-08-29, MAE is:5.24 & sMAPE is:6.30% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.42 & 13.12% & 0.90\n",
      "for 2021-08-30, MAE is:13.66 & sMAPE is:13.68% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 13.12% & 0.90\n",
      "for 2021-08-31, MAE is:11.52 & sMAPE is:10.61% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.11% & 0.89\n",
      "for 2021-09-01, MAE is:9.31 & sMAPE is:8.80% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.09% & 0.89\n",
      "for 2021-09-02, MAE is:5.45 & sMAPE is:5.34% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 13.06% & 0.89\n",
      "for 2021-09-03, MAE is:4.79 & sMAPE is:4.92% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.03% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-04, MAE is:6.50 & sMAPE is:6.80% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 13.00% & 0.89\n",
      "for 2021-09-05, MAE is:7.82 & sMAPE is:8.03% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 12.98% & 0.89\n",
      "for 2021-09-06, MAE is:16.22 & sMAPE is:14.32% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 12.99% & 0.89\n",
      "for 2021-09-07, MAE is:6.89 & sMAPE is:6.32% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 12.96% & 0.88\n",
      "for 2021-09-08, MAE is:5.68 & sMAPE is:5.24% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 12.93% & 0.88\n",
      "for 2021-09-09, MAE is:2.64 & sMAPE is:2.48% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 12.89% & 0.88\n",
      "for 2021-09-10, MAE is:4.52 & sMAPE is:4.30% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 12.86% & 0.88\n",
      "for 2021-09-11, MAE is:4.11 & sMAPE is:4.02% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 12.82% & 0.88\n",
      "for 2021-09-12, MAE is:9.10 & sMAPE is:9.12% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 12.81% & 0.88\n",
      "for 2021-09-13, MAE is:4.02 & sMAPE is:4.05% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.48 & 12.77% & 0.88\n",
      "for 2021-09-14, MAE is:12.16 & sMAPE is:10.77% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 12.76% & 0.88\n",
      "for 2021-09-15, MAE is:6.06 & sMAPE is:5.50% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 12.74% & 0.88\n",
      "for 2021-09-16, MAE is:10.32 & sMAPE is:8.76% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 12.72% & 0.88\n",
      "for 2021-09-17, MAE is:5.58 & sMAPE is:4.68% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 12.69% & 0.87\n",
      "for 2021-09-18, MAE is:8.70 & sMAPE is:7.41% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 12.67% & 0.88\n",
      "for 2021-09-19, MAE is:15.35 & sMAPE is:16.19% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 12.68% & 0.88\n",
      "for 2021-09-20, MAE is:9.55 & sMAPE is:8.49% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 12.67% & 0.88\n",
      "for 2021-09-21, MAE is:5.24 & sMAPE is:4.51% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.56 & 12.64% & 0.88\n",
      "for 2021-09-22, MAE is:4.83 & sMAPE is:4.34% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 12.61% & 0.88\n",
      "for 2021-09-23, MAE is:16.83 & sMAPE is:15.95% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 12.62% & 0.88\n",
      "for 2021-09-24, MAE is:7.19 & sMAPE is:7.18% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 12.60% & 0.88\n",
      "for 2021-09-25, MAE is:10.89 & sMAPE is:10.42% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 12.59% & 0.88\n",
      "for 2021-09-26, MAE is:5.17 & sMAPE is:4.91% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 12.56% & 0.88\n",
      "for 2021-09-27, MAE is:4.00 & sMAPE is:3.80% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 12.53% & 0.87\n",
      "for 2021-09-28, MAE is:4.69 & sMAPE is:4.37% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 12.50% & 0.87\n",
      "for 2021-09-29, MAE is:6.35 & sMAPE is:6.22% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 12.48% & 0.87\n",
      "for 2021-09-30, MAE is:10.64 & sMAPE is:11.79% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 12.47% & 0.87\n",
      "for 2021-10-01, MAE is:11.66 & sMAPE is:15.04% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 12.48% & 0.87\n",
      "for 2021-10-02, MAE is:13.83 & sMAPE is:19.03% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 12.51% & 0.87\n",
      "for 2021-10-03, MAE is:30.30 & sMAPE is:60.80% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 12.68% & 0.87\n",
      "for 2021-10-04, MAE is:11.35 & sMAPE is:13.21% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 12.68% & 0.87\n",
      "for 2021-10-05, MAE is:9.37 & sMAPE is:10.10% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 12.67% & 0.87\n",
      "for 2021-10-06, MAE is:10.79 & sMAPE is:10.91% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 12.67% & 0.87\n",
      "for 2021-10-07, MAE is:14.63 & sMAPE is:12.93% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 12.67% & 0.87\n",
      "for 2021-10-08, MAE is:5.21 & sMAPE is:4.50% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 12.64% & 0.87\n",
      "for 2021-10-09, MAE is:5.64 & sMAPE is:5.03% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 12.61% & 0.87\n",
      "for 2021-10-10, MAE is:6.23 & sMAPE is:5.81% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 12.59% & 0.86\n",
      "for 2021-10-11, MAE is:4.67 & sMAPE is:4.28% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 12.56% & 0.86\n",
      "for 2021-10-12, MAE is:9.90 & sMAPE is:8.56% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 12.54% & 0.86\n",
      "for 2021-10-13, MAE is:15.29 & sMAPE is:11.94% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 12.54% & 0.86\n",
      "for 2021-10-14, MAE is:23.58 & sMAPE is:21.15% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 12.57% & 0.86\n",
      "for 2021-10-15, MAE is:9.83 & sMAPE is:11.19% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 12.57% & 0.86\n",
      "for 2021-10-16, MAE is:8.41 & sMAPE is:8.78% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 12.55% & 0.86\n",
      "for 2021-10-17, MAE is:8.46 & sMAPE is:8.00% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 12.54% & 0.86\n",
      "for 2021-10-18, MAE is:13.90 & sMAPE is:11.28% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 12.53% & 0.86\n",
      "for 2021-10-19, MAE is:42.98 & sMAPE is:29.76% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 12.59% & 0.86\n",
      "for 2021-10-20, MAE is:29.32 & sMAPE is:36.46% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 12.68% & 0.86\n",
      "for 2021-10-21, MAE is:9.92 & sMAPE is:15.41% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 12.68% & 0.86\n",
      "for 2021-10-22, MAE is:6.72 & sMAPE is:7.82% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 12.67% & 0.86\n",
      "for 2021-10-23, MAE is:20.15 & sMAPE is:19.23% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 12.69% & 0.86\n",
      "for 2021-10-24, MAE is:20.11 & sMAPE is:20.77% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 12.72% & 0.86\n",
      "for 2021-10-25, MAE is:10.35 & sMAPE is:10.22% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 12.71% & 0.86\n",
      "for 2021-10-26, MAE is:6.56 & sMAPE is:6.66% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 12.69% & 0.86\n",
      "for 2021-10-27, MAE is:12.82 & sMAPE is:14.89% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 12.70% & 0.86\n",
      "for 2021-10-28, MAE is:5.12 & sMAPE is:6.46% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 12.68% & 0.86\n",
      "for 2021-10-29, MAE is:4.28 & sMAPE is:5.33% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 12.65% & 0.86\n",
      "for 2021-10-30, MAE is:5.12 & sMAPE is:6.85% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 12.63% & 0.85\n",
      "for 2021-10-31, MAE is:9.31 & sMAPE is:14.13% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 12.64% & 0.85\n",
      "for 2021-11-01, MAE is:14.95 & sMAPE is:24.57% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 12.68% & 0.85\n",
      "for 2021-11-02, MAE is:14.94 & sMAPE is:17.94% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 12.69% & 0.85\n",
      "for 2021-11-03, MAE is:14.02 & sMAPE is:15.15% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 12.70% & 0.85\n",
      "for 2021-11-04, MAE is:13.74 & sMAPE is:13.32% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 12.70% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-05, MAE is:9.71 & sMAPE is:10.50% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 12.70% & 0.85\n",
      "for 2021-11-06, MAE is:3.96 & sMAPE is:5.01% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 12.67% & 0.85\n",
      "for 2021-11-07, MAE is:5.99 & sMAPE is:8.23% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 12.66% & 0.85\n",
      "for 2021-11-08, MAE is:46.88 & sMAPE is:39.05% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 12.74% & 0.85\n",
      "for 2021-11-09, MAE is:23.77 & sMAPE is:24.87% & rMAE is:2.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 12.78% & 0.86\n",
      "for 2021-11-10, MAE is:3.90 & sMAPE is:4.36% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 12.75% & 0.86\n",
      "for 2021-11-11, MAE is:3.35 & sMAPE is:3.61% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 12.72% & 0.85\n",
      "for 2021-11-12, MAE is:4.80 & sMAPE is:5.35% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 12.70% & 0.85\n",
      "for 2021-11-13, MAE is:7.05 & sMAPE is:7.86% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 12.69% & 0.85\n",
      "for 2021-11-14, MAE is:4.92 & sMAPE is:5.23% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 12.66% & 0.85\n",
      "for 2021-11-15, MAE is:3.18 & sMAPE is:3.29% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 12.63% & 0.85\n",
      "for 2021-11-16, MAE is:3.75 & sMAPE is:3.89% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 12.61% & 0.85\n",
      "for 2021-11-17, MAE is:3.84 & sMAPE is:4.34% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 12.58% & 0.85\n",
      "for 2021-11-18, MAE is:3.55 & sMAPE is:3.91% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 12.55% & 0.85\n",
      "for 2021-11-19, MAE is:4.70 & sMAPE is:5.60% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 12.53% & 0.85\n",
      "for 2021-11-20, MAE is:3.98 & sMAPE is:4.68% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 12.51% & 0.85\n",
      "for 2021-11-21, MAE is:5.67 & sMAPE is:6.03% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 12.49% & 0.85\n",
      "for 2021-11-22, MAE is:28.04 & sMAPE is:21.48% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 12.51% & 0.85\n",
      "for 2021-11-23, MAE is:13.47 & sMAPE is:12.15% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 12.51% & 0.85\n",
      "for 2021-11-24, MAE is:10.75 & sMAPE is:10.09% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 12.51% & 0.85\n",
      "for 2021-11-25, MAE is:9.27 & sMAPE is:8.47% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 12.49% & 0.84\n",
      "for 2021-11-26, MAE is:6.39 & sMAPE is:5.57% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 12.47% & 0.84\n",
      "for 2021-11-27, MAE is:37.24 & sMAPE is:26.11% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 12.51% & 0.84\n",
      "for 2021-11-28, MAE is:45.75 & sMAPE is:27.20% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 12.56% & 0.84\n",
      "for 2021-11-29, MAE is:92.10 & sMAPE is:38.64% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 12.64% & 0.84\n",
      "for 2021-11-30, MAE is:76.49 & sMAPE is:46.71% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 12.74% & 0.85\n",
      "for 2021-12-01, MAE is:25.64 & sMAPE is:19.76% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 12.76% & 0.85\n",
      "for 2021-12-02, MAE is:64.81 & sMAPE is:35.48% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 12.83% & 0.85\n",
      "for 2021-12-03, MAE is:32.48 & sMAPE is:20.93% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.43 & 12.85% & 0.85\n",
      "for 2021-12-04, MAE is:4.97 & sMAPE is:3.85% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 12.82% & 0.85\n",
      "for 2021-12-05, MAE is:14.71 & sMAPE is:11.43% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 12.82% & 0.85\n",
      "for 2021-12-06, MAE is:29.16 & sMAPE is:15.90% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.50 & 12.83% & 0.85\n",
      "for 2021-12-07, MAE is:39.62 & sMAPE is:22.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 12.86% & 0.85\n",
      "for 2021-12-08, MAE is:12.68 & sMAPE is:9.78% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 12.85% & 0.85\n",
      "for 2021-12-09, MAE is:4.74 & sMAPE is:3.70% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 12.82% & 0.85\n",
      "for 2021-12-10, MAE is:9.18 & sMAPE is:6.97% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 12.81% & 0.84\n",
      "for 2021-12-11, MAE is:32.24 & sMAPE is:19.79% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 12.83% & 0.84\n",
      "for 2021-12-12, MAE is:15.70 & sMAPE is:11.63% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 12.82% & 0.85\n",
      "for 2021-12-13, MAE is:8.06 & sMAPE is:5.75% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 12.80% & 0.85\n",
      "for 2021-12-14, MAE is:75.06 & sMAPE is:35.23% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 12.87% & 0.85\n",
      "for 2021-12-15, MAE is:43.75 & sMAPE is:29.29% & rMAE is:5.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 12.91% & 0.86\n",
      "for 2021-12-16, MAE is:22.57 & sMAPE is:15.72% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 12.92% & 0.86\n",
      "for 2021-12-17, MAE is:37.51 & sMAPE is:22.89% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :9.09 & 12.95% & 0.86\n",
      "for 2021-12-18, MAE is:15.09 & sMAPE is:9.53% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 12.94% & 0.86\n",
      "for 2021-12-19, MAE is:14.57 & sMAPE is:9.79% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 12.93% & 0.86\n",
      "for 2021-12-20, MAE is:155.27 & sMAPE is:60.29% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 13.07% & 0.86\n",
      "for 2021-12-21, MAE is:137.39 & sMAPE is:37.46% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :9.90 & 13.13% & 0.86\n",
      "for 2021-12-22, MAE is:74.85 & sMAPE is:25.98% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 13.17% & 0.86\n",
      "for 2021-12-23, MAE is:32.38 & sMAPE is:13.37% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 13.17% & 0.86\n",
      "for 2021-12-24, MAE is:20.55 & sMAPE is:10.54% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 13.16% & 0.86\n",
      "for 2021-12-25, MAE is:22.34 & sMAPE is:11.47% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 13.16% & 0.86\n",
      "for 2021-12-26, MAE is:13.14 & sMAPE is:7.21% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 13.14% & 0.86\n",
      "for 2021-12-27, MAE is:16.20 & sMAPE is:9.09% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 13.13% & 0.86\n",
      "for 2021-12-28, MAE is:25.67 & sMAPE is:16.05% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 13.14% & 0.85\n",
      "for 2021-12-29, MAE is:23.07 & sMAPE is:13.66% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 13.14% & 0.85\n",
      "for 2021-12-30, MAE is:17.70 & sMAPE is:12.12% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.33 & 13.14% & 0.85\n",
      "for 2021-12-31, MAE is:6.02 & sMAPE is:4.57% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 13.11% & 0.85\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:33:41,253]\u001b[0m A new study created in RDB with name: NO_5_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:37,049]\u001b[0m Trial 0 finished with value: 29.251011799833623 and parameters: {'n_hidden': 3, 'learning_rate': 0.03244749469378567, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017253022253962504, 'dropout_rate_Layer_2': 0.2777918012051346, 'dropout_rate_Layer_3': 0.15318355845834827, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002438091338267795, 'l1_Layer_2': 1.8860100851697872e-05, 'l1_Layer_3': 0.006952361025918686, 'n_units_Layer_1': 230, 'n_units_Layer_2': 220, 'n_units_Layer_3': 245}. Best is trial 0 with value: 29.251011799833623.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.25 | sMAPE for Validation Set is: 36.76% | rMAE for Validation Set is: 1.72\n",
      "MAE for Test Set is: 135.97 | sMAPE for Test Set is: 96.42% | rMAE for Test Set is: 2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:34:37,662]\u001b[0m Trial 2 finished with value: 26.968817908723924 and parameters: {'n_hidden': 4, 'learning_rate': 0.000712756479161277, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10801040766208062, 'dropout_rate_Layer_2': 0.2400861297457193, 'dropout_rate_Layer_3': 0.21160768793752688, 'dropout_rate_Layer_4': 0.25694144330758983, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.004237112953933043, 'l1_Layer_2': 7.569453623241994e-05, 'l1_Layer_3': 1.44252378338201e-05, 'l1_Layer_4': 8.256185297445731e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 255, 'n_units_Layer_3': 100, 'n_units_Layer_4': 65}. Best is trial 2 with value: 26.968817908723924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.97 | sMAPE for Validation Set is: 31.93% | rMAE for Validation Set is: 1.59\n",
      "MAE for Test Set is: 137.82 | sMAPE for Test Set is: 98.62% | rMAE for Test Set is: 2.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:34:41,334]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:43,289]\u001b[0m Trial 1 finished with value: 23.1526863384158 and parameters: {'n_hidden': 4, 'learning_rate': 0.001704054036815154, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05471319878477128, 'dropout_rate_Layer_2': 0.01643360171379902, 'dropout_rate_Layer_3': 0.26896490844352006, 'dropout_rate_Layer_4': 0.10650266097124175, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01087239460598439, 'l1_Layer_2': 2.323056378225739e-05, 'l1_Layer_3': 0.0002589408615112237, 'l1_Layer_4': 0.000110145197196272, 'n_units_Layer_1': 260, 'n_units_Layer_2': 100, 'n_units_Layer_3': 75, 'n_units_Layer_4': 280}. Best is trial 1 with value: 23.1526863384158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.15 | sMAPE for Validation Set is: 26.69% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 127.50 | sMAPE for Test Set is: 86.51% | rMAE for Test Set is: 2.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:34:43,537]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:45,697]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:50,297]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:50,712]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:51,265]\u001b[0m Trial 3 finished with value: 29.491277838019684 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009224694201311008, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30530100980224995, 'dropout_rate_Layer_2': 0.39857458028804776, 'dropout_rate_Layer_3': 0.3158730300624808, 'dropout_rate_Layer_4': 0.11886401511344227, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0028588352047239115, 'l1_Layer_2': 2.61159572509221e-05, 'l1_Layer_3': 0.09712924231893871, 'l1_Layer_4': 0.025121508596803704, 'n_units_Layer_1': 160, 'n_units_Layer_2': 105, 'n_units_Layer_3': 280, 'n_units_Layer_4': 225}. Best is trial 1 with value: 23.1526863384158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.49 | sMAPE for Validation Set is: 36.74% | rMAE for Validation Set is: 1.74\n",
      "MAE for Test Set is: 140.67 | sMAPE for Test Set is: 102.61% | rMAE for Test Set is: 2.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:34:57,234]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:34:57,620]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:03,535]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:07,374]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:10,660]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:14,111]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:16,920]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:19,555]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:24,883]\u001b[0m Trial 7 finished with value: 30.282493163904444 and parameters: {'n_hidden': 3, 'learning_rate': 0.006991007194185302, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.052000247022594204, 'dropout_rate_Layer_2': 0.038264101847259285, 'dropout_rate_Layer_3': 0.0909529277669507, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00025456134512400906, 'l1_Layer_2': 1.6639076586739186e-05, 'l1_Layer_3': 0.018310380574259988, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 255}. Best is trial 1 with value: 23.1526863384158.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.28 | sMAPE for Validation Set is: 37.80% | rMAE for Validation Set is: 1.78\n",
      "MAE for Test Set is: 143.70 | sMAPE for Test Set is: 106.13% | rMAE for Test Set is: 2.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:35:26,538]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:30,775]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:30,868]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:33,789]\u001b[0m Trial 12 finished with value: 10.307287982224976 and parameters: {'n_hidden': 4, 'learning_rate': 0.0029626995203585124, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1592454098908935, 'dropout_rate_Layer_2': 0.37519094483872073, 'dropout_rate_Layer_3': 0.3294546968938, 'dropout_rate_Layer_4': 0.3642975363145615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.642289884680073e-05, 'l1_Layer_2': 0.0020205092667527377, 'l1_Layer_3': 8.269274039903768e-05, 'l1_Layer_4': 0.02615133114130144, 'n_units_Layer_1': 135, 'n_units_Layer_2': 245, 'n_units_Layer_3': 75, 'n_units_Layer_4': 260}. Best is trial 12 with value: 10.307287982224976.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.31 | sMAPE for Validation Set is: 12.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.41 | sMAPE for Test Set is: 17.93% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:35:34,694]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:40,294]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:42,586]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:42,920]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:45,176]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:45,733]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:50,979]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:51,264]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:55,954]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:35:59,880]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:03,962]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:06,912]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:14,246]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:16,864]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:18,135]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:22,044]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:22,409]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:24,361]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:27,627]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:32,165]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:32,636]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:35,218]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:46,707]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:51,587]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:52,393]\u001b[0m Trial 46 finished with value: 26.098962543183863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022214844355982447, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18234611949118992, 'dropout_rate_Layer_2': 0.16515403811329277, 'dropout_rate_Layer_3': 0.010707120466703857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.959443103348837e-05, 'l1_Layer_2': 0.040635437499359765, 'l1_Layer_3': 5.972235156169023e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 65}. Best is trial 12 with value: 10.307287982224976.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.10 | sMAPE for Validation Set is: 30.86% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 135.04 | sMAPE for Test Set is: 95.17% | rMAE for Test Set is: 2.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:36:54,579]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:59,012]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:36:59,328]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:05,500]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:06,883]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:09,669]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:14,542]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:14,709]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:14,881]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:21,274]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:21,304]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:21,338]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:27,419]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:33,690]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:36,056]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:39,203]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:39,855]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:42,529]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:45,046]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:45,740]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:49,367]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:54,665]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:37:57,135]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:00,479]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:02,985]\u001b[0m Trial 67 finished with value: 10.887311977940564 and parameters: {'n_hidden': 3, 'learning_rate': 0.08030347236321171, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0002564613922777792, 'dropout_rate_Layer_2': 0.06470103046790945, 'dropout_rate_Layer_3': 0.2160668744448845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06663856131834102, 'l1_Layer_2': 0.000428621662842679, 'l1_Layer_3': 0.0037831308291796273, 'n_units_Layer_1': 240, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 12 with value: 10.307287982224976.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.89 | sMAPE for Validation Set is: 13.46% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 29.03 | sMAPE for Test Set is: 18.47% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:38:04,842]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:07,591]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:09,849]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:13,358]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:13,547]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:17,680]\u001b[0m Trial 28 finished with value: 9.985806891958141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022891772788134, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05295761917073247, 'dropout_rate_Layer_2': 0.23351983858717332, 'dropout_rate_Layer_3': 0.39076928421149004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00817325616643787, 'l1_Layer_2': 1.6168408614463427e-05, 'l1_Layer_3': 0.08777865823011505, 'n_units_Layer_1': 260, 'n_units_Layer_2': 295, 'n_units_Layer_3': 120}. Best is trial 28 with value: 9.985806891958141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.99 | sMAPE for Validation Set is: 12.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.88 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:38:19,463]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:25,443]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:31,959]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:40,121]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:48,790]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:38:54,730]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:03,159]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:04,238]\u001b[0m Trial 84 finished with value: 14.327027285245544 and parameters: {'n_hidden': 3, 'learning_rate': 0.05773153374744657, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03191993175355579, 'dropout_rate_Layer_2': 0.045108756922219564, 'dropout_rate_Layer_3': 0.14309782227964635, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09933454192956757, 'l1_Layer_2': 0.0004947471819379586, 'l1_Layer_3': 0.0006824414341083601, 'n_units_Layer_1': 275, 'n_units_Layer_2': 255, 'n_units_Layer_3': 205}. Best is trial 28 with value: 9.985806891958141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 14.33 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 47.73 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:39:08,842]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:12,805]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:18,121]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:20,993]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:28,422]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:49,050]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:49,363]\u001b[0m Trial 92 finished with value: 10.467980503236783 and parameters: {'n_hidden': 4, 'learning_rate': 0.005057176841048952, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10706501307922509, 'dropout_rate_Layer_2': 0.0855656090714699, 'dropout_rate_Layer_3': 0.07121930300680254, 'dropout_rate_Layer_4': 0.0054233011986332125, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.042641984599623727, 'l1_Layer_2': 0.0021343350861063102, 'l1_Layer_3': 2.9720263422843685e-05, 'l1_Layer_4': 1.038521457411693e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 295, 'n_units_Layer_3': 190, 'n_units_Layer_4': 230}. Best is trial 28 with value: 9.985806891958141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.47 | sMAPE for Validation Set is: 13.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.63 | sMAPE for Test Set is: 17.79% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:39:49,990]\u001b[0m Trial 93 finished with value: 10.408633577020032 and parameters: {'n_hidden': 4, 'learning_rate': 0.004552514093608368, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09584246636699399, 'dropout_rate_Layer_2': 0.09723347058085846, 'dropout_rate_Layer_3': 0.07784639222521705, 'dropout_rate_Layer_4': 0.14072814452583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04697748936055189, 'l1_Layer_2': 0.003079271368239573, 'l1_Layer_3': 2.983754308974008e-05, 'l1_Layer_4': 1.2215986894427844e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 300, 'n_units_Layer_3': 190, 'n_units_Layer_4': 230}. Best is trial 28 with value: 9.985806891958141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.41 | sMAPE for Validation Set is: 12.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 29.05 | sMAPE for Test Set is: 18.66% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:39:56,018]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:58,668]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:39:59,257]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:03,988]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:06,408]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:07,163]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:13,509]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:18,346]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:18,415]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:23,010]\u001b[0m Trial 103 finished with value: 10.601430228817618 and parameters: {'n_hidden': 4, 'learning_rate': 0.005030754766187982, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1767656161135199, 'dropout_rate_Layer_2': 0.09665390215894523, 'dropout_rate_Layer_3': 0.06309559486387481, 'dropout_rate_Layer_4': 0.007989870965127214, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04707639610055169, 'l1_Layer_2': 0.002228064473383383, 'l1_Layer_3': 3.245403574633941e-05, 'l1_Layer_4': 2.3916825604032964e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 180, 'n_units_Layer_4': 210}. Best is trial 28 with value: 9.985806891958141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 13.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 29.87 | sMAPE for Test Set is: 19.08% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:40:24,338]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:25,559]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:27,236]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:29,203]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:30,967]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:32,988]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:37,208]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:39,388]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:39,934]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:43,959]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:48,083]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:48,263]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:48,408]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:53,359]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:40:58,210]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:00,610]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:03,265]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:06,641]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:10,473]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:13,187]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:14,318]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:18,299]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:20,736]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:23,960]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:26,964]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:27,168]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:30,895]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:31,173]\u001b[0m Trial 118 finished with value: 10.210072371173839 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033260230342006974, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2569434090142086, 'dropout_rate_Layer_2': 0.03052153543381736, 'dropout_rate_Layer_3': 0.11451778681618184, 'dropout_rate_Layer_4': 0.2684282063773, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0011553064484787457, 'l1_Layer_2': 0.0010750799790000278, 'l1_Layer_3': 4.4224770044042523e-05, 'l1_Layer_4': 1.0212044769092194e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 265, 'n_units_Layer_3': 230, 'n_units_Layer_4': 250}. Best is trial 28 with value: 9.985806891958141.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.21 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.42 | sMAPE for Test Set is: 18.29% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:41:34,497]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:35,915]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:38,546]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:42,161]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:44,209]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:46,580]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:50,828]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:54,189]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:55,793]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:41:59,112]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:01,628]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:05,203]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:09,712]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:10,361]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:14,311]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:14,599]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:19,974]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:23,914]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:24,230]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:26,143]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:35,178]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:35,299]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:40,195]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:42:51,961]\u001b[0m Trial 122 finished with value: 9.876985244591143 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007519266588250846, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025788537796131217, 'dropout_rate_Layer_2': 0.22089369897132166, 'dropout_rate_Layer_3': 0.39996031551172756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00095934733519436, 'l1_Layer_2': 1.6460592183094765e-05, 'l1_Layer_3': 0.0020854729098465927, 'n_units_Layer_1': 235, 'n_units_Layer_2': 75, 'n_units_Layer_3': 90}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.88 | sMAPE for Validation Set is: 12.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.62 | sMAPE for Test Set is: 17.28% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:42:56,628]\u001b[0m Trial 157 finished with value: 10.17033130568499 and parameters: {'n_hidden': 3, 'learning_rate': 0.0047933662824533475, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1994363136198694, 'dropout_rate_Layer_2': 0.26543513854638723, 'dropout_rate_Layer_3': 0.27816745260616094, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000766676887025618, 'l1_Layer_2': 0.012936142654346007, 'l1_Layer_3': 0.0002033453985292088, 'n_units_Layer_1': 85, 'n_units_Layer_2': 280, 'n_units_Layer_3': 75}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.17 | sMAPE for Validation Set is: 12.50% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.23 | sMAPE for Test Set is: 17.67% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:43:01,298]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:04,652]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:08,383]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:11,816]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:13,971]\u001b[0m Trial 155 finished with value: 10.08889043719187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007049838627381233, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06378055333788066, 'dropout_rate_Layer_2': 0.21887949605946103, 'dropout_rate_Layer_3': 0.38590981878214087, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006849822653904825, 'l1_Layer_2': 1.7546036877660466e-05, 'l1_Layer_3': 0.0010864141040343455, 'n_units_Layer_1': 255, 'n_units_Layer_2': 260, 'n_units_Layer_3': 95}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.09 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.20 | sMAPE for Test Set is: 17.64% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:43:17,652]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:20,699]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:21,874]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:25,054]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:27,237]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:29,949]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:31,657]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:36,360]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:38,989]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:40,608]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:43,444]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:45,458]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:45,920]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:47,955]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:52,009]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:43:56,327]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:00,817]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:00,966]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:07,030]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:07,328]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:07,391]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:08,305]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:16,115]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:18,573]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:19,107]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:23,635]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:24,156]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:26,148]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:29,831]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:30,009]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:30,126]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:30,266]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:36,908]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:37,487]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:38,152]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:41,563]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:44,057]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:45,469]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:45,840]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:49,767]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:50,219]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:44:56,540]\u001b[0m Trial 200 finished with value: 10.499213414511868 and parameters: {'n_hidden': 3, 'learning_rate': 0.013746268426442772, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.255974709245488, 'dropout_rate_Layer_2': 0.3588722681326778, 'dropout_rate_Layer_3': 0.3091231018296335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7282685132356993e-05, 'l1_Layer_2': 0.013683639498211485, 'l1_Layer_3': 0.0002965004622300589, 'n_units_Layer_1': 100, 'n_units_Layer_2': 275, 'n_units_Layer_3': 210}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.50 | sMAPE for Validation Set is: 13.16% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 27.86 | sMAPE for Test Set is: 18.03% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:44:56,878]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:01,637]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:13,616]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:16,153]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:17,793]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:22,574]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:24,143]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:26,834]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:30,447]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:35,387]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:35,723]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:41,513]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:43,618]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:47,526]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:50,669]\u001b[0m Trial 219 finished with value: 11.268323362428605 and parameters: {'n_hidden': 3, 'learning_rate': 0.01913021149705656, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32466293794565826, 'dropout_rate_Layer_2': 0.3996338899693933, 'dropout_rate_Layer_3': 0.37940511830036877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08784913420837616, 'l1_Layer_2': 0.005129243219331882, 'l1_Layer_3': 0.00028488547260471526, 'n_units_Layer_1': 65, 'n_units_Layer_2': 195, 'n_units_Layer_3': 90}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.27 | sMAPE for Validation Set is: 14.19% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 34.51 | sMAPE for Test Set is: 21.34% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:45:52,666]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:58,612]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:45:59,138]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:02,797]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:06,116]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:08,483]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:10,616]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:15,478]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:17,450]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:20,143]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:22,122]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:25,661]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:26,043]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:30,302]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:38,279]\u001b[0m Trial 206 finished with value: 9.939964017210949 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008608083688316584, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.041888690172037654, 'dropout_rate_Layer_2': 0.2519951710152669, 'dropout_rate_Layer_3': 0.17519626025787388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006449171263419639, 'l1_Layer_2': 1.1343163821298913e-05, 'l1_Layer_3': 0.006083369545836832, 'n_units_Layer_1': 165, 'n_units_Layer_2': 245, 'n_units_Layer_3': 60}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.94 | sMAPE for Validation Set is: 12.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.48 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:46:42,477]\u001b[0m Trial 236 finished with value: 10.138220090972647 and parameters: {'n_hidden': 3, 'learning_rate': 0.009410005036475624, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.156749102673177, 'dropout_rate_Layer_2': 0.39506723484170697, 'dropout_rate_Layer_3': 0.24842087941641083, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0853438418826729, 'l1_Layer_2': 0.03736352372463772, 'l1_Layer_3': 0.0007070788094804015, 'n_units_Layer_1': 100, 'n_units_Layer_2': 140, 'n_units_Layer_3': 95}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.14 | sMAPE for Validation Set is: 12.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.00 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:46:51,829]\u001b[0m Trial 237 finished with value: 10.379277174628202 and parameters: {'n_hidden': 3, 'learning_rate': 0.014814792667415522, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3397669748254221, 'dropout_rate_Layer_2': 0.39809718753399403, 'dropout_rate_Layer_3': 0.30664083493345984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004370724971206035, 'l1_Layer_2': 0.041311443569756585, 'l1_Layer_3': 0.0007088677713041207, 'n_units_Layer_1': 55, 'n_units_Layer_2': 190, 'n_units_Layer_3': 95}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.38 | sMAPE for Validation Set is: 13.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 30.87 | sMAPE for Test Set is: 19.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:46:53,495]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:57,668]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:46:58,066]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:02,761]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:08,755]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:10,766]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:21,707]\u001b[0m Trial 234 finished with value: 10.000198555516576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033991282015341717, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01071168773475617, 'dropout_rate_Layer_2': 0.1315754170683778, 'dropout_rate_Layer_3': 0.2523085569550833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0422946363446682, 'l1_Layer_2': 0.00010844496981016094, 'l1_Layer_3': 8.533083129162642e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 12.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.22 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:47:25,283]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:28,625]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:31,081]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:36,203]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:40,116]\u001b[0m Trial 247 finished with value: 10.083866558838603 and parameters: {'n_hidden': 3, 'learning_rate': 0.009494417362252478, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.159669243056307, 'dropout_rate_Layer_2': 0.32339187158467153, 'dropout_rate_Layer_3': 0.2470568278873705, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.009095181597288757, 'l1_Layer_2': 0.03174754433329448, 'l1_Layer_3': 0.0008297837950687973, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.08 | sMAPE for Validation Set is: 12.47% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.22 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:47:42,673]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:44,825]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:45,236]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:49,202]\u001b[0m Trial 249 finished with value: 10.261894116641423 and parameters: {'n_hidden': 3, 'learning_rate': 0.009714400760249372, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1405690063171184, 'dropout_rate_Layer_2': 0.327904928815404, 'dropout_rate_Layer_3': 0.2555531536101453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003153417296014431, 'l1_Layer_2': 0.05326855659711204, 'l1_Layer_3': 0.0007319864487988716, 'n_units_Layer_1': 90, 'n_units_Layer_2': 125, 'n_units_Layer_3': 125}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 12.82% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.67 | sMAPE for Test Set is: 17.89% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:47:50,712]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:47:55,808]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:02,429]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:05,094]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:09,084]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:10,621]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:16,199]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:24,689]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:31,111]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:37,353]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:42,169]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:44,749]\u001b[0m Trial 254 finished with value: 9.912384434625425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0044734753164532735, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03221543446287374, 'dropout_rate_Layer_2': 0.08092160113275272, 'dropout_rate_Layer_3': 0.274562389692038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05545169422674407, 'l1_Layer_2': 4.853482159574087e-05, 'l1_Layer_3': 8.132765667064595e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 80, 'n_units_Layer_3': 180}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.91 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.03 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:48:45,333]\u001b[0m Trial 264 finished with value: 10.124634691483484 and parameters: {'n_hidden': 3, 'learning_rate': 0.006567186257393714, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16617133843134024, 'dropout_rate_Layer_2': 0.3443373413492555, 'dropout_rate_Layer_3': 0.23550847225204644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018061586367894268, 'l1_Layer_2': 0.02900657264556098, 'l1_Layer_3': 0.0006292095492165684, 'n_units_Layer_1': 80, 'n_units_Layer_2': 120, 'n_units_Layer_3': 95}. Best is trial 122 with value: 9.876985244591143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.12 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 26.96 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:48:49,080]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:51,099]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:48:54,540]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:01,141]\u001b[0m Trial 266 finished with value: 9.50221252473373 and parameters: {'n_hidden': 3, 'learning_rate': 0.005821643369508276, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027872163913902487, 'dropout_rate_Layer_2': 0.16314471787935245, 'dropout_rate_Layer_3': 0.21735877061720854, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023736922393673786, 'l1_Layer_2': 0.00044317285862982987, 'l1_Layer_3': 0.00023569033490710914, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235}. Best is trial 266 with value: 9.50221252473373.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.76 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:49:04,100]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:07,858]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:10,122]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:11,804]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:16,343]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:16,466]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:21,422]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 12.13% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.54 | sMAPE for Test Set is: 17.19% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:49:29,891]\u001b[0m Trial 274 finished with value: 9.931662890045336 and parameters: {'n_hidden': 3, 'learning_rate': 0.005826791835617453, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0018601420845516577, 'dropout_rate_Layer_2': 0.21758016237887157, 'dropout_rate_Layer_3': 0.22271075050737232, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002071194223110824, 'l1_Layer_2': 0.0016159733330906234, 'l1_Layer_3': 3.934877076964612e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 265, 'n_units_Layer_3': 220}. Best is trial 266 with value: 9.50221252473373.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:29,905]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:36,167]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:40,433]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:43,233]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:44,173]\u001b[0m Trial 277 finished with value: 9.88130014841339 and parameters: {'n_hidden': 3, 'learning_rate': 0.006131812779539707, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1840088697661666, 'dropout_rate_Layer_2': 0.16581394101887642, 'dropout_rate_Layer_3': 0.017861277928676457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019112619643180646, 'l1_Layer_2': 0.00022838482828189605, 'l1_Layer_3': 5.49443495464048e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 266 with value: 9.50221252473373.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.88 | sMAPE for Validation Set is: 12.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.54 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:49:45,241]\u001b[0m Trial 256 finished with value: 9.007381197291824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009685395466953981, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012243438260390396, 'dropout_rate_Layer_2': 0.229271071529232, 'dropout_rate_Layer_3': 0.11660346540078038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010084566716254903, 'l1_Layer_2': 2.5000050356738308e-05, 'l1_Layer_3': 0.0008095014697728413, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 250}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 10.93% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 25.71 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:49:45,419]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:53,302]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:49:59,727]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:02,012]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:06,994]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:12,195]\u001b[0m Trial 285 finished with value: 9.733744098105689 and parameters: {'n_hidden': 3, 'learning_rate': 0.006986585406707431, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1624565667497176, 'dropout_rate_Layer_2': 0.34150525672989074, 'dropout_rate_Layer_3': 0.20350891287737194, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.027609105612062153, 'l1_Layer_2': 0.027386623485961412, 'l1_Layer_3': 0.0025467419036272563, 'n_units_Layer_1': 80, 'n_units_Layer_2': 120, 'n_units_Layer_3': 130}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.73 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.36 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:50:14,470]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:17,942]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:21,490]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:22,000]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:25,771]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:29,074]\u001b[0m Trial 291 finished with value: 10.092197187040105 and parameters: {'n_hidden': 3, 'learning_rate': 0.005908709645321916, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12880262746876517, 'dropout_rate_Layer_2': 0.3269941284833602, 'dropout_rate_Layer_3': 0.22222495220245275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05886728708616356, 'l1_Layer_2': 0.09769952630225927, 'l1_Layer_3': 0.006234964840684225, 'n_units_Layer_1': 90, 'n_units_Layer_2': 85, 'n_units_Layer_3': 115}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.09 | sMAPE for Validation Set is: 12.54% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.80 | sMAPE for Test Set is: 17.26% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:50:32,415]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:34,086]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:36,209]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:39,705]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:41,995]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:46,197]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:48,321]\u001b[0m Trial 296 finished with value: 10.046874659030353 and parameters: {'n_hidden': 3, 'learning_rate': 0.006573453168095561, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12542803912821074, 'dropout_rate_Layer_2': 0.32067042142888313, 'dropout_rate_Layer_3': 0.2228487652807053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.054960293511288734, 'l1_Layer_2': 0.09447738457902091, 'l1_Layer_3': 0.0065149378103084065, 'n_units_Layer_1': 80, 'n_units_Layer_2': 95, 'n_units_Layer_3': 150}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.05 | sMAPE for Validation Set is: 12.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.45 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:50:48,515]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:49,047]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:53,904]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:55,397]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:50:57,838]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:00,953]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:01,799]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:04,628]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:06,512]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:06,885]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:11,723]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:11,948]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:12,850]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:17,483]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:22,954]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:23,468]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:25,006]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:29,601]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:32,187]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:35,270]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:38,323]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:41,122]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:47,007]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:47,422]\u001b[0m Trial 318 finished with value: 9.791258354080457 and parameters: {'n_hidden': 3, 'learning_rate': 0.002414284554941584, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05109611448976423, 'dropout_rate_Layer_2': 0.1102593277574672, 'dropout_rate_Layer_3': 0.08718251537987831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002153854249119094, 'l1_Layer_2': 9.815424083375589e-05, 'l1_Layer_3': 4.3182479156721015e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 285, 'n_units_Layer_3': 260}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 11.85% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.65 | sMAPE for Test Set is: 17.79% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:51:51,625]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:51,866]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:55,510]\u001b[0m Trial 320 finished with value: 9.895085014675361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032470917699242894, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05219116881597748, 'dropout_rate_Layer_2': 0.2903771549626587, 'dropout_rate_Layer_3': 0.23034407487704114, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.023239481493825372, 'l1_Layer_2': 0.0009308061899396311, 'l1_Layer_3': 6.418615286402513e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 255}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.90 | sMAPE for Validation Set is: 12.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.48 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:51:57,941]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:58,285]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:51:58,965]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:02,215]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:04,363]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:05,089]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:06,345]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:07,382]\u001b[0m Trial 327 finished with value: 9.851760485150074 and parameters: {'n_hidden': 3, 'learning_rate': 0.002491031681097056, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05285307981641519, 'dropout_rate_Layer_2': 0.12736464704297515, 'dropout_rate_Layer_3': 0.08933285166560585, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.793909874529978e-05, 'l1_Layer_2': 0.004186136232766562, 'l1_Layer_3': 4.3232155260194704e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 215, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.85 | sMAPE for Validation Set is: 12.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.14 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:52:11,709]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:16,172]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:16,327]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:16,628]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:22,685]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:26,159]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:26,669]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:32,439]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:32,679]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:36,702]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:37,163]\u001b[0m Trial 343 finished with value: 10.085344966776544 and parameters: {'n_hidden': 3, 'learning_rate': 0.006121722812505463, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2146525058388782, 'dropout_rate_Layer_2': 0.37890055873549927, 'dropout_rate_Layer_3': 0.22078565433838157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.018250826744514722, 'l1_Layer_2': 0.030247711274482007, 'l1_Layer_3': 0.001444366837157366, 'n_units_Layer_1': 50, 'n_units_Layer_2': 145, 'n_units_Layer_3': 95}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.09 | sMAPE for Validation Set is: 12.40% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.68 | sMAPE for Test Set is: 17.16% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:52:38,838]\u001b[0m Trial 340 finished with value: 9.717517702646097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037440028531100763, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21635532311920996, 'dropout_rate_Layer_2': 0.2580949366850017, 'dropout_rate_Layer_3': 0.2182958804937287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.031189664900880112, 'l1_Layer_2': 0.008993224435123993, 'l1_Layer_3': 0.0076714748943186445, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 80}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.72 | sMAPE for Validation Set is: 11.98% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.36 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:52:41,917]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:42,826]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:44,286]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:47,681]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:49,211]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:52,599]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:52,769]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:52:58,935]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:06,281]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:12,782]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:16,285]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:17,031]\u001b[0m Trial 352 finished with value: 9.726903106229488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034527971708432003, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04624038925790141, 'dropout_rate_Layer_2': 0.26384894151154814, 'dropout_rate_Layer_3': 0.08681098587048727, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032273846535592164, 'l1_Layer_2': 0.0013947891602722055, 'l1_Layer_3': 6.0295283416916636e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.73 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.77 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:53:22,406]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:22,902]\u001b[0m Trial 358 finished with value: 9.785924515191404 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023530505189854186, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042880487693126926, 'dropout_rate_Layer_2': 0.2569889820084306, 'dropout_rate_Layer_3': 0.09057035270558095, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017310421784015627, 'l1_Layer_2': 0.00016882701857206208, 'l1_Layer_3': 5.59636939138335e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:22,992]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.48 | sMAPE for Test Set is: 17.12% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:53:29,039]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:29,353]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:29,536]\u001b[0m Trial 355 finished with value: 9.627981463615233 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023424227732007784, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04778622087619151, 'dropout_rate_Layer_2': 0.1302462787707663, 'dropout_rate_Layer_3': 0.08883623072920904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016284876271833123, 'l1_Layer_2': 0.003978928261474808, 'l1_Layer_3': 6.024751931404844e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.63 | sMAPE for Validation Set is: 11.74% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.77 | sMAPE for Test Set is: 16.82% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:53:29,798]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:40,093]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:40,281]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:40,745]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:40,816]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:48,227]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:50,693]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:53,112]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:55,221]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:55,269]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:56,194]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:53:57,079]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:03,441]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:05,474]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:07,414]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:08,423]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:11,151]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:15,601]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:16,403]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:21,014]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:22,846]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:24,943]\u001b[0m Trial 379 finished with value: 9.879588285398219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033776317720606423, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04699716963700307, 'dropout_rate_Layer_2': 0.2645251715483604, 'dropout_rate_Layer_3': 0.11671616699377199, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.036712851201106e-05, 'l1_Layer_2': 0.0002261644043624578, 'l1_Layer_3': 4.404489879267993e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.88 | sMAPE for Validation Set is: 12.15% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.74 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:54:25,403]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:30,624]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:35,126]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:39,772]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:43,157]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:46,379]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:51,100]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:51,674]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:54,336]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:57,603]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:57,842]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:58,200]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:54:58,854]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:03,574]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:06,476]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:07,472]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:07,625]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:08,883]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:11,007]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:14,735]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:18,608]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:20,779]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:22,766]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:25,931]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:36,160]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:41,088]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:48,295]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:52,497]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:55,053]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:58,440]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:55:58,766]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:03,855]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:03,993]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:08,140]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:09,457]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:09,493]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:14,881]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:17,728]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:21,636]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:24,309]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:25,509]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:26,207]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:30,156]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:30,950]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:34,652]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:36,713]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:38,556]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:45,813]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:46,099]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:51,091]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:52,941]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:54,676]\u001b[0m Trial 434 finished with value: 9.894417098762824 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016879569056623945, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07478805060538656, 'dropout_rate_Layer_2': 0.12573530525861987, 'dropout_rate_Layer_3': 0.11643882235083668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.480528409330651e-05, 'l1_Layer_2': 0.00023046108477762592, 'l1_Layer_3': 6.18474846741525e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.89 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 27.58 | sMAPE for Test Set is: 17.71% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:56:56,799]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:56:59,289]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:00,998]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:03,077]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:08,763]\u001b[0m Trial 442 finished with value: 9.947063515918883 and parameters: {'n_hidden': 3, 'learning_rate': 0.004828835589310771, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2057346579879645, 'dropout_rate_Layer_2': 0.29346455990371295, 'dropout_rate_Layer_3': 0.2485677464617268, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09985335386714231, 'l1_Layer_2': 0.014594781683423892, 'l1_Layer_3': 0.00038519924356181804, 'n_units_Layer_1': 70, 'n_units_Layer_2': 110, 'n_units_Layer_3': 60}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.95 | sMAPE for Validation Set is: 12.45% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.64 | sMAPE for Test Set is: 17.14% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:57:11,847]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:12,291]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:17,567]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:20,895]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:25,558]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:30,022]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:33,490]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:39,897]\u001b[0m Trial 453 finished with value: 10.058477393839391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034048341839799327, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18419559360506704, 'dropout_rate_Layer_2': 0.32221553059682145, 'dropout_rate_Layer_3': 0.2552956087073127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06423767005843811, 'l1_Layer_2': 0.018638619004456753, 'l1_Layer_3': 0.004640288265181525, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 95}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.06 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.67 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:57:40,578]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:42,252]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:46,607]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:49,440]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:50,144]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:50,433]\u001b[0m Trial 410 finished with value: 9.795363947719169 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006199632257765071, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07857390044449877, 'dropout_rate_Layer_2': 0.21543536330848123, 'dropout_rate_Layer_3': 0.21723499245863592, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00755539260787341, 'l1_Layer_2': 3.4698976697957726e-05, 'l1_Layer_3': 5.850851278491368e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 65, 'n_units_Layer_3': 205}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.80 | sMAPE for Validation Set is: 11.92% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.45 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:57:54,811]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:57,817]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:57:58,349]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:02,553]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:07,180]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:08,752]\u001b[0m Trial 458 finished with value: 9.808814384808533 and parameters: {'n_hidden': 3, 'learning_rate': 0.004744496555911363, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20697367528475502, 'dropout_rate_Layer_2': 0.3237656999555882, 'dropout_rate_Layer_3': 0.2155588941382982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05744814308406814, 'l1_Layer_2': 0.006383312852658329, 'l1_Layer_3': 0.005165419999724116, 'n_units_Layer_1': 55, 'n_units_Layer_2': 105, 'n_units_Layer_3': 60}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.81 | sMAPE for Validation Set is: 12.06% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.56 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:58:12,325]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:17,400]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:20,455]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:21,804]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:23,813]\u001b[0m Trial 468 finished with value: 9.492181817086717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033700677451392706, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05807928811185256, 'dropout_rate_Layer_2': 0.13145888164812003, 'dropout_rate_Layer_3': 0.09685384141586195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003572103603328274, 'l1_Layer_2': 8.006074802690477e-05, 'l1_Layer_3': 5.352129482745226e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.34 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:58:28,854]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:31,245]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:33,930]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:34,293]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:42,001]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:48,242]\u001b[0m Trial 472 finished with value: 9.544966727040112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033776081459305266, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021621547902749436, 'dropout_rate_Layer_2': 0.2625973490689934, 'dropout_rate_Layer_3': 0.25234845415603896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003361859230204383, 'l1_Layer_2': 4.7590136502030955e-05, 'l1_Layer_3': 5.7996622609515056e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 11.55% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.12 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:58:55,694]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:58:59,241]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:04,241]\u001b[0m Trial 479 finished with value: 9.800176689140846 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034883756068812225, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18258045525911773, 'dropout_rate_Layer_2': 0.3107890896471087, 'dropout_rate_Layer_3': 0.26866007054375396, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06585930273886467, 'l1_Layer_2': 0.0064194205896595065, 'l1_Layer_3': 0.017955261039848812, 'n_units_Layer_1': 55, 'n_units_Layer_2': 130, 'n_units_Layer_3': 65}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.80 | sMAPE for Validation Set is: 12.09% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.71 | sMAPE for Test Set is: 17.13% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:59:09,092]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:09,362]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:18,248]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:19,703]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:25,311]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:27,393]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:30,651]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:32,659]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:35,361]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:39,808]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:40,976]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:45,429]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:47,828]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:51,365]\u001b[0m Trial 478 finished with value: 10.003386893414474 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027325512108232444, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18613968692861402, 'dropout_rate_Layer_2': 0.314374180170116, 'dropout_rate_Layer_3': 0.29523736394799266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.06637442859049764, 'l1_Layer_2': 0.0058630422691668726, 'l1_Layer_3': 0.007170363371121587, 'n_units_Layer_1': 55, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.26 | sMAPE for Test Set is: 17.42% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 03:59:51,757]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:56,158]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 03:59:58,390]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:00,066]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:02,059]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:05,014]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:07,258]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:09,860]\u001b[0m Trial 495 finished with value: 9.865471997110093 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026903139719888607, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05201125657817541, 'dropout_rate_Layer_2': 0.2693929226639604, 'dropout_rate_Layer_3': 0.28010938565363447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014969757671421993, 'l1_Layer_2': 5.9569884959065675e-05, 'l1_Layer_3': 7.709910357932315e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.87 | sMAPE for Validation Set is: 11.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.78 | sMAPE for Test Set is: 16.70% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:00:14,162]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:14,395]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:22,284]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:22,584]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:22,797]\u001b[0m Trial 505 finished with value: 9.751052226087902 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018129470665527217, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.054358021324314304, 'dropout_rate_Layer_2': 0.2638053374801559, 'dropout_rate_Layer_3': 0.289523902918782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002782230048843897, 'l1_Layer_2': 4.6423656744020724e-05, 'l1_Layer_3': 4.3422377251026125e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.75 | sMAPE for Validation Set is: 11.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.18 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:00:29,701]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:29,834]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:29,964]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:34,289]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:34,561]\u001b[0m Trial 469 finished with value: 9.764204470849348 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006562669194655657, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0626825146986695, 'dropout_rate_Layer_2': 0.22707019983852364, 'dropout_rate_Layer_3': 0.2181854499551367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004384906093214554, 'l1_Layer_2': 3.57437923528122e-05, 'l1_Layer_3': 2.61192712414405e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.76 | sMAPE for Validation Set is: 11.83% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.75 | sMAPE for Test Set is: 17.33% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:00:37,651]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:37,863]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:38,456]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:38,691]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:45,974]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:48,185]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:52,179]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:55,793]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:00:57,248]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 11.33% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.51 | sMAPE for Test Set is: 16.55% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:01:02,941]\u001b[0m Trial 517 finished with value: 9.477832765890014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017092965295321726, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03787677572183461, 'dropout_rate_Layer_2': 0.24430170572787602, 'dropout_rate_Layer_3': 0.2712154871594388, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.284337032017889e-05, 'l1_Layer_2': 6.228117214300414e-05, 'l1_Layer_3': 5.531342489454376e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 275, 'n_units_Layer_3': 265}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:06,850]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:13,434]\u001b[0m Trial 523 finished with value: 9.780945566646215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029193794252637692, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057496577629077304, 'dropout_rate_Layer_2': 0.2998051308316613, 'dropout_rate_Layer_3': 0.2779004220948879, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003339648376249081, 'l1_Layer_2': 7.208130869965646e-05, 'l1_Layer_3': 5.185357949718898e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.78 | sMAPE for Validation Set is: 11.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.28 | sMAPE for Test Set is: 16.94% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:01:20,444]\u001b[0m Trial 526 finished with value: 9.724801029271033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022542262088236275, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056400314179408384, 'dropout_rate_Layer_2': 0.2836002818092487, 'dropout_rate_Layer_3': 0.26740981044723366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010366224787061787, 'l1_Layer_2': 8.214758021516792e-05, 'l1_Layer_3': 5.261510115413302e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.72 | sMAPE for Validation Set is: 11.62% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.20 | sMAPE for Test Set is: 16.93% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:01:23,160]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:27,306]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:32,459]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:36,326]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:39,617]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:41,162]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:44,062]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:44,697]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:48,285]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:48,736]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:52,647]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:54,776]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:57,750]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:57,994]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:01:59,201]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:04,428]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:05,047]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:09,123]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:09,232]\u001b[0m Trial 536 finished with value: 9.570414946021538 and parameters: {'n_hidden': 3, 'learning_rate': 0.002450044479415304, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03944494768114466, 'dropout_rate_Layer_2': 0.28139375796466215, 'dropout_rate_Layer_3': 0.28608183325863085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003159396663412842, 'l1_Layer_2': 7.377403628178417e-05, 'l1_Layer_3': 4.598363246738578e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 280, 'n_units_Layer_3': 295}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 11.46% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.72 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:02:15,124]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:16,489]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:19,897]\u001b[0m Trial 541 finished with value: 9.621443168695192 and parameters: {'n_hidden': 3, 'learning_rate': 0.002065199939212199, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09186479232197006, 'dropout_rate_Layer_2': 0.28489661431635976, 'dropout_rate_Layer_3': 0.282953618590037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037763681470470034, 'l1_Layer_2': 7.615046862984353e-05, 'l1_Layer_3': 4.550786661659089e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 250}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.62 | sMAPE for Validation Set is: 11.60% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.71 | sMAPE for Test Set is: 16.75% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:02:20,447]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:20,838]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:26,648]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:26,775]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:27,178]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:27,658]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:33,479]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:35,408]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:36,907]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:40,049]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:47,530]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:52,426]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:55,756]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:02:56,046]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:00,964]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:03,144]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:03,190]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:04,735]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:09,971]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:10,041]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:18,127]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:20,209]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:22,058]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:26,771]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:27,160]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:31,393]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:34,868]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:37,643]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:39,010]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:42,215]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:44,879]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:47,426]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:51,145]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:52,470]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:55,871]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:03:59,301]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:02,801]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:03,295]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:07,769]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:08,055]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:12,982]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:13,046]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:17,560]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:19,941]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:21,339]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:22,931]\u001b[0m Trial 585 finished with value: 9.589477537952547 and parameters: {'n_hidden': 3, 'learning_rate': 0.002036393375592396, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.045225167840139247, 'dropout_rate_Layer_2': 0.28083373704226866, 'dropout_rate_Layer_3': 0.07171028476843751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014924028526558443, 'l1_Layer_2': 0.00026902329828533975, 'l1_Layer_3': 6.640625316450408e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 240}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.59 | sMAPE for Validation Set is: 11.41% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.28 | sMAPE for Test Set is: 16.47% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:04:28,934]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:30,704]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:32,214]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:34,431]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:37,565]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:39,808]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:45,738]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:48,689]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:04:56,274]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:00,123]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:02,849]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:07,983]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.83 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.49 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:05:09,473]\u001b[0m Trial 572 finished with value: 9.829621255659747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024424881522541724, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.114195895141413, 'dropout_rate_Layer_2': 0.31958634975199757, 'dropout_rate_Layer_3': 0.18923317929612893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08013095001922753, 'l1_Layer_2': 0.01560457919482047, 'l1_Layer_3': 0.00593580795390261, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 80}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:14,793]\u001b[0m Trial 606 finished with value: 10.139603774702971 and parameters: {'n_hidden': 3, 'learning_rate': 0.010723531667626903, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16332506722680512, 'dropout_rate_Layer_2': 0.3425206428542689, 'dropout_rate_Layer_3': 0.20898478663871886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017940495051040544, 'l1_Layer_2': 0.08471858218557614, 'l1_Layer_3': 0.0005425693356391034, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.14 | sMAPE for Validation Set is: 12.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.79 | sMAPE for Test Set is: 17.90% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:05:24,248]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:24,670]\u001b[0m Trial 595 finished with value: 9.801276641442568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010592315218945166, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035794175006777396, 'dropout_rate_Layer_2': 0.2430959866719715, 'dropout_rate_Layer_3': 0.3987270240259834, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008689943558940625, 'l1_Layer_2': 1.1643827519339782e-05, 'l1_Layer_3': 0.0048147967355587915, 'n_units_Layer_1': 145, 'n_units_Layer_2': 255, 'n_units_Layer_3': 90}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.80 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.00 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:05:28,729]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:29,061]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:29,798]\u001b[0m Trial 608 finished with value: 9.605314140621735 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020928591364575955, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11719395357092897, 'dropout_rate_Layer_2': 0.2887182451546289, 'dropout_rate_Layer_3': 0.05990373505592154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002991592816991059, 'l1_Layer_2': 6.2428875742648e-05, 'l1_Layer_3': 4.5998488874484733e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.61 | sMAPE for Validation Set is: 11.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.39 | sMAPE for Test Set is: 16.52% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:05:34,507]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:36,270]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:41,174]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:43,437]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:45,800]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:46,367]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:46,878]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:50,827]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:54,098]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:56,790]\u001b[0m Trial 609 finished with value: 9.856336777179157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018682813724856607, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08816881701024662, 'dropout_rate_Layer_2': 0.3041416291840004, 'dropout_rate_Layer_3': 0.17956021095084843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.08229053217474369, 'l1_Layer_2': 0.011619017477621632, 'l1_Layer_3': 0.0070501241381239295, 'n_units_Layer_1': 50, 'n_units_Layer_2': 85, 'n_units_Layer_3': 80}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 12.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.68 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:05:57,354]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:05:58,885]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:04,119]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:06,904]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:08,147]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:10,923]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:11,431]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:11,461]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:11,617]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:17,220]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:19,919]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:20,508]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:25,689]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:28,982]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:37,722]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:39,813]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:42,355]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:42,969]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:48,150]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:48,801]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:06:57,965]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:02,765]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:05,845]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:10,478]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:12,423]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:14,499]\u001b[0m Trial 634 finished with value: 9.819473064118924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010570199790855596, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06689153928182495, 'dropout_rate_Layer_2': 0.21498440745336023, 'dropout_rate_Layer_3': 0.13549672400409107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006495229258845501, 'l1_Layer_2': 1.7044845977702118e-05, 'l1_Layer_3': 8.465818681612275e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 245, 'n_units_Layer_3': 105}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.82 | sMAPE for Validation Set is: 11.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.34 | sMAPE for Test Set is: 17.17% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:07:15,173]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:18,521]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:18,796]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:22,590]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:24,974]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:25,181]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:27,901]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:31,296]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:33,394]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:35,459]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:38,832]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:42,523]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:44,279]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:44,824]\u001b[0m Trial 648 finished with value: 9.573810938581188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015443983633696427, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06710398241530992, 'dropout_rate_Layer_2': 0.13047578062103476, 'dropout_rate_Layer_3': 0.26208472989467213, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.926444930482802e-05, 'l1_Layer_2': 0.0003437087242668397, 'l1_Layer_3': 7.836334638633404e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 265, 'n_units_Layer_3': 230}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 11.43% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.33 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:07:46,809]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:50,022]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:53,081]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:56,153]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:07:56,955]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:06,362]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:10,415]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:15,491]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:22,225]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:27,050]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:36,830]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:48,205]\u001b[0m Trial 673 finished with value: 9.538921993067369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024205464623826317, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05894898791848571, 'dropout_rate_Layer_2': 0.12484144022801882, 'dropout_rate_Layer_3': 0.1045396895266563, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.7382727313104085e-05, 'l1_Layer_2': 0.00037533556844944607, 'l1_Layer_3': 6.148446085795943e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.70 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:08:53,744]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:08:57,326]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:00,020]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:00,866]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:02,168]\u001b[0m Trial 676 finished with value: 9.448718053846166 and parameters: {'n_hidden': 3, 'learning_rate': 0.002007476437440675, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07196748866305003, 'dropout_rate_Layer_2': 0.1204459257971685, 'dropout_rate_Layer_3': 0.026330056965888943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.342114990070504e-05, 'l1_Layer_2': 5.762729830797105e-05, 'l1_Layer_3': 6.792931987808513e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.45 | sMAPE for Validation Set is: 11.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 24.88 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:09:03,704]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:06,339]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:07,109]\u001b[0m Trial 664 finished with value: 10.004121876206924 and parameters: {'n_hidden': 3, 'learning_rate': 0.002356533368183348, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11850588141443044, 'dropout_rate_Layer_2': 0.3013378712561982, 'dropout_rate_Layer_3': 0.20238036616205649, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09547725676892597, 'l1_Layer_2': 0.013397459742756806, 'l1_Layer_3': 0.0030814571764388008, 'n_units_Layer_1': 65, 'n_units_Layer_2': 100, 'n_units_Layer_3': 70}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 12.55% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.19 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:09:09,703]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:11,209]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:11,241]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:11,870]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:12,800]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:19,246]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:22,043]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:25,515]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:26,037]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:31,322]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:34,278]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:36,358]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:39,003]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:45,968]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:50,149]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:53,113]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:55,813]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:09:59,926]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:02,697]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:05,060]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:05,492]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:09,665]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:11,336]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:11,730]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:16,535]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:19,780]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:20,258]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:23,077]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:24,414]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:26,099]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:28,315]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:31,814]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:33,666]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:34,023]\u001b[0m Trial 708 finished with value: 9.772238929950992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022333165220829046, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06716798510652311, 'dropout_rate_Layer_2': 0.258111309081194, 'dropout_rate_Layer_3': 0.07772540633980124, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00023144495987921884, 'l1_Layer_2': 0.00047980456183336164, 'l1_Layer_3': 8.944343826891693e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 290, 'n_units_Layer_3': 270}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.77 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.05 | sMAPE for Test Set is: 16.97% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:10:36,826]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:39,727]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:40,597]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:42,251]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:45,428]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:46,784]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:49,045]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:49,498]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:52,851]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:54,042]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:10:59,174]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:01,805]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:03,922]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:04,175]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:05,083]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:09,707]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:09,977]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:14,262]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:17,403]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:19,398]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:22,199]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:25,576]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:25,774]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:31,968]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:32,213]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:32,684]\u001b[0m Trial 733 finished with value: 9.292405630125904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019203608926249612, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03589722598092452, 'dropout_rate_Layer_2': 0.1099885489555807, 'dropout_rate_Layer_3': 0.05740711113404519, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023324941076307266, 'l1_Layer_2': 5.110382523249495e-05, 'l1_Layer_3': 0.00010601107390726698, 'n_units_Layer_1': 190, 'n_units_Layer_2': 260, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.29 | sMAPE for Validation Set is: 11.10% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.85 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:11:38,466]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:43,622]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:43,712]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:45,788]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:49,689]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:50,105]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:53,506]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:56,491]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:11:57,950]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:01,384]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:04,186]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:07,336]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:14,173]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:17,139]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:22,251]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:31,509]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:35,376]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:39,082]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:41,967]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:42,371]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:47,736]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:49,916]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:51,429]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:54,378]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:12:56,924]\u001b[0m Trial 725 finished with value: 9.546088787315057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009560587145905409, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005404212434921563, 'dropout_rate_Layer_2': 0.24625417905823152, 'dropout_rate_Layer_3': 0.13146479916917278, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012025287267852934, 'l1_Layer_2': 1.1783273505086806e-05, 'l1_Layer_3': 2.8791410045762e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.55 | sMAPE for Validation Set is: 11.51% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 26.00 | sMAPE for Test Set is: 17.01% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:12:59,547]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:02,086]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:02,400]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:08,386]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:08,842]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:14,277]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:17,599]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:22,939]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:25,602]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:27,276]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:30,072]\u001b[0m Trial 771 finished with value: 9.735038998619805 and parameters: {'n_hidden': 3, 'learning_rate': 0.002062218866162726, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07193268278229556, 'dropout_rate_Layer_2': 0.13015775484592504, 'dropout_rate_Layer_3': 0.12152145886773513, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.795754833663166e-05, 'l1_Layer_2': 0.00022938444095820486, 'l1_Layer_3': 4.327323128504384e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.74 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 27.05 | sMAPE for Test Set is: 17.36% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:13:33,109]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:35,929]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:36,622]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:36,960]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:43,401]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:48,286]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:51,507]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:54,795]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:55,333]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:55,504]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:56,347]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:13:59,362]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:03,882]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:07,001]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:07,081]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:07,990]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:10,076]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:12,380]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:15,186]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:17,720]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:19,408]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:19,499]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:20,075]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:21,524]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:26,790]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:26,931]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:27,209]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:33,280]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:34,923]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:38,122]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:38,415]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:42,567]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:47,349]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:47,588]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.96 | sMAPE for Validation Set is: 12.36% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.41 | sMAPE for Test Set is: 17.04% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:14:50,092]\u001b[0m Trial 807 finished with value: 9.963960963298932 and parameters: {'n_hidden': 3, 'learning_rate': 0.005639689882552496, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16915732438774664, 'dropout_rate_Layer_2': 0.33987715693715914, 'dropout_rate_Layer_3': 0.2530373261740356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05047637671436885, 'l1_Layer_2': 0.061032813405214666, 'l1_Layer_3': 0.0006038776463782195, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 85}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:50,670]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:51,717]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:52,321]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:55,959]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:56,362]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:14:58,835]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:00,900]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:05,242]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:05,569]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:05,754]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:06,103]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:12,862]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:13,017]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:13,140]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:13,203]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:20,209]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:23,096]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:26,573]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:26,903]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:27,061]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:32,718]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:32,777]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:33,138]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:37,462]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:40,094]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:41,748]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:43,854]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:46,715]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:47,093]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:49,549]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:52,307]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:53,142]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:54,389]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:55,884]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:57,710]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:15:59,455]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:02,687]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:07,243]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:09,621]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:12,567]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:12,753]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:16,827]\u001b[0m Trial 850 finished with value: 10.017767135035838 and parameters: {'n_hidden': 3, 'learning_rate': 0.007242069117049626, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18536875346989984, 'dropout_rate_Layer_2': 0.3445548632234131, 'dropout_rate_Layer_3': 0.2295210560341641, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02312976106635989, 'l1_Layer_2': 0.015580262776338923, 'l1_Layer_3': 0.00043616030598058744, 'n_units_Layer_1': 105, 'n_units_Layer_2': 130, 'n_units_Layer_3': 110}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.02 | sMAPE for Validation Set is: 12.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.54 | sMAPE for Test Set is: 17.07% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:16:17,301]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:18,439]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:25,673]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:28,309]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:29,918]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:33,156]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:33,492]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:35,280]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:38,933]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:40,822]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:43,868]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:43,912]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:44,438]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:49,595]\u001b[0m Trial 842 finished with value: 10.036432256778525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007810739488661554, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08053975361184165, 'dropout_rate_Layer_2': 0.20827416837268126, 'dropout_rate_Layer_3': 0.3773789541249745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009921415615173456, 'l1_Layer_2': 3.65503831237718e-05, 'l1_Layer_3': 0.0007596827556746795, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 70}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.04 | sMAPE for Validation Set is: 12.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.69 | sMAPE for Test Set is: 17.33% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:16:51,262]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:53,873]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:56,714]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:57,009]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:16:58,303]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:02,655]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:03,095]\u001b[0m Trial 870 finished with value: 10.06953819335284 and parameters: {'n_hidden': 3, 'learning_rate': 0.004072561012291408, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19698901115835774, 'dropout_rate_Layer_2': 0.3531182828614219, 'dropout_rate_Layer_3': 0.24727747317976065, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.051683815881893115, 'l1_Layer_2': 0.02138213934232997, 'l1_Layer_3': 0.0007812346345914593, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 105}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 12.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.88 | sMAPE for Test Set is: 17.33% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:17:03,412]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:09,594]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:10,017]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:14,837]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:15,779]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:20,686]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:21,099]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:25,133]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:29,793]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:30,152]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:32,447]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:37,688]\u001b[0m Trial 878 finished with value: 9.807275439320996 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020720137407826073, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05752677621231084, 'dropout_rate_Layer_2': 0.2648469542467913, 'dropout_rate_Layer_3': 0.2551202965126385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003468565485692426, 'l1_Layer_2': 0.004334728357798351, 'l1_Layer_3': 4.484886611563679e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 245}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.81 | sMAPE for Validation Set is: 12.00% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.09 | sMAPE for Test Set is: 17.11% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:17:40,511]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:40,729]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:43,509]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:48,120]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:54,341]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:17:56,927]\u001b[0m Trial 893 finished with value: 10.265117717481859 and parameters: {'n_hidden': 3, 'learning_rate': 0.004557164633934358, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20797638461626383, 'dropout_rate_Layer_2': 0.36070972248509126, 'dropout_rate_Layer_3': 0.23162449136530255, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07863947450038095, 'l1_Layer_2': 0.012160643536372117, 'l1_Layer_3': 0.00015523241747614317, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.27 | sMAPE for Validation Set is: 12.59% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.56 | sMAPE for Test Set is: 17.85% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:17:57,365]\u001b[0m Trial 894 finished with value: 10.218191163366734 and parameters: {'n_hidden': 3, 'learning_rate': 0.005383799912152116, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1938111991181546, 'dropout_rate_Layer_2': 0.32882295760272345, 'dropout_rate_Layer_3': 0.23196115805305195, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.060867665715874916, 'l1_Layer_2': 0.025759964787108455, 'l1_Layer_3': 0.00044946475306780246, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 135}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 12.67% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.21 | sMAPE for Test Set is: 17.57% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:18:00,701]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:04,011]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:04,707]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:05,051]\u001b[0m Trial 892 finished with value: 10.278041136855299 and parameters: {'n_hidden': 3, 'learning_rate': 0.004729183957215712, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19499734966910798, 'dropout_rate_Layer_2': 0.35251933489807347, 'dropout_rate_Layer_3': 0.2327417253290105, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0833439503719609, 'l1_Layer_2': 0.014715815236539804, 'l1_Layer_3': 0.001159417409471658, 'n_units_Layer_1': 105, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.28 | sMAPE for Validation Set is: 12.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.56 | sMAPE for Test Set is: 17.68% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:18:09,259]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:11,892]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:12,082]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:13,024]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:17,972]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:18,897]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:22,971]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:23,864]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:26,621]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:28,185]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:30,830]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:32,588]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:35,332]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:36,071]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:41,555]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:41,960]\u001b[0m Trial 910 finished with value: 9.951369307356396 and parameters: {'n_hidden': 3, 'learning_rate': 0.006803754660339043, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11864300738885866, 'dropout_rate_Layer_2': 0.3111204736391092, 'dropout_rate_Layer_3': 0.24481391437262692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05368759914054558, 'l1_Layer_2': 0.005758342880855395, 'l1_Layer_3': 0.0006530056091389184, 'n_units_Layer_1': 85, 'n_units_Layer_2': 90, 'n_units_Layer_3': 100}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.95 | sMAPE for Validation Set is: 12.30% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.74 | sMAPE for Test Set is: 17.18% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:18:42,114]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:46,336]\u001b[0m Trial 913 finished with value: 10.373999022070036 and parameters: {'n_hidden': 3, 'learning_rate': 0.006335401152250749, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18238678851743104, 'dropout_rate_Layer_2': 0.33798438467547687, 'dropout_rate_Layer_3': 0.24524529515580745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05558452957697407, 'l1_Layer_2': 0.008944041116258386, 'l1_Layer_3': 0.00685938077463194, 'n_units_Layer_1': 85, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.37 | sMAPE for Validation Set is: 12.80% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.55 | sMAPE for Test Set is: 17.76% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:18:48,159]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:49,398]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:52,032]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:55,364]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:56,192]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:57,231]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:18:58,423]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:01,431]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:02,816]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:03,294]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:06,836]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:08,377]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:10,161]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:10,374]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:11,442]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:12,456]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:18,606]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:19,205]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:22,369]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:23,061]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:23,585]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:32,845]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:33,095]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:37,536]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:39,215]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:41,039]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:43,238]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:43,864]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:44,805]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:49,824]\u001b[0m Trial 933 finished with value: 9.168957934210866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022794042203058552, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06614711485834955, 'dropout_rate_Layer_2': 0.11613259036717002, 'dropout_rate_Layer_3': 0.09880741424897314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021582787780037455, 'l1_Layer_2': 3.590248648107906e-05, 'l1_Layer_3': 4.1688477821329336e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.17 | sMAPE for Validation Set is: 11.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 25.92 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:19:50,057]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:50,608]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:52,417]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:56,958]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:57,419]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:19:58,204]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:04,362]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:04,509]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:08,662]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:13,602]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:20,347]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:34,925]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:37,748]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:40,705]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:43,711]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:50,430]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:53,422]\u001b[0m Trial 954 finished with value: 9.71425976425576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007311183171254956, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008578722091815887, 'dropout_rate_Layer_2': 0.22630649218592908, 'dropout_rate_Layer_3': 0.39969747518180315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006727723144894052, 'l1_Layer_2': 4.750034486456708e-05, 'l1_Layer_3': 0.0008534275098348739, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 55}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.71 | sMAPE for Validation Set is: 11.90% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.22 | sMAPE for Test Set is: 17.00% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:20:53,887]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:58,360]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:58,667]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:20:58,797]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:04,936]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:06,333]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:06,491]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:10,569]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:13,647]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:13,897]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:14,364]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:19,924]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:20,305]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:20,473]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:25,381]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:26,788]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:29,392]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:29,697]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:30,650]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:35,846]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:36,051]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:37,153]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:43,486]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:47,016]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:47,962]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:50,902]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:53,104]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:21:56,876]\u001b[0m Trial 988 finished with value: 10.004523819420813 and parameters: {'n_hidden': 3, 'learning_rate': 0.003764584524561923, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10679059687007705, 'dropout_rate_Layer_2': 0.3169318524498717, 'dropout_rate_Layer_3': 0.21314017685920753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.033930539386438995, 'l1_Layer_2': 0.026713378090153596, 'l1_Layer_3': 0.0002881848047308683, 'n_units_Layer_1': 190, 'n_units_Layer_2': 125, 'n_units_Layer_3': 80}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.00 | sMAPE for Validation Set is: 12.58% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.85 | sMAPE for Test Set is: 17.40% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:21:59,943]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:02,145]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:02,731]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:06,264]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:07,003]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:08,578]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:13,656]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:13,745]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:18,276]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:18,578]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:23,191]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:26,733]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:28,737]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:32,154]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:32,886]\u001b[0m Trial 999 finished with value: 9.794315766329207 and parameters: {'n_hidden': 3, 'learning_rate': 0.003468945387989526, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09616404177730055, 'dropout_rate_Layer_2': 0.31300687030535707, 'dropout_rate_Layer_3': 0.2068826923797877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.034111945226790605, 'l1_Layer_2': 0.02600683813189393, 'l1_Layer_3': 0.0002819705605791586, 'n_units_Layer_1': 190, 'n_units_Layer_2': 130, 'n_units_Layer_3': 80}. Best is trial 256 with value: 9.007381197291824.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.79 | sMAPE for Validation Set is: 12.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.08 | sMAPE for Test Set is: 16.85% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:22:37,102]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:39,000]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:43,817]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:46,130]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:48,301]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:49,054]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:50,807]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:52,603]\u001b[0m Trial 959 finished with value: 8.974411508535319 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008468633775333887, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011258760101334484, 'dropout_rate_Layer_2': 0.001392498157371247, 'dropout_rate_Layer_3': 0.09949381796776352, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006901686428107914, 'l1_Layer_2': 1.4931498355813188e-05, 'l1_Layer_3': 3.767350794277276e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 100}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.97 | sMAPE for Validation Set is: 10.73% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 24.92 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:22:53,725]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:54,317]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:22:54,825]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:00,758]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:01,363]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:03,176]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:06,744]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:07,345]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:12,764]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:12,901]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:14,238]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:20,731]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:20,955]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:23,239]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:27,055]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:27,236]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:28,355]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:34,027]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:36,938]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:37,564]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:37,722]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:38,037]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:46,797]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:52,150]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:52,522]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:23:57,615]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:00,432]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:01,105]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:05,603]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:10,859]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:14,008]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:14,125]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:19,057]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:19,577]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:24,349]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:25,895]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:28,659]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:30,579]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:32,732]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:33,521]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:37,215]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:37,410]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:39,347]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:39,572]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:45,909]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:46,060]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:46,288]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:52,996]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:53,458]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:53,894]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:24:58,550]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:02,529]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:05,365]\u001b[0m Trial 1065 finished with value: 9.718752151769854 and parameters: {'n_hidden': 3, 'learning_rate': 0.00411513182147974, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05202000024107359, 'dropout_rate_Layer_2': 0.15867893331506835, 'dropout_rate_Layer_3': 0.2962453378407258, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019235765795030848, 'l1_Layer_2': 5.8465673949899655e-05, 'l1_Layer_3': 3.7721806261862883e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.72 | sMAPE for Validation Set is: 12.07% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 28.47 | sMAPE for Test Set is: 18.10% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:25:05,975]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:09,430]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:12,458]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:15,639]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:18,532]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:22,584]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:26,079]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:29,842]\u001b[0m Trial 1068 finished with value: 9.566760689088975 and parameters: {'n_hidden': 3, 'learning_rate': 0.004092660599406917, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.055167425172258665, 'dropout_rate_Layer_2': 0.2859477638152256, 'dropout_rate_Layer_3': 0.11250986062573148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018834248443487295, 'l1_Layer_2': 5.209353086562631e-05, 'l1_Layer_3': 6.441665608080997e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.57 | sMAPE for Validation Set is: 11.65% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.43 | sMAPE for Test Set is: 16.59% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:25:42,074]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:45,499]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:52,924]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:25:57,003]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:01,117]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:04,611]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:08,493]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:11,100]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:15,667]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:16,492]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:23,781]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:27,424]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:28,760]\u001b[0m Trial 1072 finished with value: 10.219381587412107 and parameters: {'n_hidden': 3, 'learning_rate': 0.003997782679828063, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11085724819384157, 'dropout_rate_Layer_2': 0.31963594359830766, 'dropout_rate_Layer_3': 0.1974566292314269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0694959483197404, 'l1_Layer_2': 0.028237231010820523, 'l1_Layer_3': 0.00018758238979899825, 'n_units_Layer_1': 170, 'n_units_Layer_2': 110, 'n_units_Layer_3': 65}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.22 | sMAPE for Validation Set is: 12.75% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.97 | sMAPE for Test Set is: 18.49% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:26:34,679]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:34,868]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:35,679]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:42,237]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:42,883]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:47,018]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:47,277]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:47,707]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:54,092]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:54,190]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:55,900]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:26:55,951]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:01,453]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:04,409]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:08,346]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:09,018]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:11,245]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:14,815]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:18,845]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:19,055]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:20,288]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:24,114]\u001b[0m Trial 1102 finished with value: 10.2275194569007 and parameters: {'n_hidden': 3, 'learning_rate': 0.007139617692475229, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17321169033394862, 'dropout_rate_Layer_2': 0.3451526860360109, 'dropout_rate_Layer_3': 0.22970257038753392, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09981343886624064, 'l1_Layer_2': 0.0004667286709756371, 'l1_Layer_3': 0.006796205534959662, 'n_units_Layer_1': 85, 'n_units_Layer_2': 135, 'n_units_Layer_3': 80}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.23 | sMAPE for Validation Set is: 12.72% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 28.20 | sMAPE for Test Set is: 17.97% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:27:26,747]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:28,484]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:28,835]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:29,109]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:35,126]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:37,864]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:43,328]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:43,703]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:44,171]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:48,358]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:54,588]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:54,949]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:55,820]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:27:56,166]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:02,545]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:04,448]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:05,486]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:05,772]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:12,461]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:12,493]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:13,172]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:17,615]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:19,419]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:21,689]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:23,641]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:23,768]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:25,315]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:29,920]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:34,803]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:34,925]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:35,247]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:36,998]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:41,648]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:45,328]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:45,462]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:46,424]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:47,119]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:52,167]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:53,056]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:54,631]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:28:55,185]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:01,365]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:02,123]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:02,201]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:05,013]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:10,674]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:11,017]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:11,313]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:11,382]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:18,789]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:19,525]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:19,964]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:20,026]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:26,203]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:28,414]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:29,920]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:31,654]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:33,093]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:37,343]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:37,551]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:39,093]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:42,065]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:42,269]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:45,262]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:45,282]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:49,725]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:49,923]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:53,485]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:54,692]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:56,711]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:29:59,872]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:01,895]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:02,296]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:06,660]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:10,410]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:10,537]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:10,855]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:14,018]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:22,797]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:23,180]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:23,979]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:25,143]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:29,597]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:33,130]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:33,999]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:34,419]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:40,301]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:40,449]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:46,006]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:46,592]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:46,750]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:48,182]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:30:53,515]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:55,961]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:55,973]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:30:59,871]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:01,625]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:03,978]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:08,390]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:09,099]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:09,454]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:10,244]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:17,087]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:17,370]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:17,949]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:21,999]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:23,791]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:24,372]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:28,127]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:33,042]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:33,822]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:38,937]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:39,130]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:40,266]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:46,737]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:47,199]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:47,200]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:48,688]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:54,155]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:54,783]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:56,135]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:57,456]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:31:59,336]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:04,353]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:04,724]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:05,979]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:07,280]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:11,600]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:12,495]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:13,870]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:14,888]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:18,063]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:19,154]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:23,114]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:27,023]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:28,112]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:32,034]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:35,659]\u001b[0m Trial 1246 finished with value: 9.539565647505293 and parameters: {'n_hidden': 3, 'learning_rate': 0.003031454294894819, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07362039399308287, 'dropout_rate_Layer_2': 0.10396341419334718, 'dropout_rate_Layer_3': 0.04891924681329714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025589007618832506, 'l1_Layer_2': 3.973837877660425e-05, 'l1_Layer_3': 5.778564423050932e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 295, 'n_units_Layer_3': 245}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 11.88% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 27.81 | sMAPE for Test Set is: 17.73% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:32:36,830]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:38,479]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:41,268]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:42,325]\u001b[0m Trial 1245 finished with value: 9.92820133628348 and parameters: {'n_hidden': 3, 'learning_rate': 0.004682158916638473, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2068185853007428, 'dropout_rate_Layer_2': 0.30782746911254805, 'dropout_rate_Layer_3': 0.19433229348407444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.025735427546310512, 'l1_Layer_2': 0.07348303544672957, 'l1_Layer_3': 0.0002655217296068164, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 180}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 12.34% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 26.37 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:32:44,709]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:45,485]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:46,630]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:48,469]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:54,638]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:32:57,225]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:03,582]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:05,449]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:07,270]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:11,025]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:11,502]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:17,026]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:17,351]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:22,318]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:24,467]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:26,257]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:30,166]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:32,070]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:34,182]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:37,148]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:40,725]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:41,038]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:43,419]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:46,847]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:47,215]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:48,244]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:52,476]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:52,854]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:53,256]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:58,594]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:58,795]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:33:59,335]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:02,885]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:04,369]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:08,117]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:09,479]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:11,941]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:12,399]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:13,680]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:17,498]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:23,025]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:23,423]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:23,614]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:25,677]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:31,549]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:32,307]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:33,173]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:35,233]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:39,228]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:39,838]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:40,896]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:44,680]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:52,173]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:52,610]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:56,366]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:34:58,886]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:00,692]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:01,995]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:06,009]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:10,755]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:11,369]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:12,561]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:18,243]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:19,137]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:21,405]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:26,122]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:27,341]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:30,071]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:30,547]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:34,963]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:36,581]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:38,722]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:39,295]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:39,907]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:46,832]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:52,444]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:52,708]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:35:53,208]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:00,057]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:02,672]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:05,590]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:06,238]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:12,111]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:12,276]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:17,178]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:19,469]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:23,425]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:27,781]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:30,567]\u001b[0m Trial 1336 finished with value: 9.840722295629691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022664264847051378, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08425091798358963, 'dropout_rate_Layer_2': 0.3031054072044358, 'dropout_rate_Layer_3': 0.18911290311098922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010693830069990333, 'l1_Layer_2': 0.0005951884773356153, 'l1_Layer_3': 4.224611980619818e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 255, 'n_units_Layer_3': 295}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.84 | sMAPE for Validation Set is: 11.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 25.92 | sMAPE for Test Set is: 16.80% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:36:36,794]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:37,637]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:42,125]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:43,974]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:48,050]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:48,906]\u001b[0m Trial 1345 finished with value: 9.934751738969176 and parameters: {'n_hidden': 3, 'learning_rate': 0.009624166228100967, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15845508501757893, 'dropout_rate_Layer_2': 0.36701662616009245, 'dropout_rate_Layer_3': 0.20425706798560575, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07269130975392492, 'l1_Layer_2': 0.01078007068063682, 'l1_Layer_3': 0.00030514273082521745, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 175}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.93 | sMAPE for Validation Set is: 12.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 26.86 | sMAPE for Test Set is: 17.30% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:36:54,229]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:55,045]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:36:57,086]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:00,470]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:02,701]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:04,113]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:07,249]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:10,712]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:15,912]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:19,212]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:23,140]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:28,887]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:31,660]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:32,853]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:36,261]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:37,436]\u001b[0m Trial 1301 finished with value: 9.464977575804712 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007246927450389439, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 8.172000323197065e-06, 'dropout_rate_Layer_2': 0.0464913237896087, 'dropout_rate_Layer_3': 0.08209929651235455, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00874667185427777, 'l1_Layer_2': 1.7331032095926666e-05, 'l1_Layer_3': 0.0007228860607948259, 'n_units_Layer_1': 170, 'n_units_Layer_2': 260, 'n_units_Layer_3': 255}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.46 | sMAPE for Validation Set is: 11.50% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.91 | sMAPE for Test Set is: 16.95% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:37:40,862]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:43,275]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:44,706]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:45,118]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:53,056]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:53,617]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:37:59,428]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:04,111]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:10,289]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:14,100]\u001b[0m Trial 1375 finished with value: 10.262056387585192 and parameters: {'n_hidden': 3, 'learning_rate': 0.010182958448056473, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1376600549766397, 'dropout_rate_Layer_2': 0.3623468446270999, 'dropout_rate_Layer_3': 0.22277288242171495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09396180143038915, 'l1_Layer_2': 0.010823965523733043, 'l1_Layer_3': 1.3790944455294796e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 155, 'n_units_Layer_3': 220}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 12.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.56 | sMAPE for Test Set is: 17.74% | rMAE for Test Set is: 0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:38:14,431]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:18,625]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:24,202]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:29,490]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:33,436]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:39,067]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:41,406]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:47,211]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:52,162]\u001b[0m Trial 1383 finished with value: 10.035078517942237 and parameters: {'n_hidden': 3, 'learning_rate': 0.007957519400940576, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1743472265762491, 'dropout_rate_Layer_2': 0.37112280668280107, 'dropout_rate_Layer_3': 0.19848799369012246, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.07278930761724417, 'l1_Layer_2': 0.0067312898454125695, 'l1_Layer_3': 0.005298301939244213, 'n_units_Layer_1': 265, 'n_units_Layer_2': 130, 'n_units_Layer_3': 145}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.04 | sMAPE for Validation Set is: 12.29% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 27.17 | sMAPE for Test Set is: 17.39% | rMAE for Test Set is: 0.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:38:55,801]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:38:58,199]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:05,205]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:08,223]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:08,369]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:09,537]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:14,545]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:17,013]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:21,310]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:24,227]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:27,460]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:29,791]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:30,912]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:34,480]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:37,005]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:39,923]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:40,144]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:44,471]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:49,477]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:52,365]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:39:52,714]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:01,844]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:02,023]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:03,037]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:07,619]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:12,367]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:13,398]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:14,835]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:25,792]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:33,572]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:38,026]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:39,887]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:41,684]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:43,971]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:49,867]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:40:53,063]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:41:23,832]\u001b[0m Trial 1391 finished with value: 9.620319395100827 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006042726457055495, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004977201162351709, 'dropout_rate_Layer_2': 0.05528270659251544, 'dropout_rate_Layer_3': 0.0744731989887281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003773134564331758, 'l1_Layer_2': 1.51944051110822e-05, 'l1_Layer_3': 0.0030638427294580176, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.62 | sMAPE for Validation Set is: 11.53% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 26.77 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:41:26,821]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:41:47,845]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:02,943]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:10,809]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:13,861]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:20,522]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:25,960]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:41,759]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:45,770]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:42:51,100]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:43:04,805]\u001b[0m Trial 1422 finished with value: 9.25716132634623 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007450949337245061, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07983332557586852, 'dropout_rate_Layer_2': 0.020441669936370303, 'dropout_rate_Layer_3': 0.0844388943599701, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004031272056579058, 'l1_Layer_2': 1.729384782336453e-05, 'l1_Layer_3': 2.1531014644974243e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 70, 'n_units_Layer_3': 90}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.26 | sMAPE for Validation Set is: 11.25% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.33 | sMAPE for Test Set is: 16.60% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:43:12,394]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:43:21,398]\u001b[0m Trial 1424 finished with value: 9.700295993318328 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007557791775236723, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008378830278079812, 'dropout_rate_Layer_2': 0.050703181197716135, 'dropout_rate_Layer_3': 0.07291380077996926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000504714477174265, 'l1_Layer_2': 1.634753209147813e-05, 'l1_Layer_3': 0.0029621048434201663, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 240}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.70 | sMAPE for Validation Set is: 11.68% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 25.79 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:43:27,015]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:43:30,819]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:43:34,905]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:13,898]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:14,341]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:20,223]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:24,216]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:24,729]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:35,424]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:38,826]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:44,401]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:49,860]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:44:57,365]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:45:06,398]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:45:14,073]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:45:14,460]\u001b[0m Trial 1433 finished with value: 9.385515424588098 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005482695747314733, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015355677416508128, 'dropout_rate_Layer_2': 0.03353689686691249, 'dropout_rate_Layer_3': 0.07612613014261443, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002818348968480966, 'l1_Layer_2': 1.6123425152908475e-05, 'l1_Layer_3': 4.408063095036095e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 110, 'n_units_Layer_3': 250}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.39 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 25.81 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:45:21,330]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:45:22,351]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:45:31,656]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:45:32,027]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:46:52,019]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:46:58,809]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:01,242]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:03,722]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:07,660]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:08,334]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:13,962]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:16,910]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:26,827]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:32,226]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:34,968]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:39,801]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:40,639]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:49,372]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:51,348]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:47:56,904]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:48:07,788]\u001b[0m Trial 1470 finished with value: 9.522659594306733 and parameters: {'n_hidden': 3, 'learning_rate': 0.002332487467593066, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05952019413599435, 'dropout_rate_Layer_2': 0.19057901034180508, 'dropout_rate_Layer_3': 0.06163431792220751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004102364015940569, 'l1_Layer_2': 2.6468770273380105e-05, 'l1_Layer_3': 5.5096695943722555e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 275, 'n_units_Layer_3': 255}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.52 | sMAPE for Validation Set is: 11.45% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 16.34% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:48:12,777]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:48:17,058]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:48:32,577]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:48:40,228]\u001b[0m Trial 1456 finished with value: 9.580820758116312 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005900235606344684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00044288254579080005, 'dropout_rate_Layer_2': 0.016255330735168622, 'dropout_rate_Layer_3': 0.0641808122756577, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002871796370917535, 'l1_Layer_2': 1.2971870753984042e-05, 'l1_Layer_3': 3.250586015140464e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 11.47% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.76 | sMAPE for Test Set is: 16.83% | rMAE for Test Set is: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:48:43,720]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:48:53,221]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:49:12,917]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:49:18,382]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:49:23,804]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:49:30,817]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:49:46,566]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:02,352]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:07,025]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:12,745]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:26,528]\u001b[0m Trial 1485 finished with value: 9.402447815918169 and parameters: {'n_hidden': 3, 'learning_rate': 0.002278383312696048, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08975451378993102, 'dropout_rate_Layer_2': 0.18119712160555476, 'dropout_rate_Layer_3': 0.0534222047777931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004391183624514016, 'l1_Layer_2': 3.4161724828318114e-05, 'l1_Layer_3': 5.721760933222101e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 24.68 | sMAPE for Test Set is: 16.38% | rMAE for Test Set is: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:50:33,300]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:38,242]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:45,826]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:47,725]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:49,657]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:53,699]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:50:54,108]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:51:04,038]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:51:17,975]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:51:21,584]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:51:40,059]\u001b[0m Trial 1498 finished with value: 9.466364941197403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019461818398786711, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10883476619996163, 'dropout_rate_Layer_2': 0.20080010137618587, 'dropout_rate_Layer_3': 0.042881060301697284, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007004118857223381, 'l1_Layer_2': 2.3476993557922733e-05, 'l1_Layer_3': 6.597013634620419e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 275, 'n_units_Layer_3': 230}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.47 | sMAPE for Validation Set is: 11.34% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.20 | sMAPE for Test Set is: 16.40% | rMAE for Test Set is: 0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:51:45,552]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:52:05,586]\u001b[0m Trial 1487 finished with value: 9.576890328236798 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006106209535430612, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0002135898961659856, 'dropout_rate_Layer_2': 0.015660701408542133, 'dropout_rate_Layer_3': 0.07360845948276683, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018421748593293856, 'l1_Layer_2': 1.6829325678221348e-05, 'l1_Layer_3': 1.9928278220004902e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 115, 'n_units_Layer_3': 235}. Best is trial 959 with value: 8.974411508535319.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.58 | sMAPE for Validation Set is: 11.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 25.93 | sMAPE for Test Set is: 16.99% | rMAE for Test Set is: 0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 04:52:22,644]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 04:52:24,882]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-01-01, MAE is:13.04 & sMAPE is:9.78% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :13.04 & 9.78% & 0.18\n",
      "for 2022-01-02, MAE is:20.19 & sMAPE is:16.11% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :16.62 & 12.95% & 0.23\n",
      "for 2022-01-03, MAE is:14.96 & sMAPE is:12.10% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :16.07 & 12.66% & 0.25\n",
      "for 2022-01-04, MAE is:9.64 & sMAPE is:6.78% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :14.46 & 11.19% & 0.40\n",
      "for 2022-01-05, MAE is:10.46 & sMAPE is:7.81% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.66 & 10.52% & 0.38\n",
      "for 2022-01-06, MAE is:15.80 & sMAPE is:10.70% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :14.02 & 10.55% & 0.47\n",
      "for 2022-01-07, MAE is:16.16 & sMAPE is:10.92% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :14.32 & 10.60% & 0.55\n",
      "for 2022-01-08, MAE is:18.13 & sMAPE is:12.67% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.80 & 10.86% & 0.59\n",
      "for 2022-01-09, MAE is:24.67 & sMAPE is:16.66% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :15.90 & 11.50% & 0.61\n",
      "for 2022-01-10, MAE is:13.00 & sMAPE is:8.44% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :15.61 & 11.20% & 0.59\n",
      "for 2022-01-11, MAE is:16.77 & sMAPE is:11.21% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :15.71 & 11.20% & 0.68\n",
      "for 2022-01-12, MAE is:12.98 & sMAPE is:9.57% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :15.48 & 11.06% & 0.73\n",
      "for 2022-01-13, MAE is:9.52 & sMAPE is:7.36% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :15.03 & 10.78% & 0.70\n",
      "for 2022-01-14, MAE is:7.99 & sMAPE is:5.99% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :14.52 & 10.44% & 0.68\n",
      "for 2022-01-15, MAE is:17.57 & sMAPE is:12.22% & rMAE is:2.74 ||| daily mean of MAE & sMAPE & rMAE till now are :14.73 & 10.55% & 0.81\n",
      "for 2022-01-16, MAE is:11.89 & sMAPE is:9.21% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 10.47% & 0.79\n",
      "for 2022-01-17, MAE is:12.59 & sMAPE is:9.56% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.43 & 10.42% & 0.76\n",
      "for 2022-01-18, MAE is:13.85 & sMAPE is:9.81% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :14.40 & 10.38% & 0.81\n",
      "for 2022-01-19, MAE is:11.87 & sMAPE is:9.20% & rMAE is:3.23 ||| daily mean of MAE & sMAPE & rMAE till now are :14.27 & 10.32% & 0.94\n",
      "for 2022-01-20, MAE is:7.08 & sMAPE is:5.60% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.91 & 10.09% & 0.97\n",
      "for 2022-01-21, MAE is:9.73 & sMAPE is:7.54% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :13.71 & 9.96% & 0.97\n",
      "for 2022-01-22, MAE is:11.85 & sMAPE is:8.96% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.63 & 9.92% & 0.98\n",
      "for 2022-01-23, MAE is:10.65 & sMAPE is:8.17% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :13.50 & 9.84% & 0.99\n",
      "for 2022-01-24, MAE is:10.61 & sMAPE is:7.68% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :13.38 & 9.75% & 1.00\n",
      "for 2022-01-25, MAE is:13.69 & sMAPE is:9.25% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :13.39 & 9.73% & 1.00\n",
      "for 2022-01-26, MAE is:11.95 & sMAPE is:9.32% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :13.33 & 9.72% & 1.04\n",
      "for 2022-01-27, MAE is:7.83 & sMAPE is:6.31% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :13.13 & 9.59% & 1.06\n",
      "for 2022-01-28, MAE is:14.17 & sMAPE is:11.19% & rMAE is:5.16 ||| daily mean of MAE & sMAPE & rMAE till now are :13.17 & 9.65% & 1.21\n",
      "for 2022-01-29, MAE is:16.00 & sMAPE is:16.41% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :13.26 & 9.88% & 1.19\n",
      "for 2022-01-30, MAE is:10.67 & sMAPE is:8.76% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :13.18 & 9.84% & 1.17\n",
      "for 2022-01-31, MAE is:13.50 & sMAPE is:9.43% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.19 & 9.83% & 1.17\n",
      "for 2022-02-01, MAE is:16.81 & sMAPE is:12.48% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :13.30 & 9.91% & 1.16\n",
      "for 2022-02-02, MAE is:15.19 & sMAPE is:11.58% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :13.36 & 9.96% & 1.15\n",
      "for 2022-02-03, MAE is:15.57 & sMAPE is:10.70% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :13.42 & 9.98% & 1.14\n",
      "for 2022-02-04, MAE is:11.14 & sMAPE is:8.48% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :13.36 & 9.94% & 1.13\n",
      "for 2022-02-05, MAE is:6.07 & sMAPE is:5.43% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :13.16 & 9.82% & 1.12\n",
      "for 2022-02-06, MAE is:7.75 & sMAPE is:7.28% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :13.01 & 9.75% & 1.11\n",
      "for 2022-02-07, MAE is:12.67 & sMAPE is:11.16% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :13.00 & 9.78% & 1.09\n",
      "for 2022-02-08, MAE is:9.95 & sMAPE is:8.62% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :12.92 & 9.76% & 1.08\n",
      "for 2022-02-09, MAE is:8.87 & sMAPE is:7.30% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :12.82 & 9.69% & 1.07\n",
      "for 2022-02-10, MAE is:11.69 & sMAPE is:9.05% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :12.79 & 9.68% & 1.05\n",
      "for 2022-02-11, MAE is:10.81 & sMAPE is:8.91% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :12.75 & 9.66% & 1.08\n",
      "for 2022-02-12, MAE is:9.10 & sMAPE is:8.21% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 9.63% & 1.09\n",
      "for 2022-02-13, MAE is:12.88 & sMAPE is:13.65% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :12.67 & 9.72% & 1.09\n",
      "for 2022-02-14, MAE is:8.84 & sMAPE is:8.54% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :12.58 & 9.69% & 1.08\n",
      "for 2022-02-15, MAE is:10.26 & sMAPE is:9.78% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :12.53 & 9.69% & 1.08\n",
      "for 2022-02-16, MAE is:9.90 & sMAPE is:9.48% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :12.48 & 9.69% & 1.07\n",
      "for 2022-02-17, MAE is:5.68 & sMAPE is:5.62% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 9.60% & 1.06\n",
      "for 2022-02-18, MAE is:7.92 & sMAPE is:7.40% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.24 & 9.56% & 1.04\n",
      "for 2022-02-19, MAE is:8.67 & sMAPE is:8.88% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :12.17 & 9.55% & 1.04\n",
      "for 2022-02-20, MAE is:4.94 & sMAPE is:4.99% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :12.03 & 9.46% & 1.04\n",
      "for 2022-02-21, MAE is:11.65 & sMAPE is:11.65% & rMAE is:4.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.02 & 9.50% & 1.10\n",
      "for 2022-02-22, MAE is:10.47 & sMAPE is:8.44% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :11.99 & 9.48% & 1.10\n",
      "for 2022-02-23, MAE is:11.87 & sMAPE is:11.55% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :11.99 & 9.52% & 1.13\n",
      "for 2022-02-24, MAE is:16.23 & sMAPE is:15.22% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :12.07 & 9.62% & 1.13\n",
      "for 2022-02-25, MAE is:20.32 & sMAPE is:17.89% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 9.77% & 1.14\n",
      "for 2022-02-26, MAE is:11.04 & sMAPE is:7.98% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.20 & 9.74% & 1.12\n",
      "for 2022-02-27, MAE is:22.44 & sMAPE is:17.93% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 9.88% & 1.11\n",
      "for 2022-02-28, MAE is:13.89 & sMAPE is:10.47% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :12.40 & 9.89% & 1.10\n",
      "for 2022-03-01, MAE is:16.67 & sMAPE is:11.96% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.47 & 9.92% & 1.09\n",
      "for 2022-03-02, MAE is:14.41 & sMAPE is:9.97% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.50 & 9.92% & 1.08\n",
      "for 2022-03-03, MAE is:22.47 & sMAPE is:15.70% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 10.02% & 1.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-04, MAE is:42.31 & sMAPE is:20.89% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :13.13 & 10.19% & 1.06\n",
      "for 2022-03-05, MAE is:21.81 & sMAPE is:13.30% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :13.27 & 10.24% & 1.05\n",
      "for 2022-03-06, MAE is:20.28 & sMAPE is:11.00% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.38 & 10.25% & 1.04\n",
      "for 2022-03-07, MAE is:53.24 & sMAPE is:19.43% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.98 & 10.39% & 1.03\n",
      "for 2022-03-08, MAE is:73.78 & sMAPE is:25.92% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :14.87 & 10.62% & 1.03\n",
      "for 2022-03-09, MAE is:18.58 & sMAPE is:8.28% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :14.93 & 10.59% & 1.02\n",
      "for 2022-03-10, MAE is:24.79 & sMAPE is:12.55% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :15.07 & 10.61% & 1.01\n",
      "for 2022-03-11, MAE is:24.59 & sMAPE is:14.06% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :15.21 & 10.66% & 1.01\n",
      "for 2022-03-12, MAE is:11.12 & sMAPE is:6.24% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :15.15 & 10.60% & 1.02\n",
      "for 2022-03-13, MAE is:11.57 & sMAPE is:7.14% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :15.10 & 10.55% & 1.01\n",
      "for 2022-03-14, MAE is:22.01 & sMAPE is:11.75% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.19 & 10.57% & 1.00\n",
      "for 2022-03-15, MAE is:29.68 & sMAPE is:14.14% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :15.39 & 10.62% & 1.00\n",
      "for 2022-03-16, MAE is:28.91 & sMAPE is:14.29% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :15.57 & 10.67% & 1.00\n",
      "for 2022-03-17, MAE is:12.69 & sMAPE is:7.07% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :15.53 & 10.62% & 0.99\n",
      "for 2022-03-18, MAE is:21.51 & sMAPE is:10.70% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.61 & 10.62% & 1.01\n",
      "for 2022-03-19, MAE is:18.43 & sMAPE is:10.76% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :15.65 & 10.62% & 1.01\n",
      "for 2022-03-20, MAE is:8.73 & sMAPE is:5.42% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :15.56 & 10.56% & 1.01\n",
      "for 2022-03-21, MAE is:13.02 & sMAPE is:7.15% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.53 & 10.51% & 1.01\n",
      "for 2022-03-22, MAE is:20.88 & sMAPE is:10.95% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :15.59 & 10.52% & 1.01\n",
      "for 2022-03-23, MAE is:28.11 & sMAPE is:13.81% & rMAE is:2.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.74 & 10.56% & 1.02\n",
      "for 2022-03-24, MAE is:17.14 & sMAPE is:8.59% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.76 & 10.54% & 1.02\n",
      "for 2022-03-25, MAE is:18.81 & sMAPE is:10.06% & rMAE is:3.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.80 & 10.53% & 1.05\n",
      "for 2022-03-26, MAE is:15.44 & sMAPE is:8.79% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.79 & 10.51% & 1.05\n",
      "for 2022-03-27, MAE is:15.45 & sMAPE is:8.26% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :15.79 & 10.48% & 1.04\n",
      "for 2022-03-28, MAE is:14.92 & sMAPE is:7.84% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :15.78 & 10.45% & 1.05\n",
      "for 2022-03-29, MAE is:17.50 & sMAPE is:8.23% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.80 & 10.43% & 1.06\n",
      "for 2022-03-30, MAE is:20.03 & sMAPE is:9.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :15.85 & 10.41% & 1.06\n",
      "for 2022-03-31, MAE is:23.21 & sMAPE is:10.95% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 10.42% & 1.06\n",
      "for 2022-04-01, MAE is:10.79 & sMAPE is:5.61% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 10.37% & 1.07\n",
      "for 2022-04-02, MAE is:11.52 & sMAPE is:6.19% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :15.82 & 10.32% & 1.08\n",
      "for 2022-04-03, MAE is:21.12 & sMAPE is:11.14% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.88 & 10.33% & 1.10\n",
      "for 2022-04-04, MAE is:8.77 & sMAPE is:5.00% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :15.81 & 10.27% & 1.10\n",
      "for 2022-04-05, MAE is:14.27 & sMAPE is:7.86% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :15.79 & 10.25% & 1.09\n",
      "for 2022-04-06, MAE is:23.91 & sMAPE is:12.62% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 10.27% & 1.09\n",
      "for 2022-04-07, MAE is:14.14 & sMAPE is:8.19% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :15.86 & 10.25% & 1.08\n",
      "for 2022-04-08, MAE is:9.83 & sMAPE is:5.59% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :15.80 & 10.20% & 1.08\n",
      "for 2022-04-09, MAE is:10.30 & sMAPE is:6.32% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :15.74 & 10.17% & 1.07\n",
      "for 2022-04-10, MAE is:10.67 & sMAPE is:6.63% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :15.69 & 10.13% & 1.07\n",
      "for 2022-04-11, MAE is:15.53 & sMAPE is:8.34% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :15.69 & 10.11% & 1.06\n",
      "for 2022-04-12, MAE is:16.94 & sMAPE is:9.38% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :15.70 & 10.10% & 1.07\n",
      "for 2022-04-13, MAE is:10.18 & sMAPE is:5.60% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :15.65 & 10.06% & 1.07\n",
      "for 2022-04-14, MAE is:19.33 & sMAPE is:10.71% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :15.68 & 10.07% & 1.07\n",
      "for 2022-04-15, MAE is:16.40 & sMAPE is:9.04% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :15.69 & 10.06% & 1.06\n",
      "for 2022-04-16, MAE is:20.47 & sMAPE is:12.19% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.73 & 10.08% & 1.07\n",
      "for 2022-04-17, MAE is:18.27 & sMAPE is:13.02% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :15.76 & 10.11% & 1.06\n",
      "for 2022-04-18, MAE is:19.76 & sMAPE is:13.07% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :15.79 & 10.13% & 1.06\n",
      "for 2022-04-19, MAE is:31.61 & sMAPE is:17.01% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 10.20% & 1.07\n",
      "for 2022-04-20, MAE is:10.59 & sMAPE is:5.67% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :15.89 & 10.15% & 1.07\n",
      "for 2022-04-21, MAE is:7.58 & sMAPE is:3.98% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :15.82 & 10.10% & 1.07\n",
      "for 2022-04-22, MAE is:12.45 & sMAPE is:7.74% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :15.79 & 10.08% & 1.07\n",
      "for 2022-04-23, MAE is:12.08 & sMAPE is:7.91% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :15.75 & 10.06% & 1.06\n",
      "for 2022-04-24, MAE is:36.28 & sMAPE is:28.43% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :15.93 & 10.22% & 1.06\n",
      "for 2022-04-25, MAE is:52.02 & sMAPE is:29.03% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :16.25 & 10.38% & 1.06\n",
      "for 2022-04-26, MAE is:11.71 & sMAPE is:6.29% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 10.35% & 1.06\n",
      "for 2022-04-27, MAE is:16.55 & sMAPE is:8.23% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 10.33% & 1.06\n",
      "for 2022-04-28, MAE is:15.71 & sMAPE is:7.64% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 10.31% & 1.06\n",
      "for 2022-04-29, MAE is:25.42 & sMAPE is:12.12% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :16.28 & 10.32% & 1.06\n",
      "for 2022-04-30, MAE is:7.37 & sMAPE is:3.76% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 10.27% & 1.05\n",
      "for 2022-05-01, MAE is:7.39 & sMAPE is:3.77% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :16.14 & 10.21% & 1.04\n",
      "for 2022-05-02, MAE is:9.73 & sMAPE is:4.72% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :16.08 & 10.17% & 1.04\n",
      "for 2022-05-03, MAE is:20.16 & sMAPE is:9.43% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :16.12 & 10.16% & 1.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-04, MAE is:14.81 & sMAPE is:6.60% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :16.11 & 10.13% & 1.04\n",
      "for 2022-05-05, MAE is:11.72 & sMAPE is:5.33% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :16.07 & 10.10% & 1.04\n",
      "for 2022-05-06, MAE is:13.67 & sMAPE is:6.29% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 10.07% & 1.04\n",
      "for 2022-05-07, MAE is:8.93 & sMAPE is:4.47% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :16.00 & 10.02% & 1.05\n",
      "for 2022-05-08, MAE is:14.32 & sMAPE is:8.15% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.98 & 10.01% & 1.05\n",
      "for 2022-05-09, MAE is:9.99 & sMAPE is:4.97% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :15.94 & 9.97% & 1.05\n",
      "for 2022-05-10, MAE is:5.52 & sMAPE is:3.04% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :15.86 & 9.91% & 1.04\n",
      "for 2022-05-11, MAE is:13.30 & sMAPE is:7.76% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :15.84 & 9.90% & 1.04\n",
      "for 2022-05-12, MAE is:19.01 & sMAPE is:13.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :15.86 & 9.93% & 1.03\n",
      "for 2022-05-13, MAE is:35.28 & sMAPE is:29.56% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :16.01 & 10.07% & 1.03\n",
      "for 2022-05-14, MAE is:34.08 & sMAPE is:31.89% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :16.14 & 10.24% & 1.02\n",
      "for 2022-05-15, MAE is:32.64 & sMAPE is:27.53% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :16.26 & 10.37% & 1.02\n",
      "for 2022-05-16, MAE is:9.84 & sMAPE is:5.88% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :16.22 & 10.33% & 1.02\n",
      "for 2022-05-17, MAE is:8.15 & sMAPE is:4.64% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :16.16 & 10.29% & 1.02\n",
      "for 2022-05-18, MAE is:9.26 & sMAPE is:5.26% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :16.11 & 10.25% & 1.01\n",
      "for 2022-05-19, MAE is:14.22 & sMAPE is:7.57% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :16.09 & 10.23% & 1.01\n",
      "for 2022-05-20, MAE is:23.97 & sMAPE is:13.96% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :16.15 & 10.26% & 1.01\n",
      "for 2022-05-21, MAE is:26.43 & sMAPE is:20.28% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :16.22 & 10.33% & 1.01\n",
      "for 2022-05-22, MAE is:22.25 & sMAPE is:14.66% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :16.27 & 10.36% & 1.01\n",
      "for 2022-05-23, MAE is:16.74 & sMAPE is:9.79% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :16.27 & 10.36% & 1.01\n",
      "for 2022-05-24, MAE is:29.33 & sMAPE is:28.67% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :16.36 & 10.49% & 1.01\n",
      "for 2022-05-25, MAE is:23.24 & sMAPE is:16.02% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :16.41 & 10.52% & 1.01\n",
      "for 2022-05-26, MAE is:69.26 & sMAPE is:99.14% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :16.77 & 11.13% & 1.00\n",
      "for 2022-05-27, MAE is:39.69 & sMAPE is:78.66% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :16.93 & 11.59% & 1.00\n",
      "for 2022-05-28, MAE is:57.73 & sMAPE is:148.90% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :17.20 & 12.52% & 1.00\n",
      "for 2022-05-29, MAE is:66.43 & sMAPE is:61.86% & rMAE is:3.01 ||| daily mean of MAE & sMAPE & rMAE till now are :17.53 & 12.85% & 1.01\n",
      "for 2022-05-30, MAE is:37.62 & sMAPE is:24.38% & rMAE is:3.56 ||| daily mean of MAE & sMAPE & rMAE till now are :17.67 & 12.93% & 1.03\n",
      "for 2022-05-31, MAE is:27.75 & sMAPE is:17.36% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :17.73 & 12.96% & 1.02\n",
      "for 2022-06-01, MAE is:15.88 & sMAPE is:9.47% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :17.72 & 12.93% & 1.02\n",
      "for 2022-06-02, MAE is:8.01 & sMAPE is:4.99% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :17.66 & 12.88% & 1.02\n",
      "for 2022-06-03, MAE is:11.47 & sMAPE is:7.37% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :17.62 & 12.85% & 1.01\n",
      "for 2022-06-04, MAE is:12.52 & sMAPE is:8.60% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :17.58 & 12.82% & 1.00\n",
      "for 2022-06-05, MAE is:7.41 & sMAPE is:5.82% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :17.52 & 12.77% & 1.00\n",
      "for 2022-06-06, MAE is:38.93 & sMAPE is:56.21% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :17.65 & 13.05% & 1.00\n",
      "for 2022-06-07, MAE is:52.73 & sMAPE is:38.52% & rMAE is:3.36 ||| daily mean of MAE & sMAPE & rMAE till now are :17.88 & 13.21% & 1.02\n",
      "for 2022-06-08, MAE is:20.42 & sMAPE is:15.15% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :17.89 & 13.22% & 1.01\n",
      "for 2022-06-09, MAE is:25.86 & sMAPE is:17.75% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :17.94 & 13.25% & 1.02\n",
      "for 2022-06-10, MAE is:11.14 & sMAPE is:7.62% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :17.90 & 13.22% & 1.02\n",
      "for 2022-06-11, MAE is:22.32 & sMAPE is:26.61% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :17.93 & 13.30% & 1.01\n",
      "for 2022-06-12, MAE is:30.85 & sMAPE is:45.18% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :18.01 & 13.49% & 1.01\n",
      "for 2022-06-13, MAE is:43.59 & sMAPE is:39.18% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :18.16 & 13.65% & 1.01\n",
      "for 2022-06-14, MAE is:17.04 & sMAPE is:12.61% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :18.16 & 13.64% & 1.01\n",
      "for 2022-06-15, MAE is:15.06 & sMAPE is:9.92% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :18.14 & 13.62% & 1.01\n",
      "for 2022-06-16, MAE is:34.16 & sMAPE is:21.89% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :18.23 & 13.67% & 1.01\n",
      "for 2022-06-17, MAE is:27.47 & sMAPE is:16.49% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :18.29 & 13.69% & 1.01\n",
      "for 2022-06-18, MAE is:15.03 & sMAPE is:11.55% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :18.27 & 13.68% & 1.01\n",
      "for 2022-06-19, MAE is:24.02 & sMAPE is:19.50% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :18.30 & 13.71% & 1.01\n",
      "for 2022-06-20, MAE is:32.29 & sMAPE is:21.04% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :18.38 & 13.75% & 1.01\n",
      "for 2022-06-21, MAE is:16.52 & sMAPE is:10.22% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :18.37 & 13.73% & 1.01\n",
      "for 2022-06-22, MAE is:38.47 & sMAPE is:26.66% & rMAE is:2.98 ||| daily mean of MAE & sMAPE & rMAE till now are :18.49 & 13.81% & 1.02\n",
      "for 2022-06-23, MAE is:27.83 & sMAPE is:20.64% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :18.54 & 13.85% & 1.02\n",
      "for 2022-06-24, MAE is:6.20 & sMAPE is:4.33% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :18.47 & 13.79% & 1.01\n",
      "for 2022-06-25, MAE is:8.47 & sMAPE is:5.98% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :18.42 & 13.75% & 1.01\n",
      "for 2022-06-26, MAE is:20.64 & sMAPE is:16.62% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :18.43 & 13.76% & 1.02\n",
      "for 2022-06-27, MAE is:43.65 & sMAPE is:31.97% & rMAE is:4.35 ||| daily mean of MAE & sMAPE & rMAE till now are :18.57 & 13.87% & 1.03\n",
      "for 2022-06-28, MAE is:16.18 & sMAPE is:11.29% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :18.56 & 13.85% & 1.03\n",
      "for 2022-06-29, MAE is:19.13 & sMAPE is:13.23% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :18.56 & 13.85% & 1.04\n",
      "for 2022-06-30, MAE is:20.68 & sMAPE is:13.48% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :18.57 & 13.85% & 1.04\n",
      "for 2022-07-01, MAE is:12.01 & sMAPE is:7.34% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :18.54 & 13.81% & 1.04\n",
      "for 2022-07-02, MAE is:18.55 & sMAPE is:12.96% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :18.54 & 13.81% & 1.04\n",
      "for 2022-07-03, MAE is:22.66 & sMAPE is:17.43% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :18.56 & 13.83% & 1.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-04, MAE is:10.05 & sMAPE is:6.61% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :18.51 & 13.79% & 1.04\n",
      "for 2022-07-05, MAE is:11.91 & sMAPE is:7.81% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :18.48 & 13.75% & 1.04\n",
      "for 2022-07-06, MAE is:15.12 & sMAPE is:9.73% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :18.46 & 13.73% & 1.05\n",
      "for 2022-07-07, MAE is:16.93 & sMAPE is:11.16% & rMAE is:3.16 ||| daily mean of MAE & sMAPE & rMAE till now are :18.45 & 13.72% & 1.06\n",
      "for 2022-07-08, MAE is:20.01 & sMAPE is:13.40% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :18.46 & 13.72% & 1.07\n",
      "for 2022-07-09, MAE is:42.28 & sMAPE is:43.59% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :18.58 & 13.87% & 1.07\n",
      "for 2022-07-10, MAE is:55.35 & sMAPE is:66.49% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :18.78 & 14.15% & 1.06\n",
      "for 2022-07-11, MAE is:63.58 & sMAPE is:44.36% & rMAE is:3.42 ||| daily mean of MAE & sMAPE & rMAE till now are :19.01 & 14.31% & 1.08\n",
      "for 2022-07-12, MAE is:32.22 & sMAPE is:19.43% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.08 & 14.33% & 1.08\n",
      "for 2022-07-13, MAE is:15.32 & sMAPE is:9.17% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :19.06 & 14.31% & 1.08\n",
      "for 2022-07-14, MAE is:11.04 & sMAPE is:6.94% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :19.02 & 14.27% & 1.08\n",
      "for 2022-07-15, MAE is:10.31 & sMAPE is:6.67% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :18.97 & 14.23% & 1.08\n",
      "for 2022-07-16, MAE is:57.79 & sMAPE is:69.02% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :19.17 & 14.51% & 1.09\n",
      "for 2022-07-17, MAE is:31.97 & sMAPE is:23.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :19.24 & 14.56% & 1.08\n",
      "for 2022-07-18, MAE is:8.67 & sMAPE is:5.65% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :19.18 & 14.51% & 1.08\n",
      "for 2022-07-19, MAE is:7.63 & sMAPE is:4.97% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :19.12 & 14.46% & 1.08\n",
      "for 2022-07-20, MAE is:18.85 & sMAPE is:12.35% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :19.12 & 14.45% & 1.08\n",
      "for 2022-07-21, MAE is:35.72 & sMAPE is:20.18% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :19.21 & 14.48% & 1.08\n",
      "for 2022-07-22, MAE is:10.16 & sMAPE is:5.71% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :19.16 & 14.44% & 1.08\n",
      "for 2022-07-23, MAE is:12.95 & sMAPE is:8.20% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :19.13 & 14.41% & 1.07\n",
      "for 2022-07-24, MAE is:31.83 & sMAPE is:24.90% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :19.19 & 14.46% & 1.08\n",
      "for 2022-07-25, MAE is:22.32 & sMAPE is:14.17% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :19.21 & 14.46% & 1.08\n",
      "for 2022-07-26, MAE is:21.53 & sMAPE is:14.43% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :19.22 & 14.46% & 1.08\n",
      "for 2022-07-27, MAE is:33.11 & sMAPE is:20.72% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :19.29 & 14.49% & 1.09\n",
      "for 2022-07-28, MAE is:35.25 & sMAPE is:18.89% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :19.36 & 14.51% & 1.09\n",
      "for 2022-07-29, MAE is:18.16 & sMAPE is:9.10% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :19.36 & 14.48% & 1.08\n",
      "for 2022-07-30, MAE is:14.79 & sMAPE is:7.40% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :19.33 & 14.45% & 1.08\n",
      "for 2022-07-31, MAE is:43.14 & sMAPE is:22.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :19.45 & 14.49% & 1.08\n",
      "for 2022-08-01, MAE is:11.16 & sMAPE is:5.24% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :19.41 & 14.44% & 1.07\n",
      "for 2022-08-02, MAE is:51.37 & sMAPE is:24.36% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :19.56 & 14.49% & 1.07\n",
      "for 2022-08-03, MAE is:38.17 & sMAPE is:17.35% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :19.64 & 14.50% & 1.07\n",
      "for 2022-08-04, MAE is:10.91 & sMAPE is:4.70% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :19.60 & 14.46% & 1.07\n",
      "for 2022-08-05, MAE is:12.34 & sMAPE is:5.46% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :19.57 & 14.42% & 1.06\n",
      "for 2022-08-06, MAE is:36.75 & sMAPE is:18.76% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :19.65 & 14.44% & 1.07\n",
      "for 2022-08-07, MAE is:30.38 & sMAPE is:15.15% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :19.70 & 14.44% & 1.06\n",
      "for 2022-08-08, MAE is:38.71 & sMAPE is:14.88% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :19.78 & 14.44% & 1.06\n",
      "for 2022-08-09, MAE is:25.87 & sMAPE is:10.23% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :19.81 & 14.42% & 1.06\n",
      "for 2022-08-10, MAE is:14.08 & sMAPE is:5.49% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :19.79 & 14.38% & 1.06\n",
      "for 2022-08-11, MAE is:32.88 & sMAPE is:13.65% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :19.84 & 14.38% & 1.06\n",
      "for 2022-08-12, MAE is:52.26 & sMAPE is:20.02% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :19.99 & 14.40% & 1.06\n",
      "for 2022-08-13, MAE is:14.08 & sMAPE is:5.63% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :19.96 & 14.36% & 1.06\n",
      "for 2022-08-14, MAE is:26.17 & sMAPE is:10.67% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.99 & 14.35% & 1.06\n",
      "for 2022-08-15, MAE is:36.30 & sMAPE is:14.02% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :20.06 & 14.35% & 1.06\n",
      "for 2022-08-16, MAE is:22.23 & sMAPE is:8.37% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :20.07 & 14.32% & 1.06\n",
      "for 2022-08-17, MAE is:36.32 & sMAPE is:13.32% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :20.14 & 14.32% & 1.06\n",
      "for 2022-08-18, MAE is:33.26 & sMAPE is:10.95% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :20.20 & 14.30% & 1.06\n",
      "for 2022-08-19, MAE is:85.05 & sMAPE is:25.31% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :20.48 & 14.35% & 1.06\n",
      "for 2022-08-20, MAE is:29.41 & sMAPE is:8.64% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :20.52 & 14.32% & 1.06\n",
      "for 2022-08-21, MAE is:51.29 & sMAPE is:17.83% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :20.65 & 14.34% & 1.06\n",
      "for 2022-08-22, MAE is:67.92 & sMAPE is:18.93% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :20.85 & 14.36% & 1.05\n",
      "for 2022-08-23, MAE is:93.07 & sMAPE is:23.75% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :21.16 & 14.40% & 1.05\n",
      "for 2022-08-24, MAE is:93.83 & sMAPE is:23.19% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :21.47 & 14.44% & 1.05\n",
      "for 2022-08-25, MAE is:66.60 & sMAPE is:15.36% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :21.66 & 14.44% & 1.05\n",
      "for 2022-08-26, MAE is:63.18 & sMAPE is:14.11% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :21.83 & 14.44% & 1.05\n",
      "for 2022-08-27, MAE is:53.28 & sMAPE is:11.05% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :21.96 & 14.42% & 1.04\n",
      "for 2022-08-28, MAE is:65.46 & sMAPE is:14.10% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :22.15 & 14.42% & 1.04\n",
      "for 2022-08-29, MAE is:103.13 & sMAPE is:18.87% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :22.48 & 14.44% & 1.04\n",
      "for 2022-08-30, MAE is:143.74 & sMAPE is:24.27% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :22.98 & 14.48% & 1.04\n",
      "for 2022-08-31, MAE is:45.02 & sMAPE is:7.53% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :23.07 & 14.45% & 1.03\n",
      "for 2022-09-01, MAE is:50.06 & sMAPE is:8.62% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :23.18 & 14.43% & 1.03\n",
      "for 2022-09-02, MAE is:138.63 & sMAPE is:29.73% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :23.66 & 14.49% & 1.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-03, MAE is:56.96 & sMAPE is:15.80% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :23.79 & 14.50% & 1.03\n",
      "for 2022-09-04, MAE is:86.14 & sMAPE is:28.31% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :24.04 & 14.55% & 1.03\n",
      "for 2022-09-05, MAE is:93.93 & sMAPE is:25.20% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :24.33 & 14.60% & 1.03\n",
      "for 2022-09-06, MAE is:90.06 & sMAPE is:22.70% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :24.59 & 14.63% & 1.02\n",
      "for 2022-09-07, MAE is:48.07 & sMAPE is:10.83% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :24.68 & 14.61% & 1.02\n",
      "for 2022-09-08, MAE is:32.10 & sMAPE is:7.50% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :24.71 & 14.59% & 1.02\n",
      "for 2022-09-09, MAE is:65.84 & sMAPE is:19.32% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :24.88 & 14.60% & 1.02\n",
      "for 2022-09-10, MAE is:98.40 & sMAPE is:27.15% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :25.17 & 14.65% & 1.02\n",
      "for 2022-09-11, MAE is:69.59 & sMAPE is:18.60% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :25.34 & 14.67% & 1.02\n",
      "for 2022-09-12, MAE is:43.43 & sMAPE is:10.66% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :25.41 & 14.65% & 1.02\n",
      "for 2022-09-13, MAE is:47.35 & sMAPE is:12.29% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :25.50 & 14.64% & 1.01\n",
      "for 2022-09-14, MAE is:42.93 & sMAPE is:10.37% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :25.57 & 14.63% & 1.01\n",
      "for 2022-09-15, MAE is:45.67 & sMAPE is:12.81% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :25.64 & 14.62% & 1.01\n",
      "for 2022-09-16, MAE is:80.91 & sMAPE is:27.18% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :25.86 & 14.67% & 1.01\n",
      "for 2022-09-17, MAE is:76.94 & sMAPE is:33.68% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :26.05 & 14.74% & 1.01\n",
      "for 2022-09-18, MAE is:143.33 & sMAPE is:94.77% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 15.05% & 1.01\n",
      "for 2022-09-19, MAE is:143.59 & sMAPE is:61.72% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :26.95 & 15.23% & 1.01\n",
      "for 2022-09-20, MAE is:122.76 & sMAPE is:38.63% & rMAE is:4.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.31 & 15.32% & 1.02\n",
      "for 2022-09-21, MAE is:43.54 & sMAPE is:11.37% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :27.38 & 15.30% & 1.02\n",
      "for 2022-09-22, MAE is:36.34 & sMAPE is:9.86% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :27.41 & 15.28% & 1.02\n",
      "for 2022-09-23, MAE is:29.21 & sMAPE is:8.07% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :27.42 & 15.25% & 1.02\n",
      "for 2022-09-24, MAE is:15.98 & sMAPE is:4.73% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :27.37 & 15.21% & 1.02\n",
      "for 2022-09-25, MAE is:30.15 & sMAPE is:10.57% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :27.38 & 15.20% & 1.01\n",
      "for 2022-09-26, MAE is:51.83 & sMAPE is:22.80% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :27.47 & 15.22% & 1.01\n",
      "for 2022-09-27, MAE is:53.25 & sMAPE is:19.44% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 15.24% & 1.01\n",
      "for 2022-09-28, MAE is:19.54 & sMAPE is:6.73% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :27.54 & 15.21% & 1.01\n",
      "for 2022-09-29, MAE is:28.70 & sMAPE is:9.07% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.54 & 15.19% & 1.01\n",
      "for 2022-09-30, MAE is:60.86 & sMAPE is:22.75% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.67 & 15.21% & 1.01\n",
      "for 2022-10-01, MAE is:164.75 & sMAPE is:105.60% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 15.54% & 1.01\n",
      "for 2022-10-02, MAE is:77.47 & sMAPE is:50.87% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :28.35 & 15.67% & 1.00\n",
      "for 2022-10-03, MAE is:72.47 & sMAPE is:34.02% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :28.51 & 15.74% & 1.01\n",
      "for 2022-10-04, MAE is:57.38 & sMAPE is:27.63% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :28.61 & 15.78% & 1.01\n",
      "for 2022-10-05, MAE is:126.27 & sMAPE is:120.21% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :28.96 & 16.16% & 1.01\n",
      "for 2022-10-06, MAE is:52.15 & sMAPE is:120.00% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :29.04 & 16.53% & 1.00\n",
      "for 2022-10-07, MAE is:18.23 & sMAPE is:73.78% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :29.01 & 16.73% & 1.00\n",
      "for 2022-10-08, MAE is:14.69 & sMAPE is:33.87% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :28.96 & 16.80% & 1.00\n",
      "for 2022-10-09, MAE is:30.81 & sMAPE is:40.10% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :28.96 & 16.88% & 0.99\n",
      "for 2022-10-10, MAE is:35.09 & sMAPE is:29.41% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :28.98 & 16.92% & 0.99\n",
      "for 2022-10-11, MAE is:37.90 & sMAPE is:24.34% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :29.01 & 16.95% & 0.99\n",
      "for 2022-10-12, MAE is:43.37 & sMAPE is:26.44% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :29.07 & 16.98% & 0.99\n",
      "for 2022-10-13, MAE is:88.64 & sMAPE is:48.41% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :29.27 & 17.09% & 0.99\n",
      "for 2022-10-14, MAE is:44.03 & sMAPE is:22.97% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.33 & 17.11% & 0.98\n",
      "for 2022-10-15, MAE is:17.38 & sMAPE is:11.21% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :29.28 & 17.09% & 0.98\n",
      "for 2022-10-16, MAE is:30.67 & sMAPE is:28.26% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :29.29 & 17.13% & 0.98\n",
      "for 2022-10-17, MAE is:23.21 & sMAPE is:16.60% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :29.27 & 17.13% & 0.98\n",
      "for 2022-10-18, MAE is:20.59 & sMAPE is:12.72% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :29.24 & 17.11% & 0.98\n",
      "for 2022-10-19, MAE is:15.57 & sMAPE is:10.19% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :29.19 & 17.09% & 0.98\n",
      "for 2022-10-20, MAE is:20.70 & sMAPE is:16.37% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.16 & 17.09% & 0.98\n",
      "for 2022-10-21, MAE is:14.63 & sMAPE is:9.87% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :29.11 & 17.06% & 0.98\n",
      "for 2022-10-22, MAE is:11.21 & sMAPE is:8.04% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :29.05 & 17.03% & 0.98\n",
      "for 2022-10-23, MAE is:29.35 & sMAPE is:26.73% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :29.05 & 17.06% & 0.97\n",
      "for 2022-10-24, MAE is:22.37 & sMAPE is:28.82% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :29.03 & 17.10% & 0.97\n",
      "for 2022-10-25, MAE is:27.15 & sMAPE is:26.43% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :29.02 & 17.14% & 0.97\n",
      "for 2022-10-26, MAE is:21.62 & sMAPE is:18.80% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :29.00 & 17.14% & 0.97\n",
      "for 2022-10-27, MAE is:7.95 & sMAPE is:7.29% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :28.93 & 17.11% & 0.97\n",
      "for 2022-10-28, MAE is:10.16 & sMAPE is:10.02% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :28.87 & 17.08% & 0.97\n",
      "for 2022-10-29, MAE is:8.38 & sMAPE is:8.08% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :28.80 & 17.05% & 0.96\n",
      "for 2022-10-30, MAE is:24.51 & sMAPE is:22.37% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :28.78 & 17.07% & 0.96\n",
      "for 2022-10-31, MAE is:32.60 & sMAPE is:25.14% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :28.80 & 17.10% & 0.96\n",
      "for 2022-11-01, MAE is:37.13 & sMAPE is:45.95% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :28.82 & 17.19% & 0.96\n",
      "for 2022-11-02, MAE is:24.79 & sMAPE is:40.41% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :28.81 & 17.27% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-03, MAE is:21.01 & sMAPE is:27.25% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :28.79 & 17.30% & 0.96\n",
      "for 2022-11-04, MAE is:12.73 & sMAPE is:18.86% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :28.73 & 17.31% & 0.96\n",
      "for 2022-11-05, MAE is:18.67 & sMAPE is:36.10% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :28.70 & 17.37% & 0.96\n",
      "for 2022-11-06, MAE is:10.38 & sMAPE is:29.37% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :28.64 & 17.41% & 0.95\n",
      "for 2022-11-07, MAE is:13.49 & sMAPE is:41.33% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :28.59 & 17.48% & 0.95\n",
      "for 2022-11-08, MAE is:15.61 & sMAPE is:32.78% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 17.53% & 0.95\n",
      "for 2022-11-09, MAE is:9.85 & sMAPE is:26.35% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :28.49 & 17.56% & 0.95\n",
      "for 2022-11-10, MAE is:17.15 & sMAPE is:53.01% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :28.46 & 17.67% & 0.95\n",
      "for 2022-11-11, MAE is:19.53 & sMAPE is:169.60% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :28.43 & 18.16% & 0.94\n",
      "for 2022-11-12, MAE is:3.73 & sMAPE is:113.82% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :28.35 & 18.46% & 0.94\n",
      "for 2022-11-13, MAE is:19.85 & sMAPE is:116.98% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :28.32 & 18.77% & 0.94\n",
      "for 2022-11-14, MAE is:31.67 & sMAPE is:73.11% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :28.33 & 18.94% & 0.95\n",
      "for 2022-11-15, MAE is:26.70 & sMAPE is:56.84% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :28.33 & 19.06% & 0.95\n",
      "for 2022-11-16, MAE is:7.16 & sMAPE is:26.05% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.26 & 19.08% & 0.95\n",
      "for 2022-11-17, MAE is:31.49 & sMAPE is:88.57% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :28.27 & 19.30% & 0.95\n",
      "for 2022-11-18, MAE is:80.84 & sMAPE is:117.01% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :28.44 & 19.60% & 0.95\n",
      "for 2022-11-19, MAE is:68.49 & sMAPE is:53.27% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :28.56 & 19.71% & 0.95\n",
      "for 2022-11-20, MAE is:15.32 & sMAPE is:10.29% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :28.52 & 19.68% & 0.94\n",
      "for 2022-11-21, MAE is:39.37 & sMAPE is:19.47% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 19.68% & 0.94\n",
      "for 2022-11-22, MAE is:28.45 & sMAPE is:18.43% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 19.67% & 0.94\n",
      "for 2022-11-23, MAE is:19.83 & sMAPE is:14.20% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :28.52 & 19.65% & 0.94\n",
      "for 2022-11-24, MAE is:36.73 & sMAPE is:24.01% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :28.55 & 19.67% & 0.94\n",
      "for 2022-11-25, MAE is:36.51 & sMAPE is:20.34% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :28.57 & 19.67% & 0.93\n",
      "for 2022-11-26, MAE is:13.11 & sMAPE is:6.79% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :28.53 & 19.63% & 0.93\n",
      "for 2022-11-27, MAE is:32.19 & sMAPE is:21.41% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :28.54 & 19.64% & 0.94\n",
      "for 2022-11-28, MAE is:55.46 & sMAPE is:31.14% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :28.62 & 19.67% & 0.94\n",
      "for 2022-11-29, MAE is:176.18 & sMAPE is:62.84% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :29.06 & 19.80% & 0.94\n",
      "for 2022-11-30, MAE is:96.93 & sMAPE is:29.76% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :29.27 & 19.83% & 0.94\n",
      "for 2022-12-01, MAE is:57.06 & sMAPE is:17.07% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :29.35 & 19.82% & 0.94\n",
      "for 2022-12-02, MAE is:31.47 & sMAPE is:9.75% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :29.35 & 19.79% & 0.93\n",
      "for 2022-12-03, MAE is:23.62 & sMAPE is:9.01% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 19.76% & 0.93\n",
      "for 2022-12-04, MAE is:29.76 & sMAPE is:11.17% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :29.34 & 19.74% & 0.93\n",
      "for 2022-12-05, MAE is:21.82 & sMAPE is:8.23% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :29.32 & 19.70% & 0.93\n",
      "for 2022-12-06, MAE is:45.70 & sMAPE is:13.37% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :29.37 & 19.68% & 0.93\n",
      "for 2022-12-07, MAE is:41.40 & sMAPE is:12.94% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :29.40 & 19.66% & 0.93\n",
      "for 2022-12-08, MAE is:37.11 & sMAPE is:9.62% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :29.42 & 19.63% & 0.93\n",
      "for 2022-12-09, MAE is:43.75 & sMAPE is:11.14% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :29.46 & 19.61% & 0.93\n",
      "for 2022-12-10, MAE is:27.37 & sMAPE is:7.69% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :29.46 & 19.57% & 0.93\n",
      "for 2022-12-11, MAE is:24.26 & sMAPE is:7.23% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :29.44 & 19.54% & 0.92\n",
      "for 2022-12-12, MAE is:116.22 & sMAPE is:28.73% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :29.69 & 19.56% & 0.92\n",
      "for 2022-12-13, MAE is:107.13 & sMAPE is:25.03% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 19.58% & 0.92\n",
      "for 2022-12-14, MAE is:85.92 & sMAPE is:19.94% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :30.08 & 19.58% & 0.92\n",
      "for 2022-12-15, MAE is:45.11 & sMAPE is:12.45% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :30.12 & 19.56% & 0.93\n",
      "for 2022-12-16, MAE is:70.33 & sMAPE is:17.66% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :30.24 & 19.56% & 0.93\n",
      "for 2022-12-17, MAE is:79.10 & sMAPE is:28.07% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :30.38 & 19.58% & 0.93\n",
      "for 2022-12-18, MAE is:35.88 & sMAPE is:17.49% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :30.39 & 19.57% & 0.93\n",
      "for 2022-12-19, MAE is:30.76 & sMAPE is:15.70% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :30.39 & 19.56% & 0.93\n",
      "for 2022-12-20, MAE is:32.28 & sMAPE is:18.13% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :30.40 & 19.56% & 0.93\n",
      "for 2022-12-21, MAE is:15.32 & sMAPE is:7.12% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :30.36 & 19.52% & 0.93\n",
      "for 2022-12-22, MAE is:20.04 & sMAPE is:10.87% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :30.33 & 19.50% & 0.92\n",
      "for 2022-12-23, MAE is:22.09 & sMAPE is:11.61% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :30.30 & 19.48% & 0.92\n",
      "for 2022-12-24, MAE is:27.63 & sMAPE is:19.41% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :30.30 & 19.48% & 0.92\n",
      "for 2022-12-25, MAE is:9.03 & sMAPE is:7.60% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :30.24 & 19.44% & 0.92\n",
      "for 2022-12-26, MAE is:25.83 & sMAPE is:24.35% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :30.22 & 19.46% & 0.91\n",
      "for 2022-12-27, MAE is:21.41 & sMAPE is:16.51% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :30.20 & 19.45% & 0.91\n",
      "for 2022-12-28, MAE is:12.21 & sMAPE is:10.99% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :30.15 & 19.43% & 0.91\n",
      "for 2022-12-29, MAE is:7.91 & sMAPE is:7.36% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :30.09 & 19.39% & 0.91\n",
      "for 2022-12-30, MAE is:11.00 & sMAPE is:10.85% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :30.04 & 19.37% & 0.91\n",
      "for 2022-12-31, MAE is:20.86 & sMAPE is:20.27% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :30.01 & 19.37% & 0.91\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:48:43,725]\u001b[0m A new study created in RDB with name: NO_5_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:08,375]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 29.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 64.66 | sMAPE for Validation Set is: 35.23% | rMAE for Validation Set is: 1.19\n",
      "MAE for Test Set is: 28.72 | sMAPE for Test Set is: 34.48% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:49:08,389]\u001b[0m Trial 0 finished with value: 64.65907179893173 and parameters: {'n_hidden': 3, 'learning_rate': 0.044357193930687315, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0077572019984476276, 'dropout_rate_Layer_2': 0.06325179261082746, 'dropout_rate_Layer_3': 0.26628442370310335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.6002561028444925e-05, 'l1_Layer_2': 0.0002057472554907449, 'l1_Layer_3': 0.08773421398068738, 'n_units_Layer_1': 105, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 0 with value: 64.65907179893173.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:09,120]\u001b[0m Trial 2 finished with value: 62.64289107988666 and parameters: {'n_hidden': 3, 'learning_rate': 0.006817859795796581, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3064352516277538, 'dropout_rate_Layer_2': 0.12797990677097287, 'dropout_rate_Layer_3': 0.27692790902575426, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018526019345330251, 'l1_Layer_2': 0.0338281611145758, 'l1_Layer_3': 0.0001391361413985461, 'n_units_Layer_1': 145, 'n_units_Layer_2': 205, 'n_units_Layer_3': 285}. Best is trial 2 with value: 62.64289107988666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.64 | sMAPE for Validation Set is: 32.57% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 15.35 | sMAPE for Test Set is: 18.91% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:49:15,795]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:23,855]\u001b[0m Trial 3 finished with value: 78.93558983357036 and parameters: {'n_hidden': 3, 'learning_rate': 0.002338307380180837, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29732658136294116, 'dropout_rate_Layer_2': 0.39044114347369563, 'dropout_rate_Layer_3': 0.33652375235524984, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.019018979220087707, 'l1_Layer_2': 0.02266712110970171, 'l1_Layer_3': 0.040210809468203663, 'n_units_Layer_1': 85, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300}. Best is trial 2 with value: 62.64289107988666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.94 | sMAPE for Validation Set is: 42.88% | rMAE for Validation Set is: 1.45\n",
      "MAE for Test Set is: 13.82 | sMAPE for Test Set is: 17.72% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:49:26,702]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:30,536]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:32,384]\u001b[0m Trial 5 finished with value: 66.6187425030421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005593281957515774, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22931791260366388, 'dropout_rate_Layer_2': 0.06882394297798103, 'dropout_rate_Layer_3': 0.2725356392746251, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00030952914540088817, 'l1_Layer_2': 0.02683274639552188, 'l1_Layer_3': 7.720537060415825e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 275, 'n_units_Layer_3': 300}. Best is trial 2 with value: 62.64289107988666.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.62 | sMAPE for Validation Set is: 35.25% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 22.30 | sMAPE for Test Set is: 25.06% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:49:33,871]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:36,162]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:39,452]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:39,861]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:45,497]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:48,627]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:50,144]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:52,791]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:55,485]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:49:58,373]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.97 | sMAPE for Validation Set is: 38.14% | rMAE for Validation Set is: 1.31\n",
      "MAE for Test Set is: 17.34 | sMAPE for Test Set is: 22.16% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:49:58,697]\u001b[0m Trial 4 finished with value: 70.96863243869784 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007981549744621593, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18791462583864205, 'dropout_rate_Layer_2': 0.3396031521440395, 'dropout_rate_Layer_3': 0.1340434929441052, 'dropout_rate_Layer_4': 0.1291286321514118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00040320831668911293, 'l1_Layer_2': 0.0010839202009697625, 'l1_Layer_3': 0.0029703490895578873, 'l1_Layer_4': 0.00021684564536018368, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195, 'n_units_Layer_4': 180}. Best is trial 2 with value: 62.64289107988666.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:01,411]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.34 | sMAPE for Validation Set is: 25.87% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:50:02,664]\u001b[0m Trial 7 finished with value: 50.340178219592765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016014823321313792, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38509698245475055, 'dropout_rate_Layer_2': 0.0020308691439075766, 'dropout_rate_Layer_3': 0.37972366970301, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010268297144866186, 'l1_Layer_2': 5.040575018823518e-05, 'l1_Layer_3': 0.0002852004149395672, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 7 with value: 50.340178219592765.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:06,075]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:07,324]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:10,051]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:14,265]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:15,672]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:16,962]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:19,971]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:22,807]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:25,123]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:25,379]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:30,278]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:33,315]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:36,151]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:38,041]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:44,347]\u001b[0m Trial 26 finished with value: 66.7151290145533 and parameters: {'n_hidden': 3, 'learning_rate': 0.002311314501341769, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3003916093129777, 'dropout_rate_Layer_2': 0.38492134442700165, 'dropout_rate_Layer_3': 0.00771822870085468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011995035332089557, 'l1_Layer_2': 0.0685435627155251, 'l1_Layer_3': 3.1473492129364924e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 7 with value: 50.340178219592765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 66.72 | sMAPE for Validation Set is: 34.98% | rMAE for Validation Set is: 1.23\n",
      "MAE for Test Set is: 16.25 | sMAPE for Test Set is: 20.38% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:50:46,507]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:50,130]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:52,651]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:56,222]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:50:56,438]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:00,669]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:02,325]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:03,439]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:03,853]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:05,556]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:10,440]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:12,239]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:12,397]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:14,253]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:17,970]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:19,978]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:21,750]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:22,227]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:26,316]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:27,833]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:30,610]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:32,325]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:36,379]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:39,664]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:42,547]\u001b[0m Trial 56 finished with value: 27.224861220614212 and parameters: {'n_hidden': 3, 'learning_rate': 0.004636126881492863, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19284933972111634, 'dropout_rate_Layer_2': 0.07683794270130875, 'dropout_rate_Layer_3': 0.3213599753639187, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004491367962010273, 'l1_Layer_2': 0.0009471925929126546, 'l1_Layer_3': 4.080123226275149e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 56 with value: 27.224861220614212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.22 | sMAPE for Validation Set is: 18.13% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.53 | sMAPE for Test Set is: 18.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:51:46,013]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:50,895]\u001b[0m Trial 63 finished with value: 56.89015443032014 and parameters: {'n_hidden': 3, 'learning_rate': 0.002719833596413882, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.057004933797905166, 'dropout_rate_Layer_2': 0.2660595448196271, 'dropout_rate_Layer_3': 0.3629199882226507, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.993866749390246e-05, 'l1_Layer_2': 0.002655083557072631, 'l1_Layer_3': 0.0005748808355606827, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 56 with value: 27.224861220614212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.89 | sMAPE for Validation Set is: 30.52% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 17.46 | sMAPE for Test Set is: 21.40% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:51:54,501]\u001b[0m Trial 64 finished with value: 55.58283450000556 and parameters: {'n_hidden': 3, 'learning_rate': 0.00264935528676909, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05275386350391208, 'dropout_rate_Layer_2': 0.26049036760764105, 'dropout_rate_Layer_3': 0.35966794175868805, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.906233248162829e-05, 'l1_Layer_2': 0.00013848282158959266, 'l1_Layer_3': 0.0005209281261324964, 'n_units_Layer_1': 175, 'n_units_Layer_2': 235, 'n_units_Layer_3': 235}. Best is trial 56 with value: 27.224861220614212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.58 | sMAPE for Validation Set is: 30.35% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 16.78 | sMAPE for Test Set is: 20.69% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:51:56,338]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:51:59,239]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.11 | sMAPE for Validation Set is: 25.02% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 17.88 | sMAPE for Test Set is: 21.01% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:52:02,096]\u001b[0m Trial 65 finished with value: 54.20145359954798 and parameters: {'n_hidden': 3, 'learning_rate': 0.002140384420558167, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03571663271541145, 'dropout_rate_Layer_2': 0.1973270265571408, 'dropout_rate_Layer_3': 0.3630256017202248, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.318828215783552e-05, 'l1_Layer_2': 0.00012414372479362435, 'l1_Layer_3': 0.000615716325875254, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 56 with value: 27.224861220614212.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.20 | sMAPE for Validation Set is: 29.24% | rMAE for Validation Set is: 1.00\n",
      "MAE for Test Set is: 16.38 | sMAPE for Test Set is: 20.33% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:52:02,378]\u001b[0m Trial 55 finished with value: 48.11089802548205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005888747556501075, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3226674583980768, 'dropout_rate_Layer_2': 0.009610466583049947, 'dropout_rate_Layer_3': 0.39532468268927556, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004226930399830573, 'l1_Layer_2': 0.0008637125798290286, 'l1_Layer_3': 0.0024262368097345923, 'n_units_Layer_1': 300, 'n_units_Layer_2': 255, 'n_units_Layer_3': 300}. Best is trial 56 with value: 27.224861220614212.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:03,067]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:04,342]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:06,488]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:09,461]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:11,616]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:16,539]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:22,499]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:31,249]\u001b[0m Trial 76 finished with value: 26.18127464060899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0059959896246384375, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1769135952946056, 'dropout_rate_Layer_2': 0.1928433268363351, 'dropout_rate_Layer_3': 0.37731284965803624, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.803996131814616e-05, 'l1_Layer_2': 0.00013662259476732115, 'l1_Layer_3': 0.0005658950333406616, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 76 with value: 26.18127464060899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.18 | sMAPE for Validation Set is: 17.48% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.31 | sMAPE for Test Set is: 16.68% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:52:37,727]\u001b[0m Trial 75 finished with value: 26.27321108628918 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015039973863821127, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3208610197006152, 'dropout_rate_Layer_2': 0.049690014128336575, 'dropout_rate_Layer_3': 0.37334044916397474, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02147203207376181, 'l1_Layer_2': 0.00033433650396692794, 'l1_Layer_3': 0.0021009033008598304, 'n_units_Layer_1': 120, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 76 with value: 26.18127464060899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.27 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.05 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:52:40,598]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:42,935]\u001b[0m Trial 78 finished with value: 72.41365013241546 and parameters: {'n_hidden': 3, 'learning_rate': 0.020140901926294242, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3491285607042399, 'dropout_rate_Layer_2': 0.27609496588672816, 'dropout_rate_Layer_3': 0.017437750498958016, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002429576883528678, 'l1_Layer_2': 5.429108810116714e-05, 'l1_Layer_3': 0.0006234821782090925, 'n_units_Layer_1': 105, 'n_units_Layer_2': 270, 'n_units_Layer_3': 215}. Best is trial 76 with value: 26.18127464060899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.41 | sMAPE for Validation Set is: 39.45% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 70.03 | sMAPE for Test Set is: 62.36% | rMAE for Test Set is: 3.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:52:49,391]\u001b[0m Trial 79 finished with value: 26.77558942966178 and parameters: {'n_hidden': 3, 'learning_rate': 0.006224641551744953, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0846970900710699, 'dropout_rate_Layer_2': 0.1473940119421839, 'dropout_rate_Layer_3': 0.37596391902168697, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9186719718622365e-05, 'l1_Layer_2': 0.00013400150005433802, 'l1_Layer_3': 0.0005205628154699308, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 76 with value: 26.18127464060899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.78 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 16.49% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:52:57,945]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:52:59,826]\u001b[0m Trial 82 finished with value: 27.052081840941806 and parameters: {'n_hidden': 3, 'learning_rate': 0.006242504938235546, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20016299202199536, 'dropout_rate_Layer_2': 0.28912402911120777, 'dropout_rate_Layer_3': 0.3760116707838539, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.428811350997839e-05, 'l1_Layer_2': 0.0001514621111018466, 'l1_Layer_3': 0.001051967169340291, 'n_units_Layer_1': 185, 'n_units_Layer_2': 250, 'n_units_Layer_3': 255}. Best is trial 76 with value: 26.18127464060899.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.05 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 16.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:06,442]\u001b[0m Trial 80 finished with value: 25.890126029819086 and parameters: {'n_hidden': 3, 'learning_rate': 0.00429978926130098, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31752122990940423, 'dropout_rate_Layer_2': 0.05907914825820329, 'dropout_rate_Layer_3': 0.30669402270913776, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026257305691577346, 'l1_Layer_2': 0.00033991817925807234, 'l1_Layer_3': 0.0017764015803240416, 'n_units_Layer_1': 170, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.89 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.34 | sMAPE for Test Set is: 17.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:10,732]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:53:13,907]\u001b[0m Trial 83 finished with value: 26.009565983233728 and parameters: {'n_hidden': 3, 'learning_rate': 0.006019151238272175, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07934455932535982, 'dropout_rate_Layer_2': 0.15113937477486886, 'dropout_rate_Layer_3': 0.3767717173208338, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8424506333399587e-05, 'l1_Layer_2': 0.00010427441986657235, 'l1_Layer_3': 0.0005754591777235576, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 260}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.01 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.01 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:19,486]\u001b[0m Trial 84 finished with value: 26.462537123914984 and parameters: {'n_hidden': 3, 'learning_rate': 0.006166849961624615, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08558688973162018, 'dropout_rate_Layer_2': 0.18488185479151945, 'dropout_rate_Layer_3': 0.37920234847326123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0591582120759744e-05, 'l1_Layer_2': 0.00015326018679550203, 'l1_Layer_3': 0.0006208862930641055, 'n_units_Layer_1': 185, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.46 | sMAPE for Validation Set is: 17.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.56 | sMAPE for Test Set is: 16.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:22,086]\u001b[0m Trial 86 finished with value: 26.947835260936007 and parameters: {'n_hidden': 3, 'learning_rate': 0.006164434326935402, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20945154438767943, 'dropout_rate_Layer_2': 0.19229903252814234, 'dropout_rate_Layer_3': 0.3828528981917945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.14805148468458e-05, 'l1_Layer_2': 0.0001287126686385546, 'l1_Layer_3': 0.0011284018827417178, 'n_units_Layer_1': 210, 'n_units_Layer_2': 285, 'n_units_Layer_3': 250}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.95 | sMAPE for Validation Set is: 17.83% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 16.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:27,968]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:53:30,772]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:53:30,831]\u001b[0m Trial 88 finished with value: 27.31804213037704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0053720348621475985, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1905269115489269, 'dropout_rate_Layer_2': 0.1551897621111126, 'dropout_rate_Layer_3': 0.37980277604682366, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6885791886698028e-05, 'l1_Layer_2': 0.00010357949503991397, 'l1_Layer_3': 0.0010626943203254544, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 255}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.32 | sMAPE for Validation Set is: 17.79% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.40 | sMAPE for Test Set is: 16.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:38,608]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:53:50,574]\u001b[0m Trial 92 finished with value: 26.25324283372757 and parameters: {'n_hidden': 3, 'learning_rate': 0.003688542971284213, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30594328747406835, 'dropout_rate_Layer_2': 0.05779289007413817, 'dropout_rate_Layer_3': 0.30555225166895267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09070385596417486, 'l1_Layer_2': 0.000255713510847083, 'l1_Layer_3': 0.0014339408221377894, 'n_units_Layer_1': 170, 'n_units_Layer_2': 235, 'n_units_Layer_3': 135}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.25 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.46 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:53:54,788]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:53:59,482]\u001b[0m Trial 94 finished with value: 26.44979617266571 and parameters: {'n_hidden': 3, 'learning_rate': 0.003967058882426774, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3091279498894304, 'dropout_rate_Layer_2': 0.05311554737479417, 'dropout_rate_Layer_3': 0.3003084295153655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025400763301546288, 'l1_Layer_2': 0.00031722332353382445, 'l1_Layer_3': 0.0012885674076264049, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.45 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 16.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:54:04,947]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:54:26,473]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:54:35,283]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:54:38,815]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:00,393]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:08,049]\u001b[0m Trial 101 finished with value: 25.99775191669691 and parameters: {'n_hidden': 3, 'learning_rate': 0.005032789195834377, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27010705689007924, 'dropout_rate_Layer_2': 0.18782839887920103, 'dropout_rate_Layer_3': 0.38022248730800046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.59161361206769e-05, 'l1_Layer_2': 0.0006506565460496558, 'l1_Layer_3': 0.0008378214678932515, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 210}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.00 | sMAPE for Validation Set is: 17.40% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.89 | sMAPE for Test Set is: 17.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:55:22,757]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:23,696]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:31,246]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:33,890]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:43,286]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:55:56,982]\u001b[0m Trial 108 finished with value: 27.07379370105777 and parameters: {'n_hidden': 3, 'learning_rate': 0.007385332103054715, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2808081750708334, 'dropout_rate_Layer_2': 0.21694943702941502, 'dropout_rate_Layer_3': 0.3842143537372854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9749020065767017e-05, 'l1_Layer_2': 0.0006574506453743497, 'l1_Layer_3': 0.0005046537578514556, 'n_units_Layer_1': 160, 'n_units_Layer_2': 210, 'n_units_Layer_3': 295}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.07 | sMAPE for Validation Set is: 17.75% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.60 | sMAPE for Test Set is: 17.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:56:00,705]\u001b[0m Trial 104 finished with value: 25.96638682483184 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023346298540372753, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3541554234838547, 'dropout_rate_Layer_2': 0.1564504169531716, 'dropout_rate_Layer_3': 0.3057429250909227, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.050793115655714205, 'l1_Layer_2': 0.00042960068170204977, 'l1_Layer_3': 0.003029152837370106, 'n_units_Layer_1': 120, 'n_units_Layer_2': 235, 'n_units_Layer_3': 185}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.97 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.16 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:56:34,691]\u001b[0m Trial 105 finished with value: 57.01278613509191 and parameters: {'n_hidden': 3, 'learning_rate': 0.012003230445084317, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2340620829550445, 'dropout_rate_Layer_2': 0.1207099410041668, 'dropout_rate_Layer_3': 0.21991726433683578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011287969636205429, 'l1_Layer_2': 0.005240870911241972, 'l1_Layer_3': 0.0002367785631876497, 'n_units_Layer_1': 55, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.01 | sMAPE for Validation Set is: 29.10% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 14.77 | sMAPE for Test Set is: 18.51% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:56:37,854]\u001b[0m Trial 109 finished with value: 62.27773940586718 and parameters: {'n_hidden': 3, 'learning_rate': 0.01325020323691275, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23023415712253492, 'dropout_rate_Layer_2': 0.12989879396486664, 'dropout_rate_Layer_3': 0.2158908538823453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0052217070508416685, 'l1_Layer_2': 0.006828530468826169, 'l1_Layer_3': 0.00014941186717552508, 'n_units_Layer_1': 255, 'n_units_Layer_2': 120, 'n_units_Layer_3': 220}. Best is trial 80 with value: 25.890126029819086.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.28 | sMAPE for Validation Set is: 32.70% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 19.95 | sMAPE for Test Set is: 24.32% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:56:40,079]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:41,637]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:45,096]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:45,552]\u001b[0m Trial 110 finished with value: 25.67040044097705 and parameters: {'n_hidden': 3, 'learning_rate': 0.00216635359975418, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3572185310329776, 'dropout_rate_Layer_2': 0.1690134548655608, 'dropout_rate_Layer_3': 0.2541243953605935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05906901803113385, 'l1_Layer_2': 7.973724239428783e-05, 'l1_Layer_3': 0.011506611666001247, 'n_units_Layer_1': 80, 'n_units_Layer_2': 50, 'n_units_Layer_3': 200}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.67 | sMAPE for Validation Set is: 16.82% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 15.91% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:56:50,313]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:50,586]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:55,188]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:55,333]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:56:59,632]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:00,531]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:04,212]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:07,194]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:07,929]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:11,580]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:11,992]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:12,658]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:16,847]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:18,745]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:23,907]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:24,088]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:27,811]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:32,577]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:48,899]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:51,944]\u001b[0m Trial 93 finished with value: 70.27796474653248 and parameters: {'n_hidden': 4, 'learning_rate': 0.012026280005628774, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16470459655986647, 'dropout_rate_Layer_2': 0.21968674332493715, 'dropout_rate_Layer_3': 0.18056987782040806, 'dropout_rate_Layer_4': 0.3877136929364469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 1.3282392267453286e-05, 'l1_Layer_2': 0.0012017292046564677, 'l1_Layer_3': 0.08836738843402137, 'l1_Layer_4': 2.0662822784471763e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 300}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 70.28 | sMAPE for Validation Set is: 37.50% | rMAE for Validation Set is: 1.29\n",
      "MAE for Test Set is: 28.43 | sMAPE for Test Set is: 29.79% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:57:52,157]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:56,617]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:57:56,710]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:05,794]\u001b[0m Trial 129 finished with value: 58.445547601635006 and parameters: {'n_hidden': 3, 'learning_rate': 0.00938054297897057, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.257461378466492, 'dropout_rate_Layer_2': 0.14277183221498785, 'dropout_rate_Layer_3': 0.21741854876151753, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014132428405244408, 'l1_Layer_2': 0.0062782824114812575, 'l1_Layer_3': 0.00017129361274556746, 'n_units_Layer_1': 250, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.45 | sMAPE for Validation Set is: 30.03% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 14.48 | sMAPE for Test Set is: 18.45% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:58:07,524]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:09,721]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:20,380]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:27,714]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:28,177]\u001b[0m Trial 134 finished with value: 57.546726172281154 and parameters: {'n_hidden': 3, 'learning_rate': 0.009913491777112014, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2543443414884635, 'dropout_rate_Layer_2': 0.13731850391055933, 'dropout_rate_Layer_3': 0.19870658458461204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015935381833641404, 'l1_Layer_2': 0.007006605986669227, 'l1_Layer_3': 0.00031909390041462513, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 230}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.55 | sMAPE for Validation Set is: 29.56% | rMAE for Validation Set is: 1.06\n",
      "MAE for Test Set is: 12.54 | sMAPE for Test Set is: 16.54% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:58:32,737]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:37,386]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:39,262]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:40,951]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:41,130]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:43,034]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:46,978]\u001b[0m Trial 143 finished with value: 27.43400350543152 and parameters: {'n_hidden': 3, 'learning_rate': 0.027002461118217642, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10233949953594604, 'dropout_rate_Layer_2': 0.0781602872549857, 'dropout_rate_Layer_3': 0.34859348331280404, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02077610933372038, 'l1_Layer_2': 0.014066395891122218, 'l1_Layer_3': 0.0006370805573350837, 'n_units_Layer_1': 235, 'n_units_Layer_2': 130, 'n_units_Layer_3': 295}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.43 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 14.23 | sMAPE for Test Set is: 18.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:58:48,711]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:58:51,837]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:02,696]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:06,354]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:08,958]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:11,962]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:20,300]\u001b[0m Trial 154 finished with value: 26.02798816191418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013714691103003046, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3685078833901221, 'dropout_rate_Layer_2': 0.03653347649939044, 'dropout_rate_Layer_3': 0.3647090295696831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06680884715525634, 'l1_Layer_2': 0.0003710942340543044, 'l1_Layer_3': 0.004751667874671583, 'n_units_Layer_1': 120, 'n_units_Layer_2': 235, 'n_units_Layer_3': 165}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.03 | sMAPE for Validation Set is: 17.04% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 16.44% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:59:27,163]\u001b[0m Trial 158 finished with value: 26.579315761174573 and parameters: {'n_hidden': 3, 'learning_rate': 0.002797380113835327, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3734844792691516, 'dropout_rate_Layer_2': 0.03817780249397435, 'dropout_rate_Layer_3': 0.22742490236030866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06621558533867963, 'l1_Layer_2': 0.0002894984696761764, 'l1_Layer_3': 0.00554850713661706, 'n_units_Layer_1': 125, 'n_units_Layer_2': 240, 'n_units_Layer_3': 160}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.58 | sMAPE for Validation Set is: 17.23% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 16.24% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:59:29,241]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:42,786]\u001b[0m Trial 151 finished with value: 58.136214715987165 and parameters: {'n_hidden': 3, 'learning_rate': 0.006100807742846778, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22588964854695498, 'dropout_rate_Layer_2': 0.16469042978197138, 'dropout_rate_Layer_3': 0.23408063928227868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.020104084793077834, 'l1_Layer_2': 0.0035320373721086616, 'l1_Layer_3': 8.8387389715092e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 125, 'n_units_Layer_3': 170}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 58.14 | sMAPE for Validation Set is: 30.06% | rMAE for Validation Set is: 1.07\n",
      "MAE for Test Set is: 16.45 | sMAPE for Test Set is: 20.27% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:59:45,476]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:47,199]\u001b[0m Trial 161 finished with value: 30.1027160509605 and parameters: {'n_hidden': 3, 'learning_rate': 0.023726658917581557, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1072821100635252, 'dropout_rate_Layer_2': 0.09658405571607132, 'dropout_rate_Layer_3': 0.33790467955691605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032228825667999757, 'l1_Layer_2': 0.018754341856360674, 'l1_Layer_3': 0.00042618672043557063, 'n_units_Layer_1': 220, 'n_units_Layer_2': 75, 'n_units_Layer_3': 295}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.10 | sMAPE for Validation Set is: 18.88% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 13.80 | sMAPE for Test Set is: 17.87% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:59:50,030]\u001b[0m Trial 160 finished with value: 26.361600080786257 and parameters: {'n_hidden': 3, 'learning_rate': 0.005532141558011623, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19198925697135905, 'dropout_rate_Layer_2': 0.15480058129270508, 'dropout_rate_Layer_3': 0.37732621478526385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.7081730062848924e-05, 'l1_Layer_2': 0.00010435023415764156, 'l1_Layer_3': 0.0009318766763385969, 'n_units_Layer_1': 215, 'n_units_Layer_2': 280, 'n_units_Layer_3': 240}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.36 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 16.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 06:59:53,172]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:56,765]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 06:59:59,556]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:04,045]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:04,726]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:08,707]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:08,752]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:09,042]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:14,932]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:15,212]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:15,243]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:20,726]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:20,980]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:25,179]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:25,830]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:25,997]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:29,928]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:31,940]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:34,291]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:36,423]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:38,483]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:40,483]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:42,514]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:44,649]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:46,828]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:49,847]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:50,075]\u001b[0m Trial 184 finished with value: 27.182929956901898 and parameters: {'n_hidden': 3, 'learning_rate': 0.02119539439366404, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0865009687532412, 'dropout_rate_Layer_2': 0.09963080878295905, 'dropout_rate_Layer_3': 0.3185951648516972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04670142462700816, 'l1_Layer_2': 0.0029521544725768386, 'l1_Layer_3': 0.001496731381508353, 'n_units_Layer_1': 270, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.18 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 16.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:00:55,609]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:57,328]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:00:59,299]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:01,067]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:02,816]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:04,622]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:12,902]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:19,266]\u001b[0m Trial 191 finished with value: 62.059610595171456 and parameters: {'n_hidden': 3, 'learning_rate': 0.003118153675398853, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39561803529815137, 'dropout_rate_Layer_2': 0.24823896335456663, 'dropout_rate_Layer_3': 0.028555956702400024, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015090859979172019, 'l1_Layer_2': 1.0560361032123167e-05, 'l1_Layer_3': 0.0001242239181245688, 'n_units_Layer_1': 135, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 62.06 | sMAPE for Validation Set is: 34.25% | rMAE for Validation Set is: 1.14\n",
      "MAE for Test Set is: 50.04 | sMAPE for Test Set is: 45.60% | rMAE for Test Set is: 2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:28,009]\u001b[0m Trial 197 finished with value: 60.8909727906537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021200990107596096, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39310232033608794, 'dropout_rate_Layer_2': 0.23639243991350417, 'dropout_rate_Layer_3': 0.016682690256976374, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029982664515025275, 'l1_Layer_2': 1.1709392649787829e-05, 'l1_Layer_3': 0.00015152060142196923, 'n_units_Layer_1': 135, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.89 | sMAPE for Validation Set is: 33.50% | rMAE for Validation Set is: 1.12\n",
      "MAE for Test Set is: 45.28 | sMAPE for Test Set is: 42.49% | rMAE for Test Set is: 2.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:28,839]\u001b[0m Trial 181 finished with value: 69.45862032035764 and parameters: {'n_hidden': 3, 'learning_rate': 0.001974538636703663, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39572278277342127, 'dropout_rate_Layer_2': 0.2827630696883217, 'dropout_rate_Layer_3': 0.0036425689736533824, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016425705724117993, 'l1_Layer_2': 1.0625833592834068e-05, 'l1_Layer_3': 0.0001695063210518356, 'n_units_Layer_1': 140, 'n_units_Layer_2': 180, 'n_units_Layer_3': 235}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 69.46 | sMAPE for Validation Set is: 38.01% | rMAE for Validation Set is: 1.28\n",
      "MAE for Test Set is: 33.55 | sMAPE for Test Set is: 35.59% | rMAE for Test Set is: 1.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:32,329]\u001b[0m Trial 199 finished with value: 26.438843333048528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017534245313263082, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2786768380168931, 'dropout_rate_Layer_2': 0.08299406056642991, 'dropout_rate_Layer_3': 0.37482499840010924, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.050376181723732635, 'l1_Layer_2': 0.00020838252292810724, 'l1_Layer_3': 0.004693019194304244, 'n_units_Layer_1': 120, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:32,440]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.44 | sMAPE for Validation Set is: 17.29% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.16 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:34,930]\u001b[0m Trial 200 finished with value: 25.756761571626203 and parameters: {'n_hidden': 3, 'learning_rate': 0.020096358772221722, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039088827155537575, 'dropout_rate_Layer_2': 0.08554263450641689, 'dropout_rate_Layer_3': 0.37145460829586613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09709353247270214, 'l1_Layer_2': 0.0005787581531718794, 'l1_Layer_3': 0.010322183805756793, 'n_units_Layer_1': 180, 'n_units_Layer_2': 215, 'n_units_Layer_3': 285}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.76 | sMAPE for Validation Set is: 16.76% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.73 | sMAPE for Test Set is: 15.70% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:40,267]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:40,958]\u001b[0m Trial 201 finished with value: 26.89434938863225 and parameters: {'n_hidden': 3, 'learning_rate': 0.020276103095887107, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04203075389720727, 'dropout_rate_Layer_2': 0.08411832176809567, 'dropout_rate_Layer_3': 0.35716899893220777, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09375858770252248, 'l1_Layer_2': 0.00044731591450053763, 'l1_Layer_3': 0.008859189516193912, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 285}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.89 | sMAPE for Validation Set is: 17.27% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:43,833]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:47,055]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:47,426]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:51,432]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:51,785]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:52,104]\u001b[0m Trial 203 finished with value: 61.63646994934292 and parameters: {'n_hidden': 3, 'learning_rate': 0.004424995786330349, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3893286669324872, 'dropout_rate_Layer_2': 0.2157772558082207, 'dropout_rate_Layer_3': 0.048115539716469896, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00594377378745955, 'l1_Layer_2': 1.0160416310614257e-05, 'l1_Layer_3': 0.00011845433070433698, 'n_units_Layer_1': 50, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 61.64 | sMAPE for Validation Set is: 33.70% | rMAE for Validation Set is: 1.13\n",
      "MAE for Test Set is: 41.12 | sMAPE for Test Set is: 40.70% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:01:59,013]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:59,498]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:01:59,981]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:00,110]\u001b[0m Trial 206 finished with value: 26.395275237524757 and parameters: {'n_hidden': 3, 'learning_rate': 0.04411179460726992, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007691415558396385, 'dropout_rate_Layer_2': 0.03671961652949357, 'dropout_rate_Layer_3': 0.376339195261082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09747308989933243, 'l1_Layer_2': 0.0004346639993684255, 'l1_Layer_3': 0.020397812884826772, 'n_units_Layer_1': 265, 'n_units_Layer_2': 215, 'n_units_Layer_3': 280}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.40 | sMAPE for Validation Set is: 17.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.39 | sMAPE for Test Set is: 16.69% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:02:06,285]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:08,152]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:08,370]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:14,130]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:14,424]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:18,576]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.50 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.21 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:02:20,254]\u001b[0m Trial 218 finished with value: 27.50004811678186 and parameters: {'n_hidden': 3, 'learning_rate': 0.04249520771583971, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005532961295419456, 'dropout_rate_Layer_2': 0.036217000645336735, 'dropout_rate_Layer_3': 0.38913143945891365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.07099220704146281, 'l1_Layer_2': 0.00034600611915847047, 'l1_Layer_3': 0.031420748335444205, 'n_units_Layer_1': 280, 'n_units_Layer_2': 215, 'n_units_Layer_3': 275}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:23,139]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:25,243]\u001b[0m Trial 214 finished with value: 55.31372748692275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011048328323811415, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35173477486028865, 'dropout_rate_Layer_2': 0.12937009362813912, 'dropout_rate_Layer_3': 0.14551305362611966, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.006665254518627135, 'l1_Layer_2': 6.822262323518823e-05, 'l1_Layer_3': 0.00013330452854340855, 'n_units_Layer_1': 55, 'n_units_Layer_2': 210, 'n_units_Layer_3': 140}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:25,278]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 55.31 | sMAPE for Validation Set is: 29.24% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 23.98% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:02:30,254]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:30,467]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:34,982]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:38,073]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:42,971]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:46,210]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:48,469]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:50,428]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:52,832]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:53,981]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:55,163]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:02:55,648]\u001b[0m Trial 225 finished with value: 54.910425452744825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009721502425952771, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33867356882802, 'dropout_rate_Layer_2': 0.12440355799567733, 'dropout_rate_Layer_3': 0.13577796033414383, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005993480189720088, 'l1_Layer_2': 5.8584642661146454e-05, 'l1_Layer_3': 9.914487056351957e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 220, 'n_units_Layer_3': 140}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.91 | sMAPE for Validation Set is: 28.57% | rMAE for Validation Set is: 1.01\n",
      "MAE for Test Set is: 16.47 | sMAPE for Test Set is: 20.79% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:02:56,280]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:01,644]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:02,700]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:06,581]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:08,387]\u001b[0m Trial 238 finished with value: 27.739987211438315 and parameters: {'n_hidden': 3, 'learning_rate': 0.06123832505710577, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04101658144228387, 'dropout_rate_Layer_2': 0.03371362254631993, 'dropout_rate_Layer_3': 0.36887845002785535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.09701275820362659, 'l1_Layer_2': 9.891335010093784e-05, 'l1_Layer_3': 0.007571454744134642, 'n_units_Layer_1': 300, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.74 | sMAPE for Validation Set is: 17.71% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 13.31 | sMAPE for Test Set is: 17.41% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:03:10,564]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:10,932]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:15,082]\u001b[0m Trial 240 finished with value: 27.069604052638212 and parameters: {'n_hidden': 3, 'learning_rate': 0.019437987741809316, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03793120826642564, 'dropout_rate_Layer_2': 0.05157004016827919, 'dropout_rate_Layer_3': 0.37019511544800543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04744181802908719, 'l1_Layer_2': 0.00012560286321508158, 'l1_Layer_3': 0.007803628316838119, 'n_units_Layer_1': 270, 'n_units_Layer_2': 270, 'n_units_Layer_3': 250}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.07 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.44 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:03:15,504]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:15,529]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:20,817]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:22,042]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:24,024]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:24,547]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:28,694]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:30,438]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:33,242]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:35,416]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:37,451]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:41,412]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:46,083]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:49,636]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:53,988]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:54,205]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:03:54,909]\u001b[0m Trial 252 finished with value: 49.11421483990381 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012937153733687857, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33825035853224134, 'dropout_rate_Layer_2': 0.11684439839810754, 'dropout_rate_Layer_3': 0.2821061197510474, 'dropout_rate_Layer_4': 0.19986513554744026, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006857436080127117, 'l1_Layer_2': 0.0016990783898257408, 'l1_Layer_3': 0.000409437626709386, 'l1_Layer_4': 1.4927991664219448e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160, 'n_units_Layer_4': 160}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.11 | sMAPE for Validation Set is: 26.87% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 16.93 | sMAPE for Test Set is: 22.68% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:03:59,349]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:02,291]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:02,391]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:02,496]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:08,312]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:08,432]\u001b[0m Trial 248 finished with value: 59.74907648799362 and parameters: {'n_hidden': 3, 'learning_rate': 0.001179199445175667, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3435233232081765, 'dropout_rate_Layer_2': 0.011981548286485927, 'dropout_rate_Layer_3': 0.2961401496429255, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.018329821037874637, 'l1_Layer_2': 0.00021782830102351153, 'l1_Layer_3': 4.4113399929799194e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 245, 'n_units_Layer_3': 110}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 59.75 | sMAPE for Validation Set is: 30.91% | rMAE for Validation Set is: 1.10\n",
      "MAE for Test Set is: 14.33 | sMAPE for Test Set is: 19.20% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:04:09,485]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:11,282]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:16,745]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:18,436]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:21,473]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:24,747]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:29,899]\u001b[0m Trial 270 finished with value: 26.390612819769753 and parameters: {'n_hidden': 3, 'learning_rate': 0.005331563668246994, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19476545532482661, 'dropout_rate_Layer_2': 0.1419366386778261, 'dropout_rate_Layer_3': 0.3909074492898221, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5718942346934122e-05, 'l1_Layer_2': 0.0001989090799539368, 'l1_Layer_3': 0.0016080083319011836, 'n_units_Layer_1': 210, 'n_units_Layer_2': 255, 'n_units_Layer_3': 230}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.39 | sMAPE for Validation Set is: 17.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.22 | sMAPE for Test Set is: 16.43% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:04:32,917]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:35,117]\u001b[0m Trial 269 finished with value: 56.305200715866384 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015142304574431247, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25653448041370097, 'dropout_rate_Layer_2': 0.1091648367271815, 'dropout_rate_Layer_3': 0.11399812082322743, 'dropout_rate_Layer_4': 0.21167717894650823, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00046622950520100145, 'l1_Layer_2': 3.26194642625656e-05, 'l1_Layer_3': 0.0011972663446039038, 'l1_Layer_4': 0.0002441651803154161, 'n_units_Layer_1': 80, 'n_units_Layer_2': 295, 'n_units_Layer_3': 160, 'n_units_Layer_4': 160}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:35,171]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.31 | sMAPE for Validation Set is: 30.30% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 32.13 | sMAPE for Test Set is: 33.17% | rMAE for Test Set is: 1.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:04:39,240]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:40,677]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:40,762]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.10 | sMAPE for Validation Set is: 28.80% | rMAE for Validation Set is: 0.98\n",
      "MAE for Test Set is: 23.75 | sMAPE for Test Set is: 27.54% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:04:43,851]\u001b[0m Trial 273 finished with value: 53.104503307260394 and parameters: {'n_hidden': 4, 'learning_rate': 0.001533960307400184, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25018168756456693, 'dropout_rate_Layer_2': 0.10614252025206541, 'dropout_rate_Layer_3': 0.1220647734540507, 'dropout_rate_Layer_4': 0.19327726946620222, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006003081806600672, 'l1_Layer_2': 4.128806381837673e-05, 'l1_Layer_3': 0.0013426851365225094, 'l1_Layer_4': 0.00023980224571711097, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 170, 'n_units_Layer_4': 150}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:44,732]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:48,076]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:48,160]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:49,864]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:51,863]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:54,765]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:55,707]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:57,588]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:58,371]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:04:59,996]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:03,582]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:03,675]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:06,465]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:10,910]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:10,950]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:12,055]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:16,649]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:17,898]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:21,590]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:22,221]\u001b[0m Trial 294 finished with value: 26.048851500012024 and parameters: {'n_hidden': 3, 'learning_rate': 0.019393355874987066, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026876960729241364, 'dropout_rate_Layer_2': 0.11042153401552335, 'dropout_rate_Layer_3': 0.3034034750026865, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04901148897727729, 'l1_Layer_2': 0.0024084856235937874, 'l1_Layer_3': 0.0023103336397361615, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.05 | sMAPE for Validation Set is: 17.10% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.19 | sMAPE for Test Set is: 16.25% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:05:27,680]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:30,123]\u001b[0m Trial 301 finished with value: 26.95884524652745 and parameters: {'n_hidden': 3, 'learning_rate': 0.01749823914563915, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023462275445264504, 'dropout_rate_Layer_2': 0.10113294997036056, 'dropout_rate_Layer_3': 0.3040365461404074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04078516918698233, 'l1_Layer_2': 0.002290924674696533, 'l1_Layer_3': 0.0021810465454863, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 255}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.96 | sMAPE for Validation Set is: 17.53% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.27 | sMAPE for Test Set is: 16.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:05:32,217]\u001b[0m Trial 298 finished with value: 57.28247258037981 and parameters: {'n_hidden': 4, 'learning_rate': 0.003753366592186156, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2340137029680538, 'dropout_rate_Layer_2': 0.17348215662337743, 'dropout_rate_Layer_3': 0.20424400720257846, 'dropout_rate_Layer_4': 0.13346290425575535, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0006100340596234745, 'l1_Layer_2': 0.002484093047851581, 'l1_Layer_3': 0.0012075558827902065, 'l1_Layer_4': 9.166341189212091e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 265, 'n_units_Layer_3': 170, 'n_units_Layer_4': 125}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 57.28 | sMAPE for Validation Set is: 31.28% | rMAE for Validation Set is: 1.05\n",
      "MAE for Test Set is: 30.16 | sMAPE for Test Set is: 32.77% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:05:34,865]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:35,351]\u001b[0m Trial 303 finished with value: 26.34799173051863 and parameters: {'n_hidden': 3, 'learning_rate': 0.020388021644798394, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018253726643811558, 'dropout_rate_Layer_2': 0.18511431234260994, 'dropout_rate_Layer_3': 0.2960186772544032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.037381512724010336, 'l1_Layer_2': 0.00016838676957733382, 'l1_Layer_3': 0.011731937793604083, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 285}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:35,427]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.35 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:05:42,666]\u001b[0m Trial 305 finished with value: 27.423521576240745 and parameters: {'n_hidden': 3, 'learning_rate': 0.01935926439203843, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028687454764471466, 'dropout_rate_Layer_2': 0.1870409687393597, 'dropout_rate_Layer_3': 0.29505878380738876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03552101396805199, 'l1_Layer_2': 0.0008271362365571828, 'l1_Layer_3': 0.0024054688206771075, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 285}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.42 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 11.98 | sMAPE for Test Set is: 16.14% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:05:51,879]\u001b[0m Trial 309 finished with value: 26.21037387266506 and parameters: {'n_hidden': 3, 'learning_rate': 0.00418228345674375, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3022163127489456, 'dropout_rate_Layer_2': 0.05352392267025043, 'dropout_rate_Layer_3': 0.2737863913298198, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01784948946680639, 'l1_Layer_2': 0.0009720945616705083, 'l1_Layer_3': 0.0005572313144187516, 'n_units_Layer_1': 165, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 110 with value: 25.67040044097705.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.21 | sMAPE for Validation Set is: 17.24% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 15.98% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:05:56,476]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:05:56,893]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:02,139]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:05,719]\u001b[0m Trial 310 finished with value: 25.19356124335273 and parameters: {'n_hidden': 3, 'learning_rate': 0.00314418375944778, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07240404800072077, 'dropout_rate_Layer_2': 0.1872520506236152, 'dropout_rate_Layer_3': 0.15018104633090262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.854585584391417e-05, 'l1_Layer_2': 0.0002353654309432479, 'l1_Layer_3': 0.0008042442567291271, 'n_units_Layer_1': 175, 'n_units_Layer_2': 270, 'n_units_Layer_3': 200}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.19 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.67 | sMAPE for Test Set is: 15.83% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:06:07,578]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:08,685]\u001b[0m Trial 311 finished with value: 48.56254944005186 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008100811070723517, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28946967504379917, 'dropout_rate_Layer_2': 0.06184812525367403, 'dropout_rate_Layer_3': 0.2960989595512909, 'dropout_rate_Layer_4': 0.2792120531557099, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0038598978445850366, 'l1_Layer_2': 2.6593190323610646e-05, 'l1_Layer_3': 0.013318791373550572, 'l1_Layer_4': 0.002639422291086358, 'n_units_Layer_1': 205, 'n_units_Layer_2': 300, 'n_units_Layer_3': 90, 'n_units_Layer_4': 220}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.56 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.89\n",
      "MAE for Test Set is: 18.11 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:06:09,803]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:13,650]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:13,983]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:18,244]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:20,581]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:24,190]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:24,997]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:28,749]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:29,284]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:29,491]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:34,036]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:36,237]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:39,083]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:40,817]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:44,983]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:45,379]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:49,420]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:51,119]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:53,529]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:55,101]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:06:59,232]\u001b[0m Trial 327 finished with value: 26.79136088396584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0035383261727730017, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30779548842265225, 'dropout_rate_Layer_2': 0.21491722308447636, 'dropout_rate_Layer_3': 0.25891150413703296, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06538487802162177, 'l1_Layer_2': 0.0002487342293915264, 'l1_Layer_3': 0.0013493578609070395, 'n_units_Layer_1': 50, 'n_units_Layer_2': 125, 'n_units_Layer_3': 120}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.79 | sMAPE for Validation Set is: 17.49% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.23 | sMAPE for Test Set is: 16.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:06:59,624]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:00,360]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:03,779]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:05,637]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:10,238]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:14,494]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:18,220]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:20,336]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:22,433]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:22,877]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:24,609]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:26,083]\u001b[0m Trial 328 finished with value: 26.500687889619915 and parameters: {'n_hidden': 3, 'learning_rate': 0.003674573406686023, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3015269236893081, 'dropout_rate_Layer_2': 0.13532398205471316, 'dropout_rate_Layer_3': 0.35931239249037555, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.055525708685969406, 'l1_Layer_2': 0.00046223538684198886, 'l1_Layer_3': 0.0015289885716504548, 'n_units_Layer_1': 155, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.50 | sMAPE for Validation Set is: 17.36% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.42 | sMAPE for Test Set is: 16.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:07:26,877]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:28,460]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:33,221]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:35,624]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:36,181]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:36,240]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:36,735]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:42,499]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:43,456]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:44,299]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:46,810]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:48,367]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:49,022]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:51,121]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:55,339]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:07:55,741]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:00,326]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:00,656]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:05,602]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:06,383]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:09,970]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:10,473]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:10,985]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:11,107]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:13,271]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:18,706]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:19,423]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:19,895]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:23,000]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:24,467]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:26,997]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:27,857]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:28,641]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:32,949]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:33,365]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:34,077]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:35,832]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:36,898]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:47,197]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:08:51,796]\u001b[0m Trial 386 finished with value: 26.463407754003452 and parameters: {'n_hidden': 3, 'learning_rate': 0.01903245955830893, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001425079378747713, 'dropout_rate_Layer_2': 0.0855170277021089, 'dropout_rate_Layer_3': 0.3081532790065693, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02885445188540594, 'l1_Layer_2': 0.0020272230976939192, 'l1_Layer_3': 0.0026410543149512525, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.46 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:08:54,778]\u001b[0m Trial 387 finished with value: 53.94864229408722 and parameters: {'n_hidden': 4, 'learning_rate': 0.002858250928336211, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27849235773762726, 'dropout_rate_Layer_2': 0.1559309933900916, 'dropout_rate_Layer_3': 0.3183887934085451, 'dropout_rate_Layer_4': 0.13567641660549745, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.010226154158232999, 'l1_Layer_2': 0.005237717972594479, 'l1_Layer_3': 0.00034663972771523804, 'l1_Layer_4': 0.0007601668960674212, 'n_units_Layer_1': 190, 'n_units_Layer_2': 300, 'n_units_Layer_3': 175, 'n_units_Layer_4': 125}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.95 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.99\n",
      "MAE for Test Set is: 18.24 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:08:56,271]\u001b[0m Trial 389 finished with value: 26.228735293958 and parameters: {'n_hidden': 3, 'learning_rate': 0.014158022160747876, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018933838197993193, 'dropout_rate_Layer_2': 0.08826818538178732, 'dropout_rate_Layer_3': 0.30150120179840423, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.026390547736263145, 'l1_Layer_2': 0.002038750076772463, 'l1_Layer_3': 0.0025444009217143455, 'n_units_Layer_1': 240, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.23 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 16.15% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:08:59,499]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:02,503]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.29 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.46 | sMAPE for Test Set is: 16.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:09:06,723]\u001b[0m Trial 391 finished with value: 26.287259523079385 and parameters: {'n_hidden': 3, 'learning_rate': 0.01446587507605815, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0013698862251837892, 'dropout_rate_Layer_2': 0.08526894592433433, 'dropout_rate_Layer_3': 0.3119188115272271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.027764171723644076, 'l1_Layer_2': 0.0018473104349973892, 'l1_Layer_3': 0.011413122374724041, 'n_units_Layer_1': 225, 'n_units_Layer_2': 195, 'n_units_Layer_3': 240}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:08,466]\u001b[0m Trial 392 finished with value: 26.295901858957563 and parameters: {'n_hidden': 3, 'learning_rate': 0.015582904660949694, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002147962858810788, 'dropout_rate_Layer_2': 0.363662087529301, 'dropout_rate_Layer_3': 0.31062677355351, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02103635413189879, 'l1_Layer_2': 0.001721525870924277, 'l1_Layer_3': 0.010338132687704312, 'n_units_Layer_1': 220, 'n_units_Layer_2': 175, 'n_units_Layer_3': 240}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.30 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.35 | sMAPE for Test Set is: 16.31% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:09:11,418]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:13,867]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.92 | sMAPE for Validation Set is: 23.31% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 14.96 | sMAPE for Test Set is: 19.30% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:09:15,927]\u001b[0m Trial 390 finished with value: 43.92306522319881 and parameters: {'n_hidden': 4, 'learning_rate': 0.0015587786058927067, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2840764302543635, 'dropout_rate_Layer_2': 0.16372255247546552, 'dropout_rate_Layer_3': 0.30692013023706166, 'dropout_rate_Layer_4': 0.14721812134254716, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011587134316447725, 'l1_Layer_2': 0.00012380575432178868, 'l1_Layer_3': 0.00030777184496269305, 'l1_Layer_4': 4.256241540336857e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 230, 'n_units_Layer_3': 170, 'n_units_Layer_4': 130}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:18,600]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:20,736]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:23,192]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:24,060]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:28,831]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:33,091]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:38,330]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:41,318]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:44,408]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.47 | sMAPE for Validation Set is: 17.60% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 16.35% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:09:45,298]\u001b[0m Trial 406 finished with value: 27.46540930055818 and parameters: {'n_hidden': 3, 'learning_rate': 0.014615527606340316, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07951553684051432, 'dropout_rate_Layer_2': 0.33169725174852893, 'dropout_rate_Layer_3': 0.285573279871793, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010197081184239688, 'l1_Layer_2': 0.0014922341166375413, 'l1_Layer_3': 0.011783564755952882, 'n_units_Layer_1': 200, 'n_units_Layer_2': 170, 'n_units_Layer_3': 200}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:48,385]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:51,326]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:52,836]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:55,012]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:56,876]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:59,165]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:09:59,556]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:03,495]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:07,427]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:09,537]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:13,128]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:15,550]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:16,117]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:18,933]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:20,121]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:20,731]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:21,193]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:27,024]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:27,623]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:28,016]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:29,578]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:31,201]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:36,626]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:36,669]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:36,669]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:37,204]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:42,326]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:43,905]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:46,229]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:50,969]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:54,220]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:10:57,569]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:01,818]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.97 | sMAPE for Validation Set is: 25.31% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 20.39 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:11:03,286]\u001b[0m Trial 436 finished with value: 46.96502397947361 and parameters: {'n_hidden': 4, 'learning_rate': 0.001828034290813476, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23040022673563582, 'dropout_rate_Layer_2': 0.16257354699758894, 'dropout_rate_Layer_3': 0.39054388608506313, 'dropout_rate_Layer_4': 0.17718347773286192, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.011856996850746647, 'l1_Layer_2': 0.00014035793255198073, 'l1_Layer_3': 0.001971913812511797, 'l1_Layer_4': 4.746712943280355e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 200, 'n_units_Layer_4': 145}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:04,171]\u001b[0m Trial 435 finished with value: 26.538625758619947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017144926170031306, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33760213109347426, 'dropout_rate_Layer_2': 0.039221993189007424, 'dropout_rate_Layer_3': 0.2132295141997543, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06723129080182609, 'l1_Layer_2': 0.00022812398221835447, 'l1_Layer_3': 0.007003557989154157, 'n_units_Layer_1': 110, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.54 | sMAPE for Validation Set is: 17.30% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.23 | sMAPE for Test Set is: 16.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:11:07,397]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:08,707]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:11,274]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:13,226]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:15,538]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:18,626]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.50 | sMAPE for Validation Set is: 22.47% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 17.00 | sMAPE for Test Set is: 21.09% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:11:20,073]\u001b[0m Trial 438 finished with value: 41.4984208218745 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017055875511302078, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2382914974390279, 'dropout_rate_Layer_2': 0.15448623444499376, 'dropout_rate_Layer_3': 0.37261160242721425, 'dropout_rate_Layer_4': 0.17168049444050645, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01286722491618785, 'l1_Layer_2': 0.00012959771457124233, 'l1_Layer_3': 0.0019533901770382067, 'l1_Layer_4': 4.5221272612754446e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 200, 'n_units_Layer_4': 145}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:22,291]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:24,278]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:24,415]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:27,153]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:29,679]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:30,988]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:31,793]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:35,625]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:35,867]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:36,385]\u001b[0m Trial 450 finished with value: 26.273915039232104 and parameters: {'n_hidden': 3, 'learning_rate': 0.01550253456448993, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0870574869847117, 'dropout_rate_Layer_2': 0.14272569297916138, 'dropout_rate_Layer_3': 0.2400367427287266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023305217799478507, 'l1_Layer_2': 0.0026655876055822108, 'l1_Layer_3': 0.005766643956207356, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 215}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.27 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.78 | sMAPE for Test Set is: 16.64% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:11:42,772]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:50,813]\u001b[0m Trial 457 finished with value: 25.965377023076883 and parameters: {'n_hidden': 3, 'learning_rate': 0.004268495838059933, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2751737182665762, 'dropout_rate_Layer_2': 0.03262235145310117, 'dropout_rate_Layer_3': 0.26438465916994397, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025162229912804736, 'l1_Layer_2': 0.0001362566096209599, 'l1_Layer_3': 0.001672310610301547, 'n_units_Layer_1': 75, 'n_units_Layer_2': 255, 'n_units_Layer_3': 195}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.97 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 15.69% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:11:50,998]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:55,483]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:58,389]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:11:58,710]\u001b[0m Trial 460 finished with value: 48.715021648664504 and parameters: {'n_hidden': 4, 'learning_rate': 0.00257829128601527, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22846477360043563, 'dropout_rate_Layer_2': 0.18735881145325306, 'dropout_rate_Layer_3': 0.38685341280122615, 'dropout_rate_Layer_4': 0.09905727568456746, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012272687280621435, 'l1_Layer_2': 0.00012077367574755961, 'l1_Layer_3': 0.002233664187081302, 'l1_Layer_4': 6.810249082359095e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 235, 'n_units_Layer_3': 210, 'n_units_Layer_4': 100}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.72 | sMAPE for Validation Set is: 27.78% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 23.86 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 1.22\n",
      "MAE for Validation Set is: 50.04 | sMAPE for Validation Set is: 26.79% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 16.50 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:12:02,545]\u001b[0m Trial 461 finished with value: 50.04089936816049 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025269429132179838, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23355689264422494, 'dropout_rate_Layer_2': 0.1750758010247557, 'dropout_rate_Layer_3': 0.39460505432031906, 'dropout_rate_Layer_4': 0.08053442384498095, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.012870666714612022, 'l1_Layer_2': 0.00013107506816528781, 'l1_Layer_3': 0.0027304252222946066, 'l1_Layer_4': 4.977621533100283e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 230, 'n_units_Layer_3': 210, 'n_units_Layer_4': 115}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:03,824]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:07,103]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:07,988]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:08,309]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:08,605]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:14,571]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:16,838]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:18,632]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:18,989]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:24,595]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:27,569]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:32,367]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:35,292]\u001b[0m Trial 473 finished with value: 31.16729296378361 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018555698796968085, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13169272771638885, 'dropout_rate_Layer_2': 0.15159059609313746, 'dropout_rate_Layer_3': 0.3461926616809538, 'dropout_rate_Layer_4': 0.15399119705135794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04323363680507899, 'l1_Layer_2': 0.00039859061737056677, 'l1_Layer_3': 0.007891374941677725, 'l1_Layer_4': 4.276532411741333e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260, 'n_units_Layer_4': 235}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.17 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.16 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:12:35,727]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:38,549]\u001b[0m Trial 477 finished with value: 27.51372273564228 and parameters: {'n_hidden': 3, 'learning_rate': 0.006616863839398366, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.167390808158383, 'dropout_rate_Layer_2': 0.16939902484079242, 'dropout_rate_Layer_3': 0.36403549535319935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.670012791725267e-05, 'l1_Layer_2': 0.00029905303924536035, 'l1_Layer_3': 0.0020099351103289942, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.51 | sMAPE for Validation Set is: 18.46% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.63 | sMAPE for Test Set is: 16.88% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:12:40,193]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:40,628]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:42,938]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:47,615]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:50,070]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:53,862]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:53,988]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:58,427]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:12:59,489]\u001b[0m Trial 485 finished with value: 63.090191063121715 and parameters: {'n_hidden': 4, 'learning_rate': 0.006979320826808141, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18865133531256142, 'dropout_rate_Layer_2': 0.149345078555139, 'dropout_rate_Layer_3': 0.3611935954868499, 'dropout_rate_Layer_4': 0.1611623409443367, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06628887999231725, 'l1_Layer_2': 0.00031203675508160533, 'l1_Layer_3': 0.007217724673939937, 'l1_Layer_4': 3.407831151436996e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 295, 'n_units_Layer_4': 190}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 63.09 | sMAPE for Validation Set is: 32.89% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 14.99 | sMAPE for Test Set is: 20.02% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:02,394]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:02,893]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:06,997]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:07,597]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:10,324]\u001b[0m Trial 479 finished with value: 28.564779243111833 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018921527965516831, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28249166280660415, 'dropout_rate_Layer_2': 0.14976066489613318, 'dropout_rate_Layer_3': 0.36146829275207293, 'dropout_rate_Layer_4': 0.2408176555248302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.05115707425650852, 'l1_Layer_2': 0.00033107802195950247, 'l1_Layer_3': 0.007210184607259105, 'l1_Layer_4': 3.587666089113407e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 195, 'n_units_Layer_3': 195, 'n_units_Layer_4': 185}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.56 | sMAPE for Validation Set is: 18.49% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 12.57 | sMAPE for Test Set is: 17.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:13,752]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:14,318]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:18,970]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:19,201]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:24,621]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:25,050]\u001b[0m Trial 496 finished with value: 27.20548651034828 and parameters: {'n_hidden': 3, 'learning_rate': 0.0093753245757045, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09292528804219966, 'dropout_rate_Layer_2': 0.14570524292350315, 'dropout_rate_Layer_3': 0.29214933562133844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.01045419492349763, 'l1_Layer_2': 0.0011421070705839689, 'l1_Layer_3': 0.000997676846935085, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.21 | sMAPE for Validation Set is: 17.45% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.68 | sMAPE for Test Set is: 16.60% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:28,938]\u001b[0m Trial 493 finished with value: 25.408996991260988 and parameters: {'n_hidden': 3, 'learning_rate': 0.010605734518036111, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01713270596264027, 'dropout_rate_Layer_2': 0.14748517175622808, 'dropout_rate_Layer_3': 0.20037190595629145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013352841249283072, 'l1_Layer_2': 0.0012430485921057415, 'l1_Layer_3': 0.0011959563980817314, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 225}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.41 | sMAPE for Validation Set is: 16.51% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 15.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:29,169]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:29,511]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:39,559]\u001b[0m Trial 502 finished with value: 26.090835635564403 and parameters: {'n_hidden': 3, 'learning_rate': 0.009074658214578533, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022949544787394298, 'dropout_rate_Layer_2': 0.13627971780695733, 'dropout_rate_Layer_3': 0.15100499266291695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.011434648816141335, 'l1_Layer_2': 0.0012380467794515957, 'l1_Layer_3': 0.0010513372793262564, 'n_units_Layer_1': 205, 'n_units_Layer_2': 175, 'n_units_Layer_3': 245}. Best is trial 310 with value: 25.19356124335273.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.09 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.72 | sMAPE for Test Set is: 15.76% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:43,239]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:13:51,525]\u001b[0m Trial 505 finished with value: 24.809020223678882 and parameters: {'n_hidden': 3, 'learning_rate': 0.004970770617512994, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04610132625717825, 'dropout_rate_Layer_2': 0.1095444152317526, 'dropout_rate_Layer_3': 0.16052007318471312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005404913000989364, 'l1_Layer_2': 0.001479399799804903, 'l1_Layer_3': 0.001560331787415614, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 210}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.81 | sMAPE for Validation Set is: 16.27% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.68 | sMAPE for Test Set is: 15.60% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:55,497]\u001b[0m Trial 506 finished with value: 29.14339832076369 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019472997237598496, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14398722829169366, 'dropout_rate_Layer_2': 0.20591538080168875, 'dropout_rate_Layer_3': 0.3721739936384011, 'dropout_rate_Layer_4': 0.2401474238549775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09612269967460614, 'l1_Layer_2': 0.0007941699123481267, 'l1_Layer_3': 0.02420489609980979, 'l1_Layer_4': 0.00011389840318865588, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255, 'n_units_Layer_4': 245}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.14 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 13.46 | sMAPE for Test Set is: 18.04% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:13:57,330]\u001b[0m Trial 507 finished with value: 25.003943529111268 and parameters: {'n_hidden': 3, 'learning_rate': 0.006233561856328683, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03995444876947593, 'dropout_rate_Layer_2': 0.11376065817507157, 'dropout_rate_Layer_3': 0.14779021056233319, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012536902235242323, 'l1_Layer_2': 0.0017496671505211913, 'l1_Layer_3': 0.0012631470259464768, 'n_units_Layer_1': 240, 'n_units_Layer_2': 190, 'n_units_Layer_3': 180}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.00 | sMAPE for Validation Set is: 16.39% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.41 | sMAPE for Test Set is: 15.37% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:14:01,714]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:02,726]\u001b[0m Trial 509 finished with value: 25.07860270099711 and parameters: {'n_hidden': 3, 'learning_rate': 0.006098919485874621, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.039817785758139206, 'dropout_rate_Layer_2': 0.11345211839245674, 'dropout_rate_Layer_3': 0.1411702067159798, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015521768260788348, 'l1_Layer_2': 0.0012899242340765223, 'l1_Layer_3': 0.0016533157441770922, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 215}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.08 | sMAPE for Validation Set is: 16.37% | rMAE for Validation Set is: 0.46\n",
      "MAE for Test Set is: 11.90 | sMAPE for Test Set is: 15.78% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:14:11,396]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:12,036]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:17,701]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:20,672]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:26,117]\u001b[0m Trial 511 finished with value: 25.594536528251023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038539276836503686, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050578770481370515, 'dropout_rate_Layer_2': 0.15325429598913545, 'dropout_rate_Layer_3': 0.12977495033481154, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.585341164344743e-05, 'l1_Layer_2': 0.00019422560637587024, 'l1_Layer_3': 0.0010613574185058957, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.59 | sMAPE for Validation Set is: 17.01% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.42 | sMAPE for Test Set is: 15.45% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:14:29,689]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:29,936]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:34,310]\u001b[0m Trial 514 finished with value: 26.726465670281062 and parameters: {'n_hidden': 4, 'learning_rate': 0.0037267852759568293, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11713052923863525, 'dropout_rate_Layer_2': 0.19703047300450724, 'dropout_rate_Layer_3': 0.36674384761302226, 'dropout_rate_Layer_4': 0.09447889422946752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03612953828843102, 'l1_Layer_2': 0.0008273537163174865, 'l1_Layer_3': 0.026824312164029977, 'l1_Layer_4': 0.00011931750725703093, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255, 'n_units_Layer_4': 235}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.73 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.49 | sMAPE for Test Set is: 18.90% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:14:36,176]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:36,289]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:41,363]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:43,462]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:44,037]\u001b[0m Trial 516 finished with value: 25.72430372344715 and parameters: {'n_hidden': 3, 'learning_rate': 0.005251114019024187, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023519193856922138, 'dropout_rate_Layer_2': 0.20822042932156332, 'dropout_rate_Layer_3': 0.1311816041640317, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010421657096709497, 'l1_Layer_2': 0.00017922691486652197, 'l1_Layer_3': 0.0017943488843902952, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 235}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.72 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:14:44,299]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:48,276]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:50,621]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:51,086]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:14:56,660]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:00,989]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:05,763]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:08,782]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:14,089]\u001b[0m Trial 529 finished with value: 32.408865116233045 and parameters: {'n_hidden': 4, 'learning_rate': 0.004825281182281418, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13670957349695995, 'dropout_rate_Layer_2': 0.19880532465927245, 'dropout_rate_Layer_3': 0.3363480198980202, 'dropout_rate_Layer_4': 0.2346567697458926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09203874993002921, 'l1_Layer_2': 0.0007080453222573514, 'l1_Layer_3': 0.02617883244006765, 'l1_Layer_4': 0.00012269586730193844, 'n_units_Layer_1': 275, 'n_units_Layer_2': 135, 'n_units_Layer_3': 260, 'n_units_Layer_4': 245}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.41 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.28 | sMAPE for Test Set is: 18.71% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:15:14,399]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:18,684]\u001b[0m Trial 522 finished with value: 28.03129009536303 and parameters: {'n_hidden': 4, 'learning_rate': 0.003611209388063637, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13460581287210144, 'dropout_rate_Layer_2': 0.19915944482787176, 'dropout_rate_Layer_3': 0.3692953214198431, 'dropout_rate_Layer_4': 0.2397398568882604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09024268170369104, 'l1_Layer_2': 0.000756260914820854, 'l1_Layer_3': 0.026178484206083857, 'l1_Layer_4': 0.00010672434389834286, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255, 'n_units_Layer_4': 235}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.03 | sMAPE for Validation Set is: 18.50% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.41 | sMAPE for Test Set is: 20.29% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:15:22,335]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:25,723]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:26,261]\u001b[0m Trial 538 finished with value: 188.50269137847363 and parameters: {'n_hidden': 4, 'learning_rate': 0.09701898998086206, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09268973676850331, 'dropout_rate_Layer_2': 0.23040065706362034, 'dropout_rate_Layer_3': 0.33384680412748796, 'dropout_rate_Layer_4': 0.24165365461206909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03709782226713885, 'l1_Layer_2': 0.0011921489673347007, 'l1_Layer_3': 0.05853430675154519, 'l1_Layer_4': 1.9540290767407116e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 150, 'n_units_Layer_3': 280, 'n_units_Layer_4': 275}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 188.50 | sMAPE for Validation Set is: 185.82% | rMAE for Validation Set is: 3.47\n",
      "MAE for Test Set is: 85.87 | sMAPE for Test Set is: 177.28% | rMAE for Test Set is: 4.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:15:31,355]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:32,912]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:35,540]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:36,370]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:39,068]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:39,623]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:41,906]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:44,858]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:49,650]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:15:52,931]\u001b[0m Trial 536 finished with value: 25.35116923048732 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034887168959994532, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022976347700385546, 'dropout_rate_Layer_2': 0.21945970988941316, 'dropout_rate_Layer_3': 0.13461318038463652, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013475528080574707, 'l1_Layer_2': 0.00014592755239196722, 'l1_Layer_3': 0.002008889853046556, 'n_units_Layer_1': 185, 'n_units_Layer_2': 200, 'n_units_Layer_3': 250}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.35 | sMAPE for Validation Set is: 16.84% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.64 | sMAPE for Test Set is: 15.63% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:15:56,091]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:00,820]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:03,812]\u001b[0m Trial 548 finished with value: 25.594966070873998 and parameters: {'n_hidden': 3, 'learning_rate': 0.0062830349988721385, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031739545547420187, 'dropout_rate_Layer_2': 0.12996558597875074, 'dropout_rate_Layer_3': 0.15673301942544834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015511760210605153, 'l1_Layer_2': 0.0010967226149945827, 'l1_Layer_3': 0.0018226162339741218, 'n_units_Layer_1': 160, 'n_units_Layer_2': 155, 'n_units_Layer_3': 160}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.59 | sMAPE for Validation Set is: 16.77% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 15.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:16:06,638]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:09,690]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:11,287]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:13,697]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:17,131]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:18,982]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:19,830]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:20,571]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:25,393]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:27,575]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:28,155]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:32,346]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.77 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 15.80% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:16:33,805]\u001b[0m Trial 552 finished with value: 25.768936493108175 and parameters: {'n_hidden': 3, 'learning_rate': 0.004554817780438172, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022749065088008027, 'dropout_rate_Layer_2': 0.2336715154709669, 'dropout_rate_Layer_3': 0.1349279422305923, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001782143740591587, 'l1_Layer_2': 0.00012006024858702423, 'l1_Layer_3': 0.0024324082683053485, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:33,922]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:34,308]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:39,427]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:45,082]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:48,608]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:52,065]\u001b[0m Trial 566 finished with value: 26.28689048970656 and parameters: {'n_hidden': 3, 'learning_rate': 0.006104221874145329, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.029644743577678198, 'dropout_rate_Layer_2': 0.16024595272298245, 'dropout_rate_Layer_3': 0.19085287984598184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002334405398668365, 'l1_Layer_2': 0.004257159386701728, 'l1_Layer_3': 0.001888280332814135, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.29 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 16.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:16:55,695]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:16:56,567]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:00,637]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:01,157]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:05,249]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:08,341]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:10,724]\u001b[0m Trial 572 finished with value: 26.20180707377207 and parameters: {'n_hidden': 3, 'learning_rate': 0.005992929301897264, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031956821224097993, 'dropout_rate_Layer_2': 0.16677543915562043, 'dropout_rate_Layer_3': 0.195324461060237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0020968056593667125, 'l1_Layer_2': 0.004576304023746141, 'l1_Layer_3': 0.0015804506892219715, 'n_units_Layer_1': 145, 'n_units_Layer_2': 235, 'n_units_Layer_3': 155}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.20 | sMAPE for Validation Set is: 17.03% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 16.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:17:11,370]\u001b[0m Trial 570 finished with value: 28.966503899337194 and parameters: {'n_hidden': 4, 'learning_rate': 0.008833614541577656, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1403244817889502, 'dropout_rate_Layer_2': 0.19648173257666088, 'dropout_rate_Layer_3': 0.340161391853167, 'dropout_rate_Layer_4': 0.25428664783697796, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09967871765203432, 'l1_Layer_2': 0.0006539020658424905, 'l1_Layer_3': 0.024160387996449362, 'l1_Layer_4': 8.169423531871155e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255, 'n_units_Layer_4': 250}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.97 | sMAPE for Validation Set is: 18.53% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 12.78 | sMAPE for Test Set is: 17.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:17:13,426]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:15,456]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:16,386]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:17,670]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:21,287]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:23,307]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:23,335]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:24,557]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:29,479]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:31,268]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:33,508]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:34,334]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:35,736]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:41,075]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:41,208]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:44,405]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:46,204]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:46,495]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:48,795]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:53,201]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:53,468]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:53,769]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:53,815]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:17:59,314]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:01,715]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:02,111]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:03,385]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:03,868]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:06,669]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:07,461]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:09,749]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:12,122]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:16,490]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:17,327]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:19,570]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:23,075]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:25,108]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:25,676]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:28,515]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:30,700]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:31,686]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:32,701]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:37,389]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:37,666]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:37,967]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:44,058]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:47,845]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:50,830]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:52,038]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:55,521]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:18:55,655]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:00,029]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:00,165]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:16,370]\u001b[0m Trial 625 finished with value: 25.46667607950432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008876025695882221, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3755889063486819, 'dropout_rate_Layer_2': 0.01063203315114474, 'dropout_rate_Layer_3': 0.3773794536522113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.014726588277993332, 'l1_Layer_2': 4.5691798566324605e-05, 'l1_Layer_3': 0.0004006627044728084, 'n_units_Layer_1': 115, 'n_units_Layer_2': 285, 'n_units_Layer_3': 130}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.47 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.89 | sMAPE for Test Set is: 16.07% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 26.06 | sMAPE for Validation Set is: 16.97% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.77 | sMAPE for Test Set is: 15.68% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:19:18,724]\u001b[0m Trial 633 finished with value: 26.060665741648318 and parameters: {'n_hidden': 3, 'learning_rate': 0.008239452503199329, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07944047590971641, 'dropout_rate_Layer_2': 0.12478648480337463, 'dropout_rate_Layer_3': 0.05969341615432272, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001075754515114754, 'l1_Layer_2': 0.0009709767576856257, 'l1_Layer_3': 0.0032432808083191858, 'n_units_Layer_1': 135, 'n_units_Layer_2': 210, 'n_units_Layer_3': 110}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:18,732]\u001b[0m Trial 630 finished with value: 31.248871582264787 and parameters: {'n_hidden': 4, 'learning_rate': 0.002173126247523241, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19595840357503613, 'dropout_rate_Layer_2': 0.13696778467045645, 'dropout_rate_Layer_3': 0.3203889515984101, 'dropout_rate_Layer_4': 0.30463361262861177, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.09215040458100769, 'l1_Layer_2': 0.0035669947481472997, 'l1_Layer_3': 0.021067027393704, 'l1_Layer_4': 2.0735959186173136e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 90, 'n_units_Layer_3': 230, 'n_units_Layer_4': 180}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 31.25 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.36 | sMAPE for Test Set is: 21.19% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:19:23,773]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:26,338]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:28,344]\u001b[0m Trial 634 finished with value: 26.573586115344284 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031796413605802197, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19866415690607742, 'dropout_rate_Layer_2': 0.26321432200855766, 'dropout_rate_Layer_3': 0.36833556122525524, 'dropout_rate_Layer_4': 0.21816783370797516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.03638028155307979, 'l1_Layer_2': 0.0006915402366165456, 'l1_Layer_3': 0.004821671884205437, 'l1_Layer_4': 1.008842014459071e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230, 'n_units_Layer_4': 255}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.57 | sMAPE for Validation Set is: 17.34% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.74 | sMAPE for Test Set is: 17.69% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:19:28,720]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:32,839]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:33,249]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:33,855]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:37,891]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:38,367]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:39,685]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:42,790]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:44,115]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:44,901]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:48,228]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:48,498]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:49,985]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:50,813]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:54,591]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:56,992]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:58,286]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:19:59,333]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:01,824]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:06,417]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:08,280]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:08,368]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:09,594]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:09,903]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:12,911]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:13,434]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:16,236]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:16,516]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:24,102]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:24,138]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:25,556]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:29,829]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:29,956]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:30,574]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:35,132]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:35,957]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:36,540]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:36,637]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:39,994]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:42,203]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:43,904]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:45,586]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:49,792]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:50,081]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:51,091]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:57,335]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:20:59,700]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:00,414]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:02,390]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:04,148]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:05,543]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:09,209]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:10,880]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.91 | sMAPE for Validation Set is: 16.96% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.25 | sMAPE for Test Set is: 16.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:21:13,005]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:13,020]\u001b[0m Trial 678 finished with value: 25.9090996361911 and parameters: {'n_hidden': 3, 'learning_rate': 0.004769292344976977, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3328661797324291, 'dropout_rate_Layer_2': 0.10281597994576966, 'dropout_rate_Layer_3': 0.07681715093930062, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0534655423562396, 'l1_Layer_2': 5.292566797008042e-05, 'l1_Layer_3': 0.0011369437713831772, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 140}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:14,922]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:19,182]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:20,263]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:23,255]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:23,925]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:24,464]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:24,627]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:29,822]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:31,856]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:33,138]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:38,071]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:41,460]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:44,753]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:45,081]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:48,667]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:48,828]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:49,069]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:56,598]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:21:57,539]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:02,177]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:06,094]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:06,593]\u001b[0m Trial 705 finished with value: 28.67598429143096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0035708410686013533, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17491756551682394, 'dropout_rate_Layer_2': 0.18169329913022098, 'dropout_rate_Layer_3': 0.3790411619620773, 'dropout_rate_Layer_4': 0.18519507025448853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.06273826469581718, 'l1_Layer_2': 0.0009456868297401059, 'l1_Layer_3': 0.011007771152318173, 'l1_Layer_4': 0.00020414069270355238, 'n_units_Layer_1': 245, 'n_units_Layer_2': 50, 'n_units_Layer_3': 240, 'n_units_Layer_4': 230}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.68 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 16.84% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:22:10,604]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:11,573]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:15,303]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:15,593]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:15,987]\u001b[0m Trial 714 finished with value: 27.259638058475502 and parameters: {'n_hidden': 3, 'learning_rate': 0.005533810412431022, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35793044329528423, 'dropout_rate_Layer_2': 0.03176410481877915, 'dropout_rate_Layer_3': 0.17035376062403143, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.039225000422165535, 'l1_Layer_2': 1.8786337593974432e-05, 'l1_Layer_3': 0.0016148064315580882, 'n_units_Layer_1': 285, 'n_units_Layer_2': 255, 'n_units_Layer_3': 135}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.26 | sMAPE for Validation Set is: 17.81% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.96 | sMAPE for Test Set is: 17.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:22:22,171]\u001b[0m Trial 710 finished with value: 27.330366601335715 and parameters: {'n_hidden': 4, 'learning_rate': 0.005931231904112277, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12208116993415567, 'dropout_rate_Layer_2': 0.3265172466251994, 'dropout_rate_Layer_3': 0.3756294758500736, 'dropout_rate_Layer_4': 0.2647831116004442, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04126282354195751, 'l1_Layer_2': 0.0008453137790128601, 'l1_Layer_3': 0.05929934585209859, 'l1_Layer_4': 0.000184026408584693, 'n_units_Layer_1': 255, 'n_units_Layer_2': 140, 'n_units_Layer_3': 300, 'n_units_Layer_4': 210}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.33 | sMAPE for Validation Set is: 17.91% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.83 | sMAPE for Test Set is: 19.14% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:22:23,021]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:27,372]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:27,457]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:27,667]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:33,622]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:34,233]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:35,695]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:35,928]\u001b[0m Trial 722 finished with value: 27.412273616753037 and parameters: {'n_hidden': 3, 'learning_rate': 0.005252873957789791, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36122861538840073, 'dropout_rate_Layer_2': 0.03285607394999184, 'dropout_rate_Layer_3': 0.08534285668402466, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03696792504902125, 'l1_Layer_2': 3.2820230929781314e-05, 'l1_Layer_3': 0.0020835018331898164, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.41 | sMAPE for Validation Set is: 17.78% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.33 | sMAPE for Test Set is: 16.62% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:22:38,600]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:42,366]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:43,391]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:46,455]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:52,195]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:57,290]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:22:59,721]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:02,464]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:05,331]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:05,694]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:10,584]\u001b[0m Trial 731 finished with value: 25.988611248391965 and parameters: {'n_hidden': 3, 'learning_rate': 0.006933780067593077, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35891576970573313, 'dropout_rate_Layer_2': 0.1461631008239097, 'dropout_rate_Layer_3': 0.11125024448942442, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03460436828523121, 'l1_Layer_2': 3.442422833020937e-05, 'l1_Layer_3': 0.001711854422999747, 'n_units_Layer_1': 280, 'n_units_Layer_2': 115, 'n_units_Layer_3': 200}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.99 | sMAPE for Validation Set is: 17.07% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.66 | sMAPE for Test Set is: 17.80% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:23:11,206]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:11,599]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:17,145]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:17,760]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:22,179]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:23,644]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:24,482]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:25,990]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:26,978]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:29,524]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:29,763]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:34,902]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:35,911]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:38,760]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:39,628]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:40,390]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:43,899]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:46,126]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:46,886]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:49,771]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:52,726]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:54,887]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:54,986]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:23:56,678]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:00,199]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:04,371]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:05,411]\u001b[0m Trial 751 finished with value: 25.312349745041832 and parameters: {'n_hidden': 3, 'learning_rate': 0.007286701395178747, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08319615995458146, 'dropout_rate_Layer_2': 0.1364059534490152, 'dropout_rate_Layer_3': 0.10934909085850816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030153405567438308, 'l1_Layer_2': 0.0006081533605586711, 'l1_Layer_3': 0.00062870697277575, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 255}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.31 | sMAPE for Validation Set is: 16.47% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.63 | sMAPE for Test Set is: 15.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:24:07,561]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:09,616]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:11,636]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:15,405]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:15,745]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:15,865]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:16,042]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:25,904]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:26,283]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:29,509]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:32,968]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:36,558]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:37,021]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:37,203]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:41,828]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:42,116]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:45,267]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:47,872]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:50,320]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:52,167]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:53,973]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:56,452]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:58,723]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:59,376]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:24:59,724]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:01,915]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:02,766]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:09,504]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:10,273]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:14,639]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:15,093]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:19,384]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:20,175]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:22,482]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:25,051]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:27,861]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:27,976]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:30,673]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:33,381]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:37,356]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:41,496]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:44,704]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:47,835]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:50,260]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:52,138]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:54,714]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:55,031]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:25:55,463]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:00,088]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:00,787]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:01,350]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:03,759]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:06,844]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:07,995]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:11,609]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:16,719]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:18,061]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:21,773]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:23,880]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:26,530]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:26,719]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:26,978]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:33,393]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:35,599]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:35,696]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.98 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.38 | sMAPE for Test Set is: 16.50% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:26:40,064]\u001b[0m Trial 812 finished with value: 25.979421040960755 and parameters: {'n_hidden': 3, 'learning_rate': 0.003069118161648053, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3134555120109611, 'dropout_rate_Layer_2': 0.024429473317840015, 'dropout_rate_Layer_3': 0.16856751666460268, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.060679640771567664, 'l1_Layer_2': 0.0003448290676623347, 'l1_Layer_3': 0.0013798262549316119, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:43,069]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:46,619]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:50,183]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:53,767]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:26:57,736]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:00,747]\u001b[0m Trial 835 finished with value: 26.339501359107555 and parameters: {'n_hidden': 3, 'learning_rate': 0.002886473881803401, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3564153069877723, 'dropout_rate_Layer_2': 0.03533911296766822, 'dropout_rate_Layer_3': 0.15028284656080904, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06385369317046433, 'l1_Layer_2': 0.00032276632327914596, 'l1_Layer_3': 0.001090191083087267, 'n_units_Layer_1': 160, 'n_units_Layer_2': 240, 'n_units_Layer_3': 140}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.34 | sMAPE for Validation Set is: 17.31% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.43 | sMAPE for Test Set is: 17.20% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:27:03,988]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:14,686]\u001b[0m Trial 833 finished with value: 27.033955304316304 and parameters: {'n_hidden': 4, 'learning_rate': 0.004869796606279141, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1459626228411341, 'dropout_rate_Layer_2': 0.2909605616061776, 'dropout_rate_Layer_3': 0.38745876444848454, 'dropout_rate_Layer_4': 0.3305991621192001, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.589737599458786e-05, 'l1_Layer_2': 0.001336888291952589, 'l1_Layer_3': 0.012100304797869842, 'l1_Layer_4': 0.00016772810425933797, 'n_units_Layer_1': 260, 'n_units_Layer_2': 115, 'n_units_Layer_3': 255, 'n_units_Layer_4': 205}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.03 | sMAPE for Validation Set is: 17.51% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 16.42% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:27:17,408]\u001b[0m Trial 840 finished with value: 26.628938404053063 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032464860858522856, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21569089242697476, 'dropout_rate_Layer_2': 0.1552816818934087, 'dropout_rate_Layer_3': 0.11113034542512987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8261153888273056e-05, 'l1_Layer_2': 0.0002563360257439612, 'l1_Layer_3': 0.0008785797652447822, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 215}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.63 | sMAPE for Validation Set is: 17.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 16.28% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:27:19,655]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:22,151]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:24,004]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:27,055]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:30,113]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:30,627]\u001b[0m Trial 832 finished with value: 27.82752073895776 and parameters: {'n_hidden': 4, 'learning_rate': 0.007542416511125256, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1423352971898918, 'dropout_rate_Layer_2': 0.264444232082731, 'dropout_rate_Layer_3': 0.30812156174510436, 'dropout_rate_Layer_4': 0.3355236408194074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4142677023826647e-05, 'l1_Layer_2': 0.001285693436884209, 'l1_Layer_3': 0.016485288473695965, 'l1_Layer_4': 0.00018538473284498261, 'n_units_Layer_1': 180, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255, 'n_units_Layer_4': 265}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.83 | sMAPE for Validation Set is: 17.89% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.65 | sMAPE for Test Set is: 17.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:27:35,145]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:35,295]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:40,757]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:41,139]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:42,184]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:45,513]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:48,947]\u001b[0m Trial 850 finished with value: 82.46322303675338 and parameters: {'n_hidden': 4, 'learning_rate': 0.007433589374215008, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18063369550481662, 'dropout_rate_Layer_2': 0.29390543645708556, 'dropout_rate_Layer_3': 0.39060540694670315, 'dropout_rate_Layer_4': 0.330915295254147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.488129218284094e-05, 'l1_Layer_2': 0.008742064213346579, 'l1_Layer_3': 0.003503524936422898, 'l1_Layer_4': 0.0006914775725501466, 'n_units_Layer_1': 180, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215, 'n_units_Layer_4': 205}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 82.46 | sMAPE for Validation Set is: 47.70% | rMAE for Validation Set is: 1.52\n",
      "MAE for Test Set is: 19.98 | sMAPE for Test Set is: 36.84% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:27:49,167]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:52,251]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:55,906]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:55,967]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:27:57,729]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:01,406]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:04,626]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:06,132]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:06,531]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:11,970]\u001b[0m Trial 856 finished with value: 26.70322618780412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038647127512641275, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35548172638564557, 'dropout_rate_Layer_2': 0.04171837680753597, 'dropout_rate_Layer_3': 0.15978233558352703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.06313107336755093, 'l1_Layer_2': 0.00024509628971868945, 'l1_Layer_3': 0.0010074493884654815, 'n_units_Layer_1': 150, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.70 | sMAPE for Validation Set is: 17.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.36 | sMAPE for Test Set is: 16.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:28:13,821]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:16,735]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:23,007]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:26,196]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:29,531]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:32,969]\u001b[0m Trial 864 finished with value: 26.222753224381744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021869641948739464, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3810919872119457, 'dropout_rate_Layer_2': 0.029420094713612163, 'dropout_rate_Layer_3': 0.16328925606171385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.044294543141557084, 'l1_Layer_2': 0.0004506909525747777, 'l1_Layer_3': 0.0007847757630110702, 'n_units_Layer_1': 160, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.22 | sMAPE for Validation Set is: 17.16% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.06 | sMAPE for Test Set is: 16.10% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:28:33,573]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:37,232]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:39,893]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:43,847]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:44,060]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.73 | sMAPE for Validation Set is: 17.85% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 12.58 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:28:47,504]\u001b[0m Trial 865 finished with value: 27.73334313666133 and parameters: {'n_hidden': 4, 'learning_rate': 0.006218441543371048, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16272644585698567, 'dropout_rate_Layer_2': 0.2728429217330242, 'dropout_rate_Layer_3': 0.309674978731671, 'dropout_rate_Layer_4': 0.3892858135616736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.7151642649373755e-05, 'l1_Layer_2': 0.0014931506158605882, 'l1_Layer_3': 0.005798058326870788, 'l1_Layer_4': 0.00015301238744094557, 'n_units_Layer_1': 260, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245, 'n_units_Layer_4': 195}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:50,086]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:52,878]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:53,739]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:28:58,466]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:02,750]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:03,216]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:08,506]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:08,723]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:13,891]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:17,950]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:21,285]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:35,112]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:39,662]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:43,181]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:44,980]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:48,326]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:50,165]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:29:55,566]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:11,891]\u001b[0m Trial 895 finished with value: 25.77989110087105 and parameters: {'n_hidden': 3, 'learning_rate': 0.002575427536281521, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02083793335767462, 'dropout_rate_Layer_2': 0.22202591655548673, 'dropout_rate_Layer_3': 0.3713534609760557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5191977563567185e-05, 'l1_Layer_2': 0.0008089443435090599, 'l1_Layer_3': 0.0005756266137711913, 'n_units_Layer_1': 180, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.78 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.69 | sMAPE for Test Set is: 15.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:30:16,723]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:18,880]\u001b[0m Trial 897 finished with value: 29.498966701510238 and parameters: {'n_hidden': 4, 'learning_rate': 0.004919139561815507, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1666007693387808, 'dropout_rate_Layer_2': 0.2713800713430744, 'dropout_rate_Layer_3': 0.32942837415504916, 'dropout_rate_Layer_4': 0.36089108714971574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 2.499165556797441e-05, 'l1_Layer_2': 0.0018507152327720876, 'l1_Layer_3': 0.00938462503496601, 'l1_Layer_4': 0.0002691835688937491, 'n_units_Layer_1': 195, 'n_units_Layer_2': 140, 'n_units_Layer_3': 230, 'n_units_Layer_4': 190}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.50 | sMAPE for Validation Set is: 18.86% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 15.10 | sMAPE for Test Set is: 21.08% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:30:19,635]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:19,935]\u001b[0m Trial 868 finished with value: 28.276315203858488 and parameters: {'n_hidden': 4, 'learning_rate': 0.010374302649235634, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15913262573381126, 'dropout_rate_Layer_2': 0.3129300988547404, 'dropout_rate_Layer_3': 0.3286288416476788, 'dropout_rate_Layer_4': 0.34488649201649507, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.992514929593126e-05, 'l1_Layer_2': 0.0014605865578410048, 'l1_Layer_3': 0.005658047836760981, 'l1_Layer_4': 0.0003191606103378374, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245, 'n_units_Layer_4': 265}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.28 | sMAPE for Validation Set is: 18.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.85 | sMAPE for Test Set is: 19.03% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:30:22,408]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:26,162]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:26,223]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:30,912]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:34,354]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:34,718]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:39,998]\u001b[0m Trial 903 finished with value: 39.51801195593519 and parameters: {'n_hidden': 4, 'learning_rate': 0.015696152747712095, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16148001086910477, 'dropout_rate_Layer_2': 0.3260443066953843, 'dropout_rate_Layer_3': 0.3150468361374159, 'dropout_rate_Layer_4': 0.3867854071653407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.8686713252071285e-05, 'l1_Layer_2': 0.0028737209102733816, 'l1_Layer_3': 0.0008065265003113746, 'l1_Layer_4': 0.0005388592333852192, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 39.52 | sMAPE for Validation Set is: 24.46% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 18.06 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:30:41,022]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:44,470]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:46,142]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:48,922]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:49,860]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:51,473]\u001b[0m Trial 887 finished with value: 28.578877713755748 and parameters: {'n_hidden': 4, 'learning_rate': 0.006310948539809881, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16695960620411093, 'dropout_rate_Layer_2': 0.31521241227659336, 'dropout_rate_Layer_3': 0.293353336041312, 'dropout_rate_Layer_4': 0.3861741436506878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4748908868885366e-05, 'l1_Layer_2': 0.001288990994316683, 'l1_Layer_3': 0.0059194913408154685, 'l1_Layer_4': 0.0004999610493855637, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 230, 'n_units_Layer_4': 185}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.58 | sMAPE for Validation Set is: 18.80% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 15.26 | sMAPE for Test Set is: 20.45% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:30:52,459]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:58,160]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:30:59,549]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:02,073]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:04,292]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:05,055]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:07,254]\u001b[0m Trial 907 finished with value: 28.110891797640246 and parameters: {'n_hidden': 4, 'learning_rate': 0.006148795584906375, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13265447896761898, 'dropout_rate_Layer_2': 0.3149600386664367, 'dropout_rate_Layer_3': 0.3092826562823323, 'dropout_rate_Layer_4': 0.385319467225308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.011632350087653e-05, 'l1_Layer_2': 0.002957424449237096, 'l1_Layer_3': 0.0053914259242469524, 'l1_Layer_4': 0.000513799051225584, 'n_units_Layer_1': 260, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265, 'n_units_Layer_4': 265}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.11 | sMAPE for Validation Set is: 18.10% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 12.65 | sMAPE for Test Set is: 16.91% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:31:08,741]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:09,619]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:11,130]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:14,481]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:18,397]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:18,478]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:20,089]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:25,551]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:26,344]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:26,522]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:26,811]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:29,818]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:33,813]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:34,664]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:37,388]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:38,312]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:42,419]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:45,761]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:46,243]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:49,380]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:51,835]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:53,845]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:54,002]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:31:55,340]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:00,627]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:00,914]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:01,119]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:01,365]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:06,224]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:07,490]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:08,393]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:08,658]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:14,735]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:14,851]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:19,678]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:21,701]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:23,765]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:26,941]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:27,227]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:32,007]\u001b[0m Trial 954 finished with value: 26.130322041680248 and parameters: {'n_hidden': 3, 'learning_rate': 0.003429023889499377, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38502367334745125, 'dropout_rate_Layer_2': 0.14840989830267165, 'dropout_rate_Layer_3': 0.29467899200633757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0604995935648026, 'l1_Layer_2': 0.00021766215350799435, 'l1_Layer_3': 0.0007415046644453807, 'n_units_Layer_1': 85, 'n_units_Layer_2': 245, 'n_units_Layer_3': 155}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.13 | sMAPE for Validation Set is: 17.08% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.57 | sMAPE for Test Set is: 17.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:32:35,000]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:43,436]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:43,842]\u001b[0m Trial 962 finished with value: 26.680936937327715 and parameters: {'n_hidden': 3, 'learning_rate': 0.004769402379608954, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19042104355945552, 'dropout_rate_Layer_2': 0.1596799168094912, 'dropout_rate_Layer_3': 0.38713866504483385, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.1905441140603164e-05, 'l1_Layer_2': 0.00013771295140162308, 'l1_Layer_3': 0.00041396003415053207, 'n_units_Layer_1': 150, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.68 | sMAPE for Validation Set is: 17.37% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.18 | sMAPE for Test Set is: 16.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:32:47,607]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:47,744]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:52,258]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:52,552]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.35 | sMAPE for Validation Set is: 17.17% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.20 | sMAPE for Test Set is: 16.20% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:32:55,246]\u001b[0m Trial 963 finished with value: 26.34868036976074 and parameters: {'n_hidden': 3, 'learning_rate': 0.013306573653955173, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009401531707246488, 'dropout_rate_Layer_2': 0.08144785432477805, 'dropout_rate_Layer_3': 0.06764875833969329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001666520240034424, 'l1_Layer_2': 0.0006235503558288934, 'l1_Layer_3': 0.0022990917154128575, 'n_units_Layer_1': 235, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:58,105]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:32:59,236]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:01,599]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:03,719]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:05,124]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:06,288]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:09,241]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:10,607]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:13,075]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:16,558]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:17,687]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:18,991]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:22,800]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:23,470]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:24,865]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:26,860]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:32,752]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:37,469]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:38,112]\u001b[0m Trial 960 finished with value: 28.43346419098657 and parameters: {'n_hidden': 4, 'learning_rate': 0.005102110143896362, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09780065131358286, 'dropout_rate_Layer_2': 0.3573380084086385, 'dropout_rate_Layer_3': 0.28800700175146854, 'dropout_rate_Layer_4': 0.37258021240145933, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.107054730475082e-05, 'l1_Layer_2': 0.002009660621944929, 'l1_Layer_3': 0.005134642155568598, 'l1_Layer_4': 0.0009981558007868493, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 280, 'n_units_Layer_4': 265}. Best is trial 505 with value: 24.809020223678882.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.43 | sMAPE for Validation Set is: 18.22% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 17.34% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:33:42,368]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:42,953]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:44,024]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:45,447]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:46,072]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:50,138]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:51,843]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:53,473]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:54,684]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:33:59,657]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:01,527]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:02,370]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:07,813]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:10,036]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:10,233]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:12,116]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:16,727]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:17,422]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:18,362]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:23,541]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:25,896]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:26,292]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:26,769]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:33,921]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:34,500]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:39,680]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:40,979]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:43,202]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:44,342]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:46,848]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:50,181]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:54,479]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:34:57,309]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:00,006]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:00,804]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:07,382]\u001b[0m Trial 997 finished with value: 24.424084660561835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0042308758248487946, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05405022122352427, 'dropout_rate_Layer_2': 0.06888080976080752, 'dropout_rate_Layer_3': 0.15586354437753053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002505602408222332, 'l1_Layer_2': 0.0011195792839591738, 'l1_Layer_3': 0.0017156692080779856, 'n_units_Layer_1': 255, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.42 | sMAPE for Validation Set is: 16.14% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 15.36% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:35:10,635]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:14,563]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:18,318]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:22,265]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:22,568]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:26,094]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:27,480]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:29,514]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:31,146]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:33,431]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:34,546]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:35,184]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:39,502]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:41,413]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:42,313]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:44,802]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:49,568]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:50,515]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:50,764]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:55,346]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:35:57,474]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:04,501]\u001b[0m Trial 1043 finished with value: 26.08144655412136 and parameters: {'n_hidden': 3, 'learning_rate': 0.006557816293494183, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.037818413621554164, 'dropout_rate_Layer_2': 0.10309968264334306, 'dropout_rate_Layer_3': 0.16239294291286308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003204858650215027, 'l1_Layer_2': 0.0015320394753620956, 'l1_Layer_3': 0.0021372957466863495, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.08 | sMAPE for Validation Set is: 16.80% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.82 | sMAPE for Test Set is: 15.88% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:36:08,037]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:08,057]\u001b[0m Trial 1029 finished with value: 28.359494012001505 and parameters: {'n_hidden': 4, 'learning_rate': 0.00435246644039107, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11725555050206288, 'dropout_rate_Layer_2': 0.30544901743964287, 'dropout_rate_Layer_3': 0.2586367819152003, 'dropout_rate_Layer_4': 0.339323749291488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 9.669576011327589e-05, 'l1_Layer_2': 0.005099692762480572, 'l1_Layer_3': 0.0037818280335380344, 'l1_Layer_4': 0.0012429333003770961, 'n_units_Layer_1': 265, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280, 'n_units_Layer_4': 285}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.36 | sMAPE for Validation Set is: 18.25% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 13.47 | sMAPE for Test Set is: 18.06% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:36:10,208]\u001b[0m Trial 1045 finished with value: 26.81592972503472 and parameters: {'n_hidden': 3, 'learning_rate': 0.021935100900217774, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002420868419977594, 'dropout_rate_Layer_2': 0.044846988913867944, 'dropout_rate_Layer_3': 0.3401931728767457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0032790879600749037, 'l1_Layer_2': 0.0015947418824215898, 'l1_Layer_3': 0.00208991572718896, 'n_units_Layer_1': 240, 'n_units_Layer_2': 185, 'n_units_Layer_3': 230}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.82 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 16.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:36:15,585]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:16,501]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:21,132]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:21,573]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:26,037]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:29,234]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:33,354]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:33,722]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:39,463]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:39,857]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:45,515]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:45,621]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:50,799]\u001b[0m Trial 1046 finished with value: 32.386187003595644 and parameters: {'n_hidden': 4, 'learning_rate': 0.004523673942232044, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10489489803958041, 'dropout_rate_Layer_2': 0.35229820034673054, 'dropout_rate_Layer_3': 0.2695486726494287, 'dropout_rate_Layer_4': 0.36660996718384603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.005731429841045e-05, 'l1_Layer_2': 0.0068063297763634205, 'l1_Layer_3': 0.004008862423475544, 'l1_Layer_4': 0.0017176687311201283, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265, 'n_units_Layer_4': 295}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 32.39 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 14.69 | sMAPE for Test Set is: 19.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:36:54,599]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:57,625]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:57,670]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:36:58,510]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:04,147]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:05,782]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:05,840]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:08,045]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:13,630]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:13,711]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:14,227]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:23,534]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:29,226]\u001b[0m Trial 1059 finished with value: 29.915146011689078 and parameters: {'n_hidden': 4, 'learning_rate': 0.004544893472961667, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11990882947313808, 'dropout_rate_Layer_2': 0.2889255703905389, 'dropout_rate_Layer_3': 0.25593595125934143, 'dropout_rate_Layer_4': 0.35302935543294534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010742477245690399, 'l1_Layer_2': 0.004509873840466288, 'l1_Layer_3': 0.003801006002899276, 'l1_Layer_4': 0.0017129031697540426, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265, 'n_units_Layer_4': 280}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.92 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 13.99 | sMAPE for Test Set is: 18.80% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:37:32,832]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:35,476]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:38,078]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:41,251]\u001b[0m Trial 1075 finished with value: 172.98928649889913 and parameters: {'n_hidden': 4, 'learning_rate': 0.03461568879742245, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12029827467599506, 'dropout_rate_Layer_2': 0.28997442001837304, 'dropout_rate_Layer_3': 0.26142586075063173, 'dropout_rate_Layer_4': 0.3263489958125428, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.950582141155222e-05, 'l1_Layer_2': 0.018777971711306365, 'l1_Layer_3': 0.008068731091830263, 'l1_Layer_4': 0.002307264421457303, 'n_units_Layer_1': 290, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290, 'n_units_Layer_4': 280}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 172.99 | sMAPE for Validation Set is: 151.95% | rMAE for Validation Set is: 3.18\n",
      "MAE for Test Set is: 70.60 | sMAPE for Test Set is: 123.22% | rMAE for Test Set is: 3.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:37:42,007]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:42,794]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:46,961]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:49,646]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:52,375]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:55,394]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:37:57,824]\u001b[0m Trial 1073 finished with value: 25.620001057914738 and parameters: {'n_hidden': 3, 'learning_rate': 0.005310580649334171, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08779945715446234, 'dropout_rate_Layer_2': 0.10454704074296917, 'dropout_rate_Layer_3': 0.17621933043223997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0038533232644690314, 'l1_Layer_2': 0.0013688476424181188, 'l1_Layer_3': 0.001443697728762005, 'n_units_Layer_1': 265, 'n_units_Layer_2': 180, 'n_units_Layer_3': 255}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.62 | sMAPE for Validation Set is: 16.69% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.76 | sMAPE for Test Set is: 15.65% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:38:01,464]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:02,166]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:02,690]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:06,975]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:08,779]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:09,027]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:13,743]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:13,950]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:18,575]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:18,977]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:24,328]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:27,250]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:29,547]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:29,602]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:30,844]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:32,823]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:37,705]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:37,953]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:39,660]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:41,111]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:47,955]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:48,722]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:53,663]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:54,411]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:38:55,249]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:03,117]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:04,800]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:09,034]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:09,768]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:15,196]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:17,394]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:19,904]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:22,011]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:23,083]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:23,233]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:26,887]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:27,683]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:31,488]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:34,256]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:34,311]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:40,677]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:40,949]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:46,036]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:49,427]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:52,549]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:56,228]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:39:59,881]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:08,279]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:11,362]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:14,329]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:17,798]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:17,989]\u001b[0m Trial 1125 finished with value: 30.784770549708906 and parameters: {'n_hidden': 4, 'learning_rate': 0.005916434017548419, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11088342438465665, 'dropout_rate_Layer_2': 0.30952822859545626, 'dropout_rate_Layer_3': 0.307405150416837, 'dropout_rate_Layer_4': 0.3770341786608206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.865204882985337e-05, 'l1_Layer_2': 0.0020313817838898767, 'l1_Layer_3': 0.004848461925374388, 'l1_Layer_4': 0.00016227317230408774, 'n_units_Layer_1': 270, 'n_units_Layer_2': 205, 'n_units_Layer_3': 285, 'n_units_Layer_4': 270}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.78 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 15.24 | sMAPE for Test Set is: 20.96% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:40:21,226]\u001b[0m Trial 1129 finished with value: 30.805754282157068 and parameters: {'n_hidden': 4, 'learning_rate': 0.005306857209625087, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09829464255491327, 'dropout_rate_Layer_2': 0.2771380488205156, 'dropout_rate_Layer_3': 0.3012561430589764, 'dropout_rate_Layer_4': 0.37438765182251893, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.9158093267503067e-05, 'l1_Layer_2': 0.0023133769558934198, 'l1_Layer_3': 0.004480607182450409, 'l1_Layer_4': 0.00015821213364646656, 'n_units_Layer_1': 270, 'n_units_Layer_2': 185, 'n_units_Layer_3': 280, 'n_units_Layer_4': 270}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.81 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 13.83 | sMAPE for Test Set is: 18.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:40:24,767]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:28,834]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:29,432]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:34,315]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:35,384]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:35,419]\u001b[0m Trial 1121 finished with value: 28.595291574454176 and parameters: {'n_hidden': 4, 'learning_rate': 0.0053939280792099946, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1136079849895483, 'dropout_rate_Layer_2': 0.32681569621887563, 'dropout_rate_Layer_3': 0.31176305375325203, 'dropout_rate_Layer_4': 0.36857965715434615, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8616505149952398e-05, 'l1_Layer_2': 0.0021090581766340763, 'l1_Layer_3': 0.005319571793536923, 'l1_Layer_4': 0.00031735733144809894, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280, 'n_units_Layer_4': 270}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.60 | sMAPE for Validation Set is: 18.37% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 13.50 | sMAPE for Test Set is: 17.46% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:40:41,378]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:42,021]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:42,168]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:47,035]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:48,142]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:49,589]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:50,094]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:54,809]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:57,426]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:58,579]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:58,708]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:40:59,559]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:05,829]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:09,905]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:13,540]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:15,743]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:18,047]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:21,452]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:24,466]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:25,832]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:28,299]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:31,315]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:33,364]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:35,534]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:38,081]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:39,673]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:43,115]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:43,850]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:45,166]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:47,866]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:50,671]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:55,185]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:41:56,106]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:01,504]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:02,310]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:02,742]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:07,577]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:13,654]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:17,475]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:21,722]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:24,798]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:29,103]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:31,201]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:33,232]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:37,209]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:39,059]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:40,913]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:42,414]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:45,143]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:46,067]\u001b[0m Trial 1155 finished with value: 40.31551610274909 and parameters: {'n_hidden': 4, 'learning_rate': 0.0066319051542280925, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1524841099373625, 'dropout_rate_Layer_2': 0.351330873499365, 'dropout_rate_Layer_3': 0.35186869083858385, 'dropout_rate_Layer_4': 0.35114588266749114, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.798449164887322e-05, 'l1_Layer_2': 0.0014088771395333957, 'l1_Layer_3': 0.017920107804860464, 'l1_Layer_4': 0.0009136512680809829, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 295, 'n_units_Layer_4': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.32 | sMAPE for Validation Set is: 26.68% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 19.91 | sMAPE for Test Set is: 25.64% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:42:46,472]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:53,341]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:53,610]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:58,722]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:42:59,588]\u001b[0m Trial 1182 finished with value: 29.26013539502075 and parameters: {'n_hidden': 4, 'learning_rate': 0.006678353811614378, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1489328331334519, 'dropout_rate_Layer_2': 0.3817800865794635, 'dropout_rate_Layer_3': 0.34175960900058244, 'dropout_rate_Layer_4': 0.35443952673416806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.644227474728179e-05, 'l1_Layer_2': 0.0008373165071743445, 'l1_Layer_3': 0.002093283041375295, 'l1_Layer_4': 0.0009559533312539678, 'n_units_Layer_1': 295, 'n_units_Layer_2': 170, 'n_units_Layer_3': 260, 'n_units_Layer_4': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 29.26 | sMAPE for Validation Set is: 19.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 13.69 | sMAPE for Test Set is: 18.40% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:43:04,032]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:04,542]\u001b[0m Trial 1195 finished with value: 26.19447355124538 and parameters: {'n_hidden': 3, 'learning_rate': 0.013248028453508956, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013284026250071952, 'dropout_rate_Layer_2': 0.0715837996270341, 'dropout_rate_Layer_3': 0.22717888227686214, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030216895911222032, 'l1_Layer_2': 0.0020899868178598166, 'l1_Layer_3': 0.0011919252796541641, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.19 | sMAPE for Validation Set is: 16.94% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.49 | sMAPE for Test Set is: 16.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:43:07,848]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:10,387]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:11,367]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:14,208]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:20,120]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:21,960]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:26,337]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:31,261]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:34,751]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:38,348]\u001b[0m Trial 1208 finished with value: 26.66113169940935 and parameters: {'n_hidden': 3, 'learning_rate': 0.010509582834566841, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016111177555561313, 'dropout_rate_Layer_2': 0.10349999589786116, 'dropout_rate_Layer_3': 0.22969831340542318, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013650218870355085, 'l1_Layer_2': 0.003563555144743148, 'l1_Layer_3': 0.0018466750449557883, 'n_units_Layer_1': 215, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.66 | sMAPE for Validation Set is: 17.32% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.51 | sMAPE for Test Set is: 16.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:43:38,633]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:43,853]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:44,002]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:49,008]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:49,346]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:55,328]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:43:56,489]\u001b[0m Trial 1209 finished with value: 25.576383686841535 and parameters: {'n_hidden': 3, 'learning_rate': 0.009398763221214582, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015729254413530062, 'dropout_rate_Layer_2': 0.05834534668267776, 'dropout_rate_Layer_3': 0.21940590085088302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.05647711319769409, 'l1_Layer_2': 0.002286382953800709, 'l1_Layer_3': 0.00124777259804961, 'n_units_Layer_1': 215, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.58 | sMAPE for Validation Set is: 16.71% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.39 | sMAPE for Test Set is: 15.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:43:56,640]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:02,904]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:07,131]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:07,344]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:07,572]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:13,199]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:15,185]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:15,833]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:20,452]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:21,705]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:25,989]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:28,447]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:30,386]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:33,158]\u001b[0m Trial 1221 finished with value: 25.919625544221713 and parameters: {'n_hidden': 3, 'learning_rate': 0.012396643074182662, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006875049293572447, 'dropout_rate_Layer_2': 0.056833543925578774, 'dropout_rate_Layer_3': 0.2415055027841763, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.032002978170564245, 'l1_Layer_2': 0.002159038594675764, 'l1_Layer_3': 0.0013574976380113792, 'n_units_Layer_1': 210, 'n_units_Layer_2': 175, 'n_units_Layer_3': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.92 | sMAPE for Validation Set is: 16.86% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.10 | sMAPE for Test Set is: 15.94% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:44:37,181]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:39,797]\u001b[0m Trial 1226 finished with value: 26.03517050395465 and parameters: {'n_hidden': 3, 'learning_rate': 0.009313961594933038, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0058629349118309165, 'dropout_rate_Layer_2': 0.07097117368441533, 'dropout_rate_Layer_3': 0.21380897802916882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03306390825150903, 'l1_Layer_2': 0.00225578904926745, 'l1_Layer_3': 0.0004293200442064941, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 235}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.04 | sMAPE for Validation Set is: 16.90% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.92 | sMAPE for Test Set is: 15.78% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:44:42,878]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:45,261]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:45,833]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:46,983]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:54,367]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:55,052]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:44:59,209]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:00,595]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:04,444]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:06,827]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:09,429]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:09,470]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:15,485]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:16,100]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:20,840]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:22,111]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:22,160]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:26,191]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:31,100]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:32,070]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:32,968]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:38,863]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:40,264]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:40,881]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:46,130]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:47,316]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:51,978]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:52,171]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:58,513]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:45:58,671]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:04,349]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:04,583]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:09,488]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:13,832]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:17,212]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:17,472]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:22,695]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:26,129]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:29,012]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:30,589]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:35,053]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:35,631]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:40,895]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:41,106]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:41,872]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:51,086]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:51,311]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:57,597]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:46:57,786]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:03,175]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:08,145]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:11,350]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:15,319]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:15,926]\u001b[0m Trial 1262 finished with value: 28.148575807199354 and parameters: {'n_hidden': 4, 'learning_rate': 0.00410617409062039, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12601387390614388, 'dropout_rate_Layer_2': 0.3090223688221873, 'dropout_rate_Layer_3': 0.3237304546724375, 'dropout_rate_Layer_4': 0.37957370953752917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001455778852407405, 'l1_Layer_2': 0.0011599317637753278, 'l1_Layer_3': 0.008429594458617407, 'l1_Layer_4': 0.00044933637489717976, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270, 'n_units_Layer_4': 250}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.15 | sMAPE for Validation Set is: 18.59% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 14.29 | sMAPE for Test Set is: 19.40% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:47:18,524]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:22,402]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:25,896]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:26,079]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:30,516]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:31,383]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:31,676]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:38,898]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:39,255]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:43,204]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:46,686]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:49,788]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:50,490]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:51,603]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:55,744]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:57,541]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:47:59,162]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:04,030]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:04,278]\u001b[0m Trial 1299 finished with value: 26.206705348693685 and parameters: {'n_hidden': 3, 'learning_rate': 0.008209958060397227, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04609607899541192, 'dropout_rate_Layer_2': 0.07690190258783655, 'dropout_rate_Layer_3': 0.12516138629233445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04323985010435264, 'l1_Layer_2': 0.001020773949789828, 'l1_Layer_3': 0.00036530499323123234, 'n_units_Layer_1': 230, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.21 | sMAPE for Validation Set is: 16.95% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 16.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:48:05,241]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:09,006]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:09,950]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:14,321]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:15,456]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:16,186]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:22,843]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:24,501]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:24,901]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:25,576]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:31,399]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:33,713]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:37,117]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:37,678]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:40,260]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:42,501]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:43,216]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:47,077]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:47,432]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:51,729]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:56,194]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:59,769]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:48:59,986]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:06,242]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:07,891]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:12,225]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:15,425]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:20,236]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:23,980]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:27,489]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:30,613]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:34,224]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:38,241]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:41,593]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:46,867]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:49:51,827]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:07,950]\u001b[0m Trial 1327 finished with value: 28.979599231224046 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025329958208310404, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10589570251856834, 'dropout_rate_Layer_2': 0.31808922745060003, 'dropout_rate_Layer_3': 0.3248093481362557, 'dropout_rate_Layer_4': 0.31840336862859303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.3170716116028105e-05, 'l1_Layer_2': 0.0011142613116772184, 'l1_Layer_3': 0.006522388031132193, 'l1_Layer_4': 0.0002227610079064217, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 245, 'n_units_Layer_4': 240}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.98 | sMAPE for Validation Set is: 19.01% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 16.34 | sMAPE for Test Set is: 22.42% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:50:10,798]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:13,191]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:15,877]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:17,755]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:21,350]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:37,094]\u001b[0m Trial 1351 finished with value: 26.08727461382109 and parameters: {'n_hidden': 3, 'learning_rate': 0.015197811974820504, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015746214684292416, 'dropout_rate_Layer_2': 0.06903402572347389, 'dropout_rate_Layer_3': 0.23447929320968827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.030678472305177982, 'l1_Layer_2': 0.0020749136103269806, 'l1_Layer_3': 0.0012493834999233908, 'n_units_Layer_1': 220, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.09 | sMAPE for Validation Set is: 17.05% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 15.84% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:50:40,625]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:44,995]\u001b[0m Trial 1325 finished with value: 26.33455486268527 and parameters: {'n_hidden': 4, 'learning_rate': 0.005939162207847106, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08998792625468313, 'dropout_rate_Layer_2': 0.28112289206507285, 'dropout_rate_Layer_3': 0.32556616178960385, 'dropout_rate_Layer_4': 0.3207051421784055, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002271928953877334, 'l1_Layer_2': 0.0011550427705721, 'l1_Layer_3': 0.00630202461214004, 'l1_Layer_4': 0.00022076271466747868, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260, 'n_units_Layer_4': 250}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.33 | sMAPE for Validation Set is: 17.35% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 13.23 | sMAPE for Test Set is: 18.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:50:45,591]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:46,351]\u001b[0m Trial 1349 finished with value: 25.405978965337496 and parameters: {'n_hidden': 3, 'learning_rate': 0.004780368696759316, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2276278302633465, 'dropout_rate_Layer_2': 0.033613139191649696, 'dropout_rate_Layer_3': 0.2863966317758051, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04287474865149837, 'l1_Layer_2': 4.349066815669343e-05, 'l1_Layer_3': 0.0009686177749268678, 'n_units_Layer_1': 160, 'n_units_Layer_2': 225, 'n_units_Layer_3': 180}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.41 | sMAPE for Validation Set is: 16.64% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 15.87% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:50:50,401]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:51,796]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:55,479]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:50:57,867]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:02,772]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:02,948]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:07,467]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:11,328]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:14,108]\u001b[0m Trial 1359 finished with value: 27.010004148556533 and parameters: {'n_hidden': 3, 'learning_rate': 0.019314346517237728, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018405182445423714, 'dropout_rate_Layer_2': 0.05036551536729878, 'dropout_rate_Layer_3': 0.22601696381869346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03056539105951688, 'l1_Layer_2': 0.0015381757958487703, 'l1_Layer_3': 0.0014002581795735046, 'n_units_Layer_1': 220, 'n_units_Layer_2': 185, 'n_units_Layer_3': 240}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.01 | sMAPE for Validation Set is: 17.39% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.70 | sMAPE for Test Set is: 16.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:51:16,910]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:19,830]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:23,928]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:25,200]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:27,787]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:28,382]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:33,798]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:33,917]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:39,584]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:40,398]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:41,865]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:47,821]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:51,580]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:51,803]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:56,947]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:57,262]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:51:57,872]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:06,521]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:07,015]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:11,063]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:11,973]\u001b[0m Trial 1334 finished with value: 30.168497296478503 and parameters: {'n_hidden': 4, 'learning_rate': 0.005081039155221903, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1022734763593922, 'dropout_rate_Layer_2': 0.31375280991854376, 'dropout_rate_Layer_3': 0.3209284933097484, 'dropout_rate_Layer_4': 0.3798770619805829, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.468607585724529e-05, 'l1_Layer_2': 0.0010259836884447735, 'l1_Layer_3': 0.012387448596151788, 'l1_Layer_4': 0.0002258104750672885, 'n_units_Layer_1': 275, 'n_units_Layer_2': 160, 'n_units_Layer_3': 260, 'n_units_Layer_4': 250}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.17 | sMAPE for Validation Set is: 19.11% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.04 | sMAPE for Test Set is: 19.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:52:13,028]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:15,830]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:20,024]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:23,591]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:24,014]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:28,537]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:31,650]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:34,680]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:39,035]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:43,991]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:47,386]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:50,680]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:52,548]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:54,371]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:52:58,325]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:08,185]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:10,600]\u001b[0m Trial 1399 finished with value: 26.22690986191982 and parameters: {'n_hidden': 3, 'learning_rate': 0.012973326514907457, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013514764789485288, 'dropout_rate_Layer_2': 0.07429143833445412, 'dropout_rate_Layer_3': 0.24841391284011527, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.025821340380332753, 'l1_Layer_2': 0.0022611118593556085, 'l1_Layer_3': 0.001206443902171209, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.23 | sMAPE for Validation Set is: 16.93% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.81 | sMAPE for Test Set is: 15.74% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:53:11,983]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:15,184]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:17,959]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:20,075]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:22,539]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:24,949]\u001b[0m Trial 1382 finished with value: 27.254331132377217 and parameters: {'n_hidden': 4, 'learning_rate': 0.004450526044021346, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08757297638642664, 'dropout_rate_Layer_2': 0.2813857341219331, 'dropout_rate_Layer_3': 0.3447760639742161, 'dropout_rate_Layer_4': 0.33403070959481224, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002062965863857108, 'l1_Layer_2': 0.0008587073628169561, 'l1_Layer_3': 0.011155792005540552, 'l1_Layer_4': 0.00012918362885275386, 'n_units_Layer_1': 245, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260, 'n_units_Layer_4': 250}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.25 | sMAPE for Validation Set is: 18.23% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 15.85 | sMAPE for Test Set is: 21.90% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:53:25,445]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:26,921]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:32,578]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:34,321]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:38,004]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:42,765]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:46,764]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:50,438]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:54,528]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:53:55,134]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:00,335]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:02,344]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:04,368]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:06,918]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:09,583]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:13,626]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:16,792]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:19,422]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:22,702]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:23,152]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:26,880]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:28,764]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:37,965]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:41,412]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:54:50,109]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:00,157]\u001b[0m Trial 1429 finished with value: 30.66247338735414 and parameters: {'n_hidden': 3, 'learning_rate': 0.002739474677557109, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1875797741445481, 'dropout_rate_Layer_2': 0.26810703011259013, 'dropout_rate_Layer_3': 0.3750445735396115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004260418218407804, 'l1_Layer_2': 0.0015323500389243195, 'l1_Layer_3': 0.0693497876782181, 'n_units_Layer_1': 260, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 30.66 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 13.64 | sMAPE for Test Set is: 17.98% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:55:03,869]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:07,867]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:11,283]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:13,730]\u001b[0m Trial 1434 finished with value: 26.215469434696427 and parameters: {'n_hidden': 3, 'learning_rate': 0.014303526412397575, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006762422273118648, 'dropout_rate_Layer_2': 0.09312913909074236, 'dropout_rate_Layer_3': 0.23110455492949517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02122373273263475, 'l1_Layer_2': 0.00282749446019928, 'l1_Layer_3': 0.0016020434739748984, 'n_units_Layer_1': 240, 'n_units_Layer_2': 195, 'n_units_Layer_3': 245}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.22 | sMAPE for Validation Set is: 17.00% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.99 | sMAPE for Test Set is: 15.89% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:55:16,955]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:20,068]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:21,013]\u001b[0m Trial 1431 finished with value: 27.343000583622047 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032627460316885758, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16172432637352682, 'dropout_rate_Layer_2': 0.23921213610826608, 'dropout_rate_Layer_3': 0.37402664638695665, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005057814014490904, 'l1_Layer_2': 0.0015911044135709243, 'l1_Layer_3': 0.006997069422484202, 'n_units_Layer_1': 145, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.34 | sMAPE for Validation Set is: 18.01% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 13.01 | sMAPE for Test Set is: 17.48% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:55:22,929]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:25,402]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:30,806]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:35,950]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:38,105]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:41,188]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:42,586]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:46,053]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:49,625]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:51,453]\u001b[0m Trial 1443 finished with value: 26.00203649391065 and parameters: {'n_hidden': 3, 'learning_rate': 0.011866304085151217, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015720653551043802, 'dropout_rate_Layer_2': 0.03712625253929139, 'dropout_rate_Layer_3': 0.23937486778788603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0306405773882648, 'l1_Layer_2': 0.002078622775278312, 'l1_Layer_3': 0.000992573975190799, 'n_units_Layer_1': 210, 'n_units_Layer_2': 170, 'n_units_Layer_3': 250}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.00 | sMAPE for Validation Set is: 17.09% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 16.39% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:55:52,771]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:54,500]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:58,755]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:55:59,346]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:03,830]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:12,045]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:16,503]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:17,908]\u001b[0m Trial 1455 finished with value: 25.975730188636586 and parameters: {'n_hidden': 3, 'learning_rate': 0.011694664447474789, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01914055831245713, 'dropout_rate_Layer_2': 0.021484934403065495, 'dropout_rate_Layer_3': 0.2525775421811636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008018407983707473, 'l1_Layer_2': 0.0009277130247646165, 'l1_Layer_3': 0.0004935456846511417, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 195}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 25.98 | sMAPE for Validation Set is: 16.92% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 15.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:56:21,471]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:25,954]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 27.36 | sMAPE for Validation Set is: 17.82% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.52 | sMAPE for Test Set is: 17.05% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:56:27,841]\u001b[0m Trial 1442 finished with value: 27.3576763488061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033884173416578083, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17707172624437212, 'dropout_rate_Layer_2': 0.23953557410100912, 'dropout_rate_Layer_3': 0.39331033762963, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0047847271662412325, 'l1_Layer_2': 0.0008540233670663523, 'l1_Layer_3': 0.006570938229433004, 'n_units_Layer_1': 160, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:30,586]\u001b[0m Trial 1456 finished with value: 26.931373284506844 and parameters: {'n_hidden': 3, 'learning_rate': 0.003988709505122903, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30520240127446524, 'dropout_rate_Layer_2': 0.14716133207690066, 'dropout_rate_Layer_3': 0.33895011364172506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.008662251674423e-05, 'l1_Layer_2': 0.00011304611344321309, 'l1_Layer_3': 0.0012232140082245472, 'n_units_Layer_1': 205, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.93 | sMAPE for Validation Set is: 17.61% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 16.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:56:38,116]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:43,202]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:46,434]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:49,974]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:54,378]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:56:58,251]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:02,824]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:05,883]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:09,117]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:13,133]\u001b[0m Trial 1462 finished with value: 24.564825320670064 and parameters: {'n_hidden': 3, 'learning_rate': 0.005877858589536473, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03036507070820069, 'dropout_rate_Layer_2': 0.008178852055682657, 'dropout_rate_Layer_3': 0.2502225511955847, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007977981227260459, 'l1_Layer_2': 0.0008690449083880229, 'l1_Layer_3': 0.0006604291971882567, 'n_units_Layer_1': 175, 'n_units_Layer_2': 170, 'n_units_Layer_3': 185}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.56 | sMAPE for Validation Set is: 16.02% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 15.38% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:57:15,704]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:17,066]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:20,255]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:36,227]\u001b[0m Trial 1460 finished with value: 26.870627137708937 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033116581896105797, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16123528870071774, 'dropout_rate_Layer_2': 0.25079679146840406, 'dropout_rate_Layer_3': 0.35656807360705944, 'dropout_rate_Layer_4': 0.31265971759729994, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011942803313186698, 'l1_Layer_2': 0.0008308611629407735, 'l1_Layer_3': 0.006592087304660262, 'l1_Layer_4': 9.409680202107229e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 110, 'n_units_Layer_3': 260, 'n_units_Layer_4': 225}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.87 | sMAPE for Validation Set is: 17.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 12.13 | sMAPE for Test Set is: 16.36% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:57:40,185]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:42,277]\u001b[0m Trial 1477 finished with value: 34.269933477331584 and parameters: {'n_hidden': 3, 'learning_rate': 0.003264499093542426, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20308891059454637, 'dropout_rate_Layer_2': 0.24132756381795342, 'dropout_rate_Layer_3': 0.39554586976186834, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010512365743259343, 'l1_Layer_2': 0.0009178682367633295, 'l1_Layer_3': 0.028108385247286767, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 34.27 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 17.38 | sMAPE for Test Set is: 23.30% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:57:45,482]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:45,939]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:46,481]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:48,919]\u001b[0m Trial 1463 finished with value: 26.46112917767779 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033074640675095834, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20489320857820975, 'dropout_rate_Layer_2': 0.2400118032368855, 'dropout_rate_Layer_3': 0.39240089036486897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0009129932387917439, 'l1_Layer_2': 0.000811243001546098, 'l1_Layer_3': 1.5244230682886323e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 26.46 | sMAPE for Validation Set is: 17.57% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 13.55 | sMAPE for Test Set is: 18.58% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-11 07:57:52,316]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:57:55,795]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:00,371]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:01,439]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:03,278]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:09,271]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:10,480]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:13,689]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:17,903]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:18,739]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:19,516]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:24,874]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:27,443]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:27,885]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:30,801]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:35,299]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:35,585]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:35,857]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-11 07:58:36,145]\u001b[0m Trial 1484 finished with value: 24.624776513070373 and parameters: {'n_hidden': 3, 'learning_rate': 0.005689722992925685, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0278620487909962, 'dropout_rate_Layer_2': 0.009077876917145365, 'dropout_rate_Layer_3': 0.24277909502950748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0017459338984540916, 'l1_Layer_2': 0.0014740942685468363, 'l1_Layer_3': 0.0007313113695326848, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 180}. Best is trial 997 with value: 24.424084660561835.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 24.62 | sMAPE for Validation Set is: 16.09% | rMAE for Validation Set is: 0.45\n",
      "MAE for Test Set is: 11.08 | sMAPE for Test Set is: 15.12% | rMAE for Test Set is: 0.57\n",
      "for 2023-01-01, MAE is:14.49 & sMAPE is:14.18% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :14.49 & 14.18% & 0.82\n",
      "for 2023-01-02, MAE is:32.33 & sMAPE is:25.09% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :23.41 & 19.64% & 0.87\n",
      "for 2023-01-03, MAE is:16.50 & sMAPE is:11.31% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :21.11 & 16.86% & 1.02\n",
      "for 2023-01-04, MAE is:14.46 & sMAPE is:14.14% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :19.45 & 16.18% & 1.10\n",
      "for 2023-01-05, MAE is:26.81 & sMAPE is:20.10% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :20.92 & 16.96% & 1.07\n",
      "for 2023-01-06, MAE is:13.86 & sMAPE is:11.91% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :19.74 & 16.12% & 1.03\n",
      "for 2023-01-07, MAE is:20.04 & sMAPE is:20.49% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :19.79 & 16.75% & 1.00\n",
      "for 2023-01-08, MAE is:34.86 & sMAPE is:56.23% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :21.67 & 21.68% & 1.01\n",
      "for 2023-01-09, MAE is:34.81 & sMAPE is:30.08% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :23.13 & 22.61% & 1.11\n",
      "for 2023-01-10, MAE is:19.13 & sMAPE is:16.38% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :22.73 & 21.99% & 1.08\n",
      "for 2023-01-11, MAE is:23.67 & sMAPE is:27.17% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :22.82 & 22.46% & 1.13\n",
      "for 2023-01-12, MAE is:17.81 & sMAPE is:20.35% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :22.40 & 22.29% & 1.07\n",
      "for 2023-01-13, MAE is:9.24 & sMAPE is:10.50% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :21.39 & 21.38% & 1.02\n",
      "for 2023-01-14, MAE is:7.68 & sMAPE is:8.20% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :20.41 & 20.44% & 1.00\n",
      "for 2023-01-15, MAE is:15.89 & sMAPE is:17.58% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :20.11 & 20.25% & 0.96\n",
      "for 2023-01-16, MAE is:18.23 & sMAPE is:14.14% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :19.99 & 19.87% & 0.99\n",
      "for 2023-01-17, MAE is:9.03 & sMAPE is:7.31% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :19.34 & 19.13% & 0.96\n",
      "for 2023-01-18, MAE is:8.43 & sMAPE is:6.45% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :18.74 & 18.42% & 0.92\n",
      "for 2023-01-19, MAE is:19.12 & sMAPE is:13.74% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :18.76 & 18.18% & 0.90\n",
      "for 2023-01-20, MAE is:9.94 & sMAPE is:6.59% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :18.32 & 17.60% & 0.86\n",
      "for 2023-01-21, MAE is:8.90 & sMAPE is:6.22% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :17.87 & 17.06% & 0.83\n",
      "for 2023-01-22, MAE is:12.91 & sMAPE is:8.74% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :17.64 & 16.68% & 0.80\n",
      "for 2023-01-23, MAE is:39.06 & sMAPE is:20.69% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :18.57 & 16.85% & 0.80\n",
      "for 2023-01-24, MAE is:33.81 & sMAPE is:18.68% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :19.21 & 16.93% & 0.80\n",
      "for 2023-01-25, MAE is:15.00 & sMAPE is:11.21% & rMAE is:2.52 ||| daily mean of MAE & sMAPE & rMAE till now are :19.04 & 16.70% & 0.87\n",
      "for 2023-01-26, MAE is:7.10 & sMAPE is:5.69% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :18.58 & 16.28% & 0.85\n",
      "for 2023-01-27, MAE is:18.53 & sMAPE is:12.97% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :18.58 & 16.15% & 0.85\n",
      "for 2023-01-28, MAE is:10.45 & sMAPE is:9.07% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :18.29 & 15.90% & 0.83\n",
      "for 2023-01-29, MAE is:11.99 & sMAPE is:12.05% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :18.07 & 15.77% & 0.81\n",
      "for 2023-01-30, MAE is:20.47 & sMAPE is:23.74% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :18.15 & 16.03% & 0.79\n",
      "for 2023-01-31, MAE is:8.82 & sMAPE is:9.13% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :17.85 & 15.81% & 0.77\n",
      "for 2023-02-01, MAE is:6.85 & sMAPE is:7.30% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :17.51 & 15.54% & 0.75\n",
      "for 2023-02-02, MAE is:23.13 & sMAPE is:19.65% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :17.68 & 15.67% & 0.78\n",
      "for 2023-02-03, MAE is:13.96 & sMAPE is:12.67% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :17.57 & 15.58% & 0.77\n",
      "for 2023-02-04, MAE is:9.55 & sMAPE is:8.68% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :17.34 & 15.38% & 0.78\n",
      "for 2023-02-05, MAE is:5.80 & sMAPE is:5.15% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :17.02 & 15.10% & 0.77\n",
      "for 2023-02-06, MAE is:23.18 & sMAPE is:16.01% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :17.18 & 15.12% & 0.76\n",
      "for 2023-02-07, MAE is:5.57 & sMAPE is:4.51% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :16.88 & 14.84% & 0.75\n",
      "for 2023-02-08, MAE is:13.68 & sMAPE is:12.12% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :16.80 & 14.77% & 0.75\n",
      "for 2023-02-09, MAE is:10.50 & sMAPE is:11.16% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :16.64 & 14.68% & 0.74\n",
      "for 2023-02-10, MAE is:9.92 & sMAPE is:11.03% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :16.48 & 14.60% & 0.74\n",
      "for 2023-02-11, MAE is:5.75 & sMAPE is:6.68% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :16.22 & 14.41% & 0.73\n",
      "for 2023-02-12, MAE is:8.70 & sMAPE is:9.23% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :16.05 & 14.29% & 0.73\n",
      "for 2023-02-13, MAE is:4.41 & sMAPE is:4.23% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :15.78 & 14.06% & 0.71\n",
      "for 2023-02-14, MAE is:7.65 & sMAPE is:7.04% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :15.60 & 13.90% & 0.71\n",
      "for 2023-02-15, MAE is:4.70 & sMAPE is:4.52% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.36 & 13.70% & 0.70\n",
      "for 2023-02-16, MAE is:3.68 & sMAPE is:3.86% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :15.11 & 13.49% & 0.70\n",
      "for 2023-02-17, MAE is:12.60 & sMAPE is:14.31% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :15.06 & 13.51% & 0.71\n",
      "for 2023-02-18, MAE is:16.55 & sMAPE is:19.37% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.09 & 13.63% & 0.73\n",
      "for 2023-02-19, MAE is:6.18 & sMAPE is:6.44% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 13.48% & 0.74\n",
      "for 2023-02-20, MAE is:24.08 & sMAPE is:31.79% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :15.09 & 13.84% & 0.74\n",
      "for 2023-02-21, MAE is:16.15 & sMAPE is:19.29% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :15.11 & 13.95% & 0.75\n",
      "for 2023-02-22, MAE is:9.04 & sMAPE is:9.32% & rMAE is:2.49 ||| daily mean of MAE & sMAPE & rMAE till now are :15.00 & 13.86% & 0.78\n",
      "for 2023-02-23, MAE is:2.75 & sMAPE is:2.68% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :14.77 & 13.65% & 0.77\n",
      "for 2023-02-24, MAE is:5.38 & sMAPE is:5.53% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :14.60 & 13.50% & 0.77\n",
      "for 2023-02-25, MAE is:4.52 & sMAPE is:5.10% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 13.35% & 0.76\n",
      "for 2023-02-26, MAE is:8.88 & sMAPE is:8.89% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.32 & 13.28% & 0.77\n",
      "for 2023-02-27, MAE is:6.93 & sMAPE is:5.59% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 13.14% & 0.76\n",
      "for 2023-02-28, MAE is:3.54 & sMAPE is:3.11% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :14.02 & 12.97% & 0.75\n",
      "for 2023-03-01, MAE is:8.08 & sMAPE is:6.26% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 12.86% & 0.74\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-02, MAE is:8.12 & sMAPE is:7.13% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :13.82 & 12.77% & 0.76\n",
      "for 2023-03-03, MAE is:8.24 & sMAPE is:7.94% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :13.73 & 12.69% & 0.76\n",
      "for 2023-03-04, MAE is:5.76 & sMAPE is:5.70% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :13.61 & 12.58% & 0.76\n",
      "for 2023-03-05, MAE is:11.69 & sMAPE is:9.25% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :13.58 & 12.53% & 0.76\n",
      "for 2023-03-06, MAE is:17.67 & sMAPE is:12.36% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :13.64 & 12.52% & 0.76\n",
      "for 2023-03-07, MAE is:27.42 & sMAPE is:23.71% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :13.85 & 12.69% & 0.78\n",
      "for 2023-03-08, MAE is:18.74 & sMAPE is:14.31% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :13.92 & 12.72% & 0.78\n",
      "for 2023-03-09, MAE is:11.46 & sMAPE is:9.17% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :13.88 & 12.66% & 0.78\n",
      "for 2023-03-10, MAE is:11.64 & sMAPE is:10.16% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :13.85 & 12.63% & 0.79\n",
      "for 2023-03-11, MAE is:6.86 & sMAPE is:7.02% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :13.75 & 12.55% & 0.79\n",
      "for 2023-03-12, MAE is:10.07 & sMAPE is:10.36% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :13.70 & 12.52% & 0.79\n",
      "for 2023-03-13, MAE is:22.95 & sMAPE is:23.26% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :13.83 & 12.67% & 0.78\n",
      "for 2023-03-14, MAE is:6.36 & sMAPE is:6.87% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :13.73 & 12.59% & 0.78\n",
      "for 2023-03-15, MAE is:10.35 & sMAPE is:9.40% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :13.68 & 12.54% & 0.77\n",
      "for 2023-03-16, MAE is:15.44 & sMAPE is:14.78% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :13.70 & 12.57% & 0.77\n",
      "for 2023-03-17, MAE is:5.62 & sMAPE is:6.17% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :13.60 & 12.49% & 0.76\n",
      "for 2023-03-18, MAE is:6.61 & sMAPE is:7.19% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :13.51 & 12.42% & 0.77\n",
      "for 2023-03-19, MAE is:3.75 & sMAPE is:3.91% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :13.38 & 12.31% & 0.77\n",
      "for 2023-03-20, MAE is:5.32 & sMAPE is:5.33% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :13.28 & 12.22% & 0.77\n",
      "for 2023-03-21, MAE is:7.85 & sMAPE is:7.84% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :13.21 & 12.17% & 0.77\n",
      "for 2023-03-22, MAE is:16.25 & sMAPE is:18.33% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :13.25 & 12.24% & 0.76\n",
      "for 2023-03-23, MAE is:12.30 & sMAPE is:14.63% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :13.24 & 12.27% & 0.76\n",
      "for 2023-03-24, MAE is:7.79 & sMAPE is:10.59% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :13.17 & 12.25% & 0.76\n",
      "for 2023-03-25, MAE is:9.02 & sMAPE is:12.03% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.12 & 12.25% & 0.75\n",
      "for 2023-03-26, MAE is:6.26 & sMAPE is:7.50% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :13.04 & 12.19% & 0.75\n",
      "for 2023-03-27, MAE is:13.23 & sMAPE is:14.27% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :13.04 & 12.22% & 0.75\n",
      "for 2023-03-28, MAE is:15.79 & sMAPE is:13.80% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :13.08 & 12.24% & 0.75\n",
      "for 2023-03-29, MAE is:12.07 & sMAPE is:10.42% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.06 & 12.22% & 0.75\n",
      "for 2023-03-30, MAE is:14.76 & sMAPE is:15.10% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :13.08 & 12.25% & 0.75\n",
      "for 2023-03-31, MAE is:8.41 & sMAPE is:8.37% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :13.03 & 12.21% & 0.75\n",
      "for 2023-04-01, MAE is:1.46 & sMAPE is:1.68% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :12.90 & 12.09% & 0.74\n",
      "for 2023-04-02, MAE is:10.60 & sMAPE is:12.01% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :12.88 & 12.09% & 0.75\n",
      "for 2023-04-03, MAE is:16.12 & sMAPE is:13.92% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :12.91 & 12.11% & 0.74\n",
      "for 2023-04-04, MAE is:9.67 & sMAPE is:7.57% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :12.88 & 12.06% & 0.74\n",
      "for 2023-04-05, MAE is:11.05 & sMAPE is:9.05% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :12.86 & 12.03% & 0.75\n",
      "for 2023-04-06, MAE is:6.14 & sMAPE is:5.68% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :12.79 & 11.96% & 0.74\n",
      "for 2023-04-07, MAE is:5.11 & sMAPE is:4.99% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.71 & 11.89% & 0.74\n",
      "for 2023-04-08, MAE is:6.86 & sMAPE is:6.66% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.65 & 11.84% & 0.73\n",
      "for 2023-04-09, MAE is:13.72 & sMAPE is:14.20% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 11.86% & 0.74\n",
      "for 2023-04-10, MAE is:27.46 & sMAPE is:32.23% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :12.81 & 12.07% & 0.74\n",
      "for 2023-04-11, MAE is:11.79 & sMAPE is:13.40% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :12.80 & 12.08% & 0.73\n",
      "for 2023-04-12, MAE is:7.22 & sMAPE is:7.54% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :12.75 & 12.03% & 0.73\n",
      "for 2023-04-13, MAE is:8.78 & sMAPE is:9.45% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :12.71 & 12.01% & 0.73\n",
      "for 2023-04-14, MAE is:6.18 & sMAPE is:6.23% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :12.64 & 11.95% & 0.73\n",
      "for 2023-04-15, MAE is:8.73 & sMAPE is:8.80% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :12.61 & 11.92% & 0.74\n",
      "for 2023-04-16, MAE is:2.07 & sMAPE is:2.08% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.51 & 11.83% & 0.73\n",
      "for 2023-04-17, MAE is:13.10 & sMAPE is:11.31% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :12.51 & 11.83% & 0.73\n",
      "for 2023-04-18, MAE is:9.66 & sMAPE is:9.23% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.49 & 11.80% & 0.73\n",
      "for 2023-04-19, MAE is:10.26 & sMAPE is:10.46% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :12.47 & 11.79% & 0.73\n",
      "for 2023-04-20, MAE is:5.29 & sMAPE is:5.50% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :12.40 & 11.73% & 0.73\n",
      "for 2023-04-21, MAE is:9.42 & sMAPE is:10.44% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 11.72% & 0.73\n",
      "for 2023-04-22, MAE is:11.42 & sMAPE is:14.03% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 11.74% & 0.73\n",
      "for 2023-04-23, MAE is:18.91 & sMAPE is:24.46% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :12.42 & 11.85% & 0.74\n",
      "for 2023-04-24, MAE is:16.17 & sMAPE is:15.72% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :12.46 & 11.89% & 0.74\n",
      "for 2023-04-25, MAE is:13.29 & sMAPE is:14.18% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :12.46 & 11.91% & 0.75\n",
      "for 2023-04-26, MAE is:5.64 & sMAPE is:5.89% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :12.40 & 11.86% & 0.75\n",
      "for 2023-04-27, MAE is:12.48 & sMAPE is:11.50% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :12.41 & 11.85% & 0.75\n",
      "for 2023-04-28, MAE is:8.16 & sMAPE is:7.95% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 11.82% & 0.75\n",
      "for 2023-04-29, MAE is:7.15 & sMAPE is:7.33% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 11.78% & 0.75\n",
      "for 2023-04-30, MAE is:13.27 & sMAPE is:13.94% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :12.33 & 11.80% & 0.75\n",
      "for 2023-05-01, MAE is:9.20 & sMAPE is:9.63% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :12.31 & 11.78% & 0.75\n",
      "for 2023-05-02, MAE is:9.91 & sMAPE is:9.64% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :12.29 & 11.76% & 0.75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-03, MAE is:13.75 & sMAPE is:13.49% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 11.78% & 0.76\n",
      "for 2023-05-04, MAE is:12.47 & sMAPE is:13.09% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :12.30 & 11.79% & 0.76\n",
      "for 2023-05-05, MAE is:14.83 & sMAPE is:16.64% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :12.32 & 11.83% & 0.76\n",
      "for 2023-05-06, MAE is:6.90 & sMAPE is:8.55% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.28 & 11.80% & 0.76\n",
      "for 2023-05-07, MAE is:11.62 & sMAPE is:15.09% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :12.27 & 11.83% & 0.76\n",
      "for 2023-05-08, MAE is:9.88 & sMAPE is:10.94% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :12.25 & 11.82% & 0.76\n",
      "for 2023-05-09, MAE is:6.30 & sMAPE is:7.71% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :12.21 & 11.79% & 0.76\n",
      "for 2023-05-10, MAE is:5.55 & sMAPE is:7.16% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :12.16 & 11.75% & 0.75\n",
      "for 2023-05-11, MAE is:5.23 & sMAPE is:6.20% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.10 & 11.71% & 0.75\n",
      "for 2023-05-12, MAE is:5.53 & sMAPE is:6.89% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 11.67% & 0.75\n",
      "for 2023-05-13, MAE is:17.36 & sMAPE is:36.16% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 11.86% & 0.75\n",
      "for 2023-05-14, MAE is:20.45 & sMAPE is:45.64% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :12.16 & 12.11% & 0.75\n",
      "for 2023-05-15, MAE is:5.30 & sMAPE is:6.83% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :12.11 & 12.07% & 0.75\n",
      "for 2023-05-16, MAE is:23.21 & sMAPE is:40.05% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :12.19 & 12.28% & 0.75\n",
      "for 2023-05-17, MAE is:20.55 & sMAPE is:58.46% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :12.25 & 12.61% & 0.75\n",
      "for 2023-05-18, MAE is:14.69 & sMAPE is:22.08% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :12.27 & 12.68% & 0.75\n",
      "for 2023-05-19, MAE is:11.93 & sMAPE is:15.40% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 12.70% & 0.76\n",
      "for 2023-05-20, MAE is:33.38 & sMAPE is:73.48% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :12.41 & 13.14% & 0.77\n",
      "for 2023-05-21, MAE is:38.59 & sMAPE is:101.67% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 13.76% & 0.77\n",
      "for 2023-05-22, MAE is:8.93 & sMAPE is:13.25% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :12.57 & 13.76% & 0.77\n",
      "for 2023-05-23, MAE is:15.97 & sMAPE is:35.82% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :12.60 & 13.91% & 0.78\n",
      "for 2023-05-24, MAE is:13.84 & sMAPE is:21.84% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :12.61 & 13.97% & 0.77\n",
      "for 2023-05-25, MAE is:17.68 & sMAPE is:39.41% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :12.64 & 14.15% & 0.77\n",
      "for 2023-05-26, MAE is:13.93 & sMAPE is:39.45% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.65 & 14.32% & 0.77\n",
      "for 2023-05-27, MAE is:14.68 & sMAPE is:51.55% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :12.66 & 14.57% & 0.78\n",
      "for 2023-05-28, MAE is:23.85 & sMAPE is:82.36% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.74 & 15.03% & 0.79\n",
      "for 2023-05-29, MAE is:24.19 & sMAPE is:77.84% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.82 & 15.45% & 0.79\n",
      "for 2023-05-30, MAE is:4.62 & sMAPE is:7.53% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.76 & 15.40% & 0.78\n",
      "for 2023-05-31, MAE is:13.03 & sMAPE is:37.87% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :12.76 & 15.55% & 0.78\n",
      "for 2023-06-01, MAE is:9.29 & sMAPE is:23.98% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.74 & 15.60% & 0.79\n",
      "for 2023-06-02, MAE is:3.26 & sMAPE is:6.23% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.68 & 15.54% & 0.78\n",
      "for 2023-06-03, MAE is:12.09 & sMAPE is:41.38% & rMAE is:3.65 ||| daily mean of MAE & sMAPE & rMAE till now are :12.68 & 15.71% & 0.80\n",
      "for 2023-06-04, MAE is:12.01 & sMAPE is:35.94% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :12.67 & 15.84% & 0.80\n",
      "for 2023-06-05, MAE is:3.27 & sMAPE is:6.18% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :12.61 & 15.78% & 0.80\n",
      "for 2023-06-06, MAE is:1.50 & sMAPE is:2.98% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 15.70% & 0.79\n",
      "for 2023-06-07, MAE is:11.72 & sMAPE is:20.58% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :12.54 & 15.73% & 0.79\n",
      "for 2023-06-08, MAE is:4.52 & sMAPE is:8.19% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :12.48 & 15.68% & 0.79\n",
      "for 2023-06-09, MAE is:2.47 & sMAPE is:4.36% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :12.42 & 15.61% & 0.79\n",
      "for 2023-06-10, MAE is:14.88 & sMAPE is:41.99% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :12.44 & 15.77% & 0.80\n",
      "for 2023-06-11, MAE is:21.19 & sMAPE is:71.09% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :12.49 & 16.11% & 0.81\n",
      "for 2023-06-12, MAE is:2.88 & sMAPE is:4.56% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.43 & 16.04% & 0.81\n",
      "for 2023-06-13, MAE is:2.90 & sMAPE is:4.67% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 15.97% & 0.80\n",
      "for 2023-06-14, MAE is:6.55 & sMAPE is:9.80% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :12.34 & 15.94% & 0.80\n",
      "for 2023-06-15, MAE is:8.68 & sMAPE is:11.28% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :12.32 & 15.91% & 0.80\n",
      "for 2023-06-16, MAE is:3.33 & sMAPE is:4.13% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :12.26 & 15.84% & 0.79\n",
      "for 2023-06-17, MAE is:6.83 & sMAPE is:9.87% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :12.23 & 15.80% & 0.79\n",
      "for 2023-06-18, MAE is:9.81 & sMAPE is:16.32% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :12.22 & 15.81% & 0.79\n",
      "for 2023-06-19, MAE is:7.03 & sMAPE is:8.49% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :12.19 & 15.76% & 0.78\n",
      "for 2023-06-20, MAE is:3.63 & sMAPE is:4.47% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :12.14 & 15.70% & 0.78\n",
      "for 2023-06-21, MAE is:4.51 & sMAPE is:5.94% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.09 & 15.64% & 0.78\n",
      "for 2023-06-22, MAE is:3.95 & sMAPE is:5.12% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :12.04 & 15.58% & 0.78\n",
      "for 2023-06-23, MAE is:5.18 & sMAPE is:7.42% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :12.01 & 15.53% & 0.78\n",
      "for 2023-06-24, MAE is:19.46 & sMAPE is:44.98% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 15.70% & 0.78\n",
      "for 2023-06-25, MAE is:17.18 & sMAPE is:55.86% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 15.93% & 0.78\n",
      "for 2023-06-26, MAE is:7.25 & sMAPE is:11.05% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :12.05 & 15.90% & 0.77\n",
      "for 2023-06-27, MAE is:3.55 & sMAPE is:5.33% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :12.00 & 15.84% & 0.77\n",
      "for 2023-06-28, MAE is:7.49 & sMAPE is:9.56% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :11.98 & 15.81% & 0.77\n",
      "for 2023-06-29, MAE is:5.41 & sMAPE is:7.34% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :11.94 & 15.76% & 0.77\n",
      "for 2023-06-30, MAE is:4.26 & sMAPE is:6.53% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :11.90 & 15.71% & 0.77\n",
      "CPU times: total: 1d 15h 23min 1s\n",
      "Wall time: 18h 46min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
