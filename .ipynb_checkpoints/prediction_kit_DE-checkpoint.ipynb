{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from large_scale_prediction import large_scale_predictor, large_scale_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zones = ['DE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:08:53,627]\u001b[0m A new study created in RDB with name: DE_2018\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:29,070]\u001b[0m Trial 3 finished with value: 6.9210562407333605 and parameters: {'n_hidden': 4, 'learning_rate': 0.0017944991045339576, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30624811395379886, 'dropout_rate_Layer_2': 0.37516690478513604, 'dropout_rate_Layer_3': 0.05833807796188224, 'dropout_rate_Layer_4': 0.36775530161190967, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006651075013430141, 'l1_Layer_2': 0.0005079397295447409, 'l1_Layer_3': 0.06845104081895277, 'l1_Layer_4': 2.1376742893966954e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 220, 'n_units_Layer_4': 300}. Best is trial 3 with value: 6.9210562407333605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:09:29,352]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 52.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:29,390]\u001b[0m Trial 1 pruned. Trial was pruned at epoch 24.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 24.18% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 204.34 | sMAPE for Test Set is: 61.95% | rMAE for Test Set is: 17.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:09:31,536]\u001b[0m Trial 0 finished with value: 7.034936393663649 and parameters: {'n_hidden': 3, 'learning_rate': 0.025696676339924583, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1659116405791947, 'dropout_rate_Layer_2': 0.04246558359781743, 'dropout_rate_Layer_3': 0.3891321839939945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006018668469333612, 'l1_Layer_2': 0.000994488603518028, 'l1_Layer_3': 0.009474060334758836, 'n_units_Layer_1': 110, 'n_units_Layer_2': 115, 'n_units_Layer_3': 75}. Best is trial 3 with value: 6.9210562407333605.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:35,202]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:39,362]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:43,482]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:46,263]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:51,067]\u001b[0m Trial 7 finished with value: 8.047244792348625 and parameters: {'n_hidden': 3, 'learning_rate': 0.08332959305662557, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3563748255721376, 'dropout_rate_Layer_2': 0.08322999078931059, 'dropout_rate_Layer_3': 0.018311297751121013, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.004028014538244451, 'l1_Layer_2': 2.3155085115010425e-05, 'l1_Layer_3': 3.351380187437715e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160}. Best is trial 3 with value: 6.9210562407333605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 25.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 12.17 | sMAPE for Test Set is: 31.47% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:09:54,546]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:09:56,048]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:00,392]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:02,915]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:12,084]\u001b[0m Trial 9 finished with value: 7.6621906769120285 and parameters: {'n_hidden': 3, 'learning_rate': 0.003688002552039699, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1357068088727673, 'dropout_rate_Layer_2': 0.3359804019734881, 'dropout_rate_Layer_3': 0.15939695430127224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0017315753837679755, 'l1_Layer_2': 0.007088669203961683, 'l1_Layer_3': 0.026808707573206372, 'n_units_Layer_1': 205, 'n_units_Layer_2': 250, 'n_units_Layer_3': 75}. Best is trial 3 with value: 6.9210562407333605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.66 | sMAPE for Validation Set is: 25.22% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 27.32% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:10:15,862]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:18,237]\u001b[0m Trial 5 finished with value: 7.288110970730446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0039653223555134905, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17714202938132925, 'dropout_rate_Layer_2': 0.285785835369892, 'dropout_rate_Layer_3': 0.2231666986116866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.610257749743777e-05, 'l1_Layer_2': 0.0001246461743620172, 'l1_Layer_3': 0.000699899797541665, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 195}. Best is trial 3 with value: 6.9210562407333605.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 24.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.79 | sMAPE for Test Set is: 36.87% | rMAE for Test Set is: 1.20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:10:21,263]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:24,972]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:27,752]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:30,912]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:36,454]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:38,250]\u001b[0m Trial 16 finished with value: 6.774351813838554 and parameters: {'n_hidden': 3, 'learning_rate': 0.00810604737735162, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03664364189999301, 'dropout_rate_Layer_2': 0.3941693229977144, 'dropout_rate_Layer_3': 0.18313703940537446, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011372675958195755, 'l1_Layer_2': 0.0002253646709062177, 'l1_Layer_3': 0.0005921259880377935, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 155}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 12.99 | sMAPE for Test Set is: 34.23% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:10:42,045]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:44,764]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:47,531]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:50,755]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:54,997]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:10:59,886]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:01,260]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:04,447]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:06,231]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:06,873]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:08,528]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:10,182]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:12,698]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:17,418]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:18,055]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:19,266]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:19,777]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:25,962]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:29,281]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:33,720]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:33,932]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:38,663]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:45,145]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:11:48,386]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:09,708]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:14,351]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:20,206]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:47,058]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:50,306]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:54,665]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:12:58,501]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:02,533]\u001b[0m Trial 47 finished with value: 7.28888248647669 and parameters: {'n_hidden': 3, 'learning_rate': 0.02700293269171474, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32989442929391366, 'dropout_rate_Layer_2': 0.184129248960764, 'dropout_rate_Layer_3': 0.06922116473113538, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0011480133873633125, 'l1_Layer_2': 1.996993390316058e-05, 'l1_Layer_3': 0.000299534252201466, 'n_units_Layer_1': 195, 'n_units_Layer_2': 250, 'n_units_Layer_3': 125}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 24.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 12.56 | sMAPE for Test Set is: 32.79% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:13:05,118]\u001b[0m Trial 49 finished with value: 7.090375764269514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021217334807637684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17295598995846173, 'dropout_rate_Layer_2': 0.37396031329939855, 'dropout_rate_Layer_3': 0.25587702896141096, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2283972980778953e-05, 'l1_Layer_2': 1.094853202641659e-05, 'l1_Layer_3': 4.463508852759965e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 60, 'n_units_Layer_3': 180}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:05,250]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 24.06% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 12.60 | sMAPE for Test Set is: 32.68% | rMAE for Test Set is: 1.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:13:08,933]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:13,903]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:14,260]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:17,564]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:32,433]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:36,352]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 24.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 11.55 | sMAPE for Test Set is: 30.23% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:13:39,534]\u001b[0m Trial 46 finished with value: 7.135436304778804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023707506755398077, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1739851151433942, 'dropout_rate_Layer_2': 0.39150272776456446, 'dropout_rate_Layer_3': 0.2536219673012612, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1477179690861365e-05, 'l1_Layer_2': 1.0455469079097934e-05, 'l1_Layer_3': 4.01077666081295e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 180}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.69 | sMAPE for Validation Set is: 25.33% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 11.79 | sMAPE for Test Set is: 30.93% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:13:41,283]\u001b[0m Trial 62 finished with value: 7.691260149461153 and parameters: {'n_hidden': 3, 'learning_rate': 0.029453335841049314, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06712731513362923, 'dropout_rate_Layer_2': 0.2565712160301511, 'dropout_rate_Layer_3': 0.021339582939964342, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00037263890564313373, 'l1_Layer_2': 0.01762829257721286, 'l1_Layer_3': 0.02306147023670076, 'n_units_Layer_1': 90, 'n_units_Layer_2': 115, 'n_units_Layer_3': 170}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:46,495]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:47,829]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:53,284]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:55,363]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:13:55,757]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:00,150]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:02,851]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:03,261]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:07,866]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:08,858]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:10,293]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:14,587]\u001b[0m Trial 61 finished with value: 7.191074173423832 and parameters: {'n_hidden': 4, 'learning_rate': 0.016511312451237957, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09799146193839872, 'dropout_rate_Layer_2': 0.37408939452484846, 'dropout_rate_Layer_3': 0.3944315422634894, 'dropout_rate_Layer_4': 0.34361442993754693, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.019787708686162305, 'l1_Layer_2': 0.028853985011848243, 'l1_Layer_3': 0.001277237085151133, 'l1_Layer_4': 0.0026364295699573595, 'n_units_Layer_1': 235, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165, 'n_units_Layer_4': 75}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 24.27% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:14:14,980]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:22,020]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:26,061]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:33,594]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:37,169]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:41,969]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:42,445]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:47,273]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:50,658]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:52,338]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:52,627]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:55,598]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:14:58,101]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:00,302]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:05,672]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:18,820]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:24,864]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:33,863]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:37,562]\u001b[0m Trial 82 finished with value: 7.318473457943796 and parameters: {'n_hidden': 4, 'learning_rate': 0.002276275733692811, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2565235074428533, 'dropout_rate_Layer_2': 0.3699756435716438, 'dropout_rate_Layer_3': 0.21403349545189282, 'dropout_rate_Layer_4': 0.39431459495409615, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011529352872432799, 'l1_Layer_2': 0.0002279218783284074, 'l1_Layer_3': 0.06413639916100412, 'l1_Layer_4': 0.06539532210612828, 'n_units_Layer_1': 145, 'n_units_Layer_2': 250, 'n_units_Layer_3': 50, 'n_units_Layer_4': 80}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 24.83% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 9.65 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:15:41,816]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:45,613]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:50,218]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:53,706]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:15:53,981]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:00,292]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:02,721]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:07,272]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:12,098]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:16,266]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:24,717]\u001b[0m Trial 91 finished with value: 6.778297275406911 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010769808069786067, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12042515897946014, 'dropout_rate_Layer_2': 0.25052656126223355, 'dropout_rate_Layer_3': 0.09204530228762103, 'dropout_rate_Layer_4': 0.3943250964459506, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0907189163941607e-05, 'l1_Layer_2': 3.206068282706896e-05, 'l1_Layer_3': 0.001602301684604094, 'l1_Layer_4': 0.0008091419396673367, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290, 'n_units_Layer_4': 290}. Best is trial 16 with value: 6.774351813838554.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.51 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:16:27,834]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:32,651]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:37,074]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:43,659]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:48,195]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:16:51,412]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:09,609]\u001b[0m Trial 94 finished with value: 6.605092256632765 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005004258795749814, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1085391693738717, 'dropout_rate_Layer_2': 0.23942070345613967, 'dropout_rate_Layer_3': 0.09202668442248473, 'dropout_rate_Layer_4': 0.37984778937322744, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1941010337692982e-05, 'l1_Layer_2': 0.002794195050408454, 'l1_Layer_3': 2.7770358286193828e-05, 'l1_Layer_4': 0.0011605423304250542, 'n_units_Layer_1': 300, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.25 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:17:14,480]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:14,946]\u001b[0m Trial 106 finished with value: 6.74338705907321 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019458705185421352, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00991866172045236, 'dropout_rate_Layer_2': 0.1481890180855266, 'dropout_rate_Layer_3': 0.21686292047980205, 'dropout_rate_Layer_4': 0.2935227130957579, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016359038871890431, 'l1_Layer_2': 0.00011750801194254644, 'l1_Layer_3': 0.08445891842236351, 'l1_Layer_4': 0.0032821245589475276, 'n_units_Layer_1': 150, 'n_units_Layer_2': 205, 'n_units_Layer_3': 105, 'n_units_Layer_4': 130}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 23.26% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 9.46 | sMAPE for Test Set is: 25.84% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:17:20,121]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:23,430]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:26,871]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:30,014]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:41,322]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:44,340]\u001b[0m Trial 112 finished with value: 7.095023628661976 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026776204526506708, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06881031041438639, 'dropout_rate_Layer_2': 0.14337407189060453, 'dropout_rate_Layer_3': 0.04329309399044682, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.023979712012673307, 'l1_Layer_2': 0.0023559811489531177, 'l1_Layer_3': 0.022481428163301412, 'n_units_Layer_1': 185, 'n_units_Layer_2': 135, 'n_units_Layer_3': 300}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 165.33 | sMAPE for Test Set is: 67.05% | rMAE for Test Set is: 14.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:17:50,652]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:53,671]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:17:55,447]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:03,602]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:04,423]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:09,998]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:13,486]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:14,872]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:33,761]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:37,740]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:41,228]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:46,563]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:47,984]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:52,945]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:54,483]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:18:55,344]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:06,451]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:10,653]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:15,053]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:15,344]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:21,119]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:23,668]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:29,072]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:31,324]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:33,635]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:37,487]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:41,635]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:41,972]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:46,974]\u001b[0m Trial 115 finished with value: 6.787923279382025 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005290870087225756, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15014582834749365, 'dropout_rate_Layer_2': 0.24771586094852235, 'dropout_rate_Layer_3': 0.09868318504206125, 'dropout_rate_Layer_4': 0.23861969371969674, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.10948442147294e-05, 'l1_Layer_2': 2.9933450189291874e-05, 'l1_Layer_3': 0.0017096441859250691, 'l1_Layer_4': 0.0010319367120751096, 'n_units_Layer_1': 230, 'n_units_Layer_2': 70, 'n_units_Layer_3': 300, 'n_units_Layer_4': 300}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.28 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:19:50,346]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:51,194]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:19:56,287]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:11,733]\u001b[0m Trial 150 finished with value: 6.691972724587849 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011634396407691474, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02238294155984158, 'dropout_rate_Layer_2': 0.10896271302616709, 'dropout_rate_Layer_3': 0.24953202605587932, 'dropout_rate_Layer_4': 0.27025277671086195, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006102908214300108, 'l1_Layer_2': 1.9529532319535963e-05, 'l1_Layer_3': 0.01153534789827085, 'l1_Layer_4': 0.0005835210886096955, 'n_units_Layer_1': 240, 'n_units_Layer_2': 300, 'n_units_Layer_3': 105, 'n_units_Layer_4': 205}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 22.97% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.35 | sMAPE for Test Set is: 26.74% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:20:19,244]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:27,144]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:27,159]\u001b[0m Trial 151 finished with value: 6.647694521553579 and parameters: {'n_hidden': 4, 'learning_rate': 0.0014718967927034702, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017239525193051154, 'dropout_rate_Layer_2': 0.09594766161409246, 'dropout_rate_Layer_3': 0.2521340954338705, 'dropout_rate_Layer_4': 0.31054431044920566, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008465527914855927, 'l1_Layer_2': 2.115480569656748e-05, 'l1_Layer_3': 0.011507257920797192, 'l1_Layer_4': 0.0002617100455651232, 'n_units_Layer_1': 235, 'n_units_Layer_2': 300, 'n_units_Layer_3': 95, 'n_units_Layer_4': 200}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 23.31% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:20:34,867]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:35,090]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:40,587]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:41,387]\u001b[0m Trial 156 finished with value: 6.846859189853546 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011972124313902204, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21367853882702326, 'dropout_rate_Layer_2': 0.10622401527787793, 'dropout_rate_Layer_3': 0.21981554100207615, 'dropout_rate_Layer_4': 0.29468022636296715, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005927820167056239, 'l1_Layer_2': 2.293447929607278e-05, 'l1_Layer_3': 0.001204569934862524, 'l1_Layer_4': 0.00031090570129611855, 'n_units_Layer_1': 50, 'n_units_Layer_2': 300, 'n_units_Layer_3': 100, 'n_units_Layer_4': 200}. Best is trial 94 with value: 6.605092256632765.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 23.74% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.75 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:20:45,526]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:45,816]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:52,532]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:20:56,416]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:05,624]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:05,890]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:11,260]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:14,785]\u001b[0m Trial 154 finished with value: 6.471223650544924 and parameters: {'n_hidden': 4, 'learning_rate': 0.000520646721333635, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12494472781534767, 'dropout_rate_Layer_2': 0.20918533594922034, 'dropout_rate_Layer_3': 0.08006590000868907, 'dropout_rate_Layer_4': 0.13512489564908892, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.0418401279369965e-05, 'l1_Layer_2': 0.0004328403183867016, 'l1_Layer_3': 0.013606627066740111, 'l1_Layer_4': 0.0006901895036620883, 'n_units_Layer_1': 290, 'n_units_Layer_2': 80, 'n_units_Layer_3': 280, 'n_units_Layer_4': 265}. Best is trial 154 with value: 6.471223650544924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.83 | sMAPE for Test Set is: 28.22% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:21:15,088]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:21,184]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:21,263]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:27,784]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:30,350]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:34,469]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:36,202]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:41,894]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:45,241]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:48,849]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:52,339]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:58,865]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:21:59,431]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:05,949]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:09,156]\u001b[0m Trial 166 finished with value: 6.811266602464923 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028956098486835023, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27147075859606135, 'dropout_rate_Layer_2': 0.1250813019230866, 'dropout_rate_Layer_3': 0.011921374816186159, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0002571746792688737, 'l1_Layer_2': 0.0008495434196036086, 'l1_Layer_3': 0.0008781365964244941, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 280}. Best is trial 154 with value: 6.471223650544924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 10.56 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:22:12,570]\u001b[0m Trial 179 finished with value: 6.813359509259187 and parameters: {'n_hidden': 3, 'learning_rate': 0.038384118739636576, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.180895325114875, 'dropout_rate_Layer_2': 0.25178861003325936, 'dropout_rate_Layer_3': 0.261550094805526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004044153508416273, 'l1_Layer_2': 0.0005245631940809258, 'l1_Layer_3': 1.0423482074892007e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 60}. Best is trial 154 with value: 6.471223650544924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.81 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.86 | sMAPE for Test Set is: 32.93% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:22:12,907]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:13,103]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:21,414]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:21,545]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:29,434]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:29,522]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:37,229]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:37,329]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:38,143]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:42,508]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:49,636]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:53,040]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:22:56,821]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:00,236]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:04,674]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:05,200]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:07,460]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:12,398]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:14,609]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:17,685]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:23,170]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:25,811]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:31,231]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:35,707]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:40,611]\u001b[0m Trial 207 finished with value: 7.864775250276041 and parameters: {'n_hidden': 3, 'learning_rate': 0.04110624130754888, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26920582358577794, 'dropout_rate_Layer_2': 0.24285249586167515, 'dropout_rate_Layer_3': 0.26081123407637874, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032236072603052386, 'l1_Layer_2': 0.0005794231393011367, 'l1_Layer_3': 1.2527099317569423e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 300, 'n_units_Layer_3': 50}. Best is trial 154 with value: 6.471223650544924.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.86 | sMAPE for Validation Set is: 26.40% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 12.47 | sMAPE for Test Set is: 32.83% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:23:40,890]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 23.22% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.77 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:23:45,689]\u001b[0m Trial 197 finished with value: 6.722896813373299 and parameters: {'n_hidden': 4, 'learning_rate': 0.001702560027820234, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0037744409405416797, 'dropout_rate_Layer_2': 0.0627223738857678, 'dropout_rate_Layer_3': 0.30014219478837045, 'dropout_rate_Layer_4': 0.3391269117869367, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00027175801518140467, 'l1_Layer_2': 1.0774609842456226e-05, 'l1_Layer_3': 0.002472077918564868, 'l1_Layer_4': 0.012671348301836477, 'n_units_Layer_1': 170, 'n_units_Layer_2': 220, 'n_units_Layer_3': 85, 'n_units_Layer_4': 180}. Best is trial 154 with value: 6.471223650544924.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:49,433]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:50,985]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:55,510]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:23:59,215]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:02,286]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:04,749]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:05,923]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:15,058]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:23,319]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:26,340]\u001b[0m Trial 222 finished with value: 6.4237426869856336 and parameters: {'n_hidden': 3, 'learning_rate': 0.00191644917123335, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15153201973746575, 'dropout_rate_Layer_2': 0.11914595683453266, 'dropout_rate_Layer_3': 0.12808816128427394, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004160086796072613, 'l1_Layer_2': 6.722261225435153e-05, 'l1_Layer_3': 7.760294530504906e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 80, 'n_units_Layer_3': 85}. Best is trial 222 with value: 6.4237426869856336.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 357.04 | sMAPE for Test Set is: 61.97% | rMAE for Test Set is: 31.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:24:29,628]\u001b[0m Trial 215 finished with value: 6.600593022116821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018709057909071256, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1696074209154943, 'dropout_rate_Layer_2': 0.12229293892116563, 'dropout_rate_Layer_3': 0.14218058797203784, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005638148933033834, 'l1_Layer_2': 0.0005090943820260421, 'l1_Layer_3': 1.0355164616043727e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85}. Best is trial 222 with value: 6.4237426869856336.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 239.06 | sMAPE for Test Set is: 62.17% | rMAE for Test Set is: 20.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:24:33,901]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:37,761]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:41,507]\u001b[0m Trial 220 finished with value: 6.522586718098516 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005060188222667004, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16970989856197224, 'dropout_rate_Layer_2': 0.1282071287872727, 'dropout_rate_Layer_3': 0.14694680530587623, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00038712907587851506, 'l1_Layer_2': 6.156893904602031e-05, 'l1_Layer_3': 9.537593602662057e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 222 with value: 6.4237426869856336.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 22.46% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 105.89 | sMAPE for Test Set is: 55.86% | rMAE for Test Set is: 9.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:24:43,471]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:48,009]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:50,401]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:51,479]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:24:55,389]\u001b[0m Trial 224 finished with value: 6.405948602360721 and parameters: {'n_hidden': 3, 'learning_rate': 0.005930362347874039, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17742675216650447, 'dropout_rate_Layer_2': 0.10997459841410612, 'dropout_rate_Layer_3': 0.13699990901607964, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006561330037031199, 'l1_Layer_2': 7.441614371560177e-05, 'l1_Layer_3': 7.396124788450344e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 85}. Best is trial 224 with value: 6.405948602360721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 703.39 | sMAPE for Test Set is: 65.03% | rMAE for Test Set is: 61.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:24:58,485]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:01,029]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:06,116]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:06,584]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:12,721]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:13,101]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:41,729]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:46,819]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:50,748]\u001b[0m Trial 233 finished with value: 7.340735312682514 and parameters: {'n_hidden': 3, 'learning_rate': 0.002481181213385719, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22427122476239664, 'dropout_rate_Layer_2': 0.37948806516382094, 'dropout_rate_Layer_3': 0.23948705042338592, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3921129167742541e-05, 'l1_Layer_2': 1.4220970384489228e-05, 'l1_Layer_3': 3.424325495349514e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150}. Best is trial 224 with value: 6.405948602360721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 24.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 13.39 | sMAPE for Test Set is: 35.07% | rMAE for Test Set is: 1.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:25:53,456]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:25:57,029]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:01,470]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:03,696]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:07,100]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:08,036]\u001b[0m Trial 240 finished with value: 6.598533451686748 and parameters: {'n_hidden': 3, 'learning_rate': 0.002394683202917535, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17365103639721532, 'dropout_rate_Layer_2': 0.21274664926513123, 'dropout_rate_Layer_3': 0.24690181909860867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.017420353196802036, 'l1_Layer_2': 0.0011319274608652709, 'l1_Layer_3': 0.0011122634814613756, 'n_units_Layer_1': 165, 'n_units_Layer_2': 70, 'n_units_Layer_3': 195}. Best is trial 224 with value: 6.405948602360721.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 220.10 | sMAPE for Test Set is: 59.34% | rMAE for Test Set is: 19.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:26:09,538]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:10,378]\u001b[0m Trial 239 finished with value: 6.387772904059034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005600040997073099, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2000104431238219, 'dropout_rate_Layer_2': 0.07836806956843699, 'dropout_rate_Layer_3': 0.12086533317727811, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003570330833506303, 'l1_Layer_2': 6.060609658531677e-05, 'l1_Layer_3': 8.149213341406202e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 85}. Best is trial 239 with value: 6.387772904059034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 120.37 | sMAPE for Test Set is: 56.66% | rMAE for Test Set is: 10.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:26:18,111]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:21,369]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:21,607]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:27,756]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:36,055]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:39,309]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:41,822]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:46,314]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:46,829]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:51,063]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:54,215]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:55,269]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:26:59,102]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:02,714]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:04,582]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:08,916]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:12,243]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:17,467]\u001b[0m Trial 252 finished with value: 6.4716949528581305 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029556829219029, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2472858169504598, 'dropout_rate_Layer_2': 0.05093712032414831, 'dropout_rate_Layer_3': 0.10198147483321297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.266714983007473e-05, 'l1_Layer_2': 7.537972392410729e-05, 'l1_Layer_3': 8.187132070084812e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 55, 'n_units_Layer_3': 105}. Best is trial 239 with value: 6.387772904059034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 22.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 69.40 | sMAPE for Test Set is: 51.66% | rMAE for Test Set is: 6.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:27:17,841]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:23,060]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:26,384]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:29,651]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:33,032]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:35,553]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:38,030]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:38,397]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:45,083]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:48,629]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:48,952]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:53,262]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:53,667]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:53,780]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:27:59,296]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:01,893]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:04,446]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:07,312]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:09,575]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:12,313]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:14,167]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:16,515]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:20,964]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:25,013]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:25,563]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:32,909]\u001b[0m Trial 286 finished with value: 6.407116053385498 and parameters: {'n_hidden': 3, 'learning_rate': 0.004442068998883718, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14467344575152177, 'dropout_rate_Layer_2': 0.13975576475979107, 'dropout_rate_Layer_3': 0.133717128277689, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014970113005309373, 'l1_Layer_2': 3.1128550331465306e-05, 'l1_Layer_3': 0.0006487764362068666, 'n_units_Layer_1': 185, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80}. Best is trial 239 with value: 6.387772904059034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 22.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 992.71 | sMAPE for Test Set is: 64.79% | rMAE for Test Set is: 86.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:28:36,744]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:39,888]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:46,256]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:50,188]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:50,531]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:28:58,778]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:01,324]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:02,501]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:11,761]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:14,128]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:18,486]\u001b[0m Trial 300 finished with value: 6.623445424631835 and parameters: {'n_hidden': 3, 'learning_rate': 0.002270570140142289, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20608281372545814, 'dropout_rate_Layer_2': 0.11728443350203903, 'dropout_rate_Layer_3': 0.05285538952406743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.391958151777326e-05, 'l1_Layer_2': 3.191574800443782e-05, 'l1_Layer_3': 0.0001315832064227132, 'n_units_Layer_1': 250, 'n_units_Layer_2': 55, 'n_units_Layer_3': 130}. Best is trial 239 with value: 6.387772904059034.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 23.50% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 85.75 | sMAPE for Test Set is: 49.97% | rMAE for Test Set is: 7.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:29:20,463]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:27,933]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:31,821]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:35,066]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:45,070]\u001b[0m Trial 271 finished with value: 6.180199742157922 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010500667300521345, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3154302936226079, 'dropout_rate_Layer_2': 0.16305150937659588, 'dropout_rate_Layer_3': 0.09622930479659363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004372355635707018, 'l1_Layer_2': 0.0010012964172191464, 'l1_Layer_3': 0.0017928734445229542, 'n_units_Layer_1': 65, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245}. Best is trial 271 with value: 6.180199742157922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.51 | sMAPE for Test Set is: 24.08% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:29:48,846]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:52,524]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:29:55,385]\u001b[0m Trial 306 finished with value: 6.596145436539275 and parameters: {'n_hidden': 3, 'learning_rate': 0.007152285548857227, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06599340021526218, 'dropout_rate_Layer_2': 0.23718969744003454, 'dropout_rate_Layer_3': 0.01721615133274261, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016870833822993825, 'l1_Layer_2': 0.00013444561079903764, 'l1_Layer_3': 0.002032915143824516, 'n_units_Layer_1': 120, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 271 with value: 6.180199742157922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 23.06% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:30:00,398]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:06,112]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:21,743]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:27,427]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:43,270]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:45,263]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:48,580]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:51,765]\u001b[0m Trial 310 finished with value: 6.579683180286288 and parameters: {'n_hidden': 3, 'learning_rate': 0.005382388302286528, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12946283872544434, 'dropout_rate_Layer_2': 0.02586343414168267, 'dropout_rate_Layer_3': 0.1740322662517028, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.111050286791045e-05, 'l1_Layer_2': 0.00010971130243826816, 'l1_Layer_3': 0.000606675036037794, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 105}. Best is trial 271 with value: 6.180199742157922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 22.68% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 128.86 | sMAPE for Test Set is: 56.44% | rMAE for Test Set is: 11.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:30:55,364]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:58,469]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:30:59,543]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:31:17,996]\u001b[0m Trial 325 finished with value: 6.65191934199931 and parameters: {'n_hidden': 3, 'learning_rate': 0.00521507362750177, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12138384769397043, 'dropout_rate_Layer_2': 0.2604233790344524, 'dropout_rate_Layer_3': 0.06208294630775636, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.719076809360966e-05, 'l1_Layer_2': 1.0526529338126597e-05, 'l1_Layer_3': 2.956107465929406e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 180, 'n_units_Layer_3': 155}. Best is trial 271 with value: 6.180199742157922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.09 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:31:20,155]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:31:37,966]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:31:56,522]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:32:12,503]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:32:28,258]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:32:34,100]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:32:58,945]\u001b[0m Trial 326 finished with value: 6.210668067032649 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006708067109883056, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0657395093967476, 'dropout_rate_Layer_2': 0.2752595077996357, 'dropout_rate_Layer_3': 0.11853520311999644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003683809914149051, 'l1_Layer_2': 0.0023022341496746934, 'l1_Layer_3': 0.0008204184605092839, 'n_units_Layer_1': 60, 'n_units_Layer_2': 110, 'n_units_Layer_3': 250}. Best is trial 271 with value: 6.180199742157922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.27 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:33:04,762]\u001b[0m Trial 313 finished with value: 6.18285095142114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008141081574792319, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29502340208660993, 'dropout_rate_Layer_2': 0.2356161018786728, 'dropout_rate_Layer_3': 0.08031074852229081, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003242074688324747, 'l1_Layer_2': 0.0007119309378147753, 'l1_Layer_3': 0.0008966175508471361, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 235}. Best is trial 271 with value: 6.180199742157922.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.50 | sMAPE for Test Set is: 23.88% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:33:08,955]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:33:24,367]\u001b[0m Trial 327 finished with value: 6.151115807436921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007915041580900921, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06452756164329493, 'dropout_rate_Layer_2': 0.22153945770423492, 'dropout_rate_Layer_3': 0.030599803680608904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003560274319492694, 'l1_Layer_2': 0.0023303455849357697, 'l1_Layer_3': 0.0009532771776642678, 'n_units_Layer_1': 80, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:33:28,666]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:33:33,534]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:34:30,207]\u001b[0m Trial 335 finished with value: 6.238629352595638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006498264838029901, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00931531269299364, 'dropout_rate_Layer_2': 0.25173757498663146, 'dropout_rate_Layer_3': 0.07635244842950153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013914627349661528, 'l1_Layer_2': 3.242702840164952e-05, 'l1_Layer_3': 0.0009086542148271621, 'n_units_Layer_1': 85, 'n_units_Layer_2': 110, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:34:34,357]\u001b[0m Trial 332 finished with value: 6.204303848316662 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006828858614858363, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015820892169702658, 'dropout_rate_Layer_2': 0.24963734661526987, 'dropout_rate_Layer_3': 0.017212131636901582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012714928709784763, 'l1_Layer_2': 5.530001477952641e-05, 'l1_Layer_3': 0.0008212911627045967, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 24.90% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:34:55,485]\u001b[0m Trial 337 finished with value: 6.186733306388284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006351180048615377, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010645305047983611, 'dropout_rate_Layer_2': 0.24706519424477186, 'dropout_rate_Layer_3': 0.08331029996564349, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036742145000869084, 'l1_Layer_2': 3.253634690249107e-05, 'l1_Layer_3': 0.0008860846985598611, 'n_units_Layer_1': 60, 'n_units_Layer_2': 110, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 23.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:35:15,318]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:35:30,973]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:35:38,370]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:36:01,697]\u001b[0m Trial 344 finished with value: 6.709409015493354 and parameters: {'n_hidden': 3, 'learning_rate': 0.002818127995304901, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3708964382245699, 'dropout_rate_Layer_2': 0.0989916360775018, 'dropout_rate_Layer_3': 0.008901659429728176, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023515341156494776, 'l1_Layer_2': 3.028564601053432e-05, 'l1_Layer_3': 5.427733823788847e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 115, 'n_units_Layer_3': 70}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.88 | sMAPE for Test Set is: 37.62% | rMAE for Test Set is: 1.21\n",
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:36:09,873]\u001b[0m Trial 339 finished with value: 6.194310277546002 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006365346285162694, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013370757401601506, 'dropout_rate_Layer_2': 0.25381100697358094, 'dropout_rate_Layer_3': 0.07567940205088812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013846761728367966, 'l1_Layer_2': 3.211712627794882e-05, 'l1_Layer_3': 0.0009837283618763636, 'n_units_Layer_1': 60, 'n_units_Layer_2': 105, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:36:14,164]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:36:18,249]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:36:22,819]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:36:55,075]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:05,170]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:13,397]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:26,084]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:33,935]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:40,847]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:41,277]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:46,724]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:47,245]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:37:52,285]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:38:09,149]\u001b[0m Trial 358 finished with value: 6.4698744937163575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006920002968017438, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24332951960104568, 'dropout_rate_Layer_2': 0.048505930293410826, 'dropout_rate_Layer_3': 0.15690562439282063, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.938661910660985e-05, 'l1_Layer_2': 8.597102824624597e-05, 'l1_Layer_3': 1.988109474556623e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 115}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 133.57 | sMAPE for Test Set is: 57.62% | rMAE for Test Set is: 11.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:38:30,900]\u001b[0m Trial 349 finished with value: 6.17287720156948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005624885223604201, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009143674080038975, 'dropout_rate_Layer_2': 0.2590161184253155, 'dropout_rate_Layer_3': 0.07724653947588353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001761274685019268, 'l1_Layer_2': 4.51574698558351e-05, 'l1_Layer_3': 0.0008468907578488074, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 245}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:38:36,977]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:38:53,555]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:06,514]\u001b[0m Trial 362 finished with value: 6.519821639099547 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019965154649561746, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.394828653046004, 'dropout_rate_Layer_2': 0.11110402757047538, 'dropout_rate_Layer_3': 0.39295902071223876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0022222308903040444, 'l1_Layer_2': 1.0446832976052739e-05, 'l1_Layer_3': 0.0006939945272906369, 'n_units_Layer_1': 185, 'n_units_Layer_2': 260, 'n_units_Layer_3': 120}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 22.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.12 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:39:15,772]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:23,093]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:30,427]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:36,111]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:39,158]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:41,592]\u001b[0m Trial 364 finished with value: 6.41487207084752 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007643350967529188, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21069976460844905, 'dropout_rate_Layer_2': 0.007293517063427873, 'dropout_rate_Layer_3': 0.15815998091357, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001346586387820741, 'l1_Layer_2': 0.000317226282772438, 'l1_Layer_3': 1.9786148038837794e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 90, 'n_units_Layer_3': 145}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.64 | sMAPE for Test Set is: 25.45% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:39:49,097]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:55,386]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:39:58,905]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:03,174]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:13,307]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:19,468]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:26,546]\u001b[0m Trial 369 finished with value: 6.90230332601989 and parameters: {'n_hidden': 3, 'learning_rate': 0.002715303312543965, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06433752242507942, 'dropout_rate_Layer_2': 0.1888847189865583, 'dropout_rate_Layer_3': 0.051789980123678456, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.201259419272044e-05, 'l1_Layer_2': 2.2748960885321028e-05, 'l1_Layer_3': 2.3657961322650834e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 215, 'n_units_Layer_3': 155}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 23.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 12.32 | sMAPE for Test Set is: 32.00% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:40:35,674]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:38,105]\u001b[0m Trial 373 finished with value: 6.405877453055045 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007686366390115409, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20181765814067237, 'dropout_rate_Layer_2': 0.017351989562037845, 'dropout_rate_Layer_3': 0.17070167191564567, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001880567412336597, 'l1_Layer_2': 0.0003023588192013119, 'l1_Layer_3': 1.8966748628431417e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 195}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.19 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:40:43,322]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:45,833]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:48,426]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:40:53,009]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:00,304]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:03,586]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:09,204]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:20,370]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:26,208]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:26,599]\u001b[0m Trial 382 finished with value: 6.849167389770247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017682776712383984, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08284651679282402, 'dropout_rate_Layer_2': 0.2029972265013821, 'dropout_rate_Layer_3': 0.03875214474951261, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0511277501703535e-05, 'l1_Layer_2': 7.688787217066459e-05, 'l1_Layer_3': 1.8096580581176706e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 295}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 23.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 11.38 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:41:32,041]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:34,331]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:37,898]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:46,321]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:41:53,559]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:01,129]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:09,012]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:15,720]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:29,766]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:31,182]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:41,970]\u001b[0m Trial 395 finished with value: 6.565094732778005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011566139658547672, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32653676493950834, 'dropout_rate_Layer_2': 0.06381320151513477, 'dropout_rate_Layer_3': 0.22080834237423855, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016585767115500593, 'l1_Layer_2': 2.4020540470734607e-05, 'l1_Layer_3': 0.0009859695770591864, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 55}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.77 | sMAPE for Test Set is: 21.80% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:42:44,783]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:42:50,641]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:43:08,233]\u001b[0m Trial 399 finished with value: 6.803962290339847 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013751250317945729, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08108245996620529, 'dropout_rate_Layer_2': 0.16368697086297343, 'dropout_rate_Layer_3': 0.0657912054084724, 'dropout_rate_Layer_4': 0.21177778520299223, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2005485842187976e-05, 'l1_Layer_2': 4.4543886913780364e-05, 'l1_Layer_3': 5.674293657675681e-05, 'l1_Layer_4': 1.792373809115563e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 250, 'n_units_Layer_3': 295, 'n_units_Layer_4': 215}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 23.61% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.18 | sMAPE for Test Set is: 35.71% | rMAE for Test Set is: 1.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:43:17,502]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:43:25,222]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:43:28,381]\u001b[0m Trial 401 finished with value: 6.7756330754624585 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019935860545781223, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08227924462082391, 'dropout_rate_Layer_2': 0.20620906094094815, 'dropout_rate_Layer_3': 0.03891265532862167, 'dropout_rate_Layer_4': 0.28714196649868645, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2625051258436166e-05, 'l1_Layer_2': 4.036730140832088e-05, 'l1_Layer_3': 1.5483434481635346e-05, 'l1_Layer_4': 0.0003215057720559317, 'n_units_Layer_1': 185, 'n_units_Layer_2': 240, 'n_units_Layer_3': 295, 'n_units_Layer_4': 210}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 23.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.13 | sMAPE for Test Set is: 30.30% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:43:30,915]\u001b[0m Trial 402 finished with value: 6.711747021387979 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013921502530470893, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.038594136554498004, 'dropout_rate_Layer_2': 0.16901532206371386, 'dropout_rate_Layer_3': 0.044025188899054296, 'dropout_rate_Layer_4': 0.2965505207358067, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2141918538351018e-05, 'l1_Layer_2': 8.005687972980817e-05, 'l1_Layer_3': 1.5762528010070883e-05, 'l1_Layer_4': 2.7466656103137814e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 295, 'n_units_Layer_4': 195}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 23.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.48 | sMAPE for Test Set is: 31.12% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:43:37,197]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:43:39,310]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:43:45,629]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:43:56,074]\u001b[0m Trial 403 finished with value: 6.638888601815221 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009583465899895426, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0808484489111026, 'dropout_rate_Layer_2': 0.15785082088305036, 'dropout_rate_Layer_3': 0.03909737067870281, 'dropout_rate_Layer_4': 0.21071621158776668, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.6660099253168848e-05, 'l1_Layer_2': 4.038269944713231e-05, 'l1_Layer_3': 1.3296568975239475e-05, 'l1_Layer_4': 1.8000597669318988e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 250, 'n_units_Layer_3': 300, 'n_units_Layer_4': 290}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 23.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.12 | sMAPE for Test Set is: 32.05% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:44:09,705]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:44:25,163]\u001b[0m Trial 411 finished with value: 6.557066548750416 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013003607037764334, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34021531452752574, 'dropout_rate_Layer_2': 0.04874565982317307, 'dropout_rate_Layer_3': 0.22972321063304224, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.007772160212924363, 'l1_Layer_2': 2.3896952277173684e-05, 'l1_Layer_3': 0.0008832797718309514, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 60}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.56 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:44:29,837]\u001b[0m Trial 409 finished with value: 6.753935996804188 and parameters: {'n_hidden': 4, 'learning_rate': 0.001021487665839948, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0856556013013691, 'dropout_rate_Layer_2': 0.16164745160515734, 'dropout_rate_Layer_3': 0.039375134343740514, 'dropout_rate_Layer_4': 0.2885723166096078, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.2391516092140761e-05, 'l1_Layer_2': 7.704279401291852e-05, 'l1_Layer_3': 1.2071691296330069e-05, 'l1_Layer_4': 2.578586065910557e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295, 'n_units_Layer_4': 190}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.75 | sMAPE for Validation Set is: 22.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.95 | sMAPE for Test Set is: 37.69% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:44:34,549]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:44:49,113]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:44:55,288]\u001b[0m Trial 412 finished with value: 6.704429913925101 and parameters: {'n_hidden': 4, 'learning_rate': 0.0013225580275087162, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04009848156931469, 'dropout_rate_Layer_2': 0.15264808809768726, 'dropout_rate_Layer_3': 0.015226687989266189, 'dropout_rate_Layer_4': 0.28766109225454106, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.9565227496018907e-05, 'l1_Layer_2': 8.127445587856414e-05, 'l1_Layer_3': 1.0146605166340272e-05, 'l1_Layer_4': 1.849289443695994e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285, 'n_units_Layer_4': 215}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 22.99% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.44 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:45:03,333]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:06,655]\u001b[0m Trial 415 finished with value: 6.679149553676136 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008881595838304435, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022483776165913894, 'dropout_rate_Layer_2': 0.14317631901446812, 'dropout_rate_Layer_3': 0.07550840026084993, 'dropout_rate_Layer_4': 0.2884596352201229, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6758082989000953e-05, 'l1_Layer_2': 3.946500619294623e-05, 'l1_Layer_3': 1.0136768386802545e-05, 'l1_Layer_4': 2.2997609179840598e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 260, 'n_units_Layer_3': 285, 'n_units_Layer_4': 190}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.68 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.01 | sMAPE for Test Set is: 35.22% | rMAE for Test Set is: 1.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:45:13,648]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:16,656]\u001b[0m Trial 416 finished with value: 6.716614435057102 and parameters: {'n_hidden': 4, 'learning_rate': 0.000979919476066467, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02375140138440498, 'dropout_rate_Layer_2': 0.17494505103748242, 'dropout_rate_Layer_3': 0.032794791539571044, 'dropout_rate_Layer_4': 0.28362981113660135, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1861130053720431e-05, 'l1_Layer_2': 6.226579183597686e-05, 'l1_Layer_3': 1.4245275836737715e-05, 'l1_Layer_4': 3.64015618021756e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 215}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.83 | sMAPE for Test Set is: 31.08% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:45:19,855]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:20,869]\u001b[0m Trial 405 finished with value: 6.1706419897927205 and parameters: {'n_hidden': 3, 'learning_rate': 0.00062525154379457, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00886919774287096, 'dropout_rate_Layer_2': 0.26144337836437503, 'dropout_rate_Layer_3': 0.09227605507149464, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010606153149683782, 'l1_Layer_2': 1.609756062220998e-05, 'l1_Layer_3': 0.0008504550688230103, 'n_units_Layer_1': 70, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 22.69% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:45:22,623]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:23,976]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:30,873]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:31,405]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:33,963]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:38,730]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:53,263]\u001b[0m Trial 424 finished with value: 6.642915369854369 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009925551210718158, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023777934224671598, 'dropout_rate_Layer_2': 0.13108706651238736, 'dropout_rate_Layer_3': 0.011142794421221909, 'dropout_rate_Layer_4': 0.28157607706329224, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.636145807953275e-05, 'l1_Layer_2': 5.920671215175369e-05, 'l1_Layer_3': 1.0975174366876488e-05, 'l1_Layer_4': 3.988063765668289e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 190}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.87 | sMAPE for Test Set is: 28.55% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:45:53,628]\u001b[0m Trial 428 finished with value: 6.673801429916376 and parameters: {'n_hidden': 3, 'learning_rate': 0.005787963418516231, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16218544848861988, 'dropout_rate_Layer_2': 0.020836887803108287, 'dropout_rate_Layer_3': 0.03622039380675507, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.348185205798951e-05, 'l1_Layer_2': 0.0003101590722409095, 'l1_Layer_3': 1.9031536880244663e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 280}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.45 | sMAPE for Test Set is: 29.99% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:45:54,412]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:45:57,435]\u001b[0m Trial 427 finished with value: 6.735667325226413 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009431653613349518, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024357530289430163, 'dropout_rate_Layer_2': 0.1219000738287942, 'dropout_rate_Layer_3': 0.01234788405140361, 'dropout_rate_Layer_4': 0.2653241805941338, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.3689435064641094e-05, 'l1_Layer_2': 6.066080085925775e-05, 'l1_Layer_3': 1.0015895151341235e-05, 'l1_Layer_4': 3.4524953434142384e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 180}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 11.34 | sMAPE for Test Set is: 29.97% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:46:06,239]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:06,337]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:06,795]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:14,606]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:14,852]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:20,116]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:20,950]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:21,907]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:30,783]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:30,963]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:39,471]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:39,862]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:46,304]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:46:57,870]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:02,620]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:02,896]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:20,691]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:20,840]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:24,501]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:30,054]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:31,674]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:32,343]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:37,676]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:42,220]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:44,442]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:48,225]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:55,419]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:47:59,858]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:48:02,549]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:48:03,009]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:48:10,362]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:48:41,897]\u001b[0m Trial 443 finished with value: 6.16295430233664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006441654719236718, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01649098414436512, 'dropout_rate_Layer_2': 0.027197070329075757, 'dropout_rate_Layer_3': 0.09998087024359827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019573744834895913, 'l1_Layer_2': 2.3110799170055183e-05, 'l1_Layer_3': 0.0006077089089210776, 'n_units_Layer_1': 65, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 327 with value: 6.151115807436921.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:48:46,397]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:48:52,603]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:01,745]\u001b[0m Trial 453 finished with value: 6.141553241893914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006118461122640113, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028117181116127328, 'dropout_rate_Layer_2': 0.0687143254728443, 'dropout_rate_Layer_3': 0.07264949960438356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002986442133072206, 'l1_Layer_2': 6.41145519066258e-05, 'l1_Layer_3': 0.0007676823110605938, 'n_units_Layer_1': 95, 'n_units_Layer_2': 110, 'n_units_Layer_3': 245}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:49:07,546]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:14,858]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:17,962]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:20,868]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:24,419]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:28,042]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:32,844]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:33,644]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:37,066]\u001b[0m Trial 464 finished with value: 6.16814999981133 and parameters: {'n_hidden': 3, 'learning_rate': 0.000840846007600543, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00725733560083199, 'dropout_rate_Layer_2': 0.26652173093629544, 'dropout_rate_Layer_3': 0.06463841436939397, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00047984986534600613, 'l1_Layer_2': 4.988956269147593e-05, 'l1_Layer_3': 0.000659141785862853, 'n_units_Layer_1': 70, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 23.66% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:49:39,386]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:43,566]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:49:50,174]\u001b[0m Trial 470 finished with value: 6.572373462890309 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007597916925938065, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014862856523703224, 'dropout_rate_Layer_2': 0.10345919355422499, 'dropout_rate_Layer_3': 0.020003132777309734, 'dropout_rate_Layer_4': 0.3141653015650669, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8492195945862337e-05, 'l1_Layer_2': 7.200567528561062e-05, 'l1_Layer_3': 1.0095191746616581e-05, 'l1_Layer_4': 1.4072088693957117e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 295, 'n_units_Layer_3': 280, 'n_units_Layer_4': 170}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 23.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 29.71% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:49:57,480]\u001b[0m Trial 476 finished with value: 6.757690141092799 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018739348755141007, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2251956469641903, 'dropout_rate_Layer_2': 0.07220363312728963, 'dropout_rate_Layer_3': 0.35305782070984565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005216463334095677, 'l1_Layer_2': 1.2816928819576626e-05, 'l1_Layer_3': 0.0024429831220965687, 'n_units_Layer_1': 130, 'n_units_Layer_2': 280, 'n_units_Layer_3': 65}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 23.80% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:50:00,022]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:07,406]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:16,737]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:20,564]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:25,018]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:25,419]\u001b[0m Trial 483 finished with value: 6.3746716893232644 and parameters: {'n_hidden': 3, 'learning_rate': 0.008271191194811732, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19796800105196027, 'dropout_rate_Layer_2': 0.009463670005336143, 'dropout_rate_Layer_3': 0.10723688118917678, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001790977050651478, 'l1_Layer_2': 0.002186915952510318, 'l1_Layer_3': 1.595733221259852e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 130, 'n_units_Layer_3': 90}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 22.20% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 335.53 | sMAPE for Test Set is: 61.79% | rMAE for Test Set is: 29.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:50:30,669]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:33,228]\u001b[0m Trial 478 finished with value: 6.193224287287955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008828148698531225, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020567748724432504, 'dropout_rate_Layer_2': 0.048850411608143456, 'dropout_rate_Layer_3': 0.053329560435673634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005829521693401777, 'l1_Layer_2': 0.001586296014279297, 'l1_Layer_3': 0.000596645047503701, 'n_units_Layer_1': 70, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.45% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.87 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:50:35,571]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:40,282]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:48,986]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:50:59,746]\u001b[0m Trial 490 finished with value: 6.5777286754149324 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007182878918651466, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011136395941026228, 'dropout_rate_Layer_2': 0.10548075026484267, 'dropout_rate_Layer_3': 0.02222098421687657, 'dropout_rate_Layer_4': 0.3216861700622888, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.237342431857899e-05, 'l1_Layer_2': 5.451687396723042e-05, 'l1_Layer_3': 2.981760653870126e-05, 'l1_Layer_4': 1.4750951003712568e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 300, 'n_units_Layer_3': 280, 'n_units_Layer_4': 170}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 22.67% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.71 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:51:13,102]\u001b[0m Trial 492 finished with value: 6.6412399871188805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007524133286599871, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3467761739713977, 'dropout_rate_Layer_2': 0.06606814582414716, 'dropout_rate_Layer_3': 0.21851481410558637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007322996256194888, 'l1_Layer_2': 2.010156061466443e-05, 'l1_Layer_3': 0.0004008303195854647, 'n_units_Layer_1': 85, 'n_units_Layer_2': 245, 'n_units_Layer_3': 80}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 20.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:51:18,327]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:51:19,196]\u001b[0m Trial 486 finished with value: 6.459155168559133 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007916332957833744, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3176773280185938, 'dropout_rate_Layer_2': 0.012983058224495282, 'dropout_rate_Layer_3': 0.22197262841130339, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004093878268026474, 'l1_Layer_2': 1.8827743127544693e-05, 'l1_Layer_3': 0.0003490968789307544, 'n_units_Layer_1': 240, 'n_units_Layer_2': 220, 'n_units_Layer_3': 80}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:51:25,493]\u001b[0m Trial 493 finished with value: 6.571205410843983 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014782949559972232, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30824516301068355, 'dropout_rate_Layer_2': 0.06513172825282244, 'dropout_rate_Layer_3': 0.22686118406330533, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003601493891448319, 'l1_Layer_2': 1.9651199944067557e-05, 'l1_Layer_3': 0.0004108183188876791, 'n_units_Layer_1': 255, 'n_units_Layer_2': 245, 'n_units_Layer_3': 80}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 20.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:51:28,160]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:51:28,220]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:51:34,089]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:51:39,945]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:51:43,607]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:51:56,511]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:00,311]\u001b[0m Trial 479 finished with value: 6.164771264860306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007600010553022003, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020755756167985702, 'dropout_rate_Layer_2': 0.2273045998867376, 'dropout_rate_Layer_3': 0.06371592152710903, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004914487348646836, 'l1_Layer_2': 6.503836613231439e-05, 'l1_Layer_3': 0.0006036002296435184, 'n_units_Layer_1': 105, 'n_units_Layer_2': 100, 'n_units_Layer_3': 270}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:52:01,045]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:06,756]\u001b[0m Trial 502 finished with value: 6.627187633156791 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007523032326456833, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034353950764420334, 'dropout_rate_Layer_2': 0.08965629942230179, 'dropout_rate_Layer_3': 0.0015863857540922809, 'dropout_rate_Layer_4': 0.33646950676658305, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.098281524085725e-05, 'l1_Layer_2': 5.3495449119340596e-05, 'l1_Layer_3': 1.972143918690545e-05, 'l1_Layer_4': 1.4125150403905762e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285, 'n_units_Layer_4': 220}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.83 | sMAPE for Test Set is: 34.51% | rMAE for Test Set is: 1.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:52:08,984]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:12,154]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:14,033]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:31,267]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:36,084]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:40,025]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:43,033]\u001b[0m Trial 499 finished with value: 6.407758517338856 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007286793118926809, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047360807453822554, 'dropout_rate_Layer_2': 0.1518179403814047, 'dropout_rate_Layer_3': 0.027021233301359658, 'dropout_rate_Layer_4': 0.328497240727912, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0017185807482091979, 'l1_Layer_2': 0.00015985910142210172, 'l1_Layer_3': 1.5875967647066607e-05, 'l1_Layer_4': 1.3621931543116396e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 290, 'n_units_Layer_3': 245, 'n_units_Layer_4': 140}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 10.91 | sMAPE for Test Set is: 28.89% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:52:50,806]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:51,428]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:51,882]\u001b[0m Trial 509 finished with value: 6.720581341067008 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007347959452546862, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03454210586225224, 'dropout_rate_Layer_2': 0.07215544926233089, 'dropout_rate_Layer_3': 0.0007118683491162923, 'dropout_rate_Layer_4': 0.3400804193262874, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.2123040817577232e-05, 'l1_Layer_2': 0.0003703886270136315, 'l1_Layer_3': 2.021348626791786e-05, 'l1_Layer_4': 1.3848505459554082e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285, 'n_units_Layer_4': 165}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.72 | sMAPE for Validation Set is: 23.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.64 | sMAPE for Test Set is: 28.06% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:52:58,137]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:52:59,987]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:01,933]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:02,550]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:08,495]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:13,158]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:17,505]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:19,598]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:24,795]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:26,521]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:27,463]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:33,397]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:37,929]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:38,335]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:45,501]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:45,765]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:53:55,648]\u001b[0m Trial 532 finished with value: 8.477405630627603 and parameters: {'n_hidden': 3, 'learning_rate': 0.02156873486715679, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13127826814999638, 'dropout_rate_Layer_2': 0.08584703889941622, 'dropout_rate_Layer_3': 0.13925476366759051, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0009914500889836111, 'l1_Layer_2': 2.2046749407594688e-05, 'l1_Layer_3': 0.00023301047183692564, 'n_units_Layer_1': 295, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 27.19% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 14.16 | sMAPE for Test Set is: 36.65% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:54:00,511]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:54:07,658]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:54:38,657]\u001b[0m Trial 504 finished with value: 6.16018453883309 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007479974069360169, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014025166309931244, 'dropout_rate_Layer_2': 0.03145527906911512, 'dropout_rate_Layer_3': 0.06743971096551368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004740733160049382, 'l1_Layer_2': 1.625688722725526e-05, 'l1_Layer_3': 0.00048127322529155565, 'n_units_Layer_1': 105, 'n_units_Layer_2': 95, 'n_units_Layer_3': 265}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.72 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:54:47,032]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:54:52,923]\u001b[0m Trial 535 finished with value: 6.44816910649617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010099122526512354, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.377981885575151, 'dropout_rate_Layer_2': 0.06787400854321157, 'dropout_rate_Layer_3': 0.21416303048580942, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027303401452230484, 'l1_Layer_2': 1.8512887407222258e-05, 'l1_Layer_3': 0.0008046565830027013, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 215}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.72 | sMAPE for Test Set is: 24.98% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:54:53,269]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:54:57,743]\u001b[0m Trial 526 finished with value: 6.204117521935004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006118729912512091, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035054559165202906, 'dropout_rate_Layer_2': 0.2515121042264731, 'dropout_rate_Layer_3': 0.041637200405777494, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006645759840316272, 'l1_Layer_2': 0.0008757779764070818, 'l1_Layer_3': 0.000704067863811491, 'n_units_Layer_1': 75, 'n_units_Layer_2': 105, 'n_units_Layer_3': 260}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.68% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 23.40% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:55:00,527]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:06,634]\u001b[0m Trial 531 finished with value: 6.268664444185087 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006766141571929289, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009604210284817902, 'dropout_rate_Layer_2': 0.24670901874915546, 'dropout_rate_Layer_3': 0.08825551758439909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011241171893911102, 'l1_Layer_2': 0.0007397824547649632, 'l1_Layer_3': 0.0008965447514449523, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 275}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.98 | sMAPE for Test Set is: 22.61% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:55:09,734]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:11,789]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:15,168]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:18,618]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:23,909]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:24,104]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:30,519]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:34,705]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:37,903]\u001b[0m Trial 539 finished with value: 6.352111032415924 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008141451480891465, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04933664284583573, 'dropout_rate_Layer_2': 0.05884698241207583, 'dropout_rate_Layer_3': 0.04614862586320646, 'dropout_rate_Layer_4': 0.2463849899345285, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004256279234982055, 'l1_Layer_2': 3.437847380124946e-05, 'l1_Layer_3': 3.3959024509582255e-05, 'l1_Layer_4': 1.4465617151836723e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290, 'n_units_Layer_4': 180}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 11.91 | sMAPE for Test Set is: 31.86% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:55:40,851]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:40,983]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:47,004]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:55:57,810]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:06,410]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:15,300]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:29,767]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:33,855]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:43,611]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:48,775]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:56:52,200]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:00,827]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:03,871]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:09,062]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:12,452]\u001b[0m Trial 551 finished with value: 6.465625202726276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005754678638499629, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39832938939883067, 'dropout_rate_Layer_2': 0.014140650004762334, 'dropout_rate_Layer_3': 0.19532834527217585, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001604874867302794, 'l1_Layer_2': 4.5050894594816916e-05, 'l1_Layer_3': 0.0011865998920252275, 'n_units_Layer_1': 265, 'n_units_Layer_2': 240, 'n_units_Layer_3': 210}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:57:12,904]\u001b[0m Trial 553 finished with value: 6.184989975668018 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008211889393886252, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056158445396399415, 'dropout_rate_Layer_2': 0.036979683982635056, 'dropout_rate_Layer_3': 0.05474655793355699, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006306095549257648, 'l1_Layer_2': 0.0007382634889685406, 'l1_Layer_3': 0.0006075036921720305, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.81% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.25 | sMAPE for Test Set is: 26.52% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:57:13,683]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:20,667]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:21,003]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:26,829]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:29,185]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:33,032]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:37,668]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:43,062]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:45,682]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:49,617]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:57:52,560]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:59:23,487]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:59:30,506]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:59:40,794]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:59:41,221]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:59:51,641]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 11:59:51,860]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 22.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 11:59:56,629]\u001b[0m Trial 554 finished with value: 6.142740413266298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006337102948018619, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045827036040122046, 'dropout_rate_Layer_2': 0.23970730886977523, 'dropout_rate_Layer_3': 0.02347392172839499, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029862912968694376, 'l1_Layer_2': 0.0010578143922030459, 'l1_Layer_3': 0.0004279607341552666, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 280}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:00,304]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:03,312]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:06,616]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:06,938]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:14,266]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:17,063]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:21,796]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:22,053]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:32,528]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:35,514]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:39,883]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:43,298]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:00:56,312]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:01,190]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:05,020]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:09,250]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:11,316]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:13,723]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:18,002]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:22,793]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:28,154]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:38,746]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:42,175]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:45,199]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:46,832]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:50,302]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:52,947]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:01:57,203]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:03,666]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:09,370]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:13,690]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:18,903]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:27,534]\u001b[0m Trial 578 finished with value: 6.175507877688697 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008206602830808446, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06514978205604383, 'dropout_rate_Layer_2': 0.3740607253759192, 'dropout_rate_Layer_3': 0.03373703104088103, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044587846679143935, 'l1_Layer_2': 0.002446907587450365, 'l1_Layer_3': 0.0007590199230419167, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.61 | sMAPE for Test Set is: 27.96% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:02:28,033]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:35,378]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:35,834]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:43,089]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:02:46,468]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:03:03,979]\u001b[0m Trial 594 finished with value: 6.165788187728414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007049540230872398, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03063236619363211, 'dropout_rate_Layer_2': 0.022133947397236085, 'dropout_rate_Layer_3': 0.0675019015944916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008933624718105641, 'l1_Layer_2': 0.0014694386406448809, 'l1_Layer_3': 0.0005380024821908307, 'n_units_Layer_1': 110, 'n_units_Layer_2': 110, 'n_units_Layer_3': 265}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:03:06,247]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:03:11,599]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:03:23,453]\u001b[0m Trial 618 finished with value: 6.374943519759391 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007376378840367914, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3567258087357315, 'dropout_rate_Layer_2': 0.08169562846627854, 'dropout_rate_Layer_3': 0.21057088496215415, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029396073081351215, 'l1_Layer_2': 1.3611513483745879e-05, 'l1_Layer_3': 0.0004001432904514087, 'n_units_Layer_1': 255, 'n_units_Layer_2': 255, 'n_units_Layer_3': 255}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 22.18% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.73 | sMAPE for Test Set is: 25.10% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:03:29,742]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:03:30,036]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:03:30,223]\u001b[0m Trial 625 finished with value: 6.528596450574038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007171251252636436, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24433482627822958, 'dropout_rate_Layer_2': 0.04639006955776499, 'dropout_rate_Layer_3': 0.17661800362689567, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1502143466014794e-05, 'l1_Layer_2': 7.09513595157182e-05, 'l1_Layer_3': 1.8189069860174172e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 100}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 131.02 | sMAPE for Test Set is: 57.35% | rMAE for Test Set is: 11.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:03:41,581]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:03:58,051]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:06,920]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:18,420]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:22,017]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:28,727]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:44,068]\u001b[0m Trial 635 finished with value: 6.470633976014135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010960319171998626, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24233846913003554, 'dropout_rate_Layer_2': 0.01804545068954882, 'dropout_rate_Layer_3': 0.16388030230111866, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.41146056698637e-05, 'l1_Layer_2': 0.00012750255813255093, 'l1_Layer_3': 5.004785867030577e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 120}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 344.71 | sMAPE for Test Set is: 62.85% | rMAE for Test Set is: 30.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:04:48,318]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:52,617]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:04:57,396]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:05:28,124]\u001b[0m Trial 638 finished with value: 6.400053584364901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010403055366241824, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3805680160039489, 'dropout_rate_Layer_2': 0.0810096405341066, 'dropout_rate_Layer_3': 0.2289472941300613, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002916918128461492, 'l1_Layer_2': 2.4001667186463584e-05, 'l1_Layer_3': 0.0001838774854383739, 'n_units_Layer_1': 230, 'n_units_Layer_2': 255, 'n_units_Layer_3': 260}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 22.15% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:06:03,726]\u001b[0m Trial 630 finished with value: 6.177746796715222 and parameters: {'n_hidden': 3, 'learning_rate': 0.000675872933246067, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027201719705936482, 'dropout_rate_Layer_2': 0.01249744434216597, 'dropout_rate_Layer_3': 0.07097893692592762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025235133398183725, 'l1_Layer_2': 0.001294240500974942, 'l1_Layer_3': 0.0004499898154975358, 'n_units_Layer_1': 110, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.88 | sMAPE for Test Set is: 22.44% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:06:26,518]\u001b[0m Trial 640 finished with value: 6.206212029184044 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008840793483228071, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004973093165862735, 'dropout_rate_Layer_2': 0.028357989564639398, 'dropout_rate_Layer_3': 0.050360218634934506, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012171531933537203, 'l1_Layer_2': 5.1028800361849936e-05, 'l1_Layer_3': 0.0008157477034579649, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.42 | sMAPE for Test Set is: 23.92% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:06:32,465]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:06:37,574]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:06:59,357]\u001b[0m Trial 642 finished with value: 6.439717492379138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005893279612798061, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36711274565034757, 'dropout_rate_Layer_2': 0.08078214264349642, 'dropout_rate_Layer_3': 0.19374858299165829, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030776497018009203, 'l1_Layer_2': 2.6356199003403806e-05, 'l1_Layer_3': 6.189175205423556e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 265, 'n_units_Layer_3': 265}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.44 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.07 | sMAPE for Test Set is: 23.12% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:07:03,543]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:07:15,349]\u001b[0m Trial 633 finished with value: 6.214106749458936 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005512414890435388, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04313900175727372, 'dropout_rate_Layer_2': 0.026659938591883436, 'dropout_rate_Layer_3': 0.054255378949577035, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009628026534730589, 'l1_Layer_2': 4.7540364947117525e-05, 'l1_Layer_3': 0.0016973084596538085, 'n_units_Layer_1': 105, 'n_units_Layer_2': 110, 'n_units_Layer_3': 285}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.45% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.01 | sMAPE for Test Set is: 22.89% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:07:20,076]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:07:27,476]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:07:39,439]\u001b[0m Trial 641 finished with value: 6.156512357867854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008643559542100202, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00023043512480775373, 'dropout_rate_Layer_2': 0.015125485438406232, 'dropout_rate_Layer_3': 0.05163604901317247, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031908895411037467, 'l1_Layer_2': 5.166147488102389e-05, 'l1_Layer_3': 0.0013403694896950457, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 250}. Best is trial 453 with value: 6.141553241893914.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.84 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:07:54,769]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:08:24,550]\u001b[0m Trial 645 finished with value: 6.129971406286518 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008705223434484112, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00020634004709539633, 'dropout_rate_Layer_2': 0.013563864277542626, 'dropout_rate_Layer_3': 0.04590949616591098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012498563982208512, 'l1_Layer_2': 5.11814484400992e-05, 'l1_Layer_3': 0.000536281826076087, 'n_units_Layer_1': 110, 'n_units_Layer_2': 95, 'n_units_Layer_3': 250}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.44% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:08:32,788]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:08:38,046]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:08:42,161]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:10:17,674]\u001b[0m Trial 650 finished with value: 6.1871993973112405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005342072083942753, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01767612174095351, 'dropout_rate_Layer_2': 0.005954920190061785, 'dropout_rate_Layer_3': 0.056657205135511556, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008690320314231528, 'l1_Layer_2': 4.9969891910154215e-05, 'l1_Layer_3': 0.0005520872591888367, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 290}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.26 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:10:37,657]\u001b[0m Trial 649 finished with value: 6.181362251259485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005295278635766075, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03726019466581463, 'dropout_rate_Layer_2': 0.026700219242631194, 'dropout_rate_Layer_3': 0.057209905897716115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008931105977307276, 'l1_Layer_2': 4.351296355823003e-05, 'l1_Layer_3': 0.0004896602665153098, 'n_units_Layer_1': 100, 'n_units_Layer_2': 100, 'n_units_Layer_3': 285}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.46 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:10:42,702]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:10:47,536]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:11:29,345]\u001b[0m Trial 656 finished with value: 6.163301289488928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009807741642796372, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0019721585830894915, 'dropout_rate_Layer_2': 0.0027453352957040947, 'dropout_rate_Layer_3': 0.04753597260584222, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009196505618161084, 'l1_Layer_2': 4.961547526089622e-05, 'l1_Layer_3': 0.0003801718177291009, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 255}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.47% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:11:59,099]\u001b[0m Trial 661 finished with value: 6.711711238817499 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007679255752279637, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03766574907011177, 'dropout_rate_Layer_2': 0.06375266294595605, 'dropout_rate_Layer_3': 0.0011202531505698386, 'dropout_rate_Layer_4': 0.3416184594096755, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.1584257534406546e-05, 'l1_Layer_2': 0.0003490714249892432, 'l1_Layer_3': 1.843943252513983e-05, 'l1_Layer_4': 1.2471434265778488e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 290, 'n_units_Layer_3': 285, 'n_units_Layer_4': 165}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:11:59,587]\u001b[0m Trial 660 finished with value: 6.310576045619919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010823194534079939, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019183735343243403, 'dropout_rate_Layer_2': 0.0026530379556604887, 'dropout_rate_Layer_3': 0.0454582466100949, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007111055068165503, 'l1_Layer_2': 5.265251702156183e-05, 'l1_Layer_3': 0.00045453150387382666, 'n_units_Layer_1': 100, 'n_units_Layer_2': 90, 'n_units_Layer_3': 295}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 21.97% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:12:07,536]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.29% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.69 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:12:14,069]\u001b[0m Trial 652 finished with value: 6.168677215780683 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005879181713105, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018881786033295857, 'dropout_rate_Layer_2': 0.0047114513344462036, 'dropout_rate_Layer_3': 0.05778267312317408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009002408557209965, 'l1_Layer_2': 4.837708702411334e-05, 'l1_Layer_3': 0.0004982952280678635, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:12:41,390]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:12:52,238]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 313.69 | sMAPE for Test Set is: 63.14% | rMAE for Test Set is: 27.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:12:54,637]\u001b[0m Trial 664 finished with value: 6.350176565370469 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006557719062644091, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.26721781845844766, 'dropout_rate_Layer_2': 0.03922866470690387, 'dropout_rate_Layer_3': 0.07593997095692066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00046084292381739714, 'l1_Layer_2': 0.00043347776660548497, 'l1_Layer_3': 2.6522806091707945e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:13:01,562]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:13:17,756]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:13:34,982]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:13:39,138]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:13:39,560]\u001b[0m Trial 657 finished with value: 6.208427720469054 and parameters: {'n_hidden': 3, 'learning_rate': 0.001046932368349734, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.004745457883272435, 'dropout_rate_Layer_2': 0.001390474299859194, 'dropout_rate_Layer_3': 0.03922894522269658, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006864258108502392, 'l1_Layer_2': 5.846528125784284e-05, 'l1_Layer_3': 0.000338376998924456, 'n_units_Layer_1': 105, 'n_units_Layer_2': 90, 'n_units_Layer_3': 260}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:15:00,406]\u001b[0m Trial 666 finished with value: 6.200800664556358 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005143235932745035, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01975099663353269, 'dropout_rate_Layer_2': 0.0004045558624248425, 'dropout_rate_Layer_3': 0.05939676103237353, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006795989203359523, 'l1_Layer_2': 4.4449177279530907e-05, 'l1_Layer_3': 0.00034907029009273563, 'n_units_Layer_1': 100, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.45% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.25 | sMAPE for Test Set is: 23.10% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:15:26,501]\u001b[0m Trial 669 finished with value: 6.1937605184148765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005248348845259957, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01862791084448008, 'dropout_rate_Layer_2': 0.007374400888923168, 'dropout_rate_Layer_3': 0.0409218118136093, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000830821789901685, 'l1_Layer_2': 4.467378187958936e-05, 'l1_Layer_3': 0.0003387098800341779, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.41% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.65 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:15:30,326]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:15:35,161]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:15:38,172]\u001b[0m Trial 673 finished with value: 6.137895940516138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005028915717022262, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019949918837895965, 'dropout_rate_Layer_2': 0.009558935779727292, 'dropout_rate_Layer_3': 0.056990118699994916, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008037844292744236, 'l1_Layer_2': 4.5180522430239705e-05, 'l1_Layer_3': 0.000272191071412976, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:17:10,876]\u001b[0m Trial 677 finished with value: 6.321927839049608 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005538053535679292, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00025195410192414835, 'dropout_rate_Layer_2': 0.016341470434915635, 'dropout_rate_Layer_3': 0.048899166039815284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009224777762901651, 'l1_Layer_2': 4.572052418369301e-05, 'l1_Layer_3': 0.00025092129430126, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 21.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 9.01 | sMAPE for Test Set is: 25.49% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:17:11,744]\u001b[0m Trial 678 finished with value: 6.350312504937848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050101760761289, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0011204220374942528, 'dropout_rate_Layer_2': 0.013641615243715731, 'dropout_rate_Layer_3': 0.048877798801278835, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007946832546525413, 'l1_Layer_2': 4.501154190673196e-05, 'l1_Layer_3': 0.00023956102134068503, 'n_units_Layer_1': 95, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:17:18,735]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:17:40,614]\u001b[0m Trial 674 finished with value: 6.1873931286799655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005287582467145343, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018693117219508372, 'dropout_rate_Layer_2': 0.007353984667679665, 'dropout_rate_Layer_3': 0.061707158106640354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008552041638270438, 'l1_Layer_2': 4.2636559638927264e-05, 'l1_Layer_3': 0.0002577078212689696, 'n_units_Layer_1': 95, 'n_units_Layer_2': 95, 'n_units_Layer_3': 290}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.03 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:18:00,207]\u001b[0m Trial 681 finished with value: 6.483466447321647 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007063364246994207, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38286979519856174, 'dropout_rate_Layer_2': 0.11402485067529537, 'dropout_rate_Layer_3': 0.14361274824774112, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002887859203676432, 'l1_Layer_2': 1.4704180227188852e-05, 'l1_Layer_3': 0.00011848992423238311, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 245}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 22.51% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:18:09,937]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:18:17,236]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:18:21,943]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:18:26,105]\u001b[0m Trial 675 finished with value: 6.150411661431693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005107086024055956, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00044324189563783867, 'dropout_rate_Layer_2': 0.01176631449677961, 'dropout_rate_Layer_3': 0.04855352092588312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008326082122656803, 'l1_Layer_2': 4.6775963958758334e-05, 'l1_Layer_3': 0.0003180614772356028, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.04 | sMAPE for Test Set is: 23.10% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:18:31,245]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:18:42,082]\u001b[0m Trial 682 finished with value: 6.411944447186198 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005294464513760455, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.382600611076411, 'dropout_rate_Layer_2': 0.09923209132411501, 'dropout_rate_Layer_3': 0.14897132357949172, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0028750615878126167, 'l1_Layer_2': 1.5484323580563205e-05, 'l1_Layer_3': 6.601821339530054e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 270}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 9.41 | sMAPE for Test Set is: 27.03% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:18:45,981]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:18:54,911]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:18:59,576]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:04,143]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:09,411]\u001b[0m Trial 679 finished with value: 6.151183579037699 and parameters: {'n_hidden': 3, 'learning_rate': 0.000500885337736137, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013932700125729251, 'dropout_rate_Layer_2': 0.00827459532065752, 'dropout_rate_Layer_3': 0.050409920241675475, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008115630373371234, 'l1_Layer_2': 6.251770970923662e-05, 'l1_Layer_3': 0.00020648778351025767, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 23.50% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:19:13,178]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:17,475]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:21,458]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:25,783]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:30,989]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:36,235]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:19:40,595]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:20:07,606]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:20:10,154]\u001b[0m Trial 688 finished with value: 6.198930331375139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005783074373149793, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008242425594433904, 'dropout_rate_Layer_2': 0.021779253312284558, 'dropout_rate_Layer_3': 0.06495636512264398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2270289418218143e-05, 'l1_Layer_2': 5.2143114164461866e-05, 'l1_Layer_3': 0.00027737180428441045, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.64% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.22 | sMAPE for Test Set is: 26.14% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:20:14,753]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:20:21,028]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:20:30,311]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:21:33,480]\u001b[0m Trial 689 finished with value: 6.176865365204699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005649403637624336, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008441718041468264, 'dropout_rate_Layer_2': 0.019224729943827984, 'dropout_rate_Layer_3': 0.06437532232527604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010479832021754942, 'l1_Layer_2': 3.7257455974879225e-05, 'l1_Layer_3': 0.000279637055718011, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 295}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.14 | sMAPE for Test Set is: 23.24% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:21:47,329]\u001b[0m Trial 704 finished with value: 6.146199100924243 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005981353579822623, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010459955498380302, 'dropout_rate_Layer_2': 0.018153702570703225, 'dropout_rate_Layer_3': 0.044291533321285166, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021050354457065556, 'l1_Layer_2': 8.314830544304495e-05, 'l1_Layer_3': 0.0001974644826950192, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.90 | sMAPE for Test Set is: 25.25% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:23:03,286]\u001b[0m Trial 705 finished with value: 6.185589921488055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005852699462930365, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007325711176886822, 'dropout_rate_Layer_2': 0.0009957776266218098, 'dropout_rate_Layer_3': 0.04746444935085109, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047946371311796725, 'l1_Layer_2': 6.980671224311067e-05, 'l1_Layer_3': 0.00041901300379344904, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 23.55% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:23:14,163]\u001b[0m Trial 706 finished with value: 6.188824399193294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005041824405710664, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00783865397082889, 'dropout_rate_Layer_2': 0.013984682296112058, 'dropout_rate_Layer_3': 0.046731229185244555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007576833867373676, 'l1_Layer_2': 8.805833555172156e-05, 'l1_Layer_3': 0.00020685677441517746, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 255}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.71% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.09 | sMAPE for Test Set is: 23.34% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:23:20,709]\u001b[0m Trial 708 finished with value: 6.166501712302993 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005864346339659742, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007439521183203356, 'dropout_rate_Layer_2': 0.01642487181510901, 'dropout_rate_Layer_3': 0.04647306252182912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002022386432238666, 'l1_Layer_2': 7.382634820357933e-05, 'l1_Layer_3': 0.00017580690891408522, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.08 | sMAPE for Test Set is: 25.90% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:23:29,501]\u001b[0m Trial 707 finished with value: 6.171655779371396 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005987966984483041, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006830733849875381, 'dropout_rate_Layer_2': 0.016091432745065914, 'dropout_rate_Layer_3': 0.04786962826339937, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00047240215643617057, 'l1_Layer_2': 3.3603979648239574e-05, 'l1_Layer_3': 0.0002839394730391157, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 255}. Best is trial 645 with value: 6.129971406286518.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.39 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:24:17,948]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:24:18,874]\u001b[0m Trial 709 finished with value: 6.12067625654081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005967929211531531, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006643212778728849, 'dropout_rate_Layer_2': 0.015625917250307805, 'dropout_rate_Layer_3': 0.035665419920127714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017872094030478856, 'l1_Layer_2': 0.00010493756694601218, 'l1_Layer_3': 0.00029584134187491296, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 709 with value: 6.12067625654081.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.88 | sMAPE for Test Set is: 22.43% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:24:51,738]\u001b[0m Trial 711 finished with value: 6.1001267691483845 and parameters: {'n_hidden': 3, 'learning_rate': 0.000570141952814864, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 1.8295846328729524e-05, 'dropout_rate_Layer_2': 0.0150572852150258, 'dropout_rate_Layer_3': 0.03791317629531509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017276782111078868, 'l1_Layer_2': 8.093712121775209e-05, 'l1_Layer_3': 0.00023298633321262378, 'n_units_Layer_1': 90, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 21.01% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 9.20 | sMAPE for Test Set is: 26.29% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:24:56,614]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:25:14,841]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:25:42,762]\u001b[0m Trial 713 finished with value: 6.154463238313247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005860080756715161, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0005696274304029145, 'dropout_rate_Layer_2': 0.015803539905258755, 'dropout_rate_Layer_3': 0.0360453024093688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014392248313242642, 'l1_Layer_2': 7.92067749415001e-05, 'l1_Layer_3': 0.00017505282530625224, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 24.20% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:25:48,036]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:25:52,576]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:25:59,168]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:26:05,011]\u001b[0m Trial 710 finished with value: 6.1929861962665536 and parameters: {'n_hidden': 3, 'learning_rate': 0.000595184056822951, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 3.24408963257132e-05, 'dropout_rate_Layer_2': 0.013375766993494215, 'dropout_rate_Layer_3': 0.041178675400009614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010199945923583529, 'l1_Layer_2': 9.532068392124307e-05, 'l1_Layer_3': 0.0002362021681898831, 'n_units_Layer_1': 110, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.76 | sMAPE for Test Set is: 22.19% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:26:19,707]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:26:35,857]\u001b[0m Trial 716 finished with value: 6.215613664369928 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005912557019036934, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000577931383820271, 'dropout_rate_Layer_2': 0.01614454938904812, 'dropout_rate_Layer_3': 0.03739686283255285, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018078992040297624, 'l1_Layer_2': 0.00010686606731513834, 'l1_Layer_3': 0.00014936945671258835, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.35% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.64 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:26:41,413]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:27:27,367]\u001b[0m Trial 720 finished with value: 6.14873446265461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005824825879070171, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0019218610867731342, 'dropout_rate_Layer_2': 0.019375612560116745, 'dropout_rate_Layer_3': 0.036886760780009895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001445461068032231, 'l1_Layer_2': 0.00010104901111717086, 'l1_Layer_3': 0.00011754899923544811, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.27% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.18 | sMAPE for Test Set is: 23.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:27:38,957]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:27:39,792]\u001b[0m Trial 721 finished with value: 6.16781720191511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005811421592487074, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000339949894429788, 'dropout_rate_Layer_2': 0.020529663449198918, 'dropout_rate_Layer_3': 0.03602928264327038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012508212023643983, 'l1_Layer_2': 0.0001055697065429868, 'l1_Layer_3': 0.0001560537720841352, 'n_units_Layer_1': 120, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:27:56,092]\u001b[0m Trial 723 finished with value: 6.107243873123948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005540105988486155, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0003533874732761233, 'dropout_rate_Layer_2': 0.024503268410033995, 'dropout_rate_Layer_3': 0.03232989360867853, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013648247807128297, 'l1_Layer_2': 0.00011066471789700662, 'l1_Layer_3': 0.00017102033490558598, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 21.19% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 8.91 | sMAPE for Test Set is: 25.20% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:28:06,217]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:28:11,324]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:28:20,524]\u001b[0m Trial 725 finished with value: 6.1004672787418635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005423146937258851, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010576073733306147, 'dropout_rate_Layer_2': 0.026874921456484326, 'dropout_rate_Layer_3': 0.03667889449763756, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016309790302571512, 'l1_Layer_2': 8.030013202630977e-05, 'l1_Layer_3': 0.00016019891716841168, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 21.03% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 8.83 | sMAPE for Test Set is: 24.94% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:28:23,448]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:28:45,052]\u001b[0m Trial 732 finished with value: 6.41606503067285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007965343477021722, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21380440726682537, 'dropout_rate_Layer_2': 0.014916913023169255, 'dropout_rate_Layer_3': 0.07307164767243723, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00029361323614549776, 'l1_Layer_2': 0.00016708445243051982, 'l1_Layer_3': 3.753621039377472e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 242.63 | sMAPE for Test Set is: 60.39% | rMAE for Test Set is: 21.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:29:11,906]\u001b[0m Trial 734 finished with value: 6.654732911004764 and parameters: {'n_hidden': 4, 'learning_rate': 0.000924140607496397, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025092752766622536, 'dropout_rate_Layer_2': 0.12030252947764726, 'dropout_rate_Layer_3': 0.010611402440901654, 'dropout_rate_Layer_4': 0.25562936397056774, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.65136921632869e-05, 'l1_Layer_2': 6.466140910084812e-05, 'l1_Layer_3': 1.0043204661907371e-05, 'l1_Layer_4': 3.452182780545193e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 280, 'n_units_Layer_3': 275, 'n_units_Layer_4': 180}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.28 | sMAPE for Test Set is: 27.18% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:29:35,341]\u001b[0m Trial 729 finished with value: 6.211928317557216 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006273936129726164, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00026613248715036636, 'dropout_rate_Layer_2': 0.02662597818160925, 'dropout_rate_Layer_3': 0.0332306722265022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010681127804772568, 'l1_Layer_2': 0.00011852338173465782, 'l1_Layer_3': 0.00010693115673614632, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.27 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:29:44,084]\u001b[0m Trial 731 finished with value: 6.124111809798655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005029682884791848, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00880206925650339, 'dropout_rate_Layer_2': 0.026610222444961827, 'dropout_rate_Layer_3': 0.033992442718668546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010341703928535863, 'l1_Layer_2': 0.00011197285586814063, 'l1_Layer_3': 0.00012239631672468046, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 25.72% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:29:51,970]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:29:54,754]\u001b[0m Trial 733 finished with value: 6.174999516588954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005489722544605938, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0012316745637337455, 'dropout_rate_Layer_2': 0.02956465261987689, 'dropout_rate_Layer_3': 0.03074002263607002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014068424440698429, 'l1_Layer_2': 8.351307389456927e-05, 'l1_Layer_3': 0.00013041938331198496, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.85 | sMAPE for Test Set is: 25.40% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:30:43,228]\u001b[0m Trial 735 finished with value: 6.1434608270128725 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005026037464622073, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012151416138061788, 'dropout_rate_Layer_2': 0.02970229063522003, 'dropout_rate_Layer_3': 0.03000886805737645, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001464920094253419, 'l1_Layer_2': 8.436675477905436e-05, 'l1_Layer_3': 0.00014772323299024618, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 24.01% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:30:59,426]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:31:12,871]\u001b[0m Trial 736 finished with value: 6.204499101914272 and parameters: {'n_hidden': 3, 'learning_rate': 0.000549667032998406, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00823317802472138, 'dropout_rate_Layer_2': 0.007865890691627395, 'dropout_rate_Layer_3': 0.026812486001120017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014112934708633828, 'l1_Layer_2': 8.428281389223398e-05, 'l1_Layer_3': 0.00013076056377223764, 'n_units_Layer_1': 120, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.84 | sMAPE for Test Set is: 25.35% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:31:24,463]\u001b[0m Trial 738 finished with value: 6.140661806128158 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005156463420997398, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014011197733976733, 'dropout_rate_Layer_2': 0.030239361421016006, 'dropout_rate_Layer_3': 0.02695337187863073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012461653941597814, 'l1_Layer_2': 0.00014980863488107135, 'l1_Layer_3': 0.0001591863211967238, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.45 | sMAPE for Test Set is: 24.00% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:31:27,211]\u001b[0m Trial 739 finished with value: 6.166132658706698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012090170507165, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012050798357257213, 'dropout_rate_Layer_2': 0.0058188739595204635, 'dropout_rate_Layer_3': 0.03835165665940014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001424370316638255, 'l1_Layer_2': 0.00010201074304240756, 'l1_Layer_3': 0.0001618647559555206, 'n_units_Layer_1': 125, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 23.95% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:31:53,383]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:31:58,748]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:07,049]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:11,649]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:16,502]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:23,489]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:28,817]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:33,667]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:32:40,775]\u001b[0m Trial 741 finished with value: 6.195631751470212 and parameters: {'n_hidden': 3, 'learning_rate': 0.000541218440454289, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00015179276589491909, 'dropout_rate_Layer_2': 0.030278754388882032, 'dropout_rate_Layer_3': 0.026514412786380354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013590800247133546, 'l1_Layer_2': 0.00015619169912471797, 'l1_Layer_3': 0.00017056007977014093, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.96 | sMAPE for Test Set is: 25.54% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:33:04,596]\u001b[0m Trial 753 finished with value: 6.671069502824991 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008770492144339162, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017619241965043442, 'dropout_rate_Layer_2': 0.10334627186334604, 'dropout_rate_Layer_3': 0.03460433847966023, 'dropout_rate_Layer_4': 0.33972696202126434, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.3267449698486718e-05, 'l1_Layer_2': 0.00011664040228416852, 'l1_Layer_3': 1.4784154153714365e-05, 'l1_Layer_4': 8.350946415706253e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 275, 'n_units_Layer_4': 225}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.00 | sMAPE for Test Set is: 29.05% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:33:09,075]\u001b[0m Trial 743 finished with value: 6.233068760794587 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012744591229109, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014178904260179575, 'dropout_rate_Layer_2': 0.034041936664606615, 'dropout_rate_Layer_3': 0.027364188105805223, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013340689937099557, 'l1_Layer_2': 0.00014950094106826872, 'l1_Layer_3': 8.488279889316215e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 21.74% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.38 | sMAPE for Test Set is: 23.75% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:33:10,934]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:33:18,153]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:33:37,092]\u001b[0m Trial 746 finished with value: 6.260443891766908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005516715331504186, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014178428253911964, 'dropout_rate_Layer_2': 0.035656763110225156, 'dropout_rate_Layer_3': 0.03662118086784259, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.134405798108583e-05, 'l1_Layer_2': 0.00012655381088042263, 'l1_Layer_3': 0.0001463552232020256, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.32 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:34:08,335]\u001b[0m Trial 752 finished with value: 6.183171039641259 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005566333463452428, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016143588590054596, 'dropout_rate_Layer_2': 0.022706698411529037, 'dropout_rate_Layer_3': 0.03748165242290375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012197558361730722, 'l1_Layer_2': 9.379262545846625e-05, 'l1_Layer_3': 0.00014048665450428605, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 24.12% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:34:43,807]\u001b[0m Trial 755 finished with value: 6.114168054394743 and parameters: {'n_hidden': 3, 'learning_rate': 0.000609965919516033, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014010288621750147, 'dropout_rate_Layer_2': 0.008189601902458925, 'dropout_rate_Layer_3': 0.03858696143121169, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017151093274760893, 'l1_Layer_2': 9.281377568509354e-05, 'l1_Layer_3': 0.00014669493394706988, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 8.26 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:34:53,594]\u001b[0m Trial 758 finished with value: 6.203714506949544 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006257011673103076, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014006284560401799, 'dropout_rate_Layer_2': 0.021468663716182914, 'dropout_rate_Layer_3': 0.03974874199798371, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001799029879043479, 'l1_Layer_2': 9.243566867807093e-05, 'l1_Layer_3': 0.00018478868110685797, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.51% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.25 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:34:55,962]\u001b[0m Trial 757 finished with value: 6.152067677505329 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006163890743918798, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014255984315305344, 'dropout_rate_Layer_2': 0.019750249831703107, 'dropout_rate_Layer_3': 0.03903149694427118, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019066380042098745, 'l1_Layer_2': 9.718438109793303e-05, 'l1_Layer_3': 0.00015079161417103456, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:34:59,595]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:04,129]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:09,096]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:26,871]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:30,184]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:36,542]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:42,979]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:35:46,329]\u001b[0m Trial 759 finished with value: 6.181099771636589 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006206421331492948, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013141210016528014, 'dropout_rate_Layer_2': 0.00019176317586512386, 'dropout_rate_Layer_3': 0.04124069222769866, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017524098338517975, 'l1_Layer_2': 7.679703505978976e-05, 'l1_Layer_3': 0.00018689399427318626, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 23.82% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:35:57,423]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:36:02,579]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:36:10,233]\u001b[0m Trial 770 finished with value: 6.616641338858581 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008240078121770043, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03171147858905291, 'dropout_rate_Layer_2': 0.15795116265707498, 'dropout_rate_Layer_3': 0.012990414701030545, 'dropout_rate_Layer_4': 0.3429196498984644, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8258897081857116e-05, 'l1_Layer_2': 7.844391726615327e-05, 'l1_Layer_3': 2.2174203309218027e-05, 'l1_Layer_4': 2.0182431887489253e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290, 'n_units_Layer_4': 215}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.61 | sMAPE for Test Set is: 30.85% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:36:24,809]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:36:34,047]\u001b[0m Trial 773 finished with value: 6.690753154200493 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008252466197375888, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024345181542051668, 'dropout_rate_Layer_2': 0.15522576667881832, 'dropout_rate_Layer_3': 0.021476766386810626, 'dropout_rate_Layer_4': 0.28907641281495183, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.1846512204191006e-05, 'l1_Layer_2': 5.932969427098211e-05, 'l1_Layer_3': 1.1937338070556756e-05, 'l1_Layer_4': 4.880194145088012e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 240, 'n_units_Layer_3': 290, 'n_units_Layer_4': 215}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.11 | sMAPE for Test Set is: 26.84% | rMAE for Test Set is: 0.88\n",
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.36 | sMAPE for Test Set is: 23.52% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:36:35,779]\u001b[0m Trial 762 finished with value: 6.1534181786980655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006456280926855456, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02526472107960285, 'dropout_rate_Layer_2': 0.0003065078885637028, 'dropout_rate_Layer_3': 0.03282533936168351, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018642759662998603, 'l1_Layer_2': 0.00018155500286453946, 'l1_Layer_3': 0.00020110401188723254, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:37:16,221]\u001b[0m Trial 772 finished with value: 6.144896608189275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006976924579737429, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024749923260439326, 'dropout_rate_Layer_2': 0.026454778373773958, 'dropout_rate_Layer_3': 0.030772358247972025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001865471381819186, 'l1_Layer_2': 8.069893286815458e-05, 'l1_Layer_3': 0.00010508885523249242, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.99 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:37:47,651]\u001b[0m Trial 774 finished with value: 6.1786656391707355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006884435656513696, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007208243286102644, 'dropout_rate_Layer_2': 0.011437171874388696, 'dropout_rate_Layer_3': 0.019006059722594656, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010915155625232865, 'l1_Layer_2': 0.00018181692786369994, 'l1_Layer_3': 0.00014096522534242596, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.02 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:37:56,420]\u001b[0m Trial 775 finished with value: 6.197740351250691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006678048143262837, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025071298432975012, 'dropout_rate_Layer_2': 0.012949422472130104, 'dropout_rate_Layer_3': 0.019419001793474673, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011300167795608245, 'l1_Layer_2': 0.00011557116674750907, 'l1_Layer_3': 0.0001003301283351179, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 23.13% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:38:00,670]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:38:08,336]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:38:09,228]\u001b[0m Trial 776 finished with value: 6.212638570990595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005604111421556715, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007912025541183483, 'dropout_rate_Layer_2': 0.01057909956584685, 'dropout_rate_Layer_3': 0.017598061581354463, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011110025761252173, 'l1_Layer_2': 0.00016077796233984328, 'l1_Layer_3': 0.00014622382171531579, 'n_units_Layer_1': 135, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 711 with value: 6.1001267691483845.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.43% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.11 | sMAPE for Test Set is: 26.16% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:38:48,487]\u001b[0m Trial 777 finished with value: 6.088241099484432 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005721850077181986, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00747875672543, 'dropout_rate_Layer_2': 0.010654201585301165, 'dropout_rate_Layer_3': 0.020844148448533183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011390528525321086, 'l1_Layer_2': 0.00019078129793422251, 'l1_Layer_3': 0.00010383116020259522, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 20.92% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 8.95 | sMAPE for Test Set is: 25.33% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:38:53,090]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:38:55,669]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:39:21,695]\u001b[0m Trial 778 finished with value: 6.158301759950915 and parameters: {'n_hidden': 3, 'learning_rate': 0.00056674002522936, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0071144988904425655, 'dropout_rate_Layer_2': 0.011245633940976907, 'dropout_rate_Layer_3': 0.01878814292844482, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020732834934703763, 'l1_Layer_2': 0.00011985381573957236, 'l1_Layer_3': 0.00010002709952908193, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.41 | sMAPE for Test Set is: 23.64% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:39:35,002]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:39:37,705]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:39:45,641]\u001b[0m Trial 781 finished with value: 6.150268006838818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005660314123196685, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006291410167952191, 'dropout_rate_Layer_2': 0.03915322857207035, 'dropout_rate_Layer_3': 0.029984181171237433, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002153079830703662, 'l1_Layer_2': 0.00020126841735190005, 'l1_Layer_3': 0.0002268422489619692, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:39:51,372]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:40:08,518]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:40:34,810]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:40:59,358]\u001b[0m Trial 786 finished with value: 6.168973824520019 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005683447714659983, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00852444341978133, 'dropout_rate_Layer_2': 0.01802379491086102, 'dropout_rate_Layer_3': 0.012182201166938092, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017074885637315444, 'l1_Layer_2': 0.00020430657463575973, 'l1_Layer_3': 6.436768498684512e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.12 | sMAPE for Test Set is: 26.18% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:41:03,938]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:41:12,177]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:41:19,178]\u001b[0m Trial 788 finished with value: 6.150030867531446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005421888711741789, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008399794773301194, 'dropout_rate_Layer_2': 0.009614270880141985, 'dropout_rate_Layer_3': 0.012629421950720848, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017294361836568263, 'l1_Layer_2': 0.00014163193886953724, 'l1_Layer_3': 5.7432772090228904e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.16% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 24.92% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:41:39,583]\u001b[0m Trial 791 finished with value: 6.1839609881847055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006092626942221633, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015102929539194605, 'dropout_rate_Layer_2': 0.018208673834169516, 'dropout_rate_Layer_3': 0.021813043335397596, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021116118911397897, 'l1_Layer_2': 0.00021472654409430457, 'l1_Layer_3': 7.841334271175316e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.66% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.10 | sMAPE for Test Set is: 23.33% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:42:13,829]\u001b[0m Trial 792 finished with value: 6.19075575817373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005522539551466335, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008281101623089114, 'dropout_rate_Layer_2': 0.009858323966465328, 'dropout_rate_Layer_3': 0.011077191397855207, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022349383017262163, 'l1_Layer_2': 0.00020913814955528763, 'l1_Layer_3': 9.160928132117615e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.44 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:42:40,140]\u001b[0m Trial 796 finished with value: 6.205868228209975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006238965422769097, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021135553269522888, 'dropout_rate_Layer_2': 0.00019187456631107602, 'dropout_rate_Layer_3': 0.009893486302207148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016323077828471472, 'l1_Layer_2': 0.00017427917354352447, 'l1_Layer_3': 3.632539029853937e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:43:16,201]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:43:19,705]\u001b[0m Trial 797 finished with value: 6.159327346660802 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005159130046047935, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01846975833937009, 'dropout_rate_Layer_2': 0.025900104791523226, 'dropout_rate_Layer_3': 0.006886662170861512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016776047394134416, 'l1_Layer_2': 0.00010423370814682229, 'l1_Layer_3': 2.9360994879896517e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.33 | sMAPE for Test Set is: 23.88% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:43:42,415]\u001b[0m Trial 798 finished with value: 6.2196918927086955 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005002631039464263, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022299481581690605, 'dropout_rate_Layer_2': 0.028892094508032345, 'dropout_rate_Layer_3': 0.03261235874728945, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.968609594055476e-05, 'l1_Layer_2': 9.916637463982878e-05, 'l1_Layer_3': 0.00021967738671182702, 'n_units_Layer_1': 130, 'n_units_Layer_2': 145, 'n_units_Layer_3': 285}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.83% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.15 | sMAPE for Test Set is: 23.62% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:43:45,586]\u001b[0m Trial 800 finished with value: 6.612447722660902 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008338211462050211, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13540702021439222, 'dropout_rate_Layer_2': 0.2420644273927866, 'dropout_rate_Layer_3': 0.027680015618812365, 'dropout_rate_Layer_4': 0.17824140744899053, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.143402727828328e-05, 'l1_Layer_2': 7.934562252884292e-05, 'l1_Layer_3': 2.4160369223847574e-05, 'l1_Layer_4': 0.00010046400872025188, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 295, 'n_units_Layer_4': 205}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.25 | sMAPE for Test Set is: 27.14% | rMAE for Test Set is: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:43:52,583]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:05,079]\u001b[0m Trial 799 finished with value: 6.175845607793691 and parameters: {'n_hidden': 3, 'learning_rate': 0.000509621248055317, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025506453962900077, 'dropout_rate_Layer_2': 0.02665266830651826, 'dropout_rate_Layer_3': 0.03395219652626492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012850991685332963, 'l1_Layer_2': 9.623940121178222e-05, 'l1_Layer_3': 4.124529139838423e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.11 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:44:09,060]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:12,496]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:16,836]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:30,039]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:34,780]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:39,617]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:44:59,848]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:45:03,753]\u001b[0m Trial 801 finished with value: 6.1686142706717035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005048737225115303, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028393520249740845, 'dropout_rate_Layer_2': 0.03521963250122612, 'dropout_rate_Layer_3': 0.03552213436228886, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012906112196927979, 'l1_Layer_2': 9.069202954965807e-05, 'l1_Layer_3': 0.00022678474051926378, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 25.72% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:45:26,066]\u001b[0m Trial 802 finished with value: 6.224151539174595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006378358797665209, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008336121704085896, 'dropout_rate_Layer_2': 0.018677868154320598, 'dropout_rate_Layer_3': 0.04025149283447932, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013500190214454268, 'l1_Layer_2': 0.00013840743804409409, 'l1_Layer_3': 5.127164057118687e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.55% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.82 | sMAPE for Test Set is: 22.00% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:45:34,940]\u001b[0m Trial 807 finished with value: 6.1767961754923215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006627312867620565, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006882744851350468, 'dropout_rate_Layer_2': 0.0375558612718037, 'dropout_rate_Layer_3': 0.0255302687457799, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.980883476069064e-05, 'l1_Layer_2': 7.824730488665031e-05, 'l1_Layer_3': 0.00016404092215521908, 'n_units_Layer_1': 140, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.97 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:46:07,547]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:46:34,328]\u001b[0m Trial 812 finished with value: 6.141491799063883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005931435771529441, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006124570072076441, 'dropout_rate_Layer_2': 0.0377832041838733, 'dropout_rate_Layer_3': 0.025952831484391134, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017829902863057549, 'l1_Layer_2': 8.203914224417838e-05, 'l1_Layer_3': 0.00013862818892809194, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.80 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:46:38,226]\u001b[0m Trial 813 finished with value: 6.191430350219904 and parameters: {'n_hidden': 3, 'learning_rate': 0.000589888643643391, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.000578751861784679, 'dropout_rate_Layer_2': 0.007294179518384247, 'dropout_rate_Layer_3': 0.024648896231012248, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.205881961709488e-05, 'l1_Layer_2': 8.605235312811004e-05, 'l1_Layer_3': 0.00014444931690410902, 'n_units_Layer_1': 140, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.55 | sMAPE for Test Set is: 23.97% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:46:55,566]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:47:11,863]\u001b[0m Trial 815 finished with value: 6.130477623507396 and parameters: {'n_hidden': 3, 'learning_rate': 0.000557902326165856, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001813088655654195, 'dropout_rate_Layer_2': 0.008859302013374426, 'dropout_rate_Layer_3': 0.019881736346930287, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017989264222832075, 'l1_Layer_2': 6.950600928826159e-05, 'l1_Layer_3': 0.00013546519933452006, 'n_units_Layer_1': 135, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.28 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:47:42,406]\u001b[0m Trial 816 finished with value: 6.200915849318787 and parameters: {'n_hidden': 3, 'learning_rate': 0.000559298304417216, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014749918192676466, 'dropout_rate_Layer_2': 0.008691717163853675, 'dropout_rate_Layer_3': 0.016272366058356462, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001747435779175654, 'l1_Layer_2': 0.00011176062892418396, 'l1_Layer_3': 0.00014232152828520648, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.67 | sMAPE for Test Set is: 24.69% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:48:13,458]\u001b[0m Trial 818 finished with value: 6.172857086668677 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568922182552484, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015825177343237892, 'dropout_rate_Layer_2': 0.049069809374110394, 'dropout_rate_Layer_3': 0.015913268300800802, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018272484838626924, 'l1_Layer_2': 0.0001115370841488345, 'l1_Layer_3': 0.00023891291914456954, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.26% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.75 | sMAPE for Test Set is: 24.64% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:48:21,950]\u001b[0m Trial 819 finished with value: 6.2221291545073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005644562441026444, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.019107620347115217, 'dropout_rate_Layer_2': 0.048059840816699395, 'dropout_rate_Layer_3': 0.016054752512887384, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017558002638614977, 'l1_Layer_2': 0.00011444399846653954, 'l1_Layer_3': 0.00023937434413672003, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.80% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.19 | sMAPE for Test Set is: 23.77% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:48:41,319]\u001b[0m Trial 820 finished with value: 6.195988343857555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005001901066704719, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016537705934627944, 'dropout_rate_Layer_2': 0.04537443783397197, 'dropout_rate_Layer_3': 0.01638701959465931, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000183195562465713, 'l1_Layer_2': 0.00011695050656190586, 'l1_Layer_3': 0.00011581419893759262, 'n_units_Layer_1': 130, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 22.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:48:48,099]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:48:54,310]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:49:02,174]\u001b[0m Trial 821 finished with value: 6.219874877020807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005559717241144345, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027095177064796555, 'dropout_rate_Layer_2': 0.04176025488611482, 'dropout_rate_Layer_3': 0.005191147962880744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.706546067947433e-05, 'l1_Layer_2': 6.694503535367263e-05, 'l1_Layer_3': 0.00010936824453795244, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 777 with value: 6.088241099484432.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.21 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:49:07,287]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:49:39,444]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:49:54,115]\u001b[0m Trial 822 finished with value: 6.064490910301011 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005027160131264521, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025188251566001057, 'dropout_rate_Layer_2': 0.00022961425869138727, 'dropout_rate_Layer_3': 0.004830846713710139, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00020943464555777807, 'l1_Layer_2': 6.816734744099893e-05, 'l1_Layer_3': 0.00011522233861987716, 'n_units_Layer_1': 120, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.98% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 8.49 | sMAPE for Test Set is: 23.93% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:50:20,978]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:50:32,921]\u001b[0m Trial 828 finished with value: 6.147006469308721 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005015165704868649, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.010777478705009256, 'dropout_rate_Layer_2': 0.03278735232265322, 'dropout_rate_Layer_3': 0.02901668557833844, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001167551663446056, 'l1_Layer_2': 0.0001613143978025262, 'l1_Layer_3': 0.00019243812619637853, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.65% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.34 | sMAPE for Test Set is: 24.19% | rMAE for Test Set is: 0.73\n",
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.65 | sMAPE for Test Set is: 24.60% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:50:33,074]\u001b[0m Trial 830 finished with value: 6.572902153586445 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008559165564090303, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20165434767798543, 'dropout_rate_Layer_2': 0.03560583431214748, 'dropout_rate_Layer_3': 0.2336678261678991, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0026004162140014324, 'l1_Layer_2': 3.819488270505511e-05, 'l1_Layer_3': 9.441752601286719e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:50:34,358]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:50:43,735]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:50:48,066]\u001b[0m Trial 827 finished with value: 6.176943828625055 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006905901608892726, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008843547874262746, 'dropout_rate_Layer_2': 0.03312599042515896, 'dropout_rate_Layer_3': 0.0003464788658512144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022348350251491137, 'l1_Layer_2': 0.0002474584477378859, 'l1_Layer_3': 0.00018883734598171075, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.24% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.22 | sMAPE for Test Set is: 23.28% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:50:51,751]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:50:57,439]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:51:06,859]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:51:11,670]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:51:18,620]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:51:37,788]\u001b[0m Trial 841 finished with value: 6.688097010312302 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008232282283940016, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02974821913431684, 'dropout_rate_Layer_2': 0.10680136657512837, 'dropout_rate_Layer_3': 0.04329908279411057, 'dropout_rate_Layer_4': 0.11550246322042132, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.5508812421218567e-05, 'l1_Layer_2': 2.7068026928230905e-05, 'l1_Layer_3': 1.624831496798768e-05, 'l1_Layer_4': 1.6619454541965693e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 300, 'n_units_Layer_4': 225}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 22.77% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.21 | sMAPE for Test Set is: 32.23% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:51:41,386]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:51:45,684]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:52:00,218]\u001b[0m Trial 833 finished with value: 6.15060588341026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005012003601352494, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007158495140305466, 'dropout_rate_Layer_2': 0.0374571506056237, 'dropout_rate_Layer_3': 0.0009168592174820531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011411718593764208, 'l1_Layer_2': 8.17520713741107e-05, 'l1_Layer_3': 8.91250615996371e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 21.85% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.16 | sMAPE for Test Set is: 23.72% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:52:20,108]\u001b[0m Trial 845 finished with value: 6.643070047100248 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009580663933118807, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025460066830760103, 'dropout_rate_Layer_2': 0.10709942104150608, 'dropout_rate_Layer_3': 0.02600520073770432, 'dropout_rate_Layer_4': 0.3381733872722842, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.7078483346115703e-05, 'l1_Layer_2': 2.929920808369893e-05, 'l1_Layer_3': 2.0373828830502904e-05, 'l1_Layer_4': 1.881948330550666e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 255, 'n_units_Layer_3': 280, 'n_units_Layer_4': 230}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.28 | sMAPE for Test Set is: 33.60% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:52:24,782]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:52:27,865]\u001b[0m Trial 837 finished with value: 6.128243725960885 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005445383927270233, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01552326802381628, 'dropout_rate_Layer_2': 0.024848117698567797, 'dropout_rate_Layer_3': 0.019613676653291355, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001013549298339089, 'l1_Layer_2': 7.195347143141786e-05, 'l1_Layer_3': 0.00010027085267150851, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.50 | sMAPE for Test Set is: 23.67% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:52:33,454]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:52:36,364]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:52:42,669]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:52:49,143]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:53:01,845]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:53:13,573]\u001b[0m Trial 850 finished with value: 6.782791475443175 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008551436144521075, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02751497555495842, 'dropout_rate_Layer_2': 0.11935680823032917, 'dropout_rate_Layer_3': 0.03187514668596135, 'dropout_rate_Layer_4': 0.14273307766218202, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.609840006751538e-05, 'l1_Layer_2': 2.7947817375750812e-05, 'l1_Layer_3': 0.0003239952562860473, 'l1_Layer_4': 2.4395865626078313e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 260, 'n_units_Layer_3': 295, 'n_units_Layer_4': 225}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.78 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 13.83 | sMAPE for Test Set is: 38.43% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:53:20,051]\u001b[0m Trial 843 finished with value: 6.123070043884982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005525409349095104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00035794282324458674, 'dropout_rate_Layer_2': 0.008089750059656816, 'dropout_rate_Layer_3': 0.012102194945527492, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011473517563778473, 'l1_Layer_2': 6.295434614586218e-05, 'l1_Layer_3': 0.00013292276721529753, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.63 | sMAPE for Test Set is: 24.49% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:53:22,478]\u001b[0m Trial 844 finished with value: 6.17381082285931 and parameters: {'n_hidden': 3, 'learning_rate': 0.000555198466694713, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0083932302414905, 'dropout_rate_Layer_2': 0.008085300653786133, 'dropout_rate_Layer_3': 0.00983639881246587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001194730142891048, 'l1_Layer_2': 0.0001381197898457991, 'l1_Layer_3': 0.00013218504102146966, 'n_units_Layer_1': 115, 'n_units_Layer_2': 130, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.61% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.68 | sMAPE for Test Set is: 24.57% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:53:26,692]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:53:29,162]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:53:46,652]\u001b[0m Trial 857 finished with value: 6.659351994038441 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006574093940287544, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01864783692507486, 'dropout_rate_Layer_2': 0.09170274035447844, 'dropout_rate_Layer_3': 0.018993914531884176, 'dropout_rate_Layer_4': 0.0912917005700848, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.167016415104731e-05, 'l1_Layer_2': 1.923404419691234e-05, 'l1_Layer_3': 1.9284649467552543e-05, 'l1_Layer_4': 1.1754137288019752e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 225, 'n_units_Layer_3': 290, 'n_units_Layer_4': 220}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.93 | sMAPE for Test Set is: 31.38% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:54:10,397]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:20,123]\u001b[0m Trial 853 finished with value: 6.202546154946035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005568188690069457, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 1.5922420955569205e-05, 'dropout_rate_Layer_2': 0.031547839837308085, 'dropout_rate_Layer_3': 0.013010100128855418, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.75598394604248e-05, 'l1_Layer_2': 9.098460482182673e-05, 'l1_Layer_3': 7.291177469050545e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 285}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:54:27,352]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:29,876]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:32,693]\u001b[0m Trial 854 finished with value: 6.169613346620195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005498186395155324, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0002303161098125756, 'dropout_rate_Layer_2': 0.030191811776614095, 'dropout_rate_Layer_3': 0.000910035621315905, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011221689100828321, 'l1_Layer_2': 9.50553086018611e-05, 'l1_Layer_3': 8.916210777642725e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.43 | sMAPE for Test Set is: 24.10% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:54:38,310]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:39,445]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:41,123]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:47,943]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:50,967]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:53,037]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:54:58,762]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:01,906]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:11,990]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:19,811]\u001b[0m Trial 867 finished with value: 6.5961297233066984 and parameters: {'n_hidden': 4, 'learning_rate': 0.000561463509904752, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009947286330997462, 'dropout_rate_Layer_2': 0.10656077861237956, 'dropout_rate_Layer_3': 0.0422619345103476, 'dropout_rate_Layer_4': 0.12485564858452683, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.6561621055038955e-05, 'l1_Layer_2': 2.0041823932543117e-05, 'l1_Layer_3': 1.481047283404112e-05, 'l1_Layer_4': 1.8495511434389456e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 225, 'n_units_Layer_3': 280, 'n_units_Layer_4': 235}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 22.99% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.15 | sMAPE for Test Set is: 32.71% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:55:21,852]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:26,842]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:29,931]\u001b[0m Trial 859 finished with value: 6.126381590110381 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005514550910539839, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.020608096274688334, 'dropout_rate_Layer_2': 0.019129086301193757, 'dropout_rate_Layer_3': 0.02266660165505441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.402075910319851e-05, 'l1_Layer_2': 9.792896334191258e-05, 'l1_Layer_3': 0.00015003449863625832, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 25.48% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:55:30,692]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:40,441]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:43,052]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:46,632]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:51,089]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:51,555]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:55:58,241]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:01,424]\u001b[0m Trial 876 finished with value: 6.612993405719204 and parameters: {'n_hidden': 4, 'learning_rate': 0.000680289670301901, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01090398589599495, 'dropout_rate_Layer_2': 0.0992853053587389, 'dropout_rate_Layer_3': 0.0811633771856969, 'dropout_rate_Layer_4': 0.13680104445857907, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.942574887987169e-05, 'l1_Layer_2': 2.227564543786958e-05, 'l1_Layer_3': 2.2803541854935055e-05, 'l1_Layer_4': 1.3821518006743308e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 290, 'n_units_Layer_4': 205}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.08 | sMAPE for Test Set is: 32.86% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:56:03,569]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:05,559]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:13,761]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:14,624]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:19,121]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:22,703]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:56:31,665]\u001b[0m Trial 887 finished with value: 6.672261920968346 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007041341296576877, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014176696959307854, 'dropout_rate_Layer_2': 0.09719637555396095, 'dropout_rate_Layer_3': 0.07118546855461888, 'dropout_rate_Layer_4': 0.0869386256036455, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.758915836222036e-05, 'l1_Layer_2': 1.9798580549516035e-05, 'l1_Layer_3': 2.7924296347795078e-05, 'l1_Layer_4': 1.0346489484294538e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 290, 'n_units_Layer_4': 220}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.71 | sMAPE for Test Set is: 31.08% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:56:54,849]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:57:01,656]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:57:26,571]\u001b[0m Trial 894 finished with value: 6.636840348307918 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006110744084504378, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012242728364312977, 'dropout_rate_Layer_2': 0.0806789545668739, 'dropout_rate_Layer_3': 0.09741902844758787, 'dropout_rate_Layer_4': 0.08328455399765945, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.793436060129477e-05, 'l1_Layer_2': 2.3079512435847506e-05, 'l1_Layer_3': 3.832710103493302e-05, 'l1_Layer_4': 1.0658919288251398e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 210, 'n_units_Layer_3': 285, 'n_units_Layer_4': 295}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.12 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:57:33,204]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:57:41,292]\u001b[0m Trial 885 finished with value: 6.170502751835552 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006011800785922689, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023639518283830478, 'dropout_rate_Layer_2': 0.025264364831745698, 'dropout_rate_Layer_3': 0.03044995676610146, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001313507999920556, 'l1_Layer_2': 8.208892602358712e-05, 'l1_Layer_3': 0.00017889208725002927, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.28 | sMAPE for Test Set is: 23.27% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:57:54,299]\u001b[0m Trial 890 finished with value: 6.211895259164788 and parameters: {'n_hidden': 3, 'learning_rate': 0.000558872561682869, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013595106220805718, 'dropout_rate_Layer_2': 0.02483670110266152, 'dropout_rate_Layer_3': 0.03030198907691032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001399738114571395, 'l1_Layer_2': 0.00010828560152182749, 'l1_Layer_3': 0.00020660624089631938, 'n_units_Layer_1': 125, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.38% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.29 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:58:07,411]\u001b[0m Trial 897 finished with value: 6.615933348275514 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006435502335439403, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008888144025543712, 'dropout_rate_Layer_2': 0.08133573638758103, 'dropout_rate_Layer_3': 0.08877148387200695, 'dropout_rate_Layer_4': 0.08918678978324104, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.448301226274235e-05, 'l1_Layer_2': 1.5182389378074412e-05, 'l1_Layer_3': 3.9127754225333406e-05, 'l1_Layer_4': 1.0421015210066007e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280, 'n_units_Layer_4': 285}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.30 | sMAPE for Test Set is: 26.91% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:58:14,943]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:58:21,093]\u001b[0m Trial 898 finished with value: 6.646297111023614 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005031568166946721, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013900912870453487, 'dropout_rate_Layer_2': 0.07989126087393687, 'dropout_rate_Layer_3': 0.09423700204020878, 'dropout_rate_Layer_4': 0.08496038377132496, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.12075453983888e-05, 'l1_Layer_2': 1.4942562779023492e-05, 'l1_Layer_3': 3.949068704580105e-05, 'l1_Layer_4': 1.0776249163416902e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 280, 'n_units_Layer_4': 300}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.09 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:58:24,394]\u001b[0m Trial 893 finished with value: 6.237010027664806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006321569188306943, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01161838915911324, 'dropout_rate_Layer_2': 0.024281687372368403, 'dropout_rate_Layer_3': 0.030382961106585085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013532852333592165, 'l1_Layer_2': 0.00011528915016095745, 'l1_Layer_3': 0.00023304375557334754, 'n_units_Layer_1': 145, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 21.43% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.17 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:58:36,879]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.71 | sMAPE for Validation Set is: 23.31% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 17.47 | sMAPE for Test Set is: 53.34% | rMAE for Test Set is: 1.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:58:41,515]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:58:41,543]\u001b[0m Trial 900 finished with value: 6.710361821938158 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006111412911186652, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01332098559370819, 'dropout_rate_Layer_2': 0.08312020484100308, 'dropout_rate_Layer_3': 0.09718722239215222, 'dropout_rate_Layer_4': 0.08078988200759861, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.06278652939828e-05, 'l1_Layer_2': 1.5462723144790175e-05, 'l1_Layer_3': 5.57657601078337e-05, 'l1_Layer_4': 1.0080606622614254e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280, 'n_units_Layer_4': 295}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:59:06,297]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:59:15,266]\u001b[0m Trial 905 finished with value: 6.417239012990905 and parameters: {'n_hidden': 3, 'learning_rate': 0.000695538590417441, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.261794957266444, 'dropout_rate_Layer_2': 0.047512372336765786, 'dropout_rate_Layer_3': 0.18563614331535183, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000516012203979582, 'l1_Layer_2': 7.694462522218022e-05, 'l1_Layer_3': 1.972819738886961e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 209.04 | sMAPE for Test Set is: 59.65% | rMAE for Test Set is: 18.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:59:26,386]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 12:59:34,801]\u001b[0m Trial 906 finished with value: 6.578923628445181 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005895948577827239, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011263392529070992, 'dropout_rate_Layer_2': 0.07711466339130763, 'dropout_rate_Layer_3': 0.1210627404380048, 'dropout_rate_Layer_4': 0.05040082797388426, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.329106196200792e-05, 'l1_Layer_2': 1.0028171363031427e-05, 'l1_Layer_3': 4.158749643964555e-05, 'l1_Layer_4': 1.2900683217770648e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 275, 'n_units_Layer_4': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.49 | sMAPE for Test Set is: 30.06% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:59:43,542]\u001b[0m Trial 899 finished with value: 6.26066657544667 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006784075037996322, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007755107850026578, 'dropout_rate_Layer_2': 0.014452327057538255, 'dropout_rate_Layer_3': 0.012357182216762706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002457461794518098, 'l1_Layer_2': 0.00015511936307295555, 'l1_Layer_3': 0.0001136320305247598, 'n_units_Layer_1': 135, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.77 | sMAPE for Test Set is: 24.98% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 12:59:48,068]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:00:06,809]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:00:22,408]\u001b[0m Trial 911 finished with value: 6.368393329750727 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007609907721277998, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.256857880822724, 'dropout_rate_Layer_2': 0.04178677899183637, 'dropout_rate_Layer_3': 0.19124265708981353, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004575719028700271, 'l1_Layer_2': 5.4079553431244275e-05, 'l1_Layer_3': 1.0055350269439553e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 75, 'n_units_Layer_3': 95}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 22.35% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 280.09 | sMAPE for Test Set is: 61.75% | rMAE for Test Set is: 24.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:00:46,599]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:00:50,567]\u001b[0m Trial 913 finished with value: 6.567817793605603 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005496237917356602, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006928614522628278, 'dropout_rate_Layer_2': 0.07695662666124617, 'dropout_rate_Layer_3': 0.10576132285043266, 'dropout_rate_Layer_4': 0.04578704566869085, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.570486404302692e-05, 'l1_Layer_2': 1.1475662687705798e-05, 'l1_Layer_3': 5.0939776115819136e-05, 'l1_Layer_4': 1.2582460729647905e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 275, 'n_units_Layer_4': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.10 | sMAPE for Test Set is: 29.29% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:00:56,168]\u001b[0m Trial 907 finished with value: 6.215280170260862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007105478972875947, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006905864583292844, 'dropout_rate_Layer_2': 0.008149336962079099, 'dropout_rate_Layer_3': 0.041422657676534, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017775292460317223, 'l1_Layer_2': 7.027198332907772e-05, 'l1_Layer_3': 0.0001433474689289225, 'n_units_Layer_1': 135, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.69% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.58 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:01:08,954]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:12,233]\u001b[0m Trial 909 finished with value: 6.244016823451724 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006840697288060637, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007094881661210205, 'dropout_rate_Layer_2': 0.0143359192759509, 'dropout_rate_Layer_3': 0.007855490542526187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010541483929179999, 'l1_Layer_2': 6.668572947214266e-05, 'l1_Layer_3': 6.228134583819746e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.70 | sMAPE for Test Set is: 24.71% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:01:14,261]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:18,332]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:22,201]\u001b[0m Trial 914 finished with value: 6.646630190281507 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005535946116742203, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009906929800566174, 'dropout_rate_Layer_2': 0.0789524628616792, 'dropout_rate_Layer_3': 0.11207111571162215, 'dropout_rate_Layer_4': 0.017450686098152722, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.043791176304978e-05, 'l1_Layer_2': 1.0478182130290159e-05, 'l1_Layer_3': 3.516984286037226e-05, 'l1_Layer_4': 1.2877861443537474e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 275, 'n_units_Layer_4': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.21 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:01:24,696]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:33,665]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:39,191]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:44,821]\u001b[0m Trial 919 finished with value: 6.612908923486162 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006172485909405628, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009915554509598886, 'dropout_rate_Layer_2': 0.09131722308662359, 'dropout_rate_Layer_3': 0.10279936871262486, 'dropout_rate_Layer_4': 0.026657237407831415, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000115526078955891, 'l1_Layer_2': 1.154459842883937e-05, 'l1_Layer_3': 6.427022833407476e-05, 'l1_Layer_4': 1.4318603168670481e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285, 'n_units_Layer_4': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.75 | sMAPE for Test Set is: 31.56% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:01:49,398]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:01:53,833]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:02:06,322]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:02:20,173]\u001b[0m Trial 927 finished with value: 6.617963253617551 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005492367680748599, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004468071878550514, 'dropout_rate_Layer_2': 0.07061067324357054, 'dropout_rate_Layer_3': 0.11276156105358309, 'dropout_rate_Layer_4': 0.018969794817632307, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00010105360853750947, 'l1_Layer_2': 1.070510781269315e-05, 'l1_Layer_3': 7.407539439949295e-05, 'l1_Layer_4': 1.4147661013612833e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260, 'n_units_Layer_4': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 13.98 | sMAPE for Test Set is: 38.77% | rMAE for Test Set is: 1.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:02:25,751]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:02:36,033]\u001b[0m Trial 916 finished with value: 6.127893537218359 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005607647282094805, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02231722936764382, 'dropout_rate_Layer_2': 0.04296191732499261, 'dropout_rate_Layer_3': 0.03644730529910101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.031525528322648e-05, 'l1_Layer_2': 9.272145594778407e-05, 'l1_Layer_3': 0.00015953391353601293, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.27% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 25.16% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:02:39,075]\u001b[0m Trial 928 finished with value: 6.632876691629182 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005135819831225091, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00013114729190859264, 'dropout_rate_Layer_2': 0.07045012051408092, 'dropout_rate_Layer_3': 0.10849647145070207, 'dropout_rate_Layer_4': 0.015188108020603129, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0001320497783616687, 'l1_Layer_2': 1.0973825932037306e-05, 'l1_Layer_3': 4.565186838249409e-05, 'l1_Layer_4': 1.471086226588682e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 260, 'n_units_Layer_4': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 22.96% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:02:55,524]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:02:58,086]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:07,607]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:11,968]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:14,191]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:22,632]\u001b[0m Trial 924 finished with value: 6.139900630674077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005030505149796937, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.024764820927306662, 'dropout_rate_Layer_2': 0.06484789899002369, 'dropout_rate_Layer_3': 0.024682026149179626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015528382033875562, 'l1_Layer_2': 5.8378884426808166e-05, 'l1_Layer_3': 0.0002649562227882849, 'n_units_Layer_1': 120, 'n_units_Layer_2': 160, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.79 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:03:30,749]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:36,463]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:39,174]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:41,092]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:03:49,285]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:04:09,366]\u001b[0m Trial 940 finished with value: 6.634993139388634 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006056999353387628, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007834902407381095, 'dropout_rate_Layer_2': 0.06897555528336179, 'dropout_rate_Layer_3': 0.10441366647247464, 'dropout_rate_Layer_4': 0.03308648617658763, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014362710514856362, 'l1_Layer_2': 1.0469871862692486e-05, 'l1_Layer_3': 7.242821721356054e-05, 'l1_Layer_4': 1.4077333363554229e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 260, 'n_units_Layer_4': 285}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.67 | sMAPE for Test Set is: 30.67% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:04:16,898]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:04:22,356]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:04:29,970]\u001b[0m Trial 937 finished with value: 6.155147682810532 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005375076061741, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025710916766890766, 'dropout_rate_Layer_2': 0.03169631614506312, 'dropout_rate_Layer_3': 0.014495838601664333, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.229914766982598e-05, 'l1_Layer_2': 0.00010220404297888843, 'l1_Layer_3': 0.00015308254704243053, 'n_units_Layer_1': 110, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.05 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:04:36,288]\u001b[0m Trial 941 finished with value: 6.58638345151779 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006141250839683653, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14345133295132267, 'dropout_rate_Layer_2': 0.15773882097431358, 'dropout_rate_Layer_3': 0.21102165593000174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0021894444907831555, 'l1_Layer_2': 1.4745546116015247e-05, 'l1_Layer_3': 0.0013064673616299811, 'n_units_Layer_1': 270, 'n_units_Layer_2': 260, 'n_units_Layer_3': 60}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:04:39,121]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:04:47,986]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:04:50,637]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:04:54,595]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:03,904]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:08,541]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:22,149]\u001b[0m Trial 943 finished with value: 6.224593317148483 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016160999750904, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02645329526396823, 'dropout_rate_Layer_2': 0.0771847731277709, 'dropout_rate_Layer_3': 0.045609174313227946, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012927550274913547, 'l1_Layer_2': 7.049447336589013e-05, 'l1_Layer_3': 0.00020106895079552027, 'n_units_Layer_1': 105, 'n_units_Layer_2': 170, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.56% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.48 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:05:29,960]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:32,707]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:35,847]\u001b[0m Trial 952 finished with value: 6.5180802653503775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015213622716344069, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3051022230755302, 'dropout_rate_Layer_2': 0.11123343353202858, 'dropout_rate_Layer_3': 0.23828711839988254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002838166579355614, 'l1_Layer_2': 1.1435265932493335e-05, 'l1_Layer_3': 0.00042098361438003984, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 90}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 22.61% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:05:37,971]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:43,419]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:47,175]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:05:50,391]\u001b[0m Trial 954 finished with value: 6.594889738967493 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005939950872639207, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014604813758374477, 'dropout_rate_Layer_2': 0.0854600995107277, 'dropout_rate_Layer_3': 0.11476784702614244, 'dropout_rate_Layer_4': 0.03608220541644646, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00015543631924619267, 'l1_Layer_2': 1.047448488328583e-05, 'l1_Layer_3': 4.887119477950072e-05, 'l1_Layer_4': 1.0010038164734355e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 195, 'n_units_Layer_3': 250, 'n_units_Layer_4': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.40 | sMAPE for Test Set is: 33.10% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:06:16,118]\u001b[0m Trial 958 finished with value: 6.5946488887369235 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005896468389941767, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013246576132241302, 'dropout_rate_Layer_2': 0.08019440967505538, 'dropout_rate_Layer_3': 0.09165989635413441, 'dropout_rate_Layer_4': 0.03451330403099915, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017834659917168204, 'l1_Layer_2': 1.604395830172883e-05, 'l1_Layer_3': 5.4976423406093596e-05, 'l1_Layer_4': 1.014359767908236e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270, 'n_units_Layer_4': 300}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.59 | sMAPE for Validation Set is: 22.95% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.96 | sMAPE for Test Set is: 26.28% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:06:20,254]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:06:24,654]\u001b[0m Trial 961 finished with value: 6.3587081942708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006718382653623052, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27811841626159434, 'dropout_rate_Layer_2': 0.02617705882684051, 'dropout_rate_Layer_3': 0.19143442412840045, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003536135079590238, 'l1_Layer_2': 2.5713900095362196e-05, 'l1_Layer_3': 1.3139462947035185e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 22.10% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 173.72 | sMAPE for Test Set is: 59.72% | rMAE for Test Set is: 15.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:07:03,817]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:09,417]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:12,927]\u001b[0m Trial 962 finished with value: 6.160724493652007 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006301618482701405, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012663748592892276, 'dropout_rate_Layer_2': 0.08316733145352274, 'dropout_rate_Layer_3': 0.02950064277063917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010723736626688919, 'l1_Layer_2': 0.00010074795957922235, 'l1_Layer_3': 0.00013638294029046913, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.20 | sMAPE for Test Set is: 23.39% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:07:16,032]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:19,552]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:23,504]\u001b[0m Trial 960 finished with value: 6.186411457493541 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005876028515272052, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026133595623060415, 'dropout_rate_Layer_2': 0.05375547364944178, 'dropout_rate_Layer_3': 0.03423107455916797, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015954372244891135, 'l1_Layer_2': 9.172546210206662e-05, 'l1_Layer_3': 0.00026961782281073913, 'n_units_Layer_1': 115, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.59% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 25.09% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:07:24,175]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:31,241]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:39,289]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:43,968]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:07:46,810]\u001b[0m Trial 964 finished with value: 6.195659107785132 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006333655775467801, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.012916520467255506, 'dropout_rate_Layer_2': 0.01354456186796113, 'dropout_rate_Layer_3': 0.03020766726907435, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010528166491947634, 'l1_Layer_2': 0.00010703385433278457, 'l1_Layer_3': 0.00014016488926626132, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.00 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:07:53,342]\u001b[0m Trial 971 finished with value: 6.608381817303408 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005790862954336761, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0010136737561927678, 'dropout_rate_Layer_2': 0.07358787257428591, 'dropout_rate_Layer_3': 0.10926281308334951, 'dropout_rate_Layer_4': 0.01341357674093939, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011906200516131759, 'l1_Layer_2': 1.737716636703211e-05, 'l1_Layer_3': 7.893906985925667e-05, 'l1_Layer_4': 1.2831961977085332e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255, 'n_units_Layer_4': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 23.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 12.24 | sMAPE for Test Set is: 32.34% | rMAE for Test Set is: 1.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:07:56,085]\u001b[0m Trial 970 finished with value: 6.39331883378438 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009855921502915166, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2841701465343744, 'dropout_rate_Layer_2': 0.02562959515301297, 'dropout_rate_Layer_3': 0.19232592609855959, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025002479467569423, 'l1_Layer_2': 2.7986472143426097e-05, 'l1_Layer_3': 1.3633728822953464e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 100, 'n_units_Layer_3': 80}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 58.17 | sMAPE for Test Set is: 47.60% | rMAE for Test Set is: 5.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:07:58,125]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:08:13,095]\u001b[0m Trial 976 finished with value: 6.613395925465931 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006467919785104416, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0017182139794304913, 'dropout_rate_Layer_2': 0.08672111119992099, 'dropout_rate_Layer_3': 0.0865174834548796, 'dropout_rate_Layer_4': 0.045182076490334164, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000272013981766933, 'l1_Layer_2': 1.6520323808695543e-05, 'l1_Layer_3': 6.804045554838811e-05, 'l1_Layer_4': 1.2840954005444982e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255, 'n_units_Layer_4': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.61 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.26 | sMAPE for Test Set is: 28.50% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:08:15,564]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:08:47,786]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:08:52,018]\u001b[0m Trial 980 finished with value: 6.601908325724881 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006606417210653485, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014511063171330535, 'dropout_rate_Layer_2': 0.060198790732113316, 'dropout_rate_Layer_3': 0.08450624118458945, 'dropout_rate_Layer_4': 0.01527029928049217, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0003263358543278557, 'l1_Layer_2': 1.7314273425274993e-05, 'l1_Layer_3': 8.227486167033637e-05, 'l1_Layer_4': 1.2303572679459127e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235, 'n_units_Layer_4': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 22.66% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.37 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:08:59,837]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:08,385]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:15,754]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:20,212]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:25,860]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:29,162]\u001b[0m Trial 975 finished with value: 6.17731608716615 and parameters: {'n_hidden': 3, 'learning_rate': 0.000670713435686922, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013557690905005622, 'dropout_rate_Layer_2': 0.005921877981266835, 'dropout_rate_Layer_3': 0.025354458335726512, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014613163605018174, 'l1_Layer_2': 8.038000768637777e-05, 'l1_Layer_3': 0.00021785490617373763, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.82 | sMAPE for Test Set is: 24.61% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:09:31,235]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:38,590]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:39,610]\u001b[0m Trial 978 finished with value: 6.2159132792348375 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005476104873310115, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.022782919512916187, 'dropout_rate_Layer_2': 0.007113575417863116, 'dropout_rate_Layer_3': 0.023475919460285204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019774688313469927, 'l1_Layer_2': 5.9345985718609535e-05, 'l1_Layer_3': 0.00023770414475372353, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.33% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 25.10% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:09:47,837]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:54,989]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:09:55,952]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:00,193]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:04,774]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:15,556]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:16,170]\u001b[0m Trial 988 finished with value: 6.537500936222755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010981320968137434, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35946233552879897, 'dropout_rate_Layer_2': 0.12445531027699051, 'dropout_rate_Layer_3': 0.24921747684501433, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016239577429981225, 'l1_Layer_2': 1.2123999472477168e-05, 'l1_Layer_3': 0.0004625969999106037, 'n_units_Layer_1': 160, 'n_units_Layer_2': 280, 'n_units_Layer_3': 90}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:10:21,472]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:25,578]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:29,084]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:33,913]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:40,489]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:49,495]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:53,455]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:10:53,880]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:02,893]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:24,560]\u001b[0m Trial 996 finished with value: 6.2058542540342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006004452120441215, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 6.309944577025627e-05, 'dropout_rate_Layer_2': 0.02151130998035005, 'dropout_rate_Layer_3': 0.038342285020719465, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.107510788458951e-05, 'l1_Layer_2': 0.00012147353788713386, 'l1_Layer_3': 7.327670613353226e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:11:25,095]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 11.21 | sMAPE for Test Set is: 31.17% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:11:28,816]\u001b[0m Trial 1008 finished with value: 6.635231894588852 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007023043422749077, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.007599417403833791, 'dropout_rate_Layer_2': 0.09257996787085263, 'dropout_rate_Layer_3': 0.13805264707516268, 'dropout_rate_Layer_4': 0.018088119540543044, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00012430224346996496, 'l1_Layer_2': 1.009380834876352e-05, 'l1_Layer_3': 0.00018248100616674842, 'l1_Layer_4': 1.6777089612109175e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 205, 'n_units_Layer_3': 240, 'n_units_Layer_4': 280}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:36,771]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:37,283]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:43,341]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:46,384]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:50,663]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:51,196]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:11:55,969]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:01,134]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:03,557]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:07,003]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:20,129]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:30,525]\u001b[0m Trial 1007 finished with value: 6.167480947248069 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007449074338912291, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014167533710355748, 'dropout_rate_Layer_2': 0.03924828961374256, 'dropout_rate_Layer_3': 0.011025940736497111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.353979338174188e-05, 'l1_Layer_2': 7.341674775695542e-05, 'l1_Layer_3': 0.0001896543167346288, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 260}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.90 | sMAPE for Test Set is: 22.79% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:12:31,342]\u001b[0m Trial 1021 finished with value: 6.569624423379257 and parameters: {'n_hidden': 4, 'learning_rate': 0.000616163249474377, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.016747313909020668, 'dropout_rate_Layer_2': 0.07198655900375908, 'dropout_rate_Layer_3': 0.13691040337422547, 'dropout_rate_Layer_4': 0.02802554761942668, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.902762105309738e-05, 'l1_Layer_2': 1.3457632231074051e-05, 'l1_Layer_3': 0.0002052296929533264, 'l1_Layer_4': 1.235232957214064e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250, 'n_units_Layer_4': 285}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.51 | sMAPE for Test Set is: 32.08% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:12:39,177]\u001b[0m Trial 1019 finished with value: 6.665639640443493 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006448494047692875, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017106782419903082, 'dropout_rate_Layer_2': 0.08097607020876768, 'dropout_rate_Layer_3': 0.1428678059955742, 'dropout_rate_Layer_4': 0.031405847349630825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013932396870560998, 'l1_Layer_2': 1.3865383831002674e-05, 'l1_Layer_3': 4.75890883679993e-05, 'l1_Layer_4': 0.00043586262991859626, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 250, 'n_units_Layer_4': 285}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 22.78% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.80 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:12:39,748]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:41,668]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:47,206]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:48,583]\u001b[0m Trial 1022 finished with value: 6.619176188845299 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006405791414681013, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.017085488013553585, 'dropout_rate_Layer_2': 0.07935705661278417, 'dropout_rate_Layer_3': 0.13590943562166177, 'dropout_rate_Layer_4': 0.010525876321102884, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00013301722179721813, 'l1_Layer_2': 1.3220708041368864e-05, 'l1_Layer_3': 4.975202064791003e-05, 'l1_Layer_4': 1.2155134806138462e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 215, 'n_units_Layer_3': 230, 'n_units_Layer_4': 290}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 22.79% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.33 | sMAPE for Test Set is: 28.38% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:12:50,849]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:12:55,470]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:02,452]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:10,639]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:21,031]\u001b[0m Trial 1031 finished with value: 6.554676868217752 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006188189484495553, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0198715765157079, 'dropout_rate_Layer_2': 0.07472881933639328, 'dropout_rate_Layer_3': 0.15995775487639055, 'dropout_rate_Layer_4': 0.03850905357605769, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00016721422118191545, 'l1_Layer_2': 1.681347934360197e-05, 'l1_Layer_3': 5.7555601791295954e-05, 'l1_Layer_4': 1.2186889615194138e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 190, 'n_units_Layer_3': 245, 'n_units_Layer_4': 255}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 22.73% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.53 | sMAPE for Test Set is: 32.06% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:13:25,146]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:29,938]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:30,208]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:33,075]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:38,215]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:43,004]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:47,155]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:51,277]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:13:59,781]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:08,021]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:14,256]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:18,620]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:23,005]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:32,197]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:39,348]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:39,703]\u001b[0m Trial 1033 finished with value: 6.199395504213065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005513229782495401, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026169479195641394, 'dropout_rate_Layer_2': 0.01964563807995461, 'dropout_rate_Layer_3': 0.02389179701104044, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012171901143152857, 'l1_Layer_2': 0.00011524482076410982, 'l1_Layer_3': 0.0001258741964835157, 'n_units_Layer_1': 135, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.60% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.59 | sMAPE for Test Set is: 24.79% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:14:40,782]\u001b[0m Trial 1046 finished with value: 6.5750583803407805 and parameters: {'n_hidden': 4, 'learning_rate': 0.000739491203398663, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031765999226670096, 'dropout_rate_Layer_2': 0.08652755349415674, 'dropout_rate_Layer_3': 0.11254136758167906, 'dropout_rate_Layer_4': 0.0402843434375763, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00011142705097842019, 'l1_Layer_2': 1.4292551330182122e-05, 'l1_Layer_3': 4.569896583651461e-05, 'l1_Layer_4': 1.007280844201347e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 200, 'n_units_Layer_3': 245, 'n_units_Layer_4': 290}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 10.81 | sMAPE for Test Set is: 30.12% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:14:46,244]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:51,066]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:51,895]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:53,832]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:14:57,583]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:00,382]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:02,006]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:03,293]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:07,304]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:08,846]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:12,074]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:14,434]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:16,911]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:17,336]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:23,209]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:27,552]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:29,684]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:36,356]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:36,721]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:39,607]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:15:51,584]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:09,351]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:12,878]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:16,957]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:17,686]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:23,942]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:29,209]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:33,454]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:49,781]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:53,528]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:55,047]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:16:59,671]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:03,140]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:07,415]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:15,448]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:18,938]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:21,725]\u001b[0m Trial 1069 finished with value: 6.23306324387278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006266861302116533, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027385572576284895, 'dropout_rate_Layer_2': 0.024520191757285086, 'dropout_rate_Layer_3': 0.03003590992824543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010965088631513285, 'l1_Layer_2': 7.985388631919661e-05, 'l1_Layer_3': 9.77287129814391e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 155, 'n_units_Layer_3': 290}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.76 | sMAPE for Test Set is: 24.67% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:17:22,925]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:27,630]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:29,650]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:29,746]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:35,123]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:43,773]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:45,592]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:46,040]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:17:58,811]\u001b[0m Trial 1078 finished with value: 6.194224726131648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005560394749691405, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.046305556107090154, 'dropout_rate_Layer_2': 0.03476949977611412, 'dropout_rate_Layer_3': 0.0317266259019007, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015532690143946234, 'l1_Layer_2': 0.0001021790205856799, 'l1_Layer_3': 0.00018007497435657297, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:18:05,063]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:05,546]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:12,816]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:19,737]\u001b[0m Trial 1095 finished with value: 6.376491128350825 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005500491418142355, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21699604691836993, 'dropout_rate_Layer_2': 0.009032309367739038, 'dropout_rate_Layer_3': 0.18090796882254162, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00024340089230462272, 'l1_Layer_2': 0.0006606132885045224, 'l1_Layer_3': 2.4302351037788778e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 55, 'n_units_Layer_3': 90}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 107.26 | sMAPE for Test Set is: 55.50% | rMAE for Test Set is: 9.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:18:21,687]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:26,151]\u001b[0m Trial 1094 finished with value: 6.452858254771744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008706796756865929, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3941957443305576, 'dropout_rate_Layer_2': 0.06051531670157616, 'dropout_rate_Layer_3': 0.1425339508642805, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000876757880003276, 'l1_Layer_2': 2.643903075393726e-05, 'l1_Layer_3': 0.00016896282028185946, 'n_units_Layer_1': 250, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 22.37% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.36 | sMAPE for Test Set is: 23.93% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:18:26,569]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:28,427]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:37,526]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:39,636]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:40,091]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:40,405]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:42,971]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:52,429]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:55,767]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:18:59,589]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:02,310]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:05,252]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:07,257]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:11,307]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:12,074]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:13,777]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:18,918]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:21,153]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:27,171]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:27,971]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:30,221]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:33,260]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:35,637]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:39,634]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:45,530]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:47,853]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:48,410]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:54,366]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:57,451]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:19:57,762]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:07,513]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:10,163]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:14,881]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:26,772]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:27,496]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:36,395]\u001b[0m Trial 1124 finished with value: 6.579234412962077 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005128770835184918, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015354953608514818, 'dropout_rate_Layer_2': 0.09793326077066954, 'dropout_rate_Layer_3': 0.0882858507996008, 'dropout_rate_Layer_4': 0.046601476345073924, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026805797049604687, 'l1_Layer_2': 1.3038759264223023e-05, 'l1_Layer_3': 5.304163544931299e-05, 'l1_Layer_4': 1.2032710500427385e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245, 'n_units_Layer_4': 290}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 9.52 | sMAPE for Test Set is: 24.91% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:20:36,954]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:42,008]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:46,792]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:51,638]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:20:52,853]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:00,301]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:04,469]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:05,436]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:05,592]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:12,636]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:18,462]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:21,298]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:22,646]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:27,485]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:31,729]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:34,959]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:35,153]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:39,239]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:44,608]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:45,096]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:45,241]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:53,810]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:54,480]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:21:59,422]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:03,989]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:04,217]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:05,742]\u001b[0m Trial 1131 finished with value: 6.288665560052437 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005996874400274623, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013664273966743096, 'dropout_rate_Layer_2': 0.09852556773573153, 'dropout_rate_Layer_3': 0.12261582068148756, 'dropout_rate_Layer_4': 0.023856525980789762, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00606544362967091, 'l1_Layer_2': 0.0035032203466026264, 'l1_Layer_3': 5.642244563409498e-05, 'l1_Layer_4': 0.0007014100740108547, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 240, 'n_units_Layer_4': 140}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 35.66 | sMAPE for Test Set is: 66.15% | rMAE for Test Set is: 3.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:22:05,982]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:16,040]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:16,837]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:17,268]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:27,210]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:33,336]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:36,658]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:40,057]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:41,145]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:45,350]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:45,931]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:48,357]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:22:52,471]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:23:17,873]\u001b[0m Trial 1178 finished with value: 6.497186738767244 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018556694654182943, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3401818992084398, 'dropout_rate_Layer_2': 0.064486052802962, 'dropout_rate_Layer_3': 0.20698743115858304, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002812620955896941, 'l1_Layer_2': 1.3021066738201338e-05, 'l1_Layer_3': 0.0005137095601319717, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 65}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 22.29% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 8.12 | sMAPE for Test Set is: 22.83% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:23:22,850]\u001b[0m Trial 1179 finished with value: 6.301263165664157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007379726251919395, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2322794945605853, 'dropout_rate_Layer_2': 0.011817034786214674, 'dropout_rate_Layer_3': 0.08334571399656171, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00039117016089497707, 'l1_Layer_2': 0.00029088218429272313, 'l1_Layer_3': 2.6909413022202837e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 95, 'n_units_Layer_3': 105}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 162.41 | sMAPE for Test Set is: 58.56% | rMAE for Test Set is: 14.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:23:28,422]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:23:34,203]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:23:36,788]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:13,183]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:15,492]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:18,076]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:23,095]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:26,153]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:28,794]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:29,441]\u001b[0m Trial 1177 finished with value: 6.253184778902271 and parameters: {'n_hidden': 3, 'learning_rate': 0.000592270154729416, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015391380611418547, 'dropout_rate_Layer_2': 0.030413098748678383, 'dropout_rate_Layer_3': 0.04351394671057552, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.249072235140606e-05, 'l1_Layer_2': 4.636701161558631e-05, 'l1_Layer_3': 0.00012839422630678637, 'n_units_Layer_1': 120, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:24:36,118]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:39,586]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:41,775]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:43,297]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:47,738]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:48,627]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:53,190]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:57,157]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:24:59,735]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:02,091]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:05,895]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:10,376]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:15,283]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:19,229]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:26,020]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:29,023]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:25:41,291]\u001b[0m Trial 1189 finished with value: 6.327629612554247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008978518220820367, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.252950096670653, 'dropout_rate_Layer_2': 0.008945390072950709, 'dropout_rate_Layer_3': 0.08407308586212237, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003996606791073242, 'l1_Layer_2': 0.00044550728510273264, 'l1_Layer_3': 2.7050942077757174e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 100}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 197.37 | sMAPE for Test Set is: 59.41% | rMAE for Test Set is: 17.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:25:44,298]\u001b[0m Trial 1202 finished with value: 6.419452349874061 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018352984083216883, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3790599413762562, 'dropout_rate_Layer_2': 0.07409736670543388, 'dropout_rate_Layer_3': 0.20356545848117963, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.002725315788252888, 'l1_Layer_2': 1.3453555714430791e-05, 'l1_Layer_3': 0.000497684379744949, 'n_units_Layer_1': 180, 'n_units_Layer_2': 230, 'n_units_Layer_3': 65}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 8.18 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:26:09,962]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:26:15,022]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:26:30,359]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:26:32,366]\u001b[0m Trial 1209 finished with value: 6.276134829345253 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012905176291810108, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25123626042802794, 'dropout_rate_Layer_2': 0.008995071170013465, 'dropout_rate_Layer_3': 0.09490787894361424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006278700902202188, 'l1_Layer_2': 0.0012194333098276351, 'l1_Layer_3': 2.652749564703961e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 100}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 21.74% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 246.70 | sMAPE for Test Set is: 59.74% | rMAE for Test Set is: 21.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:26:37,407]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:26:51,126]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:26:56,390]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:03,398]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:06,627]\u001b[0m Trial 1206 finished with value: 6.218695419794973 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005483645617400173, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 5.684340842646837e-05, 'dropout_rate_Layer_2': 0.018543804007367586, 'dropout_rate_Layer_3': 0.047479722884647906, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000162203344143351, 'l1_Layer_2': 9.999306680534613e-05, 'l1_Layer_3': 0.0003375952637674094, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 290}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 21.22% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 9.04 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:27:11,682]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:16,138]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:21,591]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:25,471]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:28,130]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:31,475]\u001b[0m Trial 1208 finished with value: 6.14052922352597 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005000749899213588, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02096360718949131, 'dropout_rate_Layer_2': 0.018429593370374264, 'dropout_rate_Layer_3': 0.0089463050398002, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014630498517904185, 'l1_Layer_2': 0.00010434668899728946, 'l1_Layer_3': 0.00015283462362447917, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.43% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.30 | sMAPE for Test Set is: 23.94% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:27:33,428]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:39,601]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:43,980]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:46,298]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:49,226]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:55,007]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:27:58,261]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:02,490]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:05,585]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:07,100]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:12,196]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:16,939]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:17,182]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:23,927]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:27,005]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:30,094]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:37,442]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:40,082]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:44,071]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:45,669]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:46,169]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:28:55,510]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.73 | sMAPE for Test Set is: 21.77% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:29:01,119]\u001b[0m Trial 1223 finished with value: 6.206924439498731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006680798435245408, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03850357137386986, 'dropout_rate_Layer_2': 0.013266518252359761, 'dropout_rate_Layer_3': 0.029881039232742927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014077699748452665, 'l1_Layer_2': 5.995182724635601e-05, 'l1_Layer_3': 0.00014527870426675438, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:07,500]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:16,002]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:31,601]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:37,339]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:41,502]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:43,776]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:48,645]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:50,651]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:56,003]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:29:58,654]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:05,617]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:15,492]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:19,765]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:24,962]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:33,528]\u001b[0m Trial 1245 finished with value: 6.245240144592085 and parameters: {'n_hidden': 3, 'learning_rate': 0.000592400929066549, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01523217646049893, 'dropout_rate_Layer_2': 0.03945123140349548, 'dropout_rate_Layer_3': 0.023864679874069032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021899393180428985, 'l1_Layer_2': 7.400878058378713e-05, 'l1_Layer_3': 0.00010179137080688711, 'n_units_Layer_1': 110, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 21.40% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 8.78 | sMAPE for Test Set is: 24.99% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:30:33,907]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:43,017]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:53,549]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:30:59,413]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:11,440]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:15,970]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:21,793]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:32,760]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:44,560]\u001b[0m Trial 1258 finished with value: 6.181355679107092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005540493744043829, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03193911607309984, 'dropout_rate_Layer_2': 0.013977907734409814, 'dropout_rate_Layer_3': 0.029589036676380145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015301868265529884, 'l1_Layer_2': 9.735660693960202e-05, 'l1_Layer_3': 0.00021866137352296049, 'n_units_Layer_1': 120, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.50% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 7.94 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:31:46,445]\u001b[0m Trial 1264 finished with value: 6.258134683729384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012959827016201459, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23757821591234282, 'dropout_rate_Layer_2': 0.008431872150939768, 'dropout_rate_Layer_3': 0.06356781225822508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008271173568624289, 'l1_Layer_2': 0.0012440113223903607, 'l1_Layer_3': 2.801114878436108e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 21.75% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 308.75 | sMAPE for Test Set is: 61.04% | rMAE for Test Set is: 26.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:31:51,460]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:54,500]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:31:56,395]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:04,822]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:10,991]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:15,668]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:19,731]\u001b[0m Trial 1265 finished with value: 6.276307831113425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012775654862240966, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2627017709868885, 'dropout_rate_Layer_2': 0.01010196287661212, 'dropout_rate_Layer_3': 0.08435757455127027, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008655555382940303, 'l1_Layer_2': 0.0011369859260904139, 'l1_Layer_3': 1.636783887259354e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 155, 'n_units_Layer_3': 100}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 21.99% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 346.72 | sMAPE for Test Set is: 61.82% | rMAE for Test Set is: 30.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:32:22,763]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:26,982]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:30,396]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:32,812]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:35,040]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:37,986]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:38,245]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:38,556]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:46,368]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:48,892]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:51,798]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:55,270]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:55,562]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:32:58,939]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:06,903]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:10,809]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:16,725]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:16,921]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:17,042]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:25,802]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:25,953]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:27,761]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 9.54 | sMAPE for Test Set is: 25.34% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:33:29,563]\u001b[0m Trial 1288 finished with value: 6.551167657660179 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012414757871035825, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.189532337755141, 'dropout_rate_Layer_2': 0.13512712133810956, 'dropout_rate_Layer_3': 0.2262536469458664, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0018333579526628202, 'l1_Layer_2': 2.1642289023802572e-05, 'l1_Layer_3': 6.205846679016438e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 280, 'n_units_Layer_3': 235}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:35,925]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:40,758]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:43,531]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:44,039]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:50,421]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:53,531]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:33:57,449]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:02,147]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:02,789]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:11,463]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:14,424]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:17,402]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:21,830]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:26,660]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:29,790]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:35,684]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:43,468]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:49,141]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:49,439]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:34:57,496]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:04,709]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:06,152]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:10,133]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:10,682]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:17,007]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:19,875]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:19,978]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:22,379]\u001b[0m Trial 1299 finished with value: 6.139196021951203 and parameters: {'n_hidden': 3, 'learning_rate': 0.000549399341951515, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011851589670151394, 'dropout_rate_Layer_2': 0.034055867905269335, 'dropout_rate_Layer_3': 0.030886351347634212, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00018451660748793427, 'l1_Layer_2': 0.00013479058903694926, 'l1_Layer_3': 6.353537209580632e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 822 with value: 6.064490910301011.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 21.13% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.26 | sMAPE for Test Set is: 23.56% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:35:25,601]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:31,416]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:32,286]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:36,574]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:42,946]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:43,650]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:52,869]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:35:56,895]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:00,600]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:04,060]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:06,775]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:11,409]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:11,701]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:19,258]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:25,848]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:36,727]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:43,068]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:48,907]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:53,189]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:36:57,935]\u001b[0m Trial 1332 finished with value: 6.047279259432073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007344290280142016, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05150790337752495, 'dropout_rate_Layer_2': 0.04968917517667662, 'dropout_rate_Layer_3': 0.04142967459143987, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002462638888068901, 'l1_Layer_2': 0.00011199425311118511, 'l1_Layer_3': 6.877079966738086e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 275}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 20.98% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 7.89 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:37:00,449]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:05,150]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:13,194]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:18,748]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:22,176]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:27,045]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:36,071]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:46,154]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:51,575]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:37:55,986]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:03,665]\u001b[0m Trial 1357 finished with value: 6.5957914091856535 and parameters: {'n_hidden': 4, 'learning_rate': 0.000747095934478536, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.008955447839400275, 'dropout_rate_Layer_2': 0.06371297112531711, 'dropout_rate_Layer_3': 0.10200219016552059, 'dropout_rate_Layer_4': 0.007546152514235472, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005211182571968424, 'l1_Layer_2': 1.4682150157556588e-05, 'l1_Layer_3': 5.264434536524002e-05, 'l1_Layer_4': 1.1740343144711428e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 240, 'n_units_Layer_4': 300}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 29.16% | rMAE for Test Set is: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:38:10,944]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:14,176]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:20,521]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:20,779]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:25,443]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:29,177]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:32,501]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:35,618]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:40,177]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:44,588]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:47,571]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:51,137]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:38:54,630]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:00,957]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:06,591]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:09,403]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:11,702]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:15,139]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:15,896]\u001b[0m Trial 1368 finished with value: 6.325904693844653 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013193300359725223, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28226356422160004, 'dropout_rate_Layer_2': 0.01693046816042079, 'dropout_rate_Layer_3': 0.025088921522298274, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005823982601455865, 'l1_Layer_2': 0.001195131707783405, 'l1_Layer_3': 1.644501340234761e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 155, 'n_units_Layer_3': 95}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 21.87% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 233.99 | sMAPE for Test Set is: 60.02% | rMAE for Test Set is: 20.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:39:19,650]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:25,652]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:27,249]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:35,920]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:42,356]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:50,360]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:54,950]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:39:58,564]\u001b[0m Trial 1369 finished with value: 6.38644106272844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006475822989276739, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3550993687362584, 'dropout_rate_Layer_2': 0.01220566776275224, 'dropout_rate_Layer_3': 0.1562106537124005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009055909739292767, 'l1_Layer_2': 1.676728365671809e-05, 'l1_Layer_3': 0.0010498705936830418, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 265}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 264.68 | sMAPE for Test Set is: 60.94% | rMAE for Test Set is: 23.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:39:59,963]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:05,061]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:06,728]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:12,207]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:15,346]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:18,035]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:20,882]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:25,817]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:31,565]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:38,122]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:43,021]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:40:57,507]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:06,109]\u001b[0m Trial 1394 finished with value: 6.310324875264944 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013671167287284906, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24704630136218775, 'dropout_rate_Layer_2': 0.0017677543512876898, 'dropout_rate_Layer_3': 0.022471301502846118, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003783506363338542, 'l1_Layer_2': 0.0004505585008795454, 'l1_Layer_3': 3.597164145988966e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 175, 'n_units_Layer_3': 100}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 22.04% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 269.26 | sMAPE for Test Set is: 60.98% | rMAE for Test Set is: 23.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:41:09,983]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:13,880]\u001b[0m Trial 1393 finished with value: 6.365458767164632 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007487223435613704, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12711702466942032, 'dropout_rate_Layer_2': 0.009215252205077844, 'dropout_rate_Layer_3': 0.15729151064711094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030601940638154378, 'l1_Layer_2': 1.6449385451088542e-05, 'l1_Layer_3': 0.0005477943287201005, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 699.26 | sMAPE for Test Set is: 63.66% | rMAE for Test Set is: 61.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:41:15,996]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:20,095]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:25,835]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:29,887]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:34,122]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:34,552]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:36,070]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:45,363]\u001b[0m Trial 1397 finished with value: 6.25522242654899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007100970694191507, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24615572459710666, 'dropout_rate_Layer_2': 0.0006427570077461881, 'dropout_rate_Layer_3': 0.03331468436989852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003963775700841555, 'l1_Layer_2': 0.00119970693227357, 'l1_Layer_3': 2.0549969912364192e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 100}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 137.70 | sMAPE for Test Set is: 56.07% | rMAE for Test Set is: 12.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:41:53,055]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:41:53,521]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:02,030]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:06,765]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:14,689]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:22,799]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:28,585]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:30,042]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:35,805]\u001b[0m Trial 1410 finished with value: 6.356546757221501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006754811514735703, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12336755866107686, 'dropout_rate_Layer_2': 0.004796067819153305, 'dropout_rate_Layer_3': 0.1604465680013935, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029125151364172985, 'l1_Layer_2': 1.51645905116572e-05, 'l1_Layer_3': 0.000399139234718129, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 432.01 | sMAPE for Test Set is: 64.19% | rMAE for Test Set is: 37.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:42:39,945]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:44,677]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:50,705]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:51,684]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:57,932]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:42:59,786]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:43:06,659]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:43:07,175]\u001b[0m Trial 1412 finished with value: 6.371264623062655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006483518059557339, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12760634039213184, 'dropout_rate_Layer_2': 0.004863951441278611, 'dropout_rate_Layer_3': 0.16311059735760647, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00297044727074974, 'l1_Layer_2': 1.3659855232835062e-05, 'l1_Layer_3': 0.0004283256590677216, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 270}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 397.83 | sMAPE for Test Set is: 62.68% | rMAE for Test Set is: 34.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:43:20,008]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:43:33,689]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:43:48,948]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:00,802]\u001b[0m Trial 1427 finished with value: 6.344519635146863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006100537441148827, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12426660334496825, 'dropout_rate_Layer_2': 0.00594883900164234, 'dropout_rate_Layer_3': 0.1614797263107048, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003112296604465597, 'l1_Layer_2': 1.0041437125264384e-05, 'l1_Layer_3': 0.00039220864213546964, 'n_units_Layer_1': 260, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 21.79% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 433.91 | sMAPE for Test Set is: 61.99% | rMAE for Test Set is: 37.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:44:01,285]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:14,488]\u001b[0m Trial 1429 finished with value: 6.424992724043531 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006389663525163835, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12486069684879535, 'dropout_rate_Layer_2': 0.005887850080116142, 'dropout_rate_Layer_3': 0.16248967086833496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005448949365604677, 'l1_Layer_2': 1.008446403258517e-05, 'l1_Layer_3': 0.0003905493912807914, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 22.29% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 426.68 | sMAPE for Test Set is: 62.65% | rMAE for Test Set is: 37.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:44:21,501]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:22,683]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:29,294]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:29,863]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:36,460]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:36,516]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:37,373]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:47,017]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:47,209]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:55,691]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:58,993]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:44:59,887]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:00,420]\u001b[0m Trial 1431 finished with value: 6.3690874587138175 and parameters: {'n_hidden': 3, 'learning_rate': 0.000631182320929733, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12143191323259209, 'dropout_rate_Layer_2': 0.005254799861414983, 'dropout_rate_Layer_3': 0.1650126975737372, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0029928810831368812, 'l1_Layer_2': 1.3951292827225747e-05, 'l1_Layer_3': 0.00039867794845120907, 'n_units_Layer_1': 250, 'n_units_Layer_2': 250, 'n_units_Layer_3': 275}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 22.19% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 306.57 | sMAPE for Test Set is: 62.49% | rMAE for Test Set is: 26.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:45:12,628]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:15,251]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:18,498]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:19,309]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:20,115]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:27,283]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:30,541]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:33,785]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:40,037]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:45,887]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:52,987]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:57,880]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:45:58,097]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:04,670]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:04,967]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:05,051]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:05,219]\u001b[0m Trial 1441 finished with value: 6.180284063449648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005417462177081234, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12796579310832978, 'dropout_rate_Layer_2': 0.00399553973180259, 'dropout_rate_Layer_3': 0.15787266385486706, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.004484144579702052, 'l1_Layer_2': 1.3866978751966429e-05, 'l1_Layer_3': 0.0002738760650936083, 'n_units_Layer_1': 260, 'n_units_Layer_2': 235, 'n_units_Layer_3': 285}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.18 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 296.46 | sMAPE for Test Set is: 61.33% | rMAE for Test Set is: 25.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:46:17,764]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:18,155]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:18,967]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:27,025]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:30,495]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:34,434]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:36,999]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:38,037]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:40,125]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:44,866]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:50,164]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:46:58,440]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:01,632]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:06,249]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:08,596]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:12,829]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:13,099]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:14,828]\u001b[0m Trial 1463 finished with value: 6.268869466716684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007121660569689711, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21827544367807927, 'dropout_rate_Layer_2': 0.008205921905447652, 'dropout_rate_Layer_3': 0.05394633277603888, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000374094031338781, 'l1_Layer_2': 0.0004587792424974518, 'l1_Layer_3': 2.1941708255123094e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 120}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 21.93% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 200.83 | sMAPE for Test Set is: 59.45% | rMAE for Test Set is: 17.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:47:21,381]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:24,225]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:25,223]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:29,049]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:35,255]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:36,147]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:43,699]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:49,594]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:47:55,755]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:48:06,815]\u001b[0m Trial 1472 finished with value: 6.205972109454334 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006647004762279984, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13058165127097443, 'dropout_rate_Layer_2': 0.0171921485016458, 'dropout_rate_Layer_3': 0.16807862535421628, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004441430352870867, 'l1_Layer_2': 1.000732030891609e-05, 'l1_Layer_3': 0.00027880264853905534, 'n_units_Layer_1': 255, 'n_units_Layer_2': 250, 'n_units_Layer_3': 285}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.76% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 441.95 | sMAPE for Test Set is: 63.32% | rMAE for Test Set is: 38.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:48:12,374]\u001b[0m Trial 1487 finished with value: 6.533902929103526 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006706123183212998, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0063442866534200735, 'dropout_rate_Layer_2': 0.10477693770136566, 'dropout_rate_Layer_3': 0.1315961337732469, 'dropout_rate_Layer_4': 0.2140919890353182, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00492970750720327, 'l1_Layer_2': 1.7766007429563484e-05, 'l1_Layer_3': 3.118085616845469e-05, 'l1_Layer_4': 2.0555301354956552e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 280, 'n_units_Layer_4': 280}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 11.70 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:48:14,852]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:48:18,292]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:48:22,533]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:48:28,302]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:48:34,180]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:48:49,832]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:49:05,149]\u001b[0m Trial 1491 finished with value: 6.209681270930299 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005959771625812934, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 6.370309213880101e-05, 'dropout_rate_Layer_2': 0.014056004071929798, 'dropout_rate_Layer_3': 0.032159171538592046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010261147966620268, 'l1_Layer_2': 4.536637795844048e-05, 'l1_Layer_3': 1.0283187433378371e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.53 | sMAPE for Test Set is: 24.34% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:49:05,633]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 13:49:16,676]\u001b[0m Trial 1495 finished with value: 6.3888546251054015 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006196949617174782, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006304976869796142, 'dropout_rate_Layer_2': 0.10412494623843367, 'dropout_rate_Layer_3': 0.14287293410855417, 'dropout_rate_Layer_4': 0.17420337615138368, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0054426952281954825, 'l1_Layer_2': 2.1194352154213367e-05, 'l1_Layer_3': 3.4162455835974736e-05, 'l1_Layer_4': 1.150398937638536e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 290, 'n_units_Layer_3': 275, 'n_units_Layer_4': 290}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 22.02% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 14.19 | sMAPE for Test Set is: 41.83% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 13:49:24,941]\u001b[0m Trial 1493 finished with value: 6.162270042747781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005005479327365032, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0002676519620159461, 'dropout_rate_Layer_2': 0.013784143084452607, 'dropout_rate_Layer_3': 0.03454072021637761, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011015345340220803, 'l1_Layer_2': 4.169800969867222e-05, 'l1_Layer_3': 0.00021914835230332351, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 260}. Best is trial 1332 with value: 6.047279259432073.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 21.52% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 8.93 | sMAPE for Test Set is: 25.55% | rMAE for Test Set is: 0.78\n",
      "for 2018-01-01, MAE is:28.46 & sMAPE is:102.30% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :28.46 & 102.30% & 0.88\n",
      "for 2018-01-02, MAE is:11.36 & sMAPE is:40.83% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :19.91 & 71.56% & 0.59\n",
      "for 2018-01-03, MAE is:10.36 & sMAPE is:83.22% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :16.73 & 75.45% & 0.52\n",
      "WARNING:tensorflow:5 out of the last 28 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020F0CB4FE50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-04, MAE is:12.16 & sMAPE is:63.93% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :15.59 & 72.57% & 0.62\n",
      "WARNING:tensorflow:6 out of the last 29 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000020E663D9550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "for 2018-01-05, MAE is:10.42 & sMAPE is:54.01% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :14.55 & 68.86% & 0.66\n",
      "for 2018-01-06, MAE is:6.31 & sMAPE is:18.36% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :13.18 & 60.44% & 0.60\n",
      "for 2018-01-07, MAE is:4.66 & sMAPE is:19.73% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :11.96 & 54.63% & 0.54\n",
      "for 2018-01-08, MAE is:8.29 & sMAPE is:29.59% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.50 & 51.50% & 0.49\n",
      "for 2018-01-09, MAE is:8.62 & sMAPE is:37.71% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :11.18 & 49.97% & 0.56\n",
      "for 2018-01-10, MAE is:6.47 & sMAPE is:17.68% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.71 & 46.74% & 0.53\n",
      "for 2018-01-11, MAE is:5.66 & sMAPE is:12.25% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 43.60% & 0.51\n",
      "for 2018-01-12, MAE is:3.65 & sMAPE is:8.69% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.70 & 40.69% & 0.49\n",
      "for 2018-01-13, MAE is:2.69 & sMAPE is:7.55% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :9.16 & 38.14% & 0.50\n",
      "for 2018-01-14, MAE is:2.23 & sMAPE is:7.19% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 35.93% & 0.49\n",
      "for 2018-01-15, MAE is:14.36 & sMAPE is:49.13% & rMAE is:1.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 36.81% & 0.55\n",
      "for 2018-01-16, MAE is:8.80 & sMAPE is:60.81% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 38.31% & 0.60\n",
      "for 2018-01-17, MAE is:6.12 & sMAPE is:21.89% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 37.35% & 0.60\n",
      "for 2018-01-18, MAE is:5.36 & sMAPE is:34.99% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 37.22% & 0.58\n",
      "for 2018-01-19, MAE is:4.95 & sMAPE is:14.06% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 36.00% & 0.64\n",
      "for 2018-01-20, MAE is:4.63 & sMAPE is:13.27% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 34.86% & 0.66\n",
      "for 2018-01-21, MAE is:2.60 & sMAPE is:7.55% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 33.56% & 0.65\n",
      "for 2018-01-22, MAE is:4.48 & sMAPE is:14.71% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 32.70% & 0.63\n",
      "for 2018-01-23, MAE is:6.46 & sMAPE is:19.19% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 32.12% & 0.62\n",
      "for 2018-01-24, MAE is:7.32 & sMAPE is:27.41% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 31.92% & 0.65\n",
      "for 2018-01-25, MAE is:7.94 & sMAPE is:49.50% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 32.62% & 0.68\n",
      "for 2018-01-26, MAE is:9.10 & sMAPE is:22.56% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 32.24% & 0.73\n",
      "for 2018-01-27, MAE is:6.35 & sMAPE is:25.56% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 31.99% & 0.73\n",
      "for 2018-01-28, MAE is:5.88 & sMAPE is:70.02% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 33.35% & 0.71\n",
      "for 2018-01-29, MAE is:6.80 & sMAPE is:52.20% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 34.00% & 0.70\n",
      "for 2018-01-30, MAE is:14.43 & sMAPE is:61.84% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 34.92% & 0.72\n",
      "for 2018-01-31, MAE is:10.19 & sMAPE is:29.10% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 34.74% & 0.75\n",
      "for 2018-02-01, MAE is:5.36 & sMAPE is:17.73% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 34.21% & 0.74\n",
      "for 2018-02-02, MAE is:7.19 & sMAPE is:20.51% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 33.79% & 0.77\n",
      "for 2018-02-03, MAE is:4.85 & sMAPE is:12.59% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 33.17% & 0.76\n",
      "for 2018-02-04, MAE is:2.18 & sMAPE is:6.32% & rMAE is:0.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 32.40% & 0.74\n",
      "for 2018-02-05, MAE is:3.68 & sMAPE is:8.82% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 31.75% & 0.73\n",
      "for 2018-02-06, MAE is:5.90 & sMAPE is:13.77% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 31.26% & 0.72\n",
      "for 2018-02-07, MAE is:4.68 & sMAPE is:9.78% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 30.69% & 0.71\n",
      "for 2018-02-08, MAE is:6.78 & sMAPE is:14.08% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 30.27% & 0.70\n",
      "for 2018-02-09, MAE is:3.39 & sMAPE is:8.20% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 29.72% & 0.72\n",
      "for 2018-02-10, MAE is:4.88 & sMAPE is:12.85% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 29.31% & 0.76\n",
      "for 2018-02-11, MAE is:16.09 & sMAPE is:98.69% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 30.96% & 0.75\n",
      "for 2018-02-12, MAE is:6.77 & sMAPE is:20.80% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 30.72% & 0.75\n",
      "for 2018-02-13, MAE is:5.05 & sMAPE is:13.75% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 30.34% & 0.75\n",
      "for 2018-02-14, MAE is:6.94 & sMAPE is:18.21% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 30.07% & 0.75\n",
      "for 2018-02-15, MAE is:4.64 & sMAPE is:14.57% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 29.73% & 0.74\n",
      "for 2018-02-16, MAE is:4.26 & sMAPE is:11.11% & rMAE is:1.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 29.33% & 0.77\n",
      "for 2018-02-17, MAE is:3.39 & sMAPE is:8.56% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 28.90% & 0.78\n",
      "for 2018-02-18, MAE is:2.78 & sMAPE is:7.37% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 28.46% & 0.76\n",
      "for 2018-02-19, MAE is:9.49 & sMAPE is:20.43% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 28.30% & 0.76\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-02-20, MAE is:5.07 & sMAPE is:11.73% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 27.97% & 0.75\n",
      "for 2018-02-21, MAE is:6.21 & sMAPE is:14.45% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 27.71% & 0.76\n",
      "for 2018-02-22, MAE is:8.42 & sMAPE is:19.51% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 27.56% & 0.76\n",
      "for 2018-02-23, MAE is:5.58 & sMAPE is:12.71% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.05 & 27.28% & 0.76\n",
      "for 2018-02-24, MAE is:12.77 & sMAPE is:54.66% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 27.78% & 0.76\n",
      "for 2018-02-25, MAE is:9.25 & sMAPE is:31.72% & rMAE is:4.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 27.85% & 0.82\n",
      "for 2018-02-26, MAE is:7.22 & sMAPE is:14.87% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 27.63% & 0.82\n",
      "for 2018-02-27, MAE is:8.89 & sMAPE is:17.21% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 27.45% & 0.83\n",
      "for 2018-02-28, MAE is:8.51 & sMAPE is:20.89% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 27.33% & 0.84\n",
      "for 2018-03-01, MAE is:8.85 & sMAPE is:28.77% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 27.36% & 0.83\n",
      "for 2018-03-02, MAE is:6.24 & sMAPE is:15.35% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 27.16% & 0.83\n",
      "for 2018-03-03, MAE is:4.65 & sMAPE is:12.59% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 26.93% & 0.82\n",
      "for 2018-03-04, MAE is:4.94 & sMAPE is:16.58% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 26.76% & 0.83\n",
      "for 2018-03-05, MAE is:15.64 & sMAPE is:34.40% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 26.88% & 0.84\n",
      "for 2018-03-06, MAE is:4.06 & sMAPE is:8.40% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 26.60% & 0.84\n",
      "for 2018-03-07, MAE is:5.02 & sMAPE is:10.67% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 26.36% & 0.83\n",
      "for 2018-03-08, MAE is:6.79 & sMAPE is:18.45% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 26.24% & 0.83\n",
      "for 2018-03-09, MAE is:7.44 & sMAPE is:23.35% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 26.20% & 0.84\n",
      "for 2018-03-10, MAE is:1.71 & sMAPE is:4.87% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 25.89% & 0.83\n",
      "for 2018-03-11, MAE is:2.66 & sMAPE is:9.30% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 25.65% & 0.83\n",
      "for 2018-03-12, MAE is:4.01 & sMAPE is:10.68% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 25.44% & 0.82\n",
      "for 2018-03-13, MAE is:4.71 & sMAPE is:13.02% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 25.27% & 0.82\n",
      "for 2018-03-14, MAE is:8.79 & sMAPE is:19.32% & rMAE is:3.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 25.18% & 0.85\n",
      "for 2018-03-15, MAE is:11.31 & sMAPE is:41.59% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 25.41% & 0.85\n",
      "for 2018-03-16, MAE is:7.35 & sMAPE is:28.03% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 25.44% & 0.85\n",
      "for 2018-03-17, MAE is:16.29 & sMAPE is:135.83% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 26.89% & 0.84\n",
      "for 2018-03-18, MAE is:14.36 & sMAPE is:102.83% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 27.88% & 0.84\n",
      "for 2018-03-19, MAE is:10.94 & sMAPE is:23.65% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 27.83% & 0.84\n",
      "for 2018-03-20, MAE is:4.34 & sMAPE is:9.97% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 27.60% & 0.84\n",
      "for 2018-03-21, MAE is:9.57 & sMAPE is:18.44% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 27.49% & 0.85\n",
      "for 2018-03-22, MAE is:9.86 & sMAPE is:21.51% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 27.41% & 0.85\n",
      "for 2018-03-23, MAE is:5.15 & sMAPE is:9.76% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 27.20% & 0.84\n",
      "for 2018-03-24, MAE is:4.58 & sMAPE is:10.66% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 27.00% & 0.83\n",
      "for 2018-03-25, MAE is:5.99 & sMAPE is:17.73% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 26.89% & 0.82\n",
      "for 2018-03-26, MAE is:14.42 & sMAPE is:30.40% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 26.93% & 0.83\n",
      "for 2018-03-27, MAE is:6.80 & sMAPE is:14.69% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 26.79% & 0.83\n",
      "for 2018-03-28, MAE is:4.41 & sMAPE is:11.98% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 26.62% & 0.82\n",
      "for 2018-03-29, MAE is:7.12 & sMAPE is:20.43% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 26.54% & 0.83\n",
      "for 2018-03-30, MAE is:7.13 & sMAPE is:24.27% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 26.52% & 0.82\n",
      "for 2018-03-31, MAE is:8.73 & sMAPE is:63.82% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 26.93% & 0.82\n",
      "for 2018-04-01, MAE is:2.32 & sMAPE is:10.42% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 26.75% & 0.81\n",
      "for 2018-04-02, MAE is:2.32 & sMAPE is:8.35% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 26.55% & 0.80\n",
      "for 2018-04-03, MAE is:7.65 & sMAPE is:24.75% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 26.53% & 0.80\n",
      "for 2018-04-04, MAE is:4.38 & sMAPE is:12.90% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 26.39% & 0.80\n",
      "for 2018-04-05, MAE is:4.41 & sMAPE is:13.63% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 26.25% & 0.80\n",
      "for 2018-04-06, MAE is:4.54 & sMAPE is:12.93% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.15 & 26.11% & 0.79\n",
      "for 2018-04-07, MAE is:7.61 & sMAPE is:54.21% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 26.40% & 0.79\n",
      "for 2018-04-08, MAE is:4.56 & sMAPE is:24.19% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 26.38% & 0.79\n",
      "for 2018-04-09, MAE is:7.03 & sMAPE is:17.87% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 26.30% & 0.79\n",
      "for 2018-04-10, MAE is:5.16 & sMAPE is:13.30% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 26.17% & 0.79\n",
      "for 2018-04-11, MAE is:4.27 & sMAPE is:13.90% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 26.04% & 0.79\n",
      "for 2018-04-12, MAE is:5.20 & sMAPE is:17.12% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 25.96% & 0.79\n",
      "for 2018-04-13, MAE is:6.92 & sMAPE is:19.64% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 25.90% & 0.80\n",
      "for 2018-04-14, MAE is:4.05 & sMAPE is:11.51% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 25.76% & 0.79\n",
      "for 2018-04-15, MAE is:2.98 & sMAPE is:9.67% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 25.60% & 0.79\n",
      "for 2018-04-16, MAE is:7.87 & sMAPE is:17.78% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 25.53% & 0.80\n",
      "for 2018-04-17, MAE is:4.31 & sMAPE is:10.00% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 25.39% & 0.80\n",
      "for 2018-04-18, MAE is:3.27 & sMAPE is:7.81% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 25.22% & 0.79\n",
      "for 2018-04-19, MAE is:3.32 & sMAPE is:8.36% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 25.07% & 0.79\n",
      "for 2018-04-20, MAE is:4.81 & sMAPE is:13.28% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 24.96% & 0.80\n",
      "for 2018-04-21, MAE is:3.91 & sMAPE is:13.60% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 24.86% & 0.80\n",
      "for 2018-04-22, MAE is:9.91 & sMAPE is:53.86% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 25.12% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-04-23, MAE is:4.25 & sMAPE is:15.05% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 25.03% & 0.79\n",
      "for 2018-04-24, MAE is:5.80 & sMAPE is:16.73% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 24.96% & 0.79\n",
      "for 2018-04-25, MAE is:13.48 & sMAPE is:41.09% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 25.10% & 0.79\n",
      "for 2018-04-26, MAE is:6.03 & sMAPE is:20.39% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 25.06% & 0.79\n",
      "for 2018-04-27, MAE is:5.44 & sMAPE is:14.31% & rMAE is:3.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 24.96% & 0.81\n",
      "for 2018-04-28, MAE is:4.08 & sMAPE is:13.89% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 24.87% & 0.81\n",
      "for 2018-04-29, MAE is:7.49 & sMAPE is:31.70% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 24.93% & 0.81\n",
      "for 2018-04-30, MAE is:11.00 & sMAPE is:79.59% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 25.38% & 0.81\n",
      "for 2018-05-01, MAE is:19.13 & sMAPE is:153.06% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 26.44% & 0.81\n",
      "for 2018-05-02, MAE is:6.61 & sMAPE is:18.15% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.01 & 26.37% & 0.81\n",
      "for 2018-05-03, MAE is:4.04 & sMAPE is:10.52% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 26.24% & 0.80\n",
      "for 2018-05-04, MAE is:6.88 & sMAPE is:18.33% & rMAE is:2.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 26.18% & 0.82\n",
      "for 2018-05-05, MAE is:3.42 & sMAPE is:12.35% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 26.07% & 0.82\n",
      "for 2018-05-06, MAE is:4.77 & sMAPE is:33.19% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 26.12% & 0.81\n",
      "for 2018-05-07, MAE is:6.55 & sMAPE is:20.82% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 26.08% & 0.81\n",
      "for 2018-05-08, MAE is:7.20 & sMAPE is:24.77% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 26.07% & 0.80\n",
      "for 2018-05-09, MAE is:6.87 & sMAPE is:20.10% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 26.02% & 0.81\n",
      "for 2018-05-10, MAE is:3.14 & sMAPE is:11.85% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 25.92% & 0.81\n",
      "for 2018-05-11, MAE is:12.22 & sMAPE is:32.75% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 25.97% & 0.81\n",
      "for 2018-05-12, MAE is:4.47 & sMAPE is:13.11% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 25.87% & 0.81\n",
      "for 2018-05-13, MAE is:3.73 & sMAPE is:30.90% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 25.91% & 0.81\n",
      "for 2018-05-14, MAE is:8.56 & sMAPE is:25.28% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 25.90% & 0.82\n",
      "for 2018-05-15, MAE is:10.74 & sMAPE is:28.23% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 25.92% & 0.82\n",
      "for 2018-05-16, MAE is:4.51 & sMAPE is:10.58% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 25.81% & 0.82\n",
      "for 2018-05-17, MAE is:2.33 & sMAPE is:7.21% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 25.67% & 0.81\n",
      "for 2018-05-18, MAE is:3.31 & sMAPE is:8.61% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 25.55% & 0.81\n",
      "for 2018-05-19, MAE is:4.41 & sMAPE is:12.25% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 25.45% & 0.81\n",
      "for 2018-05-20, MAE is:9.70 & sMAPE is:55.67% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 25.67% & 0.82\n",
      "for 2018-05-21, MAE is:8.81 & sMAPE is:114.24% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 26.30% & 0.82\n",
      "for 2018-05-22, MAE is:12.92 & sMAPE is:34.33% & rMAE is:2.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 26.35% & 0.83\n",
      "for 2018-05-23, MAE is:4.00 & sMAPE is:9.46% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 26.24% & 0.84\n",
      "for 2018-05-24, MAE is:3.54 & sMAPE is:9.41% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 26.12% & 0.84\n",
      "for 2018-05-25, MAE is:6.47 & sMAPE is:17.97% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 26.06% & 0.85\n",
      "for 2018-05-26, MAE is:4.26 & sMAPE is:12.06% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 25.97% & 0.86\n",
      "for 2018-05-27, MAE is:4.69 & sMAPE is:14.08% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 25.89% & 0.86\n",
      "for 2018-05-28, MAE is:9.33 & sMAPE is:23.00% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 25.87% & 0.85\n",
      "for 2018-05-29, MAE is:4.18 & sMAPE is:10.19% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 25.76% & 0.85\n",
      "for 2018-05-30, MAE is:7.25 & sMAPE is:16.45% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 25.70% & 0.85\n",
      "for 2018-05-31, MAE is:3.99 & sMAPE is:9.69% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 25.59% & 0.85\n",
      "for 2018-06-01, MAE is:10.32 & sMAPE is:21.72% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 25.57% & 0.85\n",
      "for 2018-06-02, MAE is:2.55 & sMAPE is:6.24% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 25.44% & 0.85\n",
      "for 2018-06-03, MAE is:4.56 & sMAPE is:14.37% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 25.37% & 0.86\n",
      "for 2018-06-04, MAE is:4.16 & sMAPE is:9.32% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 25.27% & 0.86\n",
      "for 2018-06-05, MAE is:8.16 & sMAPE is:17.17% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 25.21% & 0.86\n",
      "for 2018-06-06, MAE is:8.61 & sMAPE is:18.57% & rMAE is:2.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 25.17% & 0.87\n",
      "for 2018-06-07, MAE is:9.56 & sMAPE is:21.00% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 25.14% & 0.87\n",
      "for 2018-06-08, MAE is:6.12 & sMAPE is:13.50% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 25.07% & 0.88\n",
      "for 2018-06-09, MAE is:3.13 & sMAPE is:7.84% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 24.96% & 0.88\n",
      "for 2018-06-10, MAE is:5.77 & sMAPE is:15.58% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 24.91% & 0.88\n",
      "for 2018-06-11, MAE is:3.07 & sMAPE is:6.38% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 24.79% & 0.88\n",
      "for 2018-06-12, MAE is:5.80 & sMAPE is:12.04% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 24.71% & 0.88\n",
      "for 2018-06-13, MAE is:3.05 & sMAPE is:6.53% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 24.60% & 0.88\n",
      "for 2018-06-14, MAE is:4.28 & sMAPE is:9.55% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 24.51% & 0.88\n",
      "for 2018-06-15, MAE is:5.78 & sMAPE is:12.10% & rMAE is:2.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 24.44% & 0.89\n",
      "for 2018-06-16, MAE is:2.27 & sMAPE is:5.56% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 24.32% & 0.89\n",
      "for 2018-06-17, MAE is:11.10 & sMAPE is:52.98% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 24.49% & 0.89\n",
      "for 2018-06-18, MAE is:3.69 & sMAPE is:8.16% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 24.40% & 0.89\n",
      "for 2018-06-19, MAE is:4.60 & sMAPE is:10.19% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 24.31% & 0.89\n",
      "for 2018-06-20, MAE is:3.91 & sMAPE is:8.05% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 24.22% & 0.89\n",
      "for 2018-06-21, MAE is:16.53 & sMAPE is:48.11% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 24.36% & 0.89\n",
      "for 2018-06-22, MAE is:10.50 & sMAPE is:43.65% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 24.47% & 0.89\n",
      "for 2018-06-23, MAE is:2.89 & sMAPE is:12.81% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 24.40% & 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-06-24, MAE is:5.23 & sMAPE is:17.36% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 24.36% & 0.88\n",
      "for 2018-06-25, MAE is:3.66 & sMAPE is:8.23% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 24.27% & 0.88\n",
      "for 2018-06-26, MAE is:6.27 & sMAPE is:13.95% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 24.21% & 0.89\n",
      "for 2018-06-27, MAE is:4.10 & sMAPE is:9.10% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 24.13% & 0.89\n",
      "for 2018-06-28, MAE is:4.63 & sMAPE is:11.00% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.68 & 24.05% & 0.89\n",
      "for 2018-06-29, MAE is:2.52 & sMAPE is:5.71% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.66 & 23.95% & 0.88\n",
      "for 2018-06-30, MAE is:5.74 & sMAPE is:15.23% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 23.90% & 0.88\n",
      "for 2018-07-01, MAE is:6.82 & sMAPE is:24.77% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 23.91% & 0.88\n",
      "for 2018-07-02, MAE is:6.59 & sMAPE is:15.16% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.65 & 23.86% & 0.88\n",
      "for 2018-07-03, MAE is:4.74 & sMAPE is:9.79% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 23.78% & 0.88\n",
      "for 2018-07-04, MAE is:5.98 & sMAPE is:12.32% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :6.64 & 23.72% & 0.89\n",
      "for 2018-07-05, MAE is:3.21 & sMAPE is:6.60% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.62 & 23.63% & 0.88\n",
      "for 2018-07-06, MAE is:3.78 & sMAPE is:8.20% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 23.55% & 0.88\n",
      "for 2018-07-07, MAE is:10.61 & sMAPE is:35.77% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 23.61% & 0.89\n",
      "for 2018-07-08, MAE is:3.59 & sMAPE is:10.54% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.61 & 23.54% & 0.89\n",
      "for 2018-07-09, MAE is:3.89 & sMAPE is:8.67% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.60 & 23.46% & 0.89\n",
      "for 2018-07-10, MAE is:4.47 & sMAPE is:9.03% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.59 & 23.39% & 0.89\n",
      "for 2018-07-11, MAE is:3.06 & sMAPE is:6.00% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.57 & 23.30% & 0.89\n",
      "for 2018-07-12, MAE is:3.18 & sMAPE is:6.28% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 23.21% & 0.89\n",
      "for 2018-07-13, MAE is:4.19 & sMAPE is:8.62% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.54 & 23.14% & 0.89\n",
      "for 2018-07-14, MAE is:3.83 & sMAPE is:8.46% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 23.06% & 0.89\n",
      "for 2018-07-15, MAE is:4.82 & sMAPE is:11.35% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 23.00% & 0.89\n",
      "for 2018-07-16, MAE is:3.61 & sMAPE is:6.87% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.50 & 22.92% & 0.89\n",
      "for 2018-07-17, MAE is:4.35 & sMAPE is:7.81% & rMAE is:2.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.49 & 22.84% & 0.89\n",
      "for 2018-07-18, MAE is:2.65 & sMAPE is:5.58% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.47 & 22.76% & 0.90\n",
      "for 2018-07-19, MAE is:3.88 & sMAPE is:7.82% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :6.46 & 22.68% & 0.90\n",
      "for 2018-07-20, MAE is:4.18 & sMAPE is:8.23% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.45 & 22.61% & 0.90\n",
      "for 2018-07-21, MAE is:4.47 & sMAPE is:9.33% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 22.54% & 0.90\n",
      "for 2018-07-22, MAE is:7.45 & sMAPE is:17.88% & rMAE is:6.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.44 & 22.52% & 0.93\n",
      "for 2018-07-23, MAE is:3.59 & sMAPE is:6.96% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.43 & 22.44% & 0.94\n",
      "for 2018-07-24, MAE is:3.13 & sMAPE is:5.72% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 22.36% & 0.94\n",
      "for 2018-07-25, MAE is:7.30 & sMAPE is:13.53% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 22.32% & 0.94\n",
      "for 2018-07-26, MAE is:3.60 & sMAPE is:6.75% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 22.24% & 0.94\n",
      "for 2018-07-27, MAE is:5.78 & sMAPE is:11.64% & rMAE is:2.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.40 & 22.19% & 0.95\n",
      "for 2018-07-28, MAE is:2.92 & sMAPE is:5.91% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.38 & 22.12% & 0.95\n",
      "for 2018-07-29, MAE is:2.70 & sMAPE is:6.32% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 22.04% & 0.95\n",
      "for 2018-07-30, MAE is:5.20 & sMAPE is:9.99% & rMAE is:3.12 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 21.98% & 0.96\n",
      "for 2018-07-31, MAE is:2.42 & sMAPE is:4.29% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.34 & 21.90% & 0.96\n",
      "for 2018-08-01, MAE is:3.45 & sMAPE is:6.15% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.33 & 21.83% & 0.96\n",
      "for 2018-08-02, MAE is:3.38 & sMAPE is:5.77% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 21.75% & 0.96\n",
      "for 2018-08-03, MAE is:5.91 & sMAPE is:9.63% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.31 & 21.69% & 0.96\n",
      "for 2018-08-04, MAE is:3.13 & sMAPE is:5.68% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.30 & 21.62% & 0.96\n",
      "for 2018-08-05, MAE is:5.72 & sMAPE is:12.08% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 21.58% & 0.96\n",
      "for 2018-08-06, MAE is:5.16 & sMAPE is:8.06% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 21.51% & 0.96\n",
      "for 2018-08-07, MAE is:4.01 & sMAPE is:6.30% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.28 & 21.44% & 0.95\n",
      "for 2018-08-08, MAE is:4.00 & sMAPE is:6.91% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 21.38% & 0.95\n",
      "for 2018-08-09, MAE is:5.22 & sMAPE is:9.19% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 21.32% & 0.95\n",
      "for 2018-08-10, MAE is:4.67 & sMAPE is:13.03% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 21.29% & 0.95\n",
      "for 2018-08-11, MAE is:4.97 & sMAPE is:12.11% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 21.24% & 0.95\n",
      "for 2018-08-12, MAE is:7.32 & sMAPE is:18.42% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :6.25 & 21.23% & 0.95\n",
      "for 2018-08-13, MAE is:3.01 & sMAPE is:5.43% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.24 & 21.16% & 0.95\n",
      "for 2018-08-14, MAE is:3.99 & sMAPE is:7.46% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :6.23 & 21.10% & 0.94\n",
      "for 2018-08-15, MAE is:3.16 & sMAPE is:5.75% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 21.03% & 0.94\n",
      "for 2018-08-16, MAE is:4.20 & sMAPE is:7.34% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 20.97% & 0.94\n",
      "for 2018-08-17, MAE is:3.38 & sMAPE is:5.85% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 20.91% & 0.94\n",
      "for 2018-08-18, MAE is:4.13 & sMAPE is:7.75% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.85% & 0.94\n",
      "for 2018-08-19, MAE is:3.54 & sMAPE is:7.26% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 20.79% & 0.94\n",
      "for 2018-08-20, MAE is:3.19 & sMAPE is:5.77% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 20.73% & 0.94\n",
      "for 2018-08-21, MAE is:8.69 & sMAPE is:13.93% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 20.70% & 0.94\n",
      "for 2018-08-22, MAE is:7.35 & sMAPE is:11.55% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 20.66% & 0.93\n",
      "for 2018-08-23, MAE is:4.42 & sMAPE is:7.21% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 20.60% & 0.93\n",
      "for 2018-08-24, MAE is:5.09 & sMAPE is:8.82% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 20.55% & 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-08-25, MAE is:5.20 & sMAPE is:9.97% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 20.51% & 0.94\n",
      "for 2018-08-26, MAE is:5.88 & sMAPE is:12.24% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 20.47% & 0.94\n",
      "for 2018-08-27, MAE is:6.53 & sMAPE is:17.02% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.16 & 20.46% & 0.94\n",
      "for 2018-08-28, MAE is:11.82 & sMAPE is:19.66% & rMAE is:5.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.45% & 0.95\n",
      "for 2018-08-29, MAE is:5.46 & sMAPE is:8.82% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 20.41% & 0.96\n",
      "for 2018-08-30, MAE is:3.00 & sMAPE is:5.46% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 20.34% & 0.95\n",
      "for 2018-08-31, MAE is:9.99 & sMAPE is:16.92% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.33% & 0.95\n",
      "for 2018-09-01, MAE is:7.70 & sMAPE is:13.73% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.30% & 0.96\n",
      "for 2018-09-02, MAE is:4.54 & sMAPE is:8.86% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 20.26% & 0.96\n",
      "for 2018-09-03, MAE is:8.81 & sMAPE is:14.71% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 20.23% & 0.95\n",
      "for 2018-09-04, MAE is:7.03 & sMAPE is:11.48% & rMAE is:2.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 20.20% & 0.96\n",
      "for 2018-09-05, MAE is:4.74 & sMAPE is:7.30% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.15% & 0.96\n",
      "for 2018-09-06, MAE is:4.89 & sMAPE is:7.67% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.10% & 0.96\n",
      "for 2018-09-07, MAE is:5.38 & sMAPE is:9.03% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.18 & 20.05% & 0.96\n",
      "for 2018-09-08, MAE is:7.60 & sMAPE is:16.20% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.04% & 0.96\n",
      "for 2018-09-09, MAE is:6.04 & sMAPE is:12.40% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 20.01% & 0.96\n",
      "for 2018-09-10, MAE is:6.94 & sMAPE is:11.15% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 19.97% & 0.96\n",
      "for 2018-09-11, MAE is:9.65 & sMAPE is:16.11% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.96% & 0.96\n",
      "for 2018-09-12, MAE is:7.80 & sMAPE is:12.79% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.93% & 0.97\n",
      "for 2018-09-13, MAE is:6.90 & sMAPE is:10.18% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.22 & 19.89% & 0.97\n",
      "for 2018-09-14, MAE is:4.45 & sMAPE is:6.93% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.84% & 0.97\n",
      "for 2018-09-15, MAE is:3.83 & sMAPE is:7.02% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.20 & 19.79% & 0.97\n",
      "for 2018-09-16, MAE is:8.51 & sMAPE is:18.36% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.78% & 0.97\n",
      "for 2018-09-17, MAE is:7.70 & sMAPE is:12.10% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.21 & 19.75% & 0.97\n",
      "for 2018-09-18, MAE is:26.67 & sMAPE is:65.17% & rMAE is:6.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.29 & 19.93% & 1.00\n",
      "for 2018-09-19, MAE is:35.94 & sMAPE is:98.10% & rMAE is:4.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.41 & 20.23% & 1.01\n",
      "for 2018-09-20, MAE is:36.71 & sMAPE is:102.81% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.52 & 20.54% & 1.02\n",
      "for 2018-09-21, MAE is:14.44 & sMAPE is:40.44% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.55 & 20.62% & 1.01\n",
      "for 2018-09-22, MAE is:14.13 & sMAPE is:61.99% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.58 & 20.77% & 1.01\n",
      "for 2018-09-23, MAE is:35.63 & sMAPE is:124.22% & rMAE is:2.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.69 & 21.16% & 1.02\n",
      "for 2018-09-24, MAE is:11.73 & sMAPE is:35.52% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 21.22% & 1.02\n",
      "for 2018-09-25, MAE is:36.85 & sMAPE is:87.58% & rMAE is:6.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 21.46% & 1.04\n",
      "for 2018-09-26, MAE is:14.93 & sMAPE is:39.58% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 21.53% & 1.04\n",
      "for 2018-09-27, MAE is:8.43 & sMAPE is:17.11% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 21.51% & 1.04\n",
      "for 2018-09-28, MAE is:26.51 & sMAPE is:71.94% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 21.70% & 1.04\n",
      "for 2018-09-29, MAE is:7.73 & sMAPE is:17.55% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 21.68% & 1.04\n",
      "for 2018-09-30, MAE is:18.92 & sMAPE is:68.18% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 21.85% & 1.04\n",
      "for 2018-10-01, MAE is:6.55 & sMAPE is:10.99% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 21.82% & 1.04\n",
      "for 2018-10-02, MAE is:25.36 & sMAPE is:78.26% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 22.02% & 1.04\n",
      "for 2018-10-03, MAE is:23.43 & sMAPE is:159.95% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.10 & 22.52% & 1.04\n",
      "for 2018-10-04, MAE is:41.90 & sMAPE is:98.81% & rMAE is:3.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.23 & 22.80% & 1.05\n",
      "for 2018-10-05, MAE is:21.74 & sMAPE is:45.09% & rMAE is:2.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 22.88% & 1.05\n",
      "for 2018-10-06, MAE is:5.54 & sMAPE is:9.79% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 22.83% & 1.05\n",
      "for 2018-10-07, MAE is:23.58 & sMAPE is:64.16% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 22.98% & 1.05\n",
      "for 2018-10-08, MAE is:9.08 & sMAPE is:14.12% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 22.94% & 1.05\n",
      "for 2018-10-09, MAE is:33.53 & sMAPE is:61.57% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 23.08% & 1.05\n",
      "for 2018-10-10, MAE is:25.69 & sMAPE is:47.48% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 23.17% & 1.05\n",
      "for 2018-10-11, MAE is:9.67 & sMAPE is:19.32% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 23.15% & 1.05\n",
      "for 2018-10-12, MAE is:6.84 & sMAPE is:12.05% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 23.12% & 1.05\n",
      "for 2018-10-13, MAE is:10.20 & sMAPE is:22.96% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 23.12% & 1.05\n",
      "for 2018-10-14, MAE is:7.67 & sMAPE is:26.87% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 23.13% & 1.05\n",
      "for 2018-10-15, MAE is:21.47 & sMAPE is:41.65% & rMAE is:2.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 23.19% & 1.05\n",
      "for 2018-10-16, MAE is:9.61 & sMAPE is:13.30% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 23.16% & 1.06\n",
      "for 2018-10-17, MAE is:24.12 & sMAPE is:39.60% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 23.21% & 1.06\n",
      "for 2018-10-18, MAE is:4.75 & sMAPE is:7.39% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 23.16% & 1.06\n",
      "for 2018-10-19, MAE is:11.19 & sMAPE is:17.41% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 23.14% & 1.06\n",
      "for 2018-10-20, MAE is:3.75 & sMAPE is:6.20% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 23.08% & 1.06\n",
      "for 2018-10-21, MAE is:3.74 & sMAPE is:6.95% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 23.03% & 1.05\n",
      "for 2018-10-22, MAE is:7.06 & sMAPE is:12.25% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 22.99% & 1.05\n",
      "for 2018-10-23, MAE is:14.58 & sMAPE is:46.63% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 23.07% & 1.05\n",
      "for 2018-10-24, MAE is:11.78 & sMAPE is:60.11% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 23.20% & 1.05\n",
      "for 2018-10-25, MAE is:6.61 & sMAPE is:13.98% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 23.17% & 1.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-10-26, MAE is:8.73 & sMAPE is:15.18% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 23.14% & 1.05\n",
      "for 2018-10-27, MAE is:12.21 & sMAPE is:27.11% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 23.15% & 1.05\n",
      "for 2018-10-28, MAE is:22.18 & sMAPE is:74.39% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 23.32% & 1.05\n",
      "for 2018-10-29, MAE is:7.17 & sMAPE is:16.90% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 23.30% & 1.05\n",
      "for 2018-10-30, MAE is:5.28 & sMAPE is:15.71% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 23.28% & 1.04\n",
      "for 2018-10-31, MAE is:12.08 & sMAPE is:37.12% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 23.32% & 1.05\n",
      "for 2018-11-01, MAE is:27.44 & sMAPE is:89.35% & rMAE is:3.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 23.54% & 1.05\n",
      "for 2018-11-02, MAE is:32.36 & sMAPE is:86.46% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 23.74% & 1.06\n",
      "for 2018-11-03, MAE is:7.11 & sMAPE is:13.53% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 23.71% & 1.06\n",
      "for 2018-11-04, MAE is:7.97 & sMAPE is:18.00% & rMAE is:1.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 23.69% & 1.06\n",
      "for 2018-11-05, MAE is:9.95 & sMAPE is:18.51% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.85 & 23.67% & 1.06\n",
      "for 2018-11-06, MAE is:32.76 & sMAPE is:80.79% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 23.86% & 1.06\n",
      "for 2018-11-07, MAE is:31.15 & sMAPE is:81.77% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.01 & 24.05% & 1.06\n",
      "for 2018-11-08, MAE is:39.94 & sMAPE is:94.44% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 24.27% & 1.07\n",
      "for 2018-11-09, MAE is:5.48 & sMAPE is:9.51% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 24.22% & 1.07\n",
      "for 2018-11-10, MAE is:3.77 & sMAPE is:9.08% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 24.18% & 1.06\n",
      "for 2018-11-11, MAE is:4.05 & sMAPE is:10.26% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 24.13% & 1.06\n",
      "for 2018-11-12, MAE is:12.11 & sMAPE is:24.88% & rMAE is:3.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 24.13% & 1.07\n",
      "for 2018-11-13, MAE is:8.52 & sMAPE is:16.76% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 24.11% & 1.07\n",
      "for 2018-11-14, MAE is:13.36 & sMAPE is:24.10% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 24.11% & 1.07\n",
      "for 2018-11-15, MAE is:29.56 & sMAPE is:64.20% & rMAE is:5.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 24.24% & 1.09\n",
      "for 2018-11-16, MAE is:11.05 & sMAPE is:20.47% & rMAE is:3.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 24.22% & 1.09\n",
      "for 2018-11-17, MAE is:6.77 & sMAPE is:15.64% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 24.20% & 1.09\n",
      "for 2018-11-18, MAE is:5.55 & sMAPE is:12.10% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.17 & 24.16% & 1.09\n",
      "for 2018-11-19, MAE is:5.21 & sMAPE is:11.27% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 24.12% & 1.09\n",
      "for 2018-11-20, MAE is:6.50 & sMAPE is:16.23% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 24.10% & 1.09\n",
      "for 2018-11-21, MAE is:8.64 & sMAPE is:16.79% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 24.07% & 1.09\n",
      "for 2018-11-22, MAE is:47.76 & sMAPE is:87.67% & rMAE is:3.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 24.27% & 1.10\n",
      "for 2018-11-23, MAE is:15.10 & sMAPE is:19.38% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.30 & 24.25% & 1.10\n",
      "for 2018-11-24, MAE is:18.64 & sMAPE is:36.59% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 24.29% & 1.10\n",
      "for 2018-11-25, MAE is:5.48 & sMAPE is:9.43% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 24.25% & 1.10\n",
      "for 2018-11-26, MAE is:46.27 & sMAPE is:92.07% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 24.45% & 1.10\n",
      "for 2018-11-27, MAE is:36.47 & sMAPE is:61.67% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 24.56% & 1.10\n",
      "for 2018-11-28, MAE is:8.22 & sMAPE is:14.88% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 24.53% & 1.10\n",
      "for 2018-11-29, MAE is:9.68 & sMAPE is:24.75% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 24.54% & 1.10\n",
      "for 2018-11-30, MAE is:7.43 & sMAPE is:13.30% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.52 & 24.50% & 1.09\n",
      "for 2018-12-01, MAE is:29.82 & sMAPE is:89.26% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 24.69% & 1.10\n",
      "for 2018-12-02, MAE is:14.79 & sMAPE is:80.89% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.60 & 24.86% & 1.10\n",
      "for 2018-12-03, MAE is:5.01 & sMAPE is:14.91% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 24.83% & 1.09\n",
      "for 2018-12-04, MAE is:6.95 & sMAPE is:14.03% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 24.80% & 1.09\n",
      "for 2018-12-05, MAE is:8.00 & sMAPE is:13.93% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 24.77% & 1.09\n",
      "for 2018-12-06, MAE is:8.42 & sMAPE is:16.28% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 24.74% & 1.09\n",
      "for 2018-12-07, MAE is:27.47 & sMAPE is:98.06% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 24.96% & 1.09\n",
      "for 2018-12-08, MAE is:14.74 & sMAPE is:95.33% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 25.16% & 1.09\n",
      "for 2018-12-09, MAE is:41.68 & sMAPE is:154.63% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 25.54% & 1.10\n",
      "for 2018-12-10, MAE is:9.29 & sMAPE is:57.18% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 25.63% & 1.10\n",
      "for 2018-12-11, MAE is:16.56 & sMAPE is:36.63% & rMAE is:2.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 25.67% & 1.10\n",
      "for 2018-12-12, MAE is:11.22 & sMAPE is:16.62% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 25.64% & 1.10\n",
      "for 2018-12-13, MAE is:10.93 & sMAPE is:17.34% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :8.79 & 25.62% & 1.10\n",
      "for 2018-12-14, MAE is:38.15 & sMAPE is:74.50% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.88 & 25.76% & 1.10\n",
      "for 2018-12-15, MAE is:8.18 & sMAPE is:15.53% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 25.73% & 1.10\n",
      "for 2018-12-16, MAE is:30.14 & sMAPE is:90.82% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 25.91% & 1.10\n",
      "for 2018-12-17, MAE is:9.09 & sMAPE is:14.45% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :8.93 & 25.88% & 1.09\n",
      "for 2018-12-18, MAE is:28.72 & sMAPE is:66.63% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 26.00% & 1.10\n",
      "for 2018-12-19, MAE is:10.34 & sMAPE is:20.02% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 25.98% & 1.10\n",
      "for 2018-12-20, MAE is:32.59 & sMAPE is:84.75% & rMAE is:3.41 ||| daily mean of MAE & sMAPE & rMAE till now are :9.06 & 26.15% & 1.10\n",
      "for 2018-12-21, MAE is:30.80 & sMAPE is:91.84% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 26.33% & 1.10\n",
      "for 2018-12-22, MAE is:33.33 & sMAPE is:134.42% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 26.63% & 1.11\n",
      "for 2018-12-23, MAE is:7.65 & sMAPE is:19.33% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 26.61% & 1.11\n",
      "for 2018-12-24, MAE is:8.13 & sMAPE is:15.92% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 26.58% & 1.10\n",
      "for 2018-12-25, MAE is:16.92 & sMAPE is:127.39% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 26.86% & 1.10\n",
      "for 2018-12-26, MAE is:56.80 & sMAPE is:180.00% & rMAE is:5.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 27.29% & 1.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2018-12-27, MAE is:7.04 & sMAPE is:12.67% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 27.25% & 1.11\n",
      "for 2018-12-28, MAE is:30.72 & sMAPE is:70.89% & rMAE is:3.02 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 27.37% & 1.12\n",
      "for 2018-12-29, MAE is:28.01 & sMAPE is:79.56% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 27.51% & 1.12\n",
      "for 2018-12-30, MAE is:47.19 & sMAPE is:149.08% & rMAE is:4.14 ||| daily mean of MAE & sMAPE & rMAE till now are :9.54 & 27.85% & 1.13\n",
      "for 2018-12-31, MAE is:10.79 & sMAPE is:21.94% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 27.83% & 1.13\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:10:14,743]\u001b[0m A new study created in RDB with name: DE_2019\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:10:29,421]\u001b[0m Trial 0 finished with value: 10.99995969565443 and parameters: {'n_hidden': 4, 'learning_rate': 0.06882765212261215, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3947081138878768, 'dropout_rate_Layer_2': 0.014102874664817433, 'dropout_rate_Layer_3': 0.14741523517305027, 'dropout_rate_Layer_4': 0.3803071394987551, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 2.699383872489032e-05, 'l1_Layer_2': 0.00039263388366416477, 'l1_Layer_3': 0.001051118168674959, 'l1_Layer_4': 0.0002944749887832913, 'n_units_Layer_1': 265, 'n_units_Layer_2': 150, 'n_units_Layer_3': 185, 'n_units_Layer_4': 260}. Best is trial 0 with value: 10.99995969565443.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.00 | sMAPE for Validation Set is: 28.32% | rMAE for Validation Set is: 0.96\n",
      "MAE for Test Set is: 8.25 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:10:29,682]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 17.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:10:34,538]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:10:44,860]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:10:47,411]\u001b[0m Trial 1 finished with value: 10.400806158377582 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045493501195444765, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32884081441734647, 'dropout_rate_Layer_2': 0.03516487871166261, 'dropout_rate_Layer_3': 0.13880734012653653, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032061842581119864, 'l1_Layer_2': 0.003954503463044691, 'l1_Layer_3': 0.006148843934861765, 'n_units_Layer_1': 145, 'n_units_Layer_2': 65, 'n_units_Layer_3': 120}. Best is trial 1 with value: 10.400806158377582.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.40 | sMAPE for Validation Set is: 30.07% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 7.70 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:10:50,491]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:10:53,602]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:04,073]\u001b[0m Trial 5 finished with value: 9.814392804513986 and parameters: {'n_hidden': 3, 'learning_rate': 0.022725654445151337, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24611614575852414, 'dropout_rate_Layer_2': 0.3177024449266553, 'dropout_rate_Layer_3': 0.31080821187392554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002490671350753994, 'l1_Layer_2': 8.922512742031153e-05, 'l1_Layer_3': 2.4049545308807786e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 215, 'n_units_Layer_3': 95}. Best is trial 5 with value: 9.814392804513986.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.81 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 9.89 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:11:08,423]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:11,283]\u001b[0m Trial 8 finished with value: 28.709066654495633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007838194109981387, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2879135485180846, 'dropout_rate_Layer_2': 0.036739541056457006, 'dropout_rate_Layer_3': 0.2699972688066596, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007889142649866716, 'l1_Layer_2': 0.03453077520311648, 'l1_Layer_3': 0.0007390287361391825, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 280}. Best is trial 5 with value: 9.814392804513986.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 28.71 | sMAPE for Validation Set is: 75.77% | rMAE for Validation Set is: 2.51\n",
      "MAE for Test Set is: 43.56 | sMAPE for Test Set is: 115.29% | rMAE for Test Set is: 4.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:11:13,612]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:21,181]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:30,939]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:36,041]\u001b[0m Trial 10 finished with value: 8.634020196262545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009559293518054413, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03219784651471822, 'dropout_rate_Layer_2': 0.0692191694788801, 'dropout_rate_Layer_3': 0.28653782920573734, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0199052351260904, 'l1_Layer_2': 6.136894309825826e-05, 'l1_Layer_3': 0.03404818682535821, 'n_units_Layer_1': 150, 'n_units_Layer_2': 140, 'n_units_Layer_3': 265}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.63 | sMAPE for Validation Set is: 24.02% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 23.03% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:11:39,793]\u001b[0m Trial 6 finished with value: 12.372311868450055 and parameters: {'n_hidden': 3, 'learning_rate': 0.02635876451730119, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1779897013349411, 'dropout_rate_Layer_2': 0.21793743807536528, 'dropout_rate_Layer_3': 0.2320252776820868, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.207150738666212e-05, 'l1_Layer_2': 0.015428960156609727, 'l1_Layer_3': 0.001274130983529033, 'n_units_Layer_1': 80, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.37 | sMAPE for Validation Set is: 32.43% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 10.59 | sMAPE for Test Set is: 31.66% | rMAE for Test Set is: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:11:40,108]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:41,839]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:47,029]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:48,387]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:50,905]\u001b[0m Trial 14 finished with value: 9.161516220238845 and parameters: {'n_hidden': 4, 'learning_rate': 0.013744644584484076, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3132870161886982, 'dropout_rate_Layer_2': 0.026616294594970658, 'dropout_rate_Layer_3': 0.20117124699388103, 'dropout_rate_Layer_4': 0.13514121138862656, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00674870240105234, 'l1_Layer_2': 1.7537624816634716e-05, 'l1_Layer_3': 0.003744373392432089, 'l1_Layer_4': 0.004960155209069078, 'n_units_Layer_1': 165, 'n_units_Layer_2': 220, 'n_units_Layer_3': 230, 'n_units_Layer_4': 270}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.16 | sMAPE for Validation Set is: 24.45% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 22.81% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:11:52,116]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:52,794]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:11:54,906]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:01,043]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:01,076]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:01,677]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:07,738]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:08,260]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:13,538]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:16,940]\u001b[0m Trial 31 finished with value: 9.234608278589278 and parameters: {'n_hidden': 3, 'learning_rate': 0.011974750815316789, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11048652382379727, 'dropout_rate_Layer_2': 0.026996750162026652, 'dropout_rate_Layer_3': 0.3385738884518706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007045142264793338, 'l1_Layer_2': 3.2721325600160956e-05, 'l1_Layer_3': 4.135948323913051e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.23 | sMAPE for Validation Set is: 24.85% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 8.23 | sMAPE for Test Set is: 25.16% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:12:17,816]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:24,158]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:27,691]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:32,542]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:33,687]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:37,460]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:40,681]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:43,197]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:47,298]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:51,095]\u001b[0m Trial 30 finished with value: 9.857094974060521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034295755767860215, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29103409768354804, 'dropout_rate_Layer_2': 0.20356245031547138, 'dropout_rate_Layer_3': 0.3983481608342589, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.002967968333683233, 'l1_Layer_2': 0.0026562120754922464, 'l1_Layer_3': 0.004433182553721957, 'n_units_Layer_1': 185, 'n_units_Layer_2': 145, 'n_units_Layer_3': 190}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 26.37% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 24.03% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:12:53,057]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:54,996]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:12:58,776]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:01,106]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:03,562]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:06,729]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:06,921]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:07,441]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:12,906]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:15,811]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:19,441]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:20,916]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:24,243]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:27,966]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:34,107]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:39,335]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:42,965]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:48,002]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:51,599]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:55,491]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:57,737]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:13:59,324]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:02,911]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:07,425]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:14,737]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:17,695]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:21,781]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:30,785]\u001b[0m Trial 67 finished with value: 12.340039109659818 and parameters: {'n_hidden': 4, 'learning_rate': 0.09998698428649638, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0014334206840494802, 'dropout_rate_Layer_2': 0.00555960844442498, 'dropout_rate_Layer_3': 0.26092825266452035, 'dropout_rate_Layer_4': 0.2620978060572267, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004242696014684027, 'l1_Layer_2': 0.004899759908718556, 'l1_Layer_3': 0.010341067025424868, 'l1_Layer_4': 0.03915741800115671, 'n_units_Layer_1': 295, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235, 'n_units_Layer_4': 275}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 12.34 | sMAPE for Validation Set is: 30.77% | rMAE for Validation Set is: 1.08\n",
      "MAE for Test Set is: 10.00 | sMAPE for Test Set is: 28.25% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:14:35,100]\u001b[0m Trial 70 finished with value: 9.05149816676225 and parameters: {'n_hidden': 3, 'learning_rate': 0.03703982806480881, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2206472489965873, 'dropout_rate_Layer_2': 0.20583250141762266, 'dropout_rate_Layer_3': 0.3547858987078642, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1243859381777614e-05, 'l1_Layer_2': 3.793627924942253e-05, 'l1_Layer_3': 0.0002908848360030386, 'n_units_Layer_1': 180, 'n_units_Layer_2': 195, 'n_units_Layer_3': 100}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 24.74% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.71 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:14:39,185]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:47,912]\u001b[0m Trial 34 finished with value: 9.598595409883911 and parameters: {'n_hidden': 4, 'learning_rate': 0.0031921739879619943, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39068788021971657, 'dropout_rate_Layer_2': 0.30948662859725845, 'dropout_rate_Layer_3': 0.09847863965348798, 'dropout_rate_Layer_4': 0.21953692554315643, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0017898543883661283, 'l1_Layer_2': 0.0012593128516710623, 'l1_Layer_3': 1.158059860822329e-05, 'l1_Layer_4': 6.977270443582132e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 230, 'n_units_Layer_3': 50, 'n_units_Layer_4': 75}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.60 | sMAPE for Validation Set is: 25.52% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 7.00 | sMAPE for Test Set is: 22.53% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:14:51,638]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:14:55,792]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:02,123]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:02,544]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:07,502]\u001b[0m Trial 68 finished with value: 10.03160090737031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026370782810352534, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37756051577285166, 'dropout_rate_Layer_2': 0.3950680076405052, 'dropout_rate_Layer_3': 0.39892361012119354, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002537785299649994, 'l1_Layer_2': 0.00012354954335634262, 'l1_Layer_3': 0.02365036247261666, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 175}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.03 | sMAPE for Validation Set is: 26.47% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 9.19 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:15:09,749]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:10,078]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:10,691]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:16,923]\u001b[0m Trial 73 finished with value: 10.073393879243115 and parameters: {'n_hidden': 4, 'learning_rate': 0.06074759277504863, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30973756332094565, 'dropout_rate_Layer_2': 0.15605293299586284, 'dropout_rate_Layer_3': 0.24975552006261334, 'dropout_rate_Layer_4': 0.007125340631421651, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 8.625191720297904e-05, 'l1_Layer_2': 0.020700136468698803, 'l1_Layer_3': 0.006766974538483557, 'l1_Layer_4': 6.775779378336928e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135, 'n_units_Layer_4': 80}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.07 | sMAPE for Validation Set is: 26.99% | rMAE for Validation Set is: 0.88\n",
      "MAE for Test Set is: 8.31 | sMAPE for Test Set is: 26.22% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:15:17,371]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:20,388]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:25,594]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:29,288]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:31,342]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:15:46,988]\u001b[0m Trial 87 finished with value: 10.597371249891525 and parameters: {'n_hidden': 3, 'learning_rate': 0.09044121891537431, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1538860370014209, 'dropout_rate_Layer_2': 0.0669240237333606, 'dropout_rate_Layer_3': 0.36183536538098554, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 4.935920625106324e-05, 'l1_Layer_2': 0.005037089083110227, 'l1_Layer_3': 0.0003012734737953712, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 145}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.60 | sMAPE for Validation Set is: 28.03% | rMAE for Validation Set is: 0.93\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 24.76% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:15:50,568]\u001b[0m Trial 81 finished with value: 10.397560145810552 and parameters: {'n_hidden': 4, 'learning_rate': 0.07286217938676, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25078675016849694, 'dropout_rate_Layer_2': 0.10845064447666171, 'dropout_rate_Layer_3': 0.10029704303083267, 'dropout_rate_Layer_4': 0.19582592172106789, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.04400451879305047, 'l1_Layer_2': 0.0008359270696569563, 'l1_Layer_3': 0.02265483774383483, 'l1_Layer_4': 7.427466041537846e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 110, 'n_units_Layer_4': 230}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.40 | sMAPE for Validation Set is: 27.32% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 8.66 | sMAPE for Test Set is: 26.59% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:15:54,514]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:01,318]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:04,983]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:14,226]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:18,606]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:28,236]\u001b[0m Trial 83 finished with value: 9.374385917949278 and parameters: {'n_hidden': 4, 'learning_rate': 0.047728344180231856, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2582670760110033, 'dropout_rate_Layer_2': 0.11712146541998286, 'dropout_rate_Layer_3': 0.11385790968924484, 'dropout_rate_Layer_4': 0.19129102946861598, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017092939620939066, 'l1_Layer_2': 0.0006203050602656138, 'l1_Layer_3': 0.017074520771064593, 'l1_Layer_4': 0.00014877798818310953, 'n_units_Layer_1': 205, 'n_units_Layer_2': 155, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.37 | sMAPE for Validation Set is: 26.09% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 8.26 | sMAPE for Test Set is: 28.15% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:16:38,263]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:42,984]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:16:51,406]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:15,461]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:18,625]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:23,451]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:30,477]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:32,599]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:35,631]\u001b[0m Trial 95 finished with value: 11.116682839349217 and parameters: {'n_hidden': 3, 'learning_rate': 0.017685735163557034, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39911551142977797, 'dropout_rate_Layer_2': 0.31292180039118567, 'dropout_rate_Layer_3': 0.1538305397682702, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002497304994808752, 'l1_Layer_2': 0.00044498656826743563, 'l1_Layer_3': 7.79458682249439e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 55}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.12 | sMAPE for Validation Set is: 28.87% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 8.54 | sMAPE for Test Set is: 26.79% | rMAE for Test Set is: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:17:37,590]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:46,773]\u001b[0m Trial 98 finished with value: 9.052660753325155 and parameters: {'n_hidden': 4, 'learning_rate': 0.05142705313665437, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28152397134882506, 'dropout_rate_Layer_2': 0.001188472357288986, 'dropout_rate_Layer_3': 0.08337622191770247, 'dropout_rate_Layer_4': 0.23703543746073913, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.032096245378071e-05, 'l1_Layer_2': 0.0019915890279576525, 'l1_Layer_3': 0.01528123591960409, 'l1_Layer_4': 2.5889873676421644e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 165, 'n_units_Layer_4': 205}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.05 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.55 | sMAPE for Test Set is: 23.83% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:17:55,353]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:17:59,394]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:03,191]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:03,460]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:03,777]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:12,982]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:17,824]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:21,860]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:23,916]\u001b[0m Trial 105 finished with value: 9.002482279463075 and parameters: {'n_hidden': 4, 'learning_rate': 0.02882339123115102, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20369135630679336, 'dropout_rate_Layer_2': 0.03216805671055051, 'dropout_rate_Layer_3': 0.050946561588111165, 'dropout_rate_Layer_4': 0.17108301039569804, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.0704701770117274e-05, 'l1_Layer_2': 0.001008712687380863, 'l1_Layer_3': 0.034942454067392006, 'l1_Layer_4': 0.0003805040936867041, 'n_units_Layer_1': 235, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130, 'n_units_Layer_4': 245}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 24.19% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:18:26,580]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:28,480]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:31,975]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:39,368]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:41,775]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.63 | sMAPE for Test Set is: 23.70% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:18:43,581]\u001b[0m Trial 110 finished with value: 8.97654376412681 and parameters: {'n_hidden': 4, 'learning_rate': 0.04801523201781423, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19969012311865683, 'dropout_rate_Layer_2': 0.023438681802517097, 'dropout_rate_Layer_3': 0.1080939206094054, 'dropout_rate_Layer_4': 0.22523656168908018, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.8805273290295162e-05, 'l1_Layer_2': 0.0009517687934808668, 'l1_Layer_3': 0.013151905968953185, 'l1_Layer_4': 0.00026302444876582435, 'n_units_Layer_1': 235, 'n_units_Layer_2': 100, 'n_units_Layer_3': 125, 'n_units_Layer_4': 240}. Best is trial 10 with value: 8.634020196262545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:47,094]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:50,185]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:51,953]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:52,686]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:58,119]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:58,533]\u001b[0m Trial 120 finished with value: 7.7374614678308005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016738893077248844, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38428845069894907, 'dropout_rate_Layer_2': 0.25530136228739464, 'dropout_rate_Layer_3': 0.23465187811840793, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3560957271763374e-05, 'l1_Layer_2': 0.00023492011963185063, 'l1_Layer_3': 0.0009888170261325646, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 50}. Best is trial 120 with value: 7.7374614678308005.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 21.71% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 24.15% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:18:59,621]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:18:59,776]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:06,461]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:09,603]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:12,677]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:20,564]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:33,152]\u001b[0m Trial 134 finished with value: 7.733752474380064 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016939494381243863, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3926868517552189, 'dropout_rate_Layer_2': 0.30220012718422506, 'dropout_rate_Layer_3': 0.2218506101491905, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8950955218635468e-05, 'l1_Layer_2': 0.00021167993244374512, 'l1_Layer_3': 0.0009962821992485725, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 50}. Best is trial 134 with value: 7.733752474380064.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 21.74% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.11 | sMAPE for Test Set is: 23.57% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 7.44 | sMAPE for Validation Set is: 20.77% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 22.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:19:35,690]\u001b[0m Trial 133 finished with value: 7.442073909789741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011864265700326888, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3861259077943765, 'dropout_rate_Layer_2': 0.2631042077801697, 'dropout_rate_Layer_3': 0.3090542012808109, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.115464061432495e-05, 'l1_Layer_2': 0.0001947709657598446, 'l1_Layer_3': 0.00175599273610088, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 133 with value: 7.442073909789741.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:51,778]\u001b[0m Trial 130 finished with value: 8.860892633006005 and parameters: {'n_hidden': 4, 'learning_rate': 0.051632933153222905, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29741564854709734, 'dropout_rate_Layer_2': 0.062176843785246586, 'dropout_rate_Layer_3': 0.08804626794859852, 'dropout_rate_Layer_4': 0.23213368566908205, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.963044195698322e-05, 'l1_Layer_2': 0.000670509234072857, 'l1_Layer_3': 0.01993744237833714, 'l1_Layer_4': 3.539118211909224e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 55, 'n_units_Layer_3': 165, 'n_units_Layer_4': 195}. Best is trial 133 with value: 7.442073909789741.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.86 | sMAPE for Validation Set is: 23.72% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 23.17% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:19:53,403]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 20.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.76 | sMAPE for Test Set is: 22.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:19:55,644]\u001b[0m Trial 136 finished with value: 7.264296371458684 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017125114484311324, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3767790015434225, 'dropout_rate_Layer_2': 0.26349191409413425, 'dropout_rate_Layer_3': 0.22801404984100837, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.854154711040498e-05, 'l1_Layer_2': 0.0007900001218475038, 'l1_Layer_3': 0.0012256974208790555, 'n_units_Layer_1': 275, 'n_units_Layer_2': 185, 'n_units_Layer_3': 55}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:19:57,856]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:02,255]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:07,495]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:09,511]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:10,299]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:15,116]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:18,799]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:23,391]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:28,465]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:33,414]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:35,804]\u001b[0m Trial 139 finished with value: 9.437989150279062 and parameters: {'n_hidden': 4, 'learning_rate': 0.08525669017510275, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32343936458712913, 'dropout_rate_Layer_2': 0.050804427723124365, 'dropout_rate_Layer_3': 0.16713279553025748, 'dropout_rate_Layer_4': 0.18726247142505945, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004919305366236567, 'l1_Layer_2': 0.0023877584300619997, 'l1_Layer_3': 0.04630806847619786, 'l1_Layer_4': 0.0005356036313742411, 'n_units_Layer_1': 205, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115, 'n_units_Layer_4': 155}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.44 | sMAPE for Validation Set is: 25.00% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 7.83 | sMAPE for Test Set is: 24.54% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:20:40,596]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.07 | sMAPE for Validation Set is: 22.52% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 21.58% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:20:41,989]\u001b[0m Trial 143 finished with value: 8.074839040354462 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017770044372228558, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3639947383496945, 'dropout_rate_Layer_2': 0.30220564033188885, 'dropout_rate_Layer_3': 0.12750788712557382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2981616069891132e-05, 'l1_Layer_2': 0.0015094063702167945, 'l1_Layer_3': 0.004476233361297315, 'n_units_Layer_1': 280, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:47,001]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:50,672]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:51,048]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:20:56,524]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:03,540]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:09,635]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:10,011]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:14,938]\u001b[0m Trial 145 finished with value: 8.613475150419347 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027470129114283656, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23635965637259276, 'dropout_rate_Layer_2': 0.17410889279366515, 'dropout_rate_Layer_3': 0.18896906342956504, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0023094576204618984, 'l1_Layer_2': 9.331048708208064e-05, 'l1_Layer_3': 3.788019154426021e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 240, 'n_units_Layer_3': 145}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 22.13% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:21:19,688]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:33,557]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:38,502]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:54,320]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:21:56,411]\u001b[0m Trial 156 finished with value: 9.07335309049687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027045985265433314, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2458940435550852, 'dropout_rate_Layer_2': 0.19500731082606146, 'dropout_rate_Layer_3': 0.3046471648798903, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029775922470650497, 'l1_Layer_2': 8.047601593795008e-05, 'l1_Layer_3': 3.5055366511080426e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.07 | sMAPE for Validation Set is: 24.67% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.50 | sMAPE for Test Set is: 25.27% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:22:01,484]\u001b[0m Trial 159 finished with value: 8.679575921824718 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026608216364234372, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3496688476699131, 'dropout_rate_Layer_2': 0.17173463643762335, 'dropout_rate_Layer_3': 0.30519435834839337, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002571602185125331, 'l1_Layer_2': 7.296472676943284e-05, 'l1_Layer_3': 3.359123485488351e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 205, 'n_units_Layer_3': 150}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 23.07% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:22:02,853]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:08,994]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:15,318]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:17,761]\u001b[0m Trial 158 finished with value: 8.850898615817506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023514637640626866, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3444538001962455, 'dropout_rate_Layer_2': 0.15571224273526696, 'dropout_rate_Layer_3': 0.31318929810037793, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024871419578361216, 'l1_Layer_2': 7.233520995405027e-05, 'l1_Layer_3': 4.436612342409236e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 240, 'n_units_Layer_3': 145}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 23.92% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.59 | sMAPE for Test Set is: 24.97% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:22:23,659]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:27,155]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:27,408]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:29,498]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:35,859]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:36,335]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:40,083]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:46,099]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:48,468]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:51,178]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:52,381]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:55,267]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:22:56,089]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:00,321]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:06,852]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:10,153]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:14,981]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:19,608]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:23,039]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:27,840]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:36,596]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:41,641]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:45,660]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:51,598]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:23:51,941]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:00,313]\u001b[0m Trial 186 finished with value: 9.3428662782852 and parameters: {'n_hidden': 3, 'learning_rate': 0.01098879514086296, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3527193898778528, 'dropout_rate_Layer_2': 0.3213692379820618, 'dropout_rate_Layer_3': 0.27518834468146447, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005538055515491415, 'l1_Layer_2': 0.00018993676825249272, 'l1_Layer_3': 0.0077807995772189486, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 210}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 24.44% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 12.69 | sMAPE for Test Set is: 32.94% | rMAE for Test Set is: 1.24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:24:00,723]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:11,943]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:19,107]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:22,738]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:24,979]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:30,205]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:32,435]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:34,877]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:37,215]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:41,343]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:42,909]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:43,872]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:46,415]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:51,640]\u001b[0m Trial 194 finished with value: 9.093648100779488 and parameters: {'n_hidden': 3, 'learning_rate': 0.005516973350272711, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24516078698607963, 'dropout_rate_Layer_2': 0.21891293505557774, 'dropout_rate_Layer_3': 0.30672158355439594, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00803612889486498, 'l1_Layer_2': 0.0001295516521862264, 'l1_Layer_3': 5.445347888306197e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.09 | sMAPE for Validation Set is: 24.01% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 8.88 | sMAPE for Test Set is: 26.33% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:24:53,184]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:54,652]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:55,825]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:24:58,013]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:03,167]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:06,750]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:14,259]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:20,240]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:24,337]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:29,055]\u001b[0m Trial 210 finished with value: 9.007682692973253 and parameters: {'n_hidden': 3, 'learning_rate': 0.009741639008574393, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04829537564246808, 'dropout_rate_Layer_2': 0.1293580776065862, 'dropout_rate_Layer_3': 0.21038109783061293, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.02097444224837761, 'l1_Layer_2': 2.5471131317264758e-05, 'l1_Layer_3': 0.00015273436410909267, 'n_units_Layer_1': 75, 'n_units_Layer_2': 130, 'n_units_Layer_3': 215}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 24.92% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.35 | sMAPE for Test Set is: 25.93% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:25:32,315]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:36,518]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:41,970]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:43,646]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:44,946]\u001b[0m Trial 217 finished with value: 8.999673044841382 and parameters: {'n_hidden': 4, 'learning_rate': 0.024922212203644656, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2695582940951769, 'dropout_rate_Layer_2': 0.04459463896417823, 'dropout_rate_Layer_3': 0.10068632184003802, 'dropout_rate_Layer_4': 0.18364428196000934, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.0254131011801314e-05, 'l1_Layer_2': 0.001223843800188879, 'l1_Layer_3': 0.05907936555661927, 'l1_Layer_4': 0.0002822695654522756, 'n_units_Layer_1': 225, 'n_units_Layer_2': 140, 'n_units_Layer_3': 75, 'n_units_Layer_4': 175}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 23.92% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 23.42% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:25:50,638]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:52,569]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:56,675]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:25:58,994]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.77 | sMAPE for Validation Set is: 25.04% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:26:00,962]\u001b[0m Trial 216 finished with value: 8.76665417427582 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007552594218772334, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34797114349792807, 'dropout_rate_Layer_2': 0.24004688711532404, 'dropout_rate_Layer_3': 0.2751906167262152, 'dropout_rate_Layer_4': 0.1139224060502349, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.962524497251575e-05, 'l1_Layer_2': 0.0002833081638947618, 'l1_Layer_3': 0.014883920883338333, 'l1_Layer_4': 0.010155847327378488, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 85, 'n_units_Layer_4': 215}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:04,737]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:04,854]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:09,767]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:14,709]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:16,794]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:21,570]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:24,657]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:25,003]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:27,133]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:35,068]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:36,327]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:41,620]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:43,304]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:46,952]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:48,738]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:51,697]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:53,883]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:55,951]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:55,974]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:26:59,751]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:04,325]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:04,438]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:10,485]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:10,525]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:10,583]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:11,193]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:20,739]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:22,609]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:22,735]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:30,065]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:30,282]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:35,461]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:35,795]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:36,187]\u001b[0m Trial 253 finished with value: 9.398941873798158 and parameters: {'n_hidden': 3, 'learning_rate': 0.030236514124888838, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30274301163212136, 'dropout_rate_Layer_2': 0.2395329827227916, 'dropout_rate_Layer_3': 0.18700739776515338, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0016162969981598223, 'l1_Layer_2': 0.0003171345294203874, 'l1_Layer_3': 0.0006296022531491524, 'n_units_Layer_1': 235, 'n_units_Layer_2': 50, 'n_units_Layer_3': 245}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.40 | sMAPE for Validation Set is: 24.78% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 7.74 | sMAPE for Test Set is: 24.54% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:27:42,030]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:45,275]\u001b[0m Trial 257 finished with value: 10.311162995479627 and parameters: {'n_hidden': 3, 'learning_rate': 0.03198864149654297, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2935909464874215, 'dropout_rate_Layer_2': 0.2332331725257254, 'dropout_rate_Layer_3': 0.191574947015727, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.0016887964681983304, 'l1_Layer_2': 0.00026348344708967963, 'l1_Layer_3': 0.0007419322108298932, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 220}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.31 | sMAPE for Validation Set is: 26.78% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 23.32% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:27:49,535]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:51,281]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:52,366]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:27:52,909]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:04,449]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:08,259]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:11,849]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:14,856]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:19,019]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:20,658]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:23,970]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:24,367]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:26,979]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:31,102]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:35,236]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:35,453]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:37,601]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:40,767]\u001b[0m Trial 267 finished with value: 8.74200644317397 and parameters: {'n_hidden': 4, 'learning_rate': 0.028763247840108922, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20997777058336692, 'dropout_rate_Layer_2': 0.10382716614685102, 'dropout_rate_Layer_3': 0.07575422403907657, 'dropout_rate_Layer_4': 0.2866970449740979, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.4877747681728195e-05, 'l1_Layer_2': 0.002454607472768045, 'l1_Layer_3': 0.01813588680331409, 'l1_Layer_4': 0.0007013138337123114, 'n_units_Layer_1': 245, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.74 | sMAPE for Validation Set is: 23.69% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 24.89% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:28:46,847]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:47,185]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:50,086]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:55,035]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:28:55,345]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:01,112]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:04,264]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:04,585]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:07,033]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:08,705]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:13,595]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:16,309]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:17,194]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:24,540]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:29,138]\u001b[0m Trial 293 finished with value: 7.389006744736886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010926484476283312, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.166719358472665, 'dropout_rate_Layer_2': 0.2257477639173221, 'dropout_rate_Layer_3': 0.33871264035772425, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.2727419856274e-05, 'l1_Layer_2': 0.0007421401288475658, 'l1_Layer_3': 0.00023830992658318257, 'n_units_Layer_1': 280, 'n_units_Layer_2': 215, 'n_units_Layer_3': 75}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 20.23% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:29:30,685]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:34,801]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:38,562]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:40,474]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:41,022]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:43,981]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:49,556]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:50,374]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:55,034]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:29:58,114]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:02,974]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:06,928]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:07,044]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:07,170]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:15,027]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:16,453]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:18,947]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:23,549]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:28,517]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:31,982]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:32,451]\u001b[0m Trial 315 finished with value: 7.340448346946744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011034682234345398, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1411974327424253, 'dropout_rate_Layer_2': 0.2044984767791544, 'dropout_rate_Layer_3': 0.0339334367781937, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.1970020657014274e-05, 'l1_Layer_2': 0.0004066671859941637, 'l1_Layer_3': 0.00040395697231448757, 'n_units_Layer_1': 280, 'n_units_Layer_2': 215, 'n_units_Layer_3': 160}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 20.40% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 23.26% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:30:39,667]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:39,957]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:48,101]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:48,428]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:54,861]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:55,910]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:30:56,806]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:01,912]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:05,421]\u001b[0m Trial 310 finished with value: 9.082544991242763 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032320863363666788, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29421887683243697, 'dropout_rate_Layer_2': 0.14234035716911247, 'dropout_rate_Layer_3': 0.3296079705728212, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0020926671369492413, 'l1_Layer_2': 0.00019809766036144616, 'l1_Layer_3': 1.8406777822379937e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 245, 'n_units_Layer_3': 140}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.08 | sMAPE for Validation Set is: 24.41% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.57 | sMAPE for Test Set is: 25.51% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:31:12,166]\u001b[0m Trial 326 finished with value: 10.257757016400388 and parameters: {'n_hidden': 3, 'learning_rate': 0.04767782171494126, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35964110259842175, 'dropout_rate_Layer_2': 0.20957974127026915, 'dropout_rate_Layer_3': 0.18297610135790116, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0012146320307625466, 'l1_Layer_2': 0.021385962850323643, 'l1_Layer_3': 0.009368634561787492, 'n_units_Layer_1': 195, 'n_units_Layer_2': 120, 'n_units_Layer_3': 215}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.26 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 8.37 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.82\n",
      "MAE for Validation Set is: 7.37 | sMAPE for Validation Set is: 20.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:31:12,177]\u001b[0m Trial 328 finished with value: 7.37149919396908 and parameters: {'n_hidden': 3, 'learning_rate': 0.001341382750328458, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12335629290976727, 'dropout_rate_Layer_2': 0.2291073212610885, 'dropout_rate_Layer_3': 0.033105516289424264, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.993596692646245e-05, 'l1_Layer_2': 0.00014390315423690243, 'l1_Layer_3': 0.0004151174909937358, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:17,748]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:22,646]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:26,691]\u001b[0m Trial 332 finished with value: 7.444696440176425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030940416570459806, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10104049011300717, 'dropout_rate_Layer_2': 0.17590920149372957, 'dropout_rate_Layer_3': 0.025546836353322944, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.565592027584891e-05, 'l1_Layer_2': 0.0001249170824727777, 'l1_Layer_3': 0.00042390713726292423, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 205}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.44 | sMAPE for Validation Set is: 20.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 23.16% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:31:32,441]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:35,910]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:40,402]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:42,753]\u001b[0m Trial 327 finished with value: 7.636798009873651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006036581584748873, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.111844764244955, 'dropout_rate_Layer_2': 0.17924752811317118, 'dropout_rate_Layer_3': 0.034284704789856874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.910300565002173e-05, 'l1_Layer_2': 0.0005556482808388652, 'l1_Layer_3': 0.0006191664602999272, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 136 with value: 7.264296371458684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.64 | sMAPE for Validation Set is: 21.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 23.33% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:31:54,861]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:31:59,753]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:03,189]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:08,903]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:09,360]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:13,824]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 21.99% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:32:15,515]\u001b[0m Trial 340 finished with value: 6.994500904827963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006033358104190141, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09505358597338898, 'dropout_rate_Layer_2': 0.1751100478862862, 'dropout_rate_Layer_3': 0.02820500764361189, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.0399468711037196e-05, 'l1_Layer_2': 5.8603273232478805e-05, 'l1_Layer_3': 0.00040969101712751474, 'n_units_Layer_1': 260, 'n_units_Layer_2': 175, 'n_units_Layer_3': 295}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:20,916]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:23,568]\u001b[0m Trial 342 finished with value: 7.405416217791246 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013628553142980826, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1011161397822507, 'dropout_rate_Layer_2': 0.1722607083142213, 'dropout_rate_Layer_3': 0.021497660324304273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013023933387167234, 'l1_Layer_2': 6.297569122266508e-05, 'l1_Layer_3': 0.000387217868969729, 'n_units_Layer_1': 270, 'n_units_Layer_2': 160, 'n_units_Layer_3': 270}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 20.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 21.90% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:32:25,312]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:30,127]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:33,746]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:37,102]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:39,344]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:42,720]\u001b[0m Trial 336 finished with value: 8.189692752743122 and parameters: {'n_hidden': 4, 'learning_rate': 0.006617996867806664, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.324008349427452, 'dropout_rate_Layer_2': 0.35418763980497997, 'dropout_rate_Layer_3': 0.2633599468322378, 'dropout_rate_Layer_4': 0.2801029644840153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009706968954474602, 'l1_Layer_2': 0.0398670434867397, 'l1_Layer_3': 0.0036673835836196333, 'l1_Layer_4': 0.0026162746816545254, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 195, 'n_units_Layer_4': 50}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.19 | sMAPE for Validation Set is: 22.60% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:32:44,325]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:46,800]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:49,397]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:51,869]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:32:54,085]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 21.46% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:32:56,785]\u001b[0m Trial 351 finished with value: 7.23518533269925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005887577856203823, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10343882075083626, 'dropout_rate_Layer_2': 0.14746888562533358, 'dropout_rate_Layer_3': 0.042073051070623424, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.045164589997596e-05, 'l1_Layer_2': 5.0378779548851114e-05, 'l1_Layer_3': 0.0004032670918459318, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 300}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:00,429]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:00,615]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:01,766]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:08,726]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:08,905]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:13,060]\u001b[0m Trial 358 finished with value: 7.255668500160151 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005968614778829298, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1022012804647025, 'dropout_rate_Layer_2': 0.1796706345637798, 'dropout_rate_Layer_3': 0.04066229077439738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.3489727506095536e-05, 'l1_Layer_2': 2.82367058713693e-05, 'l1_Layer_3': 0.00039336239005913806, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 300}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:33:16,607]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:16,765]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 22.03% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:33:19,659]\u001b[0m Trial 362 finished with value: 7.105459157280222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009421593396944442, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12505053487978268, 'dropout_rate_Layer_2': 0.1628864058982121, 'dropout_rate_Layer_3': 0.05420982619462602, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.339767473820415e-05, 'l1_Layer_2': 2.8340914307765555e-05, 'l1_Layer_3': 0.00041438820851558253, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 280}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:25,027]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:25,547]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:31,572]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:32,913]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:37,550]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:42,115]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:42,585]\u001b[0m Trial 368 finished with value: 7.038569615317485 and parameters: {'n_hidden': 3, 'learning_rate': 0.000523422142344875, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12768746913203388, 'dropout_rate_Layer_2': 0.14867858638992387, 'dropout_rate_Layer_3': 0.053956900331095486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.891659158083957e-05, 'l1_Layer_2': 2.614876305069604e-05, 'l1_Layer_3': 0.000369198366814845, 'n_units_Layer_1': 295, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 19.39% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 21.87% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:33:42,852]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:52,149]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:55,313]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:59,181]\u001b[0m Trial 374 finished with value: 7.303813487606945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005536495923183149, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13033109019660288, 'dropout_rate_Layer_2': 0.14330703487141683, 'dropout_rate_Layer_3': 0.06340566933968252, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000192207453102173, 'l1_Layer_2': 3.7982634826755837e-05, 'l1_Layer_3': 0.0002523074353238524, 'n_units_Layer_1': 295, 'n_units_Layer_2': 105, 'n_units_Layer_3': 285}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:33:59,253]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.30 | sMAPE for Validation Set is: 20.21% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 21.84% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:33:59,540]\u001b[0m Trial 367 finished with value: 7.286535684761887 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013903743962326467, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13691992186452226, 'dropout_rate_Layer_2': 0.27914925207735264, 'dropout_rate_Layer_3': 0.2456332283401515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012939435693174727, 'l1_Layer_2': 9.126198339386727e-05, 'l1_Layer_3': 0.0001555168105962456, 'n_units_Layer_1': 170, 'n_units_Layer_2': 210, 'n_units_Layer_3': 120}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 20.47% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.33 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:34:09,570]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:12,221]\u001b[0m Trial 376 finished with value: 7.730017029872333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013702018420184694, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3644317209586112, 'dropout_rate_Layer_2': 0.27545384196475353, 'dropout_rate_Layer_3': 0.22905452671352827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.012300279981792608, 'l1_Layer_2': 9.89768742965557e-05, 'l1_Layer_3': 5.478721146187927e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.73 | sMAPE for Validation Set is: 21.47% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:34:16,596]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:18,488]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:21,298]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:23,884]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:24,947]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:27,897]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:28,991]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:32,295]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:33,040]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:43,982]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:34:47,635]\u001b[0m Trial 390 finished with value: 7.095950399925812 and parameters: {'n_hidden': 3, 'learning_rate': 0.000661492362081355, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09178331849183093, 'dropout_rate_Layer_2': 0.16125802691589514, 'dropout_rate_Layer_3': 0.0018599151468534011, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023922793707485955, 'l1_Layer_2': 2.0691063221946256e-05, 'l1_Layer_3': 0.00018662927412208167, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 340 with value: 6.994500904827963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 19.93% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 22.33% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:34:51,061]\u001b[0m Trial 391 finished with value: 6.964608517544313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006674736794094198, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08379169271292528, 'dropout_rate_Layer_2': 0.16410736088001857, 'dropout_rate_Layer_3': 0.001993238407871349, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.343248066554903e-05, 'l1_Layer_2': 2.2556945169038303e-05, 'l1_Layer_3': 7.450841041218796e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 391 with value: 6.964608517544313.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:34:54,876]\u001b[0m Trial 392 finished with value: 6.957950671030317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005023434902035086, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08076753862391639, 'dropout_rate_Layer_2': 0.1600964756586162, 'dropout_rate_Layer_3': 0.007104109110228254, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025638139384745543, 'l1_Layer_2': 3.178817623166391e-05, 'l1_Layer_3': 8.463398093708701e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:34:56,289]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:00,960]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:03,889]\u001b[0m Trial 393 finished with value: 6.973800812811284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005062620066459281, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08868167440376297, 'dropout_rate_Layer_2': 0.15887676678673932, 'dropout_rate_Layer_3': 0.01004585818554966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002942540516989011, 'l1_Layer_2': 3.201254781527812e-05, 'l1_Layer_3': 8.521202102214649e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 22.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:08,819]\u001b[0m Trial 394 finished with value: 7.0911387296854835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006322905654537863, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07853839278626425, 'dropout_rate_Layer_2': 0.16053313045319043, 'dropout_rate_Layer_3': 0.0037632087755963654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026170105883401023, 'l1_Layer_2': 2.327063066187387e-05, 'l1_Layer_3': 6.0430806369964266e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 23.73% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:14,539]\u001b[0m Trial 398 finished with value: 7.067714478008768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006615339153310008, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07241867974753748, 'dropout_rate_Layer_2': 0.1414147594337551, 'dropout_rate_Layer_3': 0.00554842846577467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024061079389796564, 'l1_Layer_2': 2.308150612149752e-05, 'l1_Layer_3': 6.801960386432973e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 22.27% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:14,969]\u001b[0m Trial 396 finished with value: 7.027694404732361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005025825071615456, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0751759175406206, 'dropout_rate_Layer_2': 0.15658091825061066, 'dropout_rate_Layer_3': 0.0039051632826309266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002568444361093467, 'l1_Layer_2': 2.182760395072932e-05, 'l1_Layer_3': 5.4529920011203104e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:21,075]\u001b[0m Trial 400 finished with value: 7.09916112779239 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006565981613607066, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056050020911177834, 'dropout_rate_Layer_2': 0.16122086597407445, 'dropout_rate_Layer_3': 0.0027726462353570083, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003064896938659557, 'l1_Layer_2': 2.272042230894113e-05, 'l1_Layer_3': 6.533039891945899e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.67% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:27,201]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:27,388]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 20.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:29,363]\u001b[0m Trial 402 finished with value: 7.259482253101868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006597727141188979, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06047846265075438, 'dropout_rate_Layer_2': 0.1629558905391681, 'dropout_rate_Layer_3': 0.0015575998891731273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031156231917230863, 'l1_Layer_2': 1.2414229036837481e-05, 'l1_Layer_3': 6.868270086155676e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.56 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.24 | sMAPE for Test Set is: 20.92% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:35:30,139]\u001b[0m Trial 399 finished with value: 7.559735905915026 and parameters: {'n_hidden': 3, 'learning_rate': 0.001528058888327361, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13248781147899322, 'dropout_rate_Layer_2': 0.2532262479242979, 'dropout_rate_Layer_3': 0.2047251682743857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042031884083700505, 'l1_Layer_2': 1.74637001048296e-05, 'l1_Layer_3': 7.611892768925704e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 290}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:34,527]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:35,599]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:43,616]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:46,486]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:46,601]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:51,653]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:53,403]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:54,005]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:35:58,066]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:02,554]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:13,242]\u001b[0m Trial 416 finished with value: 7.243122880244819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007623247164963022, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04407354074770672, 'dropout_rate_Layer_2': 0.08480885212010886, 'dropout_rate_Layer_3': 0.011474716754917867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004141563151965485, 'l1_Layer_2': 1.7280145434763252e-05, 'l1_Layer_3': 5.576902246241374e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 20.09% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 23.89% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:36:17,277]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:17,517]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:23,295]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:23,582]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:23,915]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:30,920]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:31,383]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:32,074]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:35,217]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:38,100]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:40,642]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:40,878]\u001b[0m Trial 411 finished with value: 8.25321619116866 and parameters: {'n_hidden': 4, 'learning_rate': 0.006251997673775144, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30614644274851915, 'dropout_rate_Layer_2': 0.1478735122911167, 'dropout_rate_Layer_3': 0.27840292626394886, 'dropout_rate_Layer_4': 0.3131415590463717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013667132900351024, 'l1_Layer_2': 0.03337436038264111, 'l1_Layer_3': 0.004368341300344774, 'l1_Layer_4': 0.026153837404749143, 'n_units_Layer_1': 230, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200, 'n_units_Layer_4': 150}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.25 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 23.23% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:36:47,493]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:49,992]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:51,327]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:36:52,840]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:01,400]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:05,012]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:05,627]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:13,482]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:20,008]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:20,631]\u001b[0m Trial 437 finished with value: 7.141035951435829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007063121864151319, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0261473845107685, 'dropout_rate_Layer_2': 0.16798036034742267, 'dropout_rate_Layer_3': 0.026302819060657297, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00040847589601247493, 'l1_Layer_2': 1.7213830545619796e-05, 'l1_Layer_3': 3.3414434505446606e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 290}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 19.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 21.77% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:37:21,055]\u001b[0m Trial 432 finished with value: 8.702343161883077 and parameters: {'n_hidden': 4, 'learning_rate': 0.029360345323569244, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2741932904644426, 'dropout_rate_Layer_2': 0.0369448455415107, 'dropout_rate_Layer_3': 0.09422641287177998, 'dropout_rate_Layer_4': 0.00012414778996766573, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.217974304038985e-05, 'l1_Layer_2': 0.001990202880361389, 'l1_Layer_3': 0.09017301208621802, 'l1_Layer_4': 1.8233448417502037e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 140, 'n_units_Layer_3': 95, 'n_units_Layer_4': 225}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.70 | sMAPE for Validation Set is: 23.11% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.39 | sMAPE for Test Set is: 23.21% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:37:25,276]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:28,029]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:28,178]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:29,101]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:36,136]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:37,250]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:41,123]\u001b[0m Trial 436 finished with value: 8.92928088373756 and parameters: {'n_hidden': 4, 'learning_rate': 0.020261731349101288, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27087492152215326, 'dropout_rate_Layer_2': 0.030619912227985886, 'dropout_rate_Layer_3': 0.10721233723358725, 'dropout_rate_Layer_4': 0.18503919933552104, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.051180493378131e-05, 'l1_Layer_2': 0.0017648561556412696, 'l1_Layer_3': 0.019925653956179425, 'l1_Layer_4': 1.2817740785185997e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 140, 'n_units_Layer_3': 110, 'n_units_Layer_4': 230}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 24.03% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.44 | sMAPE for Test Set is: 24.17% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:37:41,359]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:47,182]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:47,257]\u001b[0m Trial 444 finished with value: 7.096898558188639 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007942038184328292, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09180175382307355, 'dropout_rate_Layer_2': 0.1199330242128717, 'dropout_rate_Layer_3': 0.015954926752304734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046809034445777746, 'l1_Layer_2': 1.2679332854114607e-05, 'l1_Layer_3': 1.6976872810929855e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 240}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 21.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:37:47,597]\u001b[0m Trial 448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:37:54,254]\u001b[0m Trial 447 finished with value: 7.214439911960383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006767833354709141, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0719733952468857, 'dropout_rate_Layer_2': 0.1394154369029628, 'dropout_rate_Layer_3': 0.015705526076150486, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000489839738907133, 'l1_Layer_2': 2.4699005168704124e-05, 'l1_Layer_3': 0.00016341766769412537, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 240}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 22.12% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:37:57,077]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:00,828]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:03,691]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:05,754]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:06,130]\u001b[0m Trial 451 finished with value: 9.000650523422596 and parameters: {'n_hidden': 4, 'learning_rate': 0.026596863486618782, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28914161120722226, 'dropout_rate_Layer_2': 0.014625035405105704, 'dropout_rate_Layer_3': 0.09399184989962336, 'dropout_rate_Layer_4': 0.17606262666548383, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.132410593496322e-05, 'l1_Layer_2': 0.002061497649125614, 'l1_Layer_3': 0.012604407196450618, 'l1_Layer_4': 1.6764825680051482e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 120, 'n_units_Layer_3': 160, 'n_units_Layer_4': 230}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.00 | sMAPE for Validation Set is: 24.23% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:38:07,293]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:13,131]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:13,724]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:13,828]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:14,737]\u001b[0m Trial 453 finished with value: 7.521853962003893 and parameters: {'n_hidden': 3, 'learning_rate': 0.001317266353628327, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2008281742843634, 'dropout_rate_Layer_2': 0.2322036653875144, 'dropout_rate_Layer_3': 0.17826734419741927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0042784976598383975, 'l1_Layer_2': 1.9619472481848442e-05, 'l1_Layer_3': 2.339191805490049e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 265, 'n_units_Layer_3': 255}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.52 | sMAPE for Validation Set is: 21.12% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.21 | sMAPE for Test Set is: 20.98% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:38:20,576]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:24,032]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:24,061]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:25,140]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:28,231]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:30,904]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:32,913]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:38,268]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:42,223]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:43,922]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:54,112]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:55,944]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:57,833]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:38:59,423]\u001b[0m Trial 466 finished with value: 9.010952205080782 and parameters: {'n_hidden': 4, 'learning_rate': 0.03300198447184964, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2991154359508001, 'dropout_rate_Layer_2': 0.022506958882021498, 'dropout_rate_Layer_3': 0.12291343757062395, 'dropout_rate_Layer_4': 0.1902872978832381, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004098029366400563, 'l1_Layer_2': 0.0034127840079409087, 'l1_Layer_3': 0.024412917619018048, 'l1_Layer_4': 2.2940623900791968e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 110, 'n_units_Layer_3': 120, 'n_units_Layer_4': 200}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.01 | sMAPE for Validation Set is: 24.15% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 23.53% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:39:00,265]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:01,093]\u001b[0m Trial 472 finished with value: 7.239100880929768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005018574840448873, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08589933792519072, 'dropout_rate_Layer_2': 0.18474217879993143, 'dropout_rate_Layer_3': 0.03110942622563309, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003000420448233984, 'l1_Layer_2': 2.086643566376133e-05, 'l1_Layer_3': 1.3637912952038986e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 20.27% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:39:02,881]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:10,028]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:10,369]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:11,830]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:19,813]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:20,485]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:27,180]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:27,924]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:31,515]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:32,255]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:34,443]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:38,006]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:39,908]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:41,247]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:48,285]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:52,924]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:53,270]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:53,447]\u001b[0m Trial 490 finished with value: 7.759291493533323 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034206041751621875, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18615285341042906, 'dropout_rate_Layer_2': 0.2975142072016633, 'dropout_rate_Layer_3': 0.17645139562942486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011415284035940789, 'l1_Layer_2': 1.7887225430340834e-05, 'l1_Layer_3': 1.0230191860371022e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 295}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.76 | sMAPE for Validation Set is: 21.34% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:39:53,794]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:39:59,421]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:03,890]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:06,683]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:09,140]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:10,339]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:13,322]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:18,330]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:21,690]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:24,190]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:26,349]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:29,130]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:32,385]\u001b[0m Trial 498 finished with value: 8.644530740963013 and parameters: {'n_hidden': 4, 'learning_rate': 0.04749473225631333, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2746740419901432, 'dropout_rate_Layer_2': 0.0011137815060636626, 'dropout_rate_Layer_3': 0.1519531500372613, 'dropout_rate_Layer_4': 0.17384803497673107, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00023598698660563054, 'l1_Layer_2': 0.001967125667868311, 'l1_Layer_3': 0.02632115181314841, 'l1_Layer_4': 0.00015312605258725558, 'n_units_Layer_1': 220, 'n_units_Layer_2': 60, 'n_units_Layer_3': 110, 'n_units_Layer_4': 225}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.64 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.75 | sMAPE for Test Set is: 24.78% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:40:32,808]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:35,744]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:36,550]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:41,907]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:42,224]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:48,241]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:51,634]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:55,002]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:59,615]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:40:59,790]\u001b[0m Trial 514 finished with value: 7.840639427415819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017792112043558833, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11342709848062958, 'dropout_rate_Layer_2': 0.29989758368774644, 'dropout_rate_Layer_3': 0.12864758782663085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0036340078340030965, 'l1_Layer_2': 2.6945916727909506e-05, 'l1_Layer_3': 1.0297909745135268e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 165, 'n_units_Layer_3': 230}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 22.02% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 22.68% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:41:00,336]\u001b[0m Trial 515 finished with value: 6.990506336553305 and parameters: {'n_hidden': 3, 'learning_rate': 0.000590224720711011, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08036630598003511, 'dropout_rate_Layer_2': 0.16595338658882994, 'dropout_rate_Layer_3': 0.03960469179785921, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045637163576335853, 'l1_Layer_2': 3.349562181084212e-05, 'l1_Layer_3': 6.283475881704196e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:41:09,331]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:25,889]\u001b[0m Trial 513 finished with value: 7.1121015160218635 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017012289435526901, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11064931421803062, 'dropout_rate_Layer_2': 0.3560495335350282, 'dropout_rate_Layer_3': 0.12703027297861627, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0038010552032188808, 'l1_Layer_2': 2.638284373507866e-05, 'l1_Layer_3': 0.00011645220837040683, 'n_units_Layer_1': 175, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 19.97% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.20 | sMAPE for Test Set is: 20.91% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:41:28,048]\u001b[0m Trial 522 finished with value: 7.0096651310325235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006486052887255078, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09255321739743827, 'dropout_rate_Layer_2': 0.08785364592958289, 'dropout_rate_Layer_3': 0.01572101437864181, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000601071296813049, 'l1_Layer_2': 1.5870965772874225e-05, 'l1_Layer_3': 0.00010407557000462092, 'n_units_Layer_1': 275, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 19.61% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 22.70% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:41:37,195]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:37,572]\u001b[0m Trial 521 finished with value: 7.139117530947846 and parameters: {'n_hidden': 3, 'learning_rate': 0.000635249098753094, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05669659523672124, 'dropout_rate_Layer_2': 0.14894959165942206, 'dropout_rate_Layer_3': 0.00999757460314785, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012154259024537415, 'l1_Layer_2': 5.584215523272706e-05, 'l1_Layer_3': 6.449585476295422e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 120, 'n_units_Layer_3': 295}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 21.70% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:41:41,391]\u001b[0m Trial 523 finished with value: 7.281707303634736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006427946569089222, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05842454308129409, 'dropout_rate_Layer_2': 0.09182017412295754, 'dropout_rate_Layer_3': 0.009190689872654622, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003603885254813194, 'l1_Layer_2': 1.4708357054823718e-05, 'l1_Layer_3': 6.194965150899556e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.28 | sMAPE for Validation Set is: 20.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:41:42,521]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:45,552]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:50,404]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:53,333]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:54,103]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:41:58,257]\u001b[0m Trial 524 finished with value: 9.560079997637807 and parameters: {'n_hidden': 4, 'learning_rate': 0.008808239260259634, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22430322144027903, 'dropout_rate_Layer_2': 0.10023919636416123, 'dropout_rate_Layer_3': 0.06965108833023495, 'dropout_rate_Layer_4': 0.3105791468562963, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006656192686567648, 'l1_Layer_2': 0.0001017470824107081, 'l1_Layer_3': 0.004253237448101604, 'l1_Layer_4': 0.0011668548322371678, 'n_units_Layer_1': 230, 'n_units_Layer_2': 60, 'n_units_Layer_3': 165, 'n_units_Layer_4': 55}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.56 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.41 | sMAPE for Test Set is: 24.30% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:42:02,966]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:06,208]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:06,531]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:07,419]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:10,472]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:14,534]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:18,573]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:19,173]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:30,639]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:33,039]\u001b[0m Trial 535 finished with value: 6.966034319254203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007198409741816306, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09476108731388151, 'dropout_rate_Layer_2': 0.0618090473483785, 'dropout_rate_Layer_3': 0.036917144694833634, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009536825085390794, 'l1_Layer_2': 1.9119828379393612e-05, 'l1_Layer_3': 3.828722917575209e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 95, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.97 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 21.82% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:42:35,255]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:37,512]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:38,035]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:44,366]\u001b[0m Trial 536 finished with value: 7.206777420393652 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007290948018054141, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09023288483498489, 'dropout_rate_Layer_2': 0.055586037757354906, 'dropout_rate_Layer_3': 0.03183094421135768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015010997314638351, 'l1_Layer_2': 1.9770323159576964e-05, 'l1_Layer_3': 3.5070264270287804e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:44,485]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 22.24% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:42:44,706]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:50,803]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:52,666]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:42:58,477]\u001b[0m Trial 544 finished with value: 7.711370082596243 and parameters: {'n_hidden': 3, 'learning_rate': 0.003162154650843583, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07955079562462955, 'dropout_rate_Layer_2': 0.39424212502384565, 'dropout_rate_Layer_3': 0.1629309103806555, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014735735666939478, 'l1_Layer_2': 2.8585118671014877e-05, 'l1_Layer_3': 7.074843942817109e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.71 | sMAPE for Validation Set is: 21.91% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 22.09% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:43:04,912]\u001b[0m Trial 549 finished with value: 9.327273841774442 and parameters: {'n_hidden': 4, 'learning_rate': 0.019311293776681778, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1988414823580243, 'dropout_rate_Layer_2': 0.04396961969166191, 'dropout_rate_Layer_3': 0.10568179366978074, 'dropout_rate_Layer_4': 0.18539530341108798, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.152469074357519e-05, 'l1_Layer_2': 0.0024066531172569823, 'l1_Layer_3': 0.03830331834354255, 'l1_Layer_4': 2.2841802318908922e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135, 'n_units_Layer_4': 265}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.33 | sMAPE for Validation Set is: 24.92% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 23.76% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:43:10,083]\u001b[0m Trial 550 finished with value: 7.411871119662703 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033391167781013776, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08123808079070785, 'dropout_rate_Layer_2': 0.39951698355754783, 'dropout_rate_Layer_3': 0.1538560586693376, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016235753606290695, 'l1_Layer_2': 0.00807103808639051, 'l1_Layer_3': 0.00014266339190271448, 'n_units_Layer_1': 140, 'n_units_Layer_2': 265, 'n_units_Layer_3': 280}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.41 | sMAPE for Validation Set is: 20.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 22.23% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 19.36% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 22.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:43:12,046]\u001b[0m Trial 551 finished with value: 6.963979190071036 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008330846884808541, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11533896064194503, 'dropout_rate_Layer_2': 0.030765341503012696, 'dropout_rate_Layer_3': 0.01726651263384124, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000543693170359085, 'l1_Layer_2': 2.595875286307808e-05, 'l1_Layer_3': 0.0001478533543168528, 'n_units_Layer_1': 285, 'n_units_Layer_2': 135, 'n_units_Layer_3': 270}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:14,759]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:17,713]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:23,575]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:23,809]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:23,955]\u001b[0m Trial 552 finished with value: 7.17106710542042 and parameters: {'n_hidden': 3, 'learning_rate': 0.002146270553487969, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0686184131992832, 'dropout_rate_Layer_2': 0.3934536975683888, 'dropout_rate_Layer_3': 0.1541943506378509, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003929326314142025, 'l1_Layer_2': 2.899082303063721e-05, 'l1_Layer_3': 0.00012011099298143964, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 260}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 21.20% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:43:31,701]\u001b[0m Trial 554 finished with value: 7.020874722280837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008356164327182582, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11567535480665278, 'dropout_rate_Layer_2': 0.03974884890907769, 'dropout_rate_Layer_3': 0.017161033004232825, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005310267543514205, 'l1_Layer_2': 2.5418535069675514e-05, 'l1_Layer_3': 7.864519300356688e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.02 | sMAPE for Validation Set is: 19.47% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 22.11% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:43:32,283]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:32,442]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:39,444]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:39,980]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:41,786]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:47,022]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:52,544]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:43:56,547]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:04,613]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:05,348]\u001b[0m Trial 562 finished with value: 7.096386662527948 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005837413841828331, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11521262052078711, 'dropout_rate_Layer_2': 0.014193833745348768, 'dropout_rate_Layer_3': 0.04543633132131002, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009400661111188187, 'l1_Layer_2': 2.6904635780439514e-05, 'l1_Layer_3': 7.942913883585747e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 19.34% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 21.56% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:44:10,640]\u001b[0m Trial 566 finished with value: 7.144911176022558 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008285436389270953, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11551139326880208, 'dropout_rate_Layer_2': 0.03576823018158207, 'dropout_rate_Layer_3': 0.047525438615958454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008604199299078178, 'l1_Layer_2': 2.7651081223907198e-05, 'l1_Layer_3': 7.746805096869634e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 85, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.14 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:44:12,624]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:16,403]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:19,945]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:22,550]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:25,506]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:26,062]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:26,735]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:35,141]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:35,764]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:41,419]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:45,272]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:45,699]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:50,659]\u001b[0m Trial 570 finished with value: 7.02903381124229 and parameters: {'n_hidden': 3, 'learning_rate': 0.000850984437537405, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11838953542390576, 'dropout_rate_Layer_2': 0.027943056158516645, 'dropout_rate_Layer_3': 0.01971369006404582, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007048021826219735, 'l1_Layer_2': 4.980607362948839e-05, 'l1_Layer_3': 0.00010042197330323906, 'n_units_Layer_1': 280, 'n_units_Layer_2': 90, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 19.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 22.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:44:54,478]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:44:54,736]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.86 | sMAPE for Validation Set is: 28.13% | rMAE for Validation Set is: 0.86\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:44:58,023]\u001b[0m Trial 577 finished with value: 9.857752000039905 and parameters: {'n_hidden': 4, 'learning_rate': 0.005228861250728754, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1938275696034838, 'dropout_rate_Layer_2': 0.04102638444823517, 'dropout_rate_Layer_3': 0.03438517256990006, 'dropout_rate_Layer_4': 0.1915658315602903, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00014500990912030018, 'l1_Layer_2': 0.0005145577171552975, 'l1_Layer_3': 0.0012469606144760365, 'l1_Layer_4': 0.00047492341733748643, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 220, 'n_units_Layer_4': 65}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:02,885]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:03,274]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:06,681]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:10,992]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:15,372]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:15,555]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:16,621]\u001b[0m Trial 585 finished with value: 7.046368170567412 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008772907983582204, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12038113093574984, 'dropout_rate_Layer_2': 0.06460209525057115, 'dropout_rate_Layer_3': 0.016153428685224562, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037718683123544186, 'l1_Layer_2': 3.278633258552227e-05, 'l1_Layer_3': 5.102487446346462e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 100, 'n_units_Layer_3': 260}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 19.49% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 21.83% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:45:21,253]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:25,100]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:25,597]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:30,705]\u001b[0m Trial 591 finished with value: 8.618176151278742 and parameters: {'n_hidden': 4, 'learning_rate': 0.0202769658586973, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20467604333970524, 'dropout_rate_Layer_2': 0.04412451325415578, 'dropout_rate_Layer_3': 0.05827495621908317, 'dropout_rate_Layer_4': 0.14820059254708007, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.8676266689880635e-05, 'l1_Layer_2': 0.0009978800836824202, 'l1_Layer_3': 0.018020298254766007, 'l1_Layer_4': 0.000322289080839216, 'n_units_Layer_1': 200, 'n_units_Layer_2': 130, 'n_units_Layer_3': 120, 'n_units_Layer_4': 230}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.62 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:45:31,252]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:33,455]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:38,768]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:41,591]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:43,473]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:47,194]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:52,009]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:45:59,953]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:04,665]\u001b[0m Trial 598 finished with value: 7.237610776967038 and parameters: {'n_hidden': 3, 'learning_rate': 0.000869825548462046, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1511390844480395, 'dropout_rate_Layer_2': 0.029778043765262295, 'dropout_rate_Layer_3': 0.028885541250216654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003713279107816902, 'l1_Layer_2': 3.443685353563366e-05, 'l1_Layer_3': 4.2772979182039985e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:46:12,059]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:16,018]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:18,375]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:21,338]\u001b[0m Trial 608 finished with value: 7.192414316565244 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023045785946399443, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08996594343562349, 'dropout_rate_Layer_2': 0.36168868511130664, 'dropout_rate_Layer_3': 0.13110875593694452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005180040498687506, 'l1_Layer_2': 2.63237177172617e-05, 'l1_Layer_3': 0.00010668269167806897, 'n_units_Layer_1': 140, 'n_units_Layer_2': 260, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:46:21,944]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:22,454]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:25,840]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:28,589]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:31,413]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:34,401]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:38,457]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:38,901]\u001b[0m Trial 606 finished with value: 7.1757098497121525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006013036275863322, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11119203727791022, 'dropout_rate_Layer_2': 0.031387289719429515, 'dropout_rate_Layer_3': 0.027106677004661815, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005359577547103795, 'l1_Layer_2': 1.6198685804010928e-05, 'l1_Layer_3': 0.00012011572621913443, 'n_units_Layer_1': 280, 'n_units_Layer_2': 65, 'n_units_Layer_3': 295}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 19.66% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 21.67% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:46:44,978]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:45,498]\u001b[0m Trial 616 finished with value: 7.54180764282313 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022533130402506104, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09522070836597274, 'dropout_rate_Layer_2': 0.35622202187917906, 'dropout_rate_Layer_3': 0.13530026512133803, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00044009775691106505, 'l1_Layer_2': 4.6494068869846016e-05, 'l1_Layer_3': 0.00024163601384297016, 'n_units_Layer_1': 140, 'n_units_Layer_2': 280, 'n_units_Layer_3': 280}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:45,506]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.54 | sMAPE for Validation Set is: 20.80% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:46:45,779]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:52,866]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:53,537]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:53,698]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:46:54,460]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:01,008]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:04,373]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:05,988]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:11,108]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:11,270]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:11,455]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:17,405]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:18,937]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:19,207]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:24,418]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:24,549]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:29,322]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:31,072]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:35,403]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:35,428]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:36,480]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:41,788]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:42,683]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:45,772]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:46,859]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:52,601]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:52,908]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:47:55,097]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:01,949]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:05,933]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:08,659]\u001b[0m Trial 651 finished with value: 7.655815622603982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028840303278434365, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06042159499214825, 'dropout_rate_Layer_2': 0.3448121671402983, 'dropout_rate_Layer_3': 0.0664734371339303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048119316953330047, 'l1_Layer_2': 5.213736497013739e-05, 'l1_Layer_3': 0.0006833264435279667, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 260}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.66 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:48:11,159]\u001b[0m Trial 646 finished with value: 7.112110250481791 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006196027611381514, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10098706975337429, 'dropout_rate_Layer_2': 0.15263581948118368, 'dropout_rate_Layer_3': 0.034812541773844005, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046069224846258846, 'l1_Layer_2': 1.5127186704736538e-05, 'l1_Layer_3': 0.00019778786196744647, 'n_units_Layer_1': 280, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 23.13% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:48:11,933]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:15,174]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:19,106]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:20,960]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:23,552]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:25,723]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:30,945]\u001b[0m Trial 649 finished with value: 9.48155188202192 and parameters: {'n_hidden': 4, 'learning_rate': 0.02734389640267978, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.25253153488801855, 'dropout_rate_Layer_2': 0.13022250823405357, 'dropout_rate_Layer_3': 0.3063883372140925, 'dropout_rate_Layer_4': 0.36140792152636037, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007022972302284381, 'l1_Layer_2': 0.00016030696640878943, 'l1_Layer_3': 0.04481800520659201, 'l1_Layer_4': 0.04714029987180753, 'n_units_Layer_1': 280, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105, 'n_units_Layer_4': 115}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.48 | sMAPE for Validation Set is: 25.27% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:48:35,457]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:37,536]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:40,845]\u001b[0m Trial 661 finished with value: 7.557748874628316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0058080869541794955, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03584231528082165, 'dropout_rate_Layer_2': 0.35330227506821765, 'dropout_rate_Layer_3': 0.12038419372652862, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007903165683055874, 'l1_Layer_2': 0.00012304163877302656, 'l1_Layer_3': 0.00012626397884509937, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.56 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 21.89% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:48:43,539]\u001b[0m Trial 659 finished with value: 7.0943378652344355 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007588446004151003, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08336073801917301, 'dropout_rate_Layer_2': 0.1651409560852769, 'dropout_rate_Layer_3': 0.0013550043094760194, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011695938572963251, 'l1_Layer_2': 4.246910350345568e-05, 'l1_Layer_3': 0.00010638050635034122, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 285}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 19.62% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 22.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:48:45,779]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:46,302]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:53,843]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:48:57,878]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:01,090]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:04,740]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:06,856]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:12,799]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:13,168]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:15,139]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:16,203]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:21,854]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:25,404]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:28,429]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:30,598]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:30,788]\u001b[0m Trial 674 finished with value: 7.101015627278187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008729748672802526, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07664365625514565, 'dropout_rate_Layer_2': 0.1675404466264199, 'dropout_rate_Layer_3': 0.00017067809568981898, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015497171954602577, 'l1_Layer_2': 4.363037604978618e-05, 'l1_Layer_3': 5.12384038532422e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 115, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 21.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:49:31,032]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:31,649]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:37,971]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:39,908]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:44,940]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:49,507]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:50,101]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:55,532]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:59,213]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:49:59,535]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:05,487]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:06,557]\u001b[0m Trial 683 finished with value: 11.13123633733675 and parameters: {'n_hidden': 4, 'learning_rate': 0.0464607278299796, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3232739200088497, 'dropout_rate_Layer_2': 0.34941217541144587, 'dropout_rate_Layer_3': 0.26554169967159535, 'dropout_rate_Layer_4': 0.24601716777561064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.002261296424493494, 'l1_Layer_2': 0.00023626202380017876, 'l1_Layer_3': 0.011613324456394626, 'l1_Layer_4': 0.01670792628027055, 'n_units_Layer_1': 160, 'n_units_Layer_2': 265, 'n_units_Layer_3': 270, 'n_units_Layer_4': 150}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 11.13 | sMAPE for Validation Set is: 29.19% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 8.75 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:50:10,091]\u001b[0m Trial 689 finished with value: 7.029724963509949 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007659875228475906, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09168141575996532, 'dropout_rate_Layer_2': 0.14647606264653182, 'dropout_rate_Layer_3': 0.0074410472379953145, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036775067354630946, 'l1_Layer_2': 2.4576070950016102e-05, 'l1_Layer_3': 0.00014022356519868926, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 19.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:50:11,318]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:15,248]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:15,363]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:15,881]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:22,576]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:22,683]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:28,510]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:28,695]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 19.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:50:31,715]\u001b[0m Trial 696 finished with value: 7.148221965994916 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007724773385578549, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12804572824818106, 'dropout_rate_Layer_2': 0.14554804061886248, 'dropout_rate_Layer_3': 0.008722736819527482, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00034582240620741853, 'l1_Layer_2': 2.4760271863603336e-05, 'l1_Layer_3': 0.00013467204060713112, 'n_units_Layer_1': 290, 'n_units_Layer_2': 130, 'n_units_Layer_3': 280}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:35,038]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:35,568]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:35,620]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:36,212]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:44,067]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:45,218]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:47,362]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:47,699]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:51,320]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:58,790]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:50:59,463]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:04,488]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:07,527]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:08,543]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:12,603]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:17,707]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:20,574]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:20,966]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:26,235]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:28,070]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:30,414]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:33,308]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:35,871]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:35,940]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:36,483]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:40,435]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:46,827]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:47,086]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:47,483]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:48,166]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:56,621]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:51:56,921]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:03,038]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:03,239]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:03,429]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:04,671]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:09,072]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:11,245]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:12,715]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:14,526]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:20,854]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:21,164]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:21,880]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:28,464]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:30,923]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:31,648]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:33,477]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:36,292]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:37,699]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:39,076]\u001b[0m Trial 742 finished with value: 9.235839720547782 and parameters: {'n_hidden': 4, 'learning_rate': 0.010851514739508268, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34521729083504815, 'dropout_rate_Layer_2': 0.12123314267065899, 'dropout_rate_Layer_3': 0.15354226701846696, 'dropout_rate_Layer_4': 0.09210920412637497, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030327066163316602, 'l1_Layer_2': 4.0148180011338825e-05, 'l1_Layer_3': 0.0005260572805417345, 'l1_Layer_4': 0.00010171278199227068, 'n_units_Layer_1': 190, 'n_units_Layer_2': 95, 'n_units_Layer_3': 225, 'n_units_Layer_4': 195}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.24 | sMAPE for Validation Set is: 24.99% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.38 | sMAPE for Test Set is: 24.31% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:52:40,271]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:42,158]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:51,463]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:51,637]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:52,918]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:52:57,480]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:00,090]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:06,242]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:08,939]\u001b[0m Trial 756 finished with value: 7.089321869888188 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009295329547859989, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019058142900553056, 'dropout_rate_Layer_2': 0.37409601918007157, 'dropout_rate_Layer_3': 0.15050469243303846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006964391182120281, 'l1_Layer_2': 7.028631005697406e-05, 'l1_Layer_3': 8.935040068753494e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 260, 'n_units_Layer_3': 290}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 22.39% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:53:12,585]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:14,267]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:18,350]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:21,200]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:24,824]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:27,619]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:29,812]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:34,627]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:36,893]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:40,092]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:44,967]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:48,531]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:53,037]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:54,648]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:53:55,702]\u001b[0m Trial 758 finished with value: 9.536792444161641 and parameters: {'n_hidden': 4, 'learning_rate': 0.01134470681484036, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34406006011064083, 'dropout_rate_Layer_2': 0.12422105168501132, 'dropout_rate_Layer_3': 0.16274718588085302, 'dropout_rate_Layer_4': 0.09575047010172832, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035502451370205525, 'l1_Layer_2': 3.527185977148288e-05, 'l1_Layer_3': 0.09991830506076, 'l1_Layer_4': 7.655657843919002e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 220, 'n_units_Layer_4': 200}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 25.18% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:53:58,614]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:00,844]\u001b[0m Trial 760 finished with value: 8.956160815781056 and parameters: {'n_hidden': 4, 'learning_rate': 0.0116059337909216, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3469531333597645, 'dropout_rate_Layer_2': 0.1938652794185988, 'dropout_rate_Layer_3': 0.14990368239522495, 'dropout_rate_Layer_4': 0.07759764685841558, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0031062471256606433, 'l1_Layer_2': 3.799227145660883e-05, 'l1_Layer_3': 0.09548582466952397, 'l1_Layer_4': 0.0001105250464989641, 'n_units_Layer_1': 190, 'n_units_Layer_2': 100, 'n_units_Layer_3': 225, 'n_units_Layer_4': 200}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.96 | sMAPE for Validation Set is: 23.87% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.34 | sMAPE for Test Set is: 23.33% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:54:06,510]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:08,745]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:12,174]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:12,442]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:17,610]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:18,393]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:23,043]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:25,839]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:29,798]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 19.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 22.44% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:54:30,503]\u001b[0m Trial 779 finished with value: 7.028352767510333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006587179662585098, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09649795842744371, 'dropout_rate_Layer_2': 0.010224169360667158, 'dropout_rate_Layer_3': 0.0006182634329440669, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000876910452210401, 'l1_Layer_2': 2.1932917793161985e-05, 'l1_Layer_3': 0.00011574052625048283, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:35,439]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:36,405]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:37,595]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:42,930]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:43,014]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:47,219]\u001b[0m Trial 784 finished with value: 7.217073180330431 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005014856941791643, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09815697569195607, 'dropout_rate_Layer_2': 0.010108814210582257, 'dropout_rate_Layer_3': 0.00853416183434478, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009009720618658838, 'l1_Layer_2': 2.346652987512229e-05, 'l1_Layer_3': 0.00011038223462979862, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 290}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 19.93% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 21.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:54:48,855]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:53,868]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:54,359]\u001b[0m Trial 792 finished with value: 7.050405944942443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008360012063895226, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08924638183923773, 'dropout_rate_Layer_2': 0.18262839106562925, 'dropout_rate_Layer_3': 0.01924264764841863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00024221691329932127, 'l1_Layer_2': 1.712058183609295e-05, 'l1_Layer_3': 0.00010737025580109119, 'n_units_Layer_1': 295, 'n_units_Layer_2': 140, 'n_units_Layer_3': 260}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:54:54,563]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:54:56,934]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:05,139]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:07,030]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:12,309]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:15,661]\u001b[0m Trial 801 finished with value: 7.029675063692324 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009203129814920168, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09160921634356696, 'dropout_rate_Layer_2': 0.17407487964902063, 'dropout_rate_Layer_3': 0.014020853237242621, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002444986742201015, 'l1_Layer_2': 1.3076870757301094e-05, 'l1_Layer_3': 9.831331367950349e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 155, 'n_units_Layer_3': 275}. Best is trial 392 with value: 6.957950671030317.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 22.53% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:55:16,551]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:18,780]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:24,169]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:28,365]\u001b[0m Trial 802 finished with value: 6.917398831716963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009391709760869976, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2185799658110281, 'dropout_rate_Layer_2': 0.39868033546164405, 'dropout_rate_Layer_3': 0.18439755128265412, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006337172693003413, 'l1_Layer_2': 7.55972887028761e-05, 'l1_Layer_3': 5.575229896041941e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 19.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 23.14% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:55:32,126]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:34,786]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:37,111]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:40,570]\u001b[0m Trial 808 finished with value: 7.211686977254057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008801779208545235, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14135243694181585, 'dropout_rate_Layer_2': 0.2351777252111186, 'dropout_rate_Layer_3': 0.1804115432436813, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006026285931725832, 'l1_Layer_2': 2.2004824003109067e-05, 'l1_Layer_3': 8.609987218754772e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:55:44,476]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:48,622]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:52,492]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:55:52,752]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:00,610]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:03,219]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:04,658]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:11,189]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:16,350]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:28,909]\u001b[0m Trial 815 finished with value: 8.085925517398552 and parameters: {'n_hidden': 4, 'learning_rate': 0.003141768480805235, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33574830280048246, 'dropout_rate_Layer_2': 0.20141626088108233, 'dropout_rate_Layer_3': 0.15003855071285796, 'dropout_rate_Layer_4': 0.11926274238330048, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006215964473408743, 'l1_Layer_2': 2.50725422346554e-05, 'l1_Layer_3': 0.0007041165395357849, 'l1_Layer_4': 4.340000337052638e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210, 'n_units_Layer_4': 210}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.09 | sMAPE for Validation Set is: 22.13% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 23.06% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:56:31,694]\u001b[0m Trial 818 finished with value: 8.650714504549235 and parameters: {'n_hidden': 4, 'learning_rate': 0.003451077729091945, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37238132888672615, 'dropout_rate_Layer_2': 0.20518092361574364, 'dropout_rate_Layer_3': 0.1355182674289312, 'dropout_rate_Layer_4': 0.06453061246135622, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004255915497656002, 'l1_Layer_2': 2.397634127918213e-05, 'l1_Layer_3': 0.0006789090528602601, 'l1_Layer_4': 2.9207472128233332e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210, 'n_units_Layer_4': 210}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.65 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 23.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:56:38,726]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:45,682]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:52,726]\u001b[0m Trial 822 finished with value: 9.17191402247831 and parameters: {'n_hidden': 4, 'learning_rate': 0.014951938856628117, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30701172079980915, 'dropout_rate_Layer_2': 0.1727529349700363, 'dropout_rate_Layer_3': 0.11611733425748857, 'dropout_rate_Layer_4': 0.051263596451427335, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019398153188087334, 'l1_Layer_2': 2.342812028421864e-05, 'l1_Layer_3': 0.09398669374862806, 'l1_Layer_4': 0.00011448663412467049, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210, 'n_units_Layer_4': 180}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.17 | sMAPE for Validation Set is: 24.23% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:56:56,472]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:56:57,460]\u001b[0m Trial 820 finished with value: 9.665317202018405 and parameters: {'n_hidden': 4, 'learning_rate': 0.015251805922977677, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3098612428371901, 'dropout_rate_Layer_2': 0.1707494415552716, 'dropout_rate_Layer_3': 0.20743077192022896, 'dropout_rate_Layer_4': 0.04433159414766317, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019536208128366097, 'l1_Layer_2': 2.731445358417481e-05, 'l1_Layer_3': 0.07498229553838591, 'l1_Layer_4': 9.733062820975523e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210, 'n_units_Layer_4': 170}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.67 | sMAPE for Validation Set is: 25.42% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 22.60% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:56:58,443]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:57:05,074]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:57:09,664]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:57:36,385]\u001b[0m Trial 826 finished with value: 8.466313042991986 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027841133320650018, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37461399915418114, 'dropout_rate_Layer_2': 0.21872142371538808, 'dropout_rate_Layer_3': 0.11510123550940302, 'dropout_rate_Layer_4': 0.10515081833773836, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006269163209897401, 'l1_Layer_2': 2.5204653544671595e-05, 'l1_Layer_3': 0.0002623765414635269, 'l1_Layer_4': 7.684402701048497e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 150, 'n_units_Layer_3': 210, 'n_units_Layer_4': 180}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 23.16% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 25.29% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:57:42,033]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:57:52,711]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:57:55,669]\u001b[0m Trial 834 finished with value: 9.19875826593662 and parameters: {'n_hidden': 4, 'learning_rate': 0.03210141487383942, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27471796325410147, 'dropout_rate_Layer_2': 0.09439703191969831, 'dropout_rate_Layer_3': 0.09645924490040149, 'dropout_rate_Layer_4': 0.08712251070046617, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.9626336335688876e-05, 'l1_Layer_2': 0.002538337868497005, 'l1_Layer_3': 0.02722947915938183, 'l1_Layer_4': 2.143876690698653e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 140, 'n_units_Layer_3': 115, 'n_units_Layer_4': 225}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 24.72% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:57:56,533]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:00,550]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:02,383]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:06,065]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:09,280]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:10,141]\u001b[0m Trial 832 finished with value: 8.978651179775346 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030419982484342356, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3759548371509169, 'dropout_rate_Layer_2': 0.22110089106523428, 'dropout_rate_Layer_3': 0.11662693458860747, 'dropout_rate_Layer_4': 0.10805843999608672, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006131082756245349, 'l1_Layer_2': 1.386896248731215e-05, 'l1_Layer_3': 0.00030631286495304933, 'l1_Layer_4': 4.750467700307568e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 200, 'n_units_Layer_4': 185}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.98 | sMAPE for Validation Set is: 23.90% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.85 | sMAPE for Test Set is: 24.86% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:58:13,944]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:18,093]\u001b[0m Trial 829 finished with value: 9.089904216576222 and parameters: {'n_hidden': 4, 'learning_rate': 0.03319594445754019, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33799062937957297, 'dropout_rate_Layer_2': 0.028397887135883475, 'dropout_rate_Layer_3': 0.09746762666765177, 'dropout_rate_Layer_4': 0.2924220948873588, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.779171104154637e-05, 'l1_Layer_2': 0.002095661397719925, 'l1_Layer_3': 0.04418659581709597, 'l1_Layer_4': 0.0002582063230697222, 'n_units_Layer_1': 215, 'n_units_Layer_2': 130, 'n_units_Layer_3': 175, 'n_units_Layer_4': 235}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.09 | sMAPE for Validation Set is: 24.82% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.15 | sMAPE for Test Set is: 24.66% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:58:20,757]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:25,512]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:29,137]\u001b[0m Trial 842 finished with value: 7.074866525551575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009643064801270191, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.225097437549832, 'dropout_rate_Layer_2': 0.20063596616624718, 'dropout_rate_Layer_3': 0.18271230634181113, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006065618415913315, 'l1_Layer_2': 2.2507540492064174e-05, 'l1_Layer_3': 6.0909773115168675e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 19.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 22.77% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:58:32,953]\u001b[0m Trial 843 finished with value: 7.038185125545112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011412947308371778, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10797690861916862, 'dropout_rate_Layer_2': 0.17479530469035476, 'dropout_rate_Layer_3': 0.011822748671401971, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001795795275270648, 'l1_Layer_2': 1.7029425971258045e-05, 'l1_Layer_3': 7.2467773151084e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 120, 'n_units_Layer_3': 250}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 19.30% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.35 | sMAPE for Test Set is: 21.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:58:35,179]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:58:37,421]\u001b[0m Trial 845 finished with value: 7.052518727496211 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009417151843797548, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2150170841204591, 'dropout_rate_Layer_2': 0.19869812744333054, 'dropout_rate_Layer_3': 0.1947953755086648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006581801317726684, 'l1_Layer_2': 2.323843616983e-05, 'l1_Layer_3': 5.9968747478876476e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:38,417]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:41,087]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:43,279]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:43,443]\u001b[0m Trial 846 finished with value: 8.868127361285175 and parameters: {'n_hidden': 4, 'learning_rate': 0.017837089470508313, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3268461138815791, 'dropout_rate_Layer_2': 0.00021025241936183103, 'dropout_rate_Layer_3': 0.10986772704498055, 'dropout_rate_Layer_4': 0.20490883087000028, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 2.851648673494914e-05, 'l1_Layer_2': 0.00020368347734404815, 'l1_Layer_3': 0.07372522757359412, 'l1_Layer_4': 1.6944836841039507e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 120, 'n_units_Layer_3': 175, 'n_units_Layer_4': 150}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.87 | sMAPE for Validation Set is: 23.61% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 22.66% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:58:43,942]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:47,184]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:53,284]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:54,992]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:58,869]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:58:59,671]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:05,061]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:08,934]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:09,123]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:15,096]\u001b[0m Trial 856 finished with value: 7.232778591360738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007852501307537287, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22114799377293987, 'dropout_rate_Layer_2': 0.19737129837578468, 'dropout_rate_Layer_3': 0.19565428357325518, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000623764039418473, 'l1_Layer_2': 3.6860341831899005e-05, 'l1_Layer_3': 5.911266471580283e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 19.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 23.64% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 23.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:59:16,955]\u001b[0m Trial 857 finished with value: 7.089639070134443 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007747297757979334, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22199582369321494, 'dropout_rate_Layer_2': 0.20182353242519646, 'dropout_rate_Layer_3': 0.19068930391867603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005447402776432489, 'l1_Layer_2': 2.3759665163852896e-05, 'l1_Layer_3': 5.494382230015526e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 235}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:18,651]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:20,198]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:21,480]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:28,104]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:28,629]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:32,770]\u001b[0m Trial 862 finished with value: 9.075674098679029 and parameters: {'n_hidden': 4, 'learning_rate': 0.01779272962011034, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3274016120260328, 'dropout_rate_Layer_2': 0.024322567077118617, 'dropout_rate_Layer_3': 0.14659063668940148, 'dropout_rate_Layer_4': 0.12968547547908174, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.621883585071342e-05, 'l1_Layer_2': 8.18629837298353e-05, 'l1_Layer_3': 0.07103886037308561, 'l1_Layer_4': 2.3488909390551347e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 135, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.08 | sMAPE for Validation Set is: 23.94% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.27 | sMAPE for Test Set is: 22.73% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:59:33,681]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:38,107]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:40,115]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:41,382]\u001b[0m Trial 868 finished with value: 7.077270836151402 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009415441950340162, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2511730152463141, 'dropout_rate_Layer_2': 0.18787828118376765, 'dropout_rate_Layer_3': 0.1822191689499914, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028626042002838603, 'l1_Layer_2': 2.4045051054573307e-05, 'l1_Layer_3': 9.398528579422878e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 245, 'n_units_Layer_3': 210}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 23.00% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:59:44,011]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:47,668]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:48,268]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 17:59:49,069]\u001b[0m Trial 870 finished with value: 7.264253143103762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009267072984123508, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2631717269265262, 'dropout_rate_Layer_2': 0.21222661993010516, 'dropout_rate_Layer_3': 0.2137088554049632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00035421223505061755, 'l1_Layer_2': 2.2714418104367442e-05, 'l1_Layer_3': 8.531716409221591e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 215}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 20.15% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 24.40% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 17:59:56,140]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:04,532]\u001b[0m Trial 877 finished with value: 8.50311276313313 and parameters: {'n_hidden': 4, 'learning_rate': 0.017178012028059034, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34428751741300934, 'dropout_rate_Layer_2': 0.03997366531934826, 'dropout_rate_Layer_3': 0.13871550089400153, 'dropout_rate_Layer_4': 0.19546817012508982, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.869942672610445e-05, 'l1_Layer_2': 1.929368020614089e-05, 'l1_Layer_3': 0.06747835654717971, 'l1_Layer_4': 3.0861606372308323e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 130, 'n_units_Layer_3': 135, 'n_units_Layer_4': 150}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 22.81% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.20 | sMAPE for Test Set is: 22.72% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:00:06,286]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:10,527]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:11,268]\u001b[0m Trial 879 finished with value: 8.163820823959353 and parameters: {'n_hidden': 4, 'learning_rate': 0.013039365710478779, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32633357105136096, 'dropout_rate_Layer_2': 0.0008118212311647721, 'dropout_rate_Layer_3': 0.15569452245232146, 'dropout_rate_Layer_4': 0.09312056499627637, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.200538437714047e-05, 'l1_Layer_2': 8.250698152326405e-05, 'l1_Layer_3': 0.061283761889118604, 'l1_Layer_4': 3.2072272632402535e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.16 | sMAPE for Validation Set is: 22.31% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 22.90% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:00:17,374]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:17,842]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:22,929]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:26,263]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:26,473]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:31,491]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:31,722]\u001b[0m Trial 882 finished with value: 7.160585756290781 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005816738622971106, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2320294644083692, 'dropout_rate_Layer_2': 0.20434017848497874, 'dropout_rate_Layer_3': 0.1976763188793788, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010927192915613216, 'l1_Layer_2': 1.3966600147906294e-05, 'l1_Layer_3': 4.217497834775377e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 230}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 20.38% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 22.65% | rMAE for Test Set is: 0.64\n",
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 19.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 22.19% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:00:34,966]\u001b[0m Trial 886 finished with value: 7.040771951619502 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006191743378570083, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0945434872594134, 'dropout_rate_Layer_2': 0.17061042995712986, 'dropout_rate_Layer_3': 0.00953004111384381, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013709750623004405, 'l1_Layer_2': 2.1969919042201163e-05, 'l1_Layer_3': 9.208989648303672e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 280}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:37,361]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:37,635]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:41,194]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:48,308]\u001b[0m Trial 888 finished with value: 7.224573269212546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007159705951404598, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24601926910848843, 'dropout_rate_Layer_2': 0.22629388840752757, 'dropout_rate_Layer_3': 0.21665122818694965, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006154772259688782, 'l1_Layer_2': 1.580267477066297e-05, 'l1_Layer_3': 4.6125690310010187e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 255, 'n_units_Layer_3': 230}. Best is trial 802 with value: 6.917398831716963.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.22 | sMAPE for Validation Set is: 20.14% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 24.25% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:00:51,764]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:00:55,724]\u001b[0m Trial 894 finished with value: 6.79171165416867 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007389906576475073, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24686979523058608, 'dropout_rate_Layer_2': 0.18364546984745642, 'dropout_rate_Layer_3': 0.2155272517822112, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021398335747467985, 'l1_Layer_2': 1.533832288514584e-05, 'l1_Layer_3': 3.414340761212528e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.79 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:00:55,978]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:01,165]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:03,291]\u001b[0m Trial 895 finished with value: 7.322129532977855 and parameters: {'n_hidden': 4, 'learning_rate': 0.004526568821692507, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3447725309374749, 'dropout_rate_Layer_2': 0.0022173600188000187, 'dropout_rate_Layer_3': 0.16800682644267648, 'dropout_rate_Layer_4': 0.09603107106597909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 4.1400110920118234e-05, 'l1_Layer_2': 5.874453039234385e-05, 'l1_Layer_3': 0.08974799112641066, 'l1_Layer_4': 4.230293238777619e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 20.27% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.29 | sMAPE for Test Set is: 20.98% | rMAE for Test Set is: 0.61\n",
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 20.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.23 | sMAPE for Test Set is: 20.95% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:01:03,411]\u001b[0m Trial 893 finished with value: 7.188084349473956 and parameters: {'n_hidden': 4, 'learning_rate': 0.0046486854428463825, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3415713346806465, 'dropout_rate_Layer_2': 0.0032785290883989605, 'dropout_rate_Layer_3': 0.16328289375792643, 'dropout_rate_Layer_4': 0.10267851835359927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 6.796621448519814e-05, 'l1_Layer_2': 6.86845622179183e-05, 'l1_Layer_3': 0.08893198369759053, 'l1_Layer_4': 1.7476226151220092e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 130, 'n_units_Layer_3': 130, 'n_units_Layer_4': 155}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:05,030]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:09,846]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:12,767]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:13,526]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:18,331]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:19,044]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:23,841]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:26,336]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:28,270]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:01:43,870]\u001b[0m Trial 910 finished with value: 7.672981365379674 and parameters: {'n_hidden': 4, 'learning_rate': 0.005269875016768622, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32638184436416706, 'dropout_rate_Layer_2': 0.00817178012597303, 'dropout_rate_Layer_3': 0.16406255949325282, 'dropout_rate_Layer_4': 0.09378832578935349, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005909315595102531, 'l1_Layer_2': 3.8914981835155096e-05, 'l1_Layer_3': 0.08263233277667391, 'l1_Layer_4': 1.4004972754589293e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 125, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 21.09% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:01:50,508]\u001b[0m Trial 911 finished with value: 7.905979149622124 and parameters: {'n_hidden': 4, 'learning_rate': 0.005911823751857415, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3284559392401559, 'dropout_rate_Layer_2': 1.4633788235470608e-05, 'dropout_rate_Layer_3': 0.16552502729748322, 'dropout_rate_Layer_4': 0.08720737665545554, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004376996745576449, 'l1_Layer_2': 4.457253767239813e-05, 'l1_Layer_3': 0.08291447411808751, 'l1_Layer_4': 2.517066945300298e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 22.45% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:01:51,501]\u001b[0m Trial 903 finished with value: 9.281747652863741 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019277370880538284, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3864062414611651, 'dropout_rate_Layer_2': 0.19377967310649824, 'dropout_rate_Layer_3': 0.12445478059692897, 'dropout_rate_Layer_4': 0.11566197178345265, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.017740818043379642, 'l1_Layer_2': 1.4237062397892364e-05, 'l1_Layer_3': 0.00014553686084338896, 'l1_Layer_4': 4.438140179310854e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 190, 'n_units_Layer_4': 215}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 25.19% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.28 | sMAPE for Test Set is: 24.37% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:01:56,518]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:04,181]\u001b[0m Trial 912 finished with value: 7.638452262361177 and parameters: {'n_hidden': 4, 'learning_rate': 0.005004784056646453, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32710174416439475, 'dropout_rate_Layer_2': 0.0007568411766786267, 'dropout_rate_Layer_3': 0.16973686785969486, 'dropout_rate_Layer_4': 0.0984198291970215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 7.999851992550784e-05, 'l1_Layer_2': 3.6957476038476554e-05, 'l1_Layer_3': 0.07996641070559278, 'l1_Layer_4': 1.2309094612227297e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.64 | sMAPE for Validation Set is: 20.99% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:02:04,891]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:09,813]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:13,434]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:17,294]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:20,849]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:26,158]\u001b[0m Trial 916 finished with value: 7.266299666061762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011625924256582602, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.20742724823948988, 'dropout_rate_Layer_2': 0.18068852474977043, 'dropout_rate_Layer_3': 0.19899181394482607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.673075195572238e-05, 'l1_Layer_2': 3.1908511965419366e-05, 'l1_Layer_3': 1.559981592229871e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 20.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 23.64% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:02:32,206]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:34,787]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:02:54,108]\u001b[0m Trial 924 finished with value: 7.740689303144619 and parameters: {'n_hidden': 4, 'learning_rate': 0.00469712165724231, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3593491952714778, 'dropout_rate_Layer_2': 0.002640677202790035, 'dropout_rate_Layer_3': 0.15737289767395, 'dropout_rate_Layer_4': 0.10233449463152026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005672832061027398, 'l1_Layer_2': 3.425193973091929e-05, 'l1_Layer_3': 0.07077891971331479, 'l1_Layer_4': 1.7393696563921588e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 21.54% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 21.95% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:02:58,214]\u001b[0m Trial 908 finished with value: 9.4868076134172 and parameters: {'n_hidden': 4, 'learning_rate': 0.001561597373530294, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39402665460247094, 'dropout_rate_Layer_2': 0.22158082955893643, 'dropout_rate_Layer_3': 0.12409975039871038, 'dropout_rate_Layer_4': 0.11602896124303122, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.01684476458198239, 'l1_Layer_2': 1.2780454843830515e-05, 'l1_Layer_3': 0.00014852046441683156, 'l1_Layer_4': 3.831187018815806e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 155, 'n_units_Layer_3': 190, 'n_units_Layer_4': 215}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.49 | sMAPE for Validation Set is: 25.79% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.51 | sMAPE for Test Set is: 25.18% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:07,075]\u001b[0m Trial 925 finished with value: 6.917524084479408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010199535397260482, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2296512066850024, 'dropout_rate_Layer_2': 0.18730235130411846, 'dropout_rate_Layer_3': 0.18796196370236246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001744114250941494, 'l1_Layer_2': 1.7609112284547532e-05, 'l1_Layer_3': 2.7475660943349632e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.96 | sMAPE for Test Set is: 23.69% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:15,520]\u001b[0m Trial 915 finished with value: 9.27853179960222 and parameters: {'n_hidden': 4, 'learning_rate': 0.001380064003522365, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3987686450727313, 'dropout_rate_Layer_2': 0.22475943919037827, 'dropout_rate_Layer_3': 0.14483812150736827, 'dropout_rate_Layer_4': 0.16499310568617115, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.029976535102354596, 'l1_Layer_2': 1.54953524677576e-05, 'l1_Layer_3': 9.280219238090409e-05, 'l1_Layer_4': 1.8890634833676045e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 195, 'n_units_Layer_4': 240}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.28 | sMAPE for Validation Set is: 25.11% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 7.24 | sMAPE for Test Set is: 24.38% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:19,877]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:03:25,603]\u001b[0m Trial 926 finished with value: 8.318272457243786 and parameters: {'n_hidden': 4, 'learning_rate': 0.004294534521875609, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3733549558746472, 'dropout_rate_Layer_2': 0.0009109044921407258, 'dropout_rate_Layer_3': 0.15720439004086142, 'dropout_rate_Layer_4': 0.11027177114949516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0008350543220940423, 'l1_Layer_2': 3.884070052850309e-05, 'l1_Layer_3': 0.06715840583428968, 'l1_Layer_4': 1.7302597788051815e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.32 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:26,376]\u001b[0m Trial 927 finished with value: 7.928348290265383 and parameters: {'n_hidden': 4, 'learning_rate': 0.005090802104597524, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3682349241163004, 'dropout_rate_Layer_2': 9.30293901767556e-05, 'dropout_rate_Layer_3': 0.16378189760598127, 'dropout_rate_Layer_4': 0.10210567041424819, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00086869025880109, 'l1_Layer_2': 3.9987690452719414e-05, 'l1_Layer_3': 0.06842193289068356, 'l1_Layer_4': 1.809599145873561e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 22.06% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 22.80% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:29,325]\u001b[0m Trial 928 finished with value: 6.948829908697576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010280238361779243, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23416986186776412, 'dropout_rate_Layer_2': 0.2041103495772448, 'dropout_rate_Layer_3': 0.23812510583433694, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00026812090380991623, 'l1_Layer_2': 1.6804223413081926e-05, 'l1_Layer_3': 2.5633779564493243e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 240, 'n_units_Layer_3': 245}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 19.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 23.27% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:33,180]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:03:36,526]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:03:39,287]\u001b[0m Trial 929 finished with value: 7.965173258457326 and parameters: {'n_hidden': 4, 'learning_rate': 0.0051639798989876005, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36567056793331676, 'dropout_rate_Layer_2': 0.0016757019269130115, 'dropout_rate_Layer_3': 0.17713949639746657, 'dropout_rate_Layer_4': 0.10781978680373487, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000849829227935228, 'l1_Layer_2': 2.2279302296200985e-05, 'l1_Layer_3': 0.0721396209261174, 'l1_Layer_4': 1.864276830464002e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.97 | sMAPE for Validation Set is: 21.75% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 22.24% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:50,368]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:03:54,991]\u001b[0m Trial 931 finished with value: 7.691184656667059 and parameters: {'n_hidden': 4, 'learning_rate': 0.005351814806474132, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38526957872342726, 'dropout_rate_Layer_2': 0.004949187834012721, 'dropout_rate_Layer_3': 0.15905468595067346, 'dropout_rate_Layer_4': 0.11370521060926743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009295734807225468, 'l1_Layer_2': 3.47965404669775e-05, 'l1_Layer_3': 0.07078464047653944, 'l1_Layer_4': 1.63747755140865e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.69 | sMAPE for Validation Set is: 21.48% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:03:57,348]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:04:00,062]\u001b[0m Trial 935 finished with value: 7.910447319881431 and parameters: {'n_hidden': 4, 'learning_rate': 0.004644160833978325, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37491998950992844, 'dropout_rate_Layer_2': 0.00179285550053436, 'dropout_rate_Layer_3': 0.17892829847115282, 'dropout_rate_Layer_4': 0.10438678303150833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005993764423466092, 'l1_Layer_2': 3.330493341185509e-05, 'l1_Layer_3': 0.07005353892531775, 'l1_Layer_4': 1.6485535771716142e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.91 | sMAPE for Validation Set is: 21.67% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 21.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:04:12,927]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:04:13,620]\u001b[0m Trial 937 finished with value: 8.019279868660469 and parameters: {'n_hidden': 4, 'learning_rate': 0.004508599682969488, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3835938386032839, 'dropout_rate_Layer_2': 0.008138167171685721, 'dropout_rate_Layer_3': 0.17926791237536102, 'dropout_rate_Layer_4': 0.10434559614396689, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007817806871947435, 'l1_Layer_2': 3.314180590503368e-05, 'l1_Layer_3': 0.08344080532953177, 'l1_Layer_4': 1.6519619370116676e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 22.12% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 22.47% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:04:18,681]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:04:29,621]\u001b[0m Trial 938 finished with value: 7.923267840836023 and parameters: {'n_hidden': 4, 'learning_rate': 0.00493832286680235, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3626480663083498, 'dropout_rate_Layer_2': 0.0016733228541406446, 'dropout_rate_Layer_3': 0.18498952420567732, 'dropout_rate_Layer_4': 0.10244818860748352, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007863855780523895, 'l1_Layer_2': 3.2596049078690626e-05, 'l1_Layer_3': 0.08336875319703974, 'l1_Layer_4': 1.194230860198418e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:04:36,303]\u001b[0m Trial 942 finished with value: 8.183122296120201 and parameters: {'n_hidden': 4, 'learning_rate': 0.004535098228360249, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3843359545518281, 'dropout_rate_Layer_2': 6.310787732843924e-05, 'dropout_rate_Layer_3': 0.17450797125030945, 'dropout_rate_Layer_4': 0.09885538731679872, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010984823819922148, 'l1_Layer_2': 2.4522876564564874e-05, 'l1_Layer_3': 0.07226631542278378, 'l1_Layer_4': 1.6751551098221263e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 110, 'n_units_Layer_3': 145, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 23.06% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:04:44,025]\u001b[0m Trial 941 finished with value: 7.527745450698046 and parameters: {'n_hidden': 4, 'learning_rate': 0.00395032729640951, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3830272773607551, 'dropout_rate_Layer_2': 7.500900928323522e-05, 'dropout_rate_Layer_3': 0.1738082551210542, 'dropout_rate_Layer_4': 0.09943515552477233, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011433957915131332, 'l1_Layer_2': 2.3844872416335348e-05, 'l1_Layer_3': 0.07136830567232937, 'l1_Layer_4': 1.570576894349097e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 21.04% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 21.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:04:47,371]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:04:50,224]\u001b[0m Trial 943 finished with value: 8.454839947672085 and parameters: {'n_hidden': 4, 'learning_rate': 0.004619931657253817, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38933128823668645, 'dropout_rate_Layer_2': 6.607293876808966e-05, 'dropout_rate_Layer_3': 0.19675642249698488, 'dropout_rate_Layer_4': 0.09801154632695518, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011735826090217567, 'l1_Layer_2': 3.241088101052106e-05, 'l1_Layer_3': 0.0826706704707052, 'l1_Layer_4': 1.209352705499784e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 115, 'n_units_Layer_3': 145, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:04:51,277]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:04:55,092]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:05:07,696]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:05:12,676]\u001b[0m Trial 948 finished with value: 7.127191944403083 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007212962520273758, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1105273312265084, 'dropout_rate_Layer_2': 0.16642946948674456, 'dropout_rate_Layer_3': 0.027291970193135874, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.416229091888492e-05, 'l1_Layer_2': 1.8649086772850702e-05, 'l1_Layer_3': 7.798702741168255e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.13 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 22.17% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:05:18,856]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:05:27,623]\u001b[0m Trial 950 finished with value: 7.735856406240269 and parameters: {'n_hidden': 4, 'learning_rate': 0.0046354019008836185, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38293507985646646, 'dropout_rate_Layer_2': 0.008421506861484749, 'dropout_rate_Layer_3': 0.1980568810370815, 'dropout_rate_Layer_4': 0.09698568738014356, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007735315953220072, 'l1_Layer_2': 3.649254875093172e-05, 'l1_Layer_3': 0.08586297361118049, 'l1_Layer_4': 1.187171814503623e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 145, 'n_units_Layer_4': 135}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.74 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:05:39,708]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:05:55,884]\u001b[0m Trial 954 finished with value: 7.2381521955387775 and parameters: {'n_hidden': 3, 'learning_rate': 0.000553440976941461, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07889072826506793, 'dropout_rate_Layer_2': 0.14924178981258399, 'dropout_rate_Layer_3': 0.017701909993609738, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003232202972534013, 'l1_Layer_2': 3.63313954648665e-05, 'l1_Layer_3': 5.578034767831975e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.24 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 21.73% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:06:06,471]\u001b[0m Trial 944 finished with value: 9.343864322485093 and parameters: {'n_hidden': 4, 'learning_rate': 0.002747848999142163, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3642529433028912, 'dropout_rate_Layer_2': 0.17840739305261658, 'dropout_rate_Layer_3': 0.11092966642388845, 'dropout_rate_Layer_4': 0.05006380988865784, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007373579530447932, 'l1_Layer_2': 5.859995166267713e-05, 'l1_Layer_3': 3.714963829327218e-05, 'l1_Layer_4': 0.0001624529572783086, 'n_units_Layer_1': 175, 'n_units_Layer_2': 145, 'n_units_Layer_3': 215, 'n_units_Layer_4': 180}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.34 | sMAPE for Validation Set is: 25.31% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 7.96 | sMAPE for Test Set is: 26.37% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:06:16,773]\u001b[0m Trial 955 finished with value: 7.564177709888923 and parameters: {'n_hidden': 4, 'learning_rate': 0.004589431548191932, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37942387028245256, 'dropout_rate_Layer_2': 0.00949143516536259, 'dropout_rate_Layer_3': 0.19680077479340918, 'dropout_rate_Layer_4': 0.09538058378580543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007640205489168949, 'l1_Layer_2': 3.695379331564017e-05, 'l1_Layer_3': 0.06922393132057418, 'l1_Layer_4': 1.0006510648656908e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 140}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.56 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.25% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:06:29,578]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:06:33,314]\u001b[0m Trial 956 finished with value: 7.504530234734077 and parameters: {'n_hidden': 4, 'learning_rate': 0.0047585108220989806, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38207196921651687, 'dropout_rate_Layer_2': 0.008345235122565128, 'dropout_rate_Layer_3': 0.20070983962093136, 'dropout_rate_Layer_4': 0.09492094405028972, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011705751742954842, 'l1_Layer_2': 3.6975064466670125e-05, 'l1_Layer_3': 0.0682004280348395, 'l1_Layer_4': 1.62293131401852e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 125}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.50 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 22.47% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:06:44,957]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:06:50,316]\u001b[0m Trial 932 finished with value: 9.134416634934214 and parameters: {'n_hidden': 4, 'learning_rate': 0.002592705482675724, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3797345338440685, 'dropout_rate_Layer_2': 0.1800722819620158, 'dropout_rate_Layer_3': 0.11154975160576107, 'dropout_rate_Layer_4': 0.05928562146861156, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.006570802697306626, 'l1_Layer_2': 1.9872763477144416e-05, 'l1_Layer_3': 0.000998498039513018, 'l1_Layer_4': 0.00013485864548089106, 'n_units_Layer_1': 120, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215, 'n_units_Layer_4': 180}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.13 | sMAPE for Validation Set is: 24.67% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 24.23% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:06:50,812]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:06:55,723]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:06:57,495]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:06:59,970]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:03,363]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:12,834]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:16,684]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:20,391]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:23,000]\u001b[0m Trial 958 finished with value: 9.139781011715115 and parameters: {'n_hidden': 4, 'learning_rate': 0.003970210170341355, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38004086480659754, 'dropout_rate_Layer_2': 0.19936365786408689, 'dropout_rate_Layer_3': 0.07576038646681918, 'dropout_rate_Layer_4': 0.14988832990665266, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004026236050006678, 'l1_Layer_2': 1.9470703623897257e-05, 'l1_Layer_3': 0.00033695411629429655, 'l1_Layer_4': 5.674987023605505e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 205, 'n_units_Layer_4': 290}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.14 | sMAPE for Validation Set is: 24.49% | rMAE for Validation Set is: 0.80\n",
      "MAE for Test Set is: 7.25 | sMAPE for Test Set is: 24.36% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:07:34,112]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:37,792]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:07:48,416]\u001b[0m Trial 970 finished with value: 7.8852623331346985 and parameters: {'n_hidden': 4, 'learning_rate': 0.005239578374273195, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39146937896953216, 'dropout_rate_Layer_2': 0.011830346629133619, 'dropout_rate_Layer_3': 0.18770085584514706, 'dropout_rate_Layer_4': 0.11333039378265719, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.000852489244302949, 'l1_Layer_2': 1.4679533517810867e-05, 'l1_Layer_3': 0.06601897244480284, 'l1_Layer_4': 1.0496955646719387e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150, 'n_units_Layer_4': 125}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.89 | sMAPE for Validation Set is: 21.92% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 22.17% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:07:51,577]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:18,483]\u001b[0m Trial 968 finished with value: 8.901254282286823 and parameters: {'n_hidden': 4, 'learning_rate': 0.0032912830584863237, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38130882120339793, 'dropout_rate_Layer_2': 0.20399939336191747, 'dropout_rate_Layer_3': 0.1344166323920188, 'dropout_rate_Layer_4': 0.1486063881060233, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004277314458999601, 'l1_Layer_2': 1.9710396044457997e-05, 'l1_Layer_3': 0.0003621834422291184, 'l1_Layer_4': 4.995487408190133e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 185, 'n_units_Layer_3': 225, 'n_units_Layer_4': 170}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.90 | sMAPE for Validation Set is: 24.30% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 25.29% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:08:21,618]\u001b[0m Trial 974 finished with value: 7.8438106248223916 and parameters: {'n_hidden': 4, 'learning_rate': 0.00610605190991406, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38310051302989045, 'dropout_rate_Layer_2': 0.008399634962239671, 'dropout_rate_Layer_3': 0.1775929056217518, 'dropout_rate_Layer_4': 0.09796517583125747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013337098006398864, 'l1_Layer_2': 1.565146981241133e-05, 'l1_Layer_3': 0.08542402002343526, 'l1_Layer_4': 1.0058713512875293e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 120, 'n_units_Layer_3': 155, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.84 | sMAPE for Validation Set is: 21.63% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:08:27,615]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:31,569]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:39,810]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:43,081]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:46,155]\u001b[0m Trial 972 finished with value: 8.486122346789866 and parameters: {'n_hidden': 4, 'learning_rate': 0.003378964168613351, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38150941403421246, 'dropout_rate_Layer_2': 0.20049247897939357, 'dropout_rate_Layer_3': 0.07730877826514933, 'dropout_rate_Layer_4': 0.14925987866086868, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004291930320026903, 'l1_Layer_2': 1.870878023796408e-05, 'l1_Layer_3': 0.0010746754631128811, 'l1_Layer_4': 5.214816305728907e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 180, 'n_units_Layer_3': 205, 'n_units_Layer_4': 285}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:08:46,793]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:52,051]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:08:59,803]\u001b[0m Trial 978 finished with value: 8.144186292346738 and parameters: {'n_hidden': 4, 'learning_rate': 0.005270001707333448, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36712263281760504, 'dropout_rate_Layer_2': 0.00013050948461678985, 'dropout_rate_Layer_3': 0.18955630003299212, 'dropout_rate_Layer_4': 0.08434758070664085, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012261605500421388, 'l1_Layer_2': 4.015176144954687e-05, 'l1_Layer_3': 0.08303857847856662, 'l1_Layer_4': 1.239119230364839e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 120, 'n_units_Layer_3': 155, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.14 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 23.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:03,252]\u001b[0m Trial 952 finished with value: 8.91353037617948 and parameters: {'n_hidden': 4, 'learning_rate': 0.0024246225094328834, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38077505787759136, 'dropout_rate_Layer_2': 0.2044743181810172, 'dropout_rate_Layer_3': 0.11844402201392182, 'dropout_rate_Layer_4': 0.050716766873535685, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004012595706850826, 'l1_Layer_2': 2.040332013020945e-05, 'l1_Layer_3': 0.0009631353345338593, 'l1_Layer_4': 0.00017573500486525422, 'n_units_Layer_1': 120, 'n_units_Layer_2': 185, 'n_units_Layer_3': 215, 'n_units_Layer_4': 300}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.91 | sMAPE for Validation Set is: 23.55% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 23.11% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:08,315]\u001b[0m Trial 983 finished with value: 7.027788960125705 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009955596682789164, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24845476332798977, 'dropout_rate_Layer_2': 0.12690163798491583, 'dropout_rate_Layer_3': 0.236858987372656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015226575745867584, 'l1_Layer_2': 1.789690432127676e-05, 'l1_Layer_3': 2.6053071843608536e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.03 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:09,229]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:16,298]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:16,707]\u001b[0m Trial 982 finished with value: 8.054563569418766 and parameters: {'n_hidden': 4, 'learning_rate': 0.005834642526557196, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38230328364637944, 'dropout_rate_Layer_2': 2.313542732118633e-05, 'dropout_rate_Layer_3': 0.186266264375918, 'dropout_rate_Layer_4': 0.10340815477033827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0012123509390734198, 'l1_Layer_2': 5.608167464651548e-05, 'l1_Layer_3': 0.07162496521004477, 'l1_Layer_4': 1.019086483500843e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 120, 'n_units_Layer_3': 140, 'n_units_Layer_4': 135}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.05 | sMAPE for Validation Set is: 22.47% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:21,945]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.96 | sMAPE for Validation Set is: 21.90% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:24,221]\u001b[0m Trial 984 finished with value: 7.963538850387159 and parameters: {'n_hidden': 4, 'learning_rate': 0.004538776301694686, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37810392387671365, 'dropout_rate_Layer_2': 0.01312609724426456, 'dropout_rate_Layer_3': 0.1936752079041646, 'dropout_rate_Layer_4': 0.07048669989225692, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0008928788235678559, 'l1_Layer_2': 2.686920483746065e-05, 'l1_Layer_3': 0.06871198615461221, 'l1_Layer_4': 1.4139513857704246e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 105, 'n_units_Layer_3': 155, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:26,911]\u001b[0m Trial 986 finished with value: 7.229499965449153 and parameters: {'n_hidden': 3, 'learning_rate': 0.001004388492759224, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24639991022043337, 'dropout_rate_Layer_2': 0.12982534939818494, 'dropout_rate_Layer_3': 0.2324051581068248, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015763690137706414, 'l1_Layer_2': 1.0012679676709601e-05, 'l1_Layer_3': 2.6150718965712017e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 230, 'n_units_Layer_3': 245}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.23 | sMAPE for Validation Set is: 20.29% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 23.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:27,383]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:35,188]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:35,517]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:40,077]\u001b[0m Trial 989 finished with value: 8.103666789223139 and parameters: {'n_hidden': 4, 'learning_rate': 0.005562221725387878, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3865946597318865, 'dropout_rate_Layer_2': 0.008328312351466815, 'dropout_rate_Layer_3': 0.18283818068968177, 'dropout_rate_Layer_4': 0.08197723565821305, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0016619056664343085, 'l1_Layer_2': 3.360170369878151e-05, 'l1_Layer_3': 0.059722364973033716, 'l1_Layer_4': 1.3115403086765815e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 125}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.10 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 22.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:41,383]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:44,210]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:45,264]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:50,354]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:52,374]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:53,781]\u001b[0m Trial 991 finished with value: 7.9728590919587985 and parameters: {'n_hidden': 4, 'learning_rate': 0.005484585516590805, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3891033968600863, 'dropout_rate_Layer_2': 1.2212295539043485e-05, 'dropout_rate_Layer_3': 0.19818120180944218, 'dropout_rate_Layer_4': 0.0691465982264368, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0007445723266879453, 'l1_Layer_2': 3.340924514640537e-05, 'l1_Layer_3': 0.060643951096776554, 'l1_Layer_4': 1.3837564659867217e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 110, 'n_units_Layer_3': 150, 'n_units_Layer_4': 125}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.97 | sMAPE for Validation Set is: 22.01% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 21.75% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:09:57,872]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:58,115]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:58,831]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:09:58,855]\u001b[0m Trial 997 finished with value: 7.038300670114393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008119699844960147, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2761028469014712, 'dropout_rate_Layer_2': 0.18829788728895933, 'dropout_rate_Layer_3': 0.20934247809936402, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027814030386923063, 'l1_Layer_2': 1.789459719102991e-05, 'l1_Layer_3': 1.592076824679859e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 23.96% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:10:06,602]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:07,234]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:12,385]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:13,556]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:18,602]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:22,236]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:24,427]\u001b[0m Trial 1007 finished with value: 7.171664666892819 and parameters: {'n_hidden': 3, 'learning_rate': 0.00078915060946954, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2754640999245965, 'dropout_rate_Layer_2': 0.1764405564392657, 'dropout_rate_Layer_3': 0.2590726369183504, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027676750684582077, 'l1_Layer_2': 1.690367379824147e-05, 'l1_Layer_3': 1.8427918475232646e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 205}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.17 | sMAPE for Validation Set is: 20.17% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 23.47% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:10:26,433]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:26,670]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:32,619]\u001b[0m Trial 1010 finished with value: 6.823816487313537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007616916300487933, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2764056914598847, 'dropout_rate_Layer_2': 0.18821381773414986, 'dropout_rate_Layer_3': 0.2543276895915256, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027941377090023726, 'l1_Layer_2': 1.8411560644246957e-05, 'l1_Layer_3': 1.6166822946969245e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 240, 'n_units_Layer_3': 210}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 19.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:10:33,561]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:34,506]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:39,115]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:40,687]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:42,463]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:44,388]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:49,941]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:50,951]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:10:55,701]\u001b[0m Trial 1013 finished with value: 8.683935439759793 and parameters: {'n_hidden': 4, 'learning_rate': 0.003403696866342991, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36813495029872917, 'dropout_rate_Layer_2': 0.21177640939860276, 'dropout_rate_Layer_3': 0.051383638245664234, 'dropout_rate_Layer_4': 0.03129573385578282, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0031087642745699774, 'l1_Layer_2': 2.9827533183539316e-05, 'l1_Layer_3': 0.0002179435507563825, 'l1_Layer_4': 6.651521797232085e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 200, 'n_units_Layer_3': 225, 'n_units_Layer_4': 165}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.68 | sMAPE for Validation Set is: 23.73% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 23.86% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:10:57,100]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:01,447]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:03,256]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:04,412]\u001b[0m Trial 1022 finished with value: 7.010464097904475 and parameters: {'n_hidden': 3, 'learning_rate': 0.001115857489113524, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29344172937460233, 'dropout_rate_Layer_2': 0.19035492425350564, 'dropout_rate_Layer_3': 0.25401582925669053, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.8204697856827176e-05, 'l1_Layer_2': 1.8925299853110257e-05, 'l1_Layer_3': 1.5165810860182692e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 240, 'n_units_Layer_3': 185}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.76% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:11:08,607]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:10,491]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:11,017]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:23,248]\u001b[0m Trial 1030 finished with value: 7.0131525749825565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011154191068265147, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3028984557758176, 'dropout_rate_Layer_2': 0.18860724574224513, 'dropout_rate_Layer_3': 0.2547596520745607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.034069192810117e-05, 'l1_Layer_2': 1.9054149833083495e-05, 'l1_Layer_3': 1.487142523442129e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 23.18% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:11:33,614]\u001b[0m Trial 1024 finished with value: 8.674360651596965 and parameters: {'n_hidden': 4, 'learning_rate': 0.003488163593728522, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3610850277382805, 'dropout_rate_Layer_2': 0.20872045463971972, 'dropout_rate_Layer_3': 0.05068444313533646, 'dropout_rate_Layer_4': 0.030614646225569073, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004674176799021234, 'l1_Layer_2': 2.98748766159006e-05, 'l1_Layer_3': 0.0009118760770238553, 'l1_Layer_4': 7.332935060761397e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 200, 'n_units_Layer_3': 220, 'n_units_Layer_4': 290}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.67 | sMAPE for Validation Set is: 23.60% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 22.74% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:11:38,074]\u001b[0m Trial 1031 finished with value: 6.91081735197302 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006172749769641397, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1196254271496759, 'dropout_rate_Layer_2': 0.004031966060739089, 'dropout_rate_Layer_3': 0.0239865894913286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010413014425985651, 'l1_Layer_2': 2.200593530622289e-05, 'l1_Layer_3': 7.719466008583215e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 19.12% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 21.59% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:11:43,214]\u001b[0m Trial 1033 finished with value: 8.02345083371665 and parameters: {'n_hidden': 4, 'learning_rate': 0.004338438729618486, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38688032442846615, 'dropout_rate_Layer_2': 0.014870126288180203, 'dropout_rate_Layer_3': 0.18662565359594774, 'dropout_rate_Layer_4': 0.10259620515705495, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009573750310813286, 'l1_Layer_2': 2.509996705679869e-05, 'l1_Layer_3': 0.07395299759974941, 'l1_Layer_4': 1.373820758910741e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 155, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.02 | sMAPE for Validation Set is: 22.30% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 23.37% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:11:44,142]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:48,309]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:52,014]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:11:55,856]\u001b[0m Trial 1034 finished with value: 8.171800121111133 and parameters: {'n_hidden': 4, 'learning_rate': 0.004278907917964433, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3767659629072521, 'dropout_rate_Layer_2': 0.017244622243580508, 'dropout_rate_Layer_3': 0.18736789658531164, 'dropout_rate_Layer_4': 0.10218590364886908, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009064785142431092, 'l1_Layer_2': 2.7030994262742782e-05, 'l1_Layer_3': 0.07562738366502608, 'l1_Layer_4': 1.3001354688931657e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 125, 'n_units_Layer_3': 135, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.17 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:11:56,492]\u001b[0m Trial 1032 finished with value: 7.97425359041456 and parameters: {'n_hidden': 4, 'learning_rate': 0.004326556713449051, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.386919876666327, 'dropout_rate_Layer_2': 0.01639641999786179, 'dropout_rate_Layer_3': 0.18589775700239924, 'dropout_rate_Layer_4': 0.10353315842918981, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009722887985637312, 'l1_Layer_2': 2.801671791726984e-05, 'l1_Layer_3': 0.09717053424555734, 'l1_Layer_4': 1.3525290798464344e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 135, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.97 | sMAPE for Validation Set is: 22.16% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 21.55% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:12:06,047]\u001b[0m Trial 1039 finished with value: 6.960164338965576 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011022349993077805, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30192294395236624, 'dropout_rate_Layer_2': 0.08920476265425861, 'dropout_rate_Layer_3': 0.22372778604544374, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8463085042392536e-05, 'l1_Layer_2': 1.8473113184806892e-05, 'l1_Layer_3': 1.4818282672506441e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 240, 'n_units_Layer_3': 180}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 22.99% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:12:10,261]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:13,729]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:17,258]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:24,166]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:26,080]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:28,738]\u001b[0m Trial 1038 finished with value: 8.854664675328097 and parameters: {'n_hidden': 4, 'learning_rate': 0.003265625358406792, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36150338638095464, 'dropout_rate_Layer_2': 0.2566475555612404, 'dropout_rate_Layer_3': 0.04497942382622988, 'dropout_rate_Layer_4': 0.004115161518200461, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.008517520788142632, 'l1_Layer_2': 5.460113734449764e-05, 'l1_Layer_3': 0.0002166842261550222, 'l1_Layer_4': 7.125431667904603e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 205, 'n_units_Layer_3': 180, 'n_units_Layer_4': 165}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.85 | sMAPE for Validation Set is: 24.10% | rMAE for Validation Set is: 0.77\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 22.99% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:12:29,557]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:36,635]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:47,464]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:50,582]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:53,413]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:55,292]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:12:59,996]\u001b[0m Trial 1050 finished with value: 7.9555576914182575 and parameters: {'n_hidden': 4, 'learning_rate': 0.005294413214052729, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36578550132817944, 'dropout_rate_Layer_2': 0.008144782011160947, 'dropout_rate_Layer_3': 0.18193049708974832, 'dropout_rate_Layer_4': 0.10718321678735637, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009999023881984424, 'l1_Layer_2': 3.210144868785165e-05, 'l1_Layer_3': 0.07129018039212613, 'l1_Layer_4': 1.2015179842064256e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.96 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 22.54% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:13:04,179]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:04,748]\u001b[0m Trial 1051 finished with value: 7.875938937615193 and parameters: {'n_hidden': 4, 'learning_rate': 0.0053408062540111975, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.365173316355198, 'dropout_rate_Layer_2': 0.010497818463009675, 'dropout_rate_Layer_3': 0.20817282369312598, 'dropout_rate_Layer_4': 0.10665857342395745, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0009812348965250904, 'l1_Layer_2': 1.0320974249199741e-05, 'l1_Layer_3': 0.07110595030161553, 'l1_Layer_4': 1.1949514212911255e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 135}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.88 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:13:10,359]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:10,436]\u001b[0m Trial 1053 finished with value: 7.156697230868777 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012093162563825506, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32509271680734714, 'dropout_rate_Layer_2': 0.13041843947765294, 'dropout_rate_Layer_3': 0.2601110785974399, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.932047459902537e-05, 'l1_Layer_2': 1.7636347202851168e-05, 'l1_Layer_3': 1.9728170294854707e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 225, 'n_units_Layer_3': 190}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 22.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:13:24,642]\u001b[0m Trial 1058 finished with value: 6.891158735595325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010662671853352678, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29761392262664604, 'dropout_rate_Layer_2': 0.0637703749442722, 'dropout_rate_Layer_3': 0.23778141661209637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.040951568634396e-05, 'l1_Layer_2': 1.8892224486865974e-05, 'l1_Layer_3': 1.415939236059952e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 215, 'n_units_Layer_3': 165}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 23.60% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:13:26,168]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:29,421]\u001b[0m Trial 1057 finished with value: 7.809244748042338 and parameters: {'n_hidden': 4, 'learning_rate': 0.004799688325992746, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3582278980127926, 'dropout_rate_Layer_2': 0.018213500381671056, 'dropout_rate_Layer_3': 0.2063997396353651, 'dropout_rate_Layer_4': 0.11633905969422101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0007638915206360741, 'l1_Layer_2': 1.3832064883206368e-05, 'l1_Layer_3': 0.07252219833905761, 'l1_Layer_4': 1.1570399382463129e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 135}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.81 | sMAPE for Validation Set is: 21.73% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 22.85% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:13:29,696]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:30,565]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:37,806]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:38,208]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.65 | sMAPE for Validation Set is: 21.21% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 21.83% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:13:41,685]\u001b[0m Trial 1054 finished with value: 7.650548488482749 and parameters: {'n_hidden': 4, 'learning_rate': 0.005366767842898144, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.36569208026406413, 'dropout_rate_Layer_2': 0.008726376495382313, 'dropout_rate_Layer_3': 0.18116536973694622, 'dropout_rate_Layer_4': 0.10590087499066525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010119360723697419, 'l1_Layer_2': 2.9931405471480927e-05, 'l1_Layer_3': 0.07179701517574599, 'l1_Layer_4': 1.2559721615872252e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140, 'n_units_Layer_4': 135}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:44,981]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:49,118]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:13:52,705]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:02,612]\u001b[0m Trial 1065 finished with value: 8.037605195676063 and parameters: {'n_hidden': 4, 'learning_rate': 0.004928089894271824, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3585137351804528, 'dropout_rate_Layer_2': 0.01740865127496465, 'dropout_rate_Layer_3': 0.22371384141447234, 'dropout_rate_Layer_4': 0.11998129948374131, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0006338205395042371, 'l1_Layer_2': 1.1291512472145065e-05, 'l1_Layer_3': 0.08452509360552586, 'l1_Layer_4': 1.6429222435638903e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135, 'n_units_Layer_4': 145}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.04 | sMAPE for Validation Set is: 22.47% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 23.19% | rMAE for Test Set is: 0.66\n",
      "MAE for Validation Set is: 6.92 | sMAPE for Validation Set is: 19.31% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 22.21% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:14:04,804]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:04,821]\u001b[0m Trial 1064 finished with value: 6.9234066766658655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005011970867711496, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10736354497652954, 'dropout_rate_Layer_2': 0.017260560193836576, 'dropout_rate_Layer_3': 0.03513271037286155, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007962194720783847, 'l1_Layer_2': 2.6060156600333112e-05, 'l1_Layer_3': 7.606795030785398e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 125, 'n_units_Layer_3': 265}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:10,287]\u001b[0m Trial 1068 finished with value: 8.014650961482547 and parameters: {'n_hidden': 4, 'learning_rate': 0.004795154736973183, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3553627244022795, 'dropout_rate_Layer_2': 0.019480191018756816, 'dropout_rate_Layer_3': 0.2198784481179245, 'dropout_rate_Layer_4': 0.12227232605573583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0005344035537656229, 'l1_Layer_2': 1.7026956514670095e-05, 'l1_Layer_3': 0.053491224477589264, 'l1_Layer_4': 1.5625969405404793e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135, 'n_units_Layer_4': 140}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.01 | sMAPE for Validation Set is: 22.43% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 21.53% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:14:13,060]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:17,156]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:17,203]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:22,005]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:25,528]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:28,235]\u001b[0m Trial 1075 finished with value: 7.054754730887031 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010360196355471947, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31612211329024414, 'dropout_rate_Layer_2': 0.04723119676906119, 'dropout_rate_Layer_3': 0.25214410916350827, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0822762711214266e-05, 'l1_Layer_2': 1.2371753214271128e-05, 'l1_Layer_3': 2.564208565482593e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.05 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:14:31,766]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:34,382]\u001b[0m Trial 1076 finished with value: 7.193716188842081 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010723701092727343, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31805268593333746, 'dropout_rate_Layer_2': 0.05653459160661949, 'dropout_rate_Layer_3': 0.2796061353301347, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2277786958545645e-05, 'l1_Layer_2': 1.2297073614755299e-05, 'l1_Layer_3': 1.5474014791233442e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 205, 'n_units_Layer_3': 170}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.06 | sMAPE for Test Set is: 23.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:14:38,649]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:42,227]\u001b[0m Trial 1078 finished with value: 7.086153234596082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011331652131255682, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3236787389996354, 'dropout_rate_Layer_2': 0.05785166216589133, 'dropout_rate_Layer_3': 0.29258397428983574, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3562674235941884e-05, 'l1_Layer_2': 1.220466629801731e-05, 'l1_Layer_3': 1.5825778414706325e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 220, 'n_units_Layer_3': 170}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 22.58% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:14:43,318]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:47,392]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:48,236]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:53,262]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:14:57,134]\u001b[0m Trial 1081 finished with value: 7.9163815342780595 and parameters: {'n_hidden': 4, 'learning_rate': 0.003334840503837538, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3736437935660456, 'dropout_rate_Layer_2': 0.012575145323070061, 'dropout_rate_Layer_3': 0.21894688214758767, 'dropout_rate_Layer_4': 0.09509129814675568, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0010626131321459756, 'l1_Layer_2': 2.927166046249004e-05, 'l1_Layer_3': 0.07060418847634295, 'l1_Layer_4': 1.9462802464839767e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 100, 'n_units_Layer_3': 135, 'n_units_Layer_4': 150}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 21.86% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 22.13% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:15:00,004]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:02,230]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:04,359]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:06,944]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:10,400]\u001b[0m Trial 1079 finished with value: 8.244992812288096 and parameters: {'n_hidden': 4, 'learning_rate': 0.0034114320572711685, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3280707115506776, 'dropout_rate_Layer_2': 0.23392719618456137, 'dropout_rate_Layer_3': 0.049990282676599204, 'dropout_rate_Layer_4': 0.03497451741768037, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00485416087786725, 'l1_Layer_2': 3.1460976257430026e-05, 'l1_Layer_3': 0.00044726797155960116, 'l1_Layer_4': 5.816601274864284e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 170, 'n_units_Layer_4': 285}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.24 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 23.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:15:18,228]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:21,251]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:24,965]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:28,426]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:31,734]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:32,313]\u001b[0m Trial 1094 finished with value: 8.061492061519534 and parameters: {'n_hidden': 4, 'learning_rate': 0.003390276260470396, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3672822058237685, 'dropout_rate_Layer_2': 0.0005643315970390826, 'dropout_rate_Layer_3': 0.16090911919531814, 'dropout_rate_Layer_4': 0.09811371939713882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.001101692254066928, 'l1_Layer_2': 3.6376962752093094e-05, 'l1_Layer_3': 0.07850874693425333, 'l1_Layer_4': 1.0031576062446069e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 145, 'n_units_Layer_4': 130}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.06 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:15:33,080]\u001b[0m Trial 1095 finished with value: 6.894467349098076 and parameters: {'n_hidden': 3, 'learning_rate': 0.000830900804837926, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28185536927380156, 'dropout_rate_Layer_2': 0.08548448486488444, 'dropout_rate_Layer_3': 0.22239103839264968, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.662924995869017e-05, 'l1_Layer_2': 1.6689435172663335e-05, 'l1_Layer_3': 1.9626761428730527e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 240, 'n_units_Layer_3': 185}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:15:39,422]\u001b[0m Trial 1092 finished with value: 9.542895128802435 and parameters: {'n_hidden': 4, 'learning_rate': 0.003977817974808971, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3294791997040404, 'dropout_rate_Layer_2': 0.23338297574476757, 'dropout_rate_Layer_3': 0.05280034767487615, 'dropout_rate_Layer_4': 0.0335383354910815, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004889498082435099, 'l1_Layer_2': 0.02923116981028044, 'l1_Layer_3': 0.0004280923331668507, 'l1_Layer_4': 5.858923227773376e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 210, 'n_units_Layer_3': 170, 'n_units_Layer_4': 140}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.54 | sMAPE for Validation Set is: 25.26% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.49 | sMAPE for Test Set is: 23.89% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:15:40,017]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:42,937]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:45,926]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:49,727]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:15:53,278]\u001b[0m Trial 1100 finished with value: 6.830657902805332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008376470942959702, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2843443208205735, 'dropout_rate_Layer_2': 0.07730185633331896, 'dropout_rate_Layer_3': 0.22164531794665104, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.042676077127636e-05, 'l1_Layer_2': 1.606893637990806e-05, 'l1_Layer_3': 2.1252566589457127e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 235, 'n_units_Layer_3': 155}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 23.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:15:58,855]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:01,651]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:03,738]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:09,375]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:10,660]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:14,912]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:17,287]\u001b[0m Trial 1102 finished with value: 7.317728016434907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006485552971771943, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10938734080036225, 'dropout_rate_Layer_2': 0.1825970005392291, 'dropout_rate_Layer_3': 0.00040212218995960966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001695708841758031, 'l1_Layer_2': 5.593197621028545e-05, 'l1_Layer_3': 0.00015973153609827556, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 260}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 20.76% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:16:19,084]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:22,438]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:23,067]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:28,543]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:29,630]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:40,276]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:43,457]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:50,574]\u001b[0m Trial 1119 finished with value: 6.982274991723968 and parameters: {'n_hidden': 3, 'learning_rate': 0.000542052360289249, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2999537049172067, 'dropout_rate_Layer_2': 0.10222197299477902, 'dropout_rate_Layer_3': 0.25140831637731603, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.688141449511608e-05, 'l1_Layer_2': 4.213787060491691e-05, 'l1_Layer_3': 1.2258962705564522e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 240, 'n_units_Layer_3': 155}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 19.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 22.59% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:16:54,026]\u001b[0m Trial 1104 finished with value: 8.447639727925456 and parameters: {'n_hidden': 4, 'learning_rate': 0.0046992365311994515, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3394411053078714, 'dropout_rate_Layer_2': 0.2610782844136454, 'dropout_rate_Layer_3': 0.013727652156559765, 'dropout_rate_Layer_4': 0.025337898151169456, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.014471460307887785, 'l1_Layer_2': 4.623913341719096e-05, 'l1_Layer_3': 0.00021063029054847672, 'l1_Layer_4': 1.4854018370551567e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 195, 'n_units_Layer_3': 180, 'n_units_Layer_4': 290}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:16:54,084]\u001b[0m Trial 1113 finished with value: 9.056675628843253 and parameters: {'n_hidden': 4, 'learning_rate': 0.003683509325621697, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3366617250620137, 'dropout_rate_Layer_2': 0.2601021277379693, 'dropout_rate_Layer_3': 0.015816041863007953, 'dropout_rate_Layer_4': 0.03596752147759418, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009814509970775745, 'l1_Layer_2': 6.012292217175749e-05, 'l1_Layer_3': 0.0005843113557420632, 'l1_Layer_4': 7.832557713869135e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 195, 'n_units_Layer_3': 185, 'n_units_Layer_4': 255}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.06 | sMAPE for Validation Set is: 24.43% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 21.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:17:02,282]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:03,170]\u001b[0m Trial 1121 finished with value: 9.670293479640614 and parameters: {'n_hidden': 4, 'learning_rate': 0.004703238974056844, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3378897734795641, 'dropout_rate_Layer_2': 0.2586983461450031, 'dropout_rate_Layer_3': 0.021118240347397135, 'dropout_rate_Layer_4': 0.031011679001903984, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.009229118763846652, 'l1_Layer_2': 0.053455721195125504, 'l1_Layer_3': 0.0006117764672454785, 'l1_Layer_4': 1.3899023538864089e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 200, 'n_units_Layer_3': 185, 'n_units_Layer_4': 280}. Best is trial 894 with value: 6.79171165416867.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.67 | sMAPE for Validation Set is: 25.58% | rMAE for Validation Set is: 0.84\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 23.24% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:17:07,616]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:12,780]\u001b[0m Trial 1122 finished with value: 6.767058851394242 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005307860787881277, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29410277509658267, 'dropout_rate_Layer_2': 0.030283262002545268, 'dropout_rate_Layer_3': 0.2236306931953843, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.483956145135259e-05, 'l1_Layer_2': 3.631457174473424e-05, 'l1_Layer_3': 1.1653210579892962e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 155}. Best is trial 1122 with value: 6.767058851394242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 18.95% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 22.16% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:17:14,993]\u001b[0m Trial 1123 finished with value: 7.095333808194863 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007254298329386189, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06832443208765906, 'dropout_rate_Layer_2': 0.0003226756427672471, 'dropout_rate_Layer_3': 0.026725049967862402, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022439189850236065, 'l1_Layer_2': 1.6582443503422506e-05, 'l1_Layer_3': 7.15056146789715e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 135, 'n_units_Layer_3': 205}. Best is trial 1122 with value: 6.767058851394242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.10 | sMAPE for Validation Set is: 19.66% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 22.27% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:17:18,314]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:18,462]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:21,781]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:25,508]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:25,793]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:26,317]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:34,847]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:35,137]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:42,279]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:42,900]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:49,922]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:53,037]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:54,536]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:17:59,985]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:03,596]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:03,959]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:05,308]\u001b[0m Trial 1138 finished with value: 8.043191587432137 and parameters: {'n_hidden': 4, 'learning_rate': 0.006388476358330322, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3724355085489079, 'dropout_rate_Layer_2': 2.392841038405995e-05, 'dropout_rate_Layer_3': 0.16370716043364733, 'dropout_rate_Layer_4': 0.11727695321260373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0010256762709179778, 'l1_Layer_2': 4.189319369680977e-05, 'l1_Layer_3': 0.0996901279402563, 'l1_Layer_4': 1.1693942153800173e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 105, 'n_units_Layer_3': 135, 'n_units_Layer_4': 125}. Best is trial 1122 with value: 6.767058851394242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.04 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 23.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:18:11,395]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:11,898]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:19,090]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:24,126]\u001b[0m Trial 1146 finished with value: 6.932853972276837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006174235584735442, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2913425695531648, 'dropout_rate_Layer_2': 0.002519098267238229, 'dropout_rate_Layer_3': 0.2656917951977439, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.342374953293891e-05, 'l1_Layer_2': 4.3758505144937405e-05, 'l1_Layer_3': 1.0104126743444714e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 1122 with value: 6.767058851394242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.93 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 23.78% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:18:27,836]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:31,120]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:32,321]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:36,047]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:38,104]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:42,711]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:43,122]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:48,427]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:18:57,206]\u001b[0m Trial 1149 finished with value: 6.874400807130992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006269822926990066, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08184394931398196, 'dropout_rate_Layer_2': 0.02282854709115866, 'dropout_rate_Layer_3': 0.031173952900995876, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035657659343162404, 'l1_Layer_2': 1.4414358167492936e-05, 'l1_Layer_3': 8.381855813259573e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 180}. Best is trial 1122 with value: 6.767058851394242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.87 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 22.13% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:19:00,346]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:02,177]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:06,656]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:09,029]\u001b[0m Trial 1156 finished with value: 7.976094768532938 and parameters: {'n_hidden': 4, 'learning_rate': 0.004853935203881991, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3983503355831853, 'dropout_rate_Layer_2': 0.015430461314760861, 'dropout_rate_Layer_3': 0.16584279129158963, 'dropout_rate_Layer_4': 0.11025435871028082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0013778334966002407, 'l1_Layer_2': 1.924318104393276e-05, 'l1_Layer_3': 0.05905246284113381, 'l1_Layer_4': 1.3485149999896778e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 120, 'n_units_Layer_3': 155, 'n_units_Layer_4': 145}. Best is trial 1122 with value: 6.767058851394242.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.98 | sMAPE for Validation Set is: 22.20% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 22.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:19:13,342]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:17,446]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:20,909]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:21,854]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:27,554]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:30,437]\u001b[0m Trial 1160 finished with value: 6.7643345503564545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006465906640275856, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33505547251087037, 'dropout_rate_Layer_2': 0.021976780064796544, 'dropout_rate_Layer_3': 0.24315928790080135, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010890361459872828, 'l1_Layer_2': 4.286585372793174e-05, 'l1_Layer_3': 1.0620521856287455e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 135}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 22.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:19:34,412]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:38,691]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.66 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:19:43,033]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:43,081]\u001b[0m Trial 1166 finished with value: 7.655303087420969 and parameters: {'n_hidden': 4, 'learning_rate': 0.005362401820103095, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09374059231661136, 'dropout_rate_Layer_2': 0.006976631967202266, 'dropout_rate_Layer_3': 0.17693694996580897, 'dropout_rate_Layer_4': 0.09403185252032038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00114018092308724, 'l1_Layer_2': 3.9879425602514395e-05, 'l1_Layer_3': 0.0835653800207294, 'l1_Layer_4': 1.4609055566942766e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 135, 'n_units_Layer_4': 110}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:43,125]\u001b[0m Trial 1167 finished with value: 7.108554308349665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007079411710906772, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2942213175956459, 'dropout_rate_Layer_2': 0.0013973458246918646, 'dropout_rate_Layer_3': 0.2642947401711811, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.362957555622065e-05, 'l1_Layer_2': 3.299345147660338e-05, 'l1_Layer_3': 3.482190636017492e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 230, 'n_units_Layer_3': 145}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:49,300]\u001b[0m Trial 1168 finished with value: 6.768205026897639 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005215140262393445, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2924021902600611, 'dropout_rate_Layer_2': 0.004896997323735915, 'dropout_rate_Layer_3': 0.26574528349506654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.593960903670644e-05, 'l1_Layer_2': 4.1794379221822496e-05, 'l1_Layer_3': 3.510118405272849e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 230, 'n_units_Layer_3': 150}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 19.17% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 22.02% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:19:53,544]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:19:53,758]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:01,016]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:03,851]\u001b[0m Trial 1175 finished with value: 7.804747724008625 and parameters: {'n_hidden': 4, 'learning_rate': 0.006227615752788088, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05997762477935617, 'dropout_rate_Layer_2': 0.008168859166643736, 'dropout_rate_Layer_3': 0.172205432289365, 'dropout_rate_Layer_4': 0.08176044183083582, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019482169126415264, 'l1_Layer_2': 4.91571436485831e-05, 'l1_Layer_3': 0.000156731895003186, 'l1_Layer_4': 2.16330620785849e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140, 'n_units_Layer_4': 100}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.80 | sMAPE for Validation Set is: 21.09% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 22.14% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:06,418]\u001b[0m Trial 1173 finished with value: 6.817056331791008 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005755913305012087, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3344496526140454, 'dropout_rate_Layer_2': 0.019242857509234327, 'dropout_rate_Layer_3': 0.22092803191959273, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.524517578039386e-05, 'l1_Layer_2': 8.09426029428813e-05, 'l1_Layer_3': 1.1899261741926462e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 19.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 22.87% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:24,253]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:27,390]\u001b[0m Trial 1176 finished with value: 8.473759812518427 and parameters: {'n_hidden': 4, 'learning_rate': 0.004182062879973989, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3634421177757398, 'dropout_rate_Layer_2': 0.25131655783742446, 'dropout_rate_Layer_3': 0.0439569656395301, 'dropout_rate_Layer_4': 0.008156818536289905, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005064249987172724, 'l1_Layer_2': 6.729245414685718e-05, 'l1_Layer_3': 0.00019623207707182225, 'l1_Layer_4': 1.807013347676701e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 230, 'n_units_Layer_3': 180, 'n_units_Layer_4': 295}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.47 | sMAPE for Validation Set is: 23.09% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 23.39% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:27,692]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:28,531]\u001b[0m Trial 1179 finished with value: 6.773185057829878 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005076400803386713, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27980782194034226, 'dropout_rate_Layer_2': 0.012768365665938333, 'dropout_rate_Layer_3': 0.2719281525039281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.394706357202674e-05, 'l1_Layer_2': 5.4729872202046e-05, 'l1_Layer_3': 2.1894882601789177e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 18.96% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 22.47% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:34,807]\u001b[0m Trial 1178 finished with value: 8.518023355744182 and parameters: {'n_hidden': 4, 'learning_rate': 0.004140630305501828, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32815485967327374, 'dropout_rate_Layer_2': 0.25208834477812725, 'dropout_rate_Layer_3': 0.046724170397185356, 'dropout_rate_Layer_4': 0.006859084645487266, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005339519336280745, 'l1_Layer_2': 3.521939838698458e-05, 'l1_Layer_3': 0.00019266580752924325, 'l1_Layer_4': 1.9350509441901644e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 225, 'n_units_Layer_3': 175, 'n_units_Layer_4': 285}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.52 | sMAPE for Validation Set is: 23.17% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 23.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:35,181]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:43,206]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:50,168]\u001b[0m Trial 1183 finished with value: 9.499128033106997 and parameters: {'n_hidden': 4, 'learning_rate': 0.006360472762156693, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32661853376437744, 'dropout_rate_Layer_2': 0.269355222393322, 'dropout_rate_Layer_3': 0.073998517956666, 'dropout_rate_Layer_4': 0.02330058065541396, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003367151307326576, 'l1_Layer_2': 6.498403441715531e-05, 'l1_Layer_3': 0.0022333462770411025, 'l1_Layer_4': 3.741894705689438e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 145, 'n_units_Layer_4': 290}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.50 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 23.65% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:53,917]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:57,004]\u001b[0m Trial 1182 finished with value: 6.852318043788128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005014208449867853, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33725088996115793, 'dropout_rate_Layer_2': 0.014989346476407055, 'dropout_rate_Layer_3': 0.2680569433924271, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.233724768623728e-05, 'l1_Layer_2': 6.601945038859601e-05, 'l1_Layer_3': 2.1380415160295494e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:57,031]\u001b[0m Trial 1187 finished with value: 7.381948948335769 and parameters: {'n_hidden': 4, 'learning_rate': 0.006780049515609975, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08292227723447959, 'dropout_rate_Layer_2': 0.022036577112823166, 'dropout_rate_Layer_3': 0.1709889922730075, 'dropout_rate_Layer_4': 0.09542173761321716, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020833512178044153, 'l1_Layer_2': 4.3886873979846386e-05, 'l1_Layer_3': 0.00015232106923546157, 'l1_Layer_4': 2.397198663171075e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140, 'n_units_Layer_4': 95}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.38 | sMAPE for Validation Set is: 20.63% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 23.54% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 6.85 | sMAPE for Validation Set is: 19.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:20:57,650]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:20:58,042]\u001b[0m Trial 1186 finished with value: 7.916267613034063 and parameters: {'n_hidden': 4, 'learning_rate': 0.006686280233604474, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005389688706352334, 'dropout_rate_Layer_2': 0.01898871481781981, 'dropout_rate_Layer_3': 0.17208271394701366, 'dropout_rate_Layer_4': 0.13164896756000483, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00176538428202082, 'l1_Layer_2': 4.0592559919990554e-05, 'l1_Layer_3': 0.07102616533994338, 'l1_Layer_4': 2.4598850002466396e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140, 'n_units_Layer_4': 150}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.92 | sMAPE for Validation Set is: 22.07% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.62% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:21:05,810]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:08,758]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:09,377]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:09,845]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:14,327]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:17,287]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:18,431]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:30,796]\u001b[0m Trial 1193 finished with value: 7.2920275660841485 and parameters: {'n_hidden': 4, 'learning_rate': 0.0070534871668689195, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0831481361507923, 'dropout_rate_Layer_2': 0.02016353283684811, 'dropout_rate_Layer_3': 0.15875321672709292, 'dropout_rate_Layer_4': 0.09619102800548208, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0025370787279213962, 'l1_Layer_2': 5.206643573775947e-05, 'l1_Layer_3': 0.0002019112361902161, 'l1_Layer_4': 2.611639673286781e-05, 'n_units_Layer_1': 125, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 85}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 20.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 21.66% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:21:33,027]\u001b[0m Trial 1199 finished with value: 7.291431002360343 and parameters: {'n_hidden': 4, 'learning_rate': 0.0073337790686920715, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0009059170816918816, 'dropout_rate_Layer_2': 0.015612664432371096, 'dropout_rate_Layer_3': 0.1596780498114022, 'dropout_rate_Layer_4': 0.0875889928017655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002533720660705919, 'l1_Layer_2': 7.008945931196258e-05, 'l1_Layer_3': 0.0002670734410266173, 'l1_Layer_4': 2.1146058027550173e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 95, 'n_units_Layer_3': 140, 'n_units_Layer_4': 95}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 20.29% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:21:36,432]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:39,156]\u001b[0m Trial 1198 finished with value: 7.175460080372887 and parameters: {'n_hidden': 4, 'learning_rate': 0.007401772907456237, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03008032493290778, 'dropout_rate_Layer_2': 0.01704043026439259, 'dropout_rate_Layer_3': 0.1635811535743299, 'dropout_rate_Layer_4': 0.09076068994002257, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002352271471650967, 'l1_Layer_2': 6.239024910329915e-05, 'l1_Layer_3': 0.00011120971453872219, 'l1_Layer_4': 2.329635895497133e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140, 'n_units_Layer_4': 100}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.18 | sMAPE for Validation Set is: 19.95% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 21.84% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:21:40,507]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:45,762]\u001b[0m Trial 1201 finished with value: 16.09035413576904 and parameters: {'n_hidden': 4, 'learning_rate': 0.004135608921559489, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31538538070766275, 'dropout_rate_Layer_2': 0.24866004092357616, 'dropout_rate_Layer_3': 0.0964068417506367, 'dropout_rate_Layer_4': 0.04148897806071716, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005236768360622639, 'l1_Layer_2': 1.702868056480636e-05, 'l1_Layer_3': 0.0011571582141059547, 'l1_Layer_4': 1.052350124630654e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 240, 'n_units_Layer_3': 165, 'n_units_Layer_4': 290}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.09 | sMAPE for Validation Set is: 41.40% | rMAE for Validation Set is: 1.40\n",
      "MAE for Test Set is: 10.38 | sMAPE for Test Set is: 31.31% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:21:53,526]\u001b[0m Trial 1200 finished with value: 7.011267791946924 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007031103966008348, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3709360882340296, 'dropout_rate_Layer_2': 0.03434230318725995, 'dropout_rate_Layer_3': 0.20862541155520184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010228575146354971, 'l1_Layer_2': 6.317740709616999e-05, 'l1_Layer_3': 3.2517720488370524e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 220, 'n_units_Layer_3': 150}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 22.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:21:56,222]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:21:59,935]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:02,127]\u001b[0m Trial 1204 finished with value: 7.5252103345997945 and parameters: {'n_hidden': 4, 'learning_rate': 0.008215697407584023, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0020143780355500575, 'dropout_rate_Layer_2': 0.02398450306504049, 'dropout_rate_Layer_3': 0.15272249864772552, 'dropout_rate_Layer_4': 0.08209318193337584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002566050623679812, 'l1_Layer_2': 6.962456861818561e-05, 'l1_Layer_3': 0.0001175456393249409, 'l1_Layer_4': 2.573844605429594e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.53 | sMAPE for Validation Set is: 21.30% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 21.52% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:22:09,196]\u001b[0m Trial 1205 finished with value: 7.399100939510478 and parameters: {'n_hidden': 4, 'learning_rate': 0.008095409473836898, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009888719661268218, 'dropout_rate_Layer_2': 0.02423043441431659, 'dropout_rate_Layer_3': 0.15837526935228444, 'dropout_rate_Layer_4': 0.0795410827562736, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003735768550003633, 'l1_Layer_2': 5.993097667410649e-05, 'l1_Layer_3': 0.00021575711938928743, 'l1_Layer_4': 2.6088719815383285e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.40 | sMAPE for Validation Set is: 20.64% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:22:12,476]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:15,148]\u001b[0m Trial 1208 finished with value: 7.607163089654743 and parameters: {'n_hidden': 4, 'learning_rate': 0.00827178318216154, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006479224020625256, 'dropout_rate_Layer_2': 0.0260007058130862, 'dropout_rate_Layer_3': 0.15086559014652817, 'dropout_rate_Layer_4': 0.08774792171283882, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002069380488674708, 'l1_Layer_2': 7.875863129268282e-05, 'l1_Layer_3': 0.00015269213713322026, 'l1_Layer_4': 2.405112173622177e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 85}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.61 | sMAPE for Validation Set is: 21.31% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 22.22% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:22:19,349]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:23,355]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:29,603]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:33,751]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:41,024]\u001b[0m Trial 1213 finished with value: 7.577457334517157 and parameters: {'n_hidden': 4, 'learning_rate': 0.008820994385935196, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022976474374594165, 'dropout_rate_Layer_2': 0.026539079333095513, 'dropout_rate_Layer_3': 0.14920546051144276, 'dropout_rate_Layer_4': 0.07683242147924361, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003356627575931237, 'l1_Layer_2': 9.63112290754772e-05, 'l1_Layer_3': 0.0002506818865239913, 'l1_Layer_4': 2.6568954492860584e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.58 | sMAPE for Validation Set is: 21.23% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.35% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:22:42,294]\u001b[0m Trial 1211 finished with value: 7.2522146968640655 and parameters: {'n_hidden': 4, 'learning_rate': 0.008652367865953291, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005265730459160032, 'dropout_rate_Layer_2': 0.025284674253791134, 'dropout_rate_Layer_3': 0.1519859972932967, 'dropout_rate_Layer_4': 0.07752001509917689, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004014425593135, 'l1_Layer_2': 7.852712766673152e-05, 'l1_Layer_3': 0.000170525935066934, 'l1_Layer_4': 2.616340995987734e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.25 | sMAPE for Validation Set is: 20.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 21.92% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:22:45,562]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:49,861]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:51,607]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:56,309]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:22:56,609]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:07,394]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:11,022]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:15,462]\u001b[0m Trial 1215 finished with value: 9.527568953703236 and parameters: {'n_hidden': 4, 'learning_rate': 0.0027756377906079485, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3514243868162119, 'dropout_rate_Layer_2': 0.2831756537858427, 'dropout_rate_Layer_3': 0.00970354515939133, 'dropout_rate_Layer_4': 0.2812360445182458, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007129495489829842, 'l1_Layer_2': 4.561082513647345e-05, 'l1_Layer_3': 0.0028868313564237844, 'l1_Layer_4': 0.0007257827596750636, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:15,562]\u001b[0m Trial 1224 finished with value: 7.313414032708445 and parameters: {'n_hidden': 4, 'learning_rate': 0.008632347751458255, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01358978171082231, 'dropout_rate_Layer_2': 0.02511719660606974, 'dropout_rate_Layer_3': 0.154866862270301, 'dropout_rate_Layer_4': 0.06602144054883234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0065394562194919185, 'l1_Layer_2': 6.362965887832318e-05, 'l1_Layer_3': 0.0002865114638179428, 'l1_Layer_4': 3.7418284362091816e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.53 | sMAPE for Validation Set is: 25.82% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 23.05% | rMAE for Test Set is: 0.68\n",
      "MAE for Validation Set is: 7.31 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 23.38% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:23:21,024]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:24,030]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:27,439]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:28,209]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:32,742]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:38,547]\u001b[0m Trial 1226 finished with value: 7.387887960416535 and parameters: {'n_hidden': 4, 'learning_rate': 0.007674352849142697, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03589701210009891, 'dropout_rate_Layer_2': 0.027124751033631454, 'dropout_rate_Layer_3': 0.15573222088320046, 'dropout_rate_Layer_4': 0.08538023744262183, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024171390238177702, 'l1_Layer_2': 0.00011291754799738811, 'l1_Layer_3': 0.000247564581133972, 'l1_Layer_4': 3.5369313158689545e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 125, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.39 | sMAPE for Validation Set is: 20.62% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.39 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:23:41,325]\u001b[0m Trial 1225 finished with value: 8.47530214644455 and parameters: {'n_hidden': 4, 'learning_rate': 0.0050869847138168426, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34944762044968214, 'dropout_rate_Layer_2': 0.23080853420698166, 'dropout_rate_Layer_3': 0.009939199215263886, 'dropout_rate_Layer_4': 0.20151533751663075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00673176963065739, 'l1_Layer_2': 1.1203799161525753e-05, 'l1_Layer_3': 5.259037691789924e-05, 'l1_Layer_4': 2.2813784314031974e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 175, 'n_units_Layer_4': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.48 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 24.08% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:23:45,090]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:46,038]\u001b[0m Trial 1232 finished with value: 7.925355957177653 and parameters: {'n_hidden': 4, 'learning_rate': 0.010298771019830604, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0336007809443089, 'dropout_rate_Layer_2': 0.021522806968238963, 'dropout_rate_Layer_3': 0.15118498628197913, 'dropout_rate_Layer_4': 0.06191835185251313, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005462573530742131, 'l1_Layer_2': 6.345773225599511e-05, 'l1_Layer_3': 0.00021898821464879395, 'l1_Layer_4': 3.8364427478660536e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 125, 'n_units_Layer_4': 95}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.93 | sMAPE for Validation Set is: 22.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 23.95% | rMAE for Test Set is: 0.69\n",
      "MAE for Validation Set is: 7.68 | sMAPE for Validation Set is: 20.88% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:23:46,046]\u001b[0m Trial 1233 finished with value: 7.677088509571065 and parameters: {'n_hidden': 4, 'learning_rate': 0.01055675938893692, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0882583233535093, 'dropout_rate_Layer_2': 0.021055199083571743, 'dropout_rate_Layer_3': 0.15963703960789916, 'dropout_rate_Layer_4': 0.0621395748370749, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002432921484501524, 'l1_Layer_2': 6.231821826053762e-05, 'l1_Layer_3': 0.00016591677050386362, 'l1_Layer_4': 3.736366014551499e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130, 'n_units_Layer_4': 95}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:23:58,564]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:01,919]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:04,791]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:07,951]\u001b[0m Trial 1234 finished with value: 7.20902343752331 and parameters: {'n_hidden': 4, 'learning_rate': 0.010426796443886398, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04040989961591117, 'dropout_rate_Layer_2': 0.02302454006640156, 'dropout_rate_Layer_3': 0.1438309744148229, 'dropout_rate_Layer_4': 0.06189123737671451, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024718105054718524, 'l1_Layer_2': 7.632958132504956e-05, 'l1_Layer_3': 0.00016440085081495583, 'l1_Layer_4': 3.771033372101011e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 85, 'n_units_Layer_3': 130, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 20.00% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 22.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:24:16,586]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:19,384]\u001b[0m Trial 1236 finished with value: 10.478717148956642 and parameters: {'n_hidden': 4, 'learning_rate': 0.005782047969288927, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3426229877353469, 'dropout_rate_Layer_2': 0.2742067568548602, 'dropout_rate_Layer_3': 0.027963355770210564, 'dropout_rate_Layer_4': 0.18489898271826413, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 0.0011220283669297682, 'l1_Layer_2': 1.1002371935893673e-05, 'l1_Layer_3': 9.246160471371283e-05, 'l1_Layer_4': 2.1448979022464672e-05, 'n_units_Layer_1': 60, 'n_units_Layer_2': 265, 'n_units_Layer_3': 175, 'n_units_Layer_4': 265}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.48 | sMAPE for Validation Set is: 27.69% | rMAE for Validation Set is: 0.91\n",
      "MAE for Test Set is: 7.92 | sMAPE for Test Set is: 25.42% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:24:27,829]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:31,917]\u001b[0m Trial 1242 finished with value: 7.479306607132351 and parameters: {'n_hidden': 4, 'learning_rate': 0.011201569061182439, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024720602318587196, 'dropout_rate_Layer_2': 0.030411416194090775, 'dropout_rate_Layer_3': 0.1428725180009241, 'dropout_rate_Layer_4': 0.04485670548246032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024089203752863334, 'l1_Layer_2': 0.00013617234106705475, 'l1_Layer_3': 0.0002323740210205117, 'l1_Layer_4': 4.261711694441159e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.48 | sMAPE for Validation Set is: 21.10% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 23.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:24:32,441]\u001b[0m Trial 1240 finished with value: 7.318971481399831 and parameters: {'n_hidden': 4, 'learning_rate': 0.007557032361883118, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06918669649065386, 'dropout_rate_Layer_2': 0.027347858115743414, 'dropout_rate_Layer_3': 0.14365191534071564, 'dropout_rate_Layer_4': 0.08314250224952668, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0024379600322145113, 'l1_Layer_2': 0.00013515566414347294, 'l1_Layer_3': 0.00024269384220420472, 'l1_Layer_4': 4.4598790921981644e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.32 | sMAPE for Validation Set is: 20.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 20.93% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:24:39,925]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:45,068]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:46,420]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:51,276]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:54,383]\u001b[0m Trial 1245 finished with value: 6.977361546175717 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005050497809509037, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.25642329925744717, 'dropout_rate_Layer_2': 0.035058210444821714, 'dropout_rate_Layer_3': 0.29949473736307863, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.311028075191069e-05, 'l1_Layer_2': 5.800027133229882e-05, 'l1_Layer_3': 1.1563610800821945e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 210, 'n_units_Layer_3': 130}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 19.74% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 23.25% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:24:55,069]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:24:55,536]\u001b[0m Trial 1248 finished with value: 7.6391258961927955 and parameters: {'n_hidden': 4, 'learning_rate': 0.011521400372606586, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08056672201446799, 'dropout_rate_Layer_2': 0.03115789775340483, 'dropout_rate_Layer_3': 0.13845896689622317, 'dropout_rate_Layer_4': 0.04338494609624531, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007468219328576172, 'l1_Layer_2': 0.0001469168254294341, 'l1_Layer_3': 0.00020972651103823994, 'l1_Layer_4': 5.4787004902387716e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.64 | sMAPE for Validation Set is: 21.36% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 22.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:24:56,766]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:03,269]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:03,992]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:10,512]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:13,878]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:14,946]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:19,712]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:21,051]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:26,610]\u001b[0m Trial 1257 finished with value: 6.951525956769395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006194275297955784, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3121165663330059, 'dropout_rate_Layer_2': 0.006953876723545727, 'dropout_rate_Layer_3': 0.24651133551240847, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.757014165837659e-05, 'l1_Layer_2': 0.00011140769097293777, 'l1_Layer_3': 1.0339300874786349e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 19.57% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 22.38% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:25:29,290]\u001b[0m Trial 1256 finished with value: 7.042518885071551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006400773651764348, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3113818847818336, 'dropout_rate_Layer_2': 0.007449701000174337, 'dropout_rate_Layer_3': 0.3173911192041188, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.314827229043815e-05, 'l1_Layer_2': 0.00010639181042981708, 'l1_Layer_3': 2.2981461916763542e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 225, 'n_units_Layer_3': 140}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 22.83% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:25:30,371]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:46,452]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 19.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:25:48,484]\u001b[0m Trial 1264 finished with value: 7.121405102527619 and parameters: {'n_hidden': 4, 'learning_rate': 0.01023144448421206, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01669737659563956, 'dropout_rate_Layer_2': 0.024685157322349247, 'dropout_rate_Layer_3': 0.14030318060384625, 'dropout_rate_Layer_4': 0.05531970071865393, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002552925717688435, 'l1_Layer_2': 0.00010983982340000141, 'l1_Layer_3': 0.00020335574574927216, 'l1_Layer_4': 3.96485257693453e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:25:56,412]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:02,122]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:05,391]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:09,568]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:12,507]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:12,766]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:19,809]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:20,965]\u001b[0m Trial 1266 finished with value: 8.176288207751634 and parameters: {'n_hidden': 4, 'learning_rate': 0.004992962604312649, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3361051030225927, 'dropout_rate_Layer_2': 0.19409154110120072, 'dropout_rate_Layer_3': 0.00017194485015908922, 'dropout_rate_Layer_4': 0.06131472989798892, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005076753421516367, 'l1_Layer_2': 2.432089502001811e-05, 'l1_Layer_3': 2.051085021508647e-05, 'l1_Layer_4': 2.8476665440825587e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 185, 'n_units_Layer_4': 285}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.18 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.71\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:26:33,451]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:36,671]\u001b[0m Trial 1272 finished with value: 7.082293832384509 and parameters: {'n_hidden': 4, 'learning_rate': 0.009917948089202254, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015786281070230293, 'dropout_rate_Layer_2': 0.02630386328985361, 'dropout_rate_Layer_3': 0.14400101563673162, 'dropout_rate_Layer_4': 0.03165552037382492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003498515040713971, 'l1_Layer_2': 0.000102036185317499, 'l1_Layer_3': 0.00020434274564378873, 'l1_Layer_4': 3.674129567584908e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 85}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.08 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 21.93% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:26:39,514]\u001b[0m Trial 1262 finished with value: 8.71138193965069 and parameters: {'n_hidden': 4, 'learning_rate': 0.0042168744149537005, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3483307566213889, 'dropout_rate_Layer_2': 0.19222716468672368, 'dropout_rate_Layer_3': 0.06832923902132629, 'dropout_rate_Layer_4': 0.25608074320393187, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005078304906013086, 'l1_Layer_2': 2.2704280010066584e-05, 'l1_Layer_3': 2.172497231826996e-05, 'l1_Layer_4': 3.1271986341466774e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 190, 'n_units_Layer_3': 185, 'n_units_Layer_4': 295}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.71 | sMAPE for Validation Set is: 23.46% | rMAE for Validation Set is: 0.76\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 22.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:26:40,055]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:40,481]\u001b[0m Trial 1275 finished with value: 7.202897794675672 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005644939029345479, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3570621455820995, 'dropout_rate_Layer_2': 0.04481193234073261, 'dropout_rate_Layer_3': 0.2174902180177507, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.2071990964506834e-05, 'l1_Layer_2': 4.064418018274634e-05, 'l1_Layer_3': 1.1812950663825967e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 220, 'n_units_Layer_3': 125}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 20.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 22.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:26:47,947]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:51,749]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:56,622]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:26:57,167]\u001b[0m Trial 1277 finished with value: 7.696784553038896 and parameters: {'n_hidden': 4, 'learning_rate': 0.012338018041923682, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016177033661996555, 'dropout_rate_Layer_2': 0.03476565596913376, 'dropout_rate_Layer_3': 0.139779138540384, 'dropout_rate_Layer_4': 0.031758813880719654, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0036655954976163737, 'l1_Layer_2': 0.0001088557841036108, 'l1_Layer_3': 0.00048722952386991196, 'l1_Layer_4': 4.109194642699932e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.70 | sMAPE for Validation Set is: 21.44% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:27:03,608]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:08,384]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:08,789]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:14,492]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:16,905]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:17,757]\u001b[0m Trial 1283 finished with value: 7.0032515205615296 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008847341093136706, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09970840994495758, 'dropout_rate_Layer_2': 0.03220824268331706, 'dropout_rate_Layer_3': 0.015096470245896342, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008131239604580912, 'l1_Layer_2': 4.796439425568016e-05, 'l1_Layer_3': 5.1110671407962685e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 145, 'n_units_Layer_3': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.00 | sMAPE for Validation Set is: 19.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.34 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:27:22,726]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:26,072]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:28,650]\u001b[0m Trial 1278 finished with value: 6.982528302016455 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005650312474742906, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26660544092319444, 'dropout_rate_Layer_2': 0.045222497568917136, 'dropout_rate_Layer_3': 0.28189994891342657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.776048886290624e-05, 'l1_Layer_2': 2.9007586258596314e-05, 'l1_Layer_3': 0.0036893968870961476, 'n_units_Layer_1': 285, 'n_units_Layer_2': 250, 'n_units_Layer_3': 115}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.98 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:27:31,711]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:44,123]\u001b[0m Trial 1293 finished with value: 6.9921192874877365 and parameters: {'n_hidden': 4, 'learning_rate': 0.009991413635540224, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035273303101268264, 'dropout_rate_Layer_2': 0.02273776383725662, 'dropout_rate_Layer_3': 0.15440441510565805, 'dropout_rate_Layer_4': 0.07080318134368492, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002152183625276303, 'l1_Layer_2': 7.274422349971233e-05, 'l1_Layer_3': 0.0001722179875753458, 'l1_Layer_4': 4.019379453705058e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 19.40% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 22.04% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:27:46,363]\u001b[0m Trial 1288 finished with value: 8.486320131617552 and parameters: {'n_hidden': 4, 'learning_rate': 0.005086527422655406, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31680822996603797, 'dropout_rate_Layer_2': 0.21956956474861739, 'dropout_rate_Layer_3': 2.0020065205565707e-05, 'dropout_rate_Layer_4': 0.06324373792009265, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.005766188742250132, 'l1_Layer_2': 1.609596681879177e-05, 'l1_Layer_3': 1.3108155075638636e-05, 'l1_Layer_4': 1.743609691138242e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160, 'n_units_Layer_4': 285}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.49 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 21.74% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.37 | sMAPE for Test Set is: 24.71% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:27:48,847]\u001b[0m Trial 1289 finished with value: 7.185709944381977 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007917640912994939, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10252417529266977, 'dropout_rate_Layer_2': 0.040007678734480495, 'dropout_rate_Layer_3': 0.029721946262616972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010093165836864374, 'l1_Layer_2': 2.7054340854059674e-05, 'l1_Layer_3': 4.315238085600004e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:51,585]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:56,280]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:27:59,957]\u001b[0m Trial 1294 finished with value: 7.00510976117361 and parameters: {'n_hidden': 4, 'learning_rate': 0.007616198006879733, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026414927663351934, 'dropout_rate_Layer_2': 0.02543148756542676, 'dropout_rate_Layer_3': 0.1561765301109643, 'dropout_rate_Layer_4': 0.07077195122865912, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006664481825452083, 'l1_Layer_2': 9.5940795447453e-05, 'l1_Layer_3': 0.00023824228821788389, 'l1_Layer_4': 6.680525014778837e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 19.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 21.71% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:08,281]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:08,504]\u001b[0m Trial 1297 finished with value: 7.63328283260599 and parameters: {'n_hidden': 4, 'learning_rate': 0.011160002628892251, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02403448336622404, 'dropout_rate_Layer_2': 0.028922072305693852, 'dropout_rate_Layer_3': 0.15262947917870306, 'dropout_rate_Layer_4': 0.07140886851313454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0026298149572154712, 'l1_Layer_2': 9.942091739882175e-05, 'l1_Layer_3': 0.00023270374330253764, 'l1_Layer_4': 4.25175906584436e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 21.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 24.44% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:10,070]\u001b[0m Trial 1296 finished with value: 7.484061756517801 and parameters: {'n_hidden': 4, 'learning_rate': 0.008829968207340843, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02487838559907374, 'dropout_rate_Layer_2': 0.027161594274484044, 'dropout_rate_Layer_3': 0.15575187061022, 'dropout_rate_Layer_4': 0.05748082389760732, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0021707198488170607, 'l1_Layer_2': 0.00010009208447823402, 'l1_Layer_3': 0.0001252033450407787, 'l1_Layer_4': 4.2321077117247345e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 65}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.48 | sMAPE for Validation Set is: 20.78% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:17,532]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:19,091]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:20,058]\u001b[0m Trial 1300 finished with value: 7.328871211645435 and parameters: {'n_hidden': 4, 'learning_rate': 0.008547903829357812, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03180122938522693, 'dropout_rate_Layer_2': 0.03720053512968054, 'dropout_rate_Layer_3': 0.14304054537675992, 'dropout_rate_Layer_4': 0.05613512581265469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.007481245677263638, 'l1_Layer_2': 0.0001059052839335817, 'l1_Layer_3': 0.0004469849303310778, 'l1_Layer_4': 6.517862363134759e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 20.35% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.29 | sMAPE for Test Set is: 21.17% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:21,245]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:27,423]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:34,982]\u001b[0m Trial 1302 finished with value: 7.08914659275037 and parameters: {'n_hidden': 4, 'learning_rate': 0.00894562458465331, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034710224829467486, 'dropout_rate_Layer_2': 0.03829131859664321, 'dropout_rate_Layer_3': 0.14852885027463697, 'dropout_rate_Layer_4': 0.060469889951488956, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002669866640381719, 'l1_Layer_2': 0.0001036367482928409, 'l1_Layer_3': 8.425963788463635e-05, 'l1_Layer_4': 3.938008313758279e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.09 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 22.71% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:35,936]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:44,064]\u001b[0m Trial 1308 finished with value: 7.568729358927609 and parameters: {'n_hidden': 4, 'learning_rate': 0.007909644102199567, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019018732942517044, 'dropout_rate_Layer_2': 0.208794891308908, 'dropout_rate_Layer_3': 0.15935374288798285, 'dropout_rate_Layer_4': 0.0629699490223807, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0019956953141115823, 'l1_Layer_2': 7.500800753150339e-05, 'l1_Layer_3': 0.00043925112652342416, 'l1_Layer_4': 6.97981060113277e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.57 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 23.50% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:47,508]\u001b[0m Trial 1307 finished with value: 7.134315578026534 and parameters: {'n_hidden': 4, 'learning_rate': 0.007413177221454983, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04358957784664871, 'dropout_rate_Layer_2': 0.03667669312961748, 'dropout_rate_Layer_3': 0.14324329887841594, 'dropout_rate_Layer_4': 0.06522527684889191, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00647213484167512, 'l1_Layer_2': 7.269271421045186e-05, 'l1_Layer_3': 0.00028182802092833006, 'l1_Layer_4': 6.977765764927637e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.13 | sMAPE for Validation Set is: 19.99% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 21.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:28:51,028]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:54,558]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:28:58,746]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:01,139]\u001b[0m Trial 1310 finished with value: 7.2039268637477685 and parameters: {'n_hidden': 4, 'learning_rate': 0.007500853193167735, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05265643705506114, 'dropout_rate_Layer_2': 0.03632694569554848, 'dropout_rate_Layer_3': 0.1317632505250407, 'dropout_rate_Layer_4': 0.05735345175152071, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035876412662292096, 'l1_Layer_2': 0.00011824970127893176, 'l1_Layer_3': 0.00040245602669721734, 'l1_Layer_4': 3.224184561507091e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 125, 'n_units_Layer_4': 70}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.63 | sMAPE for Test Set is: 22.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:29:04,044]\u001b[0m Trial 1309 finished with value: 6.914984556831162 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008980793179558363, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11896292502136202, 'dropout_rate_Layer_2': 0.03366168340223237, 'dropout_rate_Layer_3': 0.012934122125614157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012079519311267173, 'l1_Layer_2': 1.2033713661821311e-05, 'l1_Layer_3': 5.5805814287985834e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 19.07% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 21.88% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:29:04,944]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:10,124]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:13,503]\u001b[0m Trial 1313 finished with value: 7.187887116111468 and parameters: {'n_hidden': 4, 'learning_rate': 0.007414085859021386, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029869699654652106, 'dropout_rate_Layer_2': 0.03862736489107603, 'dropout_rate_Layer_3': 0.14125504686066268, 'dropout_rate_Layer_4': 0.04985503280266346, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005463997573408606, 'l1_Layer_2': 6.328956273042286e-05, 'l1_Layer_3': 8.385170781112629e-05, 'l1_Layer_4': 6.319287720378116e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 70}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 20.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 23.10% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:29:17,178]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:18,207]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:19,097]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:24,338]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:29,671]\u001b[0m Trial 1318 finished with value: 7.347291981826504 and parameters: {'n_hidden': 4, 'learning_rate': 0.007509851748173921, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029118078587480997, 'dropout_rate_Layer_2': 0.03664593520575413, 'dropout_rate_Layer_3': 0.13341925396708273, 'dropout_rate_Layer_4': 0.06544374888322049, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003996335728417362, 'l1_Layer_2': 0.00016946016932978267, 'l1_Layer_3': 0.0003301880228824271, 'l1_Layer_4': 6.219865287444726e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.35 | sMAPE for Validation Set is: 20.50% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 7.26 | sMAPE for Test Set is: 24.41% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:29:36,614]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:41,111]\u001b[0m Trial 1322 finished with value: 7.451314230929763 and parameters: {'n_hidden': 4, 'learning_rate': 0.007692252177388755, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047185369223645426, 'dropout_rate_Layer_2': 0.03808588767480736, 'dropout_rate_Layer_3': 0.13944245764950783, 'dropout_rate_Layer_4': 0.04931308649998312, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00482996544087109, 'l1_Layer_2': 6.813810914285443e-05, 'l1_Layer_3': 5.1469789322862196e-05, 'l1_Layer_4': 5.288652638521869e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 90, 'n_units_Layer_3': 120, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.45 | sMAPE for Validation Set is: 20.53% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 22.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:29:41,327]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:42,582]\u001b[0m Trial 1325 finished with value: 16.22961908521599 and parameters: {'n_hidden': 4, 'learning_rate': 0.0049868707452598296, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3182131835666105, 'dropout_rate_Layer_2': 0.15321775238575908, 'dropout_rate_Layer_3': 0.003605367388676001, 'dropout_rate_Layer_4': 0.1677584465949305, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.021330390972282766, 'l1_Layer_2': 1.1712049492138278e-05, 'l1_Layer_3': 1.1247730950751725e-05, 'l1_Layer_4': 1.626111725827511e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 150, 'n_units_Layer_3': 160, 'n_units_Layer_4': 245}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 16.23 | sMAPE for Validation Set is: 41.85% | rMAE for Validation Set is: 1.42\n",
      "MAE for Test Set is: 10.49 | sMAPE for Test Set is: 31.71% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:29:47,812]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:51,707]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:54,817]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:29:59,024]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:01,891]\u001b[0m Trial 1324 finished with value: 6.900112524787294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008319355678891102, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11350228624695811, 'dropout_rate_Layer_2': 0.020755656244004505, 'dropout_rate_Layer_3': 0.08177778374455831, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013008031416706046, 'l1_Layer_2': 1.0182745175807295e-05, 'l1_Layer_3': 6.796394930029339e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 150, 'n_units_Layer_3': 275}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 19.19% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 22.15% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:30:06,128]\u001b[0m Trial 1329 finished with value: 15.24452670177268 and parameters: {'n_hidden': 4, 'learning_rate': 0.007209182335630664, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33498602239258307, 'dropout_rate_Layer_2': 0.21619180794527268, 'dropout_rate_Layer_3': 0.03554380432078101, 'dropout_rate_Layer_4': 0.09739361099385788, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011268751564506197, 'l1_Layer_2': 1.7140760102225107e-05, 'l1_Layer_3': 1.689632829613473e-05, 'l1_Layer_4': 1.205534420293062e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 140, 'n_units_Layer_4': 275}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.24 | sMAPE for Validation Set is: 38.49% | rMAE for Validation Set is: 1.33\n",
      "MAE for Test Set is: 9.76 | sMAPE for Test Set is: 28.92% | rMAE for Test Set is: 0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:30:08,932]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:13,071]\u001b[0m Trial 1331 finished with value: 15.475345310552163 and parameters: {'n_hidden': 4, 'learning_rate': 0.0067193003238221576, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3368546446011483, 'dropout_rate_Layer_2': 0.21723152220777675, 'dropout_rate_Layer_3': 0.016143832320600512, 'dropout_rate_Layer_4': 0.013993518033229787, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.011865893203008543, 'l1_Layer_2': 1.5546562124655515e-05, 'l1_Layer_3': 1.9175430691594116e-05, 'l1_Layer_4': 1.3672291628411179e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 140, 'n_units_Layer_3': 170, 'n_units_Layer_4': 275}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 15.48 | sMAPE for Validation Set is: 39.18% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 9.88 | sMAPE for Test Set is: 29.34% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:30:13,302]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:20,859]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:27,679]\u001b[0m Trial 1335 finished with value: 7.424416428361526 and parameters: {'n_hidden': 4, 'learning_rate': 0.007801237483756442, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06659886737009207, 'dropout_rate_Layer_2': 0.04345014525373746, 'dropout_rate_Layer_3': 0.14240432275669676, 'dropout_rate_Layer_4': 0.03662082096306114, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003683042214427711, 'l1_Layer_2': 8.317344463077732e-05, 'l1_Layer_3': 5.0015273504734466e-05, 'l1_Layer_4': 6.043907500308457e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 65}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.42 | sMAPE for Validation Set is: 21.00% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 23.81% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:30:30,919]\u001b[0m Trial 1333 finished with value: 7.193657237800807 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011196617047724222, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11189207593506954, 'dropout_rate_Layer_2': 0.04875193212980532, 'dropout_rate_Layer_3': 0.031414391144012066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001120900684791772, 'l1_Layer_2': 1.465366027543943e-05, 'l1_Layer_3': 7.536271713801922e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 140, 'n_units_Layer_3': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 20.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 22.29% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:30:34,977]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:41,146]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:44,464]\u001b[0m Trial 1338 finished with value: 6.837299345582447 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010766983280945336, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11602594443064387, 'dropout_rate_Layer_2': 0.012317407621995303, 'dropout_rate_Layer_3': 0.06566293934710508, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001619180095490984, 'l1_Layer_2': 1.2443315345344702e-05, 'l1_Layer_3': 3.440854196256e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.84 | sMAPE for Validation Set is: 18.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.28 | sMAPE for Test Set is: 21.31% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:30:49,717]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:53,884]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:30:53,891]\u001b[0m Trial 1340 finished with value: 7.288029086214093 and parameters: {'n_hidden': 4, 'learning_rate': 0.007243493563326765, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.047362713242891166, 'dropout_rate_Layer_2': 0.04490391501190603, 'dropout_rate_Layer_3': 0.1437710951692659, 'dropout_rate_Layer_4': 0.03168216569970809, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003448078619053424, 'l1_Layer_2': 8.032683072382815e-05, 'l1_Layer_3': 0.0004367681888598319, 'l1_Layer_4': 8.367028146862817e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 80, 'n_units_Layer_3': 125, 'n_units_Layer_4': 85}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.29 | sMAPE for Validation Set is: 20.25% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 22.49% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:31:00,276]\u001b[0m Trial 1339 finished with value: 6.882982528357519 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010792799735696954, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11333112146604597, 'dropout_rate_Layer_2': 0.010473549446075623, 'dropout_rate_Layer_3': 0.0478976820250873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001175730571433977, 'l1_Layer_2': 1.0018098715264312e-05, 'l1_Layer_3': 3.2597987177466555e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 155, 'n_units_Layer_3': 265}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 19.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.36 | sMAPE for Test Set is: 21.76% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:31:01,427]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:01,655]\u001b[0m Trial 1343 finished with value: 7.341791935189033 and parameters: {'n_hidden': 4, 'learning_rate': 0.009978093445572565, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04601396807205813, 'dropout_rate_Layer_2': 0.04886277180939272, 'dropout_rate_Layer_3': 0.1337039908801964, 'dropout_rate_Layer_4': 0.0366324495103957, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003563841715838613, 'l1_Layer_2': 8.457832459634229e-05, 'l1_Layer_3': 0.00032134200033143753, 'l1_Layer_4': 8.637751079152329e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 20.48% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 21.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:31:06,182]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:11,984]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:15,867]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:16,633]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:17,206]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:24,121]\u001b[0m Trial 1346 finished with value: 7.499472301216794 and parameters: {'n_hidden': 4, 'learning_rate': 0.0071554436451587945, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056840891896660806, 'dropout_rate_Layer_2': 0.042902415906180005, 'dropout_rate_Layer_3': 0.14408937766921376, 'dropout_rate_Layer_4': 0.015687666906939016, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004316934309977764, 'l1_Layer_2': 8.210648633798208e-05, 'l1_Layer_3': 0.00039993746920317274, 'l1_Layer_4': 8.693175814453233e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 85}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:24,150]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:24,253]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.50 | sMAPE for Validation Set is: 20.91% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 21.63% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:31:28,380]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:33,307]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:35,434]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:38,730]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:39,035]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:39,495]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:48,687]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:50,997]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:31:54,522]\u001b[0m Trial 1357 finished with value: 8.928886984131632 and parameters: {'n_hidden': 4, 'learning_rate': 0.006026008644052268, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15875562330079504, 'dropout_rate_Layer_2': 0.22803443110208216, 'dropout_rate_Layer_3': 0.024525812212593916, 'dropout_rate_Layer_4': 0.057435163352197616, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0014834793882068983, 'l1_Layer_2': 0.0037073536459782184, 'l1_Layer_3': 1.4997763210260543e-05, 'l1_Layer_4': 1.9310295538086174e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150, 'n_units_Layer_4': 285}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.93 | sMAPE for Validation Set is: 23.78% | rMAE for Validation Set is: 0.78\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 22.60% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:31:59,071]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:00,426]\u001b[0m Trial 1362 finished with value: 6.769516503413588 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007702328365863711, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27301724399511057, 'dropout_rate_Layer_2': 0.027442182978401876, 'dropout_rate_Layer_3': 0.29484037384329026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016808392396514877, 'l1_Layer_2': 3.410417780092449e-05, 'l1_Layer_3': 1.2316754717793793e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.77 | sMAPE for Validation Set is: 19.27% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 23.69% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:32:06,181]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:10,559]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:11,008]\u001b[0m Trial 1365 finished with value: 7.629224970152037 and parameters: {'n_hidden': 4, 'learning_rate': 0.009289045993362244, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03840290751059519, 'dropout_rate_Layer_2': 0.04220342065486445, 'dropout_rate_Layer_3': 0.14956209713962415, 'dropout_rate_Layer_4': 0.05362245055182482, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0052094626424101665, 'l1_Layer_2': 0.00011790862005195849, 'l1_Layer_3': 0.00021265508511863424, 'l1_Layer_4': 6.085259081024788e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 75, 'n_units_Layer_3': 120, 'n_units_Layer_4': 90}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.63 | sMAPE for Validation Set is: 21.18% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 22.42% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:32:16,949]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:21,387]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:22,177]\u001b[0m Trial 1368 finished with value: 7.495991861238882 and parameters: {'n_hidden': 4, 'learning_rate': 0.00846151671150023, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011127940940708568, 'dropout_rate_Layer_2': 0.03631819320651343, 'dropout_rate_Layer_3': 0.15864286910828101, 'dropout_rate_Layer_4': 0.062055827703696595, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035936493528647413, 'l1_Layer_2': 0.00011316220227348432, 'l1_Layer_3': 2.4311131630607986e-05, 'l1_Layer_4': 5.9830799495872834e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 75}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.50 | sMAPE for Validation Set is: 20.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 22.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:32:24,733]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:28,380]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:28,645]\u001b[0m Trial 1366 finished with value: 7.163009990039707 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009627909795762579, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10926883417088484, 'dropout_rate_Layer_2': 0.006430729679388386, 'dropout_rate_Layer_3': 0.05507545148841607, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012050524741498284, 'l1_Layer_2': 1.3528038010372756e-05, 'l1_Layer_3': 4.0820233382515034e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 165, 'n_units_Layer_3': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.16 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 21.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:32:29,527]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:32,883]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:39,218]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:41,470]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:44,883]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:48,362]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:49,695]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:51,121]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:53,026]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:58,238]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:32:59,617]\u001b[0m Trial 1380 finished with value: 6.82149476424581 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005028691909274937, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3811160879900378, 'dropout_rate_Layer_2': 0.03668655552659621, 'dropout_rate_Layer_3': 0.2714737748135467, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6776332362790847e-05, 'l1_Layer_2': 8.734903594782454e-05, 'l1_Layer_3': 1.8131172548672392e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.82 | sMAPE for Validation Set is: 19.04% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 22.82% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:33:00,649]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:00,766]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:08,066]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:23,346]\u001b[0m Trial 1392 finished with value: 6.9366658313528005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005951313799090109, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3691515208815333, 'dropout_rate_Layer_2': 0.036441330693093306, 'dropout_rate_Layer_3': 0.2976775541274231, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.5168790138206673e-05, 'l1_Layer_2': 7.37975670621115e-05, 'l1_Layer_3': 1.7411783613625522e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 220, 'n_units_Layer_3': 155}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 19.46% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 22.96% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:33:28,318]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:32,946]\u001b[0m Trial 1388 finished with value: 7.826694939760301 and parameters: {'n_hidden': 4, 'learning_rate': 0.005337407146231156, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30387496183689283, 'dropout_rate_Layer_2': 0.19736846250401416, 'dropout_rate_Layer_3': 0.0020630048275690586, 'dropout_rate_Layer_4': 0.06198306953577268, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00362494082455724, 'l1_Layer_2': 1.0074697782362143e-05, 'l1_Layer_3': 5.318092048502387e-05, 'l1_Layer_4': 2.559936073807495e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190, 'n_units_Layer_4': 300}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.83 | sMAPE for Validation Set is: 21.49% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 22.46% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:33:33,463]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:38,709]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:45,464]\u001b[0m Trial 1389 finished with value: 8.573249342243153 and parameters: {'n_hidden': 4, 'learning_rate': 0.007797351502300299, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30542720797194656, 'dropout_rate_Layer_2': 0.196532902685366, 'dropout_rate_Layer_3': 0.010977641095170554, 'dropout_rate_Layer_4': 0.060958858643059395, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0027911834261282143, 'l1_Layer_2': 0.00852718429288132, 'l1_Layer_3': 0.00017183700990485785, 'l1_Layer_4': 2.7246680793956955e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190, 'n_units_Layer_4': 265}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.57 | sMAPE for Validation Set is: 23.12% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 22.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:33:45,994]\u001b[0m Trial 1391 finished with value: 9.10266866477508 and parameters: {'n_hidden': 4, 'learning_rate': 0.003904855470413384, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30197082938569225, 'dropout_rate_Layer_2': 0.19819177791369275, 'dropout_rate_Layer_3': 0.03729530429982572, 'dropout_rate_Layer_4': 0.12325175747835071, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.001926700358068422, 'l1_Layer_2': 1.0228471359432757e-05, 'l1_Layer_3': 5.2340711462873895e-05, 'l1_Layer_4': 0.0058600453193376496, 'n_units_Layer_1': 80, 'n_units_Layer_2': 130, 'n_units_Layer_3': 190, 'n_units_Layer_4': 265}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.10 | sMAPE for Validation Set is: 24.26% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 23.03% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:33:49,982]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:33:52,884]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:01,112]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:05,320]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:09,729]\u001b[0m Trial 1399 finished with value: 7.363338515566492 and parameters: {'n_hidden': 4, 'learning_rate': 0.010338117269632593, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04084121392430303, 'dropout_rate_Layer_2': 0.0488864506354727, 'dropout_rate_Layer_3': 0.15047249218929368, 'dropout_rate_Layer_4': 0.05933817399382852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003519177067162041, 'l1_Layer_2': 7.073660579544302e-05, 'l1_Layer_3': 0.00020397994646073557, 'l1_Layer_4': 4.81624249748317e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 125, 'n_units_Layer_4': 55}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.36 | sMAPE for Validation Set is: 20.54% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 23.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:34:13,141]\u001b[0m Trial 1395 finished with value: 7.986036122475145 and parameters: {'n_hidden': 4, 'learning_rate': 0.003790457675647724, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3002803833441416, 'dropout_rate_Layer_2': 0.1859355198707831, 'dropout_rate_Layer_3': 0.00012715367778499964, 'dropout_rate_Layer_4': 0.06864716181781211, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.002015204124254047, 'l1_Layer_2': 1.0786327366870242e-05, 'l1_Layer_3': 5.1037858640812205e-05, 'l1_Layer_4': 2.6461926003706436e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 185, 'n_units_Layer_4': 285}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.99 | sMAPE for Validation Set is: 21.84% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 22.36% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:34:23,745]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:28,186]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:28,555]\u001b[0m Trial 1404 finished with value: 7.258221864962267 and parameters: {'n_hidden': 4, 'learning_rate': 0.009761851389421096, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03975185270533035, 'dropout_rate_Layer_2': 0.032037122338599906, 'dropout_rate_Layer_3': 0.16139240064270566, 'dropout_rate_Layer_4': 0.060775946751746315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020711509442033925, 'l1_Layer_2': 6.046354218070653e-05, 'l1_Layer_3': 0.00014052060682453804, 'l1_Layer_4': 4.6662857538312124e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 75, 'n_units_Layer_3': 120, 'n_units_Layer_4': 55}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.26 | sMAPE for Validation Set is: 20.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 22.70% | rMAE for Test Set is: 0.67\n",
      "MAE for Validation Set is: 7.36 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 21.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:34:33,012]\u001b[0m Trial 1403 finished with value: 7.364232580481961 and parameters: {'n_hidden': 4, 'learning_rate': 0.009381819278341731, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042280698612613736, 'dropout_rate_Layer_2': 0.03300770677619873, 'dropout_rate_Layer_3': 0.15281350887301712, 'dropout_rate_Layer_4': 0.047675973212483756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0035970802769704777, 'l1_Layer_2': 0.0001026574013913614, 'l1_Layer_3': 0.00014084425497340637, 'l1_Layer_4': 4.923236028646725e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130, 'n_units_Layer_4': 55}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:36,724]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:36,839]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:38,556]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:43,926]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:44,815]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:49,878]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:50,204]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:54,277]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:34:58,320]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:00,365]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:04,542]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:08,312]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:12,127]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:12,819]\u001b[0m Trial 1414 finished with value: 7.69541998626189 and parameters: {'n_hidden': 4, 'learning_rate': 0.009588864763095756, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02995474877348805, 'dropout_rate_Layer_2': 0.2290860240981292, 'dropout_rate_Layer_3': 0.16452005447135473, 'dropout_rate_Layer_4': 0.06132483072382186, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004791556623840158, 'l1_Layer_2': 0.0001359226225456696, 'l1_Layer_3': 0.00013807280733263967, 'l1_Layer_4': 7.080491037009286e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 95, 'n_units_Layer_3': 120, 'n_units_Layer_4': 55}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.70 | sMAPE for Validation Set is: 21.42% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 23.82% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:35:19,672]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:23,852]\u001b[0m Trial 1415 finished with value: 7.333418343813061 and parameters: {'n_hidden': 4, 'learning_rate': 0.010876014920863689, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029007481046250897, 'dropout_rate_Layer_2': 0.0555286099267127, 'dropout_rate_Layer_3': 0.16271632404298733, 'dropout_rate_Layer_4': 0.05723504174714478, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0031025698615894195, 'l1_Layer_2': 5.501177027893995e-05, 'l1_Layer_3': 0.00014164001846087427, 'l1_Layer_4': 6.989381493625684e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 120, 'n_units_Layer_4': 55}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.33 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 6.27 | sMAPE for Test Set is: 20.85% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:35:28,648]\u001b[0m Trial 1422 finished with value: 7.493713920137513 and parameters: {'n_hidden': 4, 'learning_rate': 0.009684484914679102, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021061105094352113, 'dropout_rate_Layer_2': 0.048598115332698325, 'dropout_rate_Layer_3': 0.15366818851507213, 'dropout_rate_Layer_4': 0.07148194041772232, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003180092541390608, 'l1_Layer_2': 8.581197461961504e-05, 'l1_Layer_3': 0.000194049617262079, 'l1_Layer_4': 3.826435367022737e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115, 'n_units_Layer_4': 60}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.49 | sMAPE for Validation Set is: 20.82% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 22.05% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:35:34,872]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:35,456]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:40,029]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:43,301]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:44,555]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:45,993]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:47,502]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:50,551]\u001b[0m Trial 1426 finished with value: 6.928160195999278 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007621118929465454, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2750911484301806, 'dropout_rate_Layer_2': 0.03883193898015684, 'dropout_rate_Layer_3': 0.2656635136079497, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012108689081521836, 'l1_Layer_2': 6.506474407380891e-05, 'l1_Layer_3': 1.3514935690349346e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 225, 'n_units_Layer_3': 165}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.93 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 23.76% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:35:55,636]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:35:58,320]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:00,875]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:02,306]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:05,644]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:11,107]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:15,132]\u001b[0m Trial 1431 finished with value: 6.943896369932747 and parameters: {'n_hidden': 3, 'learning_rate': 0.000658357104792917, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.26345901905452646, 'dropout_rate_Layer_2': 0.04083078107484278, 'dropout_rate_Layer_3': 0.25522486521930554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011923337697072986, 'l1_Layer_2': 2.2037856864408308e-05, 'l1_Layer_3': 2.8757417642757227e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 215, 'n_units_Layer_3': 140}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 19.54% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 23.45% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:36:17,714]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:21,298]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:24,103]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:26,226]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:29,225]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:37,500]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:41,902]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:42,662]\u001b[0m Trial 1444 finished with value: 7.114409821210411 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008450877619624495, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28193886581421507, 'dropout_rate_Layer_2': 0.030249654486641943, 'dropout_rate_Layer_3': 0.24604553080217062, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.556861461299076e-05, 'l1_Layer_2': 4.459555721361118e-05, 'l1_Layer_3': 1.7341020906250925e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.26% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:36:47,114]\u001b[0m Trial 1438 finished with value: 7.154552965109243 and parameters: {'n_hidden': 4, 'learning_rate': 0.010546094624104912, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0186063194252367, 'dropout_rate_Layer_2': 0.03361067551480558, 'dropout_rate_Layer_3': 0.1488339413422253, 'dropout_rate_Layer_4': 0.02948761227700861, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002659142965612548, 'l1_Layer_2': 0.00010424355504445453, 'l1_Layer_3': 0.00010414879110402672, 'l1_Layer_4': 6.284829934973676e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115, 'n_units_Layer_4': 50}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.15 | sMAPE for Validation Set is: 19.98% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 21.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:36:49,831]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:50,675]\u001b[0m Trial 1446 finished with value: 6.8302362116305515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008398669722387118, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2824388821012207, 'dropout_rate_Layer_2': 0.028130791239609383, 'dropout_rate_Layer_3': 0.2324030900166221, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017002398100234316, 'l1_Layer_2': 4.394502463864823e-05, 'l1_Layer_3': 1.770604940324619e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 230, 'n_units_Layer_3': 160}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 19.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 22.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:36:51,127]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:36:59,224]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:02,532]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:05,303]\u001b[0m Trial 1449 finished with value: 6.9007998005083975 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006159837578479003, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29600812006700217, 'dropout_rate_Layer_2': 0.06947908157311027, 'dropout_rate_Layer_3': 0.23207008985327565, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018219246164488128, 'l1_Layer_2': 6.21826548021814e-05, 'l1_Layer_3': 1.1624851472713218e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 220, 'n_units_Layer_3': 130}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.90 | sMAPE for Validation Set is: 19.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 22.98% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:37:07,976]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:12,414]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:14,506]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:16,536]\u001b[0m Trial 1454 finished with value: 7.608257316827941 and parameters: {'n_hidden': 4, 'learning_rate': 0.013360542772105561, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004693812095427345, 'dropout_rate_Layer_2': 0.024796225595511114, 'dropout_rate_Layer_3': 0.13781348944684238, 'dropout_rate_Layer_4': 0.06973062361008137, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0023436098302694786, 'l1_Layer_2': 5.406138889588503e-05, 'l1_Layer_3': 8.53001286252206e-05, 'l1_Layer_4': 3.280862663464999e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 80, 'n_units_Layer_3': 115, 'n_units_Layer_4': 80}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.61 | sMAPE for Validation Set is: 21.15% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 23.62% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:37:19,990]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:23,041]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:25,024]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:28,393]\u001b[0m Trial 1452 finished with value: 7.272329475507557 and parameters: {'n_hidden': 4, 'learning_rate': 0.010815925370392405, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00608704704546967, 'dropout_rate_Layer_2': 0.042647068434492896, 'dropout_rate_Layer_3': 0.13835880062086425, 'dropout_rate_Layer_4': 0.036324921643843086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002715163877496708, 'l1_Layer_2': 7.089762837891654e-05, 'l1_Layer_3': 9.15545150431971e-05, 'l1_Layer_4': 0.00010529331563764079, 'n_units_Layer_1': 160, 'n_units_Layer_2': 75, 'n_units_Layer_3': 115, 'n_units_Layer_4': 50}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.27 | sMAPE for Validation Set is: 20.08% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 22.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:37:32,958]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:33,292]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:37,033]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:40,784]\u001b[0m Trial 1458 finished with value: 8.605131601297213 and parameters: {'n_hidden': 4, 'learning_rate': 0.006465607665830378, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27360162507411645, 'dropout_rate_Layer_2': 0.18694634596292536, 'dropout_rate_Layer_3': 0.014665968580954687, 'dropout_rate_Layer_4': 0.042654133780083966, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002562544717068103, 'l1_Layer_2': 1.43652538354283e-05, 'l1_Layer_3': 2.3388559899330655e-05, 'l1_Layer_4': 3.5767705928615075e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 150, 'n_units_Layer_3': 170, 'n_units_Layer_4': 300}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.61 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 7.12 | sMAPE for Test Set is: 23.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:37:42,137]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:43,386]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:48,956]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:49,739]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:50,021]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:37:55,482]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:01,136]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:01,416]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.04 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 23.51% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:38:04,754]\u001b[0m Trial 1465 finished with value: 7.037424905207182 and parameters: {'n_hidden': 3, 'learning_rate': 0.007340826108402575, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011708737143226938, 'dropout_rate_Layer_2': 0.0421826625427216, 'dropout_rate_Layer_3': 0.27540230014594597, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018792722795782284, 'l1_Layer_2': 6.419619332226001e-05, 'l1_Layer_3': 6.884012147878845e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 110}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:06,287]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:07,236]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:07,776]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:11,367]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:16,194]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:18,007]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:18,588]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:19,210]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:28,807]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:29,220]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:29,704]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:37,688]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:40,626]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:43,355]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:45,208]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:49,273]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:52,171]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:53,909]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:38:57,766]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:39:00,969]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:39:04,015]\u001b[0m Trial 1488 finished with value: 7.715819684552859 and parameters: {'n_hidden': 4, 'learning_rate': 0.0025363377393701693, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3110134633918331, 'dropout_rate_Layer_2': 0.16594463711205296, 'dropout_rate_Layer_3': 0.015174842745060185, 'dropout_rate_Layer_4': 0.08635259926670444, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.003259378459619255, 'l1_Layer_2': 1.8433226405649726e-05, 'l1_Layer_3': 1.2911820760983797e-05, 'l1_Layer_4': 0.0014462656454323913, 'n_units_Layer_1': 75, 'n_units_Layer_2': 110, 'n_units_Layer_3': 195, 'n_units_Layer_4': 280}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.72 | sMAPE for Validation Set is: 21.14% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 22.78% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:39:05,825]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:39:06,658]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:39:09,864]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 18:39:10,642]\u001b[0m Trial 1487 finished with value: 7.108827261472437 and parameters: {'n_hidden': 3, 'learning_rate': 0.008258725187066373, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03382382157886667, 'dropout_rate_Layer_2': 0.03008824175647574, 'dropout_rate_Layer_3': 0.16181693171658076, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00256277465557939, 'l1_Layer_2': 5.225486976997972e-05, 'l1_Layer_3': 0.0001325382993985379, 'n_units_Layer_1': 175, 'n_units_Layer_2': 90, 'n_units_Layer_3': 115}. Best is trial 1160 with value: 6.7643345503564545.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.11 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 23.44% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 18:39:11,555]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-01-01, MAE is:38.09 & sMAPE is:183.06% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :38.09 & 183.06% & 1.55\n",
      "for 2019-01-02, MAE is:29.88 & sMAPE is:103.74% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :33.99 & 143.40% & 1.47\n",
      "for 2019-01-03, MAE is:16.91 & sMAPE is:35.73% & rMAE is:6.31 ||| daily mean of MAE & sMAPE & rMAE till now are :28.29 & 107.51% & 3.08\n",
      "for 2019-01-04, MAE is:5.42 & sMAPE is:11.40% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :22.58 & 83.48% & 2.45\n",
      "for 2019-01-05, MAE is:9.42 & sMAPE is:23.31% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :19.94 & 71.45% & 2.06\n",
      "for 2019-01-06, MAE is:17.59 & sMAPE is:38.73% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :19.55 & 66.00% & 1.86\n",
      "for 2019-01-07, MAE is:12.94 & sMAPE is:27.49% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :18.61 & 60.49% & 1.79\n",
      "for 2019-01-08, MAE is:7.63 & sMAPE is:26.21% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :17.23 & 56.21% & 1.59\n",
      "for 2019-01-09, MAE is:7.88 & sMAPE is:27.54% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :16.20 & 53.02% & 1.46\n",
      "for 2019-01-10, MAE is:22.04 & sMAPE is:39.02% & rMAE is:2.21 ||| daily mean of MAE & sMAPE & rMAE till now are :16.78 & 51.62% & 1.53\n",
      "for 2019-01-11, MAE is:10.57 & sMAPE is:18.74% & rMAE is:2.73 ||| daily mean of MAE & sMAPE & rMAE till now are :16.21 & 48.63% & 1.64\n",
      "for 2019-01-12, MAE is:8.46 & sMAPE is:23.16% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :15.57 & 46.51% & 1.55\n",
      "for 2019-01-13, MAE is:16.35 & sMAPE is:80.58% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :15.63 & 49.13% & 1.47\n",
      "for 2019-01-14, MAE is:14.86 & sMAPE is:74.53% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :15.57 & 50.95% & 1.40\n",
      "for 2019-01-15, MAE is:10.08 & sMAPE is:25.44% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :15.21 & 49.24% & 1.37\n",
      "for 2019-01-16, MAE is:11.51 & sMAPE is:32.40% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :14.98 & 48.19% & 1.35\n",
      "for 2019-01-17, MAE is:4.67 & sMAPE is:12.65% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 46.10% & 1.29\n",
      "for 2019-01-18, MAE is:18.33 & sMAPE is:34.74% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :14.59 & 45.47% & 1.29\n",
      "for 2019-01-19, MAE is:4.19 & sMAPE is:7.58% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :14.04 & 43.48% & 1.24\n",
      "for 2019-01-20, MAE is:5.48 & sMAPE is:10.61% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :13.61 & 41.83% & 1.19\n",
      "for 2019-01-21, MAE is:6.68 & sMAPE is:9.53% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :13.28 & 40.29% & 1.14\n",
      "for 2019-01-22, MAE is:8.26 & sMAPE is:12.39% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :13.06 & 39.03% & 1.11\n",
      "for 2019-01-23, MAE is:16.21 & sMAPE is:23.70% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :13.19 & 38.36% & 1.08\n",
      "for 2019-01-24, MAE is:24.63 & sMAPE is:32.29% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :13.67 & 38.11% & 1.06\n",
      "for 2019-01-25, MAE is:13.52 & sMAPE is:19.16% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :13.66 & 37.35% & 1.07\n",
      "for 2019-01-26, MAE is:5.63 & sMAPE is:11.86% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :13.35 & 36.37% & 1.06\n",
      "for 2019-01-27, MAE is:7.77 & sMAPE is:28.18% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :13.15 & 36.06% & 1.04\n",
      "for 2019-01-28, MAE is:6.47 & sMAPE is:13.82% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :12.91 & 35.27% & 1.01\n",
      "for 2019-01-29, MAE is:13.44 & sMAPE is:26.69% & rMAE is:2.89 ||| daily mean of MAE & sMAPE & rMAE till now are :12.93 & 34.97% & 1.08\n",
      "for 2019-01-30, MAE is:6.19 & sMAPE is:12.03% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.70 & 34.21% & 1.05\n",
      "for 2019-01-31, MAE is:10.83 & sMAPE is:21.05% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.64 & 33.78% & 1.03\n",
      "for 2019-02-01, MAE is:4.03 & sMAPE is:6.89% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :12.37 & 32.94% & 1.01\n",
      "for 2019-02-02, MAE is:4.21 & sMAPE is:7.97% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :12.13 & 32.19% & 1.02\n",
      "for 2019-02-03, MAE is:3.98 & sMAPE is:9.05% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :11.89 & 31.51% & 1.00\n",
      "for 2019-02-04, MAE is:9.94 & sMAPE is:20.17% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 31.18% & 1.02\n",
      "for 2019-02-05, MAE is:13.67 & sMAPE is:31.34% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :11.88 & 31.19% & 1.05\n",
      "for 2019-02-06, MAE is:7.16 & sMAPE is:15.84% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :11.75 & 30.77% & 1.08\n",
      "for 2019-02-07, MAE is:8.02 & sMAPE is:17.10% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :11.66 & 30.41% & 1.06\n",
      "for 2019-02-08, MAE is:8.39 & sMAPE is:23.05% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.57 & 30.22% & 1.05\n",
      "for 2019-02-09, MAE is:17.89 & sMAPE is:139.99% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :11.73 & 32.97% & 1.03\n",
      "for 2019-02-10, MAE is:16.50 & sMAPE is:100.71% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :11.85 & 34.62% & 1.03\n",
      "for 2019-02-11, MAE is:8.90 & sMAPE is:56.95% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :11.78 & 35.15% & 1.02\n",
      "for 2019-02-12, MAE is:8.52 & sMAPE is:20.87% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :11.70 & 34.82% & 1.02\n",
      "for 2019-02-13, MAE is:8.93 & sMAPE is:22.56% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :11.64 & 34.54% & 1.03\n",
      "for 2019-02-14, MAE is:6.02 & sMAPE is:13.13% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :11.51 & 34.07% & 1.03\n",
      "for 2019-02-15, MAE is:5.84 & sMAPE is:11.68% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :11.39 & 33.58% & 1.03\n",
      "for 2019-02-16, MAE is:4.85 & sMAPE is:13.09% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :11.25 & 33.14% & 1.01\n",
      "for 2019-02-17, MAE is:9.38 & sMAPE is:27.72% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :11.21 & 33.03% & 1.01\n",
      "for 2019-02-18, MAE is:6.18 & sMAPE is:14.40% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 32.65% & 1.00\n",
      "for 2019-02-19, MAE is:6.28 & sMAPE is:16.46% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :11.01 & 32.33% & 1.00\n",
      "for 2019-02-20, MAE is:10.05 & sMAPE is:25.42% & rMAE is:4.36 ||| daily mean of MAE & sMAPE & rMAE till now are :10.99 & 32.19% & 1.06\n",
      "for 2019-02-21, MAE is:3.96 & sMAPE is:9.26% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.86 & 31.75% & 1.05\n",
      "for 2019-02-22, MAE is:4.96 & sMAPE is:11.15% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.75 & 31.36% & 1.07\n",
      "for 2019-02-23, MAE is:3.90 & sMAPE is:10.07% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 30.97% & 1.09\n",
      "for 2019-02-24, MAE is:4.82 & sMAPE is:13.00% & rMAE is:3.00 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 30.64% & 1.12\n",
      "for 2019-02-25, MAE is:7.51 & sMAPE is:15.60% & rMAE is:3.15 ||| daily mean of MAE & sMAPE & rMAE till now are :10.46 & 30.37% & 1.16\n",
      "for 2019-02-26, MAE is:7.35 & sMAPE is:18.34% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 30.16% & 1.17\n",
      "for 2019-02-27, MAE is:4.74 & sMAPE is:10.65% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 29.82% & 1.18\n",
      "for 2019-02-28, MAE is:6.34 & sMAPE is:16.92% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 29.61% & 1.19\n",
      "for 2019-03-01, MAE is:5.43 & sMAPE is:12.54% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 29.32% & 1.20\n",
      "for 2019-03-02, MAE is:4.50 & sMAPE is:11.01% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 29.02% & 1.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-03-03, MAE is:14.33 & sMAPE is:115.89% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 30.42% & 1.18\n",
      "for 2019-03-04, MAE is:15.09 & sMAPE is:106.44% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 31.63% & 1.17\n",
      "for 2019-03-05, MAE is:13.39 & sMAPE is:73.77% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 32.29% & 1.17\n",
      "for 2019-03-06, MAE is:9.50 & sMAPE is:24.25% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 32.16% & 1.17\n",
      "for 2019-03-07, MAE is:5.86 & sMAPE is:21.64% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 32.00% & 1.16\n",
      "for 2019-03-08, MAE is:8.39 & sMAPE is:52.57% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 32.31% & 1.15\n",
      "for 2019-03-09, MAE is:22.47 & sMAPE is:136.18% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 33.84% & 1.14\n",
      "for 2019-03-10, MAE is:12.58 & sMAPE is:94.79% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.37 & 34.72% & 1.14\n",
      "for 2019-03-11, MAE is:14.24 & sMAPE is:46.85% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 34.89% & 1.13\n",
      "for 2019-03-12, MAE is:10.98 & sMAPE is:30.01% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 34.83% & 1.12\n",
      "for 2019-03-13, MAE is:10.32 & sMAPE is:66.21% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 35.26% & 1.11\n",
      "for 2019-03-14, MAE is:8.00 & sMAPE is:21.25% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 35.07% & 1.12\n",
      "for 2019-03-15, MAE is:10.58 & sMAPE is:42.33% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 35.17% & 1.11\n",
      "for 2019-03-16, MAE is:12.54 & sMAPE is:104.63% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 36.09% & 1.11\n",
      "for 2019-03-17, MAE is:13.20 & sMAPE is:151.91% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 37.62% & 1.10\n",
      "for 2019-03-18, MAE is:6.33 & sMAPE is:23.91% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :10.42 & 37.44% & 1.10\n",
      "for 2019-03-19, MAE is:4.21 & sMAPE is:9.25% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.34 & 37.08% & 1.09\n",
      "for 2019-03-20, MAE is:3.83 & sMAPE is:8.96% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 36.72% & 1.08\n",
      "for 2019-03-21, MAE is:5.59 & sMAPE is:13.14% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 36.43% & 1.08\n",
      "for 2019-03-22, MAE is:4.68 & sMAPE is:11.14% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 36.12% & 1.07\n",
      "for 2019-03-23, MAE is:3.05 & sMAPE is:8.68% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 35.78% & 1.06\n",
      "for 2019-03-24, MAE is:6.79 & sMAPE is:22.69% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 35.62% & 1.04\n",
      "for 2019-03-25, MAE is:3.85 & sMAPE is:11.81% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :9.93 & 35.34% & 1.04\n",
      "for 2019-03-26, MAE is:4.83 & sMAPE is:13.98% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :9.87 & 35.09% & 1.04\n",
      "for 2019-03-27, MAE is:4.48 & sMAPE is:12.16% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :9.81 & 34.82% & 1.05\n",
      "for 2019-03-28, MAE is:7.37 & sMAPE is:19.21% & rMAE is:2.34 ||| daily mean of MAE & sMAPE & rMAE till now are :9.78 & 34.64% & 1.06\n",
      "for 2019-03-29, MAE is:6.53 & sMAPE is:17.37% & rMAE is:3.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.74 & 34.45% & 1.09\n",
      "for 2019-03-30, MAE is:4.39 & sMAPE is:13.30% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 34.21% & 1.10\n",
      "for 2019-03-31, MAE is:5.01 & sMAPE is:28.07% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.63 & 34.14% & 1.10\n",
      "for 2019-04-01, MAE is:7.68 & sMAPE is:21.75% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :9.61 & 34.00% & 1.10\n",
      "for 2019-04-02, MAE is:4.07 & sMAPE is:12.84% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 33.77% & 1.10\n",
      "for 2019-04-03, MAE is:11.60 & sMAPE is:31.73% & rMAE is:3.21 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 33.75% & 1.12\n",
      "for 2019-04-04, MAE is:10.97 & sMAPE is:29.85% & rMAE is:3.73 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 33.71% & 1.15\n",
      "for 2019-04-05, MAE is:9.34 & sMAPE is:24.62% & rMAE is:2.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 33.62% & 1.16\n",
      "for 2019-04-06, MAE is:6.09 & sMAPE is:17.55% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 33.45% & 1.16\n",
      "for 2019-04-07, MAE is:12.52 & sMAPE is:41.35% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 33.53% & 1.17\n",
      "for 2019-04-08, MAE is:5.18 & sMAPE is:11.29% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 33.30% & 1.16\n",
      "for 2019-04-09, MAE is:4.54 & sMAPE is:11.49% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.48 & 33.08% & 1.16\n",
      "for 2019-04-10, MAE is:5.94 & sMAPE is:15.18% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 32.90% & 1.16\n",
      "for 2019-04-11, MAE is:8.46 & sMAPE is:21.05% & rMAE is:2.84 ||| daily mean of MAE & sMAPE & rMAE till now are :9.44 & 32.79% & 1.18\n",
      "for 2019-04-12, MAE is:4.98 & sMAPE is:11.68% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.39 & 32.58% & 1.18\n",
      "for 2019-04-13, MAE is:6.96 & sMAPE is:18.78% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.37 & 32.44% & 1.19\n",
      "for 2019-04-14, MAE is:7.43 & sMAPE is:23.29% & rMAE is:4.48 ||| daily mean of MAE & sMAPE & rMAE till now are :9.35 & 32.36% & 1.22\n",
      "for 2019-04-15, MAE is:6.21 & sMAPE is:15.27% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 32.19% & 1.23\n",
      "for 2019-04-16, MAE is:5.83 & sMAPE is:15.12% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 32.03% & 1.23\n",
      "for 2019-04-17, MAE is:4.56 & sMAPE is:11.65% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 31.84% & 1.24\n",
      "for 2019-04-18, MAE is:6.91 & sMAPE is:18.20% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 31.72% & 1.24\n",
      "for 2019-04-19, MAE is:5.15 & sMAPE is:20.77% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 31.62% & 1.24\n",
      "for 2019-04-20, MAE is:5.11 & sMAPE is:15.82% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.15 & 31.47% & 1.23\n",
      "for 2019-04-21, MAE is:6.39 & sMAPE is:26.26% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 31.43% & 1.23\n",
      "for 2019-04-22, MAE is:43.37 & sMAPE is:142.56% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.43 & 32.42% & 1.23\n",
      "for 2019-04-23, MAE is:11.74 & sMAPE is:102.47% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :9.45 & 33.04% & 1.22\n",
      "for 2019-04-24, MAE is:4.88 & sMAPE is:15.01% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :9.41 & 32.88% & 1.21\n",
      "for 2019-04-25, MAE is:6.66 & sMAPE is:17.54% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :9.38 & 32.75% & 1.22\n",
      "for 2019-04-26, MAE is:6.47 & sMAPE is:15.90% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.36 & 32.60% & 1.21\n",
      "for 2019-04-27, MAE is:3.94 & sMAPE is:12.04% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 32.42% & 1.21\n",
      "for 2019-04-28, MAE is:12.33 & sMAPE is:44.91% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :9.34 & 32.53% & 1.22\n",
      "for 2019-04-29, MAE is:8.30 & sMAPE is:21.09% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 32.43% & 1.21\n",
      "for 2019-04-30, MAE is:7.14 & sMAPE is:18.00% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 32.31% & 1.20\n",
      "for 2019-05-01, MAE is:11.73 & sMAPE is:49.47% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :9.33 & 32.46% & 1.20\n",
      "for 2019-05-02, MAE is:4.41 & sMAPE is:12.66% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 32.29% & 1.20\n",
      "for 2019-05-03, MAE is:2.73 & sMAPE is:6.58% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.24 & 32.08% & 1.20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-05-04, MAE is:7.23 & sMAPE is:21.00% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :9.22 & 32.00% & 1.19\n",
      "for 2019-05-05, MAE is:3.74 & sMAPE is:14.25% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.18 & 31.85% & 1.19\n",
      "for 2019-05-06, MAE is:11.30 & sMAPE is:29.38% & rMAE is:3.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.19 & 31.83% & 1.21\n",
      "for 2019-05-07, MAE is:6.29 & sMAPE is:13.05% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 31.69% & 1.21\n",
      "for 2019-05-08, MAE is:4.37 & sMAPE is:10.62% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :9.13 & 31.52% & 1.20\n",
      "for 2019-05-09, MAE is:13.22 & sMAPE is:34.20% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.17 & 31.54% & 1.20\n",
      "for 2019-05-10, MAE is:2.56 & sMAPE is:5.77% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 31.34% & 1.20\n",
      "for 2019-05-11, MAE is:4.76 & sMAPE is:12.21% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 31.20% & 1.20\n",
      "for 2019-05-12, MAE is:8.76 & sMAPE is:53.16% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :9.08 & 31.36% & 1.20\n",
      "for 2019-05-13, MAE is:3.91 & sMAPE is:10.26% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 31.21% & 1.19\n",
      "for 2019-05-14, MAE is:4.93 & sMAPE is:12.51% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 31.07% & 1.19\n",
      "for 2019-05-15, MAE is:4.67 & sMAPE is:12.01% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :8.98 & 30.92% & 1.19\n",
      "for 2019-05-16, MAE is:3.81 & sMAPE is:8.91% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.94 & 30.76% & 1.19\n",
      "for 2019-05-17, MAE is:5.80 & sMAPE is:14.29% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 30.64% & 1.19\n",
      "for 2019-05-18, MAE is:2.47 & sMAPE is:6.86% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 30.47% & 1.19\n",
      "for 2019-05-19, MAE is:9.04 & sMAPE is:31.29% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 30.48% & 1.18\n",
      "for 2019-05-20, MAE is:10.95 & sMAPE is:26.23% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 30.45% & 1.18\n",
      "for 2019-05-21, MAE is:6.36 & sMAPE is:15.32% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 30.34% & 1.18\n",
      "for 2019-05-22, MAE is:4.00 & sMAPE is:10.28% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 30.20% & 1.18\n",
      "for 2019-05-23, MAE is:4.64 & sMAPE is:11.30% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 30.06% & 1.18\n",
      "for 2019-05-24, MAE is:2.86 & sMAPE is:6.82% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :8.76 & 29.90% & 1.18\n",
      "for 2019-05-25, MAE is:2.40 & sMAPE is:7.28% & rMAE is:1.82 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 29.75% & 1.18\n",
      "for 2019-05-26, MAE is:8.30 & sMAPE is:45.42% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 29.85% & 1.18\n",
      "for 2019-05-27, MAE is:5.51 & sMAPE is:19.91% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.69 & 29.79% & 1.17\n",
      "for 2019-05-28, MAE is:5.96 & sMAPE is:13.67% & rMAE is:2.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 29.68% & 1.18\n",
      "for 2019-05-29, MAE is:7.54 & sMAPE is:19.45% & rMAE is:2.56 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 29.61% & 1.19\n",
      "for 2019-05-30, MAE is:17.63 & sMAPE is:93.95% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 30.04% & 1.19\n",
      "for 2019-05-31, MAE is:4.19 & sMAPE is:12.09% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 29.92% & 1.19\n",
      "for 2019-06-01, MAE is:4.39 & sMAPE is:14.81% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 29.82% & 1.18\n",
      "for 2019-06-02, MAE is:7.62 & sMAPE is:49.66% & rMAE is:1.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 29.95% & 1.19\n",
      "for 2019-06-03, MAE is:10.70 & sMAPE is:31.83% & rMAE is:3.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 29.96% & 1.20\n",
      "for 2019-06-04, MAE is:4.82 & sMAPE is:12.43% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 29.85% & 1.20\n",
      "for 2019-06-05, MAE is:7.88 & sMAPE is:21.86% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 29.80% & 1.21\n",
      "for 2019-06-06, MAE is:7.27 & sMAPE is:20.79% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 29.74% & 1.20\n",
      "for 2019-06-07, MAE is:9.54 & sMAPE is:23.51% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 29.70% & 1.20\n",
      "for 2019-06-08, MAE is:63.26 & sMAPE is:166.78% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :8.99 & 30.56% & 1.20\n",
      "for 2019-06-09, MAE is:7.11 & sMAPE is:35.43% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.97 & 30.59% & 1.20\n",
      "for 2019-06-10, MAE is:4.22 & sMAPE is:15.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 30.50% & 1.19\n",
      "for 2019-06-11, MAE is:9.65 & sMAPE is:22.56% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.95 & 30.45% & 1.19\n",
      "for 2019-06-12, MAE is:3.97 & sMAPE is:8.90% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 30.32% & 1.19\n",
      "for 2019-06-13, MAE is:7.34 & sMAPE is:17.38% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.91 & 30.24% & 1.19\n",
      "for 2019-06-14, MAE is:6.72 & sMAPE is:15.87% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.90 & 30.15% & 1.19\n",
      "for 2019-06-15, MAE is:7.36 & sMAPE is:21.46% & rMAE is:0.10 ||| daily mean of MAE & sMAPE & rMAE till now are :8.89 & 30.10% & 1.18\n",
      "for 2019-06-16, MAE is:5.64 & sMAPE is:18.56% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 30.03% & 1.18\n",
      "for 2019-06-17, MAE is:7.65 & sMAPE is:17.44% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 29.95% & 1.17\n",
      "for 2019-06-18, MAE is:6.76 & sMAPE is:15.52% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.85 & 29.87% & 1.17\n",
      "for 2019-06-19, MAE is:5.97 & sMAPE is:14.81% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 29.78% & 1.18\n",
      "for 2019-06-20, MAE is:3.85 & sMAPE is:10.54% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 29.67% & 1.17\n",
      "for 2019-06-21, MAE is:2.82 & sMAPE is:7.35% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 29.54% & 1.17\n",
      "for 2019-06-22, MAE is:3.01 & sMAPE is:9.15% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :8.73 & 29.42% & 1.17\n",
      "for 2019-06-23, MAE is:6.15 & sMAPE is:43.85% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 29.50% & 1.17\n",
      "for 2019-06-24, MAE is:7.18 & sMAPE is:21.87% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :8.71 & 29.46% & 1.17\n",
      "for 2019-06-25, MAE is:10.33 & sMAPE is:24.89% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.72 & 29.43% & 1.17\n",
      "for 2019-06-26, MAE is:5.86 & sMAPE is:14.43% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 29.35% & 1.17\n",
      "for 2019-06-27, MAE is:4.33 & sMAPE is:12.16% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 29.25% & 1.18\n",
      "for 2019-06-28, MAE is:8.24 & sMAPE is:18.34% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 29.19% & 1.18\n",
      "for 2019-06-29, MAE is:5.44 & sMAPE is:15.44% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 29.12% & 1.18\n",
      "for 2019-06-30, MAE is:12.93 & sMAPE is:66.72% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.68 & 29.32% & 1.18\n",
      "for 2019-07-01, MAE is:6.51 & sMAPE is:17.81% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :8.67 & 29.26% & 1.18\n",
      "for 2019-07-02, MAE is:5.70 & sMAPE is:15.78% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.65 & 29.19% & 1.18\n",
      "for 2019-07-03, MAE is:5.71 & sMAPE is:15.67% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 29.11% & 1.18\n",
      "for 2019-07-04, MAE is:3.25 & sMAPE is:9.61% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :8.61 & 29.01% & 1.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-07-05, MAE is:4.51 & sMAPE is:12.46% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 28.92% & 1.18\n",
      "for 2019-07-06, MAE is:2.87 & sMAPE is:8.94% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :8.56 & 28.81% & 1.17\n",
      "for 2019-07-07, MAE is:4.62 & sMAPE is:23.06% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :8.54 & 28.78% & 1.17\n",
      "for 2019-07-08, MAE is:3.44 & sMAPE is:9.93% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.51 & 28.68% & 1.17\n",
      "for 2019-07-09, MAE is:2.70 & sMAPE is:7.09% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.48 & 28.57% & 1.16\n",
      "for 2019-07-10, MAE is:5.31 & sMAPE is:13.42% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 28.49% & 1.16\n",
      "for 2019-07-11, MAE is:6.49 & sMAPE is:14.76% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :8.45 & 28.42% & 1.16\n",
      "for 2019-07-12, MAE is:6.00 & sMAPE is:13.62% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 28.34% & 1.15\n",
      "for 2019-07-13, MAE is:5.45 & sMAPE is:16.41% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.42 & 28.28% & 1.15\n",
      "for 2019-07-14, MAE is:6.53 & sMAPE is:21.49% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :8.41 & 28.24% & 1.15\n",
      "for 2019-07-15, MAE is:5.81 & sMAPE is:15.33% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :8.40 & 28.18% & 1.15\n",
      "for 2019-07-16, MAE is:6.20 & sMAPE is:15.50% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.39 & 28.11% & 1.15\n",
      "for 2019-07-17, MAE is:5.28 & sMAPE is:12.18% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.37 & 28.03% & 1.15\n",
      "for 2019-07-18, MAE is:4.63 & sMAPE is:11.14% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :8.35 & 27.95% & 1.15\n",
      "for 2019-07-19, MAE is:4.19 & sMAPE is:9.34% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :8.33 & 27.85% & 1.15\n",
      "for 2019-07-20, MAE is:4.81 & sMAPE is:12.49% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :8.32 & 27.78% & 1.16\n",
      "for 2019-07-21, MAE is:6.23 & sMAPE is:23.22% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :8.31 & 27.76% & 1.16\n",
      "for 2019-07-22, MAE is:4.21 & sMAPE is:10.18% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.28 & 27.67% & 1.16\n",
      "for 2019-07-23, MAE is:5.78 & sMAPE is:12.47% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 27.59% & 1.16\n",
      "for 2019-07-24, MAE is:7.21 & sMAPE is:14.20% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 27.53% & 1.16\n",
      "for 2019-07-25, MAE is:7.87 & sMAPE is:16.54% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.27 & 27.48% & 1.16\n",
      "for 2019-07-26, MAE is:3.34 & sMAPE is:7.49% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.24 & 27.38% & 1.16\n",
      "for 2019-07-27, MAE is:3.47 & sMAPE is:9.42% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 27.29% & 1.16\n",
      "for 2019-07-28, MAE is:6.25 & sMAPE is:23.07% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :8.21 & 27.27% & 1.17\n",
      "for 2019-07-29, MAE is:6.99 & sMAPE is:15.94% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.20 & 27.22% & 1.17\n",
      "for 2019-07-30, MAE is:4.77 & sMAPE is:11.33% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 27.14% & 1.17\n",
      "for 2019-07-31, MAE is:6.81 & sMAPE is:14.06% & rMAE is:1.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.18 & 27.08% & 1.17\n",
      "for 2019-08-01, MAE is:4.79 & sMAPE is:10.11% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 27.00% & 1.17\n",
      "for 2019-08-02, MAE is:3.88 & sMAPE is:8.43% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 26.92% & 1.17\n",
      "for 2019-08-03, MAE is:1.76 & sMAPE is:4.75% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 26.81% & 1.17\n",
      "for 2019-08-04, MAE is:3.59 & sMAPE is:10.98% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :8.09 & 26.74% & 1.16\n",
      "for 2019-08-05, MAE is:4.94 & sMAPE is:11.11% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.08 & 26.67% & 1.17\n",
      "for 2019-08-06, MAE is:2.76 & sMAPE is:6.54% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 26.57% & 1.16\n",
      "for 2019-08-07, MAE is:4.45 & sMAPE is:11.50% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 26.51% & 1.16\n",
      "for 2019-08-08, MAE is:3.40 & sMAPE is:9.63% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 26.43% & 1.16\n",
      "for 2019-08-09, MAE is:4.32 & sMAPE is:11.03% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 26.36% & 1.16\n",
      "for 2019-08-10, MAE is:17.87 & sMAPE is:72.16% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 26.57% & 1.15\n",
      "for 2019-08-11, MAE is:13.30 & sMAPE is:77.03% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 26.79% & 1.15\n",
      "for 2019-08-12, MAE is:6.73 & sMAPE is:15.16% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :8.06 & 26.74% & 1.15\n",
      "for 2019-08-13, MAE is:4.18 & sMAPE is:11.03% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.05 & 26.67% & 1.15\n",
      "for 2019-08-14, MAE is:5.56 & sMAPE is:13.07% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 26.61% & 1.15\n",
      "for 2019-08-15, MAE is:4.23 & sMAPE is:12.90% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 26.55% & 1.15\n",
      "for 2019-08-16, MAE is:4.09 & sMAPE is:10.86% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 26.48% & 1.14\n",
      "for 2019-08-17, MAE is:5.54 & sMAPE is:22.14% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 26.46% & 1.14\n",
      "for 2019-08-18, MAE is:3.86 & sMAPE is:17.99% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 26.43% & 1.14\n",
      "for 2019-08-19, MAE is:3.15 & sMAPE is:9.26% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 26.35% & 1.13\n",
      "for 2019-08-20, MAE is:5.34 & sMAPE is:13.69% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 26.30% & 1.13\n",
      "for 2019-08-21, MAE is:6.88 & sMAPE is:15.99% & rMAE is:2.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 26.25% & 1.14\n",
      "for 2019-08-22, MAE is:3.46 & sMAPE is:8.96% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.92 & 26.18% & 1.14\n",
      "for 2019-08-23, MAE is:5.55 & sMAPE is:14.49% & rMAE is:2.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 26.13% & 1.14\n",
      "for 2019-08-24, MAE is:3.00 & sMAPE is:9.48% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.89 & 26.06% & 1.14\n",
      "for 2019-08-25, MAE is:6.03 & sMAPE is:21.41% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 26.04% & 1.14\n",
      "for 2019-08-26, MAE is:13.50 & sMAPE is:33.05% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 26.07% & 1.14\n",
      "for 2019-08-27, MAE is:8.18 & sMAPE is:19.33% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 26.04% & 1.14\n",
      "for 2019-08-28, MAE is:10.30 & sMAPE is:20.65% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 26.02% & 1.14\n",
      "for 2019-08-29, MAE is:3.87 & sMAPE is:8.84% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.90 & 25.95% & 1.14\n",
      "for 2019-08-30, MAE is:4.86 & sMAPE is:11.67% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.88 & 25.89% & 1.13\n",
      "for 2019-08-31, MAE is:2.86 & sMAPE is:8.11% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 25.81% & 1.14\n",
      "for 2019-09-01, MAE is:2.76 & sMAPE is:10.34% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 25.75% & 1.13\n",
      "for 2019-09-02, MAE is:2.71 & sMAPE is:7.04% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 25.67% & 1.13\n",
      "for 2019-09-03, MAE is:3.77 & sMAPE is:10.30% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 25.61% & 1.13\n",
      "for 2019-09-04, MAE is:4.32 & sMAPE is:12.00% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 25.56% & 1.13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-09-05, MAE is:3.90 & sMAPE is:11.55% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 25.50% & 1.12\n",
      "for 2019-09-06, MAE is:3.42 & sMAPE is:9.79% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 25.44% & 1.12\n",
      "for 2019-09-07, MAE is:5.10 & sMAPE is:15.23% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 25.40% & 1.12\n",
      "for 2019-09-08, MAE is:6.31 & sMAPE is:18.65% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 25.37% & 1.12\n",
      "for 2019-09-09, MAE is:5.71 & sMAPE is:12.15% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 25.32% & 1.12\n",
      "for 2019-09-10, MAE is:3.88 & sMAPE is:10.67% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 25.26% & 1.12\n",
      "for 2019-09-11, MAE is:3.08 & sMAPE is:9.42% & rMAE is:3.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 25.20% & 1.13\n",
      "for 2019-09-12, MAE is:7.07 & sMAPE is:22.41% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 25.19% & 1.13\n",
      "for 2019-09-13, MAE is:5.13 & sMAPE is:13.39% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 25.14% & 1.13\n",
      "for 2019-09-14, MAE is:3.28 & sMAPE is:8.87% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 25.08% & 1.12\n",
      "for 2019-09-15, MAE is:11.72 & sMAPE is:57.01% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 25.20% & 1.12\n",
      "for 2019-09-16, MAE is:7.44 & sMAPE is:16.40% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 25.17% & 1.13\n",
      "for 2019-09-17, MAE is:9.29 & sMAPE is:25.69% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 25.17% & 1.13\n",
      "for 2019-09-18, MAE is:5.53 & sMAPE is:17.01% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 25.14% & 1.13\n",
      "for 2019-09-19, MAE is:4.48 & sMAPE is:9.79% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 25.08% & 1.13\n",
      "for 2019-09-20, MAE is:4.36 & sMAPE is:10.28% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 25.02% & 1.12\n",
      "for 2019-09-21, MAE is:6.18 & sMAPE is:17.13% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 24.99% & 1.13\n",
      "for 2019-09-22, MAE is:3.33 & sMAPE is:11.02% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 24.94% & 1.12\n",
      "for 2019-09-23, MAE is:7.64 & sMAPE is:18.71% & rMAE is:1.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 24.92% & 1.13\n",
      "for 2019-09-24, MAE is:6.71 & sMAPE is:14.65% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 24.88% & 1.13\n",
      "for 2019-09-25, MAE is:5.48 & sMAPE is:11.98% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 24.83% & 1.12\n",
      "for 2019-09-26, MAE is:4.70 & sMAPE is:11.32% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 24.78% & 1.12\n",
      "for 2019-09-27, MAE is:4.18 & sMAPE is:10.91% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 24.73% & 1.12\n",
      "for 2019-09-28, MAE is:6.88 & sMAPE is:34.01% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 24.76% & 1.12\n",
      "for 2019-09-29, MAE is:11.92 & sMAPE is:87.03% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 24.99% & 1.12\n",
      "for 2019-09-30, MAE is:12.83 & sMAPE is:71.48% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 25.16% & 1.11\n",
      "for 2019-10-01, MAE is:5.54 & sMAPE is:12.72% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 25.12% & 1.11\n",
      "for 2019-10-02, MAE is:3.60 & sMAPE is:9.00% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 25.06% & 1.11\n",
      "for 2019-10-03, MAE is:9.85 & sMAPE is:27.74% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 25.07% & 1.11\n",
      "for 2019-10-04, MAE is:4.82 & sMAPE is:11.25% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 25.02% & 1.11\n",
      "for 2019-10-05, MAE is:3.40 & sMAPE is:9.00% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 24.96% & 1.11\n",
      "for 2019-10-06, MAE is:5.59 & sMAPE is:16.06% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 24.93% & 1.11\n",
      "for 2019-10-07, MAE is:8.61 & sMAPE is:20.14% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 24.91% & 1.10\n",
      "for 2019-10-08, MAE is:4.14 & sMAPE is:12.02% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 24.86% & 1.10\n",
      "for 2019-10-09, MAE is:5.17 & sMAPE is:16.35% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 24.83% & 1.10\n",
      "for 2019-10-10, MAE is:6.26 & sMAPE is:21.20% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 24.82% & 1.10\n",
      "for 2019-10-11, MAE is:5.27 & sMAPE is:20.66% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 24.81% & 1.10\n",
      "for 2019-10-12, MAE is:9.03 & sMAPE is:82.48% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 25.01% & 1.09\n",
      "for 2019-10-13, MAE is:8.70 & sMAPE is:37.76% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 25.05% & 1.09\n",
      "for 2019-10-14, MAE is:14.26 & sMAPE is:64.48% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 25.19% & 1.10\n",
      "for 2019-10-15, MAE is:13.37 & sMAPE is:34.09% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 25.22% & 1.10\n",
      "for 2019-10-16, MAE is:4.68 & sMAPE is:12.66% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 25.18% & 1.10\n",
      "for 2019-10-17, MAE is:6.82 & sMAPE is:15.94% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 25.15% & 1.09\n",
      "for 2019-10-18, MAE is:5.51 & sMAPE is:14.60% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 25.11% & 1.09\n",
      "for 2019-10-19, MAE is:8.01 & sMAPE is:28.44% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 25.12% & 1.09\n",
      "for 2019-10-20, MAE is:2.87 & sMAPE is:8.00% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 25.06% & 1.09\n",
      "for 2019-10-21, MAE is:3.58 & sMAPE is:8.52% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 25.01% & 1.09\n",
      "for 2019-10-22, MAE is:5.17 & sMAPE is:11.34% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 24.96% & 1.09\n",
      "for 2019-10-23, MAE is:3.34 & sMAPE is:7.85% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 24.90% & 1.09\n",
      "for 2019-10-24, MAE is:5.15 & sMAPE is:13.89% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 24.87% & 1.08\n",
      "for 2019-10-25, MAE is:7.62 & sMAPE is:22.88% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 24.86% & 1.09\n",
      "for 2019-10-26, MAE is:6.31 & sMAPE is:36.04% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 24.90% & 1.09\n",
      "for 2019-10-27, MAE is:10.14 & sMAPE is:63.96% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 25.03% & 1.08\n",
      "for 2019-10-28, MAE is:6.51 & sMAPE is:16.52% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 25.00% & 1.09\n",
      "for 2019-10-29, MAE is:4.07 & sMAPE is:8.38% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 24.94% & 1.09\n",
      "for 2019-10-30, MAE is:5.38 & sMAPE is:11.55% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 24.90% & 1.09\n",
      "for 2019-10-31, MAE is:4.10 & sMAPE is:8.90% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.85% & 1.08\n",
      "for 2019-11-01, MAE is:6.23 & sMAPE is:17.00% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.82% & 1.08\n",
      "for 2019-11-02, MAE is:3.70 & sMAPE is:15.31% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.79% & 1.08\n",
      "for 2019-11-03, MAE is:6.25 & sMAPE is:31.94% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 24.81% & 1.08\n",
      "for 2019-11-04, MAE is:6.28 & sMAPE is:17.56% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 24.79% & 1.08\n",
      "for 2019-11-05, MAE is:5.33 & sMAPE is:12.46% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 24.75% & 1.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2019-11-06, MAE is:12.11 & sMAPE is:25.36% & rMAE is:2.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.75% & 1.09\n",
      "for 2019-11-07, MAE is:5.27 & sMAPE is:11.20% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 24.71% & 1.09\n",
      "for 2019-11-08, MAE is:8.70 & sMAPE is:20.12% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 24.69% & 1.09\n",
      "for 2019-11-09, MAE is:2.19 & sMAPE is:5.25% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 24.63% & 1.08\n",
      "for 2019-11-10, MAE is:7.38 & sMAPE is:19.85% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 24.62% & 1.08\n",
      "for 2019-11-11, MAE is:6.39 & sMAPE is:14.50% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 24.58% & 1.08\n",
      "for 2019-11-12, MAE is:9.34 & sMAPE is:31.45% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 24.61% & 1.09\n",
      "for 2019-11-13, MAE is:4.67 & sMAPE is:9.88% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 24.56% & 1.09\n",
      "for 2019-11-14, MAE is:6.15 & sMAPE is:14.38% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 24.53% & 1.09\n",
      "for 2019-11-15, MAE is:4.42 & sMAPE is:11.77% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 24.49% & 1.09\n",
      "for 2019-11-16, MAE is:3.91 & sMAPE is:10.78% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 24.44% & 1.09\n",
      "for 2019-11-17, MAE is:7.38 & sMAPE is:23.02% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 24.44% & 1.09\n",
      "for 2019-11-18, MAE is:6.44 & sMAPE is:15.51% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 24.41% & 1.09\n",
      "for 2019-11-19, MAE is:9.44 & sMAPE is:20.45% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 24.40% & 1.09\n",
      "for 2019-11-20, MAE is:3.89 & sMAPE is:7.32% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 24.35% & 1.09\n",
      "for 2019-11-21, MAE is:3.88 & sMAPE is:7.77% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 24.30% & 1.09\n",
      "for 2019-11-22, MAE is:3.77 & sMAPE is:8.22% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.25% & 1.09\n",
      "for 2019-11-23, MAE is:3.52 & sMAPE is:11.95% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 24.21% & 1.09\n",
      "for 2019-11-24, MAE is:9.95 & sMAPE is:32.68% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.23% & 1.09\n",
      "for 2019-11-25, MAE is:7.15 & sMAPE is:15.10% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.21% & 1.08\n",
      "for 2019-11-26, MAE is:6.14 & sMAPE is:11.41% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 24.17% & 1.08\n",
      "for 2019-11-27, MAE is:6.39 & sMAPE is:15.88% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 24.14% & 1.08\n",
      "for 2019-11-28, MAE is:6.77 & sMAPE is:27.78% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 24.15% & 1.08\n",
      "for 2019-11-29, MAE is:6.86 & sMAPE is:19.94% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 24.14% & 1.08\n",
      "for 2019-11-30, MAE is:4.19 & sMAPE is:10.57% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 24.10% & 1.08\n",
      "for 2019-12-01, MAE is:4.19 & sMAPE is:10.39% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 24.06% & 1.07\n",
      "for 2019-12-02, MAE is:4.57 & sMAPE is:9.08% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 24.02% & 1.07\n",
      "for 2019-12-03, MAE is:7.92 & sMAPE is:15.99% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 23.99% & 1.07\n",
      "for 2019-12-04, MAE is:6.81 & sMAPE is:15.91% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :7.36 & 23.97% & 1.07\n",
      "for 2019-12-05, MAE is:11.90 & sMAPE is:24.84% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 23.97% & 1.07\n",
      "for 2019-12-06, MAE is:5.27 & sMAPE is:18.54% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 23.95% & 1.07\n",
      "for 2019-12-07, MAE is:9.90 & sMAPE is:74.57% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 24.10% & 1.07\n",
      "for 2019-12-08, MAE is:35.57 & sMAPE is:178.54% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 24.55% & 1.07\n",
      "for 2019-12-09, MAE is:9.97 & sMAPE is:44.74% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 24.61% & 1.07\n",
      "for 2019-12-10, MAE is:13.84 & sMAPE is:48.97% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 24.68% & 1.07\n",
      "for 2019-12-11, MAE is:8.67 & sMAPE is:42.17% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.73% & 1.07\n",
      "for 2019-12-12, MAE is:6.59 & sMAPE is:15.21% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.71% & 1.07\n",
      "for 2019-12-13, MAE is:3.29 & sMAPE is:11.01% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 24.67% & 1.07\n",
      "for 2019-12-14, MAE is:13.17 & sMAPE is:46.53% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.73% & 1.07\n",
      "for 2019-12-15, MAE is:8.57 & sMAPE is:109.58% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.97% & 1.06\n",
      "for 2019-12-16, MAE is:7.02 & sMAPE is:16.53% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 24.95% & 1.06\n",
      "for 2019-12-17, MAE is:15.33 & sMAPE is:33.50% & rMAE is:2.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 24.97% & 1.07\n",
      "for 2019-12-18, MAE is:6.27 & sMAPE is:19.77% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 24.96% & 1.07\n",
      "for 2019-12-19, MAE is:5.47 & sMAPE is:14.59% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.93% & 1.07\n",
      "for 2019-12-20, MAE is:7.54 & sMAPE is:21.30% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.92% & 1.06\n",
      "for 2019-12-21, MAE is:5.23 & sMAPE is:23.73% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.92% & 1.06\n",
      "for 2019-12-22, MAE is:6.74 & sMAPE is:33.73% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 24.94% & 1.06\n",
      "for 2019-12-23, MAE is:7.51 & sMAPE is:58.50% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 25.03% & 1.06\n",
      "for 2019-12-24, MAE is:5.58 & sMAPE is:66.11% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 25.15% & 1.06\n",
      "for 2019-12-25, MAE is:5.14 & sMAPE is:28.96% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 25.16% & 1.06\n",
      "for 2019-12-26, MAE is:3.82 & sMAPE is:12.95% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 25.13% & 1.06\n",
      "for 2019-12-27, MAE is:2.92 & sMAPE is:7.51% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 25.08% & 1.05\n",
      "for 2019-12-28, MAE is:5.73 & sMAPE is:18.32% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 25.06% & 1.05\n",
      "for 2019-12-29, MAE is:2.51 & sMAPE is:8.42% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 25.01% & 1.05\n",
      "for 2019-12-30, MAE is:7.39 & sMAPE is:35.14% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 25.04% & 1.05\n",
      "for 2019-12-31, MAE is:15.71 & sMAPE is:74.75% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 25.18% & 1.05\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:30:46,825]\u001b[0m A new study created in RDB with name: DE_2020\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:09,842]\u001b[0m Trial 3 finished with value: 9.19976769916172 and parameters: {'n_hidden': 4, 'learning_rate': 0.08326506642040814, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35511992786608065, 'dropout_rate_Layer_2': 0.03643042008964246, 'dropout_rate_Layer_3': 0.29272109036020233, 'dropout_rate_Layer_4': 0.12212211493759538, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.00010658990516940103, 'l1_Layer_2': 0.0008572925378237564, 'l1_Layer_3': 0.0002968700637540273, 'l1_Layer_4': 0.0957134454311848, 'n_units_Layer_1': 250, 'n_units_Layer_2': 90, 'n_units_Layer_3': 110, 'n_units_Layer_4': 150}. Best is trial 3 with value: 9.19976769916172.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 9.20 | sMAPE for Validation Set is: 26.79% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 14.03 | sMAPE for Test Set is: 46.27% | rMAE for Test Set is: 1.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:31:10,110]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 53.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:25,143]\u001b[0m Trial 1 finished with value: 6.9589461308173854 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005591637891039852, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11852022612035343, 'dropout_rate_Layer_2': 0.14854208537278688, 'dropout_rate_Layer_3': 0.06529411507417007, 'dropout_rate_Layer_4': 0.30154598546137756, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0999709703639185, 'l1_Layer_2': 2.031316605059322e-05, 'l1_Layer_3': 3.336738381937634e-05, 'l1_Layer_4': 9.298599771183442e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 255, 'n_units_Layer_3': 100, 'n_units_Layer_4': 70}. Best is trial 1 with value: 6.9589461308173854.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.96 | sMAPE for Validation Set is: 22.32% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 8.12 | sMAPE for Test Set is: 33.18% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:31:28,061]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:28,584]\u001b[0m Trial 2 finished with value: 6.947372738227275 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005095273801399254, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3080848316755157, 'dropout_rate_Layer_2': 0.37340105823214736, 'dropout_rate_Layer_3': 0.34642064344245305, 'dropout_rate_Layer_4': 0.2133411114562465, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.005888392341119136, 'l1_Layer_2': 0.005746330566142922, 'l1_Layer_3': 0.0048903574330954125, 'l1_Layer_4': 4.843501417694722e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 220, 'n_units_Layer_3': 115, 'n_units_Layer_4': 205}. Best is trial 2 with value: 6.947372738227275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.29 | sMAPE for Test Set is: 30.87% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:31:33,678]\u001b[0m Trial 5 finished with value: 7.403316110312605 and parameters: {'n_hidden': 4, 'learning_rate': 0.002465949573029799, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05197680729768442, 'dropout_rate_Layer_2': 0.36741925635689165, 'dropout_rate_Layer_3': 0.3836381675881171, 'dropout_rate_Layer_4': 0.16530159873538267, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 1.0177831617108677e-05, 'l1_Layer_2': 1.104657233363945e-05, 'l1_Layer_3': 0.011511402650993444, 'l1_Layer_4': 0.009059666188145047, 'n_units_Layer_1': 55, 'n_units_Layer_2': 80, 'n_units_Layer_3': 290, 'n_units_Layer_4': 225}. Best is trial 2 with value: 6.947372738227275.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.40 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 10.67 | sMAPE for Test Set is: 39.51% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:31:36,187]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:37,652]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:39,474]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:40,322]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:43,972]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:45,797]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:46,339]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:50,217]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:50,503]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:54,829]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:55,250]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:57,715]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:31:59,149]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:05,334]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:05,453]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:05,517]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:05,896]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:15,938]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:16,214]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:18,163]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:18,994]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:25,232]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:28,472]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:30,827]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:32,758]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:36,109]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:39,347]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:41,471]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:45,120]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:48,566]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:52,163]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:54,176]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:32:59,252]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:01,601]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:03,587]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:06,654]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:07,955]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:09,923]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:10,970]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:13,775]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:15,599]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:16,990]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:21,208]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:28,372]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:28,877]\u001b[0m Trial 27 finished with value: 6.648401722284017 and parameters: {'n_hidden': 3, 'learning_rate': 0.00054421699393812, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2172977729377574, 'dropout_rate_Layer_2': 0.026675842517530902, 'dropout_rate_Layer_3': 0.16281275269341042, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.024499357495600768, 'l1_Layer_2': 4.861292199290054e-05, 'l1_Layer_3': 6.700666380137896e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 60}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.65 | sMAPE for Validation Set is: 21.95% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 7.54 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:33:29,205]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:35,684]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:37,230]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:41,061]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:43,033]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:45,405]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:45,405]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:48,051]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:49,259]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:54,355]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:55,004]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:33:59,932]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:01,930]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:06,308]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:08,501]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:08,760]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:14,516]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:14,775]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:14,902]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:21,803]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:22,219]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 23.43% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 10.76 | sMAPE for Test Set is: 39.12% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:34:22,578]\u001b[0m Trial 66 finished with value: 7.670257249713166 and parameters: {'n_hidden': 3, 'learning_rate': 0.009244338568136778, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.141921326160634, 'dropout_rate_Layer_2': 0.03803281759271071, 'dropout_rate_Layer_3': 0.13637022232552207, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.00014972194059749964, 'l1_Layer_2': 0.001789981476235854, 'l1_Layer_3': 1.838409301817892e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 255, 'n_units_Layer_3': 80}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:26,965]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:34,341]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:36,862]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:37,277]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:37,421]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:42,568]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:45,180]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:49,091]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:50,996]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:51,602]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:57,146]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:34:57,371]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:02,484]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:03,194]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:03,636]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:09,148]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:11,515]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:16,062]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:16,611]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:18,162]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:22,993]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:23,672]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:27,681]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:32,690]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:33,112]\u001b[0m Trial 77 finished with value: 7.206720648016121 and parameters: {'n_hidden': 4, 'learning_rate': 0.032686684523712685, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14789378926570773, 'dropout_rate_Layer_2': 0.21167441500379694, 'dropout_rate_Layer_3': 0.39541815130348656, 'dropout_rate_Layer_4': 0.04612844888100618, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 3.649848759817652e-05, 'l1_Layer_2': 0.0004517622340536122, 'l1_Layer_3': 0.009058152325165731, 'l1_Layer_4': 0.053236804214674756, 'n_units_Layer_1': 80, 'n_units_Layer_2': 245, 'n_units_Layer_3': 290, 'n_units_Layer_4': 100}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.21 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 7.84 | sMAPE for Test Set is: 32.47% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:35:33,894]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:33,988]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:39,911]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:43,361]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:44,243]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:48,682]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:48,764]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:49,442]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:56,879]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:57,147]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:35:57,930]\u001b[0m Trial 103 finished with value: 7.340551385968314 and parameters: {'n_hidden': 3, 'learning_rate': 0.03823192436977004, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21162905461209308, 'dropout_rate_Layer_2': 0.13464262450555875, 'dropout_rate_Layer_3': 0.005512688784274494, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.05320053825512645, 'l1_Layer_2': 0.00010632774576362062, 'l1_Layer_3': 0.00872598636725287, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 195}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.34 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 9.57 | sMAPE for Test Set is: 36.34% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:36:02,133]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:03,099]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:06,085]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:10,172]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:10,344]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:10,936]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:20,515]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:20,830]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:26,135]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:27,069]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:29,698]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:30,473]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:31,912]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:36,267]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:38,741]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:39,095]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:39,187]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:39,621]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:47,319]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:48,744]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:50,468]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:51,530]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:53,834]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:55,894]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:36:58,943]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:03,681]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:06,544]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:06,767]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:10,854]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:15,145]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:15,612]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:16,041]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:21,899]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:25,085]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:26,175]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:26,943]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:29,045]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:31,244]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:33,339]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:34,118]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:38,312]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:39,203]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:44,325]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:44,573]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:44,943]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:50,259]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:50,747]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:51,139]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:52,886]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:37:57,486]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:03,387]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:07,340]\u001b[0m Trial 161 finished with value: 8.499768347926645 and parameters: {'n_hidden': 3, 'learning_rate': 0.011023156356134418, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32336779894852713, 'dropout_rate_Layer_2': 0.13773650494905543, 'dropout_rate_Layer_3': 0.243436084109521, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000417269170749496, 'l1_Layer_2': 0.0002121839506511688, 'l1_Layer_3': 0.00061494518322913, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 70}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.50 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.83\n",
      "MAE for Test Set is: 10.74 | sMAPE for Test Set is: 39.24% | rMAE for Test Set is: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:38:09,316]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:10,942]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:15,371]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:15,449]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:22,902]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:24,653]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:32,409]\u001b[0m Trial 159 finished with value: 6.894917513973442 and parameters: {'n_hidden': 3, 'learning_rate': 0.001842112899831674, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2554234672297603, 'dropout_rate_Layer_2': 0.21514593340439983, 'dropout_rate_Layer_3': 0.24618099642296432, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00037766682345848735, 'l1_Layer_2': 0.007936571200152481, 'l1_Layer_3': 0.00039278985774513853, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 95}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 8.06 | sMAPE for Test Set is: 33.03% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:38:32,834]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:38,861]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:41,009]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:44,180]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:48,317]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:52,891]\u001b[0m Trial 174 finished with value: 7.567166496113468 and parameters: {'n_hidden': 3, 'learning_rate': 0.023686572034436113, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24279720232867452, 'dropout_rate_Layer_2': 0.19727718148626938, 'dropout_rate_Layer_3': 0.1942435325850107, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.096357370685454e-05, 'l1_Layer_2': 1.7117554941899527e-05, 'l1_Layer_3': 0.0011872281528709273, 'n_units_Layer_1': 250, 'n_units_Layer_2': 145, 'n_units_Layer_3': 60}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.57 | sMAPE for Validation Set is: 23.33% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 9.89 | sMAPE for Test Set is: 37.45% | rMAE for Test Set is: 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:38:53,934]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:38:57,951]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:11,052]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:14,167]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:15,825]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:19,691]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:19,965]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:25,804]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:36,982]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:39,315]\u001b[0m Trial 164 finished with value: 6.744245246762005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016305819042561154, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.35088539688393977, 'dropout_rate_Layer_2': 0.2897970503258262, 'dropout_rate_Layer_3': 0.2484690807390483, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016103208074962844, 'l1_Layer_2': 0.009598283061126247, 'l1_Layer_3': 0.038009406653010114, 'n_units_Layer_1': 180, 'n_units_Layer_2': 140, 'n_units_Layer_3': 65}. Best is trial 27 with value: 6.648401722284017.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.74 | sMAPE for Validation Set is: 22.02% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 7.86 | sMAPE for Test Set is: 32.45% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:39:41,844]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:41,868]\u001b[0m Trial 172 finished with value: 6.103335653209931 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010657934914029656, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24557155606760495, 'dropout_rate_Layer_2': 0.193103838484614, 'dropout_rate_Layer_3': 0.006442810723479103, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003757300140403017, 'l1_Layer_2': 0.0071452943966901685, 'l1_Layer_3': 6.124723647369365e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 85}. Best is trial 172 with value: 6.103335653209931.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 20.46% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 30.50% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:39:42,078]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:49,194]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:55,525]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:39:56,149]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:00,451]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:02,821]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:05,481]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:08,804]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:09,912]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:14,045]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:15,280]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:19,853]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:23,081]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:30,282]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:32,012]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:35,802]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:38,847]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:41,601]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:41,649]\u001b[0m Trial 187 finished with value: 6.992885262051551 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014550537001479828, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3865423252462312, 'dropout_rate_Layer_2': 0.1951893284086184, 'dropout_rate_Layer_3': 0.3619609955576644, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.636872040979506e-05, 'l1_Layer_2': 0.007289298518234461, 'l1_Layer_3': 0.00018028489037081306, 'n_units_Layer_1': 200, 'n_units_Layer_2': 235, 'n_units_Layer_3': 80}. Best is trial 172 with value: 6.103335653209931.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.99 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 7.93 | sMAPE for Test Set is: 33.01% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:40:47,677]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:48,162]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:49,319]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:54,353]\u001b[0m Trial 194 finished with value: 6.405878035840433 and parameters: {'n_hidden': 3, 'learning_rate': 0.001555527926728209, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2314371613126726, 'dropout_rate_Layer_2': 0.3808095331394131, 'dropout_rate_Layer_3': 0.0016830786424933408, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.5652637707902053e-05, 'l1_Layer_2': 0.003455403830425599, 'l1_Layer_3': 0.000182613807237686, 'n_units_Layer_1': 260, 'n_units_Layer_2': 210, 'n_units_Layer_3': 80}. Best is trial 172 with value: 6.103335653209931.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 21.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.92 | sMAPE for Test Set is: 30.49% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:40:58,307]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:40:59,036]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:03,327]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:03,804]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:07,037]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:07,633]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:09,460]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:09,804]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:11,823]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:15,418]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:19,393]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:21,225]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:22,983]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:24,113]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:28,742]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:28,991]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:29,382]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:31,607]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:36,000]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:37,603]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:40,369]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:41,782]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:42,442]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:44,205]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:46,968]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:48,302]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:52,262]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:53,085]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:54,601]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:41:54,923]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:01,977]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:04,655]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:08,176]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:12,174]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:12,469]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:17,720]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:18,796]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:23,450]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:26,880]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:35,108]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:41,777]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:42:59,792]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:43:05,275]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:44:01,549]\u001b[0m Trial 243 finished with value: 6.133705746485146 and parameters: {'n_hidden': 3, 'learning_rate': 0.000829075363422279, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3932460656178823, 'dropout_rate_Layer_2': 0.23481260718471453, 'dropout_rate_Layer_3': 0.3646919488837755, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.9168429657735436e-05, 'l1_Layer_2': 0.004486226874570328, 'l1_Layer_3': 0.00040555507273565413, 'n_units_Layer_1': 200, 'n_units_Layer_2': 210, 'n_units_Layer_3': 125}. Best is trial 172 with value: 6.103335653209931.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 20.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.01 | sMAPE for Test Set is: 30.50% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:44:05,367]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:44:09,935]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:44:44,736]\u001b[0m Trial 255 finished with value: 6.45958204060016 and parameters: {'n_hidden': 3, 'learning_rate': 0.001895662445752784, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22730466653194714, 'dropout_rate_Layer_2': 0.3096759755895799, 'dropout_rate_Layer_3': 0.05070808031089228, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.821082999067757e-05, 'l1_Layer_2': 0.002681468188497048, 'l1_Layer_3': 0.00011678408645920787, 'n_units_Layer_1': 200, 'n_units_Layer_2': 195, 'n_units_Layer_3': 70}. Best is trial 172 with value: 6.103335653209931.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 21.62% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 30.12% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:44:46,928]\u001b[0m Trial 250 finished with value: 5.83074648218448 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007243333669462366, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24991722865017818, 'dropout_rate_Layer_2': 0.0483331302271707, 'dropout_rate_Layer_3': 0.0042781668999082225, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.006039009308949788, 'l1_Layer_2': 0.0018404293332025996, 'l1_Layer_3': 0.004012195630143818, 'n_units_Layer_1': 170, 'n_units_Layer_2': 70, 'n_units_Layer_3': 70}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:44:50,411]\u001b[0m Trial 258 finished with value: 7.116292084752959 and parameters: {'n_hidden': 3, 'learning_rate': 0.003667882422311243, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11913724426883684, 'dropout_rate_Layer_2': 0.021399114357827292, 'dropout_rate_Layer_3': 0.21607765051758251, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.393234188736298e-05, 'l1_Layer_2': 0.0012379568598887834, 'l1_Layer_3': 1.0280040791361018e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.12 | sMAPE for Validation Set is: 24.22% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 7.62 | sMAPE for Test Set is: 32.66% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:45:02,621]\u001b[0m Trial 249 finished with value: 5.875169682493868 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006991660207145899, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3936347864489107, 'dropout_rate_Layer_2': 0.05618857152993384, 'dropout_rate_Layer_3': 0.30714501706442315, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005448805742240146, 'l1_Layer_2': 0.001463873779178221, 'l1_Layer_3': 0.003735020467751191, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 180}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.74% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.32 | sMAPE for Test Set is: 31.11% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:45:15,262]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:45:46,181]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:45:53,448]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:46:10,814]\u001b[0m Trial 259 finished with value: 6.251895927468271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014312383138912225, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24024156455347878, 'dropout_rate_Layer_2': 0.3029793502826568, 'dropout_rate_Layer_3': 0.10034409139431977, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014250730975141787, 'l1_Layer_2': 0.002903456505485284, 'l1_Layer_3': 0.00011342993112095077, 'n_units_Layer_1': 200, 'n_units_Layer_2': 195, 'n_units_Layer_3': 85}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 20.94% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 30.04% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:46:33,004]\u001b[0m Trial 261 finished with value: 6.204078550636908 and parameters: {'n_hidden': 3, 'learning_rate': 0.001900537308238473, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23980451392075758, 'dropout_rate_Layer_2': 0.32095342608592353, 'dropout_rate_Layer_3': 0.11643240813169586, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020808061850705983, 'l1_Layer_2': 0.0028779353318561483, 'l1_Layer_3': 8.440098044764888e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 195, 'n_units_Layer_3': 120}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 21.46% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 30.30% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:46:33,645]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:46:40,937]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:46:48,591]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:46:52,076]\u001b[0m Trial 263 finished with value: 6.227775800540155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008585422733170566, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0030413788311764306, 'dropout_rate_Layer_2': 0.3093081951597716, 'dropout_rate_Layer_3': 0.047795999755917105, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011340952506117191, 'l1_Layer_2': 0.0030746903036863774, 'l1_Layer_3': 0.00010273064966944492, 'n_units_Layer_1': 200, 'n_units_Layer_2': 190, 'n_units_Layer_3': 85}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 21.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 29.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:46:56,747]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:46:58,845]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:47:02,026]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:47:18,258]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:47:25,979]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:47:42,754]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:48:14,979]\u001b[0m Trial 273 finished with value: 6.407457251146131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019196147717374977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006622243031453839, 'dropout_rate_Layer_2': 0.301486177420119, 'dropout_rate_Layer_3': 0.09081909254709004, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019010872321813724, 'l1_Layer_2': 0.0017451753549372632, 'l1_Layer_3': 0.00011527374289637393, 'n_units_Layer_1': 175, 'n_units_Layer_2': 195, 'n_units_Layer_3': 110}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 21.76% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 29.91% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:48:19,617]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:48:26,827]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:48:30,975]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:48:38,271]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:48:56,954]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:49:00,861]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:49:46,500]\u001b[0m Trial 279 finished with value: 6.174070362309741 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008849542594066216, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025732857649266493, 'dropout_rate_Layer_2': 0.2951876901236792, 'dropout_rate_Layer_3': 0.062056170910253346, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030636669815762706, 'l1_Layer_2': 0.0018614997180492632, 'l1_Layer_3': 3.383769217121608e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 115}. Best is trial 250 with value: 5.83074648218448.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 20.56% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 30.11% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:49:56,351]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:50:01,118]\u001b[0m Trial 282 finished with value: 5.789218493728609 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005409354883120707, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08919947371940405, 'dropout_rate_Layer_2': 0.067510081460839, 'dropout_rate_Layer_3': 0.2537178293504784, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.017292462542010688, 'l1_Layer_2': 0.0007543629600167196, 'l1_Layer_3': 0.0007286353590688672, 'n_units_Layer_1': 165, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 28.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:50:08,528]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:50:23,234]\u001b[0m Trial 284 finished with value: 6.245595893574051 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027327540463182535, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01818895346721312, 'dropout_rate_Layer_2': 0.29120388179060036, 'dropout_rate_Layer_3': 0.06371223096275044, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021735716262561504, 'l1_Layer_2': 0.0023254610245041054, 'l1_Layer_3': 8.182310677839393e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 195, 'n_units_Layer_3': 135}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 20.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 30.79% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:50:32,957]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:50:59,462]\u001b[0m Trial 277 finished with value: 6.027827156893285 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006964451205477905, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20882386857278312, 'dropout_rate_Layer_2': 0.2938529419594846, 'dropout_rate_Layer_3': 0.05973635481438719, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020295964243091083, 'l1_Layer_2': 0.0018984829923809291, 'l1_Layer_3': 0.00012079599093984617, 'n_units_Layer_1': 175, 'n_units_Layer_2': 190, 'n_units_Layer_3': 110}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 20.77% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 29.66% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:51:32,825]\u001b[0m Trial 288 finished with value: 6.131375630764599 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008717142135619716, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023859895972572792, 'dropout_rate_Layer_2': 0.3110760374839827, 'dropout_rate_Layer_3': 0.09264582292023818, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021269506311210394, 'l1_Layer_2': 0.001970421158555289, 'l1_Layer_3': 6.164422066743381e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.91 | sMAPE for Test Set is: 30.32% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:51:36,228]\u001b[0m Trial 286 finished with value: 6.214902297830282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007217794844773364, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024214226596103623, 'dropout_rate_Layer_2': 0.31073454655718286, 'dropout_rate_Layer_3': 0.09995542861087099, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032232191848508723, 'l1_Layer_2': 0.0019459202279271707, 'l1_Layer_3': 2.377364595640061e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.21 | sMAPE for Validation Set is: 21.11% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 29.70% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:51:40,741]\u001b[0m Trial 291 finished with value: 6.02925778693001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008638997937179647, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15525530436864166, 'dropout_rate_Layer_2': 0.07505933104843705, 'dropout_rate_Layer_3': 0.2607066370325164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.01574467364975579, 'l1_Layer_2': 0.0006663583735920451, 'l1_Layer_3': 0.0008406613917993402, 'n_units_Layer_1': 210, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 20.19% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 30.37% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:51:46,100]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:51:46,548]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:51:51,460]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:51:53,866]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:51:59,401]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:52:08,465]\u001b[0m Trial 290 finished with value: 6.035715021501318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007251779366830319, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015867497092051076, 'dropout_rate_Layer_2': 0.30933167554752755, 'dropout_rate_Layer_3': 0.07988220465184236, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021600028646287934, 'l1_Layer_2': 0.0019959808507817576, 'l1_Layer_3': 0.00013131315693782353, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 20.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:52:50,094]\u001b[0m Trial 298 finished with value: 5.83231640511038 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009338693154814025, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10216957936286665, 'dropout_rate_Layer_2': 0.10365982829325363, 'dropout_rate_Layer_3': 0.25749235667703496, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.008857167404998256, 'l1_Layer_2': 0.0007907203178279873, 'l1_Layer_3': 0.0005813881023112807, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 145}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 29.87% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:53:44,673]\u001b[0m Trial 299 finished with value: 6.089132277528917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005618778636121915, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03591522422546496, 'dropout_rate_Layer_2': 0.2952239305124078, 'dropout_rate_Layer_3': 0.10311602321741997, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025078538741669487, 'l1_Layer_2': 0.001457691624811359, 'l1_Layer_3': 3.506454187189706e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 200, 'n_units_Layer_3': 115}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 20.65% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 30.09% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:53:47,038]\u001b[0m Trial 300 finished with value: 5.953823414436738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005541373030727832, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0336271412594763, 'dropout_rate_Layer_2': 0.2918052847268738, 'dropout_rate_Layer_3': 0.06386025240340767, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025003636050246423, 'l1_Layer_2': 0.0013637042038137106, 'l1_Layer_3': 3.464443532664341e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 20.23% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:53:49,192]\u001b[0m Trial 292 finished with value: 6.061926729264886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005498097151563259, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021249250044916367, 'dropout_rate_Layer_2': 0.2969494993176907, 'dropout_rate_Layer_3': 0.0828701079937687, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022688659737667299, 'l1_Layer_2': 0.0021076018609579865, 'l1_Layer_3': 3.495601002796253e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 29.76% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:54:26,993]\u001b[0m Trial 304 finished with value: 6.418423415158273 and parameters: {'n_hidden': 3, 'learning_rate': 0.005837375374961517, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23523480771290237, 'dropout_rate_Layer_2': 0.09987075166894203, 'dropout_rate_Layer_3': 0.13998996507197783, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002937720777462964, 'l1_Layer_2': 4.732827800799887e-05, 'l1_Layer_3': 0.0074434176853430956, 'n_units_Layer_1': 265, 'n_units_Layer_2': 80, 'n_units_Layer_3': 55}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 21.57% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 31.54% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:55:05,414]\u001b[0m Trial 301 finished with value: 6.016778993067337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005759800342382787, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03221605742469372, 'dropout_rate_Layer_2': 0.29472420526341403, 'dropout_rate_Layer_3': 0.0638839336487243, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00030996916861640616, 'l1_Layer_2': 0.001448061420610854, 'l1_Layer_3': 3.1855771733628824e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:55:39,115]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:56:05,063]\u001b[0m Trial 302 finished with value: 5.995356123178254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005675104975908478, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032814025233727354, 'dropout_rate_Layer_2': 0.29782276876915337, 'dropout_rate_Layer_3': 0.1019001386988948, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002865148465592153, 'l1_Layer_2': 0.002004033272369899, 'l1_Layer_3': 2.477067840844719e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 20.59% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 29.30% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:56:17,845]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:56:58,625]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:57:21,342]\u001b[0m Trial 307 finished with value: 6.06353097827963 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005612390499300665, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012374336253736764, 'dropout_rate_Layer_2': 0.2996573825122733, 'dropout_rate_Layer_3': 0.06812811080450477, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003133709089220419, 'l1_Layer_2': 0.0013753013434770862, 'l1_Layer_3': 2.9249590159153514e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.64% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.75 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:57:27,937]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:57:32,995]\u001b[0m Trial 306 finished with value: 6.014769699009105 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005754636535276422, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03637449388488963, 'dropout_rate_Layer_2': 0.2977007424909631, 'dropout_rate_Layer_3': 0.10064464866671605, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003072343696910473, 'l1_Layer_2': 0.0013945046087009833, 'l1_Layer_3': 3.6402974316405206e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 20.48% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 29.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:57:47,011]\u001b[0m Trial 308 finished with value: 6.117034657165317 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005394013406025479, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06610023986310873, 'dropout_rate_Layer_2': 0.2943006233624236, 'dropout_rate_Layer_3': 0.0632858590848445, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000235334683552907, 'l1_Layer_2': 0.0013729842761808155, 'l1_Layer_3': 1.8370684941202164e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 20.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.80 | sMAPE for Test Set is: 29.64% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:58:11,895]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:58:53,686]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:58:56,108]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:59:04,701]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:59:30,350]\u001b[0m Trial 314 finished with value: 6.315902049540919 and parameters: {'n_hidden': 3, 'learning_rate': 0.00672115132931786, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21784173443813648, 'dropout_rate_Layer_2': 0.12411920433159558, 'dropout_rate_Layer_3': 0.15725214959338618, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.5336056704100035e-05, 'l1_Layer_2': 6.013501778827734e-05, 'l1_Layer_3': 0.00794137522969594, 'n_units_Layer_1': 290, 'n_units_Layer_2': 170, 'n_units_Layer_3': 55}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 21.20% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.80 | sMAPE for Test Set is: 33.12% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 19:59:50,256]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 19:59:56,369]\u001b[0m Trial 316 finished with value: 6.465193976994667 and parameters: {'n_hidden': 3, 'learning_rate': 0.005579167346829479, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38497213453361556, 'dropout_rate_Layer_2': 0.12595062325999878, 'dropout_rate_Layer_3': 0.15975246796222448, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.484465033356635e-05, 'l1_Layer_2': 4.9496705926257826e-05, 'l1_Layer_3': 0.002846116442864505, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 55}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.47 | sMAPE for Validation Set is: 21.94% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 32.63% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:00:17,406]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:00:34,786]\u001b[0m Trial 313 finished with value: 6.158898015108161 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005770396399531458, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016338799238989846, 'dropout_rate_Layer_2': 0.28327956948781013, 'dropout_rate_Layer_3': 0.11790119240564416, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003307027222491806, 'l1_Layer_2': 0.0010641523916530976, 'l1_Layer_3': 1.6852892256705136e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 20.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 29.92% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:00:49,658]\u001b[0m Trial 321 finished with value: 6.379016665688663 and parameters: {'n_hidden': 3, 'learning_rate': 0.006831130418351602, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39662952513852123, 'dropout_rate_Layer_2': 0.10453971010636953, 'dropout_rate_Layer_3': 0.15952921514609575, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.891572491333616e-05, 'l1_Layer_2': 3.479699389796343e-05, 'l1_Layer_3': 0.007827983967924373, 'n_units_Layer_1': 295, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 20.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 8.12 | sMAPE for Test Set is: 33.00% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:00:51,784]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:01:31,653]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:01:34,876]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:01:55,176]\u001b[0m Trial 325 finished with value: 6.50649049917413 and parameters: {'n_hidden': 3, 'learning_rate': 0.006262042274407978, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.38353264387969255, 'dropout_rate_Layer_2': 0.10499154926299709, 'dropout_rate_Layer_3': 0.15346492869919057, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.46673487350862e-05, 'l1_Layer_2': 5.966368905173513e-05, 'l1_Layer_3': 0.002778156767491264, 'n_units_Layer_1': 295, 'n_units_Layer_2': 85, 'n_units_Layer_3': 55}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 21.37% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 31.67% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:02:04,032]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:02:12,553]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:02:13,936]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:02:28,855]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:02:46,056]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:02:54,486]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:02:56,510]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:03:03,195]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:03:05,050]\u001b[0m Trial 322 finished with value: 5.9121320128099555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005179970240040256, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05839991131526608, 'dropout_rate_Layer_2': 0.31912600196023544, 'dropout_rate_Layer_3': 0.07880853641597044, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045454774167520435, 'l1_Layer_2': 0.00114180379549698, 'l1_Layer_3': 1.917004851811832e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 180, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.91 | sMAPE for Validation Set is: 20.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 29.65% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:03:33,402]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:03:42,287]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:03:43,492]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:03:45,319]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:04:01,584]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:04:25,277]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:04:40,653]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:04:48,240]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:04:52,199]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:05:03,775]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:05:09,500]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:05:29,452]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:05:50,546]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:05:57,321]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:06:15,815]\u001b[0m Trial 343 finished with value: 6.044034682483026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006152710772596214, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00019701902936092308, 'dropout_rate_Layer_2': 0.30385001250213084, 'dropout_rate_Layer_3': 0.1063583288966952, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004185657535889572, 'l1_Layer_2': 0.0011562306350744876, 'l1_Layer_3': 5.532702965533353e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 190, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 20.71% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 29.12% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:06:52,974]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:07:19,732]\u001b[0m Trial 346 finished with value: 5.983629548737999 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006182190692976218, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.055194663590932606, 'dropout_rate_Layer_2': 0.2754937320546222, 'dropout_rate_Layer_3': 0.04496455476260608, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00041159152008061627, 'l1_Layer_2': 0.0008418477627531906, 'l1_Layer_3': 2.762085143489057e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 175, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 20.13% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:07:36,231]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:07:46,563]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:07:54,038]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:07:59,801]\u001b[0m Trial 349 finished with value: 6.0547074672067795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005600654762524334, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04837861159408072, 'dropout_rate_Layer_2': 0.27714544467866326, 'dropout_rate_Layer_3': 0.04689140077940017, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015215704995128783, 'l1_Layer_2': 0.0018247286311803659, 'l1_Layer_3': 4.025383365331154e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 200, 'n_units_Layer_3': 135}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 20.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 29.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:08:07,146]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:08:12,287]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:08:18,799]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:08:21,247]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:08:23,827]\u001b[0m Trial 353 finished with value: 6.062919744027422 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008808087515547503, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001007270557146292, 'dropout_rate_Layer_2': 0.3077112247687433, 'dropout_rate_Layer_3': 0.04560125146887563, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003978318733571514, 'l1_Layer_2': 0.0012314477713016646, 'l1_Layer_3': 4.957107128838056e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 190, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:08:26,690]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:09:06,832]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:09:10,633]\u001b[0m Trial 364 finished with value: 6.50485010147622 and parameters: {'n_hidden': 3, 'learning_rate': 0.00551987124703859, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21065646280690817, 'dropout_rate_Layer_2': 0.15126689720980735, 'dropout_rate_Layer_3': 0.139321051481776, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.3407896512396576e-05, 'l1_Layer_2': 0.00010862337858651661, 'l1_Layer_3': 0.0015538955618694065, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 50}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 22.36% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 7.91 | sMAPE for Test Set is: 33.57% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:09:14,140]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:09:27,213]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:10:27,030]\u001b[0m Trial 362 finished with value: 5.964292419626337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006367020961578199, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04035181298869173, 'dropout_rate_Layer_2': 0.276533332087863, 'dropout_rate_Layer_3': 0.04362802435999906, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019298820507816214, 'l1_Layer_2': 0.0015567636467787617, 'l1_Layer_3': 3.550860050853364e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 20.53% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:10:30,462]\u001b[0m Trial 367 finished with value: 6.094818482924829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006572148357462625, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12947932053509723, 'dropout_rate_Layer_2': 0.015002393981672857, 'dropout_rate_Layer_3': 0.2017994989153873, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00268249887853605, 'l1_Layer_2': 0.0008062663331329534, 'l1_Layer_3': 3.18418001334548e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.09 | sMAPE for Validation Set is: 20.68% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.14 | sMAPE for Test Set is: 30.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:10:45,508]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:11:30,592]\u001b[0m Trial 366 finished with value: 5.8838252920274465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006366063943642677, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1128259995367287, 'dropout_rate_Layer_2': 0.014581084592595508, 'dropout_rate_Layer_3': 0.2290550768029757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002860787405204122, 'l1_Layer_2': 0.02055468007828882, 'l1_Layer_3': 9.298977542744881e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 95, 'n_units_Layer_3': 130}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 20.25% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 29.82% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:11:51,534]\u001b[0m Trial 369 finished with value: 6.116921058789701 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012015710210099883, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1320792419839435, 'dropout_rate_Layer_2': 0.04512309380744789, 'dropout_rate_Layer_3': 0.20406865402640717, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004575870025298808, 'l1_Layer_2': 0.0007910855915204501, 'l1_Layer_3': 0.00020017825110435985, 'n_units_Layer_1': 195, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 20.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 30.17% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:12:24,093]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:12:33,527]\u001b[0m Trial 368 finished with value: 5.993989140893606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005404284659325931, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04485583195607844, 'dropout_rate_Layer_2': 0.2775076944390968, 'dropout_rate_Layer_3': 0.04500298774610992, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006803038088194584, 'l1_Layer_2': 0.0007426910785508553, 'l1_Layer_3': 4.206366420871891e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.65 | sMAPE for Test Set is: 28.91% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:12:38,068]\u001b[0m Trial 371 finished with value: 6.168551017055687 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011822000611913283, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17425800769528899, 'dropout_rate_Layer_2': 0.04821563120618257, 'dropout_rate_Layer_3': 0.23262075865842846, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0031242962093117883, 'l1_Layer_2': 0.0008253535438742945, 'l1_Layer_3': 3.582735926704258e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 95, 'n_units_Layer_3': 130}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.04 | sMAPE for Test Set is: 30.28% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:12:58,265]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:13:35,491]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:13:59,584]\u001b[0m Trial 377 finished with value: 5.924217098739338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009814206737837608, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10597156661850786, 'dropout_rate_Layer_2': 0.09366480507679685, 'dropout_rate_Layer_3': 0.25681826487519277, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025740492884751527, 'l1_Layer_2': 0.033151253229711526, 'l1_Layer_3': 0.000115262421262814, 'n_units_Layer_1': 265, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.92 | sMAPE for Validation Set is: 20.08% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.28 | sMAPE for Test Set is: 31.07% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:15:20,932]\u001b[0m Trial 379 finished with value: 6.065068900099014 and parameters: {'n_hidden': 3, 'learning_rate': 0.008251006915813153, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3891633844968946, 'dropout_rate_Layer_2': 0.07478066300143893, 'dropout_rate_Layer_3': 0.1226710222053429, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012836217126133368, 'l1_Layer_2': 0.0001914817717426598, 'l1_Layer_3': 0.007243002320534249, 'n_units_Layer_1': 135, 'n_units_Layer_2': 75, 'n_units_Layer_3': 70}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 20.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.56 | sMAPE for Test Set is: 31.69% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:15:51,519]\u001b[0m Trial 376 finished with value: 5.964479104622755 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006454185994683254, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04880148248954482, 'dropout_rate_Layer_2': 0.2645901857566262, 'dropout_rate_Layer_3': 0.029706228691185093, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000649869521565652, 'l1_Layer_2': 0.0011268309641999067, 'l1_Layer_3': 6.546844388553238e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:15:55,256]\u001b[0m Trial 378 finished with value: 6.010194125893203 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005697637638847755, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04293093386806396, 'dropout_rate_Layer_2': 0.2878598863844391, 'dropout_rate_Layer_3': 0.0466027270860911, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006695058956578021, 'l1_Layer_2': 0.0006607172765603541, 'l1_Layer_3': 2.919878316673113e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 20.39% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:16:02,326]\u001b[0m Trial 374 finished with value: 6.032643996066235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005022052775294383, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049429792141467074, 'dropout_rate_Layer_2': 0.26604116917450854, 'dropout_rate_Layer_3': 0.03137057433506597, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006634258939380507, 'l1_Layer_2': 0.001060571389193654, 'l1_Layer_3': 6.510762073838601e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 20.52% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 29.07% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:16:10,217]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:17:07,700]\u001b[0m Trial 381 finished with value: 6.238229643465533 and parameters: {'n_hidden': 3, 'learning_rate': 0.008511869547291764, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38415548053959375, 'dropout_rate_Layer_2': 0.0868180325676292, 'dropout_rate_Layer_3': 0.20560122994755753, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012136896979760593, 'l1_Layer_2': 0.00047736329720144565, 'l1_Layer_3': 0.010042287656754587, 'n_units_Layer_1': 130, 'n_units_Layer_2': 60, 'n_units_Layer_3': 60}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 20.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.30 | sMAPE for Test Set is: 31.13% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:17:21,522]\u001b[0m Trial 384 finished with value: 6.347949925487934 and parameters: {'n_hidden': 3, 'learning_rate': 0.00844506080484597, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39203224763609174, 'dropout_rate_Layer_2': 0.011833233722235756, 'dropout_rate_Layer_3': 0.20319544844280768, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.641664361998796e-05, 'l1_Layer_2': 0.0001733105418496709, 'l1_Layer_3': 0.019799738453981933, 'n_units_Layer_1': 100, 'n_units_Layer_2': 110, 'n_units_Layer_3': 70}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.35 | sMAPE for Validation Set is: 21.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 7.19 | sMAPE for Test Set is: 30.60% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:17:27,076]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:17:55,661]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:18:10,201]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:18:12,777]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:18:35,515]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:18:43,453]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:19:09,112]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:19:23,918]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:19:26,786]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:19:39,774]\u001b[0m Trial 385 finished with value: 5.979612448026515 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005071767072748365, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04440642383732555, 'dropout_rate_Layer_2': 0.27180464279338135, 'dropout_rate_Layer_3': 0.031504813395803355, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006422979337993443, 'l1_Layer_2': 0.0008538889526503098, 'l1_Layer_3': 2.840537027247111e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 160}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.98 | sMAPE for Validation Set is: 20.37% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:19:57,899]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:20:05,700]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:20:41,329]\u001b[0m Trial 390 finished with value: 5.952530235421585 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006376211116703912, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07132886390547075, 'dropout_rate_Layer_2': 0.2741423430794197, 'dropout_rate_Layer_3': 0.05050223305582939, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010633795707335571, 'l1_Layer_2': 0.0005410859364880885, 'l1_Layer_3': 3.712794034962832e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 28.60% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:20:44,560]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:20:52,822]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:20:57,572]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:21:00,887]\u001b[0m Trial 395 finished with value: 6.241766147088517 and parameters: {'n_hidden': 3, 'learning_rate': 0.006057460166526003, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39274047274315854, 'dropout_rate_Layer_2': 0.01646001498333046, 'dropout_rate_Layer_3': 0.2225460560280446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.002956923068626e-05, 'l1_Layer_2': 0.0001742654755635181, 'l1_Layer_3': 0.011270299259134925, 'n_units_Layer_1': 130, 'n_units_Layer_2': 55, 'n_units_Layer_3': 65}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 20.99% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:21:08,245]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:21:25,386]\u001b[0m Trial 389 finished with value: 5.971712277243173 and parameters: {'n_hidden': 3, 'learning_rate': 0.000647095902928896, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06778245520828045, 'dropout_rate_Layer_2': 0.2728913563363118, 'dropout_rate_Layer_3': 0.04618594806268966, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006802522263814017, 'l1_Layer_2': 0.0008598759289138727, 'l1_Layer_3': 3.824784141300436e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 160, 'n_units_Layer_3': 155}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 20.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:21:34,411]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:21:37,260]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:21:39,555]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:21:46,619]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:21:57,339]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:22:30,099]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:22:55,635]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:22:59,295]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:23:07,975]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:23:15,938]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:23:49,460]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:23:56,896]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:24:05,783]\u001b[0m Trial 404 finished with value: 5.96596800261009 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005890152679888802, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04209668831026154, 'dropout_rate_Layer_2': 0.26268263663612695, 'dropout_rate_Layer_3': 0.054946007206803225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001216975190805749, 'l1_Layer_2': 0.0009082942571196, 'l1_Layer_3': 4.822805891350703e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 20.26% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 29.87% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:24:06,630]\u001b[0m Trial 408 finished with value: 5.90395394389856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006937352401815104, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09519022119018693, 'dropout_rate_Layer_2': 0.2699321397578745, 'dropout_rate_Layer_3': 0.052986190707226745, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0011870378503189998, 'l1_Layer_2': 0.0006331974205938597, 'l1_Layer_3': 2.7130637707514924e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 20.17% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:24:14,202]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:24:15,708]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:24:39,341]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:24:47,273]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:24:57,692]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:25:41,297]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:25:51,341]\u001b[0m Trial 415 finished with value: 6.012942253916318 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005650712383803954, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031975700861987616, 'dropout_rate_Layer_2': 0.3019870340641825, 'dropout_rate_Layer_3': 0.02896990664740624, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046798608530436165, 'l1_Layer_2': 0.0005179145514095465, 'l1_Layer_3': 5.315698141212593e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 170, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 20.53% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 29.42% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:26:00,120]\u001b[0m Trial 423 finished with value: 6.202383527692471 and parameters: {'n_hidden': 3, 'learning_rate': 0.012750597052895173, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22864423922091226, 'dropout_rate_Layer_2': 0.08010488883640635, 'dropout_rate_Layer_3': 0.23960499914722336, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.348491087518684e-05, 'l1_Layer_2': 0.0002243118941144402, 'l1_Layer_3': 0.008949430418925123, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 85}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 20.73% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 29.77% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:26:08,367]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:26:15,145]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:26:15,842]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:26:57,377]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:27:06,740]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:27:24,931]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:27:25,212]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:27:39,064]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:27:47,264]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:27:51,376]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:29:24,003]\u001b[0m Trial 433 finished with value: 5.99424731922688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006919661215613615, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04178199807821797, 'dropout_rate_Layer_2': 0.3025917163421654, 'dropout_rate_Layer_3': 0.053067615078054686, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004643582823325705, 'l1_Layer_2': 0.0009698971803731161, 'l1_Layer_3': 5.113405049195677e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 20.43% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 29.64% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:29:26,907]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:29:32,419]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:29:33,187]\u001b[0m Trial 436 finished with value: 6.132339446015199 and parameters: {'n_hidden': 3, 'learning_rate': 0.004286305810325278, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3568315570340757, 'dropout_rate_Layer_2': 0.09956712201484315, 'dropout_rate_Layer_3': 0.21333489279946327, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001257869096548255, 'l1_Layer_2': 8.525838505058208e-05, 'l1_Layer_3': 0.0018236757378276899, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 21.06% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 30.03% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:30:02,251]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:30:17,251]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:30:23,731]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:30:29,848]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:30:30,671]\u001b[0m Trial 437 finished with value: 6.015460987377433 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006893491493437812, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01695802871656792, 'dropout_rate_Layer_2': 0.30215721706383963, 'dropout_rate_Layer_3': 0.054798467253013225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004676635403198766, 'l1_Layer_2': 0.00095525618959672, 'l1_Layer_3': 5.649780634590367e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 20.69% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 29.52% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:30:38,778]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:30:55,823]\u001b[0m Trial 441 finished with value: 6.115645076216268 and parameters: {'n_hidden': 3, 'learning_rate': 0.00406252793612623, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36196715567972615, 'dropout_rate_Layer_2': 0.09649803627428111, 'dropout_rate_Layer_3': 0.21640970864776166, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012278927827258403, 'l1_Layer_2': 8.482796236750981e-05, 'l1_Layer_3': 0.0018434596765717628, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 20.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.16 | sMAPE for Test Set is: 30.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:31:11,527]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:31:42,322]\u001b[0m Trial 447 finished with value: 6.231753353145759 and parameters: {'n_hidden': 3, 'learning_rate': 0.00547603771298401, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39208435169467476, 'dropout_rate_Layer_2': 0.08847636865414767, 'dropout_rate_Layer_3': 0.14864632552344206, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.477736950941912e-05, 'l1_Layer_2': 5.325033192159482e-05, 'l1_Layer_3': 0.003278369547180011, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 60}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 21.02% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 30.53% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:31:51,983]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:31:52,275]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:08,427]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:19,852]\u001b[0m Trial 446 finished with value: 5.9719420373903205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007001003505408297, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029467356306201134, 'dropout_rate_Layer_2': 0.28896279156378263, 'dropout_rate_Layer_3': 0.033722560426554915, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007127128098701338, 'l1_Layer_2': 0.0009540515801745648, 'l1_Layer_3': 4.087832444386946e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 170, 'n_units_Layer_3': 135}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 20.31% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:32:28,943]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:33,189]\u001b[0m Trial 448 finished with value: 6.027748764960488 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013854955437366517, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1550497499570352, 'dropout_rate_Layer_2': 0.053700459786972216, 'dropout_rate_Layer_3': 0.1836562876252305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0047120590583552705, 'l1_Layer_2': 0.02574475169647793, 'l1_Layer_3': 0.0003584400998739789, 'n_units_Layer_1': 285, 'n_units_Layer_2': 55, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.23 | sMAPE for Test Set is: 30.68% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:32:36,303]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:39,716]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:41,634]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:46,728]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:50,890]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:32:59,666]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:03,858]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:15,808]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:22,803]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:31,501]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:31,713]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:32,686]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:42,370]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:51,104]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:55,092]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:33:58,021]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:02,208]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:02,748]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:15,427]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:26,673]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:34,548]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:49,022]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:34:51,922]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:00,642]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:01,283]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:07,751]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:11,914]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:16,830]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:18,987]\u001b[0m Trial 468 finished with value: 6.199405519997275 and parameters: {'n_hidden': 3, 'learning_rate': 0.006631059189410615, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3452170276298269, 'dropout_rate_Layer_2': 0.09639696487303381, 'dropout_rate_Layer_3': 0.2083652032050441, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00022299873447926473, 'l1_Layer_2': 0.00017593077019717742, 'l1_Layer_3': 0.004017261424802807, 'n_units_Layer_1': 155, 'n_units_Layer_2': 75, 'n_units_Layer_3': 80}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 20.77% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:35:29,267]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:33,759]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:36,042]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:43,522]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:48,856]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:35:54,580]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:36:00,243]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:36:43,447]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:36:44,343]\u001b[0m Trial 478 finished with value: 6.119467325743212 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006242890261775506, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028078859715941522, 'dropout_rate_Layer_2': 0.2588699961873137, 'dropout_rate_Layer_3': 0.030774368593861182, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043955357967954744, 'l1_Layer_2': 0.00048100618834637216, 'l1_Layer_3': 2.03358184110803e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 185, 'n_units_Layer_3': 135}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 20.85% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.28 | sMAPE for Test Set is: 31.02% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:36:47,747]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:37:02,008]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:37:05,651]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:37:10,888]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:37:18,877]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:37:27,830]\u001b[0m Trial 489 finished with value: 6.074203024602025 and parameters: {'n_hidden': 3, 'learning_rate': 0.007377087820456186, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35257067526495317, 'dropout_rate_Layer_2': 0.09436557126266774, 'dropout_rate_Layer_3': 0.23416048532149839, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00028128453335370736, 'l1_Layer_2': 0.00020356734894500292, 'l1_Layer_3': 0.006420470137945997, 'n_units_Layer_1': 120, 'n_units_Layer_2': 80, 'n_units_Layer_3': 55}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 20.35% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.24 | sMAPE for Test Set is: 30.64% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:37:36,680]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:01,999]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:07,934]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:13,608]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:18,146]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:22,585]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:23,283]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:32,889]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:36,328]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:52,979]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:38:55,058]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:00,937]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:01,275]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:09,985]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:11,795]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:14,977]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:22,944]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:26,942]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:33,069]\u001b[0m Trial 494 finished with value: 5.8577237567963225 and parameters: {'n_hidden': 3, 'learning_rate': 0.000734679348178389, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16061656725879442, 'dropout_rate_Layer_2': 0.02845361003873649, 'dropout_rate_Layer_3': 0.15385843466103652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001354992380713049, 'l1_Layer_2': 0.0068792634687213534, 'l1_Layer_3': 5.694027776378219e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 200, 'n_units_Layer_3': 150}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.88 | sMAPE for Test Set is: 29.98% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:39:35,388]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:49,456]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:51,536]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:39:56,736]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:40:05,756]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:40:16,610]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:40:26,665]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:40:33,203]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:40:50,583]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:40:55,759]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:13,277]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:21,550]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:27,330]\u001b[0m Trial 511 finished with value: 6.1195831718280544 and parameters: {'n_hidden': 3, 'learning_rate': 0.00535146214196715, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.352959747172261, 'dropout_rate_Layer_2': 0.10368362081324807, 'dropout_rate_Layer_3': 0.22048894714055886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00023168436013471205, 'l1_Layer_2': 0.0001620278663203948, 'l1_Layer_3': 0.00772725487037517, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 50}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 20.66% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 30.31% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:41:27,697]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:38,176]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:38,342]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:38,389]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:38,716]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:49,107]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:50,413]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:50,773]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:41:58,072]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:42:25,493]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:42:28,779]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:42:34,153]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:42:42,202]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:42:47,695]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:42:51,634]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:00,856]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:02,999]\u001b[0m Trial 541 finished with value: 6.191024332366176 and parameters: {'n_hidden': 3, 'learning_rate': 0.0061489790474864485, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37469989072680115, 'dropout_rate_Layer_2': 0.374046250030432, 'dropout_rate_Layer_3': 0.19319758203551343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.60801255934517e-05, 'l1_Layer_2': 6.95501054934385e-05, 'l1_Layer_3': 0.006909078864927488, 'n_units_Layer_1': 120, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 20.60% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:43:07,743]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:09,880]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:10,897]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:14,671]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:15,559]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:17,989]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:23,355]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:24,033]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:27,915]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:32,215]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:40,290]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:43,763]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:43:47,327]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:04,752]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:06,914]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:13,692]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:21,776]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:31,982]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:37,479]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:44:53,145]\u001b[0m Trial 561 finished with value: 5.9022763839587435 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007852974110770233, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10435168597115681, 'dropout_rate_Layer_2': 0.05372066112259939, 'dropout_rate_Layer_3': 0.199847988527729, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0033396181919664865, 'l1_Layer_2': 0.001982937333726356, 'l1_Layer_3': 3.22561255766455e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 55, 'n_units_Layer_3': 140}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.90 | sMAPE for Test Set is: 29.63% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:44:59,189]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:45:10,855]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:45:32,790]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:45:41,309]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:45:57,111]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:45:57,347]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:04,836]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:18,585]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:23,465]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:35,865]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:39,996]\u001b[0m Trial 566 finished with value: 6.1365903592892215 and parameters: {'n_hidden': 3, 'learning_rate': 0.006914687343040616, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38877247701687506, 'dropout_rate_Layer_2': 0.31950379294902936, 'dropout_rate_Layer_3': 0.21399636001418101, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.197236967215284e-05, 'l1_Layer_2': 4.258021177384017e-05, 'l1_Layer_3': 0.01385951572856194, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 20.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 30.75% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:46:44,148]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:44,911]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:46:52,449]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:12,881]\u001b[0m Trial 571 finished with value: 5.9416027787982655 and parameters: {'n_hidden': 3, 'learning_rate': 0.006952409730498175, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2226018414261162, 'dropout_rate_Layer_2': 0.3061855729756514, 'dropout_rate_Layer_3': 0.1742601657239701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 6.8558128194769e-05, 'l1_Layer_2': 4.528942781631375e-05, 'l1_Layer_3': 0.006417911557506027, 'n_units_Layer_1': 115, 'n_units_Layer_2': 75, 'n_units_Layer_3': 65}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.94 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 30.43% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:47:28,895]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:32,408]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:32,915]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:35,155]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:43,808]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:46,227]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:47:52,115]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:48:00,931]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:48:13,277]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:48:26,236]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:48:31,335]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:48:43,895]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:48:56,985]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:49:06,085]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:49:10,885]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:49:18,098]\u001b[0m Trial 592 finished with value: 6.185491645742395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0066966017989994716, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12469846047935682, 'dropout_rate_Layer_2': 0.022543787647850803, 'dropout_rate_Layer_3': 0.18627139579453075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0027727852531569935, 'l1_Layer_2': 0.0013540147477051684, 'l1_Layer_3': 1.9101435017979967e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 20.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.94 | sMAPE for Test Set is: 29.99% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:49:33,858]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:49:51,123]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:50:23,681]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:50:31,927]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:50:39,052]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:50:48,111]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:50:59,884]\u001b[0m Trial 599 finished with value: 6.042343597545305 and parameters: {'n_hidden': 3, 'learning_rate': 0.006544724954304518, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21031960706221864, 'dropout_rate_Layer_2': 0.282036779443732, 'dropout_rate_Layer_3': 0.21099681500428127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010605791701102681, 'l1_Layer_2': 0.0001096808541597633, 'l1_Layer_3': 0.006937099755485496, 'n_units_Layer_1': 130, 'n_units_Layer_2': 85, 'n_units_Layer_3': 60}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 31.33% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:51:01,977]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:04,954]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:07,672]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:11,406]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:15,393]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:31,014]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:34,744]\u001b[0m Trial 603 finished with value: 6.117193717982905 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007283351315177949, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09118692450689045, 'dropout_rate_Layer_2': 0.06172589895335131, 'dropout_rate_Layer_3': 0.1659666414017473, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002138895160957532, 'l1_Layer_2': 0.0007142135482256477, 'l1_Layer_3': 2.3388960997492507e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 145, 'n_units_Layer_3': 135}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 20.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.24 | sMAPE for Test Set is: 31.29% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:51:39,413]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:49,845]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:54,420]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:54,998]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:56,936]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:51:58,877]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:00,045]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:07,585]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:07,681]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:08,026]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:25,851]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:27,642]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:31,400]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:40,011]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:43,108]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:50,208]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:57,291]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:52:57,901]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:53:26,617]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:53:30,376]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:53:38,368]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:53:46,299]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:53:54,348]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:53:59,559]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:08,015]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:16,646]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:21,721]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:23,588]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:39,782]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:41,996]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:47,038]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:49,689]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:53,323]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:54:57,410]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:55:32,808]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:55:39,218]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:55:47,856]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:55:51,401]\u001b[0m Trial 623 finished with value: 6.043433156424797 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005459612582254821, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02185736687407945, 'dropout_rate_Layer_2': 0.2734668742669491, 'dropout_rate_Layer_3': 0.0509046499366221, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009235450179813822, 'l1_Layer_2': 0.000827898423541816, 'l1_Layer_3': 6.927170004744655e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 145}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 20.50% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 29.58% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:55:54,461]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:55:56,411]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:55:58,770]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:10,178]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:16,652]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:20,490]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:26,659]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:31,908]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:40,535]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:48,594]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:56:58,246]\u001b[0m Trial 654 finished with value: 6.049319441051014 and parameters: {'n_hidden': 3, 'learning_rate': 0.002035749942439088, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1141694892163704, 'dropout_rate_Layer_2': 0.04771831630276326, 'dropout_rate_Layer_3': 0.20475748959714057, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018708112905747732, 'l1_Layer_2': 0.0008747958866458523, 'l1_Layer_3': 0.00017745730896260613, 'n_units_Layer_1': 195, 'n_units_Layer_2': 170, 'n_units_Layer_3': 125}. Best is trial 282 with value: 5.789218493728609.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.05 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.08 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:57:04,737]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:57:23,667]\u001b[0m Trial 627 finished with value: 5.716791662219738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006113199794196684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14837832578037155, 'dropout_rate_Layer_2': 0.006440880469412338, 'dropout_rate_Layer_3': 0.06768803349797159, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003987444785531386, 'l1_Layer_2': 0.0031601338739557106, 'l1_Layer_3': 0.0021870981135305788, 'n_units_Layer_1': 250, 'n_units_Layer_2': 70, 'n_units_Layer_3': 185}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.82 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:57:39,957]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:57:42,760]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:57:50,578]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:57:54,139]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:00,664]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:03,562]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:10,856]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:17,071]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:19,669]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:23,810]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:29,386]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:37,536]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:41,916]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:58:53,636]\u001b[0m Trial 664 finished with value: 6.019155844833487 and parameters: {'n_hidden': 3, 'learning_rate': 0.005197368237435015, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2181875333650294, 'dropout_rate_Layer_2': 0.10244413976840003, 'dropout_rate_Layer_3': 0.2369783360290108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.48847849842441e-05, 'l1_Layer_2': 4.454377533467298e-05, 'l1_Layer_3': 0.0031164102319272365, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 60}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 20.38% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.13 | sMAPE for Test Set is: 30.57% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 20:59:27,935]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:59:33,467]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 20:59:47,959]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:00:46,972]\u001b[0m Trial 678 finished with value: 5.99023287498224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019396006839719722, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08562659315985541, 'dropout_rate_Layer_2': 0.049957191256336686, 'dropout_rate_Layer_3': 0.06591163777732688, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003741760034226823, 'l1_Layer_2': 0.017475457754129474, 'l1_Layer_3': 0.0037001495787815242, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 195}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 20.16% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 30.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:00:53,477]\u001b[0m Trial 674 finished with value: 5.90044164047006 and parameters: {'n_hidden': 3, 'learning_rate': 0.002050136803462874, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16475944677319548, 'dropout_rate_Layer_2': 0.053645583684802906, 'dropout_rate_Layer_3': 0.022538893923958817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018193000220941048, 'l1_Layer_2': 0.0015257487864844806, 'l1_Layer_3': 0.0033154554379063814, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.90 | sMAPE for Validation Set is: 20.22% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 29.67% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:01:24,673]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:01:34,741]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:06,733]\u001b[0m Trial 676 finished with value: 5.766916451683369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005107408443823236, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15935019295526603, 'dropout_rate_Layer_2': 0.05093565089171766, 'dropout_rate_Layer_3': 0.24666982025123788, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003848801108521125, 'l1_Layer_2': 0.0011813603131783966, 'l1_Layer_3': 0.0004635551680481712, 'n_units_Layer_1': 210, 'n_units_Layer_2': 180, 'n_units_Layer_3': 210}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 28.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:02:12,645]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:14,701]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:30,743]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:33,401]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:38,369]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:42,782]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:47,696]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:48,201]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:54,193]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:59,043]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:02:59,388]\u001b[0m Trial 684 finished with value: 6.1707083309712365 and parameters: {'n_hidden': 3, 'learning_rate': 0.004667167965445192, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13607914275382416, 'dropout_rate_Layer_2': 0.10793689375179528, 'dropout_rate_Layer_3': 0.21841549907529165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010304657661650192, 'l1_Layer_2': 0.0002044493518653125, 'l1_Layer_3': 0.001046275532340048, 'n_units_Layer_1': 110, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 21.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 30.10% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:03:17,118]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:03:25,023]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:03:31,997]\u001b[0m Trial 683 finished with value: 6.062633493367298 and parameters: {'n_hidden': 3, 'learning_rate': 0.0045749768629291376, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38265508468084464, 'dropout_rate_Layer_2': 0.10734269481568759, 'dropout_rate_Layer_3': 0.24067567393289752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015925463688917243, 'l1_Layer_2': 0.00019595345434189805, 'l1_Layer_3': 0.0031011267369370804, 'n_units_Layer_1': 125, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.76% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 29.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:03:37,340]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:03:42,279]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:03:42,390]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:03:45,588]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:03:48,739]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:04:10,877]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:04:19,040]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:04:26,989]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:04:34,952]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:04:58,782]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:05:04,791]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:05:13,059]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:05:43,566]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:05:50,932]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:07:08,533]\u001b[0m Trial 703 finished with value: 5.925243741285537 and parameters: {'n_hidden': 3, 'learning_rate': 0.00428850050483428, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08220417044067001, 'dropout_rate_Layer_2': 0.007740776493859569, 'dropout_rate_Layer_3': 0.015762335194631605, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0037244657320078547, 'l1_Layer_2': 0.01724919827688407, 'l1_Layer_3': 0.00515936853775007, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 200}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.33 | sMAPE for Test Set is: 30.83% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:07:13,338]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:07:15,478]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:07:22,277]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:08:09,185]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:08:32,726]\u001b[0m Trial 697 finished with value: 5.736756220091988 and parameters: {'n_hidden': 3, 'learning_rate': 0.000517203986970251, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04543741128008893, 'dropout_rate_Layer_2': 0.007661657888829847, 'dropout_rate_Layer_3': 0.014931911625306594, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016281362129949826, 'l1_Layer_2': 0.003163241793230677, 'l1_Layer_3': 0.004983502582100786, 'n_units_Layer_1': 200, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.83 | sMAPE for Test Set is: 29.62% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:08:54,651]\u001b[0m Trial 717 finished with value: 5.970540171854434 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037834117595335597, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38987345358531805, 'dropout_rate_Layer_2': 0.0924049084981615, 'dropout_rate_Layer_3': 0.2286763983979951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00029718781517077894, 'l1_Layer_2': 0.000222397130734589, 'l1_Layer_3': 0.004020447770999898, 'n_units_Layer_1': 135, 'n_units_Layer_2': 80, 'n_units_Layer_3': 65}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.97 | sMAPE for Test Set is: 30.12% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:09:02,615]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:09:27,390]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:09:41,043]\u001b[0m Trial 720 finished with value: 6.13718560816023 and parameters: {'n_hidden': 3, 'learning_rate': 0.003777291584638379, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18879708789935604, 'dropout_rate_Layer_2': 0.010662559042463854, 'dropout_rate_Layer_3': 0.022648024219476058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0056203873688610165, 'l1_Layer_2': 0.008049624072582681, 'l1_Layer_3': 0.0070018214918673004, 'n_units_Layer_1': 165, 'n_units_Layer_2': 190, 'n_units_Layer_3': 230}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 20.70% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.36 | sMAPE for Test Set is: 31.14% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:09:44,057]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:09:52,748]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:00,526]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:00,818]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:07,740]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:12,267]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:16,517]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:19,526]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:20,266]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:25,665]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:32,898]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:35,170]\u001b[0m Trial 715 finished with value: 5.739669278901992 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005006715104357873, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06810301972855579, 'dropout_rate_Layer_2': 0.06717231082372634, 'dropout_rate_Layer_3': 0.08590531849239794, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015990154448751505, 'l1_Layer_2': 0.006964823440071515, 'l1_Layer_3': 0.0033017377057021195, 'n_units_Layer_1': 210, 'n_units_Layer_2': 185, 'n_units_Layer_3': 200}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.60% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.74 | sMAPE for Test Set is: 29.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:10:39,251]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:44,182]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:49,593]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:51,481]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:54,952]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:58,483]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:10:59,080]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:00,057]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:10,003]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:25,933]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:33,478]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:41,297]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:54,761]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:11:58,741]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:14,936]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:23,386]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:29,312]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:35,213]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:38,265]\u001b[0m Trial 745 finished with value: 6.0172279045889345 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008013120108357444, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007038663510147219, 'dropout_rate_Layer_2': 0.09812553317592537, 'dropout_rate_Layer_3': 0.03781977799326685, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007067753760503828, 'l1_Layer_2': 0.0016703218614596035, 'l1_Layer_3': 3.372035951057258e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 155}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 20.66% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.68 | sMAPE for Test Set is: 29.30% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:12:41,320]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:44,284]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:47,002]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:12:52,075]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:13:03,316]\u001b[0m Trial 743 finished with value: 6.008191081046768 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009198946518469977, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18347265418390238, 'dropout_rate_Layer_2': 0.0848396458775934, 'dropout_rate_Layer_3': 0.08147601568322071, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002845236024643008, 'l1_Layer_2': 0.0006315731470598065, 'l1_Layer_3': 7.2494207989675e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 20.24% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 30.35% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:13:23,858]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:13:31,282]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:13:35,121]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:14:18,241]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:14:33,596]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:14:41,291]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:14:47,382]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:14:58,547]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:15:02,485]\u001b[0m Trial 768 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:15:06,992]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:15:10,787]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:15:20,225]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:15:24,081]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:04,754]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:14,829]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:22,330]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:38,071]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:44,460]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:47,550]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:16:56,139]\u001b[0m Trial 749 finished with value: 5.7763481510712245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005599549467871701, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06995145212470463, 'dropout_rate_Layer_2': 0.02376290661145755, 'dropout_rate_Layer_3': 0.04278356085637783, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016557004870141625, 'l1_Layer_2': 0.005626673765198896, 'l1_Layer_3': 0.0029996254944532476, 'n_units_Layer_1': 190, 'n_units_Layer_2': 180, 'n_units_Layer_3': 215}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 29.64% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:17:01,073]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:03,946]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:06,847]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:12,028]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:17,158]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:20,842]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:23,940]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:32,780]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:38,730]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:44,530]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:17:53,899]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:18:02,476]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:18:03,537]\u001b[0m Trial 761 finished with value: 5.82138039220617 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005868101671408776, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04699697482114136, 'dropout_rate_Layer_2': 0.0707910670520174, 'dropout_rate_Layer_3': 6.623754893005443e-05, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022037908379704944, 'l1_Layer_2': 0.004136500574483152, 'l1_Layer_3': 0.00255205093902588, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 190}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 28.89% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:18:09,040]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:18:14,175]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:18:42,654]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:19:09,503]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:19:19,154]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:19:25,762]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:19:31,535]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:19:39,491]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:19:52,806]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:00,325]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:04,262]\u001b[0m Trial 796 finished with value: 6.006211656058691 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006581044528621346, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05259467124201295, 'dropout_rate_Layer_2': 0.09114443153277486, 'dropout_rate_Layer_3': 0.03076633471952387, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003886016102961026, 'l1_Layer_2': 0.0019412825622605804, 'l1_Layer_3': 6.700628500310166e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 110}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 20.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.71 | sMAPE for Test Set is: 29.54% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:20:09,325]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:13,070]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:27,024]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:42,165]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:46,231]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:20:57,109]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:16,109]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:20,460]\u001b[0m Trial 780 finished with value: 5.7854607369435795 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007000528982029922, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0930102099962664, 'dropout_rate_Layer_2': 0.02770221267176768, 'dropout_rate_Layer_3': 0.07253304638894141, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0008899767180315795, 'l1_Layer_2': 0.009610132978179012, 'l1_Layer_3': 0.0014046076622001016, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 29.24% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:21:23,629]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:24,388]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:29,512]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:32,550]\u001b[0m Trial 810 finished with value: 6.030877599627945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036073903058389373, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39227076699631364, 'dropout_rate_Layer_2': 0.22919134910433975, 'dropout_rate_Layer_3': 0.1300423655575977, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.62193616506334e-05, 'l1_Layer_2': 0.00013756602234212638, 'l1_Layer_3': 0.0019690832017717594, 'n_units_Layer_1': 115, 'n_units_Layer_2': 70, 'n_units_Layer_3': 255}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 20.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:21:35,752]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:38,038]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:42,744]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:42,852]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:43,727]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:51,948]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:21:57,340]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:22:04,748]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:22:21,534]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:22:31,642]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:22:48,437]\u001b[0m Trial 822 finished with value: 5.958063012620425 and parameters: {'n_hidden': 3, 'learning_rate': 0.004092083764043151, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3997680429033495, 'dropout_rate_Layer_2': 0.24559997150128932, 'dropout_rate_Layer_3': 0.13804224651783398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.303998645534768e-05, 'l1_Layer_2': 0.00016054362169820103, 'l1_Layer_3': 0.0030572855690712774, 'n_units_Layer_1': 115, 'n_units_Layer_2': 70, 'n_units_Layer_3': 285}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 20.21% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.73 | sMAPE for Test Set is: 28.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:22:48,882]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:22:57,004]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:23:02,096]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:23:08,136]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:23:31,044]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:23:34,126]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:23:42,028]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:23:42,898]\u001b[0m Trial 825 finished with value: 5.967282498100187 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006430321336410873, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051291825699055715, 'dropout_rate_Layer_2': 0.12361356148942013, 'dropout_rate_Layer_3': 0.043559985212879855, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002010702816492838, 'l1_Layer_2': 0.0004901555426306538, 'l1_Layer_3': 8.474963146047702e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.97 | sMAPE for Validation Set is: 20.49% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.60 | sMAPE for Test Set is: 29.11% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:24:00,401]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:12,423]\u001b[0m Trial 826 finished with value: 5.927885827923844 and parameters: {'n_hidden': 3, 'learning_rate': 0.006549349538637831, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3640502972769142, 'dropout_rate_Layer_2': 0.2955515550598366, 'dropout_rate_Layer_3': 0.12259558104834148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00010040483362838322, 'l1_Layer_2': 0.0002000778120640775, 'l1_Layer_3': 0.0027476759829727668, 'n_units_Layer_1': 110, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 30.63% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:24:20,927]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:29,064]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:34,036]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:38,245]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:42,475]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:54,352]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:24:58,577]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:25:03,616]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:25:08,652]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:25:12,614]\u001b[0m Trial 832 finished with value: 5.846672307438525 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034845970173851704, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38472537404575186, 'dropout_rate_Layer_2': 0.25431067836001625, 'dropout_rate_Layer_3': 0.11727529074388804, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.981410298283872e-05, 'l1_Layer_2': 0.00019529319632988784, 'l1_Layer_3': 0.0024724326969984226, 'n_units_Layer_1': 100, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 20.17% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.05 | sMAPE for Test Set is: 30.45% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:25:18,176]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:25:25,506]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:25:27,233]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:25:54,828]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:10,556]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:15,863]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:16,246]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:33,990]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:42,486]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:48,125]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:52,197]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:26:57,286]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:27:12,803]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:27:29,774]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:27:47,666]\u001b[0m Trial 852 finished with value: 5.883557830455139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032568883205952455, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.37129740275366996, 'dropout_rate_Layer_2': 0.2541497777949057, 'dropout_rate_Layer_3': 0.23357818773716857, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00015215873685568782, 'l1_Layer_2': 0.00028112076517826, 'l1_Layer_3': 0.0022100638166827084, 'n_units_Layer_1': 95, 'n_units_Layer_2': 65, 'n_units_Layer_3': 255}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 19.93% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 30.67% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:27:57,932]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:28:00,547]\u001b[0m Trial 844 finished with value: 5.958310934183444 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005872035927386518, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04789679835968133, 'dropout_rate_Layer_2': 0.09252966076293184, 'dropout_rate_Layer_3': 0.03174138346078732, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005295960526443613, 'l1_Layer_2': 0.0005987511888159704, 'l1_Layer_3': 6.313630801789061e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 175, 'n_units_Layer_3': 180}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.96 | sMAPE for Validation Set is: 20.38% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.67 | sMAPE for Test Set is: 29.32% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:28:09,326]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:28:15,745]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:28:16,095]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:28:25,379]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:28:43,841]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:28:51,537]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:00,381]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:00,988]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:05,863]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:06,586]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:06,743]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:14,198]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:16,272]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:16,358]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:23,887]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:27,888]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:32,644]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:33,106]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:38,169]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:40,975]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:44,166]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:29:49,642]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:30:05,904]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:30:11,138]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:30:54,811]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:11,551]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:14,479]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:24,573]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:29,686]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:35,996]\u001b[0m Trial 882 finished with value: 5.8095009670118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005962699843041405, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023052197836836152, 'dropout_rate_Layer_2': 0.019388987724650808, 'dropout_rate_Layer_3': 0.0004966063379758523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022420496293502792, 'l1_Layer_2': 0.0033280009533041507, 'l1_Layer_3': 0.0019352872422212734, 'n_units_Layer_1': 110, 'n_units_Layer_2': 150, 'n_units_Layer_3': 190}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.84 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:31:43,472]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:50,794]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:54,353]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:31:59,200]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:32:23,794]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:32:30,217]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:32:46,944]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:32:52,425]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:32:57,779]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:00,652]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:00,901]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:10,106]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:12,854]\u001b[0m Trial 877 finished with value: 5.785879229713141 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006282618450634612, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02198674137086569, 'dropout_rate_Layer_2': 0.022789920785847864, 'dropout_rate_Layer_3': 0.08589937239627321, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002347538477871628, 'l1_Layer_2': 0.004535056338974804, 'l1_Layer_3': 0.0019119406169831386, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 225}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 19.80% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 29.36% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:33:20,057]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:22,679]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:26,046]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:28,325]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:40,639]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:43,331]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:46,538]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:50,065]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:50,957]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:57,406]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:57,922]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:33:59,960]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:34:08,931]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:34:52,075]\u001b[0m Trial 894 finished with value: 5.7697036355339835 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005563116621191323, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06448765969979514, 'dropout_rate_Layer_2': 0.056146699694932925, 'dropout_rate_Layer_3': 0.08815948854111127, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002441335898854593, 'l1_Layer_2': 0.0030488492654774466, 'l1_Layer_3': 0.0015776299425238137, 'n_units_Layer_1': 195, 'n_units_Layer_2': 205, 'n_units_Layer_3': 225}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.65% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.57 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:35:04,177]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:12,800]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:16,422]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:22,752]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:33,081]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:38,641]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:42,036]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:44,476]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:35:55,771]\u001b[0m Trial 920 finished with value: 6.0583029699860775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005504661062785789, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045490139923203055, 'dropout_rate_Layer_2': 0.28353974942670535, 'dropout_rate_Layer_3': 0.05842097147601471, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004367226707565498, 'l1_Layer_2': 0.0005063483839051267, 'l1_Layer_3': 4.195254458028335e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 155, 'n_units_Layer_3': 140}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.63% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.54 | sMAPE for Test Set is: 28.80% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:36:00,380]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:36:04,232]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:36:09,507]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:37:00,819]\u001b[0m Trial 921 finished with value: 5.8825200948310625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005043383377012621, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0014157521429603304, 'dropout_rate_Layer_2': 0.023139631551207726, 'dropout_rate_Layer_3': 0.07604362535861729, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002278915855979771, 'l1_Layer_2': 0.0043955396593438525, 'l1_Layer_3': 0.0014793468700096716, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 190}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 20.10% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:38:27,121]\u001b[0m Trial 929 finished with value: 5.771844344630671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005546523061863342, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026958154564344375, 'dropout_rate_Layer_2': 0.0006330933807288767, 'dropout_rate_Layer_3': 0.09918052661802529, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022085161845267647, 'l1_Layer_2': 0.004178832323956874, 'l1_Layer_3': 0.0015735219449262857, 'n_units_Layer_1': 65, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 29.22% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:38:49,560]\u001b[0m Trial 932 finished with value: 5.756978794096708 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005016932741142436, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0004510450955067559, 'dropout_rate_Layer_2': 0.023499356685342837, 'dropout_rate_Layer_3': 0.09693550104787993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0025096552825460503, 'l1_Layer_2': 0.004083298433999587, 'l1_Layer_3': 0.0015656046408532266, 'n_units_Layer_1': 105, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 627 with value: 5.716791662219738.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 28.47% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:38:59,985]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:39:07,187]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:39:11,769]\u001b[0m Trial 934 finished with value: 5.672712050907356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005591457521910443, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03200877522975786, 'dropout_rate_Layer_2': 0.02287603163723318, 'dropout_rate_Layer_3': 0.09957799335358748, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0022536332947122708, 'l1_Layer_2': 0.006128655389645721, 'l1_Layer_3': 0.0015432333256611191, 'n_units_Layer_1': 110, 'n_units_Layer_2': 135, 'n_units_Layer_3': 225}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.38 | sMAPE for Test Set is: 28.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:39:20,417]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:39:40,039]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:39:48,882]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:39:59,084]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:40:06,086]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:40:10,693]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:40:21,607]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:40:42,010]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:40:54,699]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:14,847]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:25,626]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:28,848]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:30,600]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:30,957]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:35,222]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:41,992]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:42,116]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:43,177]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:52,648]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:41:52,834]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:42:00,543]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:42:08,468]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:42:22,687]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:42:29,178]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:42:34,159]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:42:50,958]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:02,095]\u001b[0m Trial 957 finished with value: 5.894929743592022 and parameters: {'n_hidden': 3, 'learning_rate': 0.00945621668996435, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.381965664084862, 'dropout_rate_Layer_2': 0.2951086228912345, 'dropout_rate_Layer_3': 0.20078847464958266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00023421464858138324, 'l1_Layer_2': 7.82993416886939e-05, 'l1_Layer_3': 0.0028364405437459814, 'n_units_Layer_1': 135, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.89 | sMAPE for Validation Set is: 19.88% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.67 | sMAPE for Test Set is: 31.86% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:43:05,302]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:09,555]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:16,864]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:26,685]\u001b[0m Trial 946 finished with value: 5.742728910510266 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006373032103436519, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03681024941135065, 'dropout_rate_Layer_2': 0.023950174900985735, 'dropout_rate_Layer_3': 0.08367983728524038, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017562441956545977, 'l1_Layer_2': 0.002683780383658981, 'l1_Layer_3': 0.0016975646438837986, 'n_units_Layer_1': 95, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.83% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 28.70% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:43:28,181]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:35,059]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:36,959]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:43,645]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:48,344]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:43:53,558]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:45:02,645]\u001b[0m Trial 974 finished with value: 5.934400279934846 and parameters: {'n_hidden': 3, 'learning_rate': 0.006015279089153737, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19600452779550748, 'dropout_rate_Layer_2': 0.3180783697653661, 'dropout_rate_Layer_3': 0.1328152283827838, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00024285243181799797, 'l1_Layer_2': 7.089435973009951e-05, 'l1_Layer_3': 0.003664700830917399, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 280}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.93 | sMAPE for Validation Set is: 20.07% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.81 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:45:09,667]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:45:22,500]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:45:28,296]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:45:33,142]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:45:52,463]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:45:57,790]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:46:05,576]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:46:11,380]\u001b[0m Trial 959 finished with value: 5.679098265675665 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005236968087158627, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03851615889652945, 'dropout_rate_Layer_2': 0.036989377292585494, 'dropout_rate_Layer_3': 0.12049981025460636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.004545447689944039, 'l1_Layer_2': 0.004711394711153162, 'l1_Layer_3': 0.0021468648340095516, 'n_units_Layer_1': 60, 'n_units_Layer_2': 160, 'n_units_Layer_3': 235}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 19.45% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 28.93% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:46:22,220]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:46:30,791]\u001b[0m Trial 977 finished with value: 5.737480869215655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005168399315185972, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03683453083864899, 'dropout_rate_Layer_2': 0.03546905071249888, 'dropout_rate_Layer_3': 0.08065312950365452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018882564620129026, 'l1_Layer_2': 0.005088698029327903, 'l1_Layer_3': 0.002027965679990109, 'n_units_Layer_1': 80, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:46:43,857]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:46:47,232]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:46:50,401]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:46:54,799]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:47:09,294]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:47:14,168]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:47:19,964]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:47:31,248]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:47:59,210]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:04,932]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:07,200]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:12,166]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:17,243]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:20,813]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:26,194]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:26,718]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:33,416]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:48:53,187]\u001b[0m Trial 987 finished with value: 5.767254304764325 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005115956784298502, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03686544959263301, 'dropout_rate_Layer_2': 0.037623614697750205, 'dropout_rate_Layer_3': 0.06995009087077965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017793565859383243, 'l1_Layer_2': 0.005049262180506362, 'l1_Layer_3': 0.0019938658212009497, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 240}. Best is trial 934 with value: 5.672712050907356.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.63% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 28.68% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:48:59,467]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:05,111]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:10,897]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:29,488]\u001b[0m Trial 985 finished with value: 5.670058594652464 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005169481775794139, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03851546813423856, 'dropout_rate_Layer_2': 0.036588936493006666, 'dropout_rate_Layer_3': 0.0763564652863312, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002096784750701019, 'l1_Layer_2': 0.004997955457232471, 'l1_Layer_3': 0.002112092800190727, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 6.31 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:49:35,656]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:38,081]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:43,915]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:45,799]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:53,677]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:49:56,387]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:50:00,663]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:50:10,230]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:50:15,025]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:50:24,385]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:50:38,239]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:09,410]\u001b[0m Trial 1003 finished with value: 5.728732503669501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006054043790806658, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01900642571092883, 'dropout_rate_Layer_2': 0.03496620190881586, 'dropout_rate_Layer_3': 0.09588188849935456, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0021937733267888503, 'l1_Layer_2': 0.004076543068065425, 'l1_Layer_3': 0.0015029261486648024, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 220}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.71% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.42 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:51:14,134]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:21,432]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:25,212]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:28,240]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:35,659]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:35,871]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:42,203]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:48,597]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:50,178]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:51:55,527]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:01,240]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:09,285]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:11,496]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:22,261]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:46,362]\u001b[0m Trial 1013 finished with value: 5.738616461168899 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006664050128992022, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015076525714236306, 'dropout_rate_Layer_2': 0.03325394117430703, 'dropout_rate_Layer_3': 0.06156734266749825, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001760336884477883, 'l1_Layer_2': 0.005890357637713433, 'l1_Layer_3': 0.0016602606711002687, 'n_units_Layer_1': 55, 'n_units_Layer_2': 145, 'n_units_Layer_3': 220}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 28.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:52:50,007]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:54,537]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:52:58,529]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 28.59% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:53:01,989]\u001b[0m Trial 1016 finished with value: 5.75806226614731 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006552375819043926, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.015794932978255693, 'dropout_rate_Layer_2': 0.029887946354192778, 'dropout_rate_Layer_3': 0.0736381416038964, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016475942002819764, 'l1_Layer_2': 0.005088770817106793, 'l1_Layer_3': 0.0016422153430967514, 'n_units_Layer_1': 60, 'n_units_Layer_2': 165, 'n_units_Layer_3': 220}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:05,415]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:05,469]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:11,271]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:12,350]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:19,522]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:21,328]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:28,433]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:31,396]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:40,373]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:53:51,183]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:54:11,415]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:54:32,738]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:54:38,184]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:54:48,304]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:55:04,237]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:55:16,010]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:55:51,421]\u001b[0m Trial 1039 finished with value: 5.725429795057803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005457445741874599, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03167890230251768, 'dropout_rate_Layer_2': 0.01116148784487593, 'dropout_rate_Layer_3': 0.06988587909170636, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011161023411547664, 'l1_Layer_2': 0.006134315818973351, 'l1_Layer_3': 0.0009418418069697498, 'n_units_Layer_1': 90, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.75% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 28.79% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:55:57,157]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:56:05,047]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:56:09,542]\u001b[0m Trial 1051 finished with value: 5.733287392347857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005045186476725453, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03236865875518312, 'dropout_rate_Layer_2': 0.010646843603030236, 'dropout_rate_Layer_3': 0.10524289225137747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0012097062523314767, 'l1_Layer_2': 0.006622402634010487, 'l1_Layer_3': 0.0009438191840273228, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 220}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.53 | sMAPE for Test Set is: 28.73% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:56:10,332]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:56:16,588]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:56:17,311]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:56:26,820]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:57:16,157]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:57:27,612]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:57:35,466]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:57:40,362]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:57:45,939]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:57:53,540]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:58:01,509]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:58:35,713]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:58:43,792]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:58:46,187]\u001b[0m Trial 1065 finished with value: 5.789945137266563 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005694053499790604, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04028156488283708, 'dropout_rate_Layer_2': 0.010351203157646694, 'dropout_rate_Layer_3': 0.0929879066616621, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001162694144347763, 'l1_Layer_2': 0.00683054811051585, 'l1_Layer_3': 0.0008533926202818373, 'n_units_Layer_1': 80, 'n_units_Layer_2': 125, 'n_units_Layer_3': 255}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 20.12% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.45 | sMAPE for Test Set is: 28.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 21:58:49,706]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:58:53,934]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:58:54,705]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:00,833]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:01,256]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:08,994]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:12,734]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:17,613]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:24,064]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:25,870]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:32,144]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:40,128]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:43,423]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:49,482]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:52,989]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:57,406]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 21:59:59,139]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.59 | sMAPE for Test Set is: 28.92% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:00:01,659]\u001b[0m Trial 1057 finished with value: 5.700738455555514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006728037112330109, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03792683722207396, 'dropout_rate_Layer_2': 0.03125696684831833, 'dropout_rate_Layer_3': 0.0755366510655618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0013079219027342175, 'l1_Layer_2': 0.006846019710620915, 'l1_Layer_3': 0.0015305700765145744, 'n_units_Layer_1': 55, 'n_units_Layer_2': 165, 'n_units_Layer_3': 215}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:06,539]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:11,658]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:15,861]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:15,874]\u001b[0m Trial 1063 finished with value: 5.7508811631809165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005539279138523845, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04117442337652372, 'dropout_rate_Layer_2': 0.010740636965246547, 'dropout_rate_Layer_3': 0.09286004245204163, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001210988744258731, 'l1_Layer_2': 0.0072788418653907125, 'l1_Layer_3': 0.0015656027435614454, 'n_units_Layer_1': 80, 'n_units_Layer_2': 130, 'n_units_Layer_3': 255}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.46 | sMAPE for Test Set is: 28.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:00:24,335]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:24,605]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:35,887]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:41,653]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:46,755]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:00:52,556]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:01:08,958]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:01:13,018]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:02:28,310]\u001b[0m Trial 1105 finished with value: 6.110094312200779 and parameters: {'n_hidden': 3, 'learning_rate': 0.003766295194991032, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32652694739125016, 'dropout_rate_Layer_2': 0.2647610564383834, 'dropout_rate_Layer_3': 0.11536570940752458, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.728491798853654e-05, 'l1_Layer_2': 0.00010595433398240427, 'l1_Layer_3': 0.001035474955066721, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 20.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.43 | sMAPE for Test Set is: 31.71% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:02:44,919]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:02:50,553]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:03:24,471]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:03:32,777]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:03:42,998]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:06,920]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:15,419]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:21,150]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:24,404]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:27,439]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:33,605]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:34,037]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:40,656]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:04:46,270]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:05:25,183]\u001b[0m Trial 1108 finished with value: 5.736103647665106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006636230821136627, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013624974190868309, 'dropout_rate_Layer_2': 0.03264167925276828, 'dropout_rate_Layer_3': 0.13307699758352468, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000752149318757034, 'l1_Layer_2': 0.008135700454803678, 'l1_Layer_3': 0.0011648743203628192, 'n_units_Layer_1': 55, 'n_units_Layer_2': 130, 'n_units_Layer_3': 260}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.66% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.61 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:05:37,001]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:05:41,355]\u001b[0m Trial 1122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:05:51,354]\u001b[0m Trial 1118 finished with value: 6.055508310802601 and parameters: {'n_hidden': 3, 'learning_rate': 0.004050621366455975, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33094968570872696, 'dropout_rate_Layer_2': 0.2738201005642229, 'dropout_rate_Layer_3': 0.13777988746804073, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 8.508053225577444e-05, 'l1_Layer_2': 5.3381394131364714e-05, 'l1_Layer_3': 0.0010643115070056294, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.06 | sMAPE for Validation Set is: 20.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.93 | sMAPE for Test Set is: 29.94% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:05:58,001]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:06:04,597]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:06:22,278]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:06:39,754]\u001b[0m Trial 1120 finished with value: 5.9505123935548285 and parameters: {'n_hidden': 3, 'learning_rate': 0.004332145154747122, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33717624908900806, 'dropout_rate_Layer_2': 0.2578321093132739, 'dropout_rate_Layer_3': 0.12146624463448659, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.41471916886883e-05, 'l1_Layer_2': 0.00011996601491480906, 'l1_Layer_3': 0.0011797271443072413, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 280}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 20.14% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.42 | sMAPE for Test Set is: 31.42% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:06:52,138]\u001b[0m Trial 1123 finished with value: 6.032724408738773 and parameters: {'n_hidden': 3, 'learning_rate': 0.004318827072918605, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33309804538673093, 'dropout_rate_Layer_2': 0.2764668098421717, 'dropout_rate_Layer_3': 0.12871505427844873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 9.400315682281301e-05, 'l1_Layer_2': 0.00011684095147382598, 'l1_Layer_3': 0.0010151542780148545, 'n_units_Layer_1': 105, 'n_units_Layer_2': 70, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.03 | sMAPE for Validation Set is: 20.11% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 7.68 | sMAPE for Test Set is: 31.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:07:09,599]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:07:39,436]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:07:47,101]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:07:50,621]\u001b[0m Trial 1132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:07:57,376]\u001b[0m Trial 1119 finished with value: 5.702325396782111 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006950638670773377, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04905194960243314, 'dropout_rate_Layer_2': 0.018267434663212817, 'dropout_rate_Layer_3': 0.07123321200949854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007339413244796694, 'l1_Layer_2': 0.009397149749688678, 'l1_Layer_3': 0.002185121595922659, 'n_units_Layer_1': 70, 'n_units_Layer_2': 130, 'n_units_Layer_3': 270}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.70 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.41 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:09:01,542]\u001b[0m Trial 1130 finished with value: 6.107814958074393 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006511110720675095, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0562039524193816, 'dropout_rate_Layer_2': 0.31271715971189085, 'dropout_rate_Layer_3': 0.049684472751582026, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004888301314429921, 'l1_Layer_2': 4.756955926187394e-05, 'l1_Layer_3': 6.469011549482398e-05, 'n_units_Layer_1': 160, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 20.76% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 7.07 | sMAPE for Test Set is: 30.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:09:50,964]\u001b[0m Trial 1134 finished with value: 5.7975316706578655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006693456772228386, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052113614929740114, 'dropout_rate_Layer_2': 0.008283999363179828, 'dropout_rate_Layer_3': 0.11252008811967379, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.000780273998353408, 'l1_Layer_2': 0.008536933951973809, 'l1_Layer_3': 0.0006749580666739275, 'n_units_Layer_1': 100, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 19.78% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.69 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:10:22,067]\u001b[0m Trial 1131 finished with value: 5.756234038264893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007180838953582488, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009058035535073266, 'dropout_rate_Layer_2': 0.029407192412204096, 'dropout_rate_Layer_3': 0.07044377224527365, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007092937073469747, 'l1_Layer_2': 0.0066685817913946805, 'l1_Layer_3': 0.0018436468349973874, 'n_units_Layer_1': 55, 'n_units_Layer_2': 130, 'n_units_Layer_3': 245}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 28.99% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:10:31,892]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:10:41,576]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:10:47,498]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:10:50,806]\u001b[0m Trial 1133 finished with value: 5.710311901009671 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005034571318568776, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052752194467736456, 'dropout_rate_Layer_2': 0.0457881891034224, 'dropout_rate_Layer_3': 0.07341802854775573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015908186501075805, 'l1_Layer_2': 0.008880071387536161, 'l1_Layer_3': 0.0004559128209021959, 'n_units_Layer_1': 65, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.49 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:10:52,485]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:10:57,456]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:00,793]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:05,014]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:07,321]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:12,400]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:20,946]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:26,727]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:27,063]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:11:45,757]\u001b[0m Trial 1135 finished with value: 5.999459067596335 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005670043238286083, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0924901737247806, 'dropout_rate_Layer_2': 0.26786481237030096, 'dropout_rate_Layer_3': 0.021784104614104238, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002761870015336879, 'l1_Layer_2': 0.0007399867856252045, 'l1_Layer_3': 4.321449516385282e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 160, 'n_units_Layer_3': 150}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 20.32% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 29.84% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:11:50,325]\u001b[0m Trial 1151 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:12:36,927]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:12:43,219]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:12:55,570]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:01,483]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:01,852]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:07,007]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:11,379]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:16,952]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:21,574]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:13:31,837]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:14:03,645]\u001b[0m Trial 1156 finished with value: 6.024340840098856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0038273475083930733, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.34368919812762166, 'dropout_rate_Layer_2': 0.2442597485006663, 'dropout_rate_Layer_3': 0.089102381160694, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001373228966256845, 'l1_Layer_2': 8.752808420431083e-05, 'l1_Layer_3': 0.0011610089197548379, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.02 | sMAPE for Validation Set is: 20.49% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.72 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:14:41,567]\u001b[0m Trial 1150 finished with value: 5.777841779928884 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005971668291841735, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.025037980776774105, 'dropout_rate_Layer_2': 0.020634889291478366, 'dropout_rate_Layer_3': 0.08488916436171719, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010009455464802112, 'l1_Layer_2': 0.009848366186853218, 'l1_Layer_3': 0.0010939378258741621, 'n_units_Layer_1': 80, 'n_units_Layer_2': 140, 'n_units_Layer_3': 275}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 19.73% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:15:00,834]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:15:09,464]\u001b[0m Trial 1159 finished with value: 5.794755545150856 and parameters: {'n_hidden': 3, 'learning_rate': 0.002902400474969631, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3210351977835993, 'dropout_rate_Layer_2': 0.259862849007593, 'dropout_rate_Layer_3': 0.10486730105259089, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014011548574360128, 'l1_Layer_2': 8.462759833707019e-05, 'l1_Layer_3': 0.00122720725357811, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 30.59% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:15:15,628]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:15:20,467]\u001b[0m Trial 1162 finished with value: 5.8539978435014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031238331331710206, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3216742135316195, 'dropout_rate_Layer_2': 0.24790314955662593, 'dropout_rate_Layer_3': 0.10522368966654216, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014238825712637758, 'l1_Layer_2': 8.596061831357066e-05, 'l1_Layer_3': 0.001153356187624373, 'n_units_Layer_1': 110, 'n_units_Layer_2': 65, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 20.15% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.99 | sMAPE for Test Set is: 30.24% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:15:43,439]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:15:49,406]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:16:20,217]\u001b[0m Trial 1167 finished with value: 5.806821621094365 and parameters: {'n_hidden': 3, 'learning_rate': 0.002649246463056466, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31420793143212083, 'dropout_rate_Layer_2': 0.24802060146648952, 'dropout_rate_Layer_3': 0.08704087983087024, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014499877772220824, 'l1_Layer_2': 8.50733196834108e-05, 'l1_Layer_3': 0.001095466816872892, 'n_units_Layer_1': 110, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.81 | sMAPE for Validation Set is: 19.95% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 29.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:16:33,598]\u001b[0m Trial 1165 finished with value: 5.879915489075738 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033165003562915904, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32376819617511704, 'dropout_rate_Layer_2': 0.25280370139042946, 'dropout_rate_Layer_3': 0.07122192154422484, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012572572862100818, 'l1_Layer_2': 9.83548667009288e-05, 'l1_Layer_3': 0.001194828668863534, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.88 | sMAPE for Validation Set is: 20.39% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.85 | sMAPE for Test Set is: 29.86% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:16:34,618]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:16:46,797]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.01 | sMAPE for Validation Set is: 20.23% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 29.97% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:17:14,693]\u001b[0m Trial 1163 finished with value: 6.0114164638526235 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005031111527841704, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05767132194947756, 'dropout_rate_Layer_2': 0.2761086751454093, 'dropout_rate_Layer_3': 0.022796927704678917, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00048605625204317735, 'l1_Layer_2': 0.0005384912055062881, 'l1_Layer_3': 1.9968412056114072e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 170, 'n_units_Layer_3': 140}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:17:18,473]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:17:22,685]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:17:24,350]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:17:41,646]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:18:52,947]\u001b[0m Trial 1173 finished with value: 5.945404576596769 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006373376126818428, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05512640276776397, 'dropout_rate_Layer_2': 0.2755417123969457, 'dropout_rate_Layer_3': 0.02750799697684629, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00064772641983966, 'l1_Layer_2': 0.0006889815876892645, 'l1_Layer_3': 3.070673097937656e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 145, 'n_units_Layer_3': 145}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.95 | sMAPE for Validation Set is: 20.18% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.70 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:19:00,583]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:19:03,694]\u001b[0m Trial 1174 finished with value: 5.756837462124239 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006199425841972079, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05834454239900119, 'dropout_rate_Layer_2': 0.03311484905528195, 'dropout_rate_Layer_3': 0.1050907466503869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015821697404636353, 'l1_Layer_2': 0.005680362846600728, 'l1_Layer_3': 0.001474281354020792, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 245}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 28.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:19:09,540]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:19:17,871]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:19:23,344]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:19:33,666]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:20:33,029]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:20:37,060]\u001b[0m Trial 1184 finished with value: 5.8468159883712145 and parameters: {'n_hidden': 3, 'learning_rate': 0.00273781069915128, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3076706564987007, 'dropout_rate_Layer_2': 0.2566730668604056, 'dropout_rate_Layer_3': 0.0821959334987175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013519104983886817, 'l1_Layer_2': 8.160272942993739e-05, 'l1_Layer_3': 0.0012525004652709337, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.85 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.02 | sMAPE for Test Set is: 30.04% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:20:40,706]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:20:44,129]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:20:46,745]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:20:51,624]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:20:56,433]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.83 | sMAPE for Validation Set is: 19.84% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.18 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:20:58,219]\u001b[0m Trial 1186 finished with value: 5.828282801672761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025951242335464186, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32626152995047886, 'dropout_rate_Layer_2': 0.2524185310920534, 'dropout_rate_Layer_3': 0.08601674485111398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013916785409041226, 'l1_Layer_2': 8.248876157589995e-05, 'l1_Layer_3': 0.0012732973203511972, 'n_units_Layer_1': 105, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:21:03,479]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:21:06,230]\u001b[0m Trial 1179 finished with value: 5.71906927165761 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006362901169964191, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.057729862737093934, 'dropout_rate_Layer_2': 0.03214349824918347, 'dropout_rate_Layer_3': 0.10295883163017887, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015239863698254172, 'l1_Layer_2': 0.005820116792479274, 'l1_Layer_3': 0.0013759943616439723, 'n_units_Layer_1': 65, 'n_units_Layer_2': 115, 'n_units_Layer_3': 285}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 28.61% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:21:12,341]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:21:13,470]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:21:39,557]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:21:51,769]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:22:38,370]\u001b[0m Trial 1194 finished with value: 5.779751553775907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025872791674985997, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30262601952671003, 'dropout_rate_Layer_2': 0.25689751359891594, 'dropout_rate_Layer_3': 0.07973236460387237, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013862608322152164, 'l1_Layer_2': 0.00010253344864987375, 'l1_Layer_3': 0.0011878271067764891, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 19.95% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 29.71% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:22:43,800]\u001b[0m Trial 1197 finished with value: 5.785826811192339 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024899494285115114, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.30071135259758003, 'dropout_rate_Layer_2': 0.2568669598726677, 'dropout_rate_Layer_3': 0.08305393636200056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014204200747573216, 'l1_Layer_2': 7.676173193918817e-05, 'l1_Layer_3': 0.0011702333125495656, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.79 | sMAPE for Validation Set is: 19.91% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.09 | sMAPE for Test Set is: 30.25% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:22:44,389]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.87 | sMAPE for Validation Set is: 20.33% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.55 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:22:47,888]\u001b[0m Trial 1198 finished with value: 5.8704303926414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028512927640283836, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3166870162941947, 'dropout_rate_Layer_2': 0.24160288744133246, 'dropout_rate_Layer_3': 0.08227997618864888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013834704639403194, 'l1_Layer_2': 7.962808193636492e-05, 'l1_Layer_3': 0.0012038100815891686, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:22:55,653]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:22:56,136]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:04,024]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:31,992]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:32,325]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:43,827]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:48,904]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:53,887]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:23:58,484]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:24:02,155]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:24:08,634]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:24:08,827]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:24:30,888]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:24:43,540]\u001b[0m Trial 1201 finished with value: 5.987593811122177 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006438415963670096, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04386324729514534, 'dropout_rate_Layer_2': 0.26668613717153844, 'dropout_rate_Layer_3': 0.017914390049430122, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006491023276262864, 'l1_Layer_2': 0.0007785493074144608, 'l1_Layer_3': 4.3132057849881406e-05, 'n_units_Layer_1': 155, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.99 | sMAPE for Validation Set is: 20.47% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 30.42% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:24:52,237]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:25:02,253]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:25:13,214]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:25:18,520]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:25:23,366]\u001b[0m Trial 1206 finished with value: 5.682192685290118 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023986234056841533, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3017430593916453, 'dropout_rate_Layer_2': 0.23620987861373707, 'dropout_rate_Layer_3': 0.07055353150365795, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00016012547823737586, 'l1_Layer_2': 7.562283458269577e-05, 'l1_Layer_3': 0.0012312913024507255, 'n_units_Layer_1': 95, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.68 | sMAPE for Validation Set is: 19.64% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.40 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:25:28,916]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:25:29,453]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 20.08% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.17 | sMAPE for Test Set is: 30.58% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:25:32,763]\u001b[0m Trial 1215 finished with value: 5.7994119028995454 and parameters: {'n_hidden': 3, 'learning_rate': 0.002575297555592512, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31588597838530763, 'dropout_rate_Layer_2': 0.2561273164107414, 'dropout_rate_Layer_3': 0.09087939629503058, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012420449492247165, 'l1_Layer_2': 9.503948406834439e-05, 'l1_Layer_3': 0.0011208417066264475, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:25:38,273]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:13,451]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:16,508]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:20,062]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:20,892]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:21,116]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:21,283]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:29,761]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:36,026]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:26:58,781]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:01,112]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:22,311]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:27,257]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:30,548]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:30,798]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:40,697]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:43,936]\u001b[0m Trial 1233 finished with value: 5.842293810665581 and parameters: {'n_hidden': 3, 'learning_rate': 0.002401287426689908, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3024462939863551, 'dropout_rate_Layer_2': 0.2520184498991117, 'dropout_rate_Layer_3': 0.08089082774410904, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001324330299257391, 'l1_Layer_2': 8.047718926305213e-05, 'l1_Layer_3': 0.001407109687056162, 'n_units_Layer_1': 100, 'n_units_Layer_2': 55, 'n_units_Layer_3': 300}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 19.89% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.86 | sMAPE for Test Set is: 29.71% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:27:49,001]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:51,224]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:27:54,753]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:28:00,554]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:28:07,658]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:28:17,614]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:28:54,854]\u001b[0m Trial 1239 finished with value: 5.856245249280467 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029091671550875893, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3140814816705567, 'dropout_rate_Layer_2': 0.24034504962611042, 'dropout_rate_Layer_3': 0.06462756867534855, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00018324249296842245, 'l1_Layer_2': 9.584562559395503e-05, 'l1_Layer_3': 0.00055988144700215, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.86 | sMAPE for Validation Set is: 20.20% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 29.73% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:29:00,065]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:00,764]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:11,529]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:16,901]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:21,473]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:27,207]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:31,454]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:38,235]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:46,310]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:46,999]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:29:52,377]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:30:55,414]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:30:58,374]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:31:01,849]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:31:12,775]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:31:17,952]\u001b[0m Trial 1244 finished with value: 5.725398570892698 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005687406852523346, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0015490385531014596, 'dropout_rate_Layer_2': 0.020133701337556605, 'dropout_rate_Layer_3': 0.10503643827309275, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019520713831899727, 'l1_Layer_2': 0.007742103915476192, 'l1_Layer_3': 0.002247453682361785, 'n_units_Layer_1': 65, 'n_units_Layer_2': 145, 'n_units_Layer_3': 230}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.50% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.56 | sMAPE for Test Set is: 28.51% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:31:37,673]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:31:44,443]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:32:25,903]\u001b[0m Trial 1262 finished with value: 5.774016495885076 and parameters: {'n_hidden': 3, 'learning_rate': 0.002949403345414742, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3217190520872688, 'dropout_rate_Layer_2': 0.23861710769611166, 'dropout_rate_Layer_3': 0.0738733303954766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014711406788992708, 'l1_Layer_2': 9.61873026794081e-05, 'l1_Layer_3': 0.0009474208856132858, 'n_units_Layer_1': 110, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.90% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.98 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:32:41,653]\u001b[0m Trial 1264 finished with value: 5.760793551196599 and parameters: {'n_hidden': 3, 'learning_rate': 0.000736823598587786, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.026234299666296406, 'dropout_rate_Layer_2': 0.015025102995210107, 'dropout_rate_Layer_3': 0.09003219893289174, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001771529156907123, 'l1_Layer_2': 0.0035471533770915836, 'l1_Layer_3': 0.001094936938057829, 'n_units_Layer_1': 65, 'n_units_Layer_2': 125, 'n_units_Layer_3': 270}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.76 | sMAPE for Validation Set is: 19.76% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:33:39,138]\u001b[0m Trial 1270 finished with value: 5.84231555793247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025255544571743285, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3229111396648078, 'dropout_rate_Layer_2': 0.25939302389517954, 'dropout_rate_Layer_3': 0.06443598799959013, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001926358197634137, 'l1_Layer_2': 8.968226903693757e-05, 'l1_Layer_3': 0.0008509770345827382, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 300}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.84 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 29.70% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:33:44,393]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:33:47,854]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:33:52,914]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:00,244]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:26,558]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:29,894]\u001b[0m Trial 1273 finished with value: 5.997179897171159 and parameters: {'n_hidden': 3, 'learning_rate': 0.002506984940975319, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.32088171299315943, 'dropout_rate_Layer_2': 0.2580917938864241, 'dropout_rate_Layer_3': 0.054229952680500015, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019205830478933952, 'l1_Layer_2': 7.546443485788568e-05, 'l1_Layer_3': 0.0004019897993427462, 'n_units_Layer_1': 100, 'n_units_Layer_2': 50, 'n_units_Layer_3': 300}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.00 | sMAPE for Validation Set is: 20.12% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 6.87 | sMAPE for Test Set is: 29.56% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:34:34,048]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:39,225]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:45,312]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 19.70% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.58 | sMAPE for Test Set is: 28.71% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:34:47,556]\u001b[0m Trial 1265 finished with value: 5.745707026547172 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007312172299485608, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.021679685980200706, 'dropout_rate_Layer_2': 0.02644775753388283, 'dropout_rate_Layer_3': 0.07870165878475263, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018583134346645096, 'l1_Layer_2': 0.0035493726156748924, 'l1_Layer_3': 0.0027887079591301244, 'n_units_Layer_1': 65, 'n_units_Layer_2': 125, 'n_units_Layer_3': 270}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:53,775]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:34:56,225]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:03,938]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:04,567]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:12,272]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:16,136]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:17,690]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:21,737]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:25,590]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:25,640]\u001b[0m Trial 1269 finished with value: 6.06627713206552 and parameters: {'n_hidden': 3, 'learning_rate': 0.000670098905888684, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03950540564281606, 'dropout_rate_Layer_2': 0.2917166721911551, 'dropout_rate_Layer_3': 0.03990286077540011, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008001951758950176, 'l1_Layer_2': 0.0005266488543093041, 'l1_Layer_3': 1.6609293443136136e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 20.59% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 6.66 | sMAPE for Test Set is: 29.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:35:26,422]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:37,201]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:37,500]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:35:37,972]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:36:07,757]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:36:14,891]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:37:17,938]\u001b[0m Trial 1295 finished with value: 5.802843754149322 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025797953507377164, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29840684476800067, 'dropout_rate_Layer_2': 0.2548322418897894, 'dropout_rate_Layer_3': 0.03896932836905956, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00019416265286773828, 'l1_Layer_2': 0.00010233497056980183, 'l1_Layer_3': 0.0005267515571084684, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.78 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:37:21,838]\u001b[0m Trial 1290 finished with value: 5.780138691358643 and parameters: {'n_hidden': 3, 'learning_rate': 0.00259168192804848, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2977222010633324, 'dropout_rate_Layer_2': 0.2560802823602214, 'dropout_rate_Layer_3': 0.07855349857264098, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00017185113671497204, 'l1_Layer_2': 0.00010471138608960771, 'l1_Layer_3': 0.0003298492961249336, 'n_units_Layer_1': 100, 'n_units_Layer_2': 60, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 20.05% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.31 | sMAPE for Test Set is: 31.41% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:37:46,152]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:37:54,338]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:37:54,839]\u001b[0m Trial 1293 finished with value: 5.716028668474358 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008249723324549708, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03990365491087993, 'dropout_rate_Layer_2': 0.027954470234365234, 'dropout_rate_Layer_3': 0.07786858707592927, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0015900013656203172, 'l1_Layer_2': 0.0053260109135143995, 'l1_Layer_3': 0.002969025323448807, 'n_units_Layer_1': 75, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 19.55% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.62 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:37:59,803]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:05,374]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:11,180]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:19,101]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:24,899]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:31,410]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:34,364]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:40,952]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:41,083]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:48,011]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:53,644]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:38:57,144]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:03,110]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:05,458]\u001b[0m Trial 1297 finished with value: 5.707982812768171 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006345976723609213, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03973122458566446, 'dropout_rate_Layer_2': 0.02978038872698357, 'dropout_rate_Layer_3': 0.07830624552551813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001605741632539354, 'l1_Layer_2': 0.006470478647232959, 'l1_Layer_3': 0.0021008396599381074, 'n_units_Layer_1': 75, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 19.53% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.52 | sMAPE for Test Set is: 28.51% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:39:08,393]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:13,042]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:14,892]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:21,878]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:27,262]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:32,453]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:39:40,513]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:40:05,150]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:40:22,559]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:40:29,217]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:40:43,444]\u001b[0m Trial 1301 finished with value: 5.720094857483104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006567415137373558, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03824692136591769, 'dropout_rate_Layer_2': 0.006175064377090186, 'dropout_rate_Layer_3': 0.07417583525285143, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019707968154734014, 'l1_Layer_2': 0.006966267579915807, 'l1_Layer_3': 0.0034487806758119197, 'n_units_Layer_1': 75, 'n_units_Layer_2': 120, 'n_units_Layer_3': 235}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.72 | sMAPE for Validation Set is: 19.49% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.64 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:41:08,280]\u001b[0m Trial 1318 finished with value: 5.7654401334368215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008914220002135922, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04566258521120203, 'dropout_rate_Layer_2': 0.008524282404372599, 'dropout_rate_Layer_3': 0.08463016518845934, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001257484435461786, 'l1_Layer_2': 0.004249756466854341, 'l1_Layer_3': 0.0030900768655346225, 'n_units_Layer_1': 90, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.74% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.47 | sMAPE for Test Set is: 28.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:41:13,673]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:41:18,454]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:41:26,036]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:41:40,857]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:00,249]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:08,213]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:13,769]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:24,038]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:26,286]\u001b[0m Trial 1324 finished with value: 5.727919017735946 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005742693335234598, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04310077760065489, 'dropout_rate_Layer_2': 0.005664365498227323, 'dropout_rate_Layer_3': 0.08686528451028779, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.001293125429525297, 'l1_Layer_2': 0.004496422527283302, 'l1_Layer_3': 0.002516834972123889, 'n_units_Layer_1': 80, 'n_units_Layer_2': 120, 'n_units_Layer_3': 285}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.66% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:42:32,014]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:35,141]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:39,326]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:43,395]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:44,707]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:49,944]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:54,777]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:42:56,327]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:02,144]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:04,827]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:10,806]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:16,610]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:22,381]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:38,289]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:40,551]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:43:42,609]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:06,452]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:10,787]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:15,552]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:30,523]\u001b[0m Trial 1346 finished with value: 5.817826070900819 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025903060407004887, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2997453214969561, 'dropout_rate_Layer_2': 0.24601294753352726, 'dropout_rate_Layer_3': 0.0943619974048957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00011783134571038333, 'l1_Layer_2': 8.809171990635441e-05, 'l1_Layer_3': 0.0004509184897331958, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 20.04% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.21 | sMAPE for Test Set is: 30.90% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:44:36,802]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:44,904]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:50,888]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:44:55,379]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:45:01,307]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:45:05,268]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:45:10,685]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:45:27,998]\u001b[0m Trial 1352 finished with value: 5.770468755891648 and parameters: {'n_hidden': 3, 'learning_rate': 0.002607353988827924, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2995649574415931, 'dropout_rate_Layer_2': 0.24418598113659648, 'dropout_rate_Layer_3': 0.09783025417923817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00011748402253848729, 'l1_Layer_2': 0.00012243189812035532, 'l1_Layer_3': 0.0008897313029019986, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.92% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.89 | sMAPE for Test Set is: 30.01% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:45:34,437]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:45:38,822]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:46:05,574]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:46:16,882]\u001b[0m Trial 1354 finished with value: 5.769384950481535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025483622849177463, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29977579124049025, 'dropout_rate_Layer_2': 0.23364532611674788, 'dropout_rate_Layer_3': 0.09755223862191074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000214887554934795, 'l1_Layer_2': 0.00012351245257814948, 'l1_Layer_3': 0.0009092488434130995, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.87% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 7.03 | sMAPE for Test Set is: 30.38% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:46:19,205]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:46:25,193]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:46:31,418]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:46:37,814]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:46:38,784]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:06,778]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:11,466]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:17,785]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:18,005]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 20.01% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.79 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:47:23,735]\u001b[0m Trial 1366 finished with value: 5.801100947226725 and parameters: {'n_hidden': 3, 'learning_rate': 0.002335448317387308, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2907476649653302, 'dropout_rate_Layer_2': 0.23684277464451378, 'dropout_rate_Layer_3': 0.09489399890600421, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00016426970444206285, 'l1_Layer_2': 8.221931935494252e-05, 'l1_Layer_3': 0.00048099988365198353, 'n_units_Layer_1': 110, 'n_units_Layer_2': 50, 'n_units_Layer_3': 295}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:28,349]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:28,427]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:30,011]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:38,964]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:44,203]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:44,567]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:54,637]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:47:57,916]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:20,592]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:25,967]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:34,280]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:35,101]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:39,729]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:43,757]\u001b[0m Trial 1368 finished with value: 5.7276644841374855 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006093936991998931, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.037103953440175384, 'dropout_rate_Layer_2': 0.01601944829396136, 'dropout_rate_Layer_3': 0.06515092386608538, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002138555046257181, 'l1_Layer_2': 0.005645828620018041, 'l1_Layer_3': 0.00295806043309235, 'n_units_Layer_1': 80, 'n_units_Layer_2': 145, 'n_units_Layer_3': 210}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.58% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 28.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:48:47,162]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:48,855]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:49,663]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:55,378]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:48:59,170]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:05,013]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:07,224]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:20,013]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:22,967]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:25,428]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:25,967]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:33,480]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:33,697]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:41,580]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:41,814]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:42,743]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:49,086]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:52,481]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:49:56,789]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:08,580]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:15,255]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:16,205]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:16,777]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:16,879]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:27,124]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:31,961]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:36,241]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:36,600]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:42,414]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:45,193]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:48,294]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:49,586]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:50:55,916]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:11,505]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:14,337]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:20,606]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:23,066]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:31,499]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:49,615]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:51:57,591]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:52:20,169]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:52:29,262]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:52:35,081]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:52:47,766]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:52:53,756]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:52:59,079]\u001b[0m Trial 1417 finished with value: 5.743528962666015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007300464785670714, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.018011100817724328, 'dropout_rate_Layer_2': 0.02499608131730762, 'dropout_rate_Layer_3': 0.07387187809359258, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016146516699512617, 'l1_Layer_2': 0.0026581721544049904, 'l1_Layer_3': 0.0028133308519319804, 'n_units_Layer_1': 65, 'n_units_Layer_2': 140, 'n_units_Layer_3': 270}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.68% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.48 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:52:59,229]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:03,681]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:08,976]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:09,494]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:18,840]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:27,746]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:30,443]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:35,399]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:36,175]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:40,266]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:43,399]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:48,658]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:50,159]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:53:56,077]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:15,871]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:22,226]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:33,356]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:37,740]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:38,368]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.75 | sMAPE for Validation Set is: 19.79% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.43 | sMAPE for Test Set is: 28.22% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:54:41,145]\u001b[0m Trial 1432 finished with value: 5.750452122626136 and parameters: {'n_hidden': 3, 'learning_rate': 0.000544369155601138, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.034731707570691134, 'dropout_rate_Layer_2': 0.027060287744876465, 'dropout_rate_Layer_3': 0.06697991553258532, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0019085703540922974, 'l1_Layer_2': 0.0037204657148239765, 'l1_Layer_3': 0.0028872222687526716, 'n_units_Layer_1': 70, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:45,940]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:48,758]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:52,158]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:54:59,610]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:55:00,878]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:55:06,905]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:55:51,228]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:55:57,461]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:56:30,922]\u001b[0m Trial 1464 finished with value: 5.7767428584845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032625426097225565, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.31026494841516733, 'dropout_rate_Layer_2': 0.23338556379185688, 'dropout_rate_Layer_3': 0.08230738280980164, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00013502343271191644, 'l1_Layer_2': 5.418571416279678e-05, 'l1_Layer_3': 0.001168619981972575, 'n_units_Layer_1': 105, 'n_units_Layer_2': 55, 'n_units_Layer_3': 280}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.78 | sMAPE for Validation Set is: 19.72% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.95 | sMAPE for Test Set is: 29.69% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:56:36,787]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:56:47,087]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:56:55,861]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:57:08,004]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:57:13,594]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:57:21,799]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:57:35,120]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:57:48,901]\u001b[0m Trial 1465 finished with value: 5.729573526432117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007437038655649119, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02203740826487245, 'dropout_rate_Layer_2': 0.034644945624323104, 'dropout_rate_Layer_3': 0.08007577510371269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029524032184263245, 'l1_Layer_2': 0.0025966420869407048, 'l1_Layer_3': 0.0022844418551311403, 'n_units_Layer_1': 60, 'n_units_Layer_2': 120, 'n_units_Layer_3': 270}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.73 | sMAPE for Validation Set is: 19.69% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 28.32% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:57:56,314]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 243.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:58:00,033]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:58:05,713]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:58:31,650]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:58:36,340]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:58:46,149]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:59:03,127]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:59:08,793]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:59:20,751]\u001b[0m Trial 1474 finished with value: 5.671896694566311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026612941161947047, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.29098111138790206, 'dropout_rate_Layer_2': 0.21914157343174798, 'dropout_rate_Layer_3': 0.0723181709464115, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00020592665762294725, 'l1_Layer_2': 5.3155687331602185e-05, 'l1_Layer_3': 0.0012044037884668818, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 285}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.67 | sMAPE for Validation Set is: 19.52% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 7.10 | sMAPE for Test Set is: 30.23% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 22:59:29,106]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 22:59:37,548]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:00:20,956]\u001b[0m Trial 1475 finished with value: 5.714643223892821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006083561345090507, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00815923612054277, 'dropout_rate_Layer_2': 0.021574368401759837, 'dropout_rate_Layer_3': 0.07448430982442271, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.002152970117905157, 'l1_Layer_2': 0.0024333434483637187, 'l1_Layer_3': 0.003496694821927443, 'n_units_Layer_1': 85, 'n_units_Layer_2': 130, 'n_units_Layer_3': 275}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 19.59% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 23:00:27,253]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:00:33,465]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:00:43,253]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:00:48,819]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:00:55,499]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:01:18,605]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:01:18,866]\u001b[0m Trial 1478 finished with value: 5.708067118445173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006092860256942871, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011476974619636263, 'dropout_rate_Layer_2': 0.043056826804033554, 'dropout_rate_Layer_3': 0.0723579301775823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.003484541857814018, 'l1_Layer_2': 0.002497681165552028, 'l1_Layer_3': 0.0017444069502808035, 'n_units_Layer_1': 85, 'n_units_Layer_2': 160, 'n_units_Layer_3': 200}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.71 | sMAPE for Validation Set is: 19.56% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.44 | sMAPE for Test Set is: 28.23% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 23:01:25,802]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:01:34,117]\u001b[0m Trial 1484 finished with value: 5.768600078227219 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005013943478818451, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00856266656451528, 'dropout_rate_Layer_2': 0.019297711142535895, 'dropout_rate_Layer_3': 0.09223180238403664, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0034511279507754705, 'l1_Layer_2': 0.0021579438799520447, 'l1_Layer_3': 0.0016848745118749832, 'n_units_Layer_1': 60, 'n_units_Layer_2': 150, 'n_units_Layer_3': 215}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.77 | sMAPE for Validation Set is: 19.82% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.51 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 23:01:45,351]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:01:48,669]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:01:53,738]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-02 23:02:04,396]\u001b[0m Trial 1487 finished with value: 5.738820704391688 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006037801357310223, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006949045849270218, 'dropout_rate_Layer_2': 0.018645251256491645, 'dropout_rate_Layer_3': 0.0921571396794145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0032832428863993628, 'l1_Layer_2': 0.006881897463694229, 'l1_Layer_3': 0.0019210604508937237, 'n_units_Layer_1': 85, 'n_units_Layer_2': 115, 'n_units_Layer_3': 215}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.74 | sMAPE for Validation Set is: 19.77% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 6.50 | sMAPE for Test Set is: 28.40% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 23:02:26,539]\u001b[0m Trial 1497 finished with value: 5.817965274096591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033324624409470137, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3118211762307052, 'dropout_rate_Layer_2': 0.23653205813746234, 'dropout_rate_Layer_3': 0.0921413451406813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00014944696942069386, 'l1_Layer_2': 6.279498157448336e-05, 'l1_Layer_3': 0.0011038535842904415, 'n_units_Layer_1': 90, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.82 | sMAPE for Validation Set is: 19.86% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 6.77 | sMAPE for Test Set is: 29.37% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-02 23:02:37,964]\u001b[0m Trial 1498 finished with value: 5.79845235013984 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033041714949140605, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2749342101927578, 'dropout_rate_Layer_2': 0.23795219806339324, 'dropout_rate_Layer_3': 0.09262214333178968, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0001402453675691693, 'l1_Layer_2': 5.8005578795709146e-05, 'l1_Layer_3': 0.0007676796606610812, 'n_units_Layer_1': 50, 'n_units_Layer_2': 50, 'n_units_Layer_3': 290}. Best is trial 985 with value: 5.670058594652464.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 5.80 | sMAPE for Validation Set is: 20.02% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 7.22 | sMAPE for Test Set is: 31.08% | rMAE for Test Set is: 0.70\n",
      "for 2020-01-01, MAE is:6.51 & sMAPE is:19.77% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.51 & 19.77% & 0.76\n",
      "for 2020-01-02, MAE is:5.45 & sMAPE is:14.51% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :5.98 & 17.14% & 0.79\n",
      "for 2020-01-03, MAE is:6.49 & sMAPE is:39.29% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.15 & 24.52% & 0.71\n",
      "for 2020-01-04, MAE is:5.72 & sMAPE is:44.99% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.04 & 29.64% & 0.63\n",
      "for 2020-01-05, MAE is:3.23 & sMAPE is:9.05% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 25.52% & 0.62\n",
      "for 2020-01-06, MAE is:3.08 & sMAPE is:9.00% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :5.08 & 22.77% & 0.56\n",
      "for 2020-01-07, MAE is:7.54 & sMAPE is:20.48% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 22.44% & 0.58\n",
      "for 2020-01-08, MAE is:9.11 & sMAPE is:45.00% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 25.26% & 0.60\n",
      "for 2020-01-09, MAE is:8.40 & sMAPE is:20.15% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.17 & 24.69% & 0.73\n",
      "for 2020-01-10, MAE is:6.36 & sMAPE is:19.53% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.19 & 24.18% & 0.71\n",
      "for 2020-01-11, MAE is:5.39 & sMAPE is:16.65% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 23.49% & 0.67\n",
      "for 2020-01-12, MAE is:4.05 & sMAPE is:20.42% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.94 & 23.24% & 0.64\n",
      "for 2020-01-13, MAE is:7.94 & sMAPE is:24.18% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :6.10 & 23.31% & 0.72\n",
      "for 2020-01-14, MAE is:8.42 & sMAPE is:39.16% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 24.44% & 0.71\n",
      "for 2020-01-15, MAE is:6.38 & sMAPE is:47.05% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.27 & 25.95% & 0.70\n",
      "for 2020-01-16, MAE is:6.07 & sMAPE is:17.86% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.26 & 25.44% & 0.77\n",
      "for 2020-01-17, MAE is:2.90 & sMAPE is:8.12% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.06 & 24.42% & 0.77\n",
      "for 2020-01-18, MAE is:2.90 & sMAPE is:9.54% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.89 & 23.60% & 0.75\n",
      "for 2020-01-19, MAE is:3.45 & sMAPE is:11.06% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :5.76 & 22.94% & 0.73\n",
      "for 2020-01-20, MAE is:3.96 & sMAPE is:8.66% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :5.67 & 22.22% & 0.72\n",
      "for 2020-01-21, MAE is:3.78 & sMAPE is:8.59% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.58 & 21.57% & 0.69\n",
      "for 2020-01-22, MAE is:6.92 & sMAPE is:15.38% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :5.64 & 21.29% & 0.68\n",
      "for 2020-01-23, MAE is:6.13 & sMAPE is:12.19% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :5.66 & 20.90% & 0.67\n",
      "for 2020-01-24, MAE is:4.93 & sMAPE is:9.47% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 20.42% & 0.65\n",
      "for 2020-01-25, MAE is:1.89 & sMAPE is:4.62% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :5.48 & 19.79% & 0.64\n",
      "for 2020-01-26, MAE is:3.59 & sMAPE is:10.40% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :5.41 & 19.43% & 0.64\n",
      "for 2020-01-27, MAE is:3.33 & sMAPE is:10.11% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.33 & 19.08% & 0.64\n",
      "for 2020-01-28, MAE is:7.26 & sMAPE is:21.94% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :5.40 & 19.19% & 0.64\n",
      "for 2020-01-29, MAE is:6.28 & sMAPE is:27.78% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :5.43 & 19.48% & 0.63\n",
      "for 2020-01-30, MAE is:6.42 & sMAPE is:23.00% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :5.46 & 19.60% & 0.63\n",
      "for 2020-01-31, MAE is:10.65 & sMAPE is:65.97% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :5.63 & 21.09% & 0.62\n",
      "for 2020-02-01, MAE is:15.05 & sMAPE is:125.77% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :5.93 & 24.37% & 0.61\n",
      "for 2020-02-02, MAE is:12.80 & sMAPE is:79.97% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :6.13 & 26.05% & 0.62\n",
      "for 2020-02-03, MAE is:5.69 & sMAPE is:22.91% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 25.96% & 0.62\n",
      "for 2020-02-04, MAE is:6.18 & sMAPE is:21.02% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.12 & 25.82% & 0.62\n",
      "for 2020-02-05, MAE is:4.52 & sMAPE is:14.66% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.08 & 25.51% & 0.65\n",
      "for 2020-02-06, MAE is:2.06 & sMAPE is:5.76% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :5.97 & 24.97% & 0.64\n",
      "for 2020-02-07, MAE is:6.73 & sMAPE is:17.11% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :5.99 & 24.77% & 0.64\n",
      "for 2020-02-08, MAE is:4.44 & sMAPE is:16.95% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :5.95 & 24.57% & 0.62\n",
      "for 2020-02-09, MAE is:22.46 & sMAPE is:146.39% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :6.36 & 27.61% & 0.63\n",
      "for 2020-02-10, MAE is:17.18 & sMAPE is:86.03% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :6.63 & 29.04% & 0.64\n",
      "for 2020-02-11, MAE is:14.57 & sMAPE is:101.55% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 30.76% & 0.64\n",
      "for 2020-02-12, MAE is:9.89 & sMAPE is:69.64% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 31.67% & 0.64\n",
      "for 2020-02-13, MAE is:8.20 & sMAPE is:32.44% & rMAE is:2.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 31.68% & 0.69\n",
      "for 2020-02-14, MAE is:5.86 & sMAPE is:16.20% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 31.34% & 0.72\n",
      "for 2020-02-15, MAE is:9.15 & sMAPE is:48.72% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 31.72% & 0.72\n",
      "for 2020-02-16, MAE is:20.21 & sMAPE is:162.48% & rMAE is:1.99 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 34.50% & 0.75\n",
      "for 2020-02-17, MAE is:9.29 & sMAPE is:55.50% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 34.94% & 0.75\n",
      "for 2020-02-18, MAE is:12.36 & sMAPE is:66.34% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 35.58% & 0.76\n",
      "for 2020-02-19, MAE is:6.28 & sMAPE is:27.57% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.35 & 35.42% & 0.75\n",
      "for 2020-02-20, MAE is:9.23 & sMAPE is:28.59% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 35.28% & 0.76\n",
      "for 2020-02-21, MAE is:9.15 & sMAPE is:61.89% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 35.80% & 0.76\n",
      "for 2020-02-22, MAE is:18.54 & sMAPE is:172.61% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 38.38% & 0.76\n",
      "for 2020-02-23, MAE is:8.72 & sMAPE is:82.43% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 39.19% & 0.76\n",
      "for 2020-02-24, MAE is:11.24 & sMAPE is:75.41% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 39.85% & 0.76\n",
      "for 2020-02-25, MAE is:6.76 & sMAPE is:34.09% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 39.75% & 0.77\n",
      "for 2020-02-26, MAE is:5.34 & sMAPE is:17.67% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 39.36% & 0.80\n",
      "for 2020-02-27, MAE is:5.82 & sMAPE is:15.91% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 38.96% & 0.80\n",
      "for 2020-02-28, MAE is:7.83 & sMAPE is:22.81% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 38.68% & 0.80\n",
      "for 2020-02-29, MAE is:13.12 & sMAPE is:82.11% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 39.41% & 0.81\n",
      "for 2020-03-01, MAE is:9.85 & sMAPE is:116.71% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 40.67% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-03-02, MAE is:4.42 & sMAPE is:18.39% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 40.32% & 0.80\n",
      "for 2020-03-03, MAE is:3.70 & sMAPE is:9.49% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 39.83% & 0.79\n",
      "for 2020-03-04, MAE is:4.66 & sMAPE is:11.01% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 39.38% & 0.79\n",
      "for 2020-03-05, MAE is:5.22 & sMAPE is:15.12% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 39.00% & 0.79\n",
      "for 2020-03-06, MAE is:3.57 & sMAPE is:15.65% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 38.65% & 0.79\n",
      "for 2020-03-07, MAE is:4.27 & sMAPE is:15.56% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 38.30% & 0.78\n",
      "for 2020-03-08, MAE is:6.06 & sMAPE is:38.15% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 38.30% & 0.78\n",
      "for 2020-03-09, MAE is:4.63 & sMAPE is:12.75% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 37.93% & 0.78\n",
      "for 2020-03-10, MAE is:8.93 & sMAPE is:35.20% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 37.89% & 0.78\n",
      "for 2020-03-11, MAE is:7.67 & sMAPE is:71.53% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 38.37% & 0.78\n",
      "for 2020-03-12, MAE is:11.12 & sMAPE is:96.82% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 39.18% & 0.77\n",
      "for 2020-03-13, MAE is:11.57 & sMAPE is:75.28% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 39.67% & 0.77\n",
      "for 2020-03-14, MAE is:6.07 & sMAPE is:19.07% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 39.39% & 0.79\n",
      "for 2020-03-15, MAE is:15.89 & sMAPE is:106.07% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 40.28% & 0.80\n",
      "for 2020-03-16, MAE is:7.51 & sMAPE is:23.01% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 40.06% & 0.80\n",
      "for 2020-03-17, MAE is:8.38 & sMAPE is:25.91% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 39.87% & 0.81\n",
      "for 2020-03-18, MAE is:5.02 & sMAPE is:19.31% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 39.61% & 0.80\n",
      "for 2020-03-19, MAE is:4.52 & sMAPE is:14.67% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 39.29% & 0.80\n",
      "for 2020-03-20, MAE is:6.27 & sMAPE is:22.94% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 39.09% & 0.79\n",
      "for 2020-03-21, MAE is:9.26 & sMAPE is:64.87% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 39.41% & 0.79\n",
      "for 2020-03-22, MAE is:16.44 & sMAPE is:124.56% & rMAE is:2.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 40.45% & 0.81\n",
      "for 2020-03-23, MAE is:9.17 & sMAPE is:72.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 40.83% & 0.81\n",
      "for 2020-03-24, MAE is:9.38 & sMAPE is:48.36% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 40.92% & 0.81\n",
      "for 2020-03-25, MAE is:7.67 & sMAPE is:37.64% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 40.89% & 0.83\n",
      "for 2020-03-26, MAE is:7.01 & sMAPE is:33.84% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 40.80% & 0.83\n",
      "for 2020-03-27, MAE is:7.70 & sMAPE is:32.40% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 40.71% & 0.84\n",
      "for 2020-03-28, MAE is:9.41 & sMAPE is:65.38% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 40.99% & 0.85\n",
      "for 2020-03-29, MAE is:10.78 & sMAPE is:113.98% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 41.81% & 0.85\n",
      "for 2020-03-30, MAE is:6.06 & sMAPE is:31.48% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 41.69% & 0.85\n",
      "for 2020-03-31, MAE is:5.82 & sMAPE is:24.34% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 41.50% & 0.86\n",
      "for 2020-04-01, MAE is:4.50 & sMAPE is:20.08% & rMAE is:2.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 41.27% & 0.87\n",
      "for 2020-04-02, MAE is:7.35 & sMAPE is:38.74% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 41.24% & 0.88\n",
      "for 2020-04-03, MAE is:5.67 & sMAPE is:32.68% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 41.15% & 0.90\n",
      "for 2020-04-04, MAE is:4.27 & sMAPE is:21.53% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 40.94% & 0.90\n",
      "for 2020-04-05, MAE is:11.21 & sMAPE is:81.61% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 41.37% & 0.90\n",
      "for 2020-04-06, MAE is:6.75 & sMAPE is:73.36% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 41.70% & 0.90\n",
      "for 2020-04-07, MAE is:8.50 & sMAPE is:36.26% & rMAE is:3.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 41.64% & 0.93\n",
      "for 2020-04-08, MAE is:7.21 & sMAPE is:32.11% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 41.55% & 0.94\n",
      "for 2020-04-09, MAE is:5.73 & sMAPE is:22.45% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 41.36% & 0.95\n",
      "for 2020-04-10, MAE is:5.47 & sMAPE is:26.84% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 41.21% & 0.95\n",
      "for 2020-04-11, MAE is:5.49 & sMAPE is:30.25% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 41.10% & 0.96\n",
      "for 2020-04-12, MAE is:6.57 & sMAPE is:66.71% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 41.35% & 0.96\n",
      "for 2020-04-13, MAE is:28.08 & sMAPE is:164.98% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :7.77 & 42.54% & 0.96\n",
      "for 2020-04-14, MAE is:5.17 & sMAPE is:51.47% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.75 & 42.63% & 0.96\n",
      "for 2020-04-15, MAE is:7.03 & sMAPE is:36.14% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.74 & 42.57% & 0.96\n",
      "for 2020-04-16, MAE is:6.28 & sMAPE is:25.68% & rMAE is:2.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.73 & 42.41% & 0.97\n",
      "for 2020-04-17, MAE is:6.98 & sMAPE is:25.61% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 42.25% & 0.97\n",
      "for 2020-04-18, MAE is:6.55 & sMAPE is:39.83% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 42.23% & 0.98\n",
      "for 2020-04-19, MAE is:9.62 & sMAPE is:87.91% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 42.64% & 0.98\n",
      "for 2020-04-20, MAE is:16.58 & sMAPE is:121.33% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.80 & 43.35% & 0.98\n",
      "for 2020-04-21, MAE is:37.22 & sMAPE is:153.99% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 44.34% & 0.98\n",
      "for 2020-04-22, MAE is:16.45 & sMAPE is:111.22% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :8.14 & 44.93% & 0.99\n",
      "for 2020-04-23, MAE is:9.20 & sMAPE is:36.32% & rMAE is:2.41 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 44.86% & 1.00\n",
      "for 2020-04-24, MAE is:9.42 & sMAPE is:38.88% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.16 & 44.81% & 1.00\n",
      "for 2020-04-25, MAE is:3.50 & sMAPE is:25.79% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :8.12 & 44.64% & 1.00\n",
      "for 2020-04-26, MAE is:5.55 & sMAPE is:36.07% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :8.10 & 44.57% & 0.99\n",
      "for 2020-04-27, MAE is:5.03 & sMAPE is:19.06% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 44.35% & 0.99\n",
      "for 2020-04-28, MAE is:3.07 & sMAPE is:11.44% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :8.03 & 44.08% & 0.98\n",
      "for 2020-04-29, MAE is:3.98 & sMAPE is:21.82% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :8.00 & 43.89% & 0.97\n",
      "for 2020-04-30, MAE is:4.88 & sMAPE is:27.40% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.97 & 43.75% & 0.97\n",
      "for 2020-05-01, MAE is:5.47 & sMAPE is:116.88% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.95 & 44.35% & 0.97\n",
      "for 2020-05-02, MAE is:3.27 & sMAPE is:40.95% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.91 & 44.33% & 0.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-05-03, MAE is:2.72 & sMAPE is:22.73% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :7.87 & 44.15% & 0.96\n",
      "for 2020-05-04, MAE is:6.32 & sMAPE is:24.12% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :7.86 & 43.99% & 0.96\n",
      "for 2020-05-05, MAE is:4.09 & sMAPE is:25.06% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.83 & 43.84% & 0.96\n",
      "for 2020-05-06, MAE is:4.81 & sMAPE is:26.32% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 43.70% & 0.97\n",
      "for 2020-05-07, MAE is:5.73 & sMAPE is:26.86% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.79 & 43.57% & 0.97\n",
      "for 2020-05-08, MAE is:3.85 & sMAPE is:16.33% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.76 & 43.36% & 0.96\n",
      "for 2020-05-09, MAE is:3.30 & sMAPE is:15.55% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 43.15% & 0.96\n",
      "for 2020-05-10, MAE is:6.30 & sMAPE is:52.66% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 43.22% & 0.96\n",
      "for 2020-05-11, MAE is:6.19 & sMAPE is:72.09% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 43.44% & 0.96\n",
      "for 2020-05-12, MAE is:5.81 & sMAPE is:32.18% & rMAE is:4.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 43.35% & 0.98\n",
      "for 2020-05-13, MAE is:8.67 & sMAPE is:34.80% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 43.29% & 0.98\n",
      "for 2020-05-14, MAE is:3.99 & sMAPE is:22.81% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 43.14% & 0.98\n",
      "for 2020-05-15, MAE is:4.12 & sMAPE is:22.55% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 42.99% & 0.98\n",
      "for 2020-05-16, MAE is:3.36 & sMAPE is:23.27% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 42.84% & 0.98\n",
      "for 2020-05-17, MAE is:6.70 & sMAPE is:68.13% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 43.03% & 0.98\n",
      "for 2020-05-18, MAE is:5.71 & sMAPE is:27.91% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 42.92% & 0.98\n",
      "for 2020-05-19, MAE is:4.73 & sMAPE is:21.38% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 42.76% & 0.98\n",
      "for 2020-05-20, MAE is:8.54 & sMAPE is:27.03% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 42.65% & 0.98\n",
      "for 2020-05-21, MAE is:2.97 & sMAPE is:14.06% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 42.45% & 0.98\n",
      "for 2020-05-22, MAE is:4.62 & sMAPE is:29.27% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :7.52 & 42.36% & 0.98\n",
      "for 2020-05-23, MAE is:5.82 & sMAPE is:61.41% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 42.49% & 0.98\n",
      "for 2020-05-24, MAE is:36.56 & sMAPE is:170.55% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.71 & 43.37% & 0.98\n",
      "for 2020-05-25, MAE is:4.76 & sMAPE is:55.36% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 43.46% & 0.98\n",
      "for 2020-05-26, MAE is:6.65 & sMAPE is:25.56% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :7.69 & 43.33% & 0.99\n",
      "for 2020-05-27, MAE is:6.52 & sMAPE is:24.79% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 43.21% & 0.99\n",
      "for 2020-05-28, MAE is:4.97 & sMAPE is:25.04% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 43.09% & 0.99\n",
      "for 2020-05-29, MAE is:4.18 & sMAPE is:19.68% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 42.93% & 0.99\n",
      "for 2020-05-30, MAE is:4.76 & sMAPE is:41.29% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 42.92% & 0.99\n",
      "for 2020-05-31, MAE is:12.30 & sMAPE is:105.80% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 43.33% & 0.99\n",
      "for 2020-06-01, MAE is:8.56 & sMAPE is:95.62% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 43.67% & 0.98\n",
      "for 2020-06-02, MAE is:8.14 & sMAPE is:30.14% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 43.59% & 0.99\n",
      "for 2020-06-03, MAE is:3.66 & sMAPE is:12.01% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 43.38% & 0.99\n",
      "for 2020-06-04, MAE is:6.27 & sMAPE is:25.81% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 43.27% & 0.99\n",
      "for 2020-06-05, MAE is:7.13 & sMAPE is:38.06% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.62 & 43.24% & 0.99\n",
      "for 2020-06-06, MAE is:5.36 & sMAPE is:101.02% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 43.60% & 0.99\n",
      "for 2020-06-07, MAE is:6.49 & sMAPE is:50.20% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 43.64% & 0.98\n",
      "for 2020-06-08, MAE is:5.44 & sMAPE is:18.55% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 43.49% & 0.98\n",
      "for 2020-06-09, MAE is:7.57 & sMAPE is:21.56% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.58 & 43.35% & 0.98\n",
      "for 2020-06-10, MAE is:3.75 & sMAPE is:12.74% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 43.16% & 0.98\n",
      "for 2020-06-11, MAE is:2.62 & sMAPE is:12.20% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 42.97% & 0.97\n",
      "for 2020-06-12, MAE is:3.94 & sMAPE is:19.12% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 42.83% & 0.97\n",
      "for 2020-06-13, MAE is:6.39 & sMAPE is:45.43% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.50 & 42.84% & 0.97\n",
      "for 2020-06-14, MAE is:4.42 & sMAPE is:31.42% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.48 & 42.77% & 0.97\n",
      "for 2020-06-15, MAE is:5.66 & sMAPE is:26.00% & rMAE is:2.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 42.67% & 0.98\n",
      "for 2020-06-16, MAE is:1.72 & sMAPE is:4.92% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 42.45% & 0.98\n",
      "for 2020-06-17, MAE is:5.69 & sMAPE is:15.79% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 42.29% & 0.98\n",
      "for 2020-06-18, MAE is:1.89 & sMAPE is:6.06% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 42.08% & 0.98\n",
      "for 2020-06-19, MAE is:2.76 & sMAPE is:9.69% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.37 & 41.89% & 0.97\n",
      "for 2020-06-20, MAE is:2.00 & sMAPE is:8.37% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 41.69% & 0.97\n",
      "for 2020-06-21, MAE is:4.29 & sMAPE is:25.49% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.32 & 41.60% & 0.97\n",
      "for 2020-06-22, MAE is:2.08 & sMAPE is:7.68% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 41.41% & 0.97\n",
      "for 2020-06-23, MAE is:3.87 & sMAPE is:11.94% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.27 & 41.24% & 0.97\n",
      "for 2020-06-24, MAE is:3.06 & sMAPE is:8.75% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :7.25 & 41.05% & 0.97\n",
      "for 2020-06-25, MAE is:1.62 & sMAPE is:4.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 40.85% & 0.97\n",
      "for 2020-06-26, MAE is:3.56 & sMAPE is:10.69% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 40.68% & 0.96\n",
      "for 2020-06-27, MAE is:4.99 & sMAPE is:17.90% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 40.55% & 0.97\n",
      "for 2020-06-28, MAE is:5.04 & sMAPE is:43.61% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 40.57% & 0.97\n",
      "for 2020-06-29, MAE is:5.15 & sMAPE is:18.72% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 40.45% & 0.97\n",
      "for 2020-06-30, MAE is:11.47 & sMAPE is:72.09% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.18 & 40.62% & 0.97\n",
      "for 2020-07-01, MAE is:2.98 & sMAPE is:10.14% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 40.45% & 0.97\n",
      "for 2020-07-02, MAE is:3.06 & sMAPE is:7.86% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 40.28% & 0.97\n",
      "for 2020-07-03, MAE is:5.28 & sMAPE is:14.80% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :7.13 & 40.14% & 0.97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-07-04, MAE is:9.81 & sMAPE is:69.31% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 40.30% & 0.97\n",
      "for 2020-07-05, MAE is:34.94 & sMAPE is:162.85% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.29 & 40.95% & 0.97\n",
      "for 2020-07-06, MAE is:14.96 & sMAPE is:92.23% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 41.22% & 0.97\n",
      "for 2020-07-07, MAE is:3.79 & sMAPE is:12.79% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :7.31 & 41.07% & 0.97\n",
      "for 2020-07-08, MAE is:5.27 & sMAPE is:13.34% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.30 & 40.93% & 0.96\n",
      "for 2020-07-09, MAE is:3.34 & sMAPE is:8.05% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :7.28 & 40.76% & 0.96\n",
      "for 2020-07-10, MAE is:3.23 & sMAPE is:8.41% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :7.26 & 40.59% & 0.96\n",
      "for 2020-07-11, MAE is:2.97 & sMAPE is:10.20% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.24 & 40.43% & 0.96\n",
      "for 2020-07-12, MAE is:2.76 & sMAPE is:12.13% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :7.21 & 40.28% & 0.96\n",
      "for 2020-07-13, MAE is:2.98 & sMAPE is:8.68% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.19 & 40.12% & 0.95\n",
      "for 2020-07-14, MAE is:2.92 & sMAPE is:7.80% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :7.17 & 39.96% & 0.95\n",
      "for 2020-07-15, MAE is:4.67 & sMAPE is:11.49% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 39.81% & 0.95\n",
      "for 2020-07-16, MAE is:7.69 & sMAPE is:17.75% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :7.16 & 39.70% & 0.96\n",
      "for 2020-07-17, MAE is:2.44 & sMAPE is:6.66% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.14 & 39.53% & 0.96\n",
      "for 2020-07-18, MAE is:2.43 & sMAPE is:8.61% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.11 & 39.38% & 0.96\n",
      "for 2020-07-19, MAE is:1.98 & sMAPE is:7.27% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 39.22% & 0.96\n",
      "for 2020-07-20, MAE is:3.08 & sMAPE is:9.59% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 39.07% & 0.96\n",
      "for 2020-07-21, MAE is:4.66 & sMAPE is:14.47% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :7.06 & 38.95% & 0.96\n",
      "for 2020-07-22, MAE is:3.42 & sMAPE is:9.72% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.04 & 38.81% & 0.96\n",
      "for 2020-07-23, MAE is:4.04 & sMAPE is:11.31% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.02 & 38.68% & 0.96\n",
      "for 2020-07-24, MAE is:3.07 & sMAPE is:10.40% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 38.54% & 0.95\n",
      "for 2020-07-25, MAE is:2.79 & sMAPE is:10.81% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 38.40% & 0.95\n",
      "for 2020-07-26, MAE is:9.58 & sMAPE is:66.02% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 38.54% & 0.95\n",
      "for 2020-07-27, MAE is:4.87 & sMAPE is:15.97% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 38.43% & 0.95\n",
      "for 2020-07-28, MAE is:6.45 & sMAPE is:38.70% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 38.43% & 0.95\n",
      "for 2020-07-29, MAE is:11.17 & sMAPE is:62.74% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 38.55% & 0.95\n",
      "for 2020-07-30, MAE is:5.87 & sMAPE is:15.99% & rMAE is:1.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 38.44% & 0.95\n",
      "for 2020-07-31, MAE is:4.87 & sMAPE is:13.03% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 38.32% & 0.95\n",
      "for 2020-08-01, MAE is:4.08 & sMAPE is:14.42% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 38.21% & 0.95\n",
      "for 2020-08-02, MAE is:2.47 & sMAPE is:9.81% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 38.08% & 0.95\n",
      "for 2020-08-03, MAE is:2.60 & sMAPE is:7.35% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 37.93% & 0.95\n",
      "for 2020-08-04, MAE is:3.29 & sMAPE is:9.16% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 37.80% & 0.94\n",
      "for 2020-08-05, MAE is:5.26 & sMAPE is:17.55% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 37.71% & 0.94\n",
      "for 2020-08-06, MAE is:4.92 & sMAPE is:14.32% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 37.60% & 0.95\n",
      "for 2020-08-07, MAE is:4.09 & sMAPE is:11.58% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 37.48% & 0.95\n",
      "for 2020-08-08, MAE is:2.88 & sMAPE is:9.19% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 37.35% & 0.95\n",
      "for 2020-08-09, MAE is:2.58 & sMAPE is:9.01% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 37.23% & 0.95\n",
      "for 2020-08-10, MAE is:5.91 & sMAPE is:18.84% & rMAE is:2.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 37.14% & 0.95\n",
      "for 2020-08-11, MAE is:3.74 & sMAPE is:11.24% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 37.03% & 0.95\n",
      "for 2020-08-12, MAE is:4.43 & sMAPE is:13.73% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 36.93% & 0.95\n",
      "for 2020-08-13, MAE is:4.35 & sMAPE is:12.57% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.81 & 36.82% & 0.95\n",
      "for 2020-08-14, MAE is:3.18 & sMAPE is:7.38% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.79 & 36.69% & 0.95\n",
      "for 2020-08-15, MAE is:1.39 & sMAPE is:4.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 36.55% & 0.95\n",
      "for 2020-08-16, MAE is:2.42 & sMAPE is:8.45% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 36.42% & 0.95\n",
      "for 2020-08-17, MAE is:4.45 & sMAPE is:11.15% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 36.31% & 0.95\n",
      "for 2020-08-18, MAE is:3.90 & sMAPE is:8.85% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 36.19% & 0.95\n",
      "for 2020-08-19, MAE is:4.59 & sMAPE is:11.43% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 36.09% & 0.95\n",
      "for 2020-08-20, MAE is:4.05 & sMAPE is:9.81% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 35.98% & 0.95\n",
      "for 2020-08-21, MAE is:4.67 & sMAPE is:14.79% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 35.88% & 0.95\n",
      "for 2020-08-22, MAE is:6.59 & sMAPE is:30.80% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.70 & 35.86% & 0.95\n",
      "for 2020-08-23, MAE is:8.81 & sMAPE is:65.38% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :6.71 & 35.99% & 0.95\n",
      "for 2020-08-24, MAE is:10.29 & sMAPE is:23.59% & rMAE is:2.00 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 35.94% & 0.95\n",
      "for 2020-08-25, MAE is:6.59 & sMAPE is:16.32% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.72 & 35.85% & 0.95\n",
      "for 2020-08-26, MAE is:9.94 & sMAPE is:63.84% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 35.97% & 0.95\n",
      "for 2020-08-27, MAE is:17.64 & sMAPE is:49.97% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.78 & 36.03% & 0.96\n",
      "for 2020-08-28, MAE is:4.69 & sMAPE is:11.65% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 35.93% & 0.95\n",
      "for 2020-08-29, MAE is:2.47 & sMAPE is:6.92% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 35.81% & 0.95\n",
      "for 2020-08-30, MAE is:1.21 & sMAPE is:3.42% & rMAE is:0.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 35.67% & 0.95\n",
      "for 2020-08-31, MAE is:15.34 & sMAPE is:29.90% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.77 & 35.65% & 0.95\n",
      "for 2020-09-01, MAE is:3.76 & sMAPE is:7.34% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 35.54% & 0.95\n",
      "for 2020-09-02, MAE is:5.37 & sMAPE is:10.27% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 35.43% & 0.94\n",
      "for 2020-09-03, MAE is:8.53 & sMAPE is:20.28% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 35.37% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-09-04, MAE is:6.79 & sMAPE is:20.76% & rMAE is:2.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 35.31% & 0.95\n",
      "for 2020-09-05, MAE is:3.72 & sMAPE is:11.84% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :6.74 & 35.22% & 0.95\n",
      "for 2020-09-06, MAE is:3.73 & sMAPE is:10.71% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 35.12% & 0.95\n",
      "for 2020-09-07, MAE is:5.21 & sMAPE is:11.29% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 35.02% & 0.95\n",
      "for 2020-09-08, MAE is:7.12 & sMAPE is:17.62% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 34.96% & 0.95\n",
      "for 2020-09-09, MAE is:6.16 & sMAPE is:16.49% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.73 & 34.88% & 0.94\n",
      "for 2020-09-10, MAE is:13.81 & sMAPE is:32.43% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.75 & 34.87% & 0.95\n",
      "for 2020-09-11, MAE is:7.42 & sMAPE is:15.70% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 34.80% & 0.95\n",
      "for 2020-09-12, MAE is:8.33 & sMAPE is:37.66% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :6.76 & 34.81% & 0.95\n",
      "for 2020-09-13, MAE is:16.03 & sMAPE is:55.25% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :6.80 & 34.89% & 0.95\n",
      "for 2020-09-14, MAE is:12.56 & sMAPE is:21.84% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.82 & 34.84% & 0.95\n",
      "for 2020-09-15, MAE is:20.81 & sMAPE is:25.45% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 34.80% & 0.95\n",
      "for 2020-09-16, MAE is:14.07 & sMAPE is:24.09% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 34.76% & 0.95\n",
      "for 2020-09-17, MAE is:6.66 & sMAPE is:13.69% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 34.68% & 0.95\n",
      "for 2020-09-18, MAE is:4.72 & sMAPE is:11.07% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 34.59% & 0.95\n",
      "for 2020-09-19, MAE is:3.49 & sMAPE is:9.43% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 34.49% & 0.95\n",
      "for 2020-09-20, MAE is:4.05 & sMAPE is:11.15% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 34.41% & 0.94\n",
      "for 2020-09-21, MAE is:16.04 & sMAPE is:21.68% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 34.36% & 0.95\n",
      "for 2020-09-22, MAE is:9.64 & sMAPE is:17.21% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 34.29% & 0.95\n",
      "for 2020-09-23, MAE is:7.34 & sMAPE is:14.81% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 34.22% & 0.95\n",
      "for 2020-09-24, MAE is:6.32 & sMAPE is:16.21% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 34.15% & 0.95\n",
      "for 2020-09-25, MAE is:4.30 & sMAPE is:10.34% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 34.06% & 0.95\n",
      "for 2020-09-26, MAE is:2.85 & sMAPE is:8.51% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 33.97% & 0.95\n",
      "for 2020-09-27, MAE is:7.93 & sMAPE is:31.10% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 33.96% & 0.95\n",
      "for 2020-09-28, MAE is:3.92 & sMAPE is:8.34% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 33.87% & 0.94\n",
      "for 2020-09-29, MAE is:15.20 & sMAPE is:25.77% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 33.84% & 0.95\n",
      "for 2020-09-30, MAE is:5.02 & sMAPE is:9.79% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 33.75% & 0.95\n",
      "for 2020-10-01, MAE is:4.05 & sMAPE is:9.72% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 33.66% & 0.95\n",
      "for 2020-10-02, MAE is:9.23 & sMAPE is:29.83% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 33.65% & 0.95\n",
      "for 2020-10-03, MAE is:10.63 & sMAPE is:105.92% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 33.91% & 0.95\n",
      "for 2020-10-04, MAE is:21.36 & sMAPE is:109.40% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 34.18% & 0.95\n",
      "for 2020-10-05, MAE is:5.65 & sMAPE is:24.55% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 34.14% & 0.94\n",
      "for 2020-10-06, MAE is:4.62 & sMAPE is:16.86% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 34.08% & 0.94\n",
      "for 2020-10-07, MAE is:5.25 & sMAPE is:15.71% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 34.02% & 0.94\n",
      "for 2020-10-08, MAE is:8.02 & sMAPE is:25.65% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 33.99% & 0.94\n",
      "for 2020-10-09, MAE is:16.95 & sMAPE is:64.00% & rMAE is:1.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 34.09% & 0.94\n",
      "for 2020-10-10, MAE is:3.49 & sMAPE is:11.09% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 34.01% & 0.94\n",
      "for 2020-10-11, MAE is:8.36 & sMAPE is:30.89% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 34.00% & 0.94\n",
      "for 2020-10-12, MAE is:8.54 & sMAPE is:17.94% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 33.95% & 0.94\n",
      "for 2020-10-13, MAE is:5.17 & sMAPE is:11.12% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.87% & 0.93\n",
      "for 2020-10-14, MAE is:5.14 & sMAPE is:14.87% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 33.80% & 0.93\n",
      "for 2020-10-15, MAE is:8.94 & sMAPE is:25.26% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.77% & 0.93\n",
      "for 2020-10-16, MAE is:7.47 & sMAPE is:16.61% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.71% & 0.93\n",
      "for 2020-10-17, MAE is:2.62 & sMAPE is:6.42% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 33.62% & 0.93\n",
      "for 2020-10-18, MAE is:4.70 & sMAPE is:15.00% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 33.55% & 0.93\n",
      "for 2020-10-19, MAE is:8.17 & sMAPE is:19.93% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 33.51% & 0.93\n",
      "for 2020-10-20, MAE is:5.82 & sMAPE is:17.68% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 33.45% & 0.93\n",
      "for 2020-10-21, MAE is:10.15 & sMAPE is:31.20% & rMAE is:1.65 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 33.45% & 0.93\n",
      "for 2020-10-22, MAE is:9.34 & sMAPE is:48.22% & rMAE is:1.02 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.50% & 0.94\n",
      "for 2020-10-23, MAE is:9.94 & sMAPE is:25.29% & rMAE is:2.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 33.47% & 0.94\n",
      "for 2020-10-24, MAE is:5.26 & sMAPE is:17.76% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.42% & 0.94\n",
      "for 2020-10-25, MAE is:9.38 & sMAPE is:118.20% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 33.70% & 0.94\n",
      "for 2020-10-26, MAE is:5.02 & sMAPE is:14.27% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.63% & 0.94\n",
      "for 2020-10-27, MAE is:6.93 & sMAPE is:24.72% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.60% & 0.94\n",
      "for 2020-10-28, MAE is:9.57 & sMAPE is:55.43% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 33.68% & 0.94\n",
      "for 2020-10-29, MAE is:5.64 & sMAPE is:22.15% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 33.64% & 0.94\n",
      "for 2020-10-30, MAE is:3.84 & sMAPE is:19.77% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.59% & 0.94\n",
      "for 2020-10-31, MAE is:5.96 & sMAPE is:19.85% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 33.55% & 0.94\n",
      "for 2020-11-01, MAE is:7.14 & sMAPE is:40.23% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 33.57% & 0.94\n",
      "for 2020-11-02, MAE is:4.35 & sMAPE is:55.21% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 33.64% & 0.94\n",
      "for 2020-11-03, MAE is:4.36 & sMAPE is:14.57% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 33.58% & 0.94\n",
      "for 2020-11-04, MAE is:4.78 & sMAPE is:12.53% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 33.51% & 0.94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2020-11-05, MAE is:3.77 & sMAPE is:9.47% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :6.94 & 33.43% & 0.94\n",
      "for 2020-11-06, MAE is:3.17 & sMAPE is:7.63% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :6.93 & 33.35% & 0.93\n",
      "for 2020-11-07, MAE is:4.00 & sMAPE is:10.62% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 33.28% & 0.93\n",
      "for 2020-11-08, MAE is:3.66 & sMAPE is:10.00% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 33.20% & 0.93\n",
      "for 2020-11-09, MAE is:3.90 & sMAPE is:8.36% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 33.12% & 0.93\n",
      "for 2020-11-10, MAE is:4.71 & sMAPE is:9.17% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.89 & 33.05% & 0.93\n",
      "for 2020-11-11, MAE is:4.21 & sMAPE is:9.32% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 32.97% & 0.92\n",
      "for 2020-11-12, MAE is:3.37 & sMAPE is:8.84% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 32.90% & 0.93\n",
      "for 2020-11-13, MAE is:2.25 & sMAPE is:5.50% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 32.81% & 0.93\n",
      "for 2020-11-14, MAE is:3.76 & sMAPE is:10.78% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 32.74% & 0.93\n",
      "for 2020-11-15, MAE is:12.24 & sMAPE is:108.29% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 32.98% & 0.92\n",
      "for 2020-11-16, MAE is:8.02 & sMAPE is:61.73% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.87 & 33.07% & 0.92\n",
      "for 2020-11-17, MAE is:3.00 & sMAPE is:9.15% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 32.99% & 0.92\n",
      "for 2020-11-18, MAE is:6.48 & sMAPE is:21.71% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 32.96% & 0.92\n",
      "for 2020-11-19, MAE is:3.80 & sMAPE is:50.22% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 33.01% & 0.92\n",
      "for 2020-11-20, MAE is:6.25 & sMAPE is:16.03% & rMAE is:1.96 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.96% & 0.92\n",
      "for 2020-11-21, MAE is:4.82 & sMAPE is:15.37% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.90% & 0.92\n",
      "for 2020-11-22, MAE is:8.91 & sMAPE is:40.27% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.93% & 0.92\n",
      "for 2020-11-23, MAE is:5.52 & sMAPE is:13.43% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.87% & 0.92\n",
      "for 2020-11-24, MAE is:3.92 & sMAPE is:9.57% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 32.80% & 0.92\n",
      "for 2020-11-25, MAE is:4.76 & sMAPE is:10.48% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :6.83 & 32.73% & 0.92\n",
      "for 2020-11-26, MAE is:11.39 & sMAPE is:19.69% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.69% & 0.92\n",
      "for 2020-11-27, MAE is:10.58 & sMAPE is:15.39% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :6.85 & 32.64% & 0.91\n",
      "for 2020-11-28, MAE is:4.00 & sMAPE is:8.08% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.56% & 0.91\n",
      "for 2020-11-29, MAE is:6.50 & sMAPE is:15.29% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.51% & 0.91\n",
      "for 2020-11-30, MAE is:7.29 & sMAPE is:14.40% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 32.46% & 0.91\n",
      "for 2020-12-01, MAE is:13.03 & sMAPE is:26.68% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :6.86 & 32.44% & 0.91\n",
      "for 2020-12-02, MAE is:19.86 & sMAPE is:26.53% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 32.42% & 0.91\n",
      "for 2020-12-03, MAE is:10.88 & sMAPE is:21.50% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 32.39% & 0.91\n",
      "for 2020-12-04, MAE is:7.38 & sMAPE is:20.81% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.91 & 32.36% & 0.91\n",
      "for 2020-12-05, MAE is:3.70 & sMAPE is:7.80% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 32.28% & 0.91\n",
      "for 2020-12-06, MAE is:5.19 & sMAPE is:11.98% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 32.23% & 0.91\n",
      "for 2020-12-07, MAE is:6.97 & sMAPE is:15.70% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :6.90 & 32.18% & 0.91\n",
      "for 2020-12-08, MAE is:12.80 & sMAPE is:21.28% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :6.92 & 32.15% & 0.91\n",
      "for 2020-12-09, MAE is:21.80 & sMAPE is:27.96% & rMAE is:2.67 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 32.13% & 0.92\n",
      "for 2020-12-10, MAE is:14.23 & sMAPE is:20.37% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 32.10% & 0.91\n",
      "for 2020-12-11, MAE is:10.64 & sMAPE is:20.26% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 32.06% & 0.91\n",
      "for 2020-12-12, MAE is:11.54 & sMAPE is:29.78% & rMAE is:4.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 32.06% & 0.93\n",
      "for 2020-12-13, MAE is:2.96 & sMAPE is:6.74% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :6.99 & 31.99% & 0.93\n",
      "for 2020-12-14, MAE is:3.58 & sMAPE is:8.01% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :6.98 & 31.92% & 0.93\n",
      "for 2020-12-15, MAE is:3.29 & sMAPE is:6.71% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 31.84% & 0.92\n",
      "for 2020-12-16, MAE is:7.10 & sMAPE is:13.95% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 31.79% & 0.92\n",
      "for 2020-12-17, MAE is:5.86 & sMAPE is:13.69% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 31.74% & 0.92\n",
      "for 2020-12-18, MAE is:4.78 & sMAPE is:10.71% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 31.68% & 0.92\n",
      "for 2020-12-19, MAE is:3.36 & sMAPE is:10.62% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 31.62% & 0.92\n",
      "for 2020-12-20, MAE is:7.16 & sMAPE is:20.19% & rMAE is:1.80 ||| daily mean of MAE & sMAPE & rMAE till now are :6.95 & 31.59% & 0.92\n",
      "for 2020-12-21, MAE is:10.11 & sMAPE is:30.58% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 31.59% & 0.92\n",
      "for 2020-12-22, MAE is:7.33 & sMAPE is:45.82% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 31.63% & 0.92\n",
      "for 2020-12-23, MAE is:5.04 & sMAPE is:12.01% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 31.57% & 0.92\n",
      "for 2020-12-24, MAE is:7.39 & sMAPE is:50.43% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :6.96 & 31.63% & 0.92\n",
      "for 2020-12-25, MAE is:9.75 & sMAPE is:30.25% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :6.97 & 31.62% & 0.92\n",
      "for 2020-12-26, MAE is:20.30 & sMAPE is:75.38% & rMAE is:1.47 ||| daily mean of MAE & sMAPE & rMAE till now are :7.00 & 31.74% & 0.92\n",
      "for 2020-12-27, MAE is:17.65 & sMAPE is:131.42% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.03 & 32.02% & 0.92\n",
      "for 2020-12-28, MAE is:22.21 & sMAPE is:95.05% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 32.19% & 0.92\n",
      "for 2020-12-29, MAE is:6.95 & sMAPE is:15.70% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :7.07 & 32.15% & 0.92\n",
      "for 2020-12-30, MAE is:10.87 & sMAPE is:26.92% & rMAE is:2.20 ||| daily mean of MAE & sMAPE & rMAE till now are :7.08 & 32.13% & 0.92\n",
      "for 2020-12-31, MAE is:8.31 & sMAPE is:18.23% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.09 & 32.09% & 0.92\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:36:10,084]\u001b[0m A new study created in RDB with name: DE_2021\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:36:34,577]\u001b[0m Trial 3 finished with value: 10.70781223048296 and parameters: {'n_hidden': 3, 'learning_rate': 0.008117472035115593, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05557185582853639, 'dropout_rate_Layer_2': 0.2963703374723731, 'dropout_rate_Layer_3': 0.12066807861873229, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.01153062355794548, 'l1_Layer_2': 0.0011136660571384037, 'l1_Layer_3': 1.7028859670103035e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 3 with value: 10.70781223048296.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 10.71 | sMAPE for Validation Set is: 39.14% | rMAE for Validation Set is: 1.04\n",
      "MAE for Test Set is: 51.47 | sMAPE for Test Set is: 54.99% | rMAE for Test Set is: 1.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:36:34,944]\u001b[0m Trial 2 pruned. Trial was pruned at epoch 50.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:36:40,806]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:36:45,963]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:36:49,586]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:36:53,329]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:36:59,558]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:03,519]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:03,761]\u001b[0m Trial 1 finished with value: 7.197980660599143 and parameters: {'n_hidden': 4, 'learning_rate': 0.0018346007917336225, 'batch_size': 84, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07584366108363594, 'dropout_rate_Layer_2': 0.17731950686896286, 'dropout_rate_Layer_3': 0.12020440837953417, 'dropout_rate_Layer_4': 0.1768250897972652, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.006913442887680606, 'l1_Layer_2': 0.0028943396399804234, 'l1_Layer_3': 0.0017783924873615484, 'l1_Layer_4': 1.6616789435015664e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 165, 'n_units_Layer_3': 95, 'n_units_Layer_4': 105}. Best is trial 1 with value: 7.197980660599143.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.20 | sMAPE for Validation Set is: 30.96% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 43.58 | sMAPE for Test Set is: 44.27% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:37:09,140]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:09,524]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 29.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 22.74 | sMAPE for Test Set is: 26.21% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:37:09,971]\u001b[0m Trial 0 finished with value: 6.477537545433118 and parameters: {'n_hidden': 3, 'learning_rate': 0.002209502418025251, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06827432904295398, 'dropout_rate_Layer_2': 0.09285417740168539, 'dropout_rate_Layer_3': 0.3136782691329989, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022581488166811912, 'l1_Layer_2': 4.410954680984747e-05, 'l1_Layer_3': 0.0006801668012905486, 'n_units_Layer_1': 210, 'n_units_Layer_2': 280, 'n_units_Layer_3': 120}. Best is trial 0 with value: 6.477537545433118.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:17,144]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:17,305]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:17,495]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:24,464]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:25,068]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:25,919]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:30,393]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:34,193]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.19 | sMAPE for Validation Set is: 33.35% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 44.95 | sMAPE for Test Set is: 45.62% | rMAE for Test Set is: 1.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:37:35,661]\u001b[0m Trial 6 finished with value: 7.190371204089433 and parameters: {'n_hidden': 4, 'learning_rate': 0.01168518455859821, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15734625355666415, 'dropout_rate_Layer_2': 0.02411002675883549, 'dropout_rate_Layer_3': 0.23828432425461857, 'dropout_rate_Layer_4': 0.18820632062204123, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.0001185555213827164, 'l1_Layer_2': 0.0012052908166070284, 'l1_Layer_3': 0.0001977290996975936, 'l1_Layer_4': 0.037040441990133705, 'n_units_Layer_1': 295, 'n_units_Layer_2': 145, 'n_units_Layer_3': 160, 'n_units_Layer_4': 150}. Best is trial 0 with value: 6.477537545433118.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:39,448]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:40,702]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:43,899]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:46,603]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:47,058]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:51,796]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:55,793]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:55,863]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:37:56,232]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:03,090]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:07,731]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:10,077]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:10,424]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:15,988]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:17,519]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:19,324]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:23,631]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:29,066]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:31,032]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:34,955]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:38,891]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:40,038]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:48,455]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:52,442]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:56,049]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:38:56,398]\u001b[0m Trial 45 finished with value: 8.35114403730094 and parameters: {'n_hidden': 4, 'learning_rate': 0.008680385276300665, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3728901280334391, 'dropout_rate_Layer_2': 0.02576084072169245, 'dropout_rate_Layer_3': 0.05353195114681744, 'dropout_rate_Layer_4': 0.35190650728727557, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 1.8906998324572365e-05, 'l1_Layer_2': 0.08140921351165453, 'l1_Layer_3': 0.00011018473182829016, 'l1_Layer_4': 0.0008912040580206211, 'n_units_Layer_1': 125, 'n_units_Layer_2': 270, 'n_units_Layer_3': 105, 'n_units_Layer_4': 195}. Best is trial 0 with value: 6.477537545433118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.35 | sMAPE for Validation Set is: 34.31% | rMAE for Validation Set is: 0.81\n",
      "MAE for Test Set is: 55.67 | sMAPE for Test Set is: 61.92% | rMAE for Test Set is: 1.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:39:00,347]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:04,935]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:05,845]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:06,472]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:12,735]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:20,271]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:24,814]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:24,935]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:26,023]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:33,234]\u001b[0m Trial 50 finished with value: 7.666241054063941 and parameters: {'n_hidden': 3, 'learning_rate': 0.012931764049138112, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14817175951303502, 'dropout_rate_Layer_2': 0.16873093789735447, 'dropout_rate_Layer_3': 0.14832371464314542, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008188982215551227, 'l1_Layer_2': 1.7637293997611328e-05, 'l1_Layer_3': 0.00012799374967495508, 'n_units_Layer_1': 150, 'n_units_Layer_2': 145, 'n_units_Layer_3': 225}. Best is trial 0 with value: 6.477537545433118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.67 | sMAPE for Validation Set is: 33.67% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 43.03 | sMAPE for Test Set is: 43.69% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:39:34,494]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:38,248]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:40,173]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:42,822]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:44,822]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:46,965]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:48,535]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:48,674]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:55,597]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:39:58,922]\u001b[0m Trial 63 finished with value: 8.448851481759117 and parameters: {'n_hidden': 4, 'learning_rate': 0.007741220667826929, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17181976464072754, 'dropout_rate_Layer_2': 0.25595503789978574, 'dropout_rate_Layer_3': 0.17873349616107675, 'dropout_rate_Layer_4': 0.08186878611201132, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 0.03038381386953382, 'l1_Layer_2': 0.0006468664810400116, 'l1_Layer_3': 0.0005938006566598179, 'l1_Layer_4': 0.0014424044472802929, 'n_units_Layer_1': 75, 'n_units_Layer_2': 265, 'n_units_Layer_3': 200, 'n_units_Layer_4': 220}. Best is trial 0 with value: 6.477537545433118.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.45 | sMAPE for Validation Set is: 33.75% | rMAE for Validation Set is: 0.82\n",
      "MAE for Test Set is: 47.53 | sMAPE for Test Set is: 48.98% | rMAE for Test Set is: 1.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:39:59,753]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:05,438]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:06,468]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:07,190]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:11,713]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:14,383]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:20,012]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:37,910]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:42,142]\u001b[0m Trial 67 finished with value: 6.286099194614088 and parameters: {'n_hidden': 4, 'learning_rate': 0.000690984710636095, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12080292618807748, 'dropout_rate_Layer_2': 0.10741003885565556, 'dropout_rate_Layer_3': 0.16840527595327354, 'dropout_rate_Layer_4': 0.1290766521774401, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.017254505187470508, 'l1_Layer_2': 0.007277254378533155, 'l1_Layer_3': 4.657521540224642e-05, 'l1_Layer_4': 0.0001147495798435574, 'n_units_Layer_1': 300, 'n_units_Layer_2': 205, 'n_units_Layer_3': 215, 'n_units_Layer_4': 150}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 29.04% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.07 | sMAPE for Test Set is: 24.55% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:40:44,002]\u001b[0m Trial 78 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:40:48,526]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:00,791]\u001b[0m Trial 75 finished with value: 6.935890881334507 and parameters: {'n_hidden': 4, 'learning_rate': 0.0019918590489589744, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2930990069291098, 'dropout_rate_Layer_2': 0.307986019216411, 'dropout_rate_Layer_3': 0.0888806600879883, 'dropout_rate_Layer_4': 0.3249745932289972, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021458255198590224, 'l1_Layer_2': 0.06472528934507155, 'l1_Layer_3': 0.002809696538978199, 'l1_Layer_4': 0.00017267619743193072, 'n_units_Layer_1': 165, 'n_units_Layer_2': 150, 'n_units_Layer_3': 220, 'n_units_Layer_4': 125}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.94 | sMAPE for Validation Set is: 30.36% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 39.58 | sMAPE for Test Set is: 39.68% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:41:04,953]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:08,360]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:11,553]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:14,459]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:18,008]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:18,172]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:22,597]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:30,617]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:38,153]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:42,002]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:46,262]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:48,154]\u001b[0m Trial 80 finished with value: 6.800808822814247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006790161000411767, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06304646341299047, 'dropout_rate_Layer_2': 0.2528869688194112, 'dropout_rate_Layer_3': 0.3423574488573645, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005558267115603064, 'l1_Layer_2': 2.4583763743235838e-05, 'l1_Layer_3': 0.011611645499111723, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 200}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.80 | sMAPE for Validation Set is: 29.46% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 39.79 | sMAPE for Test Set is: 39.77% | rMAE for Test Set is: 1.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:41:49,798]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:53,224]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:41:58,061]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:00,793]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:05,829]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:08,264]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:10,063]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:12,442]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:14,342]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:14,744]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:19,299]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:19,565]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:20,835]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:26,603]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:26,934]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:27,276]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:33,526]\u001b[0m Trial 108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:33,959]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:36,932]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:40,561]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:42,725]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:47,447]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:47,719]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:53,526]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:53,822]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:42:57,965]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:01,224]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:01,786]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:02,333]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:08,332]\u001b[0m Trial 121 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:09,023]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:17,009]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:19,366]\u001b[0m Trial 102 finished with value: 6.519363421346013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014169535759564584, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0481788288573915, 'dropout_rate_Layer_2': 0.2737260038334378, 'dropout_rate_Layer_3': 0.3269804368538192, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005055585485496463, 'l1_Layer_2': 3.957913082574362e-05, 'l1_Layer_3': 0.0009013031352487514, 'n_units_Layer_1': 250, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 29.12% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 43.23 | sMAPE for Test Set is: 43.39% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:43:23,142]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:30,809]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:31,301]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:35,926]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:37,259]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:39,772]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:42,434]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:48,268]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:43:57,375]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:00,574]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:04,162]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:08,809]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:19,225]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:25,807]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:28,876]\u001b[0m Trial 135 finished with value: 6.913403655929263 and parameters: {'n_hidden': 3, 'learning_rate': 0.004203908113655937, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027355064087945503, 'dropout_rate_Layer_2': 0.17248695497331737, 'dropout_rate_Layer_3': 0.08174380200948322, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.6017492919836266e-05, 'l1_Layer_2': 0.0015161560038245874, 'l1_Layer_3': 5.530632046405569e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 260, 'n_units_Layer_3': 280}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 33.46% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 21.73 | sMAPE for Test Set is: 25.22% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:44:32,738]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:32,825]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:36,270]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:39,302]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:43,357]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:43,441]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:43,672]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:50,867]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:51,603]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:44:55,150]\u001b[0m Trial 124 finished with value: 7.012977854489949 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024353261532970814, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050041466521718155, 'dropout_rate_Layer_2': 0.014488170060187988, 'dropout_rate_Layer_3': 0.30293960152001603, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010112808723920794, 'l1_Layer_2': 0.00021176919677968694, 'l1_Layer_3': 0.0014499762883334463, 'n_units_Layer_1': 270, 'n_units_Layer_2': 300, 'n_units_Layer_3': 120}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.01 | sMAPE for Validation Set is: 30.27% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 45.87 | sMAPE for Test Set is: 46.93% | rMAE for Test Set is: 1.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:45:06,223]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:11,808]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:18,849]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:22,061]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:22,239]\u001b[0m Trial 147 finished with value: 6.664423242848204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025144883629795384, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1132602951841245, 'dropout_rate_Layer_2': 0.06479295978847904, 'dropout_rate_Layer_3': 0.20739970091479026, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.104607594572249e-05, 'l1_Layer_2': 1.0044581221166738e-05, 'l1_Layer_3': 0.0006603712028252147, 'n_units_Layer_1': 55, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 67 with value: 6.286099194614088.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.66 | sMAPE for Validation Set is: 29.50% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 26.37 | sMAPE for Test Set is: 25.95% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:45:31,158]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:34,569]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:38,618]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:46,801]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:50,261]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:54,874]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:45:57,510]\u001b[0m Trial 150 finished with value: 6.131152257940134 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005253823554874979, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008704861178661833, 'dropout_rate_Layer_2': 0.27003266739543136, 'dropout_rate_Layer_3': 0.32747015745596714, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002877955468220467, 'l1_Layer_2': 0.0017862388642425815, 'l1_Layer_3': 0.0001660351967192137, 'n_units_Layer_1': 280, 'n_units_Layer_2': 155, 'n_units_Layer_3': 270}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 27.87% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.66 | sMAPE for Test Set is: 23.48% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:45:59,007]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:01,680]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:11,306]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:16,903]\u001b[0m Trial 151 finished with value: 6.170707553342441 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005407532977897144, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011602171385893721, 'dropout_rate_Layer_2': 0.19136023202681818, 'dropout_rate_Layer_3': 0.33162890128521827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.009111674771414549, 'l1_Layer_2': 0.00030792428341327814, 'l1_Layer_3': 0.00015263087325134147, 'n_units_Layer_1': 280, 'n_units_Layer_2': 160, 'n_units_Layer_3': 250}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 27.68% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.72 | sMAPE for Test Set is: 25.49% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:46:27,570]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:37,053]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:40,901]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:45,149]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:46:49,837]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:11,918]\u001b[0m Trial 173 finished with value: 6.945005513041823 and parameters: {'n_hidden': 4, 'learning_rate': 0.004214843980661314, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08531459572361023, 'dropout_rate_Layer_2': 0.13519028883537845, 'dropout_rate_Layer_3': 0.28128926482114647, 'dropout_rate_Layer_4': 0.27722616436996494, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 9.431583474383256e-05, 'l1_Layer_2': 0.005845796269191973, 'l1_Layer_3': 0.0004690622014828861, 'l1_Layer_4': 1.0324938243316769e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 135, 'n_units_Layer_3': 55, 'n_units_Layer_4': 160}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.95 | sMAPE for Validation Set is: 30.32% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.87 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:47:15,991]\u001b[0m Trial 168 finished with value: 6.151412979652664 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005796520606152154, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004127307673721307, 'dropout_rate_Layer_2': 0.14040134496247683, 'dropout_rate_Layer_3': 0.2048800554764363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000232661245822644, 'l1_Layer_2': 0.0007004108197330877, 'l1_Layer_3': 0.00012965456937444485, 'n_units_Layer_1': 270, 'n_units_Layer_2': 145, 'n_units_Layer_3': 235}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 27.92% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.44 | sMAPE for Test Set is: 24.13% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:47:18,776]\u001b[0m Trial 166 finished with value: 6.166681091659801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007656797436374377, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007968947678633674, 'dropout_rate_Layer_2': 0.2801597440331101, 'dropout_rate_Layer_3': 0.31864157268440924, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022047814414698127, 'l1_Layer_2': 0.0058612469672009795, 'l1_Layer_3': 0.00016193850782255642, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.17 | sMAPE for Validation Set is: 27.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.84 | sMAPE for Test Set is: 25.38% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:47:19,254]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:23,193]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:33,490]\u001b[0m Trial 177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:33,818]\u001b[0m Trial 167 finished with value: 6.1570551322942935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005687712665617248, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.002085437651891108, 'dropout_rate_Layer_2': 0.2811233246767554, 'dropout_rate_Layer_3': 0.30129366465070595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00044496772934660497, 'l1_Layer_2': 0.0016750556986322, 'l1_Layer_3': 0.0001307117339747544, 'n_units_Layer_1': 290, 'n_units_Layer_2': 120, 'n_units_Layer_3': 240}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 27.78% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.95 | sMAPE for Test Set is: 24.62% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:47:38,755]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:41,705]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:53,168]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:47:55,673]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:11,965]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:14,603]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:14,728]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:20,751]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:25,892]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:33,831]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:39,384]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:43,644]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:48:58,389]\u001b[0m Trial 183 finished with value: 6.142522967402911 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005884820152534417, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03522793425074271, 'dropout_rate_Layer_2': 0.19297074828473326, 'dropout_rate_Layer_3': 0.1832213423839329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.461030048652035e-05, 'l1_Layer_2': 0.002258010013147409, 'l1_Layer_3': 0.00011108372265928973, 'n_units_Layer_1': 260, 'n_units_Layer_2': 120, 'n_units_Layer_3': 265}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 27.71% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.37 | sMAPE for Test Set is: 25.02% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:49:02,282]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:02,958]\u001b[0m Trial 186 finished with value: 6.8852441249523535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008762017479424984, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09467620906861512, 'dropout_rate_Layer_2': 0.0918127761608364, 'dropout_rate_Layer_3': 0.10424539891506177, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6230364727330906e-05, 'l1_Layer_2': 0.018570927378651108, 'l1_Layer_3': 0.004570598728102854, 'n_units_Layer_1': 175, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.89 | sMAPE for Validation Set is: 30.71% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 41.20 | sMAPE for Test Set is: 41.80% | rMAE for Test Set is: 1.31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:49:07,028]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:11,620]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:16,827]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:22,205]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:24,045]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:24,664]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:29,074]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:29,702]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:35,829]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:38,990]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:49:48,610]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:00,275]\u001b[0m Trial 205 finished with value: 6.424401098897779 and parameters: {'n_hidden': 3, 'learning_rate': 0.002628647752826065, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11385972760690055, 'dropout_rate_Layer_2': 0.0842164938784569, 'dropout_rate_Layer_3': 0.2028810858574989, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1248558678355224e-05, 'l1_Layer_2': 1.3646353559111698e-05, 'l1_Layer_3': 0.0008131393392112388, 'n_units_Layer_1': 50, 'n_units_Layer_2': 190, 'n_units_Layer_3': 300}. Best is trial 150 with value: 6.131152257940134.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 28.54% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.35 | sMAPE for Test Set is: 24.39% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:50:03,211]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:06,138]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:19,599]\u001b[0m Trial 209 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:28,735]\u001b[0m Trial 206 finished with value: 6.125610667394342 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009444323212025781, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016692611453696694, 'dropout_rate_Layer_2': 0.21712568133584995, 'dropout_rate_Layer_3': 0.2749115694582604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.817744648870886e-05, 'l1_Layer_2': 0.00017355800016764935, 'l1_Layer_3': 7.802646795044749e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.13 | sMAPE for Validation Set is: 27.60% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.04 | sMAPE for Test Set is: 23.74% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:50:33,382]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:35,870]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:37,906]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:43,508]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:47,426]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:53,273]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:50:53,539]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:05,835]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:05,892]\u001b[0m Trial 211 finished with value: 6.1479265083349075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008816875960421184, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05084766184720538, 'dropout_rate_Layer_2': 0.2275014221424353, 'dropout_rate_Layer_3': 0.32045858316789416, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.0014566338506384e-05, 'l1_Layer_2': 0.00017889305429614428, 'l1_Layer_3': 3.216873170721247e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 125, 'n_units_Layer_3': 280}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.15 | sMAPE for Validation Set is: 27.51% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.34 | sMAPE for Test Set is: 26.14% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:51:06,075]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:12,475]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:15,766]\u001b[0m Trial 222 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:18,028]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:24,435]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:36,351]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 28.08% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.34 | sMAPE for Test Set is: 23.16% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:51:38,553]\u001b[0m Trial 219 finished with value: 6.261163978847911 and parameters: {'n_hidden': 3, 'learning_rate': 0.001120860496651016, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3626235134725183, 'dropout_rate_Layer_2': 0.240221260771029, 'dropout_rate_Layer_3': 0.23150128983091375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010486175049605808, 'l1_Layer_2': 0.0001148763941543791, 'l1_Layer_3': 2.303071500828167e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 110, 'n_units_Layer_3': 290}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:42,375]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:46,229]\u001b[0m Trial 224 finished with value: 6.668043924246189 and parameters: {'n_hidden': 3, 'learning_rate': 0.002176433414274555, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14055285303255818, 'dropout_rate_Layer_2': 0.10151162308268105, 'dropout_rate_Layer_3': 0.20229057556896993, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.369851018423253e-05, 'l1_Layer_2': 1.4120136040331391e-05, 'l1_Layer_3': 0.0011079147320909517, 'n_units_Layer_1': 50, 'n_units_Layer_2': 130, 'n_units_Layer_3': 250}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 30.14% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 22.74 | sMAPE for Test Set is: 24.87% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:51:51,963]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:54,793]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:51:58,090]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:02,161]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:05,378]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:14,598]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:18,812]\u001b[0m Trial 230 finished with value: 6.228042898017951 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007884514795973534, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05056270900266991, 'dropout_rate_Layer_2': 0.20349344995482582, 'dropout_rate_Layer_3': 0.20849431275975647, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.5875048484120355e-05, 'l1_Layer_2': 0.00035569173176766084, 'l1_Layer_3': 3.06151098642779e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 250}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.23 | sMAPE for Validation Set is: 27.81% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.65 | sMAPE for Test Set is: 25.05% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:52:21,469]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:24,078]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:25,851]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:29,515]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:33,332]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:34,945]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:38,769]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:43,655]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:44,607]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:49,260]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:50,040]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:52,946]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:52:57,662]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:03,366]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:08,741]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:14,776]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 28.81% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 33.47 | sMAPE for Test Set is: 32.86% | rMAE for Test Set is: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:53:28,630]\u001b[0m Trial 235 finished with value: 6.51277200395461 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007115337039068149, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3900759435799587, 'dropout_rate_Layer_2': 0.0761713833410501, 'dropout_rate_Layer_3': 0.0998833207738697, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 1.2486708905671096e-05, 'l1_Layer_2': 0.021569176120481943, 'l1_Layer_3': 0.005577891177638624, 'n_units_Layer_1': 185, 'n_units_Layer_2': 300, 'n_units_Layer_3': 285}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:31,942]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:32,057]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:37,106]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:43,001]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:48,981]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:52,327]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:56,561]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:53:59,925]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:03,090]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:03,707]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:10,307]\u001b[0m Trial 248 finished with value: 6.4330672684732475 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006681927567504712, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1563585241830809, 'dropout_rate_Layer_2': 0.2687356769714507, 'dropout_rate_Layer_3': 0.16040549222567774, 'dropout_rate_Layer_4': 0.21187703460523843, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018371174868808179, 'l1_Layer_2': 0.006485169195627034, 'l1_Layer_3': 2.1111109434394308e-05, 'l1_Layer_4': 0.00011610140422500033, 'n_units_Layer_1': 290, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235, 'n_units_Layer_4': 70}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 28.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 34.39 | sMAPE for Test Set is: 34.07% | rMAE for Test Set is: 1.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:54:10,586]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:13,669]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:14,799]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:18,333]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:18,934]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:25,555]\u001b[0m Trial 262 finished with value: 6.880303126238321 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031023890585067156, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11114443665965196, 'dropout_rate_Layer_2': 0.1474018921916021, 'dropout_rate_Layer_3': 0.22728308043784284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9159127584494188e-05, 'l1_Layer_2': 2.4603181292025413e-05, 'l1_Layer_3': 0.0004359677720323436, 'n_units_Layer_1': 65, 'n_units_Layer_2': 110, 'n_units_Layer_3': 240}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 30.11% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 26.36 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:54:29,628]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:34,600]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:35,990]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:36,844]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:41,655]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:45,312]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:45,467]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:45,713]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:51,662]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:52,306]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:54:53,656]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:02,545]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:04,971]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:06,575]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:12,624]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:16,039]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:19,540]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:20,377]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:21,506]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:25,137]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:29,062]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:29,750]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:36,686]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:42,393]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:42,535]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:47,774]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:49,616]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:51,815]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:53,128]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:56,454]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:55:58,919]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:00,799]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:01,655]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:06,083]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:06,300]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:10,849]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:12,990]\u001b[0m Trial 281 finished with value: 6.160475785815837 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007394367284919629, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06001106160970757, 'dropout_rate_Layer_2': 0.298047198249068, 'dropout_rate_Layer_3': 0.3071609799113473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011957115393427654, 'l1_Layer_2': 0.0013630929300397518, 'l1_Layer_3': 7.43640799042442e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 145, 'n_units_Layer_3': 265}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.16 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 21.03 | sMAPE for Test Set is: 23.93% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:56:21,736]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:26,181]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:29,804]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:33,215]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:37,808]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:40,692]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:44,622]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:45,172]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:49,937]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:50,495]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:55,056]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:56:55,477]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:00,577]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:03,821]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:04,083]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:09,476]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:15,311]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:20,340]\u001b[0m Trial 314 finished with value: 6.31937434175421 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012154706230875138, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14207381326254584, 'dropout_rate_Layer_2': 0.10184851812012745, 'dropout_rate_Layer_3': 0.13381807162306877, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8576674813314737e-05, 'l1_Layer_2': 2.3546189869202583e-05, 'l1_Layer_3': 0.002243334486267243, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 260}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 28.24% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.91 | sMAPE for Test Set is: 51.18% | rMAE for Test Set is: 1.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 03:57:23,282]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:26,073]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:28,963]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:29,638]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:29,865]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:34,416]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:37,765]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:37,812]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:38,292]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:45,528]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:48,392]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:48,744]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:49,248]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:55,494]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:56,003]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:57:56,473]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:03,682]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:04,108]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:09,073]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:10,326]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:11,670]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:15,059]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:18,188]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:18,493]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:22,940]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:23,190]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:23,276]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:30,077]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:30,242]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:30,289]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:37,086]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:37,704]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:37,911]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:42,930]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:45,040]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:45,362]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:45,438]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:51,350]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:52,500]\u001b[0m Trial 361 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:56,426]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:58:56,545]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:01,905]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:02,104]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:04,878]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:07,773]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:09,997]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:10,821]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:12,183]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:16,678]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:17,129]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:21,202]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:23,320]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:25,657]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:28,590]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:31,087]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:35,268]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:35,819]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:35,947]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:42,331]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:45,378]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:48,807]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:51,769]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 03:59:58,257]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:03,772]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:04,015]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:11,342]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:14,699]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:19,126]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:19,708]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:24,310]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:25,755]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:29,142]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:29,943]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:34,902]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:38,547]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:42,666]\u001b[0m Trial 382 finished with value: 6.433467318553862 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007447161964503338, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39496432869631143, 'dropout_rate_Layer_2': 0.19220924929277847, 'dropout_rate_Layer_3': 0.1572765085031194, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00016750460189869437, 'l1_Layer_2': 0.016539749665650763, 'l1_Layer_3': 0.002510576552705547, 'n_units_Layer_1': 170, 'n_units_Layer_2': 185, 'n_units_Layer_3': 190}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 28.92% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 38.67 | sMAPE for Test Set is: 38.27% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:00:43,044]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:45,714]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:45,816]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:51,492]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:51,848]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:55,325]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:58,308]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:00:58,923]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:01,601]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:05,605]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:06,146]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:10,310]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:15,069]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:21,863]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:25,237]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:37,563]\u001b[0m Trial 409 finished with value: 6.240862876082613 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005401630927949889, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1363676857709788, 'dropout_rate_Layer_2': 0.1782386146885217, 'dropout_rate_Layer_3': 0.19184946861292543, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.720680985003292e-05, 'l1_Layer_2': 1.0311472244523333e-05, 'l1_Layer_3': 0.0008225298051040356, 'n_units_Layer_1': 140, 'n_units_Layer_2': 125, 'n_units_Layer_3': 200}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 27.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.25 | sMAPE for Test Set is: 22.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:01:43,161]\u001b[0m Trial 416 finished with value: 6.57915640536298 and parameters: {'n_hidden': 3, 'learning_rate': 0.00260641449308026, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13707875375698172, 'dropout_rate_Layer_2': 0.17121594509020902, 'dropout_rate_Layer_3': 0.18650628294123262, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0101421174052198e-05, 'l1_Layer_2': 1.0107304443352293e-05, 'l1_Layer_3': 0.0006737671089427277, 'n_units_Layer_1': 140, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 206 with value: 6.125610667394342.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 29.13% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 24.17% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:01:45,468]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:47,514]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:47,684]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:52,363]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:52,684]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:01:54,916]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:01,635]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:10,849]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:14,904]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:15,455]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:22,635]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:26,072]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:29,155]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:33,939]\u001b[0m Trial 422 finished with value: 6.124420011530154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006938902713596728, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05412336491711392, 'dropout_rate_Layer_2': 0.09103647592092103, 'dropout_rate_Layer_3': 0.3194603079457589, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003111395246509575, 'l1_Layer_2': 0.00016197156409075193, 'l1_Layer_3': 0.00011793052862967236, 'n_units_Layer_1': 265, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 28.02% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.88 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:02:36,091]\u001b[0m Trial 413 finished with value: 6.882112431232866 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012232596194259814, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3463425681024237, 'dropout_rate_Layer_2': 0.10597034594576489, 'dropout_rate_Layer_3': 0.21896711669618368, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 2.2126095296890148e-05, 'l1_Layer_2': 0.0026251015195817985, 'l1_Layer_3': 0.007928456786883468, 'n_units_Layer_1': 210, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.88 | sMAPE for Validation Set is: 29.79% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 38.59 | sMAPE for Test Set is: 37.96% | rMAE for Test Set is: 1.23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:02:41,253]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:43,398]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:45,916]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:51,957]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:52,074]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:02:57,440]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:01,860]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:08,027]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:12,543]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:14,538]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:17,074]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:19,800]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:21,939]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:24,381]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:25,607]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:27,639]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:31,604]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:38,432]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:41,946]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:44,718]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:45,124]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:53,488]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:55,403]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:03:57,424]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:01,457]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:07,875]\u001b[0m Trial 448 finished with value: 13.92268713333038 and parameters: {'n_hidden': 3, 'learning_rate': 0.005602517765333624, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.37160151119443785, 'dropout_rate_Layer_2': 0.0460049743272037, 'dropout_rate_Layer_3': 0.220441855862592, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 3.292322571637617e-05, 'l1_Layer_2': 0.0018712244114267274, 'l1_Layer_3': 0.09828291309065622, 'n_units_Layer_1': 250, 'n_units_Layer_2': 280, 'n_units_Layer_3': 285}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 13.92 | sMAPE for Validation Set is: 45.89% | rMAE for Validation Set is: 1.35\n",
      "MAE for Test Set is: 61.78 | sMAPE for Test Set is: 73.88% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:04:14,676]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:22,698]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:26,489]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:28,110]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:33,036]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:34,620]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:37,717]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:38,503]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:44,370]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:47,721]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:51,262]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:55,601]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:04:58,594]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:05,143]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:09,145]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:12,633]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:22,443]\u001b[0m Trial 471 finished with value: 6.493882767274465 and parameters: {'n_hidden': 3, 'learning_rate': 0.004515886874125149, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12637847184486972, 'dropout_rate_Layer_2': 0.2119154909015062, 'dropout_rate_Layer_3': 0.21816133051906525, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0854661776724725e-05, 'l1_Layer_2': 1.2366949504181884e-05, 'l1_Layer_3': 0.0006780499962802907, 'n_units_Layer_1': 125, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.49 | sMAPE for Validation Set is: 28.89% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.14 | sMAPE for Test Set is: 23.01% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:05:25,858]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:26,395]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:36,128]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:39,345]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:41,459]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:44,865]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:56,651]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:05:58,849]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:00,588]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:04,340]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:08,016]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:08,114]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:13,446]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:16,874]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:21,062]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:23,616]\u001b[0m Trial 466 finished with value: 6.64252797968568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026618961722066825, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32201528824134723, 'dropout_rate_Layer_2': 0.16882322949564837, 'dropout_rate_Layer_3': 0.1730120046875075, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4902228216744416e-05, 'l1_Layer_2': 0.03850953444201964, 'l1_Layer_3': 0.0015135760027104879, 'n_units_Layer_1': 185, 'n_units_Layer_2': 185, 'n_units_Layer_3': 245}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.64 | sMAPE for Validation Set is: 30.74% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 37.94 | sMAPE for Test Set is: 37.83% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:06:26,792]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:29,078]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:31,665]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:31,894]\u001b[0m Trial 464 finished with value: 6.6884462820861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026723105488048863, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3162724239574978, 'dropout_rate_Layer_2': 0.16588743524254623, 'dropout_rate_Layer_3': 0.18624803624423825, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8182803498717407e-05, 'l1_Layer_2': 0.038110886487279, 'l1_Layer_3': 0.001757243979544893, 'n_units_Layer_1': 185, 'n_units_Layer_2': 185, 'n_units_Layer_3': 250}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.69 | sMAPE for Validation Set is: 29.64% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 38.04 | sMAPE for Test Set is: 37.80% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:06:32,968]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:38,387]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:41,707]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:45,031]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:45,083]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:45,457]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:45,933]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:54,448]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:54,844]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:06:55,049]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:01,318]\u001b[0m Trial 504 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:04,658]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:06,201]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:09,880]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:12,192]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:12,743]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:16,811]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:18,828]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:19,172]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:25,677]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:28,769]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:29,028]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:34,380]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:34,487]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:38,243]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:40,040]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:43,974]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:47,044]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:51,318]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:51,694]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:56,258]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:07:57,254]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:01,603]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:02,101]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:08,341]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:18,385]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:21,606]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:45,636]\u001b[0m Trial 502 finished with value: 6.431447032406415 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024602865084244157, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3224721135492878, 'dropout_rate_Layer_2': 0.24946865602809343, 'dropout_rate_Layer_3': 0.17968350405655048, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004011683229749418, 'l1_Layer_2': 0.03822714693515137, 'l1_Layer_3': 0.0016903867511168572, 'n_units_Layer_1': 150, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 29.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 37.97 | sMAPE for Test Set is: 37.09% | rMAE for Test Set is: 1.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:08:49,380]\u001b[0m Trial 531 finished with value: 6.599670560896437 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007490150801289685, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16557613349570935, 'dropout_rate_Layer_2': 0.30135251770999477, 'dropout_rate_Layer_3': 0.15912465444373416, 'dropout_rate_Layer_4': 0.24972759937106564, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030619877367448964, 'l1_Layer_2': 0.004659985535016319, 'l1_Layer_3': 1.3721450478397697e-05, 'l1_Layer_4': 0.0001426609458883805, 'n_units_Layer_1': 290, 'n_units_Layer_2': 225, 'n_units_Layer_3': 240, 'n_units_Layer_4': 70}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.60 | sMAPE for Validation Set is: 29.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 34.07 | sMAPE for Test Set is: 34.06% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:08:54,725]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:58,518]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:08:59,939]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:04,036]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:07,350]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:10,712]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:16,720]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:17,283]\u001b[0m Trial 530 finished with value: 7.655771646304824 and parameters: {'n_hidden': 3, 'learning_rate': 0.009478600570516426, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31931752936938146, 'dropout_rate_Layer_2': 0.24227008383846493, 'dropout_rate_Layer_3': 0.1824466029046161, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.259706958162946e-05, 'l1_Layer_2': 0.043193023804652085, 'l1_Layer_3': 0.0012490566076151963, 'n_units_Layer_1': 145, 'n_units_Layer_2': 215, 'n_units_Layer_3': 240}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.66 | sMAPE for Validation Set is: 32.18% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 42.95 | sMAPE for Test Set is: 43.34% | rMAE for Test Set is: 1.37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:09:22,888]\u001b[0m Trial 542 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:26,570]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:27,059]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:32,308]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:44,720]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:48,066]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:52,432]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:09:56,726]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:01,926]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:02,583]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:06,149]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:07,912]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:11,929]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:16,857]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:23,256]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:26,815]\u001b[0m Trial 558 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:31,190]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:35,534]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:36,535]\u001b[0m Trial 533 finished with value: 6.525628730357248 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026860686922911907, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31972673888815767, 'dropout_rate_Layer_2': 0.25368651103389345, 'dropout_rate_Layer_3': 0.17701749244795695, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0274348423840991e-05, 'l1_Layer_2': 0.03800754202605319, 'l1_Layer_3': 0.0014527418145546598, 'n_units_Layer_1': 155, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.53 | sMAPE for Validation Set is: 29.56% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 37.28 | sMAPE for Test Set is: 36.32% | rMAE for Test Set is: 1.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:10:38,062]\u001b[0m Trial 546 finished with value: 6.282229330615247 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006679839053759369, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07159107699412794, 'dropout_rate_Layer_2': 0.3476365818839945, 'dropout_rate_Layer_3': 0.19037880563529172, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016737881467881834, 'l1_Layer_2': 1.0027804814983848e-05, 'l1_Layer_3': 0.0072261849111870235, 'n_units_Layer_1': 180, 'n_units_Layer_2': 100, 'n_units_Layer_3': 65}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.28 | sMAPE for Validation Set is: 28.06% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.71 | sMAPE for Test Set is: 23.41% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:10:42,761]\u001b[0m Trial 554 finished with value: 7.646322239638482 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017284329275392115, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.283171215682596, 'dropout_rate_Layer_2': 0.20159241503341485, 'dropout_rate_Layer_3': 0.13114791980331447, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.005204980299691237, 'l1_Layer_2': 0.027855458937160717, 'l1_Layer_3': 0.0038280755850063483, 'n_units_Layer_1': 100, 'n_units_Layer_2': 155, 'n_units_Layer_3': 215}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.65 | sMAPE for Validation Set is: 31.59% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 46.33 | sMAPE for Test Set is: 47.33% | rMAE for Test Set is: 1.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:10:49,185]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:51,103]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:53,944]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:10:55,927]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:09,062]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:22,625]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:25,869]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:32,016]\u001b[0m Trial 564 finished with value: 6.522714367160295 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005824836352259576, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16235264498301374, 'dropout_rate_Layer_2': 0.2875750901384453, 'dropout_rate_Layer_3': 0.15601812360222364, 'dropout_rate_Layer_4': 0.2338655201752766, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030306646963037813, 'l1_Layer_2': 0.005534021917453854, 'l1_Layer_3': 2.0812381387587832e-05, 'l1_Layer_4': 0.00014964316486762024, 'n_units_Layer_1': 300, 'n_units_Layer_2': 190, 'n_units_Layer_3': 240, 'n_units_Layer_4': 70}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 29.11% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 30.86 | sMAPE for Test Set is: 31.39% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:11:32,545]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:37,515]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:37,920]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:44,401]\u001b[0m Trial 561 finished with value: 6.501474953567334 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005882926891004079, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15916674552066418, 'dropout_rate_Layer_2': 0.2852819389868999, 'dropout_rate_Layer_3': 0.1548242245889903, 'dropout_rate_Layer_4': 0.22952501216923546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0020750867429058773, 'l1_Layer_2': 0.005315809491833894, 'l1_Layer_3': 1.9867642709782884e-05, 'l1_Layer_4': 0.00015322437940629415, 'n_units_Layer_1': 290, 'n_units_Layer_2': 245, 'n_units_Layer_3': 240, 'n_units_Layer_4': 55}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.50 | sMAPE for Validation Set is: 29.39% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.87 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:11:46,667]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:47,916]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:50,553]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:50,928]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:51,756]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:11:58,568]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:03,061]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:06,679]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:07,246]\u001b[0m Trial 567 finished with value: 6.484551434936962 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005907498747953723, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1609683819119645, 'dropout_rate_Layer_2': 0.2834965881458934, 'dropout_rate_Layer_3': 0.15283163360487767, 'dropout_rate_Layer_4': 0.23034249135816687, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0027270184516116204, 'l1_Layer_2': 0.005041012146635881, 'l1_Layer_3': 2.0559026387466733e-05, 'l1_Layer_4': 0.000143687668248533, 'n_units_Layer_1': 300, 'n_units_Layer_2': 200, 'n_units_Layer_3': 240, 'n_units_Layer_4': 55}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.48 | sMAPE for Validation Set is: 29.31% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 28.56 | sMAPE for Test Set is: 29.05% | rMAE for Test Set is: 0.91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:12:09,777]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:13,803]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:14,696]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:20,674]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:21,189]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:25,012]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:26,834]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:30,191]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:34,312]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:34,985]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:40,619]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:12:43,548]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:02,425]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:07,767]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:10,791]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:13,972]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:17,473]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:20,762]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:24,477]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:26,669]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:28,973]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:31,371]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:31,816]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:36,373]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:38,080]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:41,991]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:44,310]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:51,542]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:51,787]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:13:59,805]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:01,516]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:06,940]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:08,515]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:08,659]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:08,953]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:15,618]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:16,249]\u001b[0m Trial 619 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:18,228]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:20,459]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:23,104]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:24,345]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:28,785]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:29,255]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:36,484]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:36,793]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:41,817]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:42,996]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:45,562]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:49,661]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:49,679]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:54,406]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:14:58,781]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:02,171]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:02,547]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:07,120]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:09,150]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:13,698]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:16,853]\u001b[0m Trial 623 finished with value: 6.86437983119139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021803757521136804, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3063251071405939, 'dropout_rate_Layer_2': 0.2448935761693835, 'dropout_rate_Layer_3': 0.164220741229037, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00032951162739813604, 'l1_Layer_2': 0.01169704190210345, 'l1_Layer_3': 0.0008079048881387864, 'n_units_Layer_1': 200, 'n_units_Layer_2': 220, 'n_units_Layer_3': 220}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.86 | sMAPE for Validation Set is: 30.51% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 42.52 | sMAPE for Test Set is: 42.56% | rMAE for Test Set is: 1.35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:15:19,014]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:21,298]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:21,528]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:25,427]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:28,675]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:30,926]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:34,522]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:38,619]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:42,370]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:43,129]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:46,770]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:49,820]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:50,300]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:50,409]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:57,602]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:57,840]\u001b[0m Trial 656 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:15:58,327]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:00,292]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:06,901]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:09,013]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:10,080]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:11,642]\u001b[0m Trial 662 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:17,181]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:18,061]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:20,479]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:22,240]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:23,659]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:27,433]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:28,264]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:31,139]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:34,967]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:36,786]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:41,079]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:45,254]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:48,595]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:16:52,643]\u001b[0m Trial 658 finished with value: 8.096155935639901 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015791253484045737, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.33873787436720626, 'dropout_rate_Layer_2': 0.3467711391044838, 'dropout_rate_Layer_3': 0.20215743045690637, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010450358660217632, 'l1_Layer_2': 0.0052290201792717286, 'l1_Layer_3': 0.00580160122056257, 'n_units_Layer_1': 165, 'n_units_Layer_2': 225, 'n_units_Layer_3': 135}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 8.10 | sMAPE for Validation Set is: 32.84% | rMAE for Validation Set is: 0.79\n",
      "MAE for Test Set is: 46.96 | sMAPE for Test Set is: 48.42% | rMAE for Test Set is: 1.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:16:58,360]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:02,563]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:05,944]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:10,203]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:11,760]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:15,561]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:16,087]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:21,009]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:23,175]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:23,746]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:28,113]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:30,436]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:30,764]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:32,016]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:37,063]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:38,600]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:46,151]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:46,384]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:51,873]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:55,577]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:17:58,534]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:02,471]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:02,791]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:02,956]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:12,171]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:12,847]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:18,304]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:24,922]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:30,735]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:34,479]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:37,795]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:41,556]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:42,211]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:47,094]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:49,139]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:52,481]\u001b[0m Trial 714 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:56,026]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:18:56,096]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:05,393]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:07,953]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:10,369]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:12,994]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:15,377]\u001b[0m Trial 703 finished with value: 6.570122065506496 and parameters: {'n_hidden': 3, 'learning_rate': 0.004213173651054997, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13219423183610762, 'dropout_rate_Layer_2': 0.2030587275294033, 'dropout_rate_Layer_3': 0.13172566657252593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 0.003190885119779291, 'l1_Layer_2': 0.052062104847127394, 'l1_Layer_3': 0.003211055258831896, 'n_units_Layer_1': 215, 'n_units_Layer_2': 165, 'n_units_Layer_3': 290}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.57 | sMAPE for Validation Set is: 29.51% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 39.74 | sMAPE for Test Set is: 39.45% | rMAE for Test Set is: 1.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:19:19,004]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:23,088]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:23,400]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:27,230]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:27,852]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:28,297]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:35,002]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:35,220]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:35,903]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:42,532]\u001b[0m Trial 730 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:49,694]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:50,662]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:54,764]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:55,115]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:19:59,273]\u001b[0m Trial 734 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:03,673]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:03,882]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:06,521]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:09,739]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:13,729]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:19,064]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:22,234]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:26,399]\u001b[0m Trial 741 finished with value: 6.463074967042995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031993846025655717, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.138867150588996, 'dropout_rate_Layer_2': 0.06000340371969357, 'dropout_rate_Layer_3': 0.1448656954180578, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3913082472047092e-05, 'l1_Layer_2': 2.9861702095026744e-05, 'l1_Layer_3': 0.00017678751159868006, 'n_units_Layer_1': 75, 'n_units_Layer_2': 155, 'n_units_Layer_3': 230}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.46 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.30 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:20:30,907]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:31,539]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:33,440]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:40,531]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:43,490]\u001b[0m Trial 746 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:47,476]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:47,529]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:48,145]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:56,595]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:20:56,918]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:01,475]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:04,686]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:05,588]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:10,578]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:25,078]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:26,380]\u001b[0m Trial 754 finished with value: 6.294035471286503 and parameters: {'n_hidden': 4, 'learning_rate': 0.004633125991855867, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15106695762865519, 'dropout_rate_Layer_2': 0.04737894214434327, 'dropout_rate_Layer_3': 0.16635876243686085, 'dropout_rate_Layer_4': 0.0010545208252129012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.240936069937447e-05, 'l1_Layer_2': 1.7449693733187952e-05, 'l1_Layer_3': 9.938521885488583e-05, 'l1_Layer_4': 0.009136846561250269, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245, 'n_units_Layer_4': 50}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 28.14% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.41 | sMAPE for Test Set is: 22.80% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:21:29,650]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:45,232]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:46,922]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:52,076]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:21:57,446]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:09,799]\u001b[0m Trial 762 finished with value: 7.059458224896822 and parameters: {'n_hidden': 3, 'learning_rate': 0.007555880234645785, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06836131108813627, 'dropout_rate_Layer_2': 0.25739232064246115, 'dropout_rate_Layer_3': 0.16564118134781186, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.015208561264154548, 'l1_Layer_2': 0.08901721213210442, 'l1_Layer_3': 0.0007429792403664809, 'n_units_Layer_1': 185, 'n_units_Layer_2': 50, 'n_units_Layer_3': 285}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 30.14% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 22.08 | sMAPE for Test Set is: 24.78% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:22:15,454]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:22,263]\u001b[0m Trial 764 finished with value: 6.192354572104599 and parameters: {'n_hidden': 3, 'learning_rate': 0.000728861485689331, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008064570298345548, 'dropout_rate_Layer_2': 0.19092428144856902, 'dropout_rate_Layer_3': 0.32496968823622197, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.657508952272475e-05, 'l1_Layer_2': 3.3821890332610155e-05, 'l1_Layer_3': 8.189831331923065e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 145, 'n_units_Layer_3': 270}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 28.83% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.33 | sMAPE for Test Set is: 25.37% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:22:26,370]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:27,449]\u001b[0m Trial 767 finished with value: 6.543999114796976 and parameters: {'n_hidden': 4, 'learning_rate': 0.004688363163220531, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15078578270549226, 'dropout_rate_Layer_2': 0.044471526769080866, 'dropout_rate_Layer_3': 0.17047213378340054, 'dropout_rate_Layer_4': 0.005971410409678991, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.459696489753313e-05, 'l1_Layer_2': 2.711478723693922e-05, 'l1_Layer_3': 9.65573130339927e-05, 'l1_Layer_4': 0.011744068875314075, 'n_units_Layer_1': 75, 'n_units_Layer_2': 150, 'n_units_Layer_3': 250, 'n_units_Layer_4': 55}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 28.42% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.48 | sMAPE for Test Set is: 22.79% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:22:32,562]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:37,889]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:41,136]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:45,742]\u001b[0m Trial 768 finished with value: 6.203628616653444 and parameters: {'n_hidden': 4, 'learning_rate': 0.004624468055375488, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2093124685780665, 'dropout_rate_Layer_2': 0.03150671774309807, 'dropout_rate_Layer_3': 0.16936695379019057, 'dropout_rate_Layer_4': 0.0009262161919771476, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2777341666151044e-05, 'l1_Layer_2': 2.8133222856771967e-05, 'l1_Layer_3': 0.000127761318036557, 'l1_Layer_4': 0.008802481037937303, 'n_units_Layer_1': 70, 'n_units_Layer_2': 145, 'n_units_Layer_3': 245, 'n_units_Layer_4': 75}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 27.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.05 | sMAPE for Test Set is: 22.70% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:22:50,794]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:22:55,010]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:03,089]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:10,800]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:14,935]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:20,405]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:24,116]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:28,931]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:36,283]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:40,312]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:44,858]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:53,681]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:56,067]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:23:58,987]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:02,725]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:06,672]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:10,590]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:14,720]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:16,585]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:26,244]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:30,218]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:34,485]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:35,128]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:40,660]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:43,241]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:46,156]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:47,103]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:53,924]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:54,280]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:24:54,951]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:07,144]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:11,088]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:11,461]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:19,535]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:22,635]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:26,563]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:34,539]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:34,934]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:41,848]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:44,899]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:25:45,310]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:02,466]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:12,744]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:15,922]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:19,640]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:28,561]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:31,299]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:34,674]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:35,466]\u001b[0m Trial 803 finished with value: 6.425679217739273 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009885098735392898, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35630694616561376, 'dropout_rate_Layer_2': 0.15387419180402584, 'dropout_rate_Layer_3': 0.04118205582675065, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.054650353506173e-05, 'l1_Layer_2': 0.005523643174814099, 'l1_Layer_3': 0.00041741845742059264, 'n_units_Layer_1': 175, 'n_units_Layer_2': 135, 'n_units_Layer_3': 180}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 29.43% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 23.85 | sMAPE for Test Set is: 25.21% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:26:39,892]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:44,177]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:47,400]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:51,249]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:26:51,480]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:27:02,014]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:27:07,500]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:27:11,901]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:27:26,720]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:16,606]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:20,245]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:23,788]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:33,031]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:42,302]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:45,163]\u001b[0m Trial 829 finished with value: 6.91086294368034 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005406457651116927, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38564985598257034, 'dropout_rate_Layer_2': 0.16399809053422315, 'dropout_rate_Layer_3': 0.024978965737758284, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4020885028531504e-05, 'l1_Layer_2': 0.016423352860898847, 'l1_Layer_3': 0.0001437446367433411, 'n_units_Layer_1': 190, 'n_units_Layer_2': 105, 'n_units_Layer_3': 200}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.91 | sMAPE for Validation Set is: 29.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 22.87 | sMAPE for Test Set is: 25.41% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:28:48,311]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:53,678]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:28:57,632]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:08,750]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:12,076]\u001b[0m Trial 833 finished with value: 7.061824073868845 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007606775173995576, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3829232694726295, 'dropout_rate_Layer_2': 0.1306789081710803, 'dropout_rate_Layer_3': 0.1421307284816526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4232171739066407e-05, 'l1_Layer_2': 0.01584464075233355, 'l1_Layer_3': 0.00022332579416537308, 'n_units_Layer_1': 160, 'n_units_Layer_2': 80, 'n_units_Layer_3': 200}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.06 | sMAPE for Validation Set is: 31.42% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 21.71 | sMAPE for Test Set is: 25.02% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:29:14,278]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:17,424]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:19,668]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:23,002]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:25,961]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:30,425]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:43,479]\u001b[0m Trial 847 finished with value: 6.524448367689313 and parameters: {'n_hidden': 4, 'learning_rate': 0.00726563474812935, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1723615054569727, 'dropout_rate_Layer_2': 0.05080920772237668, 'dropout_rate_Layer_3': 0.15966962572219676, 'dropout_rate_Layer_4': 0.06736314894025394, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.240054819923805e-05, 'l1_Layer_2': 4.443978434845855e-05, 'l1_Layer_3': 9.091576381906664e-05, 'l1_Layer_4': 0.0022532988437653162, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260, 'n_units_Layer_4': 55}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.52 | sMAPE for Validation Set is: 29.14% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.02 | sMAPE for Test Set is: 24.22% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:29:46,864]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:51,663]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:29:57,988]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:30:11,289]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:30:13,470]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:30:14,888]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:30:23,441]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:30:27,007]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:00,815]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:05,080]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:08,643]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:13,282]\u001b[0m Trial 842 finished with value: 6.3708856269458485 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007464991101684675, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36475624100676146, 'dropout_rate_Layer_2': 0.135399288570653, 'dropout_rate_Layer_3': 0.148227019448864, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.06265558676081e-05, 'l1_Layer_2': 0.0008011239698039079, 'l1_Layer_3': 0.002253170831066771, 'n_units_Layer_1': 160, 'n_units_Layer_2': 75, 'n_units_Layer_3': 180}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 29.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.27 | sMAPE for Test Set is: 26.10% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:31:15,240]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:18,246]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:21,902]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:24,768]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:25,246]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:29,658]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:32,447]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:33,438]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:33,438]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:31:41,037]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:32:16,160]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:32:18,845]\u001b[0m Trial 855 finished with value: 6.7031797345461355 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007089343299318566, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0552823252847555, 'dropout_rate_Layer_2': 0.30279654853311405, 'dropout_rate_Layer_3': 0.39831086865334864, 'dropout_rate_Layer_4': 0.39997963117803265, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003852412795713782, 'l1_Layer_2': 0.0072957025585286914, 'l1_Layer_3': 0.00014452562067184587, 'l1_Layer_4': 0.00010843309568888318, 'n_units_Layer_1': 80, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230, 'n_units_Layer_4': 160}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.70 | sMAPE for Validation Set is: 29.85% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 46.54 | sMAPE for Test Set is: 47.59% | rMAE for Test Set is: 1.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:32:38,926]\u001b[0m Trial 874 finished with value: 6.535201479014745 and parameters: {'n_hidden': 4, 'learning_rate': 0.007905657734966754, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17206846982460672, 'dropout_rate_Layer_2': 0.04479091240391788, 'dropout_rate_Layer_3': 0.160205752317518, 'dropout_rate_Layer_4': 0.003382550738965943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.2501579736772944e-05, 'l1_Layer_2': 9.482323629169428e-05, 'l1_Layer_3': 1.5410595215421645e-05, 'l1_Layer_4': 0.0019840152723587245, 'n_units_Layer_1': 90, 'n_units_Layer_2': 155, 'n_units_Layer_3': 260, 'n_units_Layer_4': 70}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 28.86% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.91 | sMAPE for Test Set is: 24.95% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:32:42,120]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:33:04,030]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:33:44,116]\u001b[0m Trial 870 finished with value: 6.584788546974502 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006663549484803804, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045889697027663975, 'dropout_rate_Layer_2': 0.312221747419546, 'dropout_rate_Layer_3': 0.17568703479613698, 'dropout_rate_Layer_4': 0.20305062445051666, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0030348784452850055, 'l1_Layer_2': 0.006492698286123466, 'l1_Layer_3': 0.00010010587466217451, 'l1_Layer_4': 0.00010530919691630236, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 240, 'n_units_Layer_4': 190}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.58 | sMAPE for Validation Set is: 30.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 43.48 | sMAPE for Test Set is: 43.45% | rMAE for Test Set is: 1.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:33:49,196]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:33:51,835]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:33:54,702]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:03,565]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:06,916]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:10,558]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:10,902]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:12,200]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:16,005]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:17,968]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:19,787]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:28,517]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:28,874]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:32,123]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:37,681]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:40,925]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:46,617]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:54,937]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:34:55,373]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:03,388]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:11,044]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:13,513]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:14,233]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:18,257]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:20,513]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:22,955]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:25,475]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:28,029]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:31,977]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:35,936]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:39,374]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:51,495]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:35:57,571]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:03,298]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:09,208]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:18,622]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:24,563]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:28,305]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:28,571]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:36:34,067]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:37:10,986]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:37:22,729]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:37:28,320]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:37:32,543]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:37:41,726]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:01,353]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:07,595]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:10,990]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:27,020]\u001b[0m Trial 891 finished with value: 6.34340112968712 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007030755638119181, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050256054322385266, 'dropout_rate_Layer_2': 0.3065225311891859, 'dropout_rate_Layer_3': 0.36458840115648783, 'dropout_rate_Layer_4': 0.2387949260731902, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.002505990238400012, 'l1_Layer_2': 0.00036758665805654425, 'l1_Layer_3': 7.025729454886326e-05, 'l1_Layer_4': 0.00015475660383580116, 'n_units_Layer_1': 85, 'n_units_Layer_2': 210, 'n_units_Layer_3': 235, 'n_units_Layer_4': 165}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.34 | sMAPE for Validation Set is: 29.24% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.67 | sMAPE for Test Set is: 49.40% | rMAE for Test Set is: 1.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:38:34,926]\u001b[0m Trial 918 finished with value: 6.364474872776974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010704769398698515, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07654572014117685, 'dropout_rate_Layer_2': 0.047078783827221776, 'dropout_rate_Layer_3': 0.10465021540114014, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00025153546422074816, 'l1_Layer_2': 0.00014285518853537161, 'l1_Layer_3': 0.0019746487763368232, 'n_units_Layer_1': 115, 'n_units_Layer_2': 60, 'n_units_Layer_3': 180}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 28.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 40.48 | sMAPE for Test Set is: 41.54% | rMAE for Test Set is: 1.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:38:36,516]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:40,539]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:45,024]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:47,974]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:52,612]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:38:55,995]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:00,200]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:09,358]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:12,926]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:15,986]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:19,616]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:24,938]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:39,353]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:39:49,155]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:40:08,853]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:40:13,891]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:40:17,155]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:40:37,581]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:40:49,567]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:40:53,952]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:03,763]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:07,575]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:11,149]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:16,964]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:17,699]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:22,447]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:25,936]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:29,022]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:31,438]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:33,954]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:36,353]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:41,017]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:44,321]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:51,001]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:54,091]\u001b[0m Trial 927 finished with value: 6.513979599497444 and parameters: {'n_hidden': 3, 'learning_rate': 0.00058554656246161, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04676601031241209, 'dropout_rate_Layer_2': 0.05281938389883446, 'dropout_rate_Layer_3': 0.054745542162817136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.5610918928040544e-05, 'l1_Layer_2': 0.0001408169711530361, 'l1_Layer_3': 0.00268154423718418, 'n_units_Layer_1': 55, 'n_units_Layer_2': 150, 'n_units_Layer_3': 80}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.51 | sMAPE for Validation Set is: 29.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 20.43 | sMAPE for Test Set is: 24.04% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:41:54,714]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:59,001]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:41:59,525]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:00,537]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:08,876]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:13,177]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:17,627]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:17,747]\u001b[0m Trial 969 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:24,801]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:24,847]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:30,354]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:30,518]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:36,281]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:36,905]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:41,373]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:44,848]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:42:48,266]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:00,372]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:09,503]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:16,423]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:23,701]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:28,370]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:35,354]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:35,640]\u001b[0m Trial 943 finished with value: 6.3232614176155195 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005087201427811573, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04218805010630431, 'dropout_rate_Layer_2': 0.05282957861122023, 'dropout_rate_Layer_3': 0.0565035923128577, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006894090055595838, 'l1_Layer_2': 9.244197557048158e-05, 'l1_Layer_3': 0.003037771880361684, 'n_units_Layer_1': 90, 'n_units_Layer_2': 55, 'n_units_Layer_3': 180}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 28.49% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 31.63 | sMAPE for Test Set is: 31.85% | rMAE for Test Set is: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:43:41,593]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:41,743]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:47,934]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:48,337]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:54,040]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:57,524]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:43:57,720]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:03,805]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:03,968]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:11,185]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:11,758]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:17,669]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:17,833]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:23,850]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:29,174]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:33,453]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:42,367]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:44:45,877]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:08,578]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:12,150]\u001b[0m Trial 1006 finished with value: 6.432043295683081 and parameters: {'n_hidden': 4, 'learning_rate': 0.007439294129756647, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3340306475060876, 'dropout_rate_Layer_2': 0.07361424790159894, 'dropout_rate_Layer_3': 0.2063075887123163, 'dropout_rate_Layer_4': 0.028892066231134012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 1.1996510370817111e-05, 'l1_Layer_2': 1.6022019921873308e-05, 'l1_Layer_3': 6.655081109998482e-05, 'l1_Layer_4': 0.006978810140721832, 'n_units_Layer_1': 55, 'n_units_Layer_2': 140, 'n_units_Layer_3': 250, 'n_units_Layer_4': 80}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 28.32% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 23.46% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:45:12,547]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:19,533]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:23,123]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:29,431]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:36,734]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:41,437]\u001b[0m Trial 985 finished with value: 6.419273308546817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006998351469815847, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02842405382640646, 'dropout_rate_Layer_2': 0.019456886807538265, 'dropout_rate_Layer_3': 0.07672283224492572, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.332812856416473e-05, 'l1_Layer_2': 0.00013832547555484793, 'l1_Layer_3': 0.006648379709072939, 'n_units_Layer_1': 55, 'n_units_Layer_2': 80, 'n_units_Layer_3': 175}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.42 | sMAPE for Validation Set is: 30.21% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.15 | sMAPE for Test Set is: 24.53% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:45:44,311]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:45,403]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:49,618]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:50,302]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:51,271]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:45:57,630]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:01,205]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:01,380]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:04,387]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:09,829]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:10,656]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:16,080]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:20,105]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:22,039]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:26,419]\u001b[0m Trial 1001 finished with value: 6.627676806308625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005168555242356365, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0001747420672760791, 'dropout_rate_Layer_2': 0.03402088528715561, 'dropout_rate_Layer_3': 0.05832252010698437, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0006131851518357621, 'l1_Layer_2': 0.00010276643564550407, 'l1_Layer_3': 0.008382660923080857, 'n_units_Layer_1': 55, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 25.74 | sMAPE for Test Set is: 26.42% | rMAE for Test Set is: 0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:46:29,371]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:34,127]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:46:47,468]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:07,794]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:25,629]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:29,869]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:34,260]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:38,136]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:43,135]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:47,081]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:47:50,515]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:02,916]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:06,488]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:10,527]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:15,178]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:19,004]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:27,857]\u001b[0m Trial 1033 finished with value: 6.414659445817023 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006891164412437496, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13775094355766992, 'dropout_rate_Layer_2': 0.2786712025676399, 'dropout_rate_Layer_3': 0.1881859506203634, 'dropout_rate_Layer_4': 0.14865955179322535, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006117804787137934, 'l1_Layer_2': 0.004349148667502222, 'l1_Layer_3': 1.149154201341968e-05, 'l1_Layer_4': 0.00010385014896335617, 'n_units_Layer_1': 290, 'n_units_Layer_2': 180, 'n_units_Layer_3': 230, 'n_units_Layer_4': 125}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 28.35% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.29 | sMAPE for Test Set is: 22.84% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:48:32,530]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:48:32,893]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:01,341]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:02,069]\u001b[0m Trial 1032 finished with value: 6.551521955219511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007030477103007045, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02878511203364213, 'dropout_rate_Layer_2': 0.022804998930195226, 'dropout_rate_Layer_3': 0.031032807746551632, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0002367197665724636, 'l1_Layer_2': 4.886376430468048e-05, 'l1_Layer_3': 0.01847448467121397, 'n_units_Layer_1': 70, 'n_units_Layer_2': 95, 'n_units_Layer_3': 160}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 28.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 27.16 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:49:17,912]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:20,650]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:23,116]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:25,455]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:29,635]\u001b[0m Trial 1029 finished with value: 6.616188283119914 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007013425785531562, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03299781771051012, 'dropout_rate_Layer_2': 0.02273691083302906, 'dropout_rate_Layer_3': 0.07768281592821219, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.00012721048080124235, 'l1_Layer_2': 4.549502781604591e-05, 'l1_Layer_3': 0.017680537244659646, 'n_units_Layer_1': 75, 'n_units_Layer_2': 100, 'n_units_Layer_3': 165}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 32.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 23.41 | sMAPE for Test Set is: 24.83% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:49:29,985]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:31,480]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:34,943]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:39,618]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:42,405]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:42,518]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:45,625]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:47,390]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:49,440]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:49:58,225]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:01,719]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:05,154]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:08,479]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:11,810]\u001b[0m Trial 1064 finished with value: 6.827642846114194 and parameters: {'n_hidden': 3, 'learning_rate': 0.006688378457645589, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1411196719587058, 'dropout_rate_Layer_2': 0.0693657315864602, 'dropout_rate_Layer_3': 0.14638634005944967, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.956063758606025e-05, 'l1_Layer_2': 7.049071753356198e-05, 'l1_Layer_3': 4.095447343277618e-05, 'n_units_Layer_1': 90, 'n_units_Layer_2': 145, 'n_units_Layer_3': 220}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.83 | sMAPE for Validation Set is: 29.84% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 43.71 | sMAPE for Test Set is: 44.54% | rMAE for Test Set is: 1.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:50:12,444]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:13,135]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:18,726]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:21,995]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:28,150]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:28,300]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:28,445]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:36,444]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:36,770]\u001b[0m Trial 1061 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:42,723]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:42,847]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:45,065]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:52,731]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:50:55,763]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:01,215]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:06,050]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:15,746]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:20,787]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:22,686]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:26,645]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:26,679]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:30,894]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:37,932]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:38,518]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:43,875]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:44,923]\u001b[0m Trial 1090 finished with value: 6.397200721411402 and parameters: {'n_hidden': 3, 'learning_rate': 0.002731215465136163, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13688959553745644, 'dropout_rate_Layer_2': 0.15936815295648504, 'dropout_rate_Layer_3': 0.23270002861560676, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0498353321997633e-05, 'l1_Layer_2': 1.4552502094128475e-05, 'l1_Layer_3': 0.0006603181456490376, 'n_units_Layer_1': 125, 'n_units_Layer_2': 150, 'n_units_Layer_3': 230}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.40 | sMAPE for Validation Set is: 28.22% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.19 | sMAPE for Test Set is: 24.03% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:51:50,091]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:51,024]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:51:56,765]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:00,976]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:03,450]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:05,381]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:09,871]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:16,246]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:19,823]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:23,757]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:24,527]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:28,297]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:30,025]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:31,150]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:34,288]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:36,512]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:38,294]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:42,990]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:43,122]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:45,714]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:51,076]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:53,191]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:54,361]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:52:58,955]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:02,015]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:02,283]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:07,991]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:10,470]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:14,647]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:20,221]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:24,289]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:27,953]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:32,374]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:36,182]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:40,341]\u001b[0m Trial 1122 finished with value: 6.358422048714568 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018200634353215243, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14768399546212788, 'dropout_rate_Layer_2': 0.20813318868263891, 'dropout_rate_Layer_3': 0.20617198651534943, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7686166512879483e-05, 'l1_Layer_2': 1.2486787388788966e-05, 'l1_Layer_3': 0.00010321677376778885, 'n_units_Layer_1': 65, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.36 | sMAPE for Validation Set is: 28.61% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 19.73 | sMAPE for Test Set is: 23.36% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:53:44,418]\u001b[0m Trial 1096 finished with value: 6.535666031421282 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005620828985774788, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08934237254869135, 'dropout_rate_Layer_2': 0.051273852257516475, 'dropout_rate_Layer_3': 0.015038747851093867, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.567482933918271e-05, 'l1_Layer_2': 0.00016335449302247717, 'l1_Layer_3': 0.0028579928968591136, 'n_units_Layer_1': 50, 'n_units_Layer_2': 135, 'n_units_Layer_3': 100}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 28.53% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 24.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:53:47,633]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:48,456]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:53,952]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:53:54,593]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:54:01,281]\u001b[0m Trial 1135 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:13,724]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:18,790]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:23,482]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:27,246]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:36,660]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:43,054]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:55:47,118]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:16,490]\u001b[0m Trial 1129 finished with value: 6.667383983368357 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006030516315434746, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.014466128738743741, 'dropout_rate_Layer_2': 0.04907102499659604, 'dropout_rate_Layer_3': 0.05769936894706009, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6476552958649615e-05, 'l1_Layer_2': 0.00015208383372055496, 'l1_Layer_3': 0.002749054786718892, 'n_units_Layer_1': 50, 'n_units_Layer_2': 60, 'n_units_Layer_3': 80}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.67 | sMAPE for Validation Set is: 29.39% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 26.88 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:56:28,591]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:34,943]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:39,975]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:43,816]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:47,808]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:48,112]\u001b[0m Trial 1137 finished with value: 6.624484690317232 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007766956378990328, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04697501347260008, 'dropout_rate_Layer_2': 0.07900716299783446, 'dropout_rate_Layer_3': 0.057986106929732446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016624494262621899, 'l1_Layer_2': 6.639677348323592e-05, 'l1_Layer_3': 0.0041624186164707505, 'n_units_Layer_1': 60, 'n_units_Layer_2': 90, 'n_units_Layer_3': 75}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.62 | sMAPE for Validation Set is: 28.90% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 21.92 | sMAPE for Test Set is: 24.75% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:56:53,960]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:54,242]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:56:59,527]\u001b[0m Trial 1144 finished with value: 6.252826601993241 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019869214949410573, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17189327117524988, 'dropout_rate_Layer_2': 0.22574925842104843, 'dropout_rate_Layer_3': 0.219849927949897, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.267518438204435e-05, 'l1_Layer_2': 1.532439639996476e-05, 'l1_Layer_3': 0.0021489393001607906, 'n_units_Layer_1': 60, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.25 | sMAPE for Validation Set is: 28.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.26 | sMAPE for Test Set is: 24.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:57:02,523]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:05,385]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:08,248]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:12,613]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:18,242]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:21,059]\u001b[0m Trial 1151 finished with value: 6.413748449152379 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017822929147920503, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16944614341814263, 'dropout_rate_Layer_2': 0.20573305870190733, 'dropout_rate_Layer_3': 0.2132159855568031, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.781610620323818e-05, 'l1_Layer_2': 1.5214840777149817e-05, 'l1_Layer_3': 0.00013422499896397104, 'n_units_Layer_1': 135, 'n_units_Layer_2': 195, 'n_units_Layer_3': 300}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.41 | sMAPE for Validation Set is: 29.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 22.49 | sMAPE for Test Set is: 25.15% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:57:24,242]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:26,327]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:29,169]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:30,481]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:35,262]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:36,228]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:42,879]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:46,630]\u001b[0m Trial 1132 finished with value: 6.375754615741271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006158666982790734, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.013935434246610954, 'dropout_rate_Layer_2': 0.08353208971180191, 'dropout_rate_Layer_3': 0.05500180965812775, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018264505734093796, 'l1_Layer_2': 7.423447311147156e-05, 'l1_Layer_3': 0.00410580308184806, 'n_units_Layer_1': 60, 'n_units_Layer_2': 155, 'n_units_Layer_3': 75}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.38 | sMAPE for Validation Set is: 29.46% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.46 | sMAPE for Test Set is: 24.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:57:47,454]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:48,491]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:53,031]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:56,274]\u001b[0m Trial 1168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:57,659]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:57:59,875]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:05,510]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:05,693]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:05,918]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:14,533]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:15,456]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:15,697]\u001b[0m Trial 1161 finished with value: 6.263749602716641 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019494131466089445, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18543388109709255, 'dropout_rate_Layer_2': 0.21445264219637097, 'dropout_rate_Layer_3': 0.23875629604727583, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.016685412242873e-05, 'l1_Layer_2': 1.0132098087905564e-05, 'l1_Layer_3': 0.0010060006680945516, 'n_units_Layer_1': 130, 'n_units_Layer_2': 185, 'n_units_Layer_3': 300}. Best is trial 422 with value: 6.124420011530154.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.26 | sMAPE for Validation Set is: 29.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.60 | sMAPE for Test Set is: 23.79% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:58:24,138]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:25,603]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:29,746]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:30,329]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:35,714]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:36,834]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:37,135]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:41,243]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:45,962]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:46,168]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:48,384]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:54,596]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:55,648]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:56,021]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:58:59,585]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:04,170]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:04,551]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:13,891]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:19,388]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:23,374]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:24,475]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:29,018]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:31,707]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:34,704]\u001b[0m Trial 1186 finished with value: 6.10799463450369 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016815331168524845, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18297028493649375, 'dropout_rate_Layer_2': 0.227872775159972, 'dropout_rate_Layer_3': 0.2412096588793747, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.5570803705042276e-05, 'l1_Layer_2': 2.005664680454973e-05, 'l1_Layer_3': 0.0015520393193481608, 'n_units_Layer_1': 145, 'n_units_Layer_2': 200, 'n_units_Layer_3': 300}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.11 | sMAPE for Validation Set is: 27.42% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.43 | sMAPE for Test Set is: 23.09% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 04:59:39,194]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:39,775]\u001b[0m Trial 1202 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:46,509]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:48,219]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:51,613]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 04:59:57,063]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:01,096]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:26,009]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:30,741]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:34,500]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:41,632]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:49,151]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:53,118]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:00:57,052]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:00,717]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:16,096]\u001b[0m Trial 1210 finished with value: 6.39114401278092 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007494128888647249, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17376600124383182, 'dropout_rate_Layer_2': 0.2791626967466879, 'dropout_rate_Layer_3': 0.1827380481400757, 'dropout_rate_Layer_4': 0.19623272213297108, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005247850367504865, 'l1_Layer_2': 0.008361454859416289, 'l1_Layer_3': 9.696397212255097e-05, 'l1_Layer_4': 0.00011248271376338764, 'n_units_Layer_1': 235, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235, 'n_units_Layer_4': 160}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.39 | sMAPE for Validation Set is: 28.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 26.81 | sMAPE for Test Set is: 27.91% | rMAE for Test Set is: 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:01:20,897]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:25,163]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:31,900]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:37,782]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:41,891]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:45,946]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:50,010]\u001b[0m Trial 1225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:01:53,496]\u001b[0m Trial 1203 finished with value: 6.631838618907508 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005109681317755342, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0031492605525259496, 'dropout_rate_Layer_2': 0.10140252165115729, 'dropout_rate_Layer_3': 0.06728443378569511, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017756941865586332, 'l1_Layer_2': 7.238292971468416e-05, 'l1_Layer_3': 0.012436954294294702, 'n_units_Layer_1': 85, 'n_units_Layer_2': 155, 'n_units_Layer_3': 85}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.63 | sMAPE for Validation Set is: 29.91% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 30.48 | sMAPE for Test Set is: 29.52% | rMAE for Test Set is: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:01:58,595]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:02:01,221]\u001b[0m Trial 1196 finished with value: 7.067750327464818 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005094200945749007, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.023402234673010478, 'dropout_rate_Layer_2': 0.0694386754374538, 'dropout_rate_Layer_3': 0.029970330264407923, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.024916389802072e-05, 'l1_Layer_2': 0.00029785176841826773, 'l1_Layer_3': 0.014361313787679202, 'n_units_Layer_1': 90, 'n_units_Layer_2': 150, 'n_units_Layer_3': 90}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 7.07 | sMAPE for Validation Set is: 31.27% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 22.78 | sMAPE for Test Set is: 25.20% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:02:08,105]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:02:12,278]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:02:12,729]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:02:19,949]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:02:27,786]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:02:32,583]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:02,527]\u001b[0m Trial 1234 finished with value: 6.218904501301 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019262172880702294, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14177852912556638, 'dropout_rate_Layer_2': 0.1896462517910768, 'dropout_rate_Layer_3': 0.23878267598532218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1192015027224033e-05, 'l1_Layer_2': 1.2543881336783303e-05, 'l1_Layer_3': 0.001124714409810213, 'n_units_Layer_1': 125, 'n_units_Layer_2': 180, 'n_units_Layer_3': 295}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 27.80% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.82 | sMAPE for Test Set is: 23.12% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:03:06,421]\u001b[0m Trial 1228 finished with value: 6.2360298562900764 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007863998819626216, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1691664317231125, 'dropout_rate_Layer_2': 0.2778626028320789, 'dropout_rate_Layer_3': 0.15346162596496846, 'dropout_rate_Layer_4': 0.18761355799610438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011149405467158148, 'l1_Layer_2': 0.013512698166653958, 'l1_Layer_3': 0.00011649242529899636, 'l1_Layer_4': 0.00018730481173384424, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210, 'n_units_Layer_4': 160}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 28.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 34.11 | sMAPE for Test Set is: 33.36% | rMAE for Test Set is: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:03:06,734]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:13,742]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:33,713]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:38,296]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:44,476]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:47,289]\u001b[0m Trial 1233 finished with value: 6.322152081336427 and parameters: {'n_hidden': 3, 'learning_rate': 0.001017393346762806, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05450712997262325, 'dropout_rate_Layer_2': 0.05488992642702176, 'dropout_rate_Layer_3': 0.11853250506008535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00046144483461502513, 'l1_Layer_2': 0.0006720593497231838, 'l1_Layer_3': 0.002107074829388389, 'n_units_Layer_1': 60, 'n_units_Layer_2': 140, 'n_units_Layer_3': 60}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 28.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.11 | sMAPE for Test Set is: 23.35% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:03:52,451]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:52,756]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:03:59,193]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:02,377]\u001b[0m Trial 1235 finished with value: 6.194497240752452 and parameters: {'n_hidden': 4, 'learning_rate': 0.000786467599744574, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17195372964315125, 'dropout_rate_Layer_2': 0.2801721637474333, 'dropout_rate_Layer_3': 0.1523140005192331, 'dropout_rate_Layer_4': 0.190603713038939, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0018703807783164886, 'l1_Layer_2': 0.007822320264177835, 'l1_Layer_3': 5.915797437063109e-05, 'l1_Layer_4': 0.00018003597834021298, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 150, 'n_units_Layer_4': 150}. Best is trial 1186 with value: 6.10799463450369.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.19 | sMAPE for Validation Set is: 27.63% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 32.05 | sMAPE for Test Set is: 31.70% | rMAE for Test Set is: 1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:04:07,450]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:13,212]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:31,108]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:32,046]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:37,049]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:38,257]\u001b[0m Trial 1244 finished with value: 6.070523495104513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013050810969734636, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16325653991922126, 'dropout_rate_Layer_2': 0.19591096306496847, 'dropout_rate_Layer_3': 0.24096386646036852, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0383929153207412e-05, 'l1_Layer_2': 1.3890823332154736e-05, 'l1_Layer_3': 0.0013467981407759987, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 290}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.07 | sMAPE for Validation Set is: 27.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 20.36 | sMAPE for Test Set is: 24.06% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:04:40,425]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:45,071]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:50,707]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:04:56,250]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:00,258]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:06,196]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:19,458]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:23,233]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:35,378]\u001b[0m Trial 1246 finished with value: 6.241174553510774 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006455241841676053, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18975785547499674, 'dropout_rate_Layer_2': 0.2820309346999422, 'dropout_rate_Layer_3': 0.1427625131226251, 'dropout_rate_Layer_4': 0.17101944676596081, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011654964766130297, 'l1_Layer_2': 0.02076230227685718, 'l1_Layer_3': 0.0001464999267925939, 'l1_Layer_4': 0.00012958069775676344, 'n_units_Layer_1': 100, 'n_units_Layer_2': 205, 'n_units_Layer_3': 155, 'n_units_Layer_4': 235}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 27.68% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 27.44 | sMAPE for Test Set is: 27.64% | rMAE for Test Set is: 0.87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:05:40,028]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:40,641]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:46,768]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:47,686]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:05:50,782]\u001b[0m Trial 1256 finished with value: 6.451072983316585 and parameters: {'n_hidden': 3, 'learning_rate': 0.001087702523914548, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3642598159695905, 'dropout_rate_Layer_2': 0.1222586025043027, 'dropout_rate_Layer_3': 0.12397894599713133, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005859528582762142, 'l1_Layer_2': 0.0005371742904721541, 'l1_Layer_3': 0.0011254450689125214, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 50}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.45 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 21.12 | sMAPE for Test Set is: 24.75% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:06:02,842]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:04,059]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:09,303]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:14,494]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:18,278]\u001b[0m Trial 1259 finished with value: 6.236564568565361 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010824019730774495, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.39002744896658353, 'dropout_rate_Layer_2': 0.03196118716578644, 'dropout_rate_Layer_3': 0.12263501160114221, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008117405821955624, 'l1_Layer_2': 0.0007451424371527259, 'l1_Layer_3': 0.0011691123174523538, 'n_units_Layer_1': 170, 'n_units_Layer_2': 115, 'n_units_Layer_3': 110}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.24 | sMAPE for Validation Set is: 28.87% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.07 | sMAPE for Test Set is: 23.69% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:06:18,477]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:29,341]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:31,910]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:35,254]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:38,399]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:42,506]\u001b[0m Trial 1277 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:47,368]\u001b[0m Trial 1267 finished with value: 6.224585909002921 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017380514972490638, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15974618524922377, 'dropout_rate_Layer_2': 0.1991185288125396, 'dropout_rate_Layer_3': 0.21438816310668835, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8053023061035433e-05, 'l1_Layer_2': 2.2062381317428892e-05, 'l1_Layer_3': 0.0013020791170154792, 'n_units_Layer_1': 140, 'n_units_Layer_2': 190, 'n_units_Layer_3': 285}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.22 | sMAPE for Validation Set is: 27.96% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 23.15% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:06:52,035]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:52,492]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:58,098]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:06:59,319]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:05,712]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:05,810]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:07,110]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:08,335]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:16,526]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:18,795]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:22,701]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:27,674]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:30,076]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:33,167]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:35,008]\u001b[0m Trial 1292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:40,558]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:41,440]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:44,432]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:47,251]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:53,089]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:53,460]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:58,988]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:07:59,749]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:00,055]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:08,639]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:09,684]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:09,714]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:18,425]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:18,799]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:25,702]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:29,272]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:29,983]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:36,100]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:37,782]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:39,636]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:44,828]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:08:49,446]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:09:02,190]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:09:07,449]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:09:11,248]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:09:17,450]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:09:21,182]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:09:47,064]\u001b[0m Trial 1321 finished with value: 6.76162706795343 and parameters: {'n_hidden': 3, 'learning_rate': 0.001580074137032094, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.38176526058289206, 'dropout_rate_Layer_2': 0.008552602305501242, 'dropout_rate_Layer_3': 0.1393376124171355, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0015733285177870688, 'l1_Layer_2': 0.001417259464502984, 'l1_Layer_3': 0.0006918476772035387, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 120}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.76 | sMAPE for Validation Set is: 29.39% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 20.54 | sMAPE for Test Set is: 24.35% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:09:51,918]\u001b[0m Trial 1312 finished with value: 6.4319304539008675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013827150286411104, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3781530018702368, 'dropout_rate_Layer_2': 0.02676765227498413, 'dropout_rate_Layer_3': 0.16634370860021697, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014064406721938463, 'l1_Layer_2': 0.0015413899468656653, 'l1_Layer_3': 0.00043932422079074007, 'n_units_Layer_1': 180, 'n_units_Layer_2': 110, 'n_units_Layer_3': 115}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 28.55% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 20.23 | sMAPE for Test Set is: 23.60% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:09:54,771]\u001b[0m Trial 1301 finished with value: 6.117667644793098 and parameters: {'n_hidden': 4, 'learning_rate': 0.000644028400195597, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20744822578298247, 'dropout_rate_Layer_2': 0.2597391531268804, 'dropout_rate_Layer_3': 0.13185994318190375, 'dropout_rate_Layer_4': 0.09382805835749713, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015958906112790877, 'l1_Layer_2': 0.00727743519088281, 'l1_Layer_3': 0.0001065073261584269, 'l1_Layer_4': 0.0001867743827832749, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 205, 'n_units_Layer_4': 95}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.12 | sMAPE for Validation Set is: 27.97% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 30.86 | sMAPE for Test Set is: 30.70% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:10:00,276]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:04,762]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:10,675]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:28,590]\u001b[0m Trial 1314 finished with value: 6.3119969558465385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013444601423136043, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.391558279221428, 'dropout_rate_Layer_2': 0.006096088137992554, 'dropout_rate_Layer_3': 0.14159389922594004, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037594205736038146, 'l1_Layer_2': 0.0015302611439899799, 'l1_Layer_3': 0.0020828665008759, 'n_units_Layer_1': 170, 'n_units_Layer_2': 165, 'n_units_Layer_3': 120}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.31 | sMAPE for Validation Set is: 28.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.76 | sMAPE for Test Set is: 23.26% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:10:32,458]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:37,356]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:40,839]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:41,617]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:47,207]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:48,140]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:10:59,399]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:03,268]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:09,822]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:15,389]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:15,980]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:22,723]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:23,357]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:30,734]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:33,104]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:37,277]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:40,641]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:45,691]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:11:55,797]\u001b[0m Trial 1322 finished with value: 6.100064926708227 and parameters: {'n_hidden': 4, 'learning_rate': 0.0009230290372831644, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07718933362276473, 'dropout_rate_Layer_2': 0.3276602425684627, 'dropout_rate_Layer_3': 0.21686516325714658, 'dropout_rate_Layer_4': 0.09279130215371986, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0011198148300893718, 'l1_Layer_2': 0.007443452851767872, 'l1_Layer_3': 4.887966241817203e-05, 'l1_Layer_4': 0.00013762600202746854, 'n_units_Layer_1': 125, 'n_units_Layer_2': 195, 'n_units_Layer_3': 235, 'n_units_Layer_4': 150}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.10 | sMAPE for Validation Set is: 27.44% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 31.02 | sMAPE for Test Set is: 30.33% | rMAE for Test Set is: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:11:59,565]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:05,902]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:10,867]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:15,012]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:15,354]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:22,585]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:22,827]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:23,667]\u001b[0m Trial 1333 finished with value: 6.334476300242358 and parameters: {'n_hidden': 4, 'learning_rate': 0.0006541179456488003, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1666179549524523, 'dropout_rate_Layer_2': 0.2570174231898026, 'dropout_rate_Layer_3': 0.14644318435745685, 'dropout_rate_Layer_4': 0.12091616111809961, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0027074382942595975, 'l1_Layer_2': 0.008935205793431914, 'l1_Layer_3': 0.002456025827768581, 'l1_Layer_4': 0.000300077232453538, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 210, 'n_units_Layer_4': 95}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.33 | sMAPE for Validation Set is: 28.44% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 35.70 | sMAPE for Test Set is: 34.44% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:12:31,284]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:34,300]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:34,381]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:39,069]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:40,837]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:45,136]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:45,677]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:46,404]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:55,018]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:12:55,154]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:01,944]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:02,597]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:08,712]\u001b[0m Trial 1345 finished with value: 6.272163084159739 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017964904480233168, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3476687483550913, 'dropout_rate_Layer_2': 0.014520068126214786, 'dropout_rate_Layer_3': 0.1082281093604416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00036235827059630775, 'l1_Layer_2': 0.0019230904673463293, 'l1_Layer_3': 0.001034435440588582, 'n_units_Layer_1': 125, 'n_units_Layer_2': 165, 'n_units_Layer_3': 110}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:08,878]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.27 | sMAPE for Validation Set is: 29.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 19.29 | sMAPE for Test Set is: 22.94% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:13:09,489]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:18,721]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:18,923]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:19,136]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:19,152]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:29,232]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:29,666]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:29,858]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:39,349]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:39,464]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:46,889]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:47,066]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:13:52,833]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:00,336]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:27,258]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:31,708]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:37,862]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:38,835]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:43,121]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:47,831]\u001b[0m Trial 1376 finished with value: 6.142478651123652 and parameters: {'n_hidden': 4, 'learning_rate': 0.0011613421924712955, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08594048263754202, 'dropout_rate_Layer_2': 0.3276414275739469, 'dropout_rate_Layer_3': 0.03884168109507988, 'dropout_rate_Layer_4': 0.0881944362918184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.003285323823677519, 'l1_Layer_2': 0.001933902824606631, 'l1_Layer_3': 0.0012858492014424776, 'l1_Layer_4': 0.0001770531546352245, 'n_units_Layer_1': 120, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210, 'n_units_Layer_4': 90}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.14 | sMAPE for Validation Set is: 27.91% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 37.05 | sMAPE for Test Set is: 36.32% | rMAE for Test Set is: 1.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:14:50,522]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:53,621]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:54,515]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:55,185]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:14:59,424]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:03,675]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:07,467]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:08,528]\u001b[0m Trial 1382 finished with value: 6.544310326055729 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007076590496669922, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07944104657617887, 'dropout_rate_Layer_2': 0.2684703928510131, 'dropout_rate_Layer_3': 0.2456171663559894, 'dropout_rate_Layer_4': 0.08934995063419775, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00079088688420522, 'l1_Layer_2': 0.008351713834599596, 'l1_Layer_3': 0.000230425105134064, 'l1_Layer_4': 0.00018250390204607012, 'n_units_Layer_1': 230, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210, 'n_units_Layer_4': 110}. Best is trial 1244 with value: 6.070523495104513.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.54 | sMAPE for Validation Set is: 28.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 19.55 | sMAPE for Test Set is: 22.92% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:15:10,925]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:18,462]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:19,866]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:21,031]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:21,423]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:22,310]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:30,737]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:33,390]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:35,373]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:37,647]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:38,919]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:44,415]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:49,742]\u001b[0m Trial 1407 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:50,391]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:52,340]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:56,037]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:58,447]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:15:58,613]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:03,078]\u001b[0m Trial 1412 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:12,429]\u001b[0m Trial 1415 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:12,706]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:20,855]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:21,091]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:28,487]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:32,271]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:34,281]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:40,379]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:41,441]\u001b[0m Trial 1416 finished with value: 6.037337891997022 and parameters: {'n_hidden': 3, 'learning_rate': 0.000697838768538468, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12593877106163887, 'dropout_rate_Layer_2': 0.21562448882146149, 'dropout_rate_Layer_3': 0.19454133398032988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3471320498430863e-05, 'l1_Layer_2': 2.6620663597780295e-05, 'l1_Layer_3': 0.00010304693120173728, 'n_units_Layer_1': 70, 'n_units_Layer_2': 175, 'n_units_Layer_3': 225}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 27.20% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 23.08% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:16:42,027]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:49,768]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:50,034]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:55,611]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:16:56,860]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:17:02,369]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:17:04,489]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:17:08,167]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:17:22,729]\u001b[0m Trial 1432 finished with value: 6.293001350918257 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014435442155994707, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10191635861673852, 'dropout_rate_Layer_2': 0.21258741586807836, 'dropout_rate_Layer_3': 0.1905768183805106, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3039986842357871e-05, 'l1_Layer_2': 2.726290452267634e-05, 'l1_Layer_3': 0.00010514638448026146, 'n_units_Layer_1': 260, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.29 | sMAPE for Validation Set is: 28.10% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 20.31 | sMAPE for Test Set is: 23.93% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:17:25,881]\u001b[0m Trial 1433 finished with value: 6.20381635420097 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008298092277107552, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10086524953741569, 'dropout_rate_Layer_2': 0.21185237260753012, 'dropout_rate_Layer_3': 0.19320700362584206, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0196794660138386e-05, 'l1_Layer_2': 1.601109428629329e-05, 'l1_Layer_3': 8.278258789632068e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.20 | sMAPE for Validation Set is: 27.95% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 20.19 | sMAPE for Test Set is: 23.85% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:17:35,709]\u001b[0m Trial 1423 finished with value: 6.0402735256115205 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007084495091134604, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1288973506412136, 'dropout_rate_Layer_2': 0.21390305838043983, 'dropout_rate_Layer_3': 0.186822708538757, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3593048430181759e-05, 'l1_Layer_2': 2.7069063081000423e-05, 'l1_Layer_3': 0.0008215611729324122, 'n_units_Layer_1': 55, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.04 | sMAPE for Validation Set is: 27.15% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 23.35% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:17:40,360]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:11,276]\u001b[0m Trial 1424 finished with value: 6.296574415664016 and parameters: {'n_hidden': 4, 'learning_rate': 0.0007427306900709682, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15812289717631392, 'dropout_rate_Layer_2': 0.3410385681551099, 'dropout_rate_Layer_3': 0.15387100934182726, 'dropout_rate_Layer_4': 0.18148983048200817, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.006090035988771554, 'l1_Layer_2': 0.015813871742906632, 'l1_Layer_3': 7.807067989210086e-05, 'l1_Layer_4': 0.00012068502962742736, 'n_units_Layer_1': 240, 'n_units_Layer_2': 240, 'n_units_Layer_3': 205, 'n_units_Layer_4': 120}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.30 | sMAPE for Validation Set is: 28.38% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.30 | sMAPE for Test Set is: 25.23% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:18:15,701]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:19,654]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:23,209]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:27,881]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:32,121]\u001b[0m Trial 1434 finished with value: 6.317538804930732 and parameters: {'n_hidden': 4, 'learning_rate': 0.0008673052428784567, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16695313269498852, 'dropout_rate_Layer_2': 0.2804229087223201, 'dropout_rate_Layer_3': 0.2219965460786321, 'dropout_rate_Layer_4': 0.20302617441116408, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0029704117497673724, 'l1_Layer_2': 0.01912682470796106, 'l1_Layer_3': 9.070351238742626e-05, 'l1_Layer_4': 0.0002452661853991051, 'n_units_Layer_1': 245, 'n_units_Layer_2': 125, 'n_units_Layer_3': 240, 'n_units_Layer_4': 110}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.32 | sMAPE for Validation Set is: 28.32% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 31.32 | sMAPE for Test Set is: 30.81% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:18:33,078]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:38,882]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:39,566]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:45,364]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:46,353]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:50,494]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:54,805]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:18:58,747]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:02,693]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:09,023]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:13,346]\u001b[0m Trial 1442 finished with value: 6.372546658864316 and parameters: {'n_hidden': 4, 'learning_rate': 0.0010692279055142715, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1691051886775235, 'dropout_rate_Layer_2': 0.3368721949049515, 'dropout_rate_Layer_3': 0.018713017475140287, 'dropout_rate_Layer_4': 0.20400765234628448, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.005888269642766598, 'l1_Layer_2': 0.003916500634186782, 'l1_Layer_3': 9.492618284118123e-05, 'l1_Layer_4': 0.000260083848151456, 'n_units_Layer_1': 140, 'n_units_Layer_2': 235, 'n_units_Layer_3': 190, 'n_units_Layer_4': 115}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.37 | sMAPE for Validation Set is: 28.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 28.22 | sMAPE for Test Set is: 28.26% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:19:13,637]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:20,581]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:20,901]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:22,720]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:41,671]\u001b[0m Trial 1444 finished with value: 6.434860199261784 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011181987471952093, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.36276606391464106, 'dropout_rate_Layer_2': 0.002155347992250131, 'dropout_rate_Layer_3': 0.12237335077285745, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028060701211533455, 'l1_Layer_2': 0.0018279554757219712, 'l1_Layer_3': 0.002068283633836958, 'n_units_Layer_1': 130, 'n_units_Layer_2': 165, 'n_units_Layer_3': 125}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.43 | sMAPE for Validation Set is: 28.60% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 25.07% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:19:45,736]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:49,081]\u001b[0m Trial 1457 finished with value: 6.552443717980382 and parameters: {'n_hidden': 4, 'learning_rate': 0.0012803384249816558, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16904926418303431, 'dropout_rate_Layer_2': 0.3429450271258378, 'dropout_rate_Layer_3': 0.00634224628362573, 'dropout_rate_Layer_4': 0.27238088707433833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.004883157785516886, 'l1_Layer_2': 0.014423264846337852, 'l1_Layer_3': 7.781299541912987e-05, 'l1_Layer_4': 0.000261678201771168, 'n_units_Layer_1': 130, 'n_units_Layer_2': 235, 'n_units_Layer_3': 185, 'n_units_Layer_4': 120}. Best is trial 1416 with value: 6.037337891997022.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 6.55 | sMAPE for Validation Set is: 29.15% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 30.75 | sMAPE for Test Set is: 30.38% | rMAE for Test Set is: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 05:19:49,722]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:52,624]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:58,448]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:19:58,681]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:05,142]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:07,400]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:08,283]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:10,374]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:15,077]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:15,673]\u001b[0m Trial 1468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:18,021]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:26,381]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:36,770]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:41,062]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:45,661]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:47,028]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:52,811]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:55,184]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:20:58,180]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:02,498]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:03,878]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:04,123]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:05,641]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:07,714]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:13,398]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:19,160]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:20,943]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:22,375]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:22,633]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:32,949]\u001b[0m Trial 1487 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:35,128]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:38,709]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:40,709]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:41,276]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:42,785]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:45,832]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:53,957]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:54,674]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:56,421]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:21:58,734]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:22:00,834]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 05:22:01,410]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-01-01, MAE is:5.00 & sMAPE is:10.54% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :5.00 & 10.54% & 0.37\n",
      "for 2021-01-02, MAE is:3.31 & sMAPE is:6.45% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :4.16 & 8.49% & 0.24\n",
      "for 2021-01-03, MAE is:8.34 & sMAPE is:19.87% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :5.55 & 12.29% & 0.21\n",
      "for 2021-01-04, MAE is:10.88 & sMAPE is:23.29% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :6.88 & 15.04% & 0.46\n",
      "for 2021-01-05, MAE is:8.55 & sMAPE is:16.23% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :7.22 & 15.28% & 0.55\n",
      "for 2021-01-06, MAE is:4.97 & sMAPE is:9.96% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :6.84 & 14.39% & 0.60\n",
      "for 2021-01-07, MAE is:18.98 & sMAPE is:28.91% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 16.46% & 0.63\n",
      "for 2021-01-08, MAE is:22.79 & sMAPE is:29.38% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.35 & 18.08% & 0.65\n",
      "for 2021-01-09, MAE is:1.77 & sMAPE is:2.97% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :9.40 & 16.40% & 0.60\n",
      "for 2021-01-10, MAE is:3.44 & sMAPE is:6.89% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 15.45% & 0.56\n",
      "for 2021-01-11, MAE is:8.58 & sMAPE is:18.48% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :8.78 & 15.72% & 0.57\n",
      "for 2021-01-12, MAE is:11.69 & sMAPE is:29.42% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 16.87% & 0.63\n",
      "for 2021-01-13, MAE is:3.92 & sMAPE is:9.76% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :8.63 & 16.32% & 0.61\n",
      "for 2021-01-14, MAE is:23.82 & sMAPE is:36.96% & rMAE is:4.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.72 & 17.79% & 0.91\n",
      "for 2021-01-15, MAE is:13.42 & sMAPE is:18.30% & rMAE is:1.50 ||| daily mean of MAE & sMAPE & rMAE till now are :9.96 & 17.83% & 0.95\n",
      "for 2021-01-16, MAE is:2.88 & sMAPE is:5.27% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :9.52 & 17.04% & 0.93\n",
      "for 2021-01-17, MAE is:4.13 & sMAPE is:7.60% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :9.20 & 16.49% & 0.93\n",
      "for 2021-01-18, MAE is:7.73 & sMAPE is:13.32% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 16.31% & 0.94\n",
      "for 2021-01-19, MAE is:4.40 & sMAPE is:10.65% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :8.87 & 16.01% & 0.92\n",
      "for 2021-01-20, MAE is:6.79 & sMAPE is:17.05% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 16.06% & 0.92\n",
      "for 2021-01-21, MAE is:9.97 & sMAPE is:40.62% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 17.23% & 0.89\n",
      "for 2021-01-22, MAE is:8.78 & sMAPE is:25.67% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :8.83 & 17.62% & 0.87\n",
      "for 2021-01-23, MAE is:4.57 & sMAPE is:8.89% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 17.24% & 0.87\n",
      "for 2021-01-24, MAE is:4.52 & sMAPE is:9.10% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :8.47 & 16.90% & 0.87\n",
      "for 2021-01-25, MAE is:6.21 & sMAPE is:10.10% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :8.38 & 16.63% & 0.87\n",
      "for 2021-01-26, MAE is:8.00 & sMAPE is:13.93% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.36 & 16.52% & 0.86\n",
      "for 2021-01-27, MAE is:3.67 & sMAPE is:6.28% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :8.19 & 16.14% & 0.83\n",
      "for 2021-01-28, MAE is:3.36 & sMAPE is:6.35% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 15.79% & 0.80\n",
      "for 2021-01-29, MAE is:1.89 & sMAPE is:3.77% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :7.81 & 15.38% & 0.78\n",
      "for 2021-01-30, MAE is:5.17 & sMAPE is:10.50% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.72 & 15.22% & 0.81\n",
      "for 2021-01-31, MAE is:6.01 & sMAPE is:12.70% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 15.14% & 0.90\n",
      "for 2021-02-01, MAE is:6.68 & sMAPE is:11.69% & rMAE is:1.34 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 15.03% & 0.92\n",
      "for 2021-02-02, MAE is:5.04 & sMAPE is:9.02% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.55 & 14.85% & 0.91\n",
      "for 2021-02-03, MAE is:4.33 & sMAPE is:9.91% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 14.70% & 0.89\n",
      "for 2021-02-04, MAE is:10.32 & sMAPE is:21.08% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :7.54 & 14.88% & 0.91\n",
      "for 2021-02-05, MAE is:3.56 & sMAPE is:7.09% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :7.43 & 14.67% & 0.92\n",
      "for 2021-02-06, MAE is:5.82 & sMAPE is:16.51% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.39 & 14.72% & 0.91\n",
      "for 2021-02-07, MAE is:6.98 & sMAPE is:86.80% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.38 & 16.61% & 0.89\n",
      "for 2021-02-08, MAE is:9.73 & sMAPE is:36.60% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 17.13% & 0.88\n",
      "for 2021-02-09, MAE is:16.65 & sMAPE is:28.88% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 17.42% & 0.90\n",
      "for 2021-02-10, MAE is:18.34 & sMAPE is:26.86% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :7.93 & 17.65% & 0.90\n",
      "for 2021-02-11, MAE is:20.13 & sMAPE is:24.80% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :8.22 & 17.82% & 0.90\n",
      "for 2021-02-12, MAE is:5.24 & sMAPE is:8.05% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 17.59% & 0.89\n",
      "for 2021-02-13, MAE is:3.20 & sMAPE is:5.70% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 17.32% & 0.87\n",
      "for 2021-02-14, MAE is:3.63 & sMAPE is:7.51% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :7.94 & 17.10% & 0.85\n",
      "for 2021-02-15, MAE is:3.39 & sMAPE is:6.91% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.84 & 16.88% & 0.84\n",
      "for 2021-02-16, MAE is:5.11 & sMAPE is:9.90% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :7.78 & 16.73% & 0.83\n",
      "for 2021-02-17, MAE is:3.77 & sMAPE is:7.09% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 16.53% & 0.82\n",
      "for 2021-02-18, MAE is:8.06 & sMAPE is:15.99% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :7.70 & 16.52% & 0.81\n",
      "for 2021-02-19, MAE is:5.75 & sMAPE is:13.03% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.67 & 16.45% & 0.80\n",
      "for 2021-02-20, MAE is:7.59 & sMAPE is:20.81% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 16.54% & 0.79\n",
      "for 2021-02-21, MAE is:8.38 & sMAPE is:26.92% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 16.74% & 0.79\n",
      "for 2021-02-22, MAE is:5.25 & sMAPE is:10.04% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 16.61% & 0.79\n",
      "for 2021-02-23, MAE is:5.66 & sMAPE is:12.03% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 16.53% & 0.79\n",
      "for 2021-02-24, MAE is:7.50 & sMAPE is:21.69% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :7.59 & 16.62% & 0.79\n",
      "for 2021-02-25, MAE is:5.57 & sMAPE is:11.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :7.56 & 16.53% & 0.79\n",
      "for 2021-02-26, MAE is:4.99 & sMAPE is:10.55% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :7.51 & 16.43% & 0.80\n",
      "for 2021-02-27, MAE is:6.25 & sMAPE is:14.23% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :7.49 & 16.39% & 0.79\n",
      "for 2021-02-28, MAE is:4.75 & sMAPE is:11.44% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :7.44 & 16.31% & 0.79\n",
      "for 2021-03-01, MAE is:5.74 & sMAPE is:11.31% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 16.22% & 0.79\n",
      "for 2021-03-02, MAE is:9.70 & sMAPE is:18.64% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 16.26% & 0.80\n",
      "for 2021-03-03, MAE is:5.69 & sMAPE is:10.71% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 16.17% & 0.80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-03-04, MAE is:6.56 & sMAPE is:12.87% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :7.41 & 16.12% & 0.80\n",
      "for 2021-03-05, MAE is:6.75 & sMAPE is:12.87% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :7.40 & 16.07% & 0.80\n",
      "for 2021-03-06, MAE is:3.36 & sMAPE is:7.40% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :7.34 & 15.94% & 0.81\n",
      "for 2021-03-07, MAE is:7.02 & sMAPE is:16.33% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :7.33 & 15.94% & 0.82\n",
      "for 2021-03-08, MAE is:13.28 & sMAPE is:21.73% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.42 & 16.03% & 0.83\n",
      "for 2021-03-09, MAE is:8.98 & sMAPE is:14.28% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :7.45 & 16.00% & 0.83\n",
      "for 2021-03-10, MAE is:8.72 & sMAPE is:17.61% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.46 & 16.03% & 0.84\n",
      "for 2021-03-11, MAE is:8.12 & sMAPE is:48.53% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :7.47 & 16.49% & 0.83\n",
      "for 2021-03-12, MAE is:11.69 & sMAPE is:66.77% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :7.53 & 17.20% & 0.83\n",
      "for 2021-03-13, MAE is:15.79 & sMAPE is:97.39% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 18.31% & 0.82\n",
      "for 2021-03-14, MAE is:10.25 & sMAPE is:111.28% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.68 & 19.59% & 0.82\n",
      "for 2021-03-15, MAE is:4.38 & sMAPE is:9.14% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 19.45% & 0.81\n",
      "for 2021-03-16, MAE is:7.58 & sMAPE is:14.32% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.64 & 19.38% & 0.82\n",
      "for 2021-03-17, MAE is:6.93 & sMAPE is:12.06% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 19.28% & 0.81\n",
      "for 2021-03-18, MAE is:5.68 & sMAPE is:8.36% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :7.60 & 19.14% & 0.81\n",
      "for 2021-03-19, MAE is:7.90 & sMAPE is:14.08% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 19.07% & 0.80\n",
      "for 2021-03-20, MAE is:4.90 & sMAPE is:9.52% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :7.57 & 18.95% & 0.79\n",
      "for 2021-03-21, MAE is:10.66 & sMAPE is:30.55% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 19.10% & 0.79\n",
      "for 2021-03-22, MAE is:7.68 & sMAPE is:12.68% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :7.61 & 19.02% & 0.79\n",
      "for 2021-03-23, MAE is:9.14 & sMAPE is:15.70% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :7.63 & 18.98% & 0.79\n",
      "for 2021-03-24, MAE is:9.00 & sMAPE is:15.99% & rMAE is:1.91 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 18.94% & 0.81\n",
      "for 2021-03-25, MAE is:7.84 & sMAPE is:13.31% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :7.65 & 18.88% & 0.81\n",
      "for 2021-03-26, MAE is:8.52 & sMAPE is:16.92% & rMAE is:1.45 ||| daily mean of MAE & sMAPE & rMAE till now are :7.66 & 18.85% & 0.82\n",
      "for 2021-03-27, MAE is:21.83 & sMAPE is:66.53% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :7.82 & 19.41% & 0.82\n",
      "for 2021-03-28, MAE is:22.08 & sMAPE is:67.94% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :7.99 & 19.96% & 0.82\n",
      "for 2021-03-29, MAE is:10.77 & sMAPE is:29.50% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :8.02 & 20.07% & 0.81\n",
      "for 2021-03-30, MAE is:12.14 & sMAPE is:23.29% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 20.11% & 0.82\n",
      "for 2021-03-31, MAE is:8.03 & sMAPE is:13.45% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 20.04% & 0.83\n",
      "for 2021-04-01, MAE is:5.28 & sMAPE is:10.20% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :8.04 & 19.93% & 0.83\n",
      "for 2021-04-02, MAE is:15.01 & sMAPE is:48.59% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :8.11 & 20.24% & 0.83\n",
      "for 2021-04-03, MAE is:3.91 & sMAPE is:12.56% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.07 & 20.16% & 0.82\n",
      "for 2021-04-04, MAE is:15.52 & sMAPE is:61.92% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :8.15 & 20.60% & 0.83\n",
      "for 2021-04-05, MAE is:36.31 & sMAPE is:168.65% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :8.44 & 22.16% & 0.82\n",
      "for 2021-04-06, MAE is:10.32 & sMAPE is:32.55% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 22.27% & 0.82\n",
      "for 2021-04-07, MAE is:8.01 & sMAPE is:15.42% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :8.46 & 22.20% & 0.82\n",
      "for 2021-04-08, MAE is:21.81 & sMAPE is:45.80% & rMAE is:2.66 ||| daily mean of MAE & sMAPE & rMAE till now are :8.59 & 22.44% & 0.84\n",
      "for 2021-04-09, MAE is:11.10 & sMAPE is:20.25% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.62 & 22.42% & 0.84\n",
      "for 2021-04-10, MAE is:4.54 & sMAPE is:7.90% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 22.27% & 0.83\n",
      "for 2021-04-11, MAE is:8.41 & sMAPE is:18.30% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :8.58 & 22.23% & 0.83\n",
      "for 2021-04-12, MAE is:14.90 & sMAPE is:24.93% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :8.64 & 22.26% & 0.82\n",
      "for 2021-04-13, MAE is:10.74 & sMAPE is:18.53% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :8.66 & 22.22% & 0.82\n",
      "for 2021-04-14, MAE is:12.74 & sMAPE is:16.99% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :8.70 & 22.17% & 0.81\n",
      "for 2021-04-15, MAE is:9.98 & sMAPE is:14.31% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.71 & 22.10% & 0.82\n",
      "for 2021-04-16, MAE is:12.62 & sMAPE is:21.49% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 22.09% & 0.82\n",
      "for 2021-04-17, MAE is:9.05 & sMAPE is:15.60% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :8.75 & 22.03% & 0.83\n",
      "for 2021-04-18, MAE is:10.59 & sMAPE is:18.16% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :8.77 & 21.99% & 0.83\n",
      "for 2021-04-19, MAE is:12.37 & sMAPE is:15.94% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :8.80 & 21.94% & 0.83\n",
      "for 2021-04-20, MAE is:15.47 & sMAPE is:21.19% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :8.86 & 21.93% & 0.83\n",
      "for 2021-04-21, MAE is:15.06 & sMAPE is:24.05% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :8.92 & 21.95% & 0.83\n",
      "for 2021-04-22, MAE is:18.35 & sMAPE is:50.04% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :9.00 & 22.20% & 0.83\n",
      "for 2021-04-23, MAE is:10.30 & sMAPE is:17.33% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 22.16% & 0.83\n",
      "for 2021-04-24, MAE is:8.42 & sMAPE is:18.63% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.01 & 22.13% & 0.83\n",
      "for 2021-04-25, MAE is:14.25 & sMAPE is:53.90% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.05 & 22.40% & 0.83\n",
      "for 2021-04-26, MAE is:7.34 & sMAPE is:12.16% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :9.04 & 22.32% & 0.83\n",
      "for 2021-04-27, MAE is:7.93 & sMAPE is:13.10% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :9.03 & 22.24% & 0.83\n",
      "for 2021-04-28, MAE is:13.91 & sMAPE is:25.03% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 22.26% & 0.83\n",
      "for 2021-04-29, MAE is:9.64 & sMAPE is:16.94% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :9.07 & 22.22% & 0.83\n",
      "for 2021-04-30, MAE is:16.52 & sMAPE is:27.32% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :9.14 & 22.26% & 0.84\n",
      "for 2021-05-01, MAE is:6.13 & sMAPE is:10.44% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 22.16% & 0.84\n",
      "for 2021-05-02, MAE is:10.27 & sMAPE is:35.48% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.12 & 22.27% & 0.84\n",
      "for 2021-05-03, MAE is:8.15 & sMAPE is:13.01% & rMAE is:2.39 ||| daily mean of MAE & sMAPE & rMAE till now are :9.11 & 22.19% & 0.85\n",
      "for 2021-05-04, MAE is:21.01 & sMAPE is:69.95% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :9.21 & 22.58% & 0.85\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-05-05, MAE is:19.47 & sMAPE is:58.08% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.29 & 22.86% & 0.85\n",
      "for 2021-05-06, MAE is:12.03 & sMAPE is:19.50% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 22.84% & 0.85\n",
      "for 2021-05-07, MAE is:8.46 & sMAPE is:12.17% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :9.31 & 22.75% & 0.86\n",
      "for 2021-05-08, MAE is:11.17 & sMAPE is:24.90% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :9.32 & 22.77% & 0.86\n",
      "for 2021-05-09, MAE is:40.75 & sMAPE is:143.74% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 23.71% & 0.86\n",
      "for 2021-05-10, MAE is:8.99 & sMAPE is:15.54% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :9.56 & 23.64% & 0.86\n",
      "for 2021-05-11, MAE is:10.83 & sMAPE is:16.01% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :9.57 & 23.59% & 0.86\n",
      "for 2021-05-12, MAE is:7.03 & sMAPE is:10.70% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 23.49% & 0.85\n",
      "for 2021-05-13, MAE is:6.86 & sMAPE is:11.05% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 23.39% & 0.85\n",
      "for 2021-05-14, MAE is:6.65 & sMAPE is:9.55% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :9.51 & 23.29% & 0.85\n",
      "for 2021-05-15, MAE is:6.90 & sMAPE is:11.34% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.49 & 23.20% & 0.85\n",
      "for 2021-05-16, MAE is:22.69 & sMAPE is:60.52% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :9.59 & 23.48% & 0.85\n",
      "for 2021-05-17, MAE is:9.31 & sMAPE is:12.71% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :9.58 & 23.40% & 0.85\n",
      "for 2021-05-18, MAE is:4.40 & sMAPE is:5.99% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 23.27% & 0.85\n",
      "for 2021-05-19, MAE is:9.90 & sMAPE is:13.27% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :9.55 & 23.20% & 0.85\n",
      "for 2021-05-20, MAE is:7.22 & sMAPE is:10.25% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :9.53 & 23.11% & 0.85\n",
      "for 2021-05-21, MAE is:30.98 & sMAPE is:84.13% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :9.68 & 23.54% & 0.85\n",
      "for 2021-05-22, MAE is:43.55 & sMAPE is:151.34% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :9.92 & 24.44% & 0.85\n",
      "for 2021-05-23, MAE is:20.82 & sMAPE is:98.47% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 24.96% & 0.85\n",
      "for 2021-05-24, MAE is:25.99 & sMAPE is:78.34% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 25.33% & 0.85\n",
      "for 2021-05-25, MAE is:8.95 & sMAPE is:15.23% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 25.26% & 0.85\n",
      "for 2021-05-26, MAE is:6.91 & sMAPE is:11.09% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 25.16% & 0.85\n",
      "for 2021-05-27, MAE is:16.56 & sMAPE is:25.72% & rMAE is:2.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.12 & 25.17% & 0.86\n",
      "for 2021-05-28, MAE is:5.82 & sMAPE is:8.14% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 25.05% & 0.85\n",
      "for 2021-05-29, MAE is:10.12 & sMAPE is:22.24% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 25.03% & 0.85\n",
      "for 2021-05-30, MAE is:18.31 & sMAPE is:61.63% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 25.28% & 0.85\n",
      "for 2021-05-31, MAE is:11.77 & sMAPE is:18.53% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 25.23% & 0.85\n",
      "for 2021-06-01, MAE is:6.39 & sMAPE is:9.32% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 25.13% & 0.85\n",
      "for 2021-06-02, MAE is:9.96 & sMAPE is:15.92% & rMAE is:2.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.14 & 25.07% & 0.85\n",
      "for 2021-06-03, MAE is:9.74 & sMAPE is:15.91% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 25.01% & 0.85\n",
      "for 2021-06-04, MAE is:10.28 & sMAPE is:15.55% & rMAE is:2.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 24.95% & 0.87\n",
      "for 2021-06-05, MAE is:4.76 & sMAPE is:7.71% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 24.84% & 0.86\n",
      "for 2021-06-06, MAE is:6.90 & sMAPE is:11.89% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 24.75% & 0.86\n",
      "for 2021-06-07, MAE is:10.69 & sMAPE is:14.71% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 24.69% & 0.86\n",
      "for 2021-06-08, MAE is:7.91 & sMAPE is:10.54% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 24.60% & 0.86\n",
      "for 2021-06-09, MAE is:7.43 & sMAPE is:9.91% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 24.51% & 0.86\n",
      "for 2021-06-10, MAE is:8.14 & sMAPE is:10.66% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 24.42% & 0.86\n",
      "for 2021-06-11, MAE is:6.45 & sMAPE is:8.34% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 24.32% & 0.86\n",
      "for 2021-06-12, MAE is:27.84 & sMAPE is:67.24% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 24.59% & 0.86\n",
      "for 2021-06-13, MAE is:31.70 & sMAPE is:131.06% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 25.24% & 0.86\n",
      "for 2021-06-14, MAE is:11.52 & sMAPE is:16.16% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 25.18% & 0.86\n",
      "for 2021-06-15, MAE is:12.62 & sMAPE is:16.57% & rMAE is:2.22 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 25.13% & 0.87\n",
      "for 2021-06-16, MAE is:14.37 & sMAPE is:17.96% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.31 & 25.09% & 0.88\n",
      "for 2021-06-17, MAE is:12.23 & sMAPE is:15.99% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :10.32 & 25.03% & 0.88\n",
      "for 2021-06-18, MAE is:6.09 & sMAPE is:7.53% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 24.93% & 0.89\n",
      "for 2021-06-19, MAE is:9.42 & sMAPE is:13.67% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 24.86% & 0.88\n",
      "for 2021-06-20, MAE is:11.69 & sMAPE is:21.89% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.29 & 24.85% & 0.88\n",
      "for 2021-06-21, MAE is:4.38 & sMAPE is:5.80% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 24.73% & 0.88\n",
      "for 2021-06-22, MAE is:8.69 & sMAPE is:10.68% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 24.65% & 0.88\n",
      "for 2021-06-23, MAE is:14.62 & sMAPE is:16.05% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 24.60% & 0.89\n",
      "for 2021-06-24, MAE is:14.26 & sMAPE is:15.92% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :10.30 & 24.55% & 0.89\n",
      "for 2021-06-25, MAE is:7.27 & sMAPE is:8.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 24.46% & 0.89\n",
      "for 2021-06-26, MAE is:6.50 & sMAPE is:8.26% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.26 & 24.37% & 0.89\n",
      "for 2021-06-27, MAE is:13.45 & sMAPE is:23.01% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.28 & 24.36% & 0.89\n",
      "for 2021-06-28, MAE is:8.12 & sMAPE is:9.18% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 24.28% & 0.89\n",
      "for 2021-06-29, MAE is:7.54 & sMAPE is:8.57% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 24.19% & 0.89\n",
      "for 2021-06-30, MAE is:7.42 & sMAPE is:8.45% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 24.10% & 0.89\n",
      "for 2021-07-01, MAE is:7.03 & sMAPE is:8.21% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :10.22 & 24.02% & 0.89\n",
      "for 2021-07-02, MAE is:7.57 & sMAPE is:8.08% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.20 & 23.93% & 0.89\n",
      "for 2021-07-03, MAE is:8.42 & sMAPE is:9.95% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 23.85% & 0.90\n",
      "for 2021-07-04, MAE is:5.95 & sMAPE is:7.10% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 23.76% & 0.89\n",
      "for 2021-07-05, MAE is:6.12 & sMAPE is:6.46% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 23.67% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-07-06, MAE is:10.65 & sMAPE is:13.07% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 23.61% & 0.89\n",
      "for 2021-07-07, MAE is:11.70 & sMAPE is:12.18% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :10.16 & 23.55% & 0.90\n",
      "for 2021-07-08, MAE is:11.91 & sMAPE is:10.82% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.17 & 23.48% & 0.89\n",
      "for 2021-07-09, MAE is:5.75 & sMAPE is:6.08% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :10.15 & 23.39% & 0.89\n",
      "for 2021-07-10, MAE is:6.35 & sMAPE is:7.74% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :10.13 & 23.31% & 0.90\n",
      "for 2021-07-11, MAE is:6.26 & sMAPE is:7.78% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :10.11 & 23.23% & 0.90\n",
      "for 2021-07-12, MAE is:6.32 & sMAPE is:6.61% & rMAE is:2.01 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 23.14% & 0.91\n",
      "for 2021-07-13, MAE is:6.25 & sMAPE is:6.60% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 23.06% & 0.90\n",
      "for 2021-07-14, MAE is:6.51 & sMAPE is:7.38% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.05 & 22.98% & 0.90\n",
      "for 2021-07-15, MAE is:9.21 & sMAPE is:11.22% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 22.92% & 0.90\n",
      "for 2021-07-16, MAE is:4.81 & sMAPE is:5.70% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 22.83% & 0.90\n",
      "for 2021-07-17, MAE is:13.59 & sMAPE is:23.45% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 22.83% & 0.90\n",
      "for 2021-07-18, MAE is:21.46 & sMAPE is:56.28% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :10.09 & 23.00% & 0.90\n",
      "for 2021-07-19, MAE is:8.25 & sMAPE is:9.46% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 22.93% & 0.90\n",
      "for 2021-07-20, MAE is:6.85 & sMAPE is:7.48% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :10.07 & 22.86% & 0.90\n",
      "for 2021-07-21, MAE is:7.78 & sMAPE is:8.76% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.06 & 22.79% & 0.90\n",
      "for 2021-07-22, MAE is:6.58 & sMAPE is:7.24% & rMAE is:1.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.04 & 22.71% & 0.90\n",
      "for 2021-07-23, MAE is:8.60 & sMAPE is:10.21% & rMAE is:2.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.03 & 22.65% & 0.91\n",
      "for 2021-07-24, MAE is:5.33 & sMAPE is:6.90% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :10.01 & 22.57% & 0.90\n",
      "for 2021-07-25, MAE is:12.85 & sMAPE is:20.49% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :10.02 & 22.56% & 0.90\n",
      "for 2021-07-26, MAE is:5.41 & sMAPE is:6.18% & rMAE is:1.35 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 22.48% & 0.90\n",
      "for 2021-07-27, MAE is:8.05 & sMAPE is:9.37% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :9.99 & 22.42% & 0.91\n",
      "for 2021-07-28, MAE is:10.81 & sMAPE is:13.85% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :10.00 & 22.38% & 0.91\n",
      "for 2021-07-29, MAE is:28.21 & sMAPE is:68.50% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :10.08 & 22.60% & 0.91\n",
      "for 2021-07-30, MAE is:14.08 & sMAPE is:21.61% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :10.10 & 22.59% & 0.90\n",
      "for 2021-07-31, MAE is:33.01 & sMAPE is:86.24% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 22.89% & 0.90\n",
      "for 2021-08-01, MAE is:6.89 & sMAPE is:12.78% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :10.19 & 22.85% & 0.90\n",
      "for 2021-08-02, MAE is:14.53 & sMAPE is:18.26% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :10.21 & 22.83% & 0.90\n",
      "for 2021-08-03, MAE is:14.77 & sMAPE is:16.28% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 22.80% & 0.91\n",
      "for 2021-08-04, MAE is:12.19 & sMAPE is:12.98% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :10.24 & 22.75% & 0.91\n",
      "for 2021-08-05, MAE is:15.51 & sMAPE is:17.39% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :10.27 & 22.73% & 0.90\n",
      "for 2021-08-06, MAE is:6.27 & sMAPE is:8.93% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :10.25 & 22.66% & 0.90\n",
      "for 2021-08-07, MAE is:5.83 & sMAPE is:9.35% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :10.23 & 22.60% & 0.90\n",
      "for 2021-08-08, MAE is:46.71 & sMAPE is:147.15% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 23.17% & 0.90\n",
      "for 2021-08-09, MAE is:10.69 & sMAPE is:15.47% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :10.40 & 23.13% & 0.90\n",
      "for 2021-08-10, MAE is:12.67 & sMAPE is:14.01% & rMAE is:1.39 ||| daily mean of MAE & sMAPE & rMAE till now are :10.41 & 23.09% & 0.90\n",
      "for 2021-08-11, MAE is:14.36 & sMAPE is:14.58% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :10.43 & 23.05% & 0.90\n",
      "for 2021-08-12, MAE is:14.99 & sMAPE is:14.65% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 23.02% & 0.90\n",
      "for 2021-08-13, MAE is:9.43 & sMAPE is:9.91% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.44 & 22.96% & 0.90\n",
      "for 2021-08-14, MAE is:21.00 & sMAPE is:38.54% & rMAE is:1.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 23.03% & 0.90\n",
      "for 2021-08-15, MAE is:11.46 & sMAPE is:22.24% & rMAE is:0.20 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 23.02% & 0.90\n",
      "for 2021-08-16, MAE is:12.70 & sMAPE is:18.20% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 23.00% & 0.90\n",
      "for 2021-08-17, MAE is:13.75 & sMAPE is:26.16% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 23.02% & 0.90\n",
      "for 2021-08-18, MAE is:5.88 & sMAPE is:7.69% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 22.95% & 0.90\n",
      "for 2021-08-19, MAE is:15.76 & sMAPE is:17.77% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :10.52 & 22.93% & 0.90\n",
      "for 2021-08-20, MAE is:9.42 & sMAPE is:9.54% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :10.51 & 22.87% & 0.90\n",
      "for 2021-08-21, MAE is:8.39 & sMAPE is:9.10% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 22.81% & 0.89\n",
      "for 2021-08-22, MAE is:5.37 & sMAPE is:6.72% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 22.74% & 0.89\n",
      "for 2021-08-23, MAE is:12.31 & sMAPE is:13.92% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 22.70% & 0.89\n",
      "for 2021-08-24, MAE is:11.29 & sMAPE is:12.48% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :10.49 & 22.66% & 0.89\n",
      "for 2021-08-25, MAE is:12.33 & sMAPE is:14.26% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 22.62% & 0.89\n",
      "for 2021-08-26, MAE is:10.11 & sMAPE is:11.45% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 22.58% & 0.89\n",
      "for 2021-08-27, MAE is:9.83 & sMAPE is:11.09% & rMAE is:1.52 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 22.53% & 0.89\n",
      "for 2021-08-28, MAE is:4.92 & sMAPE is:5.83% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :10.47 & 22.46% & 0.89\n",
      "for 2021-08-29, MAE is:4.70 & sMAPE is:5.65% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :10.45 & 22.39% & 0.89\n",
      "for 2021-08-30, MAE is:16.59 & sMAPE is:16.09% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :10.48 & 22.36% & 0.89\n",
      "for 2021-08-31, MAE is:16.55 & sMAPE is:16.15% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :10.50 & 22.34% & 0.89\n",
      "for 2021-09-01, MAE is:17.53 & sMAPE is:16.68% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.53 & 22.32% & 0.89\n",
      "for 2021-09-02, MAE is:16.12 & sMAPE is:14.25% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :10.55 & 22.28% & 0.89\n",
      "for 2021-09-03, MAE is:11.91 & sMAPE is:10.65% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 22.24% & 0.89\n",
      "for 2021-09-04, MAE is:11.24 & sMAPE is:10.55% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :10.56 & 22.19% & 0.89\n",
      "for 2021-09-05, MAE is:15.83 & sMAPE is:16.49% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :10.58 & 22.17% & 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-09-06, MAE is:19.37 & sMAPE is:15.49% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.62 & 22.14% & 0.89\n",
      "for 2021-09-07, MAE is:14.40 & sMAPE is:11.36% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :10.63 & 22.10% & 0.89\n",
      "for 2021-09-08, MAE is:15.01 & sMAPE is:12.43% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :10.65 & 22.06% & 0.89\n",
      "for 2021-09-09, MAE is:22.27 & sMAPE is:18.46% & rMAE is:1.83 ||| daily mean of MAE & sMAPE & rMAE till now are :10.70 & 22.04% & 0.89\n",
      "for 2021-09-10, MAE is:17.68 & sMAPE is:13.77% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 22.01% & 0.89\n",
      "for 2021-09-11, MAE is:8.83 & sMAPE is:7.04% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :10.72 & 21.95% & 0.89\n",
      "for 2021-09-12, MAE is:13.28 & sMAPE is:12.43% & rMAE is:1.66 ||| daily mean of MAE & sMAPE & rMAE till now are :10.73 & 21.91% & 0.89\n",
      "for 2021-09-13, MAE is:24.20 & sMAPE is:17.79% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :10.78 & 21.90% & 0.90\n",
      "for 2021-09-14, MAE is:15.77 & sMAPE is:10.96% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :10.80 & 21.85% & 0.90\n",
      "for 2021-09-15, MAE is:40.87 & sMAPE is:27.52% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :10.91 & 21.88% & 0.90\n",
      "for 2021-09-16, MAE is:15.80 & sMAPE is:9.91% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.93 & 21.83% & 0.90\n",
      "for 2021-09-17, MAE is:10.31 & sMAPE is:6.67% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :10.93 & 21.77% & 0.89\n",
      "for 2021-09-18, MAE is:18.33 & sMAPE is:13.44% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :10.96 & 21.74% & 0.90\n",
      "for 2021-09-19, MAE is:28.25 & sMAPE is:27.61% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :11.02 & 21.76% & 0.90\n",
      "for 2021-09-20, MAE is:30.36 & sMAPE is:21.05% & rMAE is:2.17 ||| daily mean of MAE & sMAPE & rMAE till now are :11.10 & 21.76% & 0.91\n",
      "for 2021-09-21, MAE is:13.85 & sMAPE is:9.16% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :11.11 & 21.71% & 0.91\n",
      "for 2021-09-22, MAE is:19.22 & sMAPE is:13.51% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :11.14 & 21.68% & 0.91\n",
      "for 2021-09-23, MAE is:53.10 & sMAPE is:63.28% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :11.30 & 21.84% & 0.90\n",
      "for 2021-09-24, MAE is:26.02 & sMAPE is:23.09% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :11.35 & 21.84% & 0.90\n",
      "for 2021-09-25, MAE is:37.25 & sMAPE is:31.83% & rMAE is:1.67 ||| daily mean of MAE & sMAPE & rMAE till now are :11.45 & 21.88% & 0.91\n",
      "for 2021-09-26, MAE is:20.73 & sMAPE is:15.93% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :11.48 & 21.86% & 0.90\n",
      "for 2021-09-27, MAE is:15.19 & sMAPE is:10.74% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :11.50 & 21.82% & 0.91\n",
      "for 2021-09-28, MAE is:25.64 & sMAPE is:16.48% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :11.55 & 21.80% & 0.91\n",
      "for 2021-09-29, MAE is:27.84 & sMAPE is:21.29% & rMAE is:1.59 ||| daily mean of MAE & sMAPE & rMAE till now are :11.61 & 21.79% & 0.91\n",
      "for 2021-09-30, MAE is:31.97 & sMAPE is:27.01% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.68 & 21.81% & 0.91\n",
      "for 2021-10-01, MAE is:36.02 & sMAPE is:36.37% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :11.77 & 21.87% & 0.91\n",
      "for 2021-10-02, MAE is:28.37 & sMAPE is:30.37% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :11.83 & 21.90% & 0.91\n",
      "for 2021-10-03, MAE is:41.50 & sMAPE is:129.33% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :11.94 & 22.29% & 0.91\n",
      "for 2021-10-04, MAE is:50.01 & sMAPE is:33.98% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :12.08 & 22.33% & 0.91\n",
      "for 2021-10-05, MAE is:30.99 & sMAPE is:19.41% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :12.15 & 22.32% & 0.91\n",
      "for 2021-10-06, MAE is:71.50 & sMAPE is:44.42% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :12.36 & 22.40% & 0.91\n",
      "for 2021-10-07, MAE is:125.39 & sMAPE is:51.77% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :12.76 & 22.50% & 0.91\n",
      "for 2021-10-08, MAE is:43.23 & sMAPE is:20.57% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :12.87 & 22.50% & 0.91\n",
      "for 2021-10-09, MAE is:36.61 & sMAPE is:25.98% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :12.96 & 22.51% & 0.91\n",
      "for 2021-10-10, MAE is:26.71 & sMAPE is:18.80% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :13.00 & 22.50% & 0.91\n",
      "for 2021-10-11, MAE is:34.32 & sMAPE is:20.80% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :13.08 & 22.49% & 0.91\n",
      "for 2021-10-12, MAE is:40.51 & sMAPE is:24.29% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :13.18 & 22.50% & 0.91\n",
      "for 2021-10-13, MAE is:30.15 & sMAPE is:16.12% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :13.23 & 22.47% & 0.91\n",
      "for 2021-10-14, MAE is:32.39 & sMAPE is:20.00% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :13.30 & 22.46% & 0.91\n",
      "for 2021-10-15, MAE is:51.48 & sMAPE is:44.58% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :13.43 & 22.54% & 0.91\n",
      "for 2021-10-16, MAE is:35.94 & sMAPE is:23.69% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :13.51 & 22.55% & 0.91\n",
      "for 2021-10-17, MAE is:23.14 & sMAPE is:15.95% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :13.54 & 22.52% & 0.91\n",
      "for 2021-10-18, MAE is:40.90 & sMAPE is:22.06% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :13.64 & 22.52% & 0.92\n",
      "for 2021-10-19, MAE is:36.02 & sMAPE is:25.91% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :13.72 & 22.53% & 0.92\n",
      "for 2021-10-20, MAE is:46.71 & sMAPE is:76.12% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :13.83 & 22.72% & 0.91\n",
      "for 2021-10-21, MAE is:30.05 & sMAPE is:48.80% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :13.88 & 22.80% & 0.91\n",
      "for 2021-10-22, MAE is:20.62 & sMAPE is:30.39% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :13.91 & 22.83% & 0.91\n",
      "for 2021-10-23, MAE is:62.80 & sMAPE is:49.57% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :14.07 & 22.92% & 0.91\n",
      "for 2021-10-24, MAE is:52.54 & sMAPE is:43.57% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :14.20 & 22.99% & 0.91\n",
      "for 2021-10-25, MAE is:64.36 & sMAPE is:40.60% & rMAE is:3.37 ||| daily mean of MAE & sMAPE & rMAE till now are :14.37 & 23.05% & 0.92\n",
      "for 2021-10-26, MAE is:29.08 & sMAPE is:17.25% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :14.42 & 23.03% & 0.92\n",
      "for 2021-10-27, MAE is:37.93 & sMAPE is:26.42% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :14.50 & 23.04% & 0.92\n",
      "for 2021-10-28, MAE is:33.21 & sMAPE is:21.71% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :14.56 & 23.04% & 0.92\n",
      "for 2021-10-29, MAE is:30.09 & sMAPE is:25.89% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 23.05% & 0.92\n",
      "for 2021-10-30, MAE is:15.38 & sMAPE is:17.38% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 23.03% & 0.92\n",
      "for 2021-10-31, MAE is:12.42 & sMAPE is:18.10% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :14.61 & 23.01% & 0.91\n",
      "for 2021-11-01, MAE is:25.87 & sMAPE is:27.34% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :14.64 & 23.03% & 0.91\n",
      "for 2021-11-02, MAE is:69.53 & sMAPE is:38.68% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :14.82 & 23.08% & 0.92\n",
      "for 2021-11-03, MAE is:24.11 & sMAPE is:12.35% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :14.85 & 23.04% & 0.92\n",
      "for 2021-11-04, MAE is:17.67 & sMAPE is:10.99% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :14.86 & 23.00% & 0.91\n",
      "for 2021-11-05, MAE is:30.54 & sMAPE is:19.80% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :14.91 & 22.99% & 0.91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2021-11-06, MAE is:38.58 & sMAPE is:41.28% & rMAE is:2.72 ||| daily mean of MAE & sMAPE & rMAE till now are :14.99 & 23.05% & 0.92\n",
      "for 2021-11-07, MAE is:34.65 & sMAPE is:97.59% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :15.05 & 23.29% & 0.92\n",
      "for 2021-11-08, MAE is:89.67 & sMAPE is:57.95% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :15.29 & 23.40% & 0.92\n",
      "for 2021-11-09, MAE is:29.49 & sMAPE is:17.75% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :15.34 & 23.38% & 0.92\n",
      "for 2021-11-10, MAE is:45.48 & sMAPE is:26.31% & rMAE is:1.74 ||| daily mean of MAE & sMAPE & rMAE till now are :15.43 & 23.39% & 0.92\n",
      "for 2021-11-11, MAE is:17.59 & sMAPE is:9.10% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :15.44 & 23.35% & 0.92\n",
      "for 2021-11-12, MAE is:26.72 & sMAPE is:17.04% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :15.47 & 23.33% & 0.92\n",
      "for 2021-11-13, MAE is:47.61 & sMAPE is:33.09% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :15.58 & 23.36% & 0.92\n",
      "for 2021-11-14, MAE is:18.24 & sMAPE is:11.30% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :15.58 & 23.32% & 0.92\n",
      "for 2021-11-15, MAE is:63.76 & sMAPE is:30.67% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :15.74 & 23.34% & 0.92\n",
      "for 2021-11-16, MAE is:46.80 & sMAPE is:19.97% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :15.83 & 23.33% & 0.92\n",
      "for 2021-11-17, MAE is:27.66 & sMAPE is:16.59% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :15.87 & 23.31% & 0.92\n",
      "for 2021-11-18, MAE is:30.64 & sMAPE is:22.28% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :15.92 & 23.31% & 0.92\n",
      "for 2021-11-19, MAE is:29.80 & sMAPE is:24.15% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :15.96 & 23.31% & 0.92\n",
      "for 2021-11-20, MAE is:20.61 & sMAPE is:17.50% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :15.97 & 23.29% & 0.91\n",
      "for 2021-11-21, MAE is:50.29 & sMAPE is:34.69% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :16.08 & 23.33% & 0.92\n",
      "for 2021-11-22, MAE is:68.35 & sMAPE is:32.09% & rMAE is:4.04 ||| daily mean of MAE & sMAPE & rMAE till now are :16.24 & 23.36% & 0.92\n",
      "for 2021-11-23, MAE is:49.49 & sMAPE is:20.63% & rMAE is:2.28 ||| daily mean of MAE & sMAPE & rMAE till now are :16.34 & 23.35% & 0.93\n",
      "for 2021-11-24, MAE is:63.81 & sMAPE is:24.01% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :16.48 & 23.35% & 0.93\n",
      "for 2021-11-25, MAE is:60.22 & sMAPE is:26.18% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :16.62 & 23.36% & 0.93\n",
      "for 2021-11-26, MAE is:36.98 & sMAPE is:19.49% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :16.68 & 23.35% & 0.93\n",
      "for 2021-11-27, MAE is:65.52 & sMAPE is:37.17% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :16.83 & 23.39% & 0.93\n",
      "for 2021-11-28, MAE is:13.68 & sMAPE is:6.70% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :16.82 & 23.34% & 0.92\n",
      "for 2021-11-29, MAE is:83.47 & sMAPE is:32.27% & rMAE is:2.08 ||| daily mean of MAE & sMAPE & rMAE till now are :17.02 & 23.36% & 0.93\n",
      "for 2021-11-30, MAE is:100.20 & sMAPE is:61.84% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :17.27 & 23.48% & 0.93\n",
      "for 2021-12-01, MAE is:84.54 & sMAPE is:62.06% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :17.47 & 23.59% & 0.93\n",
      "for 2021-12-02, MAE is:82.02 & sMAPE is:49.02% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :17.66 & 23.67% & 0.93\n",
      "for 2021-12-03, MAE is:41.59 & sMAPE is:25.52% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :17.73 & 23.68% & 0.93\n",
      "for 2021-12-04, MAE is:72.65 & sMAPE is:43.89% & rMAE is:3.07 ||| daily mean of MAE & sMAPE & rMAE till now are :17.89 & 23.74% & 0.93\n",
      "for 2021-12-05, MAE is:48.52 & sMAPE is:33.06% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :17.98 & 23.76% & 0.93\n",
      "for 2021-12-06, MAE is:76.54 & sMAPE is:30.88% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :18.16 & 23.78% & 0.93\n",
      "for 2021-12-07, MAE is:63.08 & sMAPE is:31.19% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :18.29 & 23.81% & 0.93\n",
      "for 2021-12-08, MAE is:61.74 & sMAPE is:37.23% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :18.41 & 23.85% & 0.93\n",
      "for 2021-12-09, MAE is:80.47 & sMAPE is:31.38% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :18.60 & 23.87% & 0.93\n",
      "for 2021-12-10, MAE is:36.83 & sMAPE is:15.95% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :18.65 & 23.84% & 0.93\n",
      "for 2021-12-11, MAE is:39.09 & sMAPE is:17.47% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :18.71 & 23.83% & 0.93\n",
      "for 2021-12-12, MAE is:47.75 & sMAPE is:27.46% & rMAE is:1.84 ||| daily mean of MAE & sMAPE & rMAE till now are :18.79 & 23.84% & 0.93\n",
      "for 2021-12-13, MAE is:58.76 & sMAPE is:22.91% & rMAE is:2.04 ||| daily mean of MAE & sMAPE & rMAE till now are :18.91 & 23.83% & 0.94\n",
      "for 2021-12-14, MAE is:73.38 & sMAPE is:25.71% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :19.06 & 23.84% & 0.94\n",
      "for 2021-12-15, MAE is:47.78 & sMAPE is:16.43% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :19.15 & 23.82% & 0.94\n",
      "for 2021-12-16, MAE is:76.11 & sMAPE is:23.08% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :19.31 & 23.82% & 0.94\n",
      "for 2021-12-17, MAE is:47.34 & sMAPE is:14.14% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :19.39 & 23.79% & 0.93\n",
      "for 2021-12-18, MAE is:49.62 & sMAPE is:21.51% & rMAE is:1.09 ||| daily mean of MAE & sMAPE & rMAE till now are :19.47 & 23.78% & 0.94\n",
      "for 2021-12-19, MAE is:83.90 & sMAPE is:64.79% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :19.66 & 23.90% & 0.94\n",
      "for 2021-12-20, MAE is:117.26 & sMAPE is:39.29% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :19.93 & 23.94% & 0.94\n",
      "for 2021-12-21, MAE is:135.85 & sMAPE is:34.85% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :20.26 & 23.97% & 0.94\n",
      "for 2021-12-22, MAE is:73.67 & sMAPE is:18.39% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :20.41 & 23.96% & 0.94\n",
      "for 2021-12-23, MAE is:74.09 & sMAPE is:25.61% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :20.56 & 23.96% & 0.94\n",
      "for 2021-12-24, MAE is:68.47 & sMAPE is:35.01% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :20.69 & 23.99% & 0.94\n",
      "for 2021-12-25, MAE is:54.70 & sMAPE is:25.53% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :20.79 & 24.00% & 0.93\n",
      "for 2021-12-26, MAE is:29.56 & sMAPE is:17.06% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :20.81 & 23.98% & 0.93\n",
      "for 2021-12-27, MAE is:56.46 & sMAPE is:35.38% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :20.91 & 24.01% & 0.93\n",
      "for 2021-12-28, MAE is:84.25 & sMAPE is:61.99% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :21.09 & 24.11% & 0.93\n",
      "for 2021-12-29, MAE is:36.38 & sMAPE is:23.76% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :21.13 & 24.11% & 0.93\n",
      "for 2021-12-30, MAE is:73.88 & sMAPE is:69.22% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :21.27 & 24.24% & 0.93\n",
      "for 2021-12-31, MAE is:73.82 & sMAPE is:162.06% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :21.42 & 24.61% & 0.92\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:27:08,380]\u001b[0m A new study created in RDB with name: DE_2022\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:20,920]\u001b[0m Trial 2 finished with value: 52.768944725899274 and parameters: {'n_hidden': 3, 'learning_rate': 0.027728405908475532, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18719895045294843, 'dropout_rate_Layer_2': 0.34194900251517746, 'dropout_rate_Layer_3': 0.22608457188592346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.000853054259080361, 'l1_Layer_2': 0.00010586091297395407, 'l1_Layer_3': 9.018261620010056e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 280, 'n_units_Layer_3': 290}. Best is trial 2 with value: 52.768944725899274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.77 | sMAPE for Validation Set is: 57.66% | rMAE for Validation Set is: 1.68\n",
      "MAE for Test Set is: 188.62 | sMAPE for Test Set is: 116.64% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:27:21,286]\u001b[0m Trial 0 pruned. Trial was pruned at epoch 12.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:25,616]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:28,691]\u001b[0m Trial 6 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:32,075]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:35,845]\u001b[0m Trial 3 finished with value: 53.036545600615845 and parameters: {'n_hidden': 4, 'learning_rate': 0.00706784546108051, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3438165873815598, 'dropout_rate_Layer_2': 0.0746014751404704, 'dropout_rate_Layer_3': 0.03588699317376416, 'dropout_rate_Layer_4': 0.3553983827998054, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.048248130316767585, 'l1_Layer_2': 4.988399925928304e-05, 'l1_Layer_3': 0.010050930118744302, 'l1_Layer_4': 0.055028118823745614, 'n_units_Layer_1': 90, 'n_units_Layer_2': 210, 'n_units_Layer_3': 145, 'n_units_Layer_4': 120}. Best is trial 2 with value: 52.768944725899274.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.04 | sMAPE for Validation Set is: 57.58% | rMAE for Validation Set is: 1.69\n",
      "MAE for Test Set is: 189.16 | sMAPE for Test Set is: 117.30% | rMAE for Test Set is: 2.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:27:48,013]\u001b[0m Trial 8 finished with value: 42.629658150970386 and parameters: {'n_hidden': 4, 'learning_rate': 0.0028500590255850734, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12656797190939803, 'dropout_rate_Layer_2': 0.20881257781862034, 'dropout_rate_Layer_3': 0.14102665889143018, 'dropout_rate_Layer_4': 0.152671891761469, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.01340496558888976, 'l1_Layer_2': 0.001336576721544211, 'l1_Layer_3': 1.3558975757590246e-05, 'l1_Layer_4': 0.00399556755035477, 'n_units_Layer_1': 290, 'n_units_Layer_2': 85, 'n_units_Layer_3': 150, 'n_units_Layer_4': 100}. Best is trial 8 with value: 42.629658150970386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.63 | sMAPE for Validation Set is: 42.95% | rMAE for Validation Set is: 1.36\n",
      "MAE for Test Set is: 169.01 | sMAPE for Test Set is: 95.81% | rMAE for Test Set is: 1.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:27:51,419]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:54,559]\u001b[0m Trial 11 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:58,621]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:27:59,358]\u001b[0m Trial 5 finished with value: 43.291130305781714 and parameters: {'n_hidden': 4, 'learning_rate': 0.03415959316422688, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09147080621577795, 'dropout_rate_Layer_2': 0.3145465534555253, 'dropout_rate_Layer_3': 0.3006402603352958, 'dropout_rate_Layer_4': 0.16668468940135744, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0004262505418783854, 'l1_Layer_2': 0.000436002392111076, 'l1_Layer_3': 0.0003996638818041133, 'l1_Layer_4': 4.366294196734967e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 150, 'n_units_Layer_3': 150, 'n_units_Layer_4': 75}. Best is trial 8 with value: 42.629658150970386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.29 | sMAPE for Validation Set is: 43.62% | rMAE for Validation Set is: 1.38\n",
      "MAE for Test Set is: 170.47 | sMAPE for Test Set is: 96.95% | rMAE for Test Set is: 1.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:28:05,988]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:11,324]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:14,172]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:14,240]\u001b[0m Trial 9 finished with value: 49.404261493903185 and parameters: {'n_hidden': 4, 'learning_rate': 0.012339164659046694, 'batch_size': 70, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13374654728625163, 'dropout_rate_Layer_2': 0.1494070020151786, 'dropout_rate_Layer_3': 0.2656030716725097, 'dropout_rate_Layer_4': 0.0043849803972804136, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.88147876684576e-05, 'l1_Layer_2': 0.004972484269682276, 'l1_Layer_3': 0.008063316783447202, 'l1_Layer_4': 0.00039593435655523295, 'n_units_Layer_1': 295, 'n_units_Layer_2': 190, 'n_units_Layer_3': 120, 'n_units_Layer_4': 180}. Best is trial 8 with value: 42.629658150970386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.40 | sMAPE for Validation Set is: 52.05% | rMAE for Validation Set is: 1.57\n",
      "MAE for Test Set is: 183.92 | sMAPE for Test Set is: 111.03% | rMAE for Test Set is: 2.11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:28:18,768]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:18,874]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:24,980]\u001b[0m Trial 19 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:27,729]\u001b[0m Trial 20 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:31,693]\u001b[0m Trial 1 finished with value: 56.49919298736299 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005271789494018116, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1814604685112393, 'dropout_rate_Layer_2': 0.18101244115489187, 'dropout_rate_Layer_3': 0.08234865993294674, 'dropout_rate_Layer_4': 0.16548251759866123, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'tanh', 'activation_Layer_4': 'sigmoid', 'l1_Layer_1': 2.2509516812606468e-05, 'l1_Layer_2': 1.0662486340337303e-05, 'l1_Layer_3': 5.080289066150672e-05, 'l1_Layer_4': 0.0069269129262994715, 'n_units_Layer_1': 230, 'n_units_Layer_2': 215, 'n_units_Layer_3': 185, 'n_units_Layer_4': 295}. Best is trial 8 with value: 42.629658150970386.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 56.50 | sMAPE for Validation Set is: 63.93% | rMAE for Validation Set is: 1.80\n",
      "MAE for Test Set is: 193.64 | sMAPE for Test Set is: 122.78% | rMAE for Test Set is: 2.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:28:38,533]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:41,235]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:41,481]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:48,691]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:51,160]\u001b[0m Trial 23 finished with value: 21.06983572431561 and parameters: {'n_hidden': 3, 'learning_rate': 0.007829460582741858, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21320090423948682, 'dropout_rate_Layer_2': 0.15953988086351503, 'dropout_rate_Layer_3': 0.012856875863166018, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011059032348778575, 'l1_Layer_2': 0.0009907229566689475, 'l1_Layer_3': 0.010664619964658159, 'n_units_Layer_1': 110, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.07 | sMAPE for Validation Set is: 24.67% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.91 | sMAPE for Test Set is: 31.73% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:28:52,593]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:54,656]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:54,836]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:28:58,003]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:05,278]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:11,853]\u001b[0m Trial 14 finished with value: 46.14362436847315 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029472497152714943, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03496868145925589, 'dropout_rate_Layer_2': 0.17127013939968794, 'dropout_rate_Layer_3': 0.2431806773142697, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001623723361788129, 'l1_Layer_2': 1.1251685000079887e-05, 'l1_Layer_3': 0.008682602744416484, 'n_units_Layer_1': 180, 'n_units_Layer_2': 205, 'n_units_Layer_3': 210}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.14 | sMAPE for Validation Set is: 47.19% | rMAE for Validation Set is: 1.47\n",
      "MAE for Test Set is: 178.73 | sMAPE for Test Set is: 105.45% | rMAE for Test Set is: 2.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:29:12,184]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.47 | sMAPE for Validation Set is: 50.83% | rMAE for Validation Set is: 1.54\n",
      "MAE for Test Set is: 180.80 | sMAPE for Test Set is: 107.64% | rMAE for Test Set is: 2.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:29:16,849]\u001b[0m Trial 30 finished with value: 48.467024244153855 and parameters: {'n_hidden': 3, 'learning_rate': 0.05576410417075741, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28958812978236903, 'dropout_rate_Layer_2': 0.3406367896786191, 'dropout_rate_Layer_3': 0.39777401797979994, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.966930585033335e-05, 'l1_Layer_2': 0.005148722579777677, 'l1_Layer_3': 0.0008229628240807512, 'n_units_Layer_1': 195, 'n_units_Layer_2': 145, 'n_units_Layer_3': 225}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:25,745]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:28,270]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:31,520]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:34,747]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:40,071]\u001b[0m Trial 32 finished with value: 48.16101465113337 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016456030915834217, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0594013067439418, 'dropout_rate_Layer_2': 0.046958330678647055, 'dropout_rate_Layer_3': 0.3242765938884854, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0023843568829223e-05, 'l1_Layer_2': 0.02651216974742064, 'l1_Layer_3': 0.00039583016414684234, 'n_units_Layer_1': 135, 'n_units_Layer_2': 90, 'n_units_Layer_3': 140}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.16 | sMAPE for Validation Set is: 50.79% | rMAE for Validation Set is: 1.53\n",
      "MAE for Test Set is: 179.86 | sMAPE for Test Set is: 107.00% | rMAE for Test Set is: 2.07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:29:43,326]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:45,818]\u001b[0m Trial 38 finished with value: 21.15422457680356 and parameters: {'n_hidden': 3, 'learning_rate': 0.04793513780605616, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.009963844022664453, 'dropout_rate_Layer_2': 0.26709150029246254, 'dropout_rate_Layer_3': 0.2892506172854747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00040678845856838313, 'l1_Layer_2': 0.004017707802408697, 'l1_Layer_3': 0.00011958142703665774, 'n_units_Layer_1': 300, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.15 | sMAPE for Validation Set is: 25.37% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.34 | sMAPE for Test Set is: 31.41% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:29:48,061]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:51,479]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:29:58,826]\u001b[0m Trial 43 finished with value: 22.533956496695566 and parameters: {'n_hidden': 3, 'learning_rate': 0.04666268308149892, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.035229805424459124, 'dropout_rate_Layer_2': 0.3543139961173725, 'dropout_rate_Layer_3': 0.23708314534805852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0006107111456602192, 'l1_Layer_2': 0.0047492575272863515, 'l1_Layer_3': 0.0001273193185137212, 'n_units_Layer_1': 285, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.53 | sMAPE for Validation Set is: 27.68% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 64.68 | sMAPE for Test Set is: 32.92% | rMAE for Test Set is: 0.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:30:02,572]\u001b[0m Trial 40 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:05,872]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:06,077]\u001b[0m Trial 46 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:11,511]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:21,336]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:21,917]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:21,946]\u001b[0m Trial 48 finished with value: 22.618770511034924 and parameters: {'n_hidden': 3, 'learning_rate': 0.05411926209313966, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042382078575289764, 'dropout_rate_Layer_2': 0.27094075836616727, 'dropout_rate_Layer_3': 0.2952818066768225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001382494431620001, 'l1_Layer_2': 0.004653755409286224, 'l1_Layer_3': 0.0001663187878559471, 'n_units_Layer_1': 225, 'n_units_Layer_2': 50, 'n_units_Layer_3': 230}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.62 | sMAPE for Validation Set is: 27.77% | rMAE for Validation Set is: 0.72\n",
      "MAE for Test Set is: 80.70 | sMAPE for Test Set is: 35.79% | rMAE for Test Set is: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:30:27,802]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:27,977]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:35,246]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:35,433]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:41,606]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.29 | sMAPE for Validation Set is: 25.12% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 68.00 | sMAPE for Test Set is: 33.22% | rMAE for Test Set is: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:30:44,426]\u001b[0m Trial 52 finished with value: 21.287258521134184 and parameters: {'n_hidden': 3, 'learning_rate': 0.05013339046277392, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.006330144619611771, 'dropout_rate_Layer_2': 0.27216286370710374, 'dropout_rate_Layer_3': 0.18218876734551104, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.719247257868709e-05, 'l1_Layer_2': 0.006410099452739796, 'l1_Layer_3': 3.109669959495393e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 230}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:48,389]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:50,374]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:30:54,573]\u001b[0m Trial 56 finished with value: 23.012179517836984 and parameters: {'n_hidden': 3, 'learning_rate': 0.04858689835150154, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.005351141090193821, 'dropout_rate_Layer_2': 0.22545039210191337, 'dropout_rate_Layer_3': 0.3593006995618093, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7117907445761533e-05, 'l1_Layer_2': 0.002415626500997578, 'l1_Layer_3': 2.5509634403828918e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 75, 'n_units_Layer_3': 275}. Best is trial 23 with value: 21.06983572431561.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.01 | sMAPE for Validation Set is: 26.95% | rMAE for Validation Set is: 0.73\n",
      "MAE for Test Set is: 78.43 | sMAPE for Test Set is: 35.78% | rMAE for Test Set is: 0.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:30:56,546]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:02,225]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:05,295]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:12,156]\u001b[0m Trial 62 finished with value: 20.149658880759883 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016869259999727122, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06563549443725254, 'dropout_rate_Layer_2': 0.3747624784006175, 'dropout_rate_Layer_3': 0.23064898577176496, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.8414409327656075e-05, 'l1_Layer_2': 0.010380871673095524, 'l1_Layer_3': 1.2529063867659162e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 100, 'n_units_Layer_3': 205}. Best is trial 62 with value: 20.149658880759883.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.15 | sMAPE for Validation Set is: 23.92% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 53.38 | sMAPE for Test Set is: 29.61% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:31:18,385]\u001b[0m Trial 63 finished with value: 19.674738234177205 and parameters: {'n_hidden': 4, 'learning_rate': 0.011894861377926369, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06779628968593707, 'dropout_rate_Layer_2': 0.12019339355881939, 'dropout_rate_Layer_3': 7.524297163435945e-05, 'dropout_rate_Layer_4': 0.019992617269048385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014662944621900579, 'l1_Layer_2': 0.0018388092307005917, 'l1_Layer_3': 0.0061934994579108706, 'l1_Layer_4': 0.00025858420652709904, 'n_units_Layer_1': 135, 'n_units_Layer_2': 155, 'n_units_Layer_3': 130, 'n_units_Layer_4': 55}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.67 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 50.94 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:31:21,141]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.59 | sMAPE for Validation Set is: 25.34% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 56.38 | sMAPE for Test Set is: 30.88% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:31:23,504]\u001b[0m Trial 57 finished with value: 21.587619197213225 and parameters: {'n_hidden': 4, 'learning_rate': 0.01395303579636405, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07254589704147729, 'dropout_rate_Layer_2': 0.10476793532389012, 'dropout_rate_Layer_3': 0.015842618462038372, 'dropout_rate_Layer_4': 0.008737123555526971, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0014086101341583648, 'l1_Layer_2': 0.0019086573177379852, 'l1_Layer_3': 0.007675416149120678, 'l1_Layer_4': 0.0003422520918715903, 'n_units_Layer_1': 140, 'n_units_Layer_2': 160, 'n_units_Layer_3': 230, 'n_units_Layer_4': 55}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:24,584]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:29,220]\u001b[0m Trial 65 finished with value: 20.066949717984077 and parameters: {'n_hidden': 4, 'learning_rate': 0.012743586465777001, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0727760222844629, 'dropout_rate_Layer_2': 0.11588379429915008, 'dropout_rate_Layer_3': 0.005528062151510713, 'dropout_rate_Layer_4': 0.0003989016359001174, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0015996736911489192, 'l1_Layer_2': 0.002395682424811194, 'l1_Layer_3': 0.0055682320662096135, 'l1_Layer_4': 0.0004048510746254134, 'n_units_Layer_1': 125, 'n_units_Layer_2': 100, 'n_units_Layer_3': 235, 'n_units_Layer_4': 50}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.07 | sMAPE for Validation Set is: 23.34% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.12 | sMAPE for Test Set is: 29.44% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:31:31,673]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:35,718]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:43,572]\u001b[0m Trial 69 finished with value: 20.60862387774821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014081277428259786, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11419167300174149, 'dropout_rate_Layer_2': 0.37953347572367446, 'dropout_rate_Layer_3': 0.18208809365027276, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.157333423322193e-05, 'l1_Layer_2': 0.009237060883875771, 'l1_Layer_3': 6.600590598645783e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.61 | sMAPE for Validation Set is: 24.05% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 53.51 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:31:47,503]\u001b[0m Trial 70 finished with value: 20.138204524184072 and parameters: {'n_hidden': 3, 'learning_rate': 0.00125416253348425, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11472294188909754, 'dropout_rate_Layer_2': 0.3321589149908563, 'dropout_rate_Layer_3': 0.1755924809071714, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.2999319084414374e-05, 'l1_Layer_2': 0.009971843610419969, 'l1_Layer_3': 5.7462901112961253e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 65, 'n_units_Layer_3': 170}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.14 | sMAPE for Validation Set is: 23.55% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 53.82 | sMAPE for Test Set is: 29.72% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:31:50,140]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:31:58,527]\u001b[0m Trial 72 finished with value: 20.46708258695942 and parameters: {'n_hidden': 4, 'learning_rate': 0.01888719195336907, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.052428437355427945, 'dropout_rate_Layer_2': 0.06000588228991773, 'dropout_rate_Layer_3': 3.506875204560126e-05, 'dropout_rate_Layer_4': 0.07342190404072522, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00017702618146441912, 'l1_Layer_2': 0.03842787636039863, 'l1_Layer_3': 0.0037552823221465737, 'l1_Layer_4': 0.00024887457218988234, 'n_units_Layer_1': 165, 'n_units_Layer_2': 115, 'n_units_Layer_3': 105, 'n_units_Layer_4': 205}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.47 | sMAPE for Validation Set is: 23.57% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 55.52 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:00,887]\u001b[0m Trial 75 finished with value: 20.948468853392857 and parameters: {'n_hidden': 4, 'learning_rate': 0.015230321753771087, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.043596695622110285, 'dropout_rate_Layer_2': 0.063109783292113, 'dropout_rate_Layer_3': 8.890129790888825e-05, 'dropout_rate_Layer_4': 0.083561178642184, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00020433996119274066, 'l1_Layer_2': 0.05489128165418387, 'l1_Layer_3': 0.004098686109220408, 'l1_Layer_4': 0.00021528556336810058, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 260, 'n_units_Layer_4': 210}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.95 | sMAPE for Validation Set is: 24.96% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 58.33 | sMAPE for Test Set is: 31.07% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:03,528]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:06,487]\u001b[0m Trial 73 finished with value: 20.78145052826382 and parameters: {'n_hidden': 3, 'learning_rate': 0.0852662081299321, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39476577930402434, 'dropout_rate_Layer_2': 0.23740284852283478, 'dropout_rate_Layer_3': 0.3983489634669346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028296758996909486, 'l1_Layer_2': 0.00018204957630628253, 'l1_Layer_3': 1.972935151053347e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 275, 'n_units_Layer_3': 220}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.78 | sMAPE for Validation Set is: 24.50% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.45 | sMAPE for Test Set is: 31.51% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:09,457]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:12,259]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:12,705]\u001b[0m Trial 81 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:19,955]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:24,847]\u001b[0m Trial 78 finished with value: 21.686177308808045 and parameters: {'n_hidden': 3, 'learning_rate': 0.09692523697336992, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3881887668882356, 'dropout_rate_Layer_2': 0.25253611509473795, 'dropout_rate_Layer_3': 0.39780176049390026, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019613685746574903, 'l1_Layer_2': 0.0001858823842451729, 'l1_Layer_3': 3.317375194235612e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 275, 'n_units_Layer_3': 215}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.69 | sMAPE for Validation Set is: 25.23% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 65.95 | sMAPE for Test Set is: 33.27% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:27,751]\u001b[0m Trial 76 finished with value: 21.59536387323223 and parameters: {'n_hidden': 3, 'learning_rate': 0.08777514627198137, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39935232215121025, 'dropout_rate_Layer_2': 0.23334340391068348, 'dropout_rate_Layer_3': 0.3980846387753706, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021978212131763277, 'l1_Layer_2': 0.0001456089588293719, 'l1_Layer_3': 1.0606680302375287e-05, 'n_units_Layer_1': 135, 'n_units_Layer_2': 300, 'n_units_Layer_3': 215}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.60 | sMAPE for Validation Set is: 25.26% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 59.45 | sMAPE for Test Set is: 31.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:32,614]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:37,220]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:48,345]\u001b[0m Trial 86 finished with value: 23.351376379382568 and parameters: {'n_hidden': 3, 'learning_rate': 0.046722397827753503, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15646510389938167, 'dropout_rate_Layer_2': 0.3204805952747911, 'dropout_rate_Layer_3': 0.04401136272029951, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.459874005007918e-05, 'l1_Layer_2': 0.03170837397641265, 'l1_Layer_3': 0.003870868633392169, 'n_units_Layer_1': 140, 'n_units_Layer_2': 130, 'n_units_Layer_3': 60}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 23.35 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.74\n",
      "MAE for Test Set is: 69.37 | sMAPE for Test Set is: 34.37% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:52,135]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:32:56,466]\u001b[0m Trial 88 finished with value: 19.803072151449584 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022699001188839388, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0670770825031496, 'dropout_rate_Layer_2': 0.37415089946772256, 'dropout_rate_Layer_3': 0.25931668770602734, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.1297209299891296e-05, 'l1_Layer_2': 0.013455228716239883, 'l1_Layer_3': 1.0584022478668907e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 63 with value: 19.674738234177205.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.80 | sMAPE for Validation Set is: 23.24% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.49 | sMAPE for Test Set is: 28.94% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:32:59,057]\u001b[0m Trial 83 finished with value: 19.61043753717532 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008517585113970862, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06804967501530551, 'dropout_rate_Layer_2': 0.2938336099575475, 'dropout_rate_Layer_3': 0.2185096667406032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010436382160728606, 'l1_Layer_2': 0.01188845295361562, 'l1_Layer_3': 3.247629985688391e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 65, 'n_units_Layer_3': 210}. Best is trial 83 with value: 19.61043753717532.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.61 | sMAPE for Validation Set is: 22.90% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.35 | sMAPE for Test Set is: 28.80% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:33:04,062]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:04,426]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:08,746]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:10,940]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:11,639]\u001b[0m Trial 95 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:16,818]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:16,986]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:22,147]\u001b[0m Trial 87 finished with value: 19.47153190300729 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007166150978707621, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39821162414495925, 'dropout_rate_Layer_2': 0.36727092037769915, 'dropout_rate_Layer_3': 0.25551937399562147, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.750134934063771e-05, 'l1_Layer_2': 0.0006578938075714693, 'l1_Layer_3': 1.1146022255335154e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.47 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.85 | sMAPE for Test Set is: 29.57% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:33:24,128]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:26,216]\u001b[0m Trial 90 finished with value: 20.276978449717138 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007343441404581305, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0632418457035662, 'dropout_rate_Layer_2': 0.36876547123313125, 'dropout_rate_Layer_3': 0.26033776356467886, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.647414783003249e-05, 'l1_Layer_2': 0.014687891226176803, 'l1_Layer_3': 1.5941014762739234e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.28 | sMAPE for Validation Set is: 23.36% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 51.41 | sMAPE for Test Set is: 29.02% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:33:26,564]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:30,253]\u001b[0m Trial 101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:30,875]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:35,507]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:36,295]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:45,153]\u001b[0m Trial 99 finished with value: 19.796094319322037 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008332127555244652, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12283065088976128, 'dropout_rate_Layer_2': 0.2997118907381745, 'dropout_rate_Layer_3': 0.160197272297173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0631984446636826e-05, 'l1_Layer_2': 0.0028588412522983077, 'l1_Layer_3': 1.0246155063668143e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 105, 'n_units_Layer_3': 160}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.80 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.78 | sMAPE for Test Set is: 29.82% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:33:51,342]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:51,821]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:54,210]\u001b[0m Trial 108 finished with value: 72.9650045426953 and parameters: {'n_hidden': 3, 'learning_rate': 0.07983406232069647, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3723081986498477, 'dropout_rate_Layer_2': 0.33265712083223825, 'dropout_rate_Layer_3': 0.16726354324714054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 5.3403566015725206e-05, 'l1_Layer_2': 0.00020757412007139082, 'l1_Layer_3': 0.03493166470274145, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 75}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 72.97 | sMAPE for Validation Set is: 99.61% | rMAE for Validation Set is: 2.32\n",
      "MAE for Test Set is: 211.92 | sMAPE for Test Set is: 147.69% | rMAE for Test Set is: 2.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:33:55,189]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:33:59,913]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:01,667]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:03,371]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:03,749]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:07,992]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:10,934]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:13,298]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:14,971]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:17,210]\u001b[0m Trial 119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:17,847]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:19,526]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:24,779]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:25,512]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:29,255]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:29,364]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:34,104]\u001b[0m Trial 121 finished with value: 20.763688001561654 and parameters: {'n_hidden': 4, 'learning_rate': 0.013074247042881777, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04834444488591503, 'dropout_rate_Layer_2': 0.06386127917278456, 'dropout_rate_Layer_3': 0.0031313215292517287, 'dropout_rate_Layer_4': 0.08744246835805673, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.00021389208057317073, 'l1_Layer_2': 0.04984454493869696, 'l1_Layer_3': 0.004139546009370791, 'l1_Layer_4': 0.00019354243809047118, 'n_units_Layer_1': 155, 'n_units_Layer_2': 110, 'n_units_Layer_3': 295, 'n_units_Layer_4': 215}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.76 | sMAPE for Validation Set is: 23.98% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 55.67 | sMAPE for Test Set is: 30.25% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:34:37,619]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:41,016]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:45,082]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:45,512]\u001b[0m Trial 127 finished with value: 20.38789391440497 and parameters: {'n_hidden': 3, 'learning_rate': 0.005723778247418405, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13144749834678407, 'dropout_rate_Layer_2': 0.2475638498757891, 'dropout_rate_Layer_3': 0.13512686390054782, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.7569139098981817e-05, 'l1_Layer_2': 0.02044847291300021, 'l1_Layer_3': 0.0011976672811350585, 'n_units_Layer_1': 205, 'n_units_Layer_2': 50, 'n_units_Layer_3': 150}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.39 | sMAPE for Validation Set is: 24.19% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 51.49 | sMAPE for Test Set is: 28.97% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:34:51,886]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:54,718]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:34:56,751]\u001b[0m Trial 128 finished with value: 21.99856777363871 and parameters: {'n_hidden': 3, 'learning_rate': 0.08832316004844662, 'batch_size': 63, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3356302382667984, 'dropout_rate_Layer_2': 0.2666327097825227, 'dropout_rate_Layer_3': 0.3380795225487671, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.534741820459725e-05, 'l1_Layer_2': 4.731215910641378e-05, 'l1_Layer_3': 4.787347072460165e-05, 'n_units_Layer_1': 50, 'n_units_Layer_2': 245, 'n_units_Layer_3': 175}. Best is trial 87 with value: 19.47153190300729.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 22.00 | sMAPE for Validation Set is: 24.87% | rMAE for Validation Set is: 0.70\n",
      "MAE for Test Set is: 59.10 | sMAPE for Test Set is: 31.68% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:34:59,429]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:01,745]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:04,459]\u001b[0m Trial 136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:04,575]\u001b[0m Trial 116 finished with value: 19.292917917990014 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011652558676073397, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20559788382090374, 'dropout_rate_Layer_2': 0.308663711802753, 'dropout_rate_Layer_3': 0.13522406329175038, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.934094431426717e-05, 'l1_Layer_2': 0.007677850870558377, 'l1_Layer_3': 1.636514531435334e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 110, 'n_units_Layer_3': 180}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.29 | sMAPE for Validation Set is: 22.86% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 54.26 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:35:04,658]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:11,891]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:15,576]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:20,367]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:20,865]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:21,324]\u001b[0m Trial 142 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:27,082]\u001b[0m Trial 143 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:28,986]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:30,386]\u001b[0m Trial 146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:32,154]\u001b[0m Trial 147 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:33,732]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:36,335]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:36,864]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:42,853]\u001b[0m Trial 150 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:44,012]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:46,374]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:47,140]\u001b[0m Trial 154 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:50,488]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:52,511]\u001b[0m Trial 140 finished with value: 19.694503903514057 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008243985095077822, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2941850007371859, 'dropout_rate_Layer_2': 0.3124803380148102, 'dropout_rate_Layer_3': 0.12563116259281865, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.191159977805867e-05, 'l1_Layer_2': 0.005559511015215217, 'l1_Layer_3': 1.873781794168723e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 90, 'n_units_Layer_3': 205}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.69 | sMAPE for Validation Set is: 22.98% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 55.04 | sMAPE for Test Set is: 29.83% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:35:53,348]\u001b[0m Trial 157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:56,431]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:35:58,103]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:02,630]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:04,813]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:07,192]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:09,548]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:11,949]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:12,782]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:18,867]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:20,772]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:22,825]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:23,668]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:26,739]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:29,013]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:29,424]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:31,737]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:33,227]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:35,939]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:39,097]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:43,864]\u001b[0m Trial 152 finished with value: 19.595697939437112 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025579791641807213, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21687066746828304, 'dropout_rate_Layer_2': 0.17487227639530573, 'dropout_rate_Layer_3': 0.3554397734226039, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.780991657579347e-05, 'l1_Layer_2': 6.237968372370772e-05, 'l1_Layer_3': 2.02774651623328e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 215, 'n_units_Layer_3': 255}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.60 | sMAPE for Validation Set is: 23.38% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.53 | sMAPE for Test Set is: 29.09% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:36:46,730]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:36:59,292]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:01,265]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:04,726]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:05,161]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:07,282]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:16,663]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:17,096]\u001b[0m Trial 177 finished with value: 50.1852979776846 and parameters: {'n_hidden': 3, 'learning_rate': 0.020181406524257726, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.13819916601458823, 'dropout_rate_Layer_2': 0.2329848360023366, 'dropout_rate_Layer_3': 0.0860941761478877, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0920408715260047e-05, 'l1_Layer_2': 0.011523572587395486, 'l1_Layer_3': 0.0038938763088627476, 'n_units_Layer_1': 115, 'n_units_Layer_2': 150, 'n_units_Layer_3': 50}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.19 | sMAPE for Validation Set is: 53.12% | rMAE for Validation Set is: 1.60\n",
      "MAE for Test Set is: 184.56 | sMAPE for Test Set is: 111.69% | rMAE for Test Set is: 2.12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:37:19,335]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:31,399]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:34,730]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:35,190]\u001b[0m Trial 186 finished with value: 19.992949761522993 and parameters: {'n_hidden': 4, 'learning_rate': 0.003532909868636848, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09348694268265226, 'dropout_rate_Layer_2': 0.01418067184941537, 'dropout_rate_Layer_3': 0.3673032758636556, 'dropout_rate_Layer_4': 0.391114703238193, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 5.940360644183226e-05, 'l1_Layer_2': 2.2164994637921613e-05, 'l1_Layer_3': 0.003955876392971894, 'l1_Layer_4': 0.0004334128912763957, 'n_units_Layer_1': 100, 'n_units_Layer_2': 115, 'n_units_Layer_3': 90, 'n_units_Layer_4': 115}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.99 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.47 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:37:39,858]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:40,092]\u001b[0m Trial 190 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:45,944]\u001b[0m Trial 193 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:48,888]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:51,799]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:52,509]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:56,203]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:59,050]\u001b[0m Trial 198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:59,612]\u001b[0m Trial 197 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:37:59,784]\u001b[0m Trial 184 finished with value: 20.36917678785724 and parameters: {'n_hidden': 3, 'learning_rate': 0.006162296657763302, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2332497562106675, 'dropout_rate_Layer_2': 0.3892523802553737, 'dropout_rate_Layer_3': 0.08548356385179737, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000458152049461461, 'l1_Layer_2': 0.01241255593569215, 'l1_Layer_3': 0.0031076908576642918, 'n_units_Layer_1': 125, 'n_units_Layer_2': 145, 'n_units_Layer_3': 185}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.37 | sMAPE for Validation Set is: 23.65% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 59.80 | sMAPE for Test Set is: 31.36% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:38:04,598]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:04,833]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:05,518]\u001b[0m Trial 200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:10,653]\u001b[0m Trial 201 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:10,702]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:10,980]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:17,892]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:18,091]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:18,414]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:28,243]\u001b[0m Trial 203 finished with value: 20.961751845846404 and parameters: {'n_hidden': 3, 'learning_rate': 0.005351027414697471, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.24688910256838578, 'dropout_rate_Layer_2': 0.3974758719434277, 'dropout_rate_Layer_3': 0.1350258193905559, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00043576305624536517, 'l1_Layer_2': 0.0023030228584063443, 'l1_Layer_3': 0.07121032428449597, 'n_units_Layer_1': 75, 'n_units_Layer_2': 175, 'n_units_Layer_3': 185}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.96 | sMAPE for Validation Set is: 24.55% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.16 | sMAPE for Test Set is: 31.32% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:38:31,260]\u001b[0m Trial 211 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:38,832]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:39,490]\u001b[0m Trial 210 finished with value: 21.19577121154778 and parameters: {'n_hidden': 3, 'learning_rate': 0.0052908187502820475, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.23744757498587693, 'dropout_rate_Layer_2': 0.36358958390794394, 'dropout_rate_Layer_3': 0.11309137960080329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003944825284250614, 'l1_Layer_2': 0.0026413035587752017, 'l1_Layer_3': 0.09798018992332297, 'n_units_Layer_1': 60, 'n_units_Layer_2': 105, 'n_units_Layer_3': 185}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.20 | sMAPE for Validation Set is: 24.75% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 59.50 | sMAPE for Test Set is: 31.55% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:38:44,937]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:49,365]\u001b[0m Trial 215 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:52,275]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:55,022]\u001b[0m Trial 217 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:38:55,039]\u001b[0m Trial 209 finished with value: 20.608477817360917 and parameters: {'n_hidden': 3, 'learning_rate': 0.04815249945454936, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15718619646069212, 'dropout_rate_Layer_2': 0.29536426367560437, 'dropout_rate_Layer_3': 0.3992389209255561, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003070152994711972, 'l1_Layer_2': 0.00010447574677412927, 'l1_Layer_3': 1.9923328801360042e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 195, 'n_units_Layer_3': 240}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.61 | sMAPE for Validation Set is: 24.26% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 57.56 | sMAPE for Test Set is: 30.66% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:38:56,138]\u001b[0m Trial 208 finished with value: 20.246383539280913 and parameters: {'n_hidden': 3, 'learning_rate': 0.00760621493603416, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.39095060467942133, 'dropout_rate_Layer_2': 0.29534518611460636, 'dropout_rate_Layer_3': 0.3674686198486568, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003782859527379097, 'l1_Layer_2': 0.00011026938595261406, 'l1_Layer_3': 0.0004630293846693009, 'n_units_Layer_1': 115, 'n_units_Layer_2': 185, 'n_units_Layer_3': 235}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.25 | sMAPE for Validation Set is: 23.79% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.51 | sMAPE for Test Set is: 30.50% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:39:02,941]\u001b[0m Trial 220 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:04,698]\u001b[0m Trial 218 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:04,834]\u001b[0m Trial 219 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:05,456]\u001b[0m Trial 221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:11,068]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:12,462]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:14,497]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:18,110]\u001b[0m Trial 227 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:19,468]\u001b[0m Trial 226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:21,507]\u001b[0m Trial 228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:22,390]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:26,660]\u001b[0m Trial 214 finished with value: 20.464700728677897 and parameters: {'n_hidden': 3, 'learning_rate': 0.009624390145449937, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07174689689530442, 'dropout_rate_Layer_2': 0.10495512240688212, 'dropout_rate_Layer_3': 0.26426387803901574, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013681265055671408, 'l1_Layer_2': 0.011276430963110625, 'l1_Layer_3': 0.0012863697753539324, 'n_units_Layer_1': 240, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.46 | sMAPE for Validation Set is: 23.89% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 57.95 | sMAPE for Test Set is: 30.81% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:39:35,510]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:37,874]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:50,494]\u001b[0m Trial 233 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:52,568]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:54,345]\u001b[0m Trial 235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:55,848]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:39:59,983]\u001b[0m Trial 238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:04,210]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:07,320]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:08,796]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:10,546]\u001b[0m Trial 232 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:11,834]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:12,638]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:18,086]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:18,334]\u001b[0m Trial 222 finished with value: 20.02277331279255 and parameters: {'n_hidden': 3, 'learning_rate': 0.009680132350539739, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08259083141233783, 'dropout_rate_Layer_2': 0.020385219761523576, 'dropout_rate_Layer_3': 0.26498679936207425, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012582863726421283, 'l1_Layer_2': 0.013905075731669353, 'l1_Layer_3': 0.0017161894548040693, 'n_units_Layer_1': 155, 'n_units_Layer_2': 180, 'n_units_Layer_3': 240}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.02 | sMAPE for Validation Set is: 23.20% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 57.21 | sMAPE for Test Set is: 30.39% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:40:18,916]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:21,554]\u001b[0m Trial 243 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:26,050]\u001b[0m Trial 246 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:29,783]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:30,222]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:30,702]\u001b[0m Trial 248 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:34,167]\u001b[0m Trial 251 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:34,477]\u001b[0m Trial 250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:35,001]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:35,733]\u001b[0m Trial 253 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:43,558]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:46,318]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:52,093]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:54,641]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:54,700]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:59,384]\u001b[0m Trial 262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:40:59,970]\u001b[0m Trial 259 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:00,054]\u001b[0m Trial 261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:02,234]\u001b[0m Trial 257 finished with value: 20.841056817838822 and parameters: {'n_hidden': 3, 'learning_rate': 0.012725509687512486, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19561178441279678, 'dropout_rate_Layer_2': 0.10746627261550935, 'dropout_rate_Layer_3': 0.2846535965051679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0016775493959332287, 'l1_Layer_2': 0.007090284084928394, 'l1_Layer_3': 0.0016255763837179972, 'n_units_Layer_1': 225, 'n_units_Layer_2': 195, 'n_units_Layer_3': 230}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.84 | sMAPE for Validation Set is: 24.48% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 60.58 | sMAPE for Test Set is: 31.51% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:41:05,387]\u001b[0m Trial 263 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:08,290]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:09,478]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:10,276]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:16,830]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:17,220]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:18,743]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:21,458]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:22,610]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:27,296]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:30,334]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:32,618]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:37,732]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:44,559]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:48,593]\u001b[0m Trial 280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:41:58,277]\u001b[0m Trial 267 finished with value: 20.577152481254476 and parameters: {'n_hidden': 3, 'learning_rate': 0.006138013029795138, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11276172674842559, 'dropout_rate_Layer_2': 0.19764734117162197, 'dropout_rate_Layer_3': 0.3076971475650276, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009003136333574468, 'l1_Layer_2': 0.024730093130141614, 'l1_Layer_3': 0.0001408252716225033, 'n_units_Layer_1': 170, 'n_units_Layer_2': 260, 'n_units_Layer_3': 250}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.58 | sMAPE for Validation Set is: 23.93% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 56.69 | sMAPE for Test Set is: 30.42% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:42:12,142]\u001b[0m Trial 273 finished with value: 19.853023517803056 and parameters: {'n_hidden': 3, 'learning_rate': 0.003044455175756576, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.220448062741058, 'dropout_rate_Layer_2': 0.26450350334139894, 'dropout_rate_Layer_3': 0.3595672662787218, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000380184794429103, 'l1_Layer_2': 0.00011180853697255184, 'l1_Layer_3': 2.2036855855397746e-05, 'n_units_Layer_1': 120, 'n_units_Layer_2': 200, 'n_units_Layer_3': 230}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.85 | sMAPE for Validation Set is: 23.48% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 55.98 | sMAPE for Test Set is: 29.86% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:42:14,576]\u001b[0m Trial 282 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:17,914]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:22,138]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:27,737]\u001b[0m Trial 277 finished with value: 20.919402389679544 and parameters: {'n_hidden': 3, 'learning_rate': 0.005183074207737215, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026249842826075065, 'dropout_rate_Layer_2': 0.17416352346683298, 'dropout_rate_Layer_3': 0.21859628027007974, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.022811534576225565, 'l1_Layer_2': 0.023652645663893263, 'l1_Layer_3': 0.00015632036719425855, 'n_units_Layer_1': 160, 'n_units_Layer_2': 145, 'n_units_Layer_3': 250}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.92 | sMAPE for Validation Set is: 24.17% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 61.12 | sMAPE for Test Set is: 31.96% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:42:31,444]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:33,019]\u001b[0m Trial 286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:35,409]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:37,742]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:39,386]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:41,554]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:43,527]\u001b[0m Trial 292 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:44,525]\u001b[0m Trial 293 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:48,279]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:48,575]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:52,928]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:55,548]\u001b[0m Trial 298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:55,912]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:56,408]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:42:58,157]\u001b[0m Trial 294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:03,524]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:04,657]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:07,717]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:09,977]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:13,983]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:14,013]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:20,553]\u001b[0m Trial 308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:24,531]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:32,873]\u001b[0m Trial 299 finished with value: 20.205815621648863 and parameters: {'n_hidden': 3, 'learning_rate': 0.002636858038946917, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09499883630849695, 'dropout_rate_Layer_2': 0.008788950878908299, 'dropout_rate_Layer_3': 0.14219744586688549, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0027402260899535846, 'l1_Layer_2': 0.005653823164901125, 'l1_Layer_3': 0.0007447978030951146, 'n_units_Layer_1': 120, 'n_units_Layer_2': 85, 'n_units_Layer_3': 210}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.21 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.07 | sMAPE for Test Set is: 29.43% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:43:36,297]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:49,221]\u001b[0m Trial 307 finished with value: 19.7801563694625 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028795391597553764, 'batch_size': 56, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0851420163182532, 'dropout_rate_Layer_2': 0.06984649012524599, 'dropout_rate_Layer_3': 0.1466219909072531, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.003583163441090948, 'l1_Layer_2': 0.006034532499461915, 'l1_Layer_3': 0.000665302330382307, 'n_units_Layer_1': 105, 'n_units_Layer_2': 50, 'n_units_Layer_3': 215}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.78 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.25 | sMAPE for Test Set is: 30.31% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:43:52,892]\u001b[0m Trial 301 finished with value: 19.791099692224847 and parameters: {'n_hidden': 3, 'learning_rate': 0.003314088409232073, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1714443436707939, 'dropout_rate_Layer_2': 0.3960410928271877, 'dropout_rate_Layer_3': 0.36589746350986446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004310695057862991, 'l1_Layer_2': 1.0533261470393311e-05, 'l1_Layer_3': 4.277756216589556e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 235}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.79 | sMAPE for Validation Set is: 23.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.70 | sMAPE for Test Set is: 29.49% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:43:53,177]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:43:59,871]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:00,583]\u001b[0m Trial 310 finished with value: 20.10997042893753 and parameters: {'n_hidden': 3, 'learning_rate': 0.003259502770899458, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21557452552472, 'dropout_rate_Layer_2': 0.27046382800944296, 'dropout_rate_Layer_3': 0.3630408923722926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000457132389463249, 'l1_Layer_2': 0.00011317550488765828, 'l1_Layer_3': 5.6480698765133695e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 200, 'n_units_Layer_3': 235}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.11 | sMAPE for Validation Set is: 23.75% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.28 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:44:11,427]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:11,761]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:12,303]\u001b[0m Trial 312 finished with value: 19.491147781817773 and parameters: {'n_hidden': 3, 'learning_rate': 0.003569125709272149, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21425641784132365, 'dropout_rate_Layer_2': 0.3916809895098978, 'dropout_rate_Layer_3': 0.36314906119675017, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000441913930722627, 'l1_Layer_2': 0.00010419236614042297, 'l1_Layer_3': 5.9364021431811874e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 125, 'n_units_Layer_3': 270}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.49 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.21 | sMAPE for Test Set is: 28.49% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:44:16,977]\u001b[0m Trial 318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:19,839]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:20,033]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:20,449]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:20,729]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:27,348]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:28,909]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:31,702]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:34,204]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:40,252]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:42,625]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:44,225]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:47,176]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:49,662]\u001b[0m Trial 332 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:50,350]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:44:55,614]\u001b[0m Trial 329 finished with value: 20.364791635103956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021588697104441387, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10213643222712311, 'dropout_rate_Layer_2': 0.3197862795694235, 'dropout_rate_Layer_3': 0.24074062271724156, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005978850292740469, 'l1_Layer_2': 0.0064622617978387755, 'l1_Layer_3': 0.00013812691792231793, 'n_units_Layer_1': 75, 'n_units_Layer_2': 75, 'n_units_Layer_3': 195}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.36 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 55.83 | sMAPE for Test Set is: 30.24% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:44:57,058]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:00,448]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:01,407]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:01,466]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:03,497]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:11,656]\u001b[0m Trial 333 finished with value: 19.64940667660723 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023688914126276054, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0909829690608524, 'dropout_rate_Layer_2': 0.025171642622799036, 'dropout_rate_Layer_3': 0.07634614675895139, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.684137376853547e-05, 'l1_Layer_2': 0.007618432550934746, 'l1_Layer_3': 0.0001470592412276629, 'n_units_Layer_1': 65, 'n_units_Layer_2': 65, 'n_units_Layer_3': 200}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.65 | sMAPE for Validation Set is: 22.96% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.87 | sMAPE for Test Set is: 30.38% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:45:14,067]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:18,164]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:23,301]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:23,731]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:26,526]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:28,542]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:30,372]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:31,826]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:35,898]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:36,959]\u001b[0m Trial 349 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:40,786]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:40,961]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:41,123]\u001b[0m Trial 348 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:46,893]\u001b[0m Trial 347 finished with value: 19.84541237100043 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027890044385944237, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 3.114194864485033e-06, 'dropout_rate_Layer_2': 0.013570601546474596, 'dropout_rate_Layer_3': 0.10371845236686385, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007707422117368243, 'l1_Layer_2': 0.003288894006469172, 'l1_Layer_3': 0.0002524078563870893, 'n_units_Layer_1': 75, 'n_units_Layer_2': 90, 'n_units_Layer_3': 190}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.85 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 54.12 | sMAPE for Test Set is: 29.73% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:45:47,283]\u001b[0m Trial 353 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:47,679]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:53,661]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:45:55,054]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:00,151]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:10,052]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:14,464]\u001b[0m Trial 362 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:17,267]\u001b[0m Trial 361 finished with value: 19.791103417628083 and parameters: {'n_hidden': 3, 'learning_rate': 0.002660354523008363, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0027549682834810893, 'dropout_rate_Layer_2': 0.01769791284143049, 'dropout_rate_Layer_3': 0.08965698768441341, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007686090775287468, 'l1_Layer_2': 0.0038547061830837065, 'l1_Layer_3': 1.2363751457974085e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 90, 'n_units_Layer_3': 180}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.79 | sMAPE for Validation Set is: 23.06% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.99 | sMAPE for Test Set is: 29.39% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:46:20,860]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:20,979]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:26,571]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:29,560]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:29,632]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:37,357]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:37,471]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:43,799]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:43,999]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:48,546]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:50,142]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:46:54,371]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:03,248]\u001b[0m Trial 376 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:03,554]\u001b[0m Trial 368 finished with value: 19.529299665455202 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025281242626360076, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0161661849782365, 'dropout_rate_Layer_2': 0.022057249922926205, 'dropout_rate_Layer_3': 0.10852106559806977, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0014218570859146284, 'l1_Layer_2': 0.003181462055313086, 'l1_Layer_3': 1.3340890280307187e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 85, 'n_units_Layer_3': 185}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.53 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 56.50 | sMAPE for Test Set is: 29.89% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:47:09,012]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:32,163]\u001b[0m Trial 375 finished with value: 20.834329058236857 and parameters: {'n_hidden': 3, 'learning_rate': 0.003799286049551012, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2093162864229646, 'dropout_rate_Layer_2': 0.3744839845752223, 'dropout_rate_Layer_3': 0.36823462302560184, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0033514765914292753, 'l1_Layer_2': 4.0461094787075905e-05, 'l1_Layer_3': 4.30202544757397e-05, 'n_units_Layer_1': 185, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.83 | sMAPE for Validation Set is: 24.32% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 58.74 | sMAPE for Test Set is: 31.43% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:47:38,937]\u001b[0m Trial 365 finished with value: 20.218436387196544 and parameters: {'n_hidden': 3, 'learning_rate': 0.002382730387094973, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17130621084202527, 'dropout_rate_Layer_2': 0.3699545414108516, 'dropout_rate_Layer_3': 0.09468922323173679, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0035088823855071545, 'l1_Layer_2': 0.00038950947245236473, 'l1_Layer_3': 5.705908860900781e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 95, 'n_units_Layer_3': 200}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.22 | sMAPE for Validation Set is: 23.53% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 61.44 | sMAPE for Test Set is: 31.57% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:47:39,502]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:44,725]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:49,262]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:51,177]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:54,166]\u001b[0m Trial 384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:47:57,226]\u001b[0m Trial 379 finished with value: 20.09425616636789 and parameters: {'n_hidden': 3, 'learning_rate': 0.003617646216574121, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2137725740334766, 'dropout_rate_Layer_2': 0.3652256087296943, 'dropout_rate_Layer_3': 0.3618898809856061, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005359856215205951, 'l1_Layer_2': 3.5795169275530833e-05, 'l1_Layer_3': 4.234292835619534e-05, 'n_units_Layer_1': 110, 'n_units_Layer_2': 145, 'n_units_Layer_3': 230}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.09 | sMAPE for Validation Set is: 23.49% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 55.55 | sMAPE for Test Set is: 29.78% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:48:01,323]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:05,189]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:06,352]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:12,365]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:16,966]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:20,526]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:22,399]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:23,529]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:27,788]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:29,943]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:33,631]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:34,273]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:43,311]\u001b[0m Trial 396 finished with value: 19.58924043386426 and parameters: {'n_hidden': 4, 'learning_rate': 0.009348378732051217, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06561974103290961, 'dropout_rate_Layer_2': 0.2415664088055906, 'dropout_rate_Layer_3': 0.05016250083538891, 'dropout_rate_Layer_4': 0.3330414099222263, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0019515193144465598, 'l1_Layer_2': 0.002063849350120098, 'l1_Layer_3': 1.5486550667937302e-05, 'l1_Layer_4': 0.0004966906037915717, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 200, 'n_units_Layer_4': 275}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.59 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.46 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:48:46,463]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:50,983]\u001b[0m Trial 397 finished with value: 21.35952907001506 and parameters: {'n_hidden': 4, 'learning_rate': 0.009207995942659057, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04395711205964016, 'dropout_rate_Layer_2': 0.2447550254958678, 'dropout_rate_Layer_3': 0.04801067050317545, 'dropout_rate_Layer_4': 0.20673633856215656, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0039721953066456555, 'l1_Layer_2': 0.0009560681623809708, 'l1_Layer_3': 0.06586747347978027, 'l1_Layer_4': 0.0005009585577237566, 'n_units_Layer_1': 185, 'n_units_Layer_2': 135, 'n_units_Layer_3': 200, 'n_units_Layer_4': 140}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.36 | sMAPE for Validation Set is: 25.00% | rMAE for Validation Set is: 0.68\n",
      "MAE for Test Set is: 54.03 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:48:55,314]\u001b[0m Trial 399 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:55,777]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:59,674]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:48:59,814]\u001b[0m Trial 404 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:04,351]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:07,636]\u001b[0m Trial 407 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:12,646]\u001b[0m Trial 405 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:17,069]\u001b[0m Trial 402 finished with value: 20.443462974039537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0036258097835478796, 'batch_size': 42, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16584705819702042, 'dropout_rate_Layer_2': 0.002155165207290727, 'dropout_rate_Layer_3': 0.14569320753039067, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008128708681774202, 'l1_Layer_2': 0.00669969045370039, 'l1_Layer_3': 0.0024329216437448562, 'n_units_Layer_1': 115, 'n_units_Layer_2': 165, 'n_units_Layer_3': 200}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.44 | sMAPE for Validation Set is: 23.94% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 58.25 | sMAPE for Test Set is: 30.89% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:49:19,978]\u001b[0m Trial 410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:24,183]\u001b[0m Trial 398 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:27,122]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:28,636]\u001b[0m Trial 412 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:30,285]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:30,902]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:31,730]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:36,910]\u001b[0m Trial 409 finished with value: 19.66607511769821 and parameters: {'n_hidden': 4, 'learning_rate': 0.007292936990444299, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.042116905699499496, 'dropout_rate_Layer_2': 0.2904659867565813, 'dropout_rate_Layer_3': 0.006421836963009624, 'dropout_rate_Layer_4': 0.3399555476237388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0029074490213170374, 'l1_Layer_2': 0.0008984668852026205, 'l1_Layer_3': 1.738977926675815e-05, 'l1_Layer_4': 0.0004130907710754227, 'n_units_Layer_1': 190, 'n_units_Layer_2': 155, 'n_units_Layer_3': 210, 'n_units_Layer_4': 125}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.67 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.11 | sMAPE for Test Set is: 28.77% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:49:37,325]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:42,401]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:42,533]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:49,994]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:53,856]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:49:55,709]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:01,272]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:07,491]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:10,782]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:13,711]\u001b[0m Trial 418 finished with value: 21.158828100323735 and parameters: {'n_hidden': 3, 'learning_rate': 0.012324673396112325, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2155354646622868, 'dropout_rate_Layer_2': 0.12632911142344272, 'dropout_rate_Layer_3': 0.10486865138659612, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001991281787196445, 'l1_Layer_2': 0.04963552736452026, 'l1_Layer_3': 0.0007186373374383192, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 175}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.16 | sMAPE for Validation Set is: 24.60% | rMAE for Validation Set is: 0.67\n",
      "MAE for Test Set is: 63.17 | sMAPE for Test Set is: 32.22% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:50:14,467]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:18,699]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:21,247]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:24,079]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:27,738]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:28,233]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:29,642]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:35,049]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:38,660]\u001b[0m Trial 436 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:41,383]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:41,968]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:42,407]\u001b[0m Trial 425 finished with value: 21.622411381838713 and parameters: {'n_hidden': 3, 'learning_rate': 0.013704431191290887, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.27075372158704464, 'dropout_rate_Layer_2': 0.1308696285129634, 'dropout_rate_Layer_3': 0.09647299499716724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001991046487241869, 'l1_Layer_2': 0.05733172932919447, 'l1_Layer_3': 0.0008332166502470849, 'n_units_Layer_1': 130, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 21.62 | sMAPE for Validation Set is: 25.02% | rMAE for Validation Set is: 0.69\n",
      "MAE for Test Set is: 65.72 | sMAPE for Test Set is: 32.90% | rMAE for Test Set is: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:50:47,211]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:49,362]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:53,693]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:55,476]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:50:56,087]\u001b[0m Trial 441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:08,571]\u001b[0m Trial 443 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:22,065]\u001b[0m Trial 446 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:26,402]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:28,648]\u001b[0m Trial 444 finished with value: 20.832376631812874 and parameters: {'n_hidden': 3, 'learning_rate': 0.002241805976636188, 'batch_size': 49, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.061653267315379054, 'dropout_rate_Layer_2': 0.034098489947013956, 'dropout_rate_Layer_3': 0.18761707787417575, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0023827547660932196, 'l1_Layer_2': 0.01488066460816473, 'l1_Layer_3': 0.0003889675387533135, 'n_units_Layer_1': 85, 'n_units_Layer_2': 70, 'n_units_Layer_3': 175}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.83 | sMAPE for Validation Set is: 24.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 56.14 | sMAPE for Test Set is: 30.41% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:51:33,023]\u001b[0m Trial 445 finished with value: 19.39604456504061 and parameters: {'n_hidden': 3, 'learning_rate': 0.002477205846587339, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0122264295818517, 'dropout_rate_Layer_2': 0.14126167139661816, 'dropout_rate_Layer_3': 0.10134997268013315, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0010937436648301934, 'l1_Layer_2': 0.0023520827448017412, 'l1_Layer_3': 1.1641473144027234e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 75, 'n_units_Layer_3': 190}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.40 | sMAPE for Validation Set is: 23.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.62 | sMAPE for Test Set is: 29.12% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:51:39,148]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:43,283]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:46,376]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:49,667]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:54,882]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:51:57,999]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:06,080]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:13,097]\u001b[0m Trial 448 finished with value: 20.416501164919865 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030514262594212244, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21076259062998265, 'dropout_rate_Layer_2': 0.2661829970921937, 'dropout_rate_Layer_3': 0.3234782892971286, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008444324771730339, 'l1_Layer_2': 0.0001258745070573885, 'l1_Layer_3': 1.3792901759601079e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.42 | sMAPE for Validation Set is: 23.75% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 50.91 | sMAPE for Test Set is: 28.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:52:14,107]\u001b[0m Trial 447 finished with value: 20.340153555662635 and parameters: {'n_hidden': 3, 'learning_rate': 0.003026437173415222, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20752725897808236, 'dropout_rate_Layer_2': 0.2732261754428788, 'dropout_rate_Layer_3': 0.3233427036268912, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007631800954932905, 'l1_Layer_2': 0.00011846565442841379, 'l1_Layer_3': 1.4682765085042423e-05, 'n_units_Layer_1': 145, 'n_units_Layer_2': 135, 'n_units_Layer_3': 225}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.34 | sMAPE for Validation Set is: 23.66% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 53.95 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:52:15,136]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:15,572]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:16,035]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:23,045]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:23,442]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:28,123]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:32,974]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:36,417]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:39,068]\u001b[0m Trial 467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:42,296]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:46,111]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:49,587]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:49,797]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:54,735]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:55,342]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:56,757]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:52:58,689]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:03,601]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:04,765]\u001b[0m Trial 476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:07,093]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:09,184]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:12,387]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:12,720]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:17,867]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:24,710]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:30,677]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:30,848]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:35,813]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:38,399]\u001b[0m Trial 487 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:41,539]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:43,044]\u001b[0m Trial 485 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:45,282]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:45,831]\u001b[0m Trial 459 finished with value: 20.18257717994311 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017378111112549286, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18959476153836088, 'dropout_rate_Layer_2': 0.22279559012706432, 'dropout_rate_Layer_3': 0.3582225393503393, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003320977415268858, 'l1_Layer_2': 1.6174234813306282e-05, 'l1_Layer_3': 2.835913418050982e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 105, 'n_units_Layer_3': 275}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.18 | sMAPE for Validation Set is: 23.59% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 52.28 | sMAPE for Test Set is: 28.91% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:53:48,870]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:50,674]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:51,245]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:51,766]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:53:53,896]\u001b[0m Trial 493 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:00,963]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:04,657]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:07,704]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:11,870]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:12,047]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:12,672]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:18,323]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:18,598]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:23,308]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:23,855]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:27,386]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:29,104]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:29,766]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:32,902]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:33,822]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:34,413]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:39,691]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:43,047]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:44,734]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:46,255]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:52,006]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:52,262]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:58,862]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:54:59,031]\u001b[0m Trial 504 finished with value: 19.62101244058245 and parameters: {'n_hidden': 3, 'learning_rate': 0.0075068444095298965, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00041969063031832565, 'dropout_rate_Layer_2': 0.0830574215579568, 'dropout_rate_Layer_3': 0.20137139901511242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00032328081732314597, 'l1_Layer_2': 0.0015068698726961765, 'l1_Layer_3': 0.00022555072166220976, 'n_units_Layer_1': 130, 'n_units_Layer_2': 100, 'n_units_Layer_3': 200}. Best is trial 116 with value: 19.292917917990014.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.62 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.54 | sMAPE for Test Set is: 29.38% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:55:03,071]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:03,423]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:04,127]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:10,635]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:10,968]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:15,498]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:16,134]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:21,016]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:25,787]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:28,296]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:28,834]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:39,918]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:44,202]\u001b[0m Trial 533 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:47,723]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:55:52,805]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:56:00,137]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:56:01,984]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:56:05,463]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:56:09,013]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:56:29,297]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:56:33,206]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:57:22,070]\u001b[0m Trial 540 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:57:22,540]\u001b[0m Trial 541 finished with value: 19.227731267417223 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007795000634543801, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035387114481929806, 'dropout_rate_Layer_2': 0.03221335473780118, 'dropout_rate_Layer_3': 0.015467562669901022, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000142302176070487, 'l1_Layer_2': 0.0017432985887911746, 'l1_Layer_3': 0.007162962903957537, 'n_units_Layer_1': 155, 'n_units_Layer_2': 90, 'n_units_Layer_3': 235}. Best is trial 541 with value: 19.227731267417223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.23 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.54 | sMAPE for Test Set is: 28.09% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:57:52,169]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:57:52,945]\u001b[0m Trial 543 finished with value: 19.50322431124622 and parameters: {'n_hidden': 3, 'learning_rate': 0.01370266137309637, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.033699519456937124, 'dropout_rate_Layer_2': 0.042314928039066536, 'dropout_rate_Layer_3': 0.012675104487311082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020364082564486234, 'l1_Layer_2': 0.0018252844176748107, 'l1_Layer_3': 0.007454066243732793, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210}. Best is trial 541 with value: 19.227731267417223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.21 | sMAPE for Test Set is: 28.08% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:57:55,895]\u001b[0m Trial 532 finished with value: 20.283083456194714 and parameters: {'n_hidden': 3, 'learning_rate': 0.003907851467471597, 'batch_size': 7, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04085161176734865, 'dropout_rate_Layer_2': 0.04271184987751845, 'dropout_rate_Layer_3': 0.19797248256798725, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003036492017188356, 'l1_Layer_2': 0.0012404643642163048, 'l1_Layer_3': 0.0005180794163515929, 'n_units_Layer_1': 130, 'n_units_Layer_2': 65, 'n_units_Layer_3': 230}. Best is trial 541 with value: 19.227731267417223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.28 | sMAPE for Validation Set is: 23.80% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 59.20 | sMAPE for Test Set is: 31.28% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:57:56,473]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:57:57,027]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:57:57,038]\u001b[0m Trial 542 finished with value: 20.17213397861526 and parameters: {'n_hidden': 3, 'learning_rate': 0.004251463605536137, 'batch_size': 14, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0748460912128162, 'dropout_rate_Layer_2': 0.04293971311879202, 'dropout_rate_Layer_3': 0.13054698047540808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.871002084510449e-05, 'l1_Layer_2': 0.0024202372447018426, 'l1_Layer_3': 0.00047577799125408086, 'n_units_Layer_1': 130, 'n_units_Layer_2': 95, 'n_units_Layer_3': 195}. Best is trial 541 with value: 19.227731267417223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.17 | sMAPE for Validation Set is: 23.23% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 54.38 | sMAPE for Test Set is: 29.62% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:58:02,569]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:04,989]\u001b[0m Trial 549 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:05,158]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:10,425]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:10,548]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:13,468]\u001b[0m Trial 551 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:16,906]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:20,333]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:24,839]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:27,783]\u001b[0m Trial 559 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:30,340]\u001b[0m Trial 548 finished with value: 19.394412503608777 and parameters: {'n_hidden': 3, 'learning_rate': 0.01363490250309425, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022239842314095204, 'dropout_rate_Layer_2': 0.03252577000862772, 'dropout_rate_Layer_3': 0.014956977393198807, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014985640270926272, 'l1_Layer_2': 0.001817754034823545, 'l1_Layer_3': 0.006978297512331264, 'n_units_Layer_1': 145, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 541 with value: 19.227731267417223.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.39 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.32 | sMAPE for Test Set is: 28.57% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:58:31,706]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:34,178]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:34,794]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:39,069]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:39,220]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:39,258]\u001b[0m Trial 563 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.39 | sMAPE for Validation Set is: 23.14% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.35 | sMAPE for Test Set is: 27.30% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:58:45,351]\u001b[0m Trial 558 finished with value: 19.39246244678562 and parameters: {'n_hidden': 3, 'learning_rate': 0.014000223712618177, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022279438373096885, 'dropout_rate_Layer_2': 0.033175434019518314, 'dropout_rate_Layer_3': 0.012098072144267957, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016905637024627716, 'l1_Layer_2': 0.0019262869325332916, 'l1_Layer_3': 0.013193926876504423, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 235}. Best is trial 541 with value: 19.227731267417223.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:46,104]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:46,958]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:49,808]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:53,849]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:57,135]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:58:59,967]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:03,041]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:06,008]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:09,013]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:11,978]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:13,954]\u001b[0m Trial 568 finished with value: 18.79732114049476 and parameters: {'n_hidden': 3, 'learning_rate': 0.013846079835371226, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014516823965763554, 'dropout_rate_Layer_2': 0.03223957749265548, 'dropout_rate_Layer_3': 0.009760952937911304, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012463921870297366, 'l1_Layer_2': 0.0014874821446032845, 'l1_Layer_3': 0.008811093667534013, 'n_units_Layer_1': 145, 'n_units_Layer_2': 275, 'n_units_Layer_3': 235}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 48.75 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:59:17,284]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:19,227]\u001b[0m Trial 578 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:19,805]\u001b[0m Trial 572 finished with value: 19.47600690744221 and parameters: {'n_hidden': 3, 'learning_rate': 0.013141663563850582, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015893830971126836, 'dropout_rate_Layer_2': 0.02849141443939388, 'dropout_rate_Layer_3': 0.010274561957593622, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016745927361778626, 'l1_Layer_2': 0.0015867134663069256, 'l1_Layer_3': 0.012609858129352884, 'n_units_Layer_1': 155, 'n_units_Layer_2': 85, 'n_units_Layer_3': 235}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.48 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.43 | sMAPE for Test Set is: 28.29% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:59:23,121]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:27,921]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:33,598]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:36,186]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:36,576]\u001b[0m Trial 585 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.05 | sMAPE for Validation Set is: 23.62% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 49.76 | sMAPE for Test Set is: 28.26% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 06:59:38,507]\u001b[0m Trial 583 finished with value: 20.048632977843507 and parameters: {'n_hidden': 3, 'learning_rate': 0.017426603557469545, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014941527214031539, 'dropout_rate_Layer_2': 0.039810523334110226, 'dropout_rate_Layer_3': 0.023054043240752303, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019802562927890053, 'l1_Layer_2': 0.003557221935421687, 'l1_Layer_3': 0.01715099620352897, 'n_units_Layer_1': 155, 'n_units_Layer_2': 280, 'n_units_Layer_3': 250}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:40,257]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:44,442]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:44,645]\u001b[0m Trial 589 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:45,322]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:46,061]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:50,672]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:53,271]\u001b[0m Trial 592 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 06:59:57,522]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:01,437]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:03,362]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:04,551]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:07,226]\u001b[0m Trial 591 finished with value: 19.555351983298802 and parameters: {'n_hidden': 3, 'learning_rate': 0.016938561707304553, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007339681274207625, 'dropout_rate_Layer_2': 0.04320497182575874, 'dropout_rate_Layer_3': 0.039037953811881895, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010794392202746041, 'l1_Layer_2': 0.0019565773384144173, 'l1_Layer_3': 0.020254165011704454, 'n_units_Layer_1': 140, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.56 | sMAPE for Validation Set is: 23.33% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.82 | sMAPE for Test Set is: 28.75% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:00:07,823]\u001b[0m Trial 595 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:09,066]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:12,059]\u001b[0m Trial 598 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:15,102]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:17,061]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:18,084]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:19,394]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:24,272]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:24,485]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:28,875]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:29,212]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:34,392]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:39,013]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:43,392]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:48,425]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:51,388]\u001b[0m Trial 615 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:00:56,187]\u001b[0m Trial 601 finished with value: 19.748255268570656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0023542752981353748, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11592372625775181, 'dropout_rate_Layer_2': 0.019658157143586222, 'dropout_rate_Layer_3': 0.15069204816965306, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.158463279870504e-05, 'l1_Layer_2': 0.0001360756934164341, 'l1_Layer_3': 0.0009624249294021036, 'n_units_Layer_1': 185, 'n_units_Layer_2': 75, 'n_units_Layer_3': 215}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.75 | sMAPE for Validation Set is: 23.30% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.03 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:01:00,857]\u001b[0m Trial 613 finished with value: 19.25302879553656 and parameters: {'n_hidden': 3, 'learning_rate': 0.01097199508161282, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0020684331747543817, 'dropout_rate_Layer_2': 0.025236831352631668, 'dropout_rate_Layer_3': 0.017381379106753473, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.747938397239566e-05, 'l1_Layer_2': 0.0014001509706395153, 'l1_Layer_3': 0.018655032018794846, 'n_units_Layer_1': 135, 'n_units_Layer_2': 285, 'n_units_Layer_3': 215}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.25 | sMAPE for Validation Set is: 23.07% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.12 | sMAPE for Test Set is: 28.32% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:01:04,057]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:01:14,933]\u001b[0m Trial 616 finished with value: 19.590956523206426 and parameters: {'n_hidden': 3, 'learning_rate': 0.011185606901836082, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0015904484754850285, 'dropout_rate_Layer_2': 0.010734987548700121, 'dropout_rate_Layer_3': 0.018697058086751046, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017988201158187828, 'l1_Layer_2': 0.0011609183565133247, 'l1_Layer_3': 0.01718934564243335, 'n_units_Layer_1': 155, 'n_units_Layer_2': 285, 'n_units_Layer_3': 230}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.59 | sMAPE for Validation Set is: 23.08% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.10 | sMAPE for Test Set is: 28.11% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:01:21,269]\u001b[0m Trial 620 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:01:29,287]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:01:29,766]\u001b[0m Trial 617 finished with value: 19.56618537673848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014527909916925341, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11317452192983178, 'dropout_rate_Layer_2': 0.04479477142298252, 'dropout_rate_Layer_3': 0.16642302126218225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4648219858093534e-05, 'l1_Layer_2': 5.451669091039675e-05, 'l1_Layer_3': 0.0011575173851300067, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 140}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.57 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.21 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:01:33,952]\u001b[0m Trial 619 finished with value: 19.585852803277266 and parameters: {'n_hidden': 3, 'learning_rate': 0.00438260374297377, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1149140620076281, 'dropout_rate_Layer_2': 0.048461530387366863, 'dropout_rate_Layer_3': 0.16092543471051454, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9185838226551754e-05, 'l1_Layer_2': 0.0001271956806793091, 'l1_Layer_3': 5.791090001505412e-05, 'n_units_Layer_1': 195, 'n_units_Layer_2': 75, 'n_units_Layer_3': 170}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.59 | sMAPE for Validation Set is: 23.05% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.24 | sMAPE for Test Set is: 28.39% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:01:34,329]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.25 | sMAPE for Validation Set is: 22.91% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 60.88 | sMAPE for Test Set is: 30.84% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:01:37,355]\u001b[0m Trial 605 finished with value: 19.252162787753615 and parameters: {'n_hidden': 3, 'learning_rate': 0.00244198779655651, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11205671910404683, 'dropout_rate_Layer_2': 0.0181288073642683, 'dropout_rate_Layer_3': 0.16333237510859674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012211340262384415, 'l1_Layer_2': 0.00333639365793202, 'l1_Layer_3': 0.0012432574120920601, 'n_units_Layer_1': 105, 'n_units_Layer_2': 80, 'n_units_Layer_3': 215}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:01:39,809]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:01:41,330]\u001b[0m Trial 626 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:01:55,863]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:01,412]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:05,549]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:06,098]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:09,994]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:12,767]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:16,211]\u001b[0m Trial 634 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:18,925]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:24,814]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:31,128]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:34,239]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:35,375]\u001b[0m Trial 636 finished with value: 20.158895273736956 and parameters: {'n_hidden': 3, 'learning_rate': 0.013941979307835918, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01556886833624566, 'dropout_rate_Layer_2': 0.024453865123243955, 'dropout_rate_Layer_3': 0.01936503007643926, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013158759976541164, 'l1_Layer_2': 0.004613658309439802, 'l1_Layer_3': 0.018820679360607228, 'n_units_Layer_1': 155, 'n_units_Layer_2': 290, 'n_units_Layer_3': 215}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.16 | sMAPE for Validation Set is: 23.67% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 50.45 | sMAPE for Test Set is: 28.58% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:02:40,117]\u001b[0m Trial 629 finished with value: 19.226584282365646 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022262995903376535, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.198049452872632, 'dropout_rate_Layer_2': 0.21168495530584666, 'dropout_rate_Layer_3': 0.07204955286559375, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0030475395581058737, 'l1_Layer_2': 2.0574701075216757e-05, 'l1_Layer_3': 2.5677090501969e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 50, 'n_units_Layer_3': 155}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.23 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.27 | sMAPE for Test Set is: 29.10% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:02:47,165]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:50,339]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:55,172]\u001b[0m Trial 643 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:02:55,698]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:00,233]\u001b[0m Trial 632 finished with value: 19.493218943521356 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013661527376274084, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12160326836613211, 'dropout_rate_Layer_2': 0.059409462258179974, 'dropout_rate_Layer_3': 0.1606168991600509, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.02744454209027e-05, 'l1_Layer_2': 9.966887972868228e-05, 'l1_Layer_3': 6.244208921205068e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 55, 'n_units_Layer_3': 125}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.49 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.82 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:03:00,614]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:04,000]\u001b[0m Trial 644 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:07,177]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:08,988]\u001b[0m Trial 648 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:12,202]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:14,483]\u001b[0m Trial 640 finished with value: 19.34395668302432 and parameters: {'n_hidden': 3, 'learning_rate': 0.001512835991518163, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12187588291941104, 'dropout_rate_Layer_2': 0.06223521359238128, 'dropout_rate_Layer_3': 0.16561021127674727, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.553444006462143e-05, 'l1_Layer_2': 9.576159659920695e-05, 'l1_Layer_3': 6.761648126487154e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 125}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:14,543]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.34 | sMAPE for Validation Set is: 22.84% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.46 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:03:18,420]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:18,922]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:19,237]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:19,664]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:27,171]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:27,874]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:31,383]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:33,668]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:34,443]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:40,506]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:44,302]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:47,356]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:51,535]\u001b[0m Trial 656 finished with value: 19.548943690377353 and parameters: {'n_hidden': 3, 'learning_rate': 0.01206054742726018, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018198994888236075, 'dropout_rate_Layer_2': 0.0388913475345436, 'dropout_rate_Layer_3': 0.022838591724703122, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.691847011340701e-05, 'l1_Layer_2': 0.001470809180880693, 'l1_Layer_3': 0.019950888112736095, 'n_units_Layer_1': 150, 'n_units_Layer_2': 300, 'n_units_Layer_3': 230}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.55 | sMAPE for Validation Set is: 23.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.49 | sMAPE for Test Set is: 28.47% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:03:56,364]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:57,027]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:03:57,608]\u001b[0m Trial 662 finished with value: 20.367268492243145 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012326949368545962, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14977915464712208, 'dropout_rate_Layer_2': 0.050069610535186646, 'dropout_rate_Layer_3': 0.1732101631914725, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.143021710006973e-05, 'l1_Layer_2': 3.887639572779766e-05, 'l1_Layer_3': 5.982644409662561e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 55, 'n_units_Layer_3': 120}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.37 | sMAPE for Validation Set is: 23.70% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 65.78 | sMAPE for Test Set is: 32.61% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:04:03,128]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:06,568]\u001b[0m Trial 666 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:07,119]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:07,214]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:13,743]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:23,067]\u001b[0m Trial 672 finished with value: 20.376644061592927 and parameters: {'n_hidden': 3, 'learning_rate': 0.011927145811963354, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 1.663332033429582e-05, 'dropout_rate_Layer_2': 0.040048102872572, 'dropout_rate_Layer_3': 0.27809459179293816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.289862419607294e-05, 'l1_Layer_2': 0.002189226156969491, 'l1_Layer_3': 0.010797090287267821, 'n_units_Layer_1': 145, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.38 | sMAPE for Validation Set is: 23.68% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 51.92 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:04:27,870]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:28,421]\u001b[0m Trial 667 finished with value: 19.376555584868004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015828393667662866, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12956071038414024, 'dropout_rate_Layer_2': 0.10337529122325104, 'dropout_rate_Layer_3': 0.17309135092315292, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.777363211692202e-05, 'l1_Layer_2': 5.0479410291179214e-05, 'l1_Layer_3': 1.2997453202835606e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 140}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.38 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.75 | sMAPE for Test Set is: 29.35% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:04:34,781]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:37,504]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:38,482]\u001b[0m Trial 673 finished with value: 19.261310322968644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016462862231728687, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12668019748862688, 'dropout_rate_Layer_2': 0.11034394378452363, 'dropout_rate_Layer_3': 0.19371437005698655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.699145056120315e-05, 'l1_Layer_2': 1.633165331178451e-05, 'l1_Layer_3': 1.1044580032326402e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 75, 'n_units_Layer_3': 105}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.26 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.79 | sMAPE for Test Set is: 30.91% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:04:41,755]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:45,533]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:45,618]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:50,512]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:51,029]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:56,144]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:04:56,605]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:00,727]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:03,529]\u001b[0m Trial 684 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:05,153]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:07,212]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:09,546]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:29,221]\u001b[0m Trial 691 finished with value: 19.241430418809088 and parameters: {'n_hidden': 3, 'learning_rate': 0.015178693079646864, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028348178352791988, 'dropout_rate_Layer_2': 0.060117781365920185, 'dropout_rate_Layer_3': 0.00804318322606291, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011519830340507314, 'l1_Layer_2': 0.0027894691235993683, 'l1_Layer_3': 0.007626340663608467, 'n_units_Layer_1': 140, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.24 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 47.64 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:05:33,337]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:36,800]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:40,930]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:44,586]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:49,114]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:05:53,441]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:00,496]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:06,915]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:11,856]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:14,890]\u001b[0m Trial 692 finished with value: 19.272416314566907 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018251710539138205, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 6.123167326285272e-05, 'dropout_rate_Layer_2': 0.33811868353853763, 'dropout_rate_Layer_3': 0.2438112166677055, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.578579456956116e-05, 'l1_Layer_2': 0.01244434525729411, 'l1_Layer_3': 1.2355885050918578e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 210}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.27 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.63 | sMAPE for Test Set is: 27.92% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:06:16,831]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:20,043]\u001b[0m Trial 703 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:24,476]\u001b[0m Trial 682 finished with value: 18.803014587108567 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008886115381329945, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13379166012274846, 'dropout_rate_Layer_2': 0.11335389295811209, 'dropout_rate_Layer_3': 0.2193823505617281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9795413365862265e-05, 'l1_Layer_2': 1.140080603078745e-05, 'l1_Layer_3': 1.119985659496911e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:24,604]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 52.04 | sMAPE for Test Set is: 28.59% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:06:26,176]\u001b[0m Trial 687 finished with value: 19.504758294849648 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009031440936779037, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13443866566425497, 'dropout_rate_Layer_2': 0.11189592364620085, 'dropout_rate_Layer_3': 0.22081430210236186, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.9758942287535015e-05, 'l1_Layer_2': 1.0551350749482985e-05, 'l1_Layer_3': 1.1271575919178556e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 105}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.02 | sMAPE for Test Set is: 29.17% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:06:27,082]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:33,313]\u001b[0m Trial 707 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:34,089]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:39,293]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:44,121]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:47,237]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:47,808]\u001b[0m Trial 713 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:53,762]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:06:58,178]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:00,753]\u001b[0m Trial 708 finished with value: 19.0643825767643 and parameters: {'n_hidden': 3, 'learning_rate': 0.007910930067814634, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.016432139521562153, 'dropout_rate_Layer_2': 0.046338542824269635, 'dropout_rate_Layer_3': 0.006752317607122316, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020444872186350097, 'l1_Layer_2': 0.0014093605957716234, 'l1_Layer_3': 0.009118448474623524, 'n_units_Layer_1': 130, 'n_units_Layer_2': 75, 'n_units_Layer_3': 205}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.06 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.71 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:07:00,937]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:06,915]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:09,806]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:13,383]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:23,580]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:28,769]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:31,748]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:32,268]\u001b[0m Trial 718 finished with value: 19.0839758692951 and parameters: {'n_hidden': 3, 'learning_rate': 0.007431763031345751, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.029225425107387362, 'dropout_rate_Layer_2': 0.0435447248385292, 'dropout_rate_Layer_3': 0.006334568926093215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028953214794960033, 'l1_Layer_2': 0.0013687304332585207, 'l1_Layer_3': 0.005210889277074177, 'n_units_Layer_1': 125, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 22.28% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 48.56 | sMAPE for Test Set is: 27.43% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:07:39,130]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:44,284]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:47,652]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:51,638]\u001b[0m Trial 714 finished with value: 19.818119665627027 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006360851601577964, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17869836390091393, 'dropout_rate_Layer_2': 0.15491003713173146, 'dropout_rate_Layer_3': 0.19115258110184852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4536802710097857e-05, 'l1_Layer_2': 1.581668499290258e-05, 'l1_Layer_3': 1.7924076953455018e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 115, 'n_units_Layer_3': 100}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.82 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.60 | sMAPE for Test Set is: 29.12% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:07:57,502]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:07:58,514]\u001b[0m Trial 725 finished with value: 18.902878878622747 and parameters: {'n_hidden': 3, 'learning_rate': 0.00775988540342932, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007170873795901745, 'dropout_rate_Layer_2': 0.057265278215594156, 'dropout_rate_Layer_3': 0.015352122802770417, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023004899690625945, 'l1_Layer_2': 0.0012367763510542995, 'l1_Layer_3': 0.0089202839923591, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 51.32 | sMAPE for Test Set is: 28.34% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:08:02,259]\u001b[0m Trial 731 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:05,573]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:20,943]\u001b[0m Trial 730 finished with value: 18.965273887712087 and parameters: {'n_hidden': 3, 'learning_rate': 0.008290515525875009, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020341420838880908, 'dropout_rate_Layer_2': 0.030260849493661836, 'dropout_rate_Layer_3': 0.005816763117749329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016300202250997076, 'l1_Layer_2': 0.0019402790115523136, 'l1_Layer_3': 0.0059331810993218355, 'n_units_Layer_1': 130, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.97 | sMAPE for Validation Set is: 22.38% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.61 | sMAPE for Test Set is: 27.10% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:08:26,659]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:29,416]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:30,016]\u001b[0m Trial 733 finished with value: 19.197419319251065 and parameters: {'n_hidden': 3, 'learning_rate': 0.007519202744088224, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00650125349376969, 'dropout_rate_Layer_2': 0.04504928800547814, 'dropout_rate_Layer_3': 0.03239976996166269, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023603234767272924, 'l1_Layer_2': 0.0011816765995383179, 'l1_Layer_3': 0.009325842652937004, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.20 | sMAPE for Validation Set is: 22.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.61 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:08:34,413]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:36,490]\u001b[0m Trial 720 finished with value: 19.458598967114643 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005212141087192447, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18091101877051435, 'dropout_rate_Layer_2': 0.14966459627777468, 'dropout_rate_Layer_3': 0.1913609148755162, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4706321347520072e-05, 'l1_Layer_2': 1.7544963375005536e-05, 'l1_Layer_3': 2.0658484748907038e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 115, 'n_units_Layer_3': 105}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.46 | sMAPE for Validation Set is: 22.63% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 61.91 | sMAPE for Test Set is: 31.54% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:08:36,779]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:43,624]\u001b[0m Trial 740 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:44,086]\u001b[0m Trial 741 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:48,263]\u001b[0m Trial 742 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:48,635]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:54,266]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:08:58,815]\u001b[0m Trial 734 finished with value: 19.892166932811282 and parameters: {'n_hidden': 4, 'learning_rate': 0.0005050228573968785, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12514345735805055, 'dropout_rate_Layer_2': 0.098881035073584, 'dropout_rate_Layer_3': 0.21730469640426853, 'dropout_rate_Layer_4': 0.023993881322641936, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 6.627770604619769e-05, 'l1_Layer_2': 1.9304262349348697e-05, 'l1_Layer_3': 2.1476952290578627e-05, 'l1_Layer_4': 0.009059257085537483, 'n_units_Layer_1': 260, 'n_units_Layer_2': 60, 'n_units_Layer_3': 135, 'n_units_Layer_4': 215}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.89 | sMAPE for Validation Set is: 23.44% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.10 | sMAPE for Test Set is: 30.02% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:09:03,410]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:07,533]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:11,544]\u001b[0m Trial 749 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:14,108]\u001b[0m Trial 746 finished with value: 19.277916562054966 and parameters: {'n_hidden': 3, 'learning_rate': 0.007622308645519583, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0005841723175623453, 'dropout_rate_Layer_2': 0.05721321351882763, 'dropout_rate_Layer_3': 0.05055554328398875, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015203999403901736, 'l1_Layer_2': 0.0007804866596086155, 'l1_Layer_3': 0.011706837644379216, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.28 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.51 | sMAPE for Test Set is: 28.46% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:09:15,015]\u001b[0m Trial 745 finished with value: 19.291505336264215 and parameters: {'n_hidden': 3, 'learning_rate': 0.007651705201913615, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01861392333317231, 'dropout_rate_Layer_2': 0.05868467639358571, 'dropout_rate_Layer_3': 0.03962557234669302, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022462779484977322, 'l1_Layer_2': 0.001246091108364429, 'l1_Layer_3': 0.011579986814699447, 'n_units_Layer_1': 190, 'n_units_Layer_2': 80, 'n_units_Layer_3': 225}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.29 | sMAPE for Validation Set is: 22.93% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.21 | sMAPE for Test Set is: 29.00% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:09:20,095]\u001b[0m Trial 739 finished with value: 19.18121498963964 and parameters: {'n_hidden': 3, 'learning_rate': 0.007128594271948481, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007059723015239449, 'dropout_rate_Layer_2': 0.04523699493101089, 'dropout_rate_Layer_3': 0.03439129245529593, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00023085324246234064, 'l1_Layer_2': 0.000728144769753117, 'l1_Layer_3': 0.00963851396367498, 'n_units_Layer_1': 205, 'n_units_Layer_2': 75, 'n_units_Layer_3': 240}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.18 | sMAPE for Validation Set is: 22.42% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.59 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:09:20,601]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:22,786]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:27,436]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:27,887]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:32,740]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:36,687]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:41,034]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:46,359]\u001b[0m Trial 759 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:09:58,306]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:02,247]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:08,174]\u001b[0m Trial 763 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:20,981]\u001b[0m Trial 760 finished with value: 19.1173864570865 and parameters: {'n_hidden': 3, 'learning_rate': 0.007255624231509597, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00792322992078523, 'dropout_rate_Layer_2': 0.047060280894622004, 'dropout_rate_Layer_3': 0.041990890302341724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022652088858577692, 'l1_Layer_2': 0.0006522454579621411, 'l1_Layer_3': 0.012176449101721741, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.12 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.66 | sMAPE for Test Set is: 28.53% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:10:27,182]\u001b[0m Trial 765 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:30,787]\u001b[0m Trial 753 finished with value: 19.42572797559049 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009428947275589749, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15826006302990153, 'dropout_rate_Layer_2': 0.12025930082182584, 'dropout_rate_Layer_3': 0.23411228669549983, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.515836239824726e-05, 'l1_Layer_2': 2.6887888449246818e-05, 'l1_Layer_3': 1.0265897329047812e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 75}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.43 | sMAPE for Validation Set is: 22.85% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.50 | sMAPE for Test Set is: 29.34% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:10:36,914]\u001b[0m Trial 750 finished with value: 19.44907610865293 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009784040867961002, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21161418217375644, 'dropout_rate_Layer_2': 0.12406827431623454, 'dropout_rate_Layer_3': 0.18734056242093605, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.777273018282997e-05, 'l1_Layer_2': 1.5614846650475415e-05, 'l1_Layer_3': 1.1029414839615815e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.45 | sMAPE for Validation Set is: 22.65% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.81 | sMAPE for Test Set is: 29.23% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:10:39,288]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:42,368]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:44,159]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:46,465]\u001b[0m Trial 770 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:10:54,798]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:00,626]\u001b[0m Trial 768 finished with value: 19.14257335205429 and parameters: {'n_hidden': 3, 'learning_rate': 0.007054110287300397, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02153367613392719, 'dropout_rate_Layer_2': 0.04280002608510485, 'dropout_rate_Layer_3': 0.05273941859296939, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015224702973989625, 'l1_Layer_2': 0.0007671259623289627, 'l1_Layer_3': 0.009607615946683813, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 240}. Best is trial 568 with value: 18.79732114049476.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.14 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.88 | sMAPE for Test Set is: 28.64% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:11:19,027]\u001b[0m Trial 774 finished with value: 18.67042975127558 and parameters: {'n_hidden': 3, 'learning_rate': 0.007433949420684643, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.028594151907505506, 'dropout_rate_Layer_2': 0.07495724894227343, 'dropout_rate_Layer_3': 0.03883394569662042, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015207761821964624, 'l1_Layer_2': 0.00047787234179220436, 'l1_Layer_3': 0.007858547405353786, 'n_units_Layer_1': 215, 'n_units_Layer_2': 90, 'n_units_Layer_3': 245}. Best is trial 774 with value: 18.67042975127558.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.67 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 52.85 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:11:24,254]\u001b[0m Trial 773 finished with value: 18.4479187553308 and parameters: {'n_hidden': 3, 'learning_rate': 0.005451537977693456, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02786155709945562, 'dropout_rate_Layer_2': 0.04459402266374564, 'dropout_rate_Layer_3': 0.036895120491687264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000161373612653726, 'l1_Layer_2': 0.0006673884704428913, 'l1_Layer_3': 0.007697259675029842, 'n_units_Layer_1': 210, 'n_units_Layer_2': 90, 'n_units_Layer_3': 240}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.45 | sMAPE for Validation Set is: 21.89% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 47.85 | sMAPE for Test Set is: 27.14% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:11:28,151]\u001b[0m Trial 764 finished with value: 19.26902316525287 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008494140288344156, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15728532264651668, 'dropout_rate_Layer_2': 0.19068763231571986, 'dropout_rate_Layer_3': 0.24462628803046066, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4838638287640784e-05, 'l1_Layer_2': 3.018732920651695e-05, 'l1_Layer_3': 1.0695209965739172e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 70, 'n_units_Layer_3': 80}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.27 | sMAPE for Validation Set is: 22.83% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.25 | sMAPE for Test Set is: 30.32% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:11:33,300]\u001b[0m Trial 775 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:36,690]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:40,472]\u001b[0m Trial 779 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:44,032]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:44,435]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:49,413]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:52,711]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:53,047]\u001b[0m Trial 783 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:58,108]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:58,459]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:11:59,282]\u001b[0m Trial 784 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:03,845]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:05,459]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:07,450]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:08,963]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:09,784]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:13,991]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:19,811]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:40,026]\u001b[0m Trial 772 finished with value: 19.5980719382857 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008190198913776894, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.21668752784842482, 'dropout_rate_Layer_2': 0.12396682786584699, 'dropout_rate_Layer_3': 0.25057802544623525, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.531900659599344e-05, 'l1_Layer_2': 2.853381756543452e-05, 'l1_Layer_3': 1.1549286298518329e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 70, 'n_units_Layer_3': 65}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.60 | sMAPE for Validation Set is: 22.87% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.26 | sMAPE for Test Set is: 29.49% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:12:43,629]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:48,964]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:49,498]\u001b[0m Trial 795 finished with value: 20.589279611823002 and parameters: {'n_hidden': 3, 'learning_rate': 0.004265173586402684, 'batch_size': 21, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17713180215677882, 'dropout_rate_Layer_2': 0.1782386470930114, 'dropout_rate_Layer_3': 0.3439400559453606, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003411262571062979, 'l1_Layer_2': 9.080223948245096e-05, 'l1_Layer_3': 1.5252705770630956e-05, 'n_units_Layer_1': 100, 'n_units_Layer_2': 125, 'n_units_Layer_3': 235}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 24.47% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 60.21 | sMAPE for Test Set is: 31.30% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:12:55,222]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:12:58,539]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:09,091]\u001b[0m Trial 798 finished with value: 19.351437663942075 and parameters: {'n_hidden': 3, 'learning_rate': 0.008281518102757117, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01035200731959225, 'dropout_rate_Layer_2': 0.04408009931175486, 'dropout_rate_Layer_3': 0.03202176683260099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014128817342851378, 'l1_Layer_2': 0.0007155815388728732, 'l1_Layer_3': 0.008516860320312543, 'n_units_Layer_1': 200, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.35 | sMAPE for Validation Set is: 23.04% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 47.74 | sMAPE for Test Set is: 27.42% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:13:11,733]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:16,959]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:19,861]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:22,672]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:25,327]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:40,304]\u001b[0m Trial 807 finished with value: 19.109181905990983 and parameters: {'n_hidden': 3, 'learning_rate': 0.007851949742150095, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03113988298173297, 'dropout_rate_Layer_2': 0.043814323300802004, 'dropout_rate_Layer_3': 0.04343743275646919, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015390676368247456, 'l1_Layer_2': 0.0006876647473701187, 'l1_Layer_3': 0.009669560858490904, 'n_units_Layer_1': 195, 'n_units_Layer_2': 80, 'n_units_Layer_3': 240}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.11 | sMAPE for Validation Set is: 22.76% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 51.21 | sMAPE for Test Set is: 28.26% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:13:43,499]\u001b[0m Trial 793 finished with value: 18.91374459859823 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006787026644697074, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15973228903197192, 'dropout_rate_Layer_2': 0.19423632848409583, 'dropout_rate_Layer_3': 0.2515811606832281, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0678968965810732e-05, 'l1_Layer_2': 2.7910297507514384e-05, 'l1_Layer_3': 2.960639359061111e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 65}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.91 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.65 | sMAPE for Test Set is: 30.05% | rMAE for Test Set is: 0.65\n",
      "MAE for Validation Set is: 20.34 | sMAPE for Validation Set is: 23.72% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 56.24 | sMAPE for Test Set is: 30.18% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:13:43,598]\u001b[0m Trial 801 finished with value: 20.342029725630912 and parameters: {'n_hidden': 3, 'learning_rate': 0.0037248652570009725, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20941205646352148, 'dropout_rate_Layer_2': 0.27454070000448605, 'dropout_rate_Layer_3': 0.33009184505170003, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008094599605993645, 'l1_Layer_2': 0.00010923287513682729, 'l1_Layer_3': 2.423734711223888e-05, 'n_units_Layer_1': 140, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:13:50,972]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:03,161]\u001b[0m Trial 808 finished with value: 19.049436650881663 and parameters: {'n_hidden': 3, 'learning_rate': 0.005746038563399148, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012485907118501916, 'dropout_rate_Layer_2': 0.04644422921063478, 'dropout_rate_Layer_3': 0.0508901898372294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013340008700672693, 'l1_Layer_2': 0.000759475573160093, 'l1_Layer_3': 0.009572082225067087, 'n_units_Layer_1': 195, 'n_units_Layer_2': 70, 'n_units_Layer_3': 240}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.05 | sMAPE for Validation Set is: 22.53% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.09 | sMAPE for Test Set is: 28.54% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:14:06,567]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:10,215]\u001b[0m Trial 813 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:13,867]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:14,360]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:19,582]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:22,821]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:23,013]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:24,335]\u001b[0m Trial 792 finished with value: 19.297049893762367 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007497723048933219, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10088965358161338, 'dropout_rate_Layer_2': 0.1968155420446775, 'dropout_rate_Layer_3': 0.2522602693504011, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.094470585871695e-05, 'l1_Layer_2': 2.8453253795362456e-05, 'l1_Layer_3': 2.9430836717574642e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 80, 'n_units_Layer_3': 70}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.30 | sMAPE for Validation Set is: 22.75% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 63.92 | sMAPE for Test Set is: 31.59% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:14:30,610]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:31,375]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:34,767]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:44,049]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:44,427]\u001b[0m Trial 810 finished with value: 19.466406950375944 and parameters: {'n_hidden': 3, 'learning_rate': 0.001843997753824492, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12065798611551352, 'dropout_rate_Layer_2': 0.0027974136782975088, 'dropout_rate_Layer_3': 0.09023905545276031, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6628537496753154e-05, 'l1_Layer_2': 0.00764608003411174, 'l1_Layer_3': 0.00016845297605352908, 'n_units_Layer_1': 300, 'n_units_Layer_2': 95, 'n_units_Layer_3': 185}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.47 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 53.89 | sMAPE for Test Set is: 29.21% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:14:45,432]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:14:49,870]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:01,858]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:16,831]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:19,806]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:20,643]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:20,861]\u001b[0m Trial 826 finished with value: 20.14055500223012 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024306158888858613, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2594544422371026, 'dropout_rate_Layer_2': 0.29510253671838144, 'dropout_rate_Layer_3': 0.3636332780857929, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0019153544997777769, 'l1_Layer_2': 0.00018658517720574182, 'l1_Layer_3': 1.6713851330965448e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 140, 'n_units_Layer_3': 230}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.14 | sMAPE for Validation Set is: 23.68% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 53.40 | sMAPE for Test Set is: 29.29% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:15:29,476]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:29,846]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:34,113]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:37,587]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:40,727]\u001b[0m Trial 833 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:44,973]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:48,096]\u001b[0m Trial 835 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:15:55,063]\u001b[0m Trial 832 finished with value: 19.421655695901446 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006337814750863217, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.142151118632091, 'dropout_rate_Layer_2': 0.18987876542425758, 'dropout_rate_Layer_3': 0.2775436585875308, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.735338116715746e-05, 'l1_Layer_2': 3.266981624292706e-05, 'l1_Layer_3': 1.6104883871903003e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.42 | sMAPE for Validation Set is: 22.67% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 60.56 | sMAPE for Test Set is: 31.18% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:15:58,132]\u001b[0m Trial 840 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:01,852]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:05,090]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:08,645]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:11,883]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:17,636]\u001b[0m Trial 837 finished with value: 19.4844303151782 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006222309165919876, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35851319468296905, 'dropout_rate_Layer_2': 0.23451546205195653, 'dropout_rate_Layer_3': 0.2737994801514637, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0696224730751292e-05, 'l1_Layer_2': 3.837253395637052e-05, 'l1_Layer_3': 4.350322221148984e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 90}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.48 | sMAPE for Validation Set is: 22.70% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.80 | sMAPE for Test Set is: 30.91% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:16:20,663]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:21,516]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:29,428]\u001b[0m Trial 838 finished with value: 19.405192991472934 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007033390667492332, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.35465590153183124, 'dropout_rate_Layer_2': 0.18504436730106244, 'dropout_rate_Layer_3': 0.2848557243920084, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.256563628306569e-05, 'l1_Layer_2': 7.404440733289308e-05, 'l1_Layer_3': 1.659392086506311e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 85}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.41 | sMAPE for Validation Set is: 22.80% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 59.89 | sMAPE for Test Set is: 30.73% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:16:32,387]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:34,769]\u001b[0m Trial 848 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:35,769]\u001b[0m Trial 850 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:36,962]\u001b[0m Trial 849 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:37,617]\u001b[0m Trial 839 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:38,128]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:41,700]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:42,905]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:44,099]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:45,943]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:49,859]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:50,967]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:51,380]\u001b[0m Trial 857 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:16:57,162]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:00,297]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:00,560]\u001b[0m Trial 861 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:04,965]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:08,640]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:16,112]\u001b[0m Trial 862 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:16,820]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:24,185]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:24,509]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:29,105]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:31,412]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:32,166]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:37,791]\u001b[0m Trial 873 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:38,862]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:42,287]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:42,658]\u001b[0m Trial 868 finished with value: 19.027462880204624 and parameters: {'n_hidden': 3, 'learning_rate': 0.006915283073039513, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009694867011216288, 'dropout_rate_Layer_2': 0.02201449821437102, 'dropout_rate_Layer_3': 0.012705076707293282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015403801882634777, 'l1_Layer_2': 0.0008185517966801867, 'l1_Layer_3': 0.005986797729573524, 'n_units_Layer_1': 210, 'n_units_Layer_2': 90, 'n_units_Layer_3': 220}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.03 | sMAPE for Validation Set is: 22.62% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 51.73 | sMAPE for Test Set is: 28.36% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:17:45,315]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:46,807]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:47,360]\u001b[0m Trial 877 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:47,514]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:53,252]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:55,569]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:58,113]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:17:58,673]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:03,443]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:06,683]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:06,722]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:12,929]\u001b[0m Trial 886 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:17,303]\u001b[0m Trial 880 finished with value: 18.970512186091263 and parameters: {'n_hidden': 3, 'learning_rate': 0.00674759544887793, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017897781922240383, 'dropout_rate_Layer_2': 0.021059248140270062, 'dropout_rate_Layer_3': 0.055054996902663196, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001622388571035782, 'l1_Layer_2': 0.0005662724931226996, 'l1_Layer_3': 0.014010465642621046, 'n_units_Layer_1': 180, 'n_units_Layer_2': 85, 'n_units_Layer_3': 230}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.97 | sMAPE for Validation Set is: 22.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.03 | sMAPE for Test Set is: 27.57% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:18:17,826]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:22,458]\u001b[0m Trial 891 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:22,688]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:22,965]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:29,406]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:30,166]\u001b[0m Trial 888 finished with value: 19.21140951418288 and parameters: {'n_hidden': 3, 'learning_rate': 0.007561916897116838, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026728799079496247, 'dropout_rate_Layer_2': 0.028701815356865158, 'dropout_rate_Layer_3': 0.00779431734256458, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013404878641058642, 'l1_Layer_2': 0.0007657813518647144, 'l1_Layer_3': 0.009430186930777377, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 250}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.21 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.53 | sMAPE for Test Set is: 28.21% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:18:36,304]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:36,480]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:36,663]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:41,962]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:43,764]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:43,906]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:46,692]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:50,623]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:53,508]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:18:53,961]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:03,853]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:07,746]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:20,294]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:23,236]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:27,386]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:31,373]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:37,505]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:39,785]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:41,418]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:48,612]\u001b[0m Trial 907 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:55,318]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:19:58,612]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:01,693]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:04,704]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:07,617]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:10,457]\u001b[0m Trial 922 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:16,311]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:18,888]\u001b[0m Trial 915 finished with value: 19.502899781320128 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033775878744337776, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19199338028892243, 'dropout_rate_Layer_2': 0.16518194661308633, 'dropout_rate_Layer_3': 0.3450261434061941, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025537704961883377, 'l1_Layer_2': 0.00010598720889627772, 'l1_Layer_3': 1.19604164913811e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 200, 'n_units_Layer_3': 180}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 23.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 55.10 | sMAPE for Test Set is: 29.49% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:20:19,408]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:23,301]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:27,021]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:27,874]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:30,993]\u001b[0m Trial 928 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:31,895]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:33,613]\u001b[0m Trial 919 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:38,555]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:40,394]\u001b[0m Trial 932 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:40,882]\u001b[0m Trial 931 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:45,757]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:51,596]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:20:54,893]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:02,139]\u001b[0m Trial 938 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:04,596]\u001b[0m Trial 933 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:07,768]\u001b[0m Trial 935 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:10,547]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:11,584]\u001b[0m Trial 940 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:11,585]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:13,306]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:18,841]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:20,499]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:20,696]\u001b[0m Trial 943 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:21,677]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:25,228]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:28,084]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:34,322]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:36,931]\u001b[0m Trial 947 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:36,961]\u001b[0m Trial 951 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:37,440]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:41,314]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:44,627]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:45,304]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:47,620]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:49,213]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:51,029]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:54,530]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:56,058]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:21:58,888]\u001b[0m Trial 962 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:01,824]\u001b[0m Trial 963 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:05,652]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:08,889]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:11,411]\u001b[0m Trial 964 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:11,451]\u001b[0m Trial 961 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:15,955]\u001b[0m Trial 967 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:19,291]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:24,945]\u001b[0m Trial 953 finished with value: 19.9167030439136 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013242343605362448, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23130407872553344, 'dropout_rate_Layer_2': 0.28797442744671553, 'dropout_rate_Layer_3': 0.35255562079267533, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008846191378121272, 'l1_Layer_2': 0.00012218974632939326, 'l1_Layer_3': 1.2378136816765657e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 120, 'n_units_Layer_3': 245}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.92 | sMAPE for Validation Set is: 23.35% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 56.29 | sMAPE for Test Set is: 30.08% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:22:28,529]\u001b[0m Trial 972 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:28,919]\u001b[0m Trial 968 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:33,375]\u001b[0m Trial 973 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:37,675]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:41,240]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:44,886]\u001b[0m Trial 977 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:45,004]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:45,942]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:51,718]\u001b[0m Trial 979 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:54,823]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:55,448]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.59 | sMAPE for Validation Set is: 23.99% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 56.15 | sMAPE for Test Set is: 30.34% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:22:58,141]\u001b[0m Trial 969 finished with value: 20.589896512279633 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031856838588900727, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.23353975259977428, 'dropout_rate_Layer_2': 0.3080396052996717, 'dropout_rate_Layer_3': 0.36813074843606103, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000979468137300043, 'l1_Layer_2': 0.0001067108807029263, 'l1_Layer_3': 1.2286489258791284e-05, 'n_units_Layer_1': 150, 'n_units_Layer_2': 50, 'n_units_Layer_3': 270}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:58,842]\u001b[0m Trial 980 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:22:59,939]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:00,992]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:04,297]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:06,167]\u001b[0m Trial 985 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:07,661]\u001b[0m Trial 986 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:13,728]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:14,528]\u001b[0m Trial 990 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:17,857]\u001b[0m Trial 991 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:18,121]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:18,868]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:24,354]\u001b[0m Trial 993 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:26,206]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:28,903]\u001b[0m Trial 996 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:30,004]\u001b[0m Trial 997 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:32,994]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:34,833]\u001b[0m Trial 995 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:35,015]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:41,040]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:41,590]\u001b[0m Trial 1002 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:46,398]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:49,185]\u001b[0m Trial 1003 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:53,768]\u001b[0m Trial 1006 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:23:54,166]\u001b[0m Trial 989 finished with value: 19.921746086020793 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015104746900520038, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1946342681828085, 'dropout_rate_Layer_2': 0.24510368415303962, 'dropout_rate_Layer_3': 0.09024831713538689, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001577992774417602, 'l1_Layer_2': 4.719575548693479e-05, 'l1_Layer_3': 1.74396055086344e-05, 'n_units_Layer_1': 105, 'n_units_Layer_2': 240, 'n_units_Layer_3': 160}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.92 | sMAPE for Validation Set is: 23.33% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 51.68 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:23:58,341]\u001b[0m Trial 1005 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:00,428]\u001b[0m Trial 1008 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:00,685]\u001b[0m Trial 1001 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:00,898]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:08,637]\u001b[0m Trial 1011 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:09,957]\u001b[0m Trial 1010 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:11,925]\u001b[0m Trial 1012 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:16,282]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:20,320]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:20,370]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:26,825]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:32,329]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:36,374]\u001b[0m Trial 1018 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:39,100]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:42,358]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:43,153]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:45,971]\u001b[0m Trial 1009 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:48,228]\u001b[0m Trial 1013 finished with value: 18.756017602541707 and parameters: {'n_hidden': 3, 'learning_rate': 0.008340438685721801, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009570884065258503, 'dropout_rate_Layer_2': 0.0430515351880268, 'dropout_rate_Layer_3': 0.013964903370782211, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019862875193805125, 'l1_Layer_2': 0.00047942199603177583, 'l1_Layer_3': 0.006928065358928497, 'n_units_Layer_1': 210, 'n_units_Layer_2': 80, 'n_units_Layer_3': 245}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.76 | sMAPE for Validation Set is: 22.40% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.91 | sMAPE for Test Set is: 27.89% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:24:49,244]\u001b[0m Trial 1023 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:49,504]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:54,917]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:58,751]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:59,258]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:24:59,619]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:03,076]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:08,825]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:10,885]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:11,547]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:16,680]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:17,208]\u001b[0m Trial 1036 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:22,182]\u001b[0m Trial 1037 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:22,752]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:22,921]\u001b[0m Trial 1034 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:29,461]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:29,805]\u001b[0m Trial 1031 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:29,851]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:30,067]\u001b[0m Trial 1040 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:39,290]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:40,858]\u001b[0m Trial 1043 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:43,241]\u001b[0m Trial 1042 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:43,651]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:46,754]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:50,152]\u001b[0m Trial 1048 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:51,625]\u001b[0m Trial 1049 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:53,417]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:55,994]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:57,213]\u001b[0m Trial 1051 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:25:59,168]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:01,654]\u001b[0m Trial 1053 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:08,753]\u001b[0m Trial 1055 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:10,837]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:10,903]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:12,144]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:12,702]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:22,239]\u001b[0m Trial 1062 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:28,432]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:30,553]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:33,176]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:36,696]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:36,972]\u001b[0m Trial 1060 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:41,855]\u001b[0m Trial 1067 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:43,679]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:48,574]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:49,073]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:53,988]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:54,698]\u001b[0m Trial 1072 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:58,709]\u001b[0m Trial 1073 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:26:58,925]\u001b[0m Trial 1065 finished with value: 19.071960396243316 and parameters: {'n_hidden': 3, 'learning_rate': 0.00707818812584708, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.035159811950225606, 'dropout_rate_Layer_2': 0.013427644820934906, 'dropout_rate_Layer_3': 0.021878574539768873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012178160263029158, 'l1_Layer_2': 0.0011054722511162224, 'l1_Layer_3': 0.007677231652588326, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.07 | sMAPE for Validation Set is: 22.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.57 | sMAPE for Test Set is: 28.24% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:27:07,165]\u001b[0m Trial 1075 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:07,684]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:12,679]\u001b[0m Trial 1077 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:13,857]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:17,415]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:19,446]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:24,521]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:24,561]\u001b[0m Trial 1082 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:30,781]\u001b[0m Trial 1083 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:31,025]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:36,709]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:40,305]\u001b[0m Trial 1087 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:43,813]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:46,759]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:50,824]\u001b[0m Trial 1090 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:54,992]\u001b[0m Trial 1089 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:27:55,181]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:01,041]\u001b[0m Trial 1093 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:07,063]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:07,491]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:12,761]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:13,167]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:13,763]\u001b[0m Trial 1061 finished with value: 18.927625415271333 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012060280986315416, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17024139327217772, 'dropout_rate_Layer_2': 0.1361146201690546, 'dropout_rate_Layer_3': 0.20985104453043524, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3242844827231572e-05, 'l1_Layer_2': 1.883635289346152e-05, 'l1_Layer_3': 4.210502955566434e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 80, 'n_units_Layer_3': 50}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 54.72 | sMAPE for Test Set is: 29.45% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:28:20,672]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:21,413]\u001b[0m Trial 1099 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:23,906]\u001b[0m Trial 1098 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:28,712]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:30,839]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:34,022]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:34,309]\u001b[0m Trial 1104 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:39,756]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:39,866]\u001b[0m Trial 1074 finished with value: 19.096582365406736 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011565037958027552, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17538535559831114, 'dropout_rate_Layer_2': 0.1675214102979138, 'dropout_rate_Layer_3': 0.20975621859120253, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.751470469949903e-05, 'l1_Layer_2': 2.13056352754312e-05, 'l1_Layer_3': 0.0001049265304480836, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 130}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.10 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 62.50 | sMAPE for Test Set is: 31.37% | rMAE for Test Set is: 0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:28:48,001]\u001b[0m Trial 1105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:28:57,138]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:02,225]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:04,549]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:06,169]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:09,461]\u001b[0m Trial 1112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:12,494]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:13,681]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:19,382]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:19,938]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:22,172]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:27,838]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:30,630]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:31,809]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:32,740]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:40,690]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:44,027]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:47,299]\u001b[0m Trial 1121 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:51,424]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:29:57,480]\u001b[0m Trial 1127 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:00,837]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:07,387]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:09,713]\u001b[0m Trial 1122 finished with value: 18.858020002428493 and parameters: {'n_hidden': 3, 'learning_rate': 0.008113520822856898, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019011372579804914, 'dropout_rate_Layer_2': 0.04089571057949641, 'dropout_rate_Layer_3': 0.020604700747400156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002725421943613948, 'l1_Layer_2': 0.0012710589939783227, 'l1_Layer_3': 0.011686950759917623, 'n_units_Layer_1': 200, 'n_units_Layer_2': 95, 'n_units_Layer_3': 235}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.86 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.31 | sMAPE for Test Set is: 27.64% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:30:13,731]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:16,093]\u001b[0m Trial 1131 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:19,608]\u001b[0m Trial 1107 finished with value: 19.49309511790562 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012121856664797353, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17322542531173285, 'dropout_rate_Layer_2': 0.1647056595010981, 'dropout_rate_Layer_3': 0.23995404243793808, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3884889303900205e-05, 'l1_Layer_2': 1.327053804645885e-05, 'l1_Layer_3': 0.00010085004973503003, 'n_units_Layer_1': 180, 'n_units_Layer_2': 90, 'n_units_Layer_3': 50}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.49 | sMAPE for Validation Set is: 23.00% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.40 | sMAPE for Test Set is: 29.42% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:30:23,906]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:46,638]\u001b[0m Trial 1132 finished with value: 20.68712274051967 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027565432608762327, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22013685915975695, 'dropout_rate_Layer_2': 0.2713960830808728, 'dropout_rate_Layer_3': 0.331054610329175, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007972174608323918, 'l1_Layer_2': 0.00012172517362448472, 'l1_Layer_3': 1.630189473998215e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 120, 'n_units_Layer_3': 225}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.69 | sMAPE for Validation Set is: 24.33% | rMAE for Validation Set is: 0.66\n",
      "MAE for Test Set is: 61.36 | sMAPE for Test Set is: 31.54% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:30:51,025]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:54,646]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:58,836]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:30:59,209]\u001b[0m Trial 1133 finished with value: 20.40927814811371 and parameters: {'n_hidden': 3, 'learning_rate': 0.00273607023752203, 'batch_size': 28, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.21876095886607178, 'dropout_rate_Layer_2': 0.2700412069704014, 'dropout_rate_Layer_3': 0.3587781418086225, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008263488975278164, 'l1_Layer_2': 0.00014103534072967667, 'l1_Layer_3': 1.5204756085669673e-05, 'n_units_Layer_1': 130, 'n_units_Layer_2': 140, 'n_units_Layer_3': 215}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.41 | sMAPE for Validation Set is: 23.83% | rMAE for Validation Set is: 0.65\n",
      "MAE for Test Set is: 54.97 | sMAPE for Test Set is: 29.96% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:31:04,576]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:07,491]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:11,789]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:15,519]\u001b[0m Trial 1141 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:17,978]\u001b[0m Trial 1125 finished with value: 19.763052253760332 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011920951250792757, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.3976094044565172, 'dropout_rate_Layer_2': 0.14136090387430852, 'dropout_rate_Layer_3': 0.2426599047614387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2995185585629884e-05, 'l1_Layer_2': 1.4207926020478093e-05, 'l1_Layer_3': 0.00010051548916152663, 'n_units_Layer_1': 180, 'n_units_Layer_2': 90, 'n_units_Layer_3': 55}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.76 | sMAPE for Validation Set is: 22.92% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 57.13 | sMAPE for Test Set is: 30.29% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:31:19,847]\u001b[0m Trial 1143 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:20,274]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:21,780]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:27,413]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:27,991]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:30,332]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:36,101]\u001b[0m Trial 1149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:36,772]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:37,484]\u001b[0m Trial 1135 finished with value: 19.503185532715595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010759084242873635, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19208849292161448, 'dropout_rate_Layer_2': 0.20444889126026478, 'dropout_rate_Layer_3': 0.21044080133123563, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.532381229175532e-05, 'l1_Layer_2': 1.963243134770614e-05, 'l1_Layer_3': 3.9396392246269265e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 85, 'n_units_Layer_3': 65}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.50 | sMAPE for Validation Set is: 22.94% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.74 | sMAPE for Test Set is: 28.72% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:31:43,509]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:45,796]\u001b[0m Trial 1154 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:48,451]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:50,899]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:52,787]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:57,285]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:31:57,598]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:07,299]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:11,159]\u001b[0m Trial 1162 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:14,918]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:18,613]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:22,488]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:23,981]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:28,841]\u001b[0m Trial 1167 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:32,386]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:36,699]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:40,982]\u001b[0m Trial 1151 finished with value: 19.596433284413106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010790118812703906, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16188987678259986, 'dropout_rate_Layer_2': 0.2043056029266071, 'dropout_rate_Layer_3': 0.20953158605671013, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.3522223869405e-05, 'l1_Layer_2': 1.0384771864193786e-05, 'l1_Layer_3': 0.00015397060927728405, 'n_units_Layer_1': 245, 'n_units_Layer_2': 80, 'n_units_Layer_3': 70}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.60 | sMAPE for Validation Set is: 22.68% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 58.93 | sMAPE for Test Set is: 31.03% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:32:43,572]\u001b[0m Trial 1170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:48,613]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:53,886]\u001b[0m Trial 1173 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:55,237]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:32:58,893]\u001b[0m Trial 1174 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:01,567]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:02,904]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:06,386]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:09,071]\u001b[0m Trial 1178 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:10,193]\u001b[0m Trial 1168 finished with value: 19.089155385756182 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021485142245353667, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.193119327228138, 'dropout_rate_Layer_2': 0.29697518388723054, 'dropout_rate_Layer_3': 0.379330472166988, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003294970715604237, 'l1_Layer_2': 0.0011086146734808435, 'l1_Layer_3': 2.050163843997105e-05, 'n_units_Layer_1': 95, 'n_units_Layer_2': 190, 'n_units_Layer_3': 150}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.09 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.00 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:33:11,145]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:14,768]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:18,408]\u001b[0m Trial 1180 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:18,601]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:24,944]\u001b[0m Trial 1185 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:34,449]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:41,171]\u001b[0m Trial 1184 finished with value: 19.39229391929602 and parameters: {'n_hidden': 3, 'learning_rate': 0.008709979303090499, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006250367018382588, 'dropout_rate_Layer_2': 0.05018468114940973, 'dropout_rate_Layer_3': 0.03912396035570354, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010225817520375848, 'l1_Layer_2': 0.0014205007616197014, 'l1_Layer_3': 0.006550498711408783, 'n_units_Layer_1': 120, 'n_units_Layer_2': 70, 'n_units_Layer_3': 230}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.39 | sMAPE for Validation Set is: 22.88% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 50.24 | sMAPE for Test Set is: 28.26% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:33:43,163]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:45,842]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:47,735]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:50,180]\u001b[0m Trial 1186 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:55,781]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:33:57,930]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:01,237]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:02,086]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:02,937]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:05,451]\u001b[0m Trial 1182 finished with value: 18.993768781217117 and parameters: {'n_hidden': 3, 'learning_rate': 0.002072291859685594, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19563609846504804, 'dropout_rate_Layer_2': 0.2949618601193258, 'dropout_rate_Layer_3': 0.3885743211115069, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037871347526502306, 'l1_Layer_2': 0.00042878252903137616, 'l1_Layer_3': 2.163176469054226e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.99 | sMAPE for Validation Set is: 22.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 48.58 | sMAPE for Test Set is: 27.55% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:34:05,872]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:10,283]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:12,791]\u001b[0m Trial 1197 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:15,841]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:22,463]\u001b[0m Trial 1201 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:25,845]\u001b[0m Trial 1203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:29,283]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:33,606]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:37,370]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:40,664]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:44,221]\u001b[0m Trial 1199 finished with value: 19.199461761689165 and parameters: {'n_hidden': 3, 'learning_rate': 0.010522758336926149, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013755235072567344, 'dropout_rate_Layer_2': 0.04010025782563682, 'dropout_rate_Layer_3': 0.01783872487981191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002643572399715594, 'l1_Layer_2': 0.0005201598663967592, 'l1_Layer_3': 0.008202955693588053, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 220}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.20 | sMAPE for Validation Set is: 22.82% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.78 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:34:48,928]\u001b[0m Trial 1209 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:49,849]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:54,583]\u001b[0m Trial 1211 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:34:54,840]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:02,922]\u001b[0m Trial 1213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:06,913]\u001b[0m Trial 1202 finished with value: 18.895569956594144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014535999470504438, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19182889209884474, 'dropout_rate_Layer_2': 0.31748837063335644, 'dropout_rate_Layer_3': 0.3907027833280041, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029359861312892784, 'l1_Layer_2': 0.0007395800733517862, 'l1_Layer_3': 2.3947118451026012e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 210, 'n_units_Layer_3': 135}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 22.28% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.76 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:35:11,201]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:11,812]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.13 | sMAPE for Validation Set is: 22.51% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.31 | sMAPE for Test Set is: 28.81% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:35:16,103]\u001b[0m Trial 1208 finished with value: 19.125330119722936 and parameters: {'n_hidden': 3, 'learning_rate': 0.010207474538999091, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013639010302120343, 'dropout_rate_Layer_2': 0.04220486608951206, 'dropout_rate_Layer_3': 0.0202659978920961, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025221082383372547, 'l1_Layer_2': 0.0008268383345876802, 'l1_Layer_3': 0.007844114396624509, 'n_units_Layer_1': 200, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:16,959]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:18,422]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:19,522]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:21,742]\u001b[0m Trial 1218 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:24,730]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:29,817]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:31,500]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:32,489]\u001b[0m Trial 1222 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:34,276]\u001b[0m Trial 1223 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:36,700]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:43,935]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:44,411]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:44,891]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:52,285]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:52,397]\u001b[0m Trial 1231 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:35:52,875]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:00,818]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:03,120]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:06,300]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:10,589]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:10,760]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:23,337]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:26,010]\u001b[0m Trial 1233 finished with value: 19.041668107992447 and parameters: {'n_hidden': 3, 'learning_rate': 0.009902920953394328, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026653720781918286, 'dropout_rate_Layer_2': 0.03778067268573204, 'dropout_rate_Layer_3': 0.018310081474613306, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00031771097569811824, 'l1_Layer_2': 0.0006507276802939325, 'l1_Layer_3': 0.006322765930601071, 'n_units_Layer_1': 205, 'n_units_Layer_2': 85, 'n_units_Layer_3': 245}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.04 | sMAPE for Validation Set is: 22.72% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.47 | sMAPE for Test Set is: 27.76% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:36:30,137]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:30,515]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:37,247]\u001b[0m Trial 1242 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:37,841]\u001b[0m Trial 1225 finished with value: 18.701735232005408 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014355493710372872, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19059762670888938, 'dropout_rate_Layer_2': 0.3189820758764712, 'dropout_rate_Layer_3': 0.39334106632982446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0003036966003812879, 'l1_Layer_2': 0.0012622227132774032, 'l1_Layer_3': 2.333869778307428e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 120}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.70 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 51.09 | sMAPE for Test Set is: 28.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:36:38,141]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:48,725]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:49,031]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:53,207]\u001b[0m Trial 1239 finished with value: 18.91935428892656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014479978245724827, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1928198320020745, 'dropout_rate_Layer_2': 0.31345313644024464, 'dropout_rate_Layer_3': 0.3973954545076031, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029118885774457595, 'l1_Layer_2': 0.0007618605422554165, 'l1_Layer_3': 1.9413907892474337e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 220, 'n_units_Layer_3': 110}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.92 | sMAPE for Validation Set is: 22.10% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 52.03 | sMAPE for Test Set is: 28.84% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:36:55,593]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:36:57,656]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:00,279]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:03,033]\u001b[0m Trial 1251 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:03,603]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:04,102]\u001b[0m Trial 1250 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:09,291]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:12,265]\u001b[0m Trial 1254 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:12,881]\u001b[0m Trial 1255 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:13,088]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:18,809]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:18,953]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:24,380]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:24,782]\u001b[0m Trial 1258 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:26,783]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:27,296]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:35,110]\u001b[0m Trial 1262 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:37,297]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:38,004]\u001b[0m Trial 1265 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:40,707]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:42,742]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:48,135]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:49,799]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:53,328]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:37:58,229]\u001b[0m Trial 1264 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:01,760]\u001b[0m Trial 1274 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:04,998]\u001b[0m Trial 1275 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:09,349]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:09,672]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:14,662]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:19,284]\u001b[0m Trial 1272 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:19,871]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:24,749]\u001b[0m Trial 1280 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:25,791]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:31,483]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:34,692]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:39,856]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:47,965]\u001b[0m Trial 1273 finished with value: 19.021109750159848 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014952423099016331, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20652387025894112, 'dropout_rate_Layer_2': 0.3180331868613651, 'dropout_rate_Layer_3': 0.3982091295301743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00025693211367748206, 'l1_Layer_2': 0.0012617755126306997, 'l1_Layer_3': 1.839588243364074e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 240, 'n_units_Layer_3': 120}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.02 | sMAPE for Validation Set is: 22.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.80 | sMAPE for Test Set is: 28.19% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:38:51,411]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:38:54,895]\u001b[0m Trial 1288 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:08,543]\u001b[0m Trial 1277 finished with value: 19.220692382988762 and parameters: {'n_hidden': 3, 'learning_rate': 0.002021453744169665, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12365969453561504, 'dropout_rate_Layer_2': 0.07575851864603715, 'dropout_rate_Layer_3': 0.17875365544415966, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.0873918806404285e-05, 'l1_Layer_2': 6.56821872093759e-05, 'l1_Layer_3': 1.9049891063546882e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 75, 'n_units_Layer_3': 150}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.22 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 60.86 | sMAPE for Test Set is: 31.00% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:39:12,239]\u001b[0m Trial 1286 finished with value: 18.813302629373315 and parameters: {'n_hidden': 3, 'learning_rate': 0.006917183871004133, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012950767715333704, 'dropout_rate_Layer_2': 0.007190805284385669, 'dropout_rate_Layer_3': 0.019771704310771215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012573110174945288, 'l1_Layer_2': 0.0006125596003743648, 'l1_Layer_3': 0.006877006831332695, 'n_units_Layer_1': 200, 'n_units_Layer_2': 65, 'n_units_Layer_3': 240}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.81 | sMAPE for Validation Set is: 22.20% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.80 | sMAPE for Test Set is: 27.26% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:39:16,237]\u001b[0m Trial 1291 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:20,740]\u001b[0m Trial 1284 finished with value: 18.85765141494669 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014106478908770678, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20532303104060817, 'dropout_rate_Layer_2': 0.30228067891697036, 'dropout_rate_Layer_3': 0.39783932568140595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00027094989930135434, 'l1_Layer_2': 0.0010601744090119839, 'l1_Layer_3': 1.8552546264300824e-05, 'n_units_Layer_1': 80, 'n_units_Layer_2': 235, 'n_units_Layer_3': 105}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.86 | sMAPE for Validation Set is: 22.05% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.00 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:39:27,556]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:31,743]\u001b[0m Trial 1293 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:35,456]\u001b[0m Trial 1295 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:37,818]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:40,434]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:44,467]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:47,717]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:53,773]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:39:56,287]\u001b[0m Trial 1289 finished with value: 19.313255349395998 and parameters: {'n_hidden': 3, 'learning_rate': 0.002353822825587822, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12777495319519128, 'dropout_rate_Layer_2': 0.07417434682292236, 'dropout_rate_Layer_3': 0.15109077176173225, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.337670654683584e-05, 'l1_Layer_2': 4.57173372246402e-05, 'l1_Layer_3': 1.1927320294012742e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.31 | sMAPE for Validation Set is: 22.66% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.77 | sMAPE for Test Set is: 30.45% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:40:00,692]\u001b[0m Trial 1297 finished with value: 18.822675042649383 and parameters: {'n_hidden': 3, 'learning_rate': 0.0064140240477877156, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02709617328299164, 'dropout_rate_Layer_2': 0.005875840001023952, 'dropout_rate_Layer_3': 0.020842502719539878, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001611758569048989, 'l1_Layer_2': 0.0006007506897296347, 'l1_Layer_3': 0.006804719957544336, 'n_units_Layer_1': 195, 'n_units_Layer_2': 65, 'n_units_Layer_3': 255}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.82 | sMAPE for Validation Set is: 22.36% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 45.58 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:40:17,897]\u001b[0m Trial 1303 finished with value: 19.06208615740418 and parameters: {'n_hidden': 3, 'learning_rate': 0.005974798517778416, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013296979146932009, 'dropout_rate_Layer_2': 0.005023066825070185, 'dropout_rate_Layer_3': 0.033281005578311644, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022042511534050202, 'l1_Layer_2': 0.0005098019537202788, 'l1_Layer_3': 0.005440280394821534, 'n_units_Layer_1': 195, 'n_units_Layer_2': 55, 'n_units_Layer_3': 270}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.06 | sMAPE for Validation Set is: 22.73% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 49.45 | sMAPE for Test Set is: 27.81% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:40:21,030]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:24,021]\u001b[0m Trial 1301 finished with value: 18.647207136827365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0060973317794841475, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01400208829392582, 'dropout_rate_Layer_2': 0.00804431838482765, 'dropout_rate_Layer_3': 0.008199693280417811, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002117813123655095, 'l1_Layer_2': 0.0007453522483736134, 'l1_Layer_3': 0.007333659064995793, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.65 | sMAPE for Validation Set is: 22.25% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 48.76 | sMAPE for Test Set is: 27.49% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:40:26,301]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:29,208]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:32,514]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:44,959]\u001b[0m Trial 1302 finished with value: 18.8541979002886 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014769319648015805, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.19961512536348436, 'dropout_rate_Layer_2': 0.33016777496665606, 'dropout_rate_Layer_3': 0.3995627435860236, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018429217240975316, 'l1_Layer_2': 0.000856063677256571, 'l1_Layer_3': 1.3556473169147854e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 250, 'n_units_Layer_3': 100}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 22.02% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.16 | sMAPE for Test Set is: 28.22% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:40:47,896]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:50,405]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:54,339]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:40:58,241]\u001b[0m Trial 1292 finished with value: 18.904254003239856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009321854782859953, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10773468667914267, 'dropout_rate_Layer_2': 0.09507055825836319, 'dropout_rate_Layer_3': 0.2062544633079978, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.157184876415718e-05, 'l1_Layer_2': 7.243839578735146e-05, 'l1_Layer_3': 3.190968146873187e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 75, 'n_units_Layer_3': 130}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.90 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 56.32 | sMAPE for Test Set is: 29.55% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:41:06,710]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:41:14,484]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:41:18,026]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:41:21,773]\u001b[0m Trial 1314 finished with value: 19.01711722060844 and parameters: {'n_hidden': 3, 'learning_rate': 0.005207119187073669, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015103618601541182, 'dropout_rate_Layer_2': 0.011464489961369343, 'dropout_rate_Layer_3': 0.03331093551029523, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022949455796374054, 'l1_Layer_2': 0.0006036684681525407, 'l1_Layer_3': 0.0034443901255237783, 'n_units_Layer_1': 190, 'n_units_Layer_2': 50, 'n_units_Layer_3': 255}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.02 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 48.85 | sMAPE for Test Set is: 27.70% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:41:24,781]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:41:28,071]\u001b[0m Trial 1319 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:41:38,886]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:04,770]\u001b[0m Trial 1307 finished with value: 19.083885164766727 and parameters: {'n_hidden': 3, 'learning_rate': 0.002321184572833172, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14968522435229786, 'dropout_rate_Layer_2': 0.09617360929088349, 'dropout_rate_Layer_3': 0.15069374821722953, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.928884820280303e-05, 'l1_Layer_2': 7.325058371940792e-05, 'l1_Layer_3': 1.3295866085775138e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 95, 'n_units_Layer_3': 160}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 22.59% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 53.52 | sMAPE for Test Set is: 28.90% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:42:07,559]\u001b[0m Trial 1318 finished with value: 18.857842993184065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014339528691991843, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18541967053792877, 'dropout_rate_Layer_2': 0.31727258591075325, 'dropout_rate_Layer_3': 0.3995881515290614, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017443742322679204, 'l1_Layer_2': 0.001132518461325472, 'l1_Layer_3': 1.79224195403461e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 120}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.86 | sMAPE for Validation Set is: 22.22% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 52.13 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:42:08,582]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:12,890]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:21,181]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:22,401]\u001b[0m Trial 1321 finished with value: 18.801387747788123 and parameters: {'n_hidden': 3, 'learning_rate': 0.001481495468691788, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1845595577205741, 'dropout_rate_Layer_2': 0.33239338345554026, 'dropout_rate_Layer_3': 0.3899235844826765, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019899431938736502, 'l1_Layer_2': 0.001173472275797059, 'l1_Layer_3': 1.885825288324721e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 120}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 22.03% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 51.29 | sMAPE for Test Set is: 28.57% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:42:25,620]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:30,521]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:40,112]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:47,896]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:52,086]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:42:53,506]\u001b[0m Trial 1311 finished with value: 19.04038091280052 and parameters: {'n_hidden': 3, 'learning_rate': 0.002473721930853628, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.149997832244222, 'dropout_rate_Layer_2': 0.07865324687896505, 'dropout_rate_Layer_3': 0.1554169496127095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.796109581172387e-05, 'l1_Layer_2': 4.262463161183976e-05, 'l1_Layer_3': 1.774156659283075e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 95, 'n_units_Layer_3': 160}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.04 | sMAPE for Validation Set is: 23.03% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 59.04 | sMAPE for Test Set is: 30.16% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:42:56,579]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:00,601]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:12,008]\u001b[0m Trial 1328 finished with value: 18.802981638888543 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014106091520015892, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1767806202270397, 'dropout_rate_Layer_2': 0.3312102132086312, 'dropout_rate_Layer_3': 0.39931883590008294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001824714700688374, 'l1_Layer_2': 0.0011231641101448685, 'l1_Layer_3': 1.283489476057822e-05, 'n_units_Layer_1': 85, 'n_units_Layer_2': 230, 'n_units_Layer_3': 125}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 22.09% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 49.55 | sMAPE for Test Set is: 27.88% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:43:25,206]\u001b[0m Trial 1324 finished with value: 19.99701830073275 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025420470265938334, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14953512399218888, 'dropout_rate_Layer_2': 0.09352003599467022, 'dropout_rate_Layer_3': 0.2122820046946463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.908227298174189e-05, 'l1_Layer_2': 7.185288411155971e-05, 'l1_Layer_3': 1.3777651514359432e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 95, 'n_units_Layer_3': 165}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 20.00 | sMAPE for Validation Set is: 24.22% | rMAE for Validation Set is: 0.64\n",
      "MAE for Test Set is: 56.95 | sMAPE for Test Set is: 29.89% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:43:28,926]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:33,257]\u001b[0m Trial 1338 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.74 | sMAPE for Validation Set is: 22.11% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.22 | sMAPE for Test Set is: 27.99% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 18.93 | sMAPE for Validation Set is: 22.24% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 52.38 | sMAPE for Test Set is: 28.77% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:43:35,730]\u001b[0m Trial 1335 finished with value: 18.736046256353486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012673249692800002, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17258664366739018, 'dropout_rate_Layer_2': 0.31989785577013685, 'dropout_rate_Layer_3': 0.38926637707237965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014698138956559243, 'l1_Layer_2': 0.0007505182172125386, 'l1_Layer_3': 1.9976329008500677e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:35,768]\u001b[0m Trial 1333 finished with value: 18.93421235761829 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013342954228917259, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17771617733978776, 'dropout_rate_Layer_2': 0.31434738346468166, 'dropout_rate_Layer_3': 0.38832259424357335, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016412123044329255, 'l1_Layer_2': 0.00219126296259466, 'l1_Layer_3': 2.009718632128437e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:37,365]\u001b[0m Trial 1339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:44,243]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:44,495]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:45,701]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:50,761]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:52,264]\u001b[0m Trial 1344 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:53,122]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:57,687]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:43:58,449]\u001b[0m Trial 1336 finished with value: 60.171385080676735 and parameters: {'n_hidden': 4, 'learning_rate': 0.0030807447023247087, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.14767276873441193, 'dropout_rate_Layer_2': 0.09323050202565276, 'dropout_rate_Layer_3': 0.13895324883802643, 'dropout_rate_Layer_4': 0.2629982424694864, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'tanh', 'l1_Layer_1': 6.250571982114126e-05, 'l1_Layer_2': 6.899092740556157e-05, 'l1_Layer_3': 3.604187003355075e-05, 'l1_Layer_4': 8.241610796559384e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 115, 'n_units_Layer_3': 150, 'n_units_Layer_4': 115}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 60.17 | sMAPE for Validation Set is: 70.67% | rMAE for Validation Set is: 1.91\n",
      "MAE for Test Set is: 198.04 | sMAPE for Test Set is: 128.28% | rMAE for Test Set is: 2.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:44:00,627]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:02,953]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:07,646]\u001b[0m Trial 1349 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:09,764]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:10,097]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:18,603]\u001b[0m Trial 1353 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:20,402]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:25,024]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:26,970]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:31,178]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:34,625]\u001b[0m Trial 1360 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:39,736]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:43,407]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:54,786]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:44:59,244]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:01,519]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:10,474]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:23,071]\u001b[0m Trial 1357 finished with value: 19.146682376515265 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009932469027938433, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17527577518754392, 'dropout_rate_Layer_2': 0.3157714786435838, 'dropout_rate_Layer_3': 0.38915563906391915, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014489840532306712, 'l1_Layer_2': 0.0033606495705171963, 'l1_Layer_3': 2.0436075620392047e-05, 'n_units_Layer_1': 65, 'n_units_Layer_2': 220, 'n_units_Layer_3': 130}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.15 | sMAPE for Validation Set is: 22.56% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 56.54 | sMAPE for Test Set is: 29.95% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:45:34,875]\u001b[0m Trial 1356 finished with value: 19.79464809646015 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018280090352874381, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13829548546011605, 'dropout_rate_Layer_2': 0.11110406913004457, 'dropout_rate_Layer_3': 0.12337467192406011, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.620091730556455e-05, 'l1_Layer_2': 0.0001433776605220984, 'l1_Layer_3': 1.8663642914930973e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 773 with value: 18.4479187553308.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.79 | sMAPE for Validation Set is: 23.19% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 60.22 | sMAPE for Test Set is: 30.99% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:45:39,250]\u001b[0m Trial 1369 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:44,974]\u001b[0m Trial 1370 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:48,933]\u001b[0m Trial 1367 finished with value: 18.390110242047403 and parameters: {'n_hidden': 3, 'learning_rate': 0.0055152199644295545, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.005299755128134365, 'dropout_rate_Layer_2': 0.004308077281887402, 'dropout_rate_Layer_3': 0.027428210337176663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006378559769785829, 'l1_Layer_2': 0.000598665599981492, 'l1_Layer_3': 0.006816912494523346, 'n_units_Layer_1': 210, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.39 | sMAPE for Validation Set is: 21.82% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 48.24 | sMAPE for Test Set is: 27.18% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:45:49,148]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:55,400]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:45:55,730]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:01,658]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:13,439]\u001b[0m Trial 1366 finished with value: 19.467042205855947 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019326643877835554, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1373424835024031, 'dropout_rate_Layer_2': 0.11129288350675327, 'dropout_rate_Layer_3': 0.11926711731387463, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.016788792699164e-05, 'l1_Layer_2': 0.0005925582866815709, 'l1_Layer_3': 1.895182795129315e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 100, 'n_units_Layer_3': 145}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.47 | sMAPE for Validation Set is: 23.44% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 54.84 | sMAPE for Test Set is: 29.48% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:46:19,683]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:22,014]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:24,189]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:25,257]\u001b[0m Trial 1368 finished with value: 19.663962636455697 and parameters: {'n_hidden': 3, 'learning_rate': 0.001213573491670689, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15650769787598073, 'dropout_rate_Layer_2': 0.33461508984221505, 'dropout_rate_Layer_3': 0.3994645922729128, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001341685656253539, 'l1_Layer_2': 0.004091574504454019, 'l1_Layer_3': 1.532793368107165e-05, 'n_units_Layer_1': 70, 'n_units_Layer_2': 225, 'n_units_Layer_3': 130}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.66 | sMAPE for Validation Set is: 22.69% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 49.61 | sMAPE for Test Set is: 27.97% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:46:28,539]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:32,165]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:35,366]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:46:39,445]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:06,865]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:10,283]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:12,663]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:14,400]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:19,238]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:23,098]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:26,703]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:26,856]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:26,884]\u001b[0m Trial 1388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:34,518]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:36,061]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:39,106]\u001b[0m Trial 1393 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:42,554]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:44,056]\u001b[0m Trial 1397 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:47,219]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:52,111]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:53,517]\u001b[0m Trial 1400 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:47:56,547]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:00,424]\u001b[0m Trial 1380 finished with value: 18.915362030634004 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013153495411257132, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10637059335150863, 'dropout_rate_Layer_2': 0.08400106207530643, 'dropout_rate_Layer_3': 0.15845250737032598, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0746796517728972e-05, 'l1_Layer_2': 4.248587701006179e-05, 'l1_Layer_3': 1.0145169243383602e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 80, 'n_units_Layer_3': 160}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.92 | sMAPE for Validation Set is: 22.48% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 59.09 | sMAPE for Test Set is: 30.36% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:48:01,146]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:01,203]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:03,723]\u001b[0m Trial 1396 finished with value: 18.798589133475414 and parameters: {'n_hidden': 3, 'learning_rate': 0.0066582875022357805, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007220130335663343, 'dropout_rate_Layer_2': 0.011561252713175357, 'dropout_rate_Layer_3': 0.030548528329935546, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019951008947891976, 'l1_Layer_2': 0.0008549110849477029, 'l1_Layer_3': 0.007337878774197084, 'n_units_Layer_1': 210, 'n_units_Layer_2': 70, 'n_units_Layer_3': 245}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.80 | sMAPE for Validation Set is: 22.14% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 47.67 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:48:10,728]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:13,654]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:17,185]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:17,460]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:17,707]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:25,804]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:28,856]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:29,085]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:34,940]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:38,342]\u001b[0m Trial 1412 finished with value: 19.65723519055454 and parameters: {'n_hidden': 3, 'learning_rate': 0.0027035843334765794, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11161177132587119, 'dropout_rate_Layer_2': 0.08594217078103683, 'dropout_rate_Layer_3': 0.15606333946226994, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.9366237628319924e-05, 'l1_Layer_2': 6.054588340467441e-05, 'l1_Layer_3': 1.4731392397116097e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 170}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.66 | sMAPE for Validation Set is: 23.01% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 73.00 | sMAPE for Test Set is: 33.90% | rMAE for Test Set is: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:48:38,726]\u001b[0m Trial 1416 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:40,577]\u001b[0m Trial 1407 finished with value: 19.275326893873224 and parameters: {'n_hidden': 3, 'learning_rate': 0.002647085476465566, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10942832376639465, 'dropout_rate_Layer_2': 0.07928335752698684, 'dropout_rate_Layer_3': 0.15395489609873383, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9634587969592714e-05, 'l1_Layer_2': 6.241733146910445e-05, 'l1_Layer_3': 1.5069178681910372e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.28 | sMAPE for Validation Set is: 22.64% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 58.30 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:48:47,543]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:48,392]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:53,698]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:48:53,920]\u001b[0m Trial 1421 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:00,122]\u001b[0m Trial 1422 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:00,266]\u001b[0m Trial 1423 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:06,618]\u001b[0m Trial 1424 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:06,751]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:13,453]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:13,499]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:14,084]\u001b[0m Trial 1415 finished with value: 19.679231380410425 and parameters: {'n_hidden': 3, 'learning_rate': 0.002513372094327123, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07467707567031526, 'dropout_rate_Layer_2': 0.0796158208573249, 'dropout_rate_Layer_3': 0.15882571376127216, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9411373303015647e-05, 'l1_Layer_2': 6.139644489140542e-05, 'l1_Layer_3': 1.4641844074711717e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 90, 'n_units_Layer_3': 165}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.68 | sMAPE for Validation Set is: 23.10% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 52.76 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:49:23,038]\u001b[0m Trial 1430 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:26,379]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:26,590]\u001b[0m Trial 1419 finished with value: 19.084174183615982 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014331095448116302, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18897877373478816, 'dropout_rate_Layer_2': 0.3108433512831492, 'dropout_rate_Layer_3': 0.3900375653275731, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001865117728384731, 'l1_Layer_2': 0.0013236840206054202, 'l1_Layer_3': 1.0691540621232185e-05, 'n_units_Layer_1': 55, 'n_units_Layer_2': 240, 'n_units_Layer_3': 100}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 22.26% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.22 | sMAPE for Test Set is: 28.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:49:26,779]\u001b[0m Trial 1431 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:27,354]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:34,928]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:36,382]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:38,237]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:42,297]\u001b[0m Trial 1433 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:45,884]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:46,150]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:53,704]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:56,229]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:49:59,049]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:01,543]\u001b[0m Trial 1443 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:05,374]\u001b[0m Trial 1445 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:07,909]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:10,309]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:12,429]\u001b[0m Trial 1437 finished with value: 18.816279069262958 and parameters: {'n_hidden': 3, 'learning_rate': 0.004576113978118473, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.033233318607239624, 'dropout_rate_Layer_2': 0.00013968469136797605, 'dropout_rate_Layer_3': 0.0339254987036502, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020972995248874702, 'l1_Layer_2': 0.0006169116322460715, 'l1_Layer_3': 0.008385355661291565, 'n_units_Layer_1': 120, 'n_units_Layer_2': 65, 'n_units_Layer_3': 250}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.82 | sMAPE for Validation Set is: 22.61% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.03 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:50:13,837]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:16,791]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:21,602]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:24,632]\u001b[0m Trial 1450 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:25,542]\u001b[0m Trial 1436 finished with value: 18.84957931835059 and parameters: {'n_hidden': 3, 'learning_rate': 0.004937033621333841, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.033608720844295316, 'dropout_rate_Layer_2': 0.023063917830283418, 'dropout_rate_Layer_3': 0.010980783534208045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000210622668465405, 'l1_Layer_2': 0.0007965672801192046, 'l1_Layer_3': 0.008677126849071471, 'n_units_Layer_1': 195, 'n_units_Layer_2': 50, 'n_units_Layer_3': 250}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:25,565]\u001b[0m Trial 1451 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.85 | sMAPE for Validation Set is: 22.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.50 | sMAPE for Test Set is: 28.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:50:26,760]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:34,185]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:34,920]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:35,418]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:35,769]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:43,415]\u001b[0m Trial 1457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:45,539]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:50,272]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:54,864]\u001b[0m Trial 1462 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:50:57,155]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:01,198]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:01,457]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:07,569]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:07,847]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:17,053]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:21,363]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:25,602]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:26,424]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:33,301]\u001b[0m Trial 1472 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:36,383]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:40,714]\u001b[0m Trial 1475 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:45,221]\u001b[0m Trial 1476 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:49,474]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:53,134]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:51:55,820]\u001b[0m Trial 1468 finished with value: 19.176018686809574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016210123437508533, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2034756859555353, 'dropout_rate_Layer_2': 0.3031712539765037, 'dropout_rate_Layer_3': 0.38202636421480896, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015917423541543857, 'l1_Layer_2': 0.0015103514692210523, 'l1_Layer_3': 1.7939658506121047e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 215, 'n_units_Layer_3': 135}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.18 | sMAPE for Validation Set is: 22.41% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 50.32 | sMAPE for Test Set is: 28.14% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:51:57,284]\u001b[0m Trial 1479 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:01,949]\u001b[0m Trial 1473 finished with value: 19.36707259470191 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014970431360288767, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2010835018590121, 'dropout_rate_Layer_2': 0.30366512684685254, 'dropout_rate_Layer_3': 0.3840324279281472, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00016594398021625888, 'l1_Layer_2': 0.0014516780838001234, 'l1_Layer_3': 1.0027174337177726e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.37 | sMAPE for Validation Set is: 22.71% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 52.46 | sMAPE for Test Set is: 28.99% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:52:03,452]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:08,944]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:11,141]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:15,039]\u001b[0m Trial 1474 finished with value: 19.218326176642346 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013774649378870871, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08322974759957458, 'dropout_rate_Layer_2': 0.1296646654671798, 'dropout_rate_Layer_3': 0.17103693784635068, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.2002928074118244e-05, 'l1_Layer_2': 8.817594262415685e-05, 'l1_Layer_3': 2.1495771910167357e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.22 | sMAPE for Validation Set is: 22.67% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 55.91 | sMAPE for Test Set is: 29.79% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:52:25,389]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:39,374]\u001b[0m Trial 1485 finished with value: 18.89358929748392 and parameters: {'n_hidden': 3, 'learning_rate': 0.005269111113972038, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026334409212257374, 'dropout_rate_Layer_2': 0.024925300314759403, 'dropout_rate_Layer_3': 0.03704849030982117, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00033311365958747427, 'l1_Layer_2': 0.0008156488737138715, 'l1_Layer_3': 0.010019942299395151, 'n_units_Layer_1': 190, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.89 | sMAPE for Validation Set is: 22.27% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 50.34 | sMAPE for Test Set is: 28.15% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:52:42,762]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:46,038]\u001b[0m Trial 1489 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:46,848]\u001b[0m Trial 1480 finished with value: 19.543846304477704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016095566176503567, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.20046261241346747, 'dropout_rate_Layer_2': 0.29925067735979183, 'dropout_rate_Layer_3': 0.3828689493513767, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015928958207552318, 'l1_Layer_2': 0.0014375622572900708, 'l1_Layer_3': 2.2205554062977557e-05, 'n_units_Layer_1': 75, 'n_units_Layer_2': 220, 'n_units_Layer_3': 135}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.54 | sMAPE for Validation Set is: 22.89% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 51.27 | sMAPE for Test Set is: 28.37% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:52:51,203]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:52:57,473]\u001b[0m Trial 1484 finished with value: 19.076275283724794 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033715109785907612, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12151816138706677, 'dropout_rate_Layer_2': 0.06285537524042091, 'dropout_rate_Layer_3': 0.10985153269488612, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.3786627827782877e-05, 'l1_Layer_2': 8.486717140936345e-05, 'l1_Layer_3': 2.897380647600449e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 160}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.08 | sMAPE for Validation Set is: 22.55% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 57.43 | sMAPE for Test Set is: 29.81% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:53:03,775]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:06,983]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:19,719]\u001b[0m Trial 1491 finished with value: 19.100215188538453 and parameters: {'n_hidden': 3, 'learning_rate': 0.004991118234214709, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030740874406594877, 'dropout_rate_Layer_2': 0.028265479036926784, 'dropout_rate_Layer_3': 0.032382935912826816, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00037407357342878964, 'l1_Layer_2': 0.0011785584255797489, 'l1_Layer_3': 0.009250232901790188, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 245}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 19.10 | sMAPE for Validation Set is: 22.58% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 52.16 | sMAPE for Test Set is: 28.70% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:53:28,169]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:34,762]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:37,628]\u001b[0m Trial 1495 finished with value: 18.65675192405919 and parameters: {'n_hidden': 3, 'learning_rate': 0.004786909707391415, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03954483654617939, 'dropout_rate_Layer_2': 0.0249089046246265, 'dropout_rate_Layer_3': 0.03412889156060925, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00010629308266657239, 'l1_Layer_2': 0.001129196098426817, 'l1_Layer_3': 0.009266718242630681, 'n_units_Layer_1': 185, 'n_units_Layer_2': 205, 'n_units_Layer_3': 245}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.66 | sMAPE for Validation Set is: 22.18% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 49.94 | sMAPE for Test Set is: 27.91% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 07:53:41,183]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:41,689]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:46,763]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 07:53:50,195]\u001b[0m Trial 1487 finished with value: 18.747109596775346 and parameters: {'n_hidden': 3, 'learning_rate': 0.003421398569617748, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0847113223165483, 'dropout_rate_Layer_2': 0.13931689648767376, 'dropout_rate_Layer_3': 0.17420292782045083, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.7175857467081758e-05, 'l1_Layer_2': 9.53610280912278e-05, 'l1_Layer_3': 3.7134026694396294e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 80, 'n_units_Layer_3': 135}. Best is trial 1367 with value: 18.390110242047403.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 18.75 | sMAPE for Validation Set is: 22.39% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 59.87 | sMAPE for Test Set is: 30.54% | rMAE for Test Set is: 0.69\n",
      "for 2022-01-01, MAE is:36.43 & sMAPE is:55.25% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :36.43 & 55.25% & 0.31\n",
      "for 2022-01-02, MAE is:48.72 & sMAPE is:67.44% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :42.57 & 61.34% & 0.35\n",
      "for 2022-01-03, MAE is:24.01 & sMAPE is:64.95% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :36.39 & 62.55% & 0.34\n",
      "for 2022-01-04, MAE is:54.44 & sMAPE is:41.95% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :40.90 & 57.40% & 0.53\n",
      "for 2022-01-05, MAE is:24.35 & sMAPE is:19.85% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :37.59 & 49.89% & 0.52\n",
      "for 2022-01-06, MAE is:75.51 & sMAPE is:44.67% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :43.91 & 49.02% & 0.54\n",
      "for 2022-01-07, MAE is:26.61 & sMAPE is:15.58% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :41.44 & 44.24% & 0.48\n",
      "for 2022-01-08, MAE is:33.78 & sMAPE is:21.59% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :40.48 & 41.41% & 0.47\n",
      "for 2022-01-09, MAE is:50.90 & sMAPE is:35.97% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :41.64 & 40.81% & 0.48\n",
      "for 2022-01-10, MAE is:70.69 & sMAPE is:30.42% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :44.54 & 39.77% & 0.47\n",
      "for 2022-01-11, MAE is:43.87 & sMAPE is:18.31% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :44.48 & 37.82% & 0.46\n",
      "for 2022-01-12, MAE is:23.73 & sMAPE is:10.10% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :42.75 & 35.51% & 0.44\n",
      "for 2022-01-13, MAE is:32.14 & sMAPE is:16.67% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :41.94 & 34.06% & 0.47\n",
      "for 2022-01-14, MAE is:30.33 & sMAPE is:17.30% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :41.11 & 32.86% & 0.56\n",
      "for 2022-01-15, MAE is:32.26 & sMAPE is:16.41% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :40.52 & 31.76% & 0.57\n",
      "for 2022-01-16, MAE is:78.37 & sMAPE is:48.01% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :42.88 & 32.78% & 0.59\n",
      "for 2022-01-17, MAE is:54.24 & sMAPE is:52.05% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :43.55 & 33.91% & 0.58\n",
      "for 2022-01-18, MAE is:37.96 & sMAPE is:17.43% & rMAE is:1.94 ||| daily mean of MAE & sMAPE & rMAE till now are :43.24 & 33.00% & 0.65\n",
      "for 2022-01-19, MAE is:40.05 & sMAPE is:22.31% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :43.07 & 32.43% & 0.65\n",
      "for 2022-01-20, MAE is:28.41 & sMAPE is:23.34% & rMAE is:0.45 ||| daily mean of MAE & sMAPE & rMAE till now are :42.34 & 31.98% & 0.64\n",
      "for 2022-01-21, MAE is:28.34 & sMAPE is:17.68% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :41.67 & 31.30% & 0.65\n",
      "for 2022-01-22, MAE is:32.66 & sMAPE is:19.01% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :41.26 & 30.74% & 0.66\n",
      "for 2022-01-23, MAE is:21.40 & sMAPE is:11.75% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :40.40 & 29.91% & 0.64\n",
      "for 2022-01-24, MAE is:55.23 & sMAPE is:24.19% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :41.02 & 29.68% & 0.64\n",
      "for 2022-01-25, MAE is:64.83 & sMAPE is:22.39% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :41.97 & 29.38% & 0.65\n",
      "for 2022-01-26, MAE is:31.34 & sMAPE is:14.24% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :41.56 & 28.80% & 0.65\n",
      "for 2022-01-27, MAE is:45.03 & sMAPE is:30.85% & rMAE is:1.55 ||| daily mean of MAE & sMAPE & rMAE till now are :41.69 & 28.88% & 0.68\n",
      "for 2022-01-28, MAE is:50.96 & sMAPE is:29.89% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :42.02 & 28.91% & 0.70\n",
      "for 2022-01-29, MAE is:66.10 & sMAPE is:54.32% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :42.85 & 29.79% & 0.70\n",
      "for 2022-01-30, MAE is:70.67 & sMAPE is:117.53% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :43.78 & 32.72% & 0.70\n",
      "for 2022-01-31, MAE is:36.08 & sMAPE is:18.88% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :43.53 & 32.27% & 0.70\n",
      "for 2022-02-01, MAE is:60.82 & sMAPE is:37.47% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :44.07 & 32.43% & 0.69\n",
      "for 2022-02-02, MAE is:49.52 & sMAPE is:48.98% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :44.24 & 32.93% & 0.68\n",
      "for 2022-02-03, MAE is:15.64 & sMAPE is:8.66% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :43.39 & 32.22% & 0.67\n",
      "for 2022-02-04, MAE is:50.47 & sMAPE is:32.15% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :43.60 & 32.22% & 0.67\n",
      "for 2022-02-05, MAE is:30.13 & sMAPE is:35.13% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :43.22 & 32.30% & 0.68\n",
      "for 2022-02-06, MAE is:31.87 & sMAPE is:86.80% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :42.92 & 33.77% & 0.69\n",
      "for 2022-02-07, MAE is:37.85 & sMAPE is:56.43% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :42.78 & 34.37% & 0.68\n",
      "for 2022-02-08, MAE is:25.61 & sMAPE is:19.58% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :42.34 & 33.99% & 0.68\n",
      "for 2022-02-09, MAE is:33.10 & sMAPE is:19.58% & rMAE is:0.94 ||| daily mean of MAE & sMAPE & rMAE till now are :42.11 & 33.63% & 0.68\n",
      "for 2022-02-10, MAE is:26.56 & sMAPE is:14.40% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :41.73 & 33.16% & 0.71\n",
      "for 2022-02-11, MAE is:36.49 & sMAPE is:21.00% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :41.61 & 32.87% & 0.71\n",
      "for 2022-02-12, MAE is:49.31 & sMAPE is:32.11% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :41.79 & 32.85% & 0.71\n",
      "for 2022-02-13, MAE is:39.30 & sMAPE is:40.01% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :41.73 & 33.01% & 0.71\n",
      "for 2022-02-14, MAE is:27.72 & sMAPE is:36.19% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :41.42 & 33.08% & 0.72\n",
      "for 2022-02-15, MAE is:42.30 & sMAPE is:28.72% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :41.44 & 32.99% & 0.73\n",
      "for 2022-02-16, MAE is:26.29 & sMAPE is:22.37% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :41.12 & 32.76% & 0.72\n",
      "for 2022-02-17, MAE is:45.53 & sMAPE is:62.30% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :41.21 & 33.38% & 0.71\n",
      "for 2022-02-18, MAE is:22.78 & sMAPE is:19.88% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :40.83 & 33.10% & 0.71\n",
      "for 2022-02-19, MAE is:65.01 & sMAPE is:118.23% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :41.32 & 34.81% & 0.70\n",
      "for 2022-02-20, MAE is:36.27 & sMAPE is:53.45% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :41.22 & 35.17% & 0.71\n",
      "for 2022-02-21, MAE is:31.17 & sMAPE is:62.05% & rMAE is:1.16 ||| daily mean of MAE & sMAPE & rMAE till now are :41.02 & 35.69% & 0.72\n",
      "for 2022-02-22, MAE is:31.97 & sMAPE is:27.49% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :40.85 & 35.53% & 0.73\n",
      "for 2022-02-23, MAE is:35.79 & sMAPE is:27.50% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :40.76 & 35.39% & 0.73\n",
      "for 2022-02-24, MAE is:26.47 & sMAPE is:20.15% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :40.50 & 35.11% & 0.72\n",
      "for 2022-02-25, MAE is:21.63 & sMAPE is:17.29% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :40.16 & 34.79% & 0.72\n",
      "for 2022-02-26, MAE is:104.78 & sMAPE is:59.00% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :41.30 & 35.21% & 0.72\n",
      "for 2022-02-27, MAE is:31.95 & sMAPE is:17.45% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :41.13 & 34.91% & 0.71\n",
      "for 2022-02-28, MAE is:58.36 & sMAPE is:28.68% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :41.43 & 34.80% & 0.71\n",
      "for 2022-03-01, MAE is:62.31 & sMAPE is:27.20% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :41.77 & 34.68% & 0.71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-03-02, MAE is:44.72 & sMAPE is:16.83% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :41.82 & 34.38% & 0.70\n",
      "for 2022-03-03, MAE is:86.12 & sMAPE is:28.78% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :42.54 & 34.29% & 0.69\n",
      "for 2022-03-04, MAE is:63.26 & sMAPE is:19.16% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :42.87 & 34.05% & 0.69\n",
      "for 2022-03-05, MAE is:47.29 & sMAPE is:14.41% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :42.94 & 33.75% & 0.68\n",
      "for 2022-03-06, MAE is:52.12 & sMAPE is:15.94% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :43.08 & 33.47% & 0.68\n",
      "for 2022-03-07, MAE is:53.92 & sMAPE is:13.36% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :43.24 & 33.17% & 0.67\n",
      "for 2022-03-08, MAE is:134.27 & sMAPE is:29.27% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :44.60 & 33.11% & 0.67\n",
      "for 2022-03-09, MAE is:72.93 & sMAPE is:16.50% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :45.02 & 32.87% & 0.67\n",
      "for 2022-03-10, MAE is:182.69 & sMAPE is:52.76% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :47.01 & 33.15% & 0.69\n",
      "for 2022-03-11, MAE is:182.59 & sMAPE is:112.86% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :48.95 & 34.29% & 0.69\n",
      "for 2022-03-12, MAE is:52.26 & sMAPE is:40.47% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :49.00 & 34.38% & 0.69\n",
      "for 2022-03-13, MAE is:79.92 & sMAPE is:62.23% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :49.42 & 34.77% & 0.68\n",
      "for 2022-03-14, MAE is:58.85 & sMAPE is:22.72% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :49.55 & 34.60% & 0.68\n",
      "for 2022-03-15, MAE is:27.36 & sMAPE is:8.78% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :49.25 & 34.25% & 0.67\n",
      "for 2022-03-16, MAE is:76.52 & sMAPE is:28.00% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :49.62 & 34.17% & 0.67\n",
      "for 2022-03-17, MAE is:31.12 & sMAPE is:14.69% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :49.37 & 33.91% & 0.66\n",
      "for 2022-03-18, MAE is:27.05 & sMAPE is:11.77% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 33.62% & 0.66\n",
      "for 2022-03-19, MAE is:80.39 & sMAPE is:58.37% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :49.49 & 33.94% & 0.66\n",
      "for 2022-03-20, MAE is:69.41 & sMAPE is:100.21% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :49.74 & 34.78% & 0.66\n",
      "for 2022-03-21, MAE is:64.29 & sMAPE is:34.24% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :49.92 & 34.77% & 0.67\n",
      "for 2022-03-22, MAE is:35.95 & sMAPE is:15.49% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :49.75 & 34.54% & 0.67\n",
      "for 2022-03-23, MAE is:37.19 & sMAPE is:15.35% & rMAE is:0.81 ||| daily mean of MAE & sMAPE & rMAE till now are :49.59 & 34.30% & 0.67\n",
      "for 2022-03-24, MAE is:38.84 & sMAPE is:16.36% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :49.46 & 34.09% & 0.67\n",
      "for 2022-03-25, MAE is:49.62 & sMAPE is:20.72% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.47 & 33.93% & 0.69\n",
      "for 2022-03-26, MAE is:47.33 & sMAPE is:27.34% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :49.44 & 33.85% & 0.69\n",
      "for 2022-03-27, MAE is:31.86 & sMAPE is:18.53% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :49.24 & 33.67% & 0.68\n",
      "for 2022-03-28, MAE is:32.67 & sMAPE is:14.90% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :49.05 & 33.46% & 0.68\n",
      "for 2022-03-29, MAE is:32.68 & sMAPE is:13.83% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :48.86 & 33.23% & 0.69\n",
      "for 2022-03-30, MAE is:45.64 & sMAPE is:18.34% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :48.82 & 33.06% & 0.69\n",
      "for 2022-03-31, MAE is:41.44 & sMAPE is:18.95% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :48.74 & 32.91% & 0.69\n",
      "for 2022-04-01, MAE is:18.93 & sMAPE is:12.79% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :48.41 & 32.69% & 0.69\n",
      "for 2022-04-02, MAE is:16.25 & sMAPE is:9.80% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :48.06 & 32.44% & 0.69\n",
      "for 2022-04-03, MAE is:34.68 & sMAPE is:20.37% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :47.92 & 32.31% & 0.69\n",
      "for 2022-04-04, MAE is:101.99 & sMAPE is:82.47% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :48.50 & 32.84% & 0.69\n",
      "for 2022-04-05, MAE is:82.61 & sMAPE is:56.05% & rMAE is:1.19 ||| daily mean of MAE & sMAPE & rMAE till now are :48.86 & 33.09% & 0.69\n",
      "for 2022-04-06, MAE is:70.60 & sMAPE is:47.22% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 33.23% & 0.69\n",
      "for 2022-04-07, MAE is:43.55 & sMAPE is:44.59% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :49.02 & 33.35% & 0.69\n",
      "for 2022-04-08, MAE is:60.23 & sMAPE is:72.84% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :49.14 & 33.75% & 0.69\n",
      "for 2022-04-09, MAE is:104.84 & sMAPE is:102.68% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :49.70 & 34.45% & 0.69\n",
      "for 2022-04-10, MAE is:67.75 & sMAPE is:100.18% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 35.11% & 0.69\n",
      "for 2022-04-11, MAE is:56.96 & sMAPE is:28.42% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :49.95 & 35.04% & 0.69\n",
      "for 2022-04-12, MAE is:42.50 & sMAPE is:23.15% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :49.88 & 34.92% & 0.69\n",
      "for 2022-04-13, MAE is:61.25 & sMAPE is:31.15% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :49.99 & 34.89% & 0.69\n",
      "for 2022-04-14, MAE is:22.66 & sMAPE is:10.29% & rMAE is:0.15 ||| daily mean of MAE & sMAPE & rMAE till now are :49.73 & 34.65% & 0.68\n",
      "for 2022-04-15, MAE is:23.70 & sMAPE is:12.11% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :49.48 & 34.44% & 0.68\n",
      "for 2022-04-16, MAE is:35.06 & sMAPE is:29.05% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :49.34 & 34.39% & 0.67\n",
      "for 2022-04-17, MAE is:46.02 & sMAPE is:55.71% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :49.31 & 34.58% & 0.68\n",
      "for 2022-04-18, MAE is:52.03 & sMAPE is:42.86% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :49.34 & 34.66% & 0.67\n",
      "for 2022-04-19, MAE is:27.22 & sMAPE is:13.21% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :49.13 & 34.46% & 0.68\n",
      "for 2022-04-20, MAE is:19.83 & sMAPE is:10.18% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :48.87 & 34.24% & 0.68\n",
      "for 2022-04-21, MAE is:24.87 & sMAPE is:11.73% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :48.65 & 34.04% & 0.68\n",
      "for 2022-04-22, MAE is:36.43 & sMAPE is:22.66% & rMAE is:1.25 ||| daily mean of MAE & sMAPE & rMAE till now are :48.54 & 33.94% & 0.68\n",
      "for 2022-04-23, MAE is:59.50 & sMAPE is:66.23% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :48.64 & 34.23% & 0.69\n",
      "for 2022-04-24, MAE is:30.63 & sMAPE is:29.68% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :48.48 & 34.19% & 0.69\n",
      "for 2022-04-25, MAE is:56.43 & sMAPE is:29.33% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :48.55 & 34.14% & 0.69\n",
      "for 2022-04-26, MAE is:20.78 & sMAPE is:9.03% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :48.31 & 33.93% & 0.69\n",
      "for 2022-04-27, MAE is:16.38 & sMAPE is:7.20% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :48.04 & 33.70% & 0.69\n",
      "for 2022-04-28, MAE is:18.91 & sMAPE is:8.51% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :47.79 & 33.48% & 0.69\n",
      "for 2022-04-29, MAE is:18.75 & sMAPE is:8.32% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :47.55 & 33.27% & 0.69\n",
      "for 2022-04-30, MAE is:12.55 & sMAPE is:6.27% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :47.26 & 33.05% & 0.68\n",
      "for 2022-05-01, MAE is:23.16 & sMAPE is:12.34% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :47.06 & 32.88% & 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-05-02, MAE is:22.81 & sMAPE is:9.92% & rMAE is:1.77 ||| daily mean of MAE & sMAPE & rMAE till now are :46.86 & 32.69% & 0.69\n",
      "for 2022-05-03, MAE is:16.13 & sMAPE is:7.34% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :46.61 & 32.48% & 0.69\n",
      "for 2022-05-04, MAE is:17.46 & sMAPE is:7.55% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :46.37 & 32.28% & 0.70\n",
      "for 2022-05-05, MAE is:17.06 & sMAPE is:7.58% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :46.14 & 32.08% & 0.71\n",
      "for 2022-05-06, MAE is:20.01 & sMAPE is:8.98% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :45.93 & 31.90% & 0.72\n",
      "for 2022-05-07, MAE is:21.51 & sMAPE is:10.06% & rMAE is:2.06 ||| daily mean of MAE & sMAPE & rMAE till now are :45.74 & 31.73% & 0.73\n",
      "for 2022-05-08, MAE is:37.75 & sMAPE is:23.43% & rMAE is:1.62 ||| daily mean of MAE & sMAPE & rMAE till now are :45.68 & 31.66% & 0.74\n",
      "for 2022-05-09, MAE is:23.08 & sMAPE is:11.07% & rMAE is:3.44 ||| daily mean of MAE & sMAPE & rMAE till now are :45.50 & 31.50% & 0.76\n",
      "for 2022-05-10, MAE is:40.75 & sMAPE is:23.61% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :45.46 & 31.44% & 0.76\n",
      "for 2022-05-11, MAE is:57.42 & sMAPE is:42.64% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :45.56 & 31.53% & 0.76\n",
      "for 2022-05-12, MAE is:34.29 & sMAPE is:21.35% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :45.47 & 31.45% & 0.76\n",
      "for 2022-05-13, MAE is:44.30 & sMAPE is:33.42% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :45.46 & 31.47% & 0.76\n",
      "for 2022-05-14, MAE is:33.88 & sMAPE is:31.30% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :45.38 & 31.47% & 0.76\n",
      "for 2022-05-15, MAE is:48.99 & sMAPE is:37.31% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :45.40 & 31.51% & 0.77\n",
      "for 2022-05-16, MAE is:18.88 & sMAPE is:9.44% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :45.21 & 31.35% & 0.78\n",
      "for 2022-05-17, MAE is:16.51 & sMAPE is:7.27% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.00 & 31.17% & 0.77\n",
      "for 2022-05-18, MAE is:19.68 & sMAPE is:9.18% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :44.81 & 31.01% & 0.77\n",
      "for 2022-05-19, MAE is:20.31 & sMAPE is:10.06% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :44.64 & 30.86% & 0.77\n",
      "for 2022-05-20, MAE is:23.13 & sMAPE is:11.08% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :44.48 & 30.72% & 0.77\n",
      "for 2022-05-21, MAE is:79.40 & sMAPE is:76.23% & rMAE is:1.60 ||| daily mean of MAE & sMAPE & rMAE till now are :44.73 & 31.04% & 0.77\n",
      "for 2022-05-22, MAE is:23.79 & sMAPE is:14.22% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :44.58 & 30.92% & 0.77\n",
      "for 2022-05-23, MAE is:19.30 & sMAPE is:9.74% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :44.41 & 30.78% & 0.77\n",
      "for 2022-05-24, MAE is:29.98 & sMAPE is:19.62% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :44.31 & 30.70% & 0.77\n",
      "for 2022-05-25, MAE is:29.21 & sMAPE is:16.12% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :44.20 & 30.60% & 0.77\n",
      "for 2022-05-26, MAE is:94.35 & sMAPE is:101.84% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :44.55 & 31.09% & 0.77\n",
      "for 2022-05-27, MAE is:97.30 & sMAPE is:116.01% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :44.91 & 31.66% & 0.77\n",
      "for 2022-05-28, MAE is:57.35 & sMAPE is:146.77% & rMAE is:0.86 ||| daily mean of MAE & sMAPE & rMAE till now are :44.99 & 32.44% & 0.77\n",
      "for 2022-05-29, MAE is:23.56 & sMAPE is:15.41% & rMAE is:1.28 ||| daily mean of MAE & sMAPE & rMAE till now are :44.85 & 32.33% & 0.77\n",
      "for 2022-05-30, MAE is:40.70 & sMAPE is:20.10% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :44.82 & 32.25% & 0.78\n",
      "for 2022-05-31, MAE is:15.56 & sMAPE is:7.14% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :44.62 & 32.08% & 0.77\n",
      "for 2022-06-01, MAE is:14.00 & sMAPE is:6.70% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :44.42 & 31.91% & 0.77\n",
      "for 2022-06-02, MAE is:15.95 & sMAPE is:8.64% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :44.24 & 31.76% & 0.77\n",
      "for 2022-06-03, MAE is:18.09 & sMAPE is:9.72% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :44.07 & 31.62% & 0.76\n",
      "for 2022-06-04, MAE is:11.42 & sMAPE is:7.80% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :43.86 & 31.46% & 0.76\n",
      "for 2022-06-05, MAE is:26.22 & sMAPE is:16.83% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :43.74 & 31.37% & 0.76\n",
      "for 2022-06-06, MAE is:71.64 & sMAPE is:78.80% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :43.92 & 31.67% & 0.76\n",
      "for 2022-06-07, MAE is:12.24 & sMAPE is:7.21% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :43.72 & 31.52% & 0.76\n",
      "for 2022-06-08, MAE is:16.13 & sMAPE is:8.04% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :43.55 & 31.37% & 0.76\n",
      "for 2022-06-09, MAE is:15.19 & sMAPE is:7.88% & rMAE is:1.04 ||| daily mean of MAE & sMAPE & rMAE till now are :43.37 & 31.22% & 0.76\n",
      "for 2022-06-10, MAE is:16.11 & sMAPE is:8.92% & rMAE is:2.58 ||| daily mean of MAE & sMAPE & rMAE till now are :43.20 & 31.08% & 0.77\n",
      "for 2022-06-11, MAE is:47.81 & sMAPE is:41.52% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :43.23 & 31.15% & 0.77\n",
      "for 2022-06-12, MAE is:50.66 & sMAPE is:53.73% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :43.27 & 31.29% & 0.78\n",
      "for 2022-06-13, MAE is:13.99 & sMAPE is:9.40% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :43.10 & 31.15% & 0.77\n",
      "for 2022-06-14, MAE is:22.58 & sMAPE is:11.26% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :42.97 & 31.03% & 0.78\n",
      "for 2022-06-15, MAE is:21.89 & sMAPE is:10.22% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :42.84 & 30.91% & 0.78\n",
      "for 2022-06-16, MAE is:37.23 & sMAPE is:20.73% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :42.81 & 30.85% & 0.78\n",
      "for 2022-06-17, MAE is:43.35 & sMAPE is:17.42% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :42.81 & 30.77% & 0.78\n",
      "for 2022-06-18, MAE is:48.03 & sMAPE is:26.70% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :42.85 & 30.74% & 0.78\n",
      "for 2022-06-19, MAE is:72.94 & sMAPE is:46.21% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :43.02 & 30.83% & 0.78\n",
      "for 2022-06-20, MAE is:29.05 & sMAPE is:10.09% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :42.94 & 30.71% & 0.78\n",
      "for 2022-06-21, MAE is:60.88 & sMAPE is:21.73% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :43.04 & 30.66% & 0.78\n",
      "for 2022-06-22, MAE is:43.50 & sMAPE is:13.15% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :43.05 & 30.56% & 0.78\n",
      "for 2022-06-23, MAE is:39.71 & sMAPE is:13.31% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :43.03 & 30.46% & 0.77\n",
      "for 2022-06-24, MAE is:19.94 & sMAPE is:7.49% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :42.90 & 30.33% & 0.77\n",
      "for 2022-06-25, MAE is:30.19 & sMAPE is:12.69% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :42.82 & 30.23% & 0.77\n",
      "for 2022-06-26, MAE is:64.12 & sMAPE is:34.70% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :42.94 & 30.25% & 0.77\n",
      "for 2022-06-27, MAE is:28.46 & sMAPE is:9.22% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :42.86 & 30.13% & 0.77\n",
      "for 2022-06-28, MAE is:38.39 & sMAPE is:11.76% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :42.84 & 30.03% & 0.77\n",
      "for 2022-06-29, MAE is:35.65 & sMAPE is:10.65% & rMAE is:1.12 ||| daily mean of MAE & sMAPE & rMAE till now are :42.80 & 29.92% & 0.78\n",
      "for 2022-06-30, MAE is:45.90 & sMAPE is:14.79% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :42.82 & 29.84% & 0.78\n",
      "for 2022-07-01, MAE is:28.47 & sMAPE is:9.02% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :42.74 & 29.73% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-07-02, MAE is:84.15 & sMAPE is:39.38% & rMAE is:1.92 ||| daily mean of MAE & sMAPE & rMAE till now are :42.96 & 29.78% & 0.78\n",
      "for 2022-07-03, MAE is:74.62 & sMAPE is:39.15% & rMAE is:3.75 ||| daily mean of MAE & sMAPE & rMAE till now are :43.13 & 29.83% & 0.80\n",
      "for 2022-07-04, MAE is:46.66 & sMAPE is:17.35% & rMAE is:1.10 ||| daily mean of MAE & sMAPE & rMAE till now are :43.15 & 29.76% & 0.80\n",
      "for 2022-07-05, MAE is:39.79 & sMAPE is:12.76% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :43.14 & 29.67% & 0.80\n",
      "for 2022-07-06, MAE is:51.68 & sMAPE is:18.22% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :43.18 & 29.61% & 0.80\n",
      "for 2022-07-07, MAE is:94.25 & sMAPE is:35.90% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :43.45 & 29.64% & 0.80\n",
      "for 2022-07-08, MAE is:70.65 & sMAPE is:24.83% & rMAE is:1.51 ||| daily mean of MAE & sMAPE & rMAE till now are :43.60 & 29.62% & 0.81\n",
      "for 2022-07-09, MAE is:149.29 & sMAPE is:78.97% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :44.15 & 29.88% & 0.81\n",
      "for 2022-07-10, MAE is:73.58 & sMAPE is:68.34% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :44.31 & 30.08% & 0.81\n",
      "for 2022-07-11, MAE is:85.56 & sMAPE is:26.10% & rMAE is:1.08 ||| daily mean of MAE & sMAPE & rMAE till now are :44.52 & 30.06% & 0.81\n",
      "for 2022-07-12, MAE is:49.07 & sMAPE is:13.39% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :44.55 & 29.97% & 0.81\n",
      "for 2022-07-13, MAE is:44.63 & sMAPE is:13.83% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :44.55 & 29.89% & 0.81\n",
      "for 2022-07-14, MAE is:34.62 & sMAPE is:10.06% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :44.50 & 29.79% & 0.81\n",
      "for 2022-07-15, MAE is:47.21 & sMAPE is:15.28% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :44.51 & 29.71% & 0.81\n",
      "for 2022-07-16, MAE is:147.81 & sMAPE is:86.84% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :45.03 & 30.00% & 0.82\n",
      "for 2022-07-17, MAE is:74.03 & sMAPE is:37.62% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :45.18 & 30.04% & 0.82\n",
      "for 2022-07-18, MAE is:68.68 & sMAPE is:16.44% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :45.30 & 29.97% & 0.82\n",
      "for 2022-07-19, MAE is:62.48 & sMAPE is:15.00% & rMAE is:1.58 ||| daily mean of MAE & sMAPE & rMAE till now are :45.38 & 29.90% & 0.82\n",
      "for 2022-07-20, MAE is:54.87 & sMAPE is:16.76% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :45.43 & 29.83% & 0.82\n",
      "for 2022-07-21, MAE is:24.25 & sMAPE is:6.21% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :45.33 & 29.72% & 0.82\n",
      "for 2022-07-22, MAE is:32.80 & sMAPE is:8.75% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :45.26 & 29.61% & 0.82\n",
      "for 2022-07-23, MAE is:33.77 & sMAPE is:9.94% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :45.21 & 29.52% & 0.81\n",
      "for 2022-07-24, MAE is:86.91 & sMAPE is:41.48% & rMAE is:1.72 ||| daily mean of MAE & sMAPE & rMAE till now are :45.41 & 29.57% & 0.82\n",
      "for 2022-07-25, MAE is:49.09 & sMAPE is:14.93% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :45.43 & 29.50% & 0.82\n",
      "for 2022-07-26, MAE is:63.70 & sMAPE is:21.04% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :45.52 & 29.46% & 0.82\n",
      "for 2022-07-27, MAE is:82.30 & sMAPE is:21.81% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :45.69 & 29.43% & 0.82\n",
      "for 2022-07-28, MAE is:57.86 & sMAPE is:12.90% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :45.75 & 29.35% & 0.82\n",
      "for 2022-07-29, MAE is:31.76 & sMAPE is:7.19% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :45.69 & 29.24% & 0.82\n",
      "for 2022-07-30, MAE is:50.03 & sMAPE is:14.10% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :45.71 & 29.17% & 0.82\n",
      "for 2022-07-31, MAE is:51.77 & sMAPE is:16.51% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :45.74 & 29.11% & 0.82\n",
      "for 2022-08-01, MAE is:42.22 & sMAPE is:10.48% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :45.72 & 29.02% & 0.81\n",
      "for 2022-08-02, MAE is:53.40 & sMAPE is:15.53% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :45.75 & 28.96% & 0.81\n",
      "for 2022-08-03, MAE is:59.58 & sMAPE is:16.91% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :45.82 & 28.90% & 0.82\n",
      "for 2022-08-04, MAE is:40.85 & sMAPE is:9.83% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :45.80 & 28.82% & 0.81\n",
      "for 2022-08-05, MAE is:45.65 & sMAPE is:12.16% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :45.80 & 28.74% & 0.81\n",
      "for 2022-08-06, MAE is:87.47 & sMAPE is:30.40% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :45.99 & 28.75% & 0.81\n",
      "for 2022-08-07, MAE is:93.19 & sMAPE is:45.58% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :46.20 & 28.82% & 0.82\n",
      "for 2022-08-08, MAE is:40.92 & sMAPE is:11.76% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :46.18 & 28.75% & 0.81\n",
      "for 2022-08-09, MAE is:45.64 & sMAPE is:13.09% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :46.18 & 28.67% & 0.81\n",
      "for 2022-08-10, MAE is:35.86 & sMAPE is:10.52% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :46.13 & 28.59% & 0.81\n",
      "for 2022-08-11, MAE is:42.67 & sMAPE is:11.81% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :46.11 & 28.52% & 0.81\n",
      "for 2022-08-12, MAE is:72.92 & sMAPE is:18.14% & rMAE is:1.24 ||| daily mean of MAE & sMAPE & rMAE till now are :46.23 & 28.47% & 0.82\n",
      "for 2022-08-13, MAE is:53.32 & sMAPE is:15.46% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :46.26 & 28.41% & 0.81\n",
      "for 2022-08-14, MAE is:61.70 & sMAPE is:23.59% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :46.33 & 28.39% & 0.81\n",
      "for 2022-08-15, MAE is:53.24 & sMAPE is:13.77% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :46.36 & 28.33% & 0.81\n",
      "for 2022-08-16, MAE is:69.17 & sMAPE is:14.68% & rMAE is:0.47 ||| daily mean of MAE & sMAPE & rMAE till now are :46.46 & 28.27% & 0.81\n",
      "for 2022-08-17, MAE is:56.89 & sMAPE is:10.68% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :46.51 & 28.19% & 0.81\n",
      "for 2022-08-18, MAE is:43.90 & sMAPE is:8.39% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :46.50 & 28.10% & 0.81\n",
      "for 2022-08-19, MAE is:34.14 & sMAPE is:6.97% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :46.44 & 28.01% & 0.80\n",
      "for 2022-08-20, MAE is:38.55 & sMAPE is:8.92% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :46.41 & 27.93% & 0.80\n",
      "for 2022-08-21, MAE is:103.63 & sMAPE is:33.02% & rMAE is:1.75 ||| daily mean of MAE & sMAPE & rMAE till now are :46.66 & 27.95% & 0.81\n",
      "for 2022-08-22, MAE is:59.71 & sMAPE is:11.45% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :46.71 & 27.88% & 0.81\n",
      "for 2022-08-23, MAE is:94.48 & sMAPE is:17.01% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :46.91 & 27.84% & 0.81\n",
      "for 2022-08-24, MAE is:69.70 & sMAPE is:11.58% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :47.01 & 27.77% & 0.81\n",
      "for 2022-08-25, MAE is:56.66 & sMAPE is:9.65% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :47.05 & 27.69% & 0.81\n",
      "for 2022-08-26, MAE is:125.04 & sMAPE is:19.90% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :47.38 & 27.66% & 0.81\n",
      "for 2022-08-27, MAE is:55.80 & sMAPE is:9.22% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :47.41 & 27.58% & 0.80\n",
      "for 2022-08-28, MAE is:145.97 & sMAPE is:44.65% & rMAE is:1.76 ||| daily mean of MAE & sMAPE & rMAE till now are :47.83 & 27.65% & 0.81\n",
      "for 2022-08-29, MAE is:119.25 & sMAPE is:19.49% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :48.12 & 27.62% & 0.81\n",
      "for 2022-08-30, MAE is:73.48 & sMAPE is:11.07% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :48.23 & 27.55% & 0.81\n",
      "for 2022-08-31, MAE is:51.07 & sMAPE is:8.63% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :48.24 & 27.47% & 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-09-01, MAE is:57.56 & sMAPE is:10.02% & rMAE is:1.69 ||| daily mean of MAE & sMAPE & rMAE till now are :48.28 & 27.40% & 0.82\n",
      "for 2022-09-02, MAE is:138.49 & sMAPE is:30.38% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :48.64 & 27.41% & 0.82\n",
      "for 2022-09-03, MAE is:92.24 & sMAPE is:35.82% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :48.82 & 27.45% & 0.81\n",
      "for 2022-09-04, MAE is:115.22 & sMAPE is:49.60% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :49.09 & 27.54% & 0.81\n",
      "for 2022-09-05, MAE is:94.78 & sMAPE is:27.74% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :49.28 & 27.54% & 0.81\n",
      "for 2022-09-06, MAE is:86.03 & sMAPE is:21.40% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :49.42 & 27.51% & 0.81\n",
      "for 2022-09-07, MAE is:43.30 & sMAPE is:9.63% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :49.40 & 27.44% & 0.81\n",
      "for 2022-09-08, MAE is:40.72 & sMAPE is:9.10% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :49.36 & 27.37% & 0.80\n",
      "for 2022-09-09, MAE is:53.41 & sMAPE is:15.98% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.38 & 27.32% & 0.80\n",
      "for 2022-09-10, MAE is:61.90 & sMAPE is:16.86% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :49.43 & 27.28% & 0.80\n",
      "for 2022-09-11, MAE is:41.15 & sMAPE is:11.17% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :49.40 & 27.22% & 0.80\n",
      "for 2022-09-12, MAE is:47.60 & sMAPE is:11.46% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :49.39 & 27.16% & 0.80\n",
      "for 2022-09-13, MAE is:37.66 & sMAPE is:9.62% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :49.34 & 27.09% & 0.80\n",
      "for 2022-09-14, MAE is:72.87 & sMAPE is:16.69% & rMAE is:1.61 ||| daily mean of MAE & sMAPE & rMAE till now are :49.44 & 27.05% & 0.80\n",
      "for 2022-09-15, MAE is:51.59 & sMAPE is:14.05% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :49.44 & 27.00% & 0.80\n",
      "for 2022-09-16, MAE is:141.44 & sMAPE is:63.68% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 27.14% & 0.80\n",
      "for 2022-09-17, MAE is:121.96 & sMAPE is:98.24% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :50.08 & 27.41% & 0.80\n",
      "for 2022-09-18, MAE is:38.80 & sMAPE is:54.64% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :50.03 & 27.52% & 0.80\n",
      "for 2022-09-19, MAE is:102.20 & sMAPE is:41.21% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :50.23 & 27.57% & 0.80\n",
      "for 2022-09-20, MAE is:65.54 & sMAPE is:18.60% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :50.29 & 27.53% & 0.80\n",
      "for 2022-09-21, MAE is:49.18 & sMAPE is:12.49% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :50.29 & 27.48% & 0.80\n",
      "for 2022-09-22, MAE is:69.78 & sMAPE is:18.25% & rMAE is:1.46 ||| daily mean of MAE & sMAPE & rMAE till now are :50.36 & 27.44% & 0.80\n",
      "for 2022-09-23, MAE is:35.42 & sMAPE is:9.62% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :50.30 & 27.38% & 0.80\n",
      "for 2022-09-24, MAE is:35.39 & sMAPE is:10.71% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :50.25 & 27.31% & 0.80\n",
      "for 2022-09-25, MAE is:35.59 & sMAPE is:13.00% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :50.19 & 27.26% & 0.80\n",
      "for 2022-09-26, MAE is:80.17 & sMAPE is:32.88% & rMAE is:1.70 ||| daily mean of MAE & sMAPE & rMAE till now are :50.30 & 27.28% & 0.80\n",
      "for 2022-09-27, MAE is:41.50 & sMAPE is:14.82% & rMAE is:0.75 ||| daily mean of MAE & sMAPE & rMAE till now are :50.27 & 27.23% & 0.80\n",
      "for 2022-09-28, MAE is:87.26 & sMAPE is:23.75% & rMAE is:2.59 ||| daily mean of MAE & sMAPE & rMAE till now are :50.41 & 27.22% & 0.81\n",
      "for 2022-09-29, MAE is:60.53 & sMAPE is:14.36% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :50.45 & 27.17% & 0.81\n",
      "for 2022-09-30, MAE is:98.63 & sMAPE is:30.77% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :50.62 & 27.19% & 0.81\n",
      "for 2022-10-01, MAE is:87.35 & sMAPE is:80.13% & rMAE is:0.33 ||| daily mean of MAE & sMAPE & rMAE till now are :50.76 & 27.38% & 0.81\n",
      "for 2022-10-02, MAE is:58.94 & sMAPE is:50.04% & rMAE is:0.36 ||| daily mean of MAE & sMAPE & rMAE till now are :50.79 & 27.46% & 0.81\n",
      "for 2022-10-03, MAE is:80.68 & sMAPE is:40.36% & rMAE is:1.79 ||| daily mean of MAE & sMAPE & rMAE till now are :50.89 & 27.51% & 0.81\n",
      "for 2022-10-04, MAE is:87.42 & sMAPE is:34.21% & rMAE is:1.11 ||| daily mean of MAE & sMAPE & rMAE till now are :51.03 & 27.53% & 0.81\n",
      "for 2022-10-05, MAE is:107.54 & sMAPE is:78.99% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :51.23 & 27.72% & 0.81\n",
      "for 2022-10-06, MAE is:60.79 & sMAPE is:88.31% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :51.26 & 27.94% & 0.81\n",
      "for 2022-10-07, MAE is:53.99 & sMAPE is:34.13% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :51.27 & 27.96% & 0.81\n",
      "for 2022-10-08, MAE is:35.66 & sMAPE is:26.17% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :51.22 & 27.95% & 0.81\n",
      "for 2022-10-09, MAE is:46.06 & sMAPE is:32.59% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :51.20 & 27.97% & 0.81\n",
      "for 2022-10-10, MAE is:35.41 & sMAPE is:24.04% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :51.14 & 27.95% & 0.81\n",
      "for 2022-10-11, MAE is:65.79 & sMAPE is:25.99% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :51.20 & 27.95% & 0.81\n",
      "for 2022-10-12, MAE is:48.98 & sMAPE is:15.73% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :51.19 & 27.90% & 0.80\n",
      "for 2022-10-13, MAE is:39.06 & sMAPE is:15.78% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :51.15 & 27.86% & 0.80\n",
      "for 2022-10-14, MAE is:55.82 & sMAPE is:23.03% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :51.16 & 27.85% & 0.80\n",
      "for 2022-10-15, MAE is:28.73 & sMAPE is:16.85% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :51.08 & 27.81% & 0.80\n",
      "for 2022-10-16, MAE is:42.05 & sMAPE is:45.50% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :51.05 & 27.87% & 0.80\n",
      "for 2022-10-17, MAE is:22.97 & sMAPE is:14.00% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :50.96 & 27.82% & 0.80\n",
      "for 2022-10-18, MAE is:24.59 & sMAPE is:13.04% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :50.86 & 27.77% & 0.80\n",
      "for 2022-10-19, MAE is:21.99 & sMAPE is:12.58% & rMAE is:0.19 ||| daily mean of MAE & sMAPE & rMAE till now are :50.77 & 27.72% & 0.80\n",
      "for 2022-10-20, MAE is:14.99 & sMAPE is:11.63% & rMAE is:0.13 ||| daily mean of MAE & sMAPE & rMAE till now are :50.64 & 27.66% & 0.80\n",
      "for 2022-10-21, MAE is:22.71 & sMAPE is:15.25% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :50.55 & 27.62% & 0.79\n",
      "for 2022-10-22, MAE is:14.20 & sMAPE is:10.85% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :50.43 & 27.56% & 0.79\n",
      "for 2022-10-23, MAE is:27.31 & sMAPE is:24.72% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :50.35 & 27.55% & 0.79\n",
      "for 2022-10-24, MAE is:17.83 & sMAPE is:23.54% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :50.24 & 27.54% & 0.79\n",
      "for 2022-10-25, MAE is:18.76 & sMAPE is:17.30% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :50.13 & 27.51% & 0.79\n",
      "for 2022-10-26, MAE is:13.67 & sMAPE is:11.29% & rMAE is:0.29 ||| daily mean of MAE & sMAPE & rMAE till now are :50.01 & 27.45% & 0.79\n",
      "for 2022-10-27, MAE is:22.31 & sMAPE is:19.34% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :49.92 & 27.43% & 0.79\n",
      "for 2022-10-28, MAE is:13.75 & sMAPE is:12.44% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :49.80 & 27.38% & 0.79\n",
      "for 2022-10-29, MAE is:14.59 & sMAPE is:15.92% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :49.68 & 27.34% & 0.79\n",
      "for 2022-10-30, MAE is:23.62 & sMAPE is:21.51% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :49.60 & 27.32% & 0.79\n",
      "for 2022-10-31, MAE is:26.05 & sMAPE is:19.18% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :49.52 & 27.29% & 0.78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2022-11-01, MAE is:49.09 & sMAPE is:55.87% & rMAE is:1.21 ||| daily mean of MAE & sMAPE & rMAE till now are :49.52 & 27.39% & 0.79\n",
      "for 2022-11-02, MAE is:23.89 & sMAPE is:38.08% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.43 & 27.42% & 0.79\n",
      "for 2022-11-03, MAE is:23.96 & sMAPE is:25.21% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :49.35 & 27.41% & 0.79\n",
      "for 2022-11-04, MAE is:74.05 & sMAPE is:49.12% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :49.43 & 27.48% & 0.79\n",
      "for 2022-11-05, MAE is:25.34 & sMAPE is:18.46% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :49.35 & 27.45% & 0.79\n",
      "for 2022-11-06, MAE is:47.96 & sMAPE is:68.55% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :49.35 & 27.59% & 0.79\n",
      "for 2022-11-07, MAE is:29.70 & sMAPE is:67.70% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :49.28 & 27.72% & 0.78\n",
      "for 2022-11-08, MAE is:21.72 & sMAPE is:25.22% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :49.20 & 27.71% & 0.78\n",
      "for 2022-11-09, MAE is:30.69 & sMAPE is:24.68% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :49.14 & 27.70% & 0.78\n",
      "for 2022-11-10, MAE is:25.29 & sMAPE is:18.27% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :49.06 & 27.67% & 0.78\n",
      "for 2022-11-11, MAE is:22.89 & sMAPE is:17.59% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :48.98 & 27.64% & 0.78\n",
      "for 2022-11-12, MAE is:34.45 & sMAPE is:22.85% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :48.93 & 27.62% & 0.78\n",
      "for 2022-11-13, MAE is:16.37 & sMAPE is:11.04% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :48.83 & 27.57% & 0.78\n",
      "for 2022-11-14, MAE is:30.00 & sMAPE is:18.33% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :48.77 & 27.54% & 0.78\n",
      "for 2022-11-15, MAE is:27.69 & sMAPE is:15.58% & rMAE is:0.34 ||| daily mean of MAE & sMAPE & rMAE till now are :48.70 & 27.50% & 0.78\n",
      "for 2022-11-16, MAE is:33.80 & sMAPE is:25.60% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :48.66 & 27.50% & 0.78\n",
      "for 2022-11-17, MAE is:34.99 & sMAPE is:48.40% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :48.61 & 27.56% & 0.78\n",
      "for 2022-11-18, MAE is:39.26 & sMAPE is:24.78% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :48.59 & 27.55% & 0.78\n",
      "for 2022-11-19, MAE is:70.64 & sMAPE is:41.58% & rMAE is:1.81 ||| daily mean of MAE & sMAPE & rMAE till now are :48.65 & 27.60% & 0.78\n",
      "for 2022-11-20, MAE is:32.33 & sMAPE is:16.36% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :48.60 & 27.56% & 0.78\n",
      "for 2022-11-21, MAE is:67.93 & sMAPE is:27.74% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :48.66 & 27.56% & 0.78\n",
      "for 2022-11-22, MAE is:30.20 & sMAPE is:16.98% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :48.61 & 27.53% & 0.78\n",
      "for 2022-11-23, MAE is:31.77 & sMAPE is:16.89% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :48.55 & 27.50% & 0.78\n",
      "for 2022-11-24, MAE is:88.82 & sMAPE is:42.51% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :48.68 & 27.54% & 0.78\n",
      "for 2022-11-25, MAE is:57.26 & sMAPE is:23.35% & rMAE is:0.66 ||| daily mean of MAE & sMAPE & rMAE till now are :48.70 & 27.53% & 0.78\n",
      "for 2022-11-26, MAE is:21.73 & sMAPE is:9.19% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :48.62 & 27.47% & 0.78\n",
      "for 2022-11-27, MAE is:33.93 & sMAPE is:20.75% & rMAE is:0.53 ||| daily mean of MAE & sMAPE & rMAE till now are :48.58 & 27.45% & 0.78\n",
      "for 2022-11-28, MAE is:116.59 & sMAPE is:45.01% & rMAE is:2.05 ||| daily mean of MAE & sMAPE & rMAE till now are :48.78 & 27.51% & 0.78\n",
      "for 2022-11-29, MAE is:85.31 & sMAPE is:24.47% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :48.89 & 27.50% & 0.78\n",
      "for 2022-11-30, MAE is:89.35 & sMAPE is:23.95% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :49.01 & 27.49% & 0.78\n",
      "for 2022-12-01, MAE is:75.84 & sMAPE is:20.67% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.09 & 27.47% & 0.78\n",
      "for 2022-12-02, MAE is:55.05 & sMAPE is:16.66% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :49.11 & 27.43% & 0.78\n",
      "for 2022-12-03, MAE is:39.88 & sMAPE is:15.04% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 27.40% & 0.78\n",
      "for 2022-12-04, MAE is:27.83 & sMAPE is:10.33% & rMAE is:0.23 ||| daily mean of MAE & sMAPE & rMAE till now are :49.02 & 27.35% & 0.78\n",
      "for 2022-12-05, MAE is:68.46 & sMAPE is:20.92% & rMAE is:1.38 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 27.33% & 0.78\n",
      "for 2022-12-06, MAE is:61.56 & sMAPE is:17.31% & rMAE is:2.23 ||| daily mean of MAE & sMAPE & rMAE till now are :49.11 & 27.30% & 0.78\n",
      "for 2022-12-07, MAE is:35.29 & sMAPE is:10.45% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :49.07 & 27.25% & 0.78\n",
      "for 2022-12-08, MAE is:62.09 & sMAPE is:16.87% & rMAE is:5.47 ||| daily mean of MAE & sMAPE & rMAE till now are :49.11 & 27.22% & 0.80\n",
      "for 2022-12-09, MAE is:75.78 & sMAPE is:19.65% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :49.19 & 27.20% & 0.80\n",
      "for 2022-12-10, MAE is:36.20 & sMAPE is:10.60% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :49.15 & 27.15% & 0.80\n",
      "for 2022-12-11, MAE is:28.22 & sMAPE is:9.09% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.09 & 27.10% & 0.80\n",
      "for 2022-12-12, MAE is:99.28 & sMAPE is:23.87% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :49.24 & 27.09% & 0.80\n",
      "for 2022-12-13, MAE is:83.15 & sMAPE is:18.23% & rMAE is:1.42 ||| daily mean of MAE & sMAPE & rMAE till now are :49.33 & 27.06% & 0.80\n",
      "for 2022-12-14, MAE is:101.24 & sMAPE is:23.81% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :49.48 & 27.05% & 0.80\n",
      "for 2022-12-15, MAE is:23.50 & sMAPE is:5.93% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :49.41 & 26.99% & 0.80\n",
      "for 2022-12-16, MAE is:64.44 & sMAPE is:16.01% & rMAE is:2.35 ||| daily mean of MAE & sMAPE & rMAE till now are :49.45 & 26.96% & 0.80\n",
      "for 2022-12-17, MAE is:61.37 & sMAPE is:19.77% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :49.49 & 26.94% & 0.80\n",
      "for 2022-12-18, MAE is:40.51 & sMAPE is:19.68% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :49.46 & 26.92% & 0.80\n",
      "for 2022-12-19, MAE is:25.92 & sMAPE is:13.82% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :49.39 & 26.88% & 0.80\n",
      "for 2022-12-20, MAE is:31.90 & sMAPE is:16.34% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :49.34 & 26.85% & 0.80\n",
      "for 2022-12-21, MAE is:49.72 & sMAPE is:22.29% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :49.35 & 26.84% & 0.80\n",
      "for 2022-12-22, MAE is:24.26 & sMAPE is:13.62% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :49.28 & 26.80% & 0.80\n",
      "for 2022-12-23, MAE is:30.75 & sMAPE is:16.10% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :49.22 & 26.77% & 0.79\n",
      "for 2022-12-24, MAE is:32.50 & sMAPE is:32.39% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :49.18 & 26.79% & 0.79\n",
      "for 2022-12-25, MAE is:26.81 & sMAPE is:22.45% & rMAE is:0.32 ||| daily mean of MAE & sMAPE & rMAE till now are :49.11 & 26.78% & 0.79\n",
      "for 2022-12-26, MAE is:62.02 & sMAPE is:88.53% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :49.15 & 26.95% & 0.79\n",
      "for 2022-12-27, MAE is:25.03 & sMAPE is:33.19% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 26.97% & 0.79\n",
      "for 2022-12-28, MAE is:81.55 & sMAPE is:106.64% & rMAE is:0.48 ||| daily mean of MAE & sMAPE & rMAE till now are :49.17 & 27.19% & 0.79\n",
      "for 2022-12-29, MAE is:37.96 & sMAPE is:143.86% & rMAE is:0.21 ||| daily mean of MAE & sMAPE & rMAE till now are :49.14 & 27.51% & 0.79\n",
      "for 2022-12-30, MAE is:27.80 & sMAPE is:93.47% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :49.08 & 27.69% & 0.78\n",
      "for 2022-12-31, MAE is:25.11 & sMAPE is:199.09% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :49.02 & 28.16% & 0.78\n",
      "Directory 'C:\\Users\\z110474\\Time Series Paper\\Modular_Codes- V 6.3\\hyperparameter_optimization_trials' already exists, using it to store the results of the hyperparameter optimization!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:14:23,918]\u001b[0m A new study created in RDB with name: DE_2023\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:44,399]\u001b[0m Trial 1 finished with value: 51.56777648055574 and parameters: {'n_hidden': 3, 'learning_rate': 0.012662324296397836, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1718297118840731, 'dropout_rate_Layer_2': 0.16293013410050106, 'dropout_rate_Layer_3': 0.11501845994011295, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.717674672146979e-05, 'l1_Layer_2': 0.00599154976937566, 'l1_Layer_3': 0.03490943478649447, 'n_units_Layer_1': 150, 'n_units_Layer_2': 225, 'n_units_Layer_3': 285}. Best is trial 1 with value: 51.56777648055574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.57 | sMAPE for Validation Set is: 29.28% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:14:44,556]\u001b[0m Trial 3 pruned. Trial was pruned at epoch 58.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:45,525]\u001b[0m Trial 2 finished with value: 100.63773498686555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013673908354001265, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.16334651832077834, 'dropout_rate_Layer_2': 0.13817917744933214, 'dropout_rate_Layer_3': 0.2581944129694595, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013876094398524762, 'l1_Layer_2': 1.5527674251791517e-05, 'l1_Layer_3': 0.0002149033652500531, 'n_units_Layer_1': 160, 'n_units_Layer_2': 100, 'n_units_Layer_3': 190}. Best is trial 1 with value: 51.56777648055574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.64 | sMAPE for Validation Set is: 47.44% | rMAE for Validation Set is: 1.16\n",
      "MAE for Test Set is: 27.43 | sMAPE for Test Set is: 31.28% | rMAE for Test Set is: 0.80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:14:50,043]\u001b[0m Trial 4 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:51,439]\u001b[0m Trial 5 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:54,003]\u001b[0m Trial 7 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:54,675]\u001b[0m Trial 8 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:57,811]\u001b[0m Trial 9 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:14:59,920]\u001b[0m Trial 10 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:04,514]\u001b[0m Trial 12 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:09,422]\u001b[0m Trial 13 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:12,617]\u001b[0m Trial 14 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:17,809]\u001b[0m Trial 15 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:21,648]\u001b[0m Trial 16 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:25,892]\u001b[0m Trial 17 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:30,039]\u001b[0m Trial 18 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:30,603]\u001b[0m Trial 0 finished with value: 65.3519820714463 and parameters: {'n_hidden': 3, 'learning_rate': 0.013016094794548612, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.331528877936889, 'dropout_rate_Layer_2': 0.21189159281514086, 'dropout_rate_Layer_3': 0.34143006338930815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.0005836790155653299, 'l1_Layer_2': 0.09778601756829204, 'l1_Layer_3': 0.0014632686327838648, 'n_units_Layer_1': 135, 'n_units_Layer_2': 125, 'n_units_Layer_3': 160}. Best is trial 1 with value: 51.56777648055574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 65.35 | sMAPE for Validation Set is: 33.27% | rMAE for Validation Set is: 0.75\n",
      "MAE for Test Set is: 22.36 | sMAPE for Test Set is: 30.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:15:38,229]\u001b[0m Trial 19 finished with value: 102.6592167048481 and parameters: {'n_hidden': 3, 'learning_rate': 0.03431713176814728, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.22350813878148293, 'dropout_rate_Layer_2': 0.26507335791109876, 'dropout_rate_Layer_3': 0.3620723046339904, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009141118666660712, 'l1_Layer_2': 0.00030024327775934694, 'l1_Layer_3': 2.528795510311859e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 280, 'n_units_Layer_3': 225}. Best is trial 1 with value: 51.56777648055574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 102.66 | sMAPE for Validation Set is: 48.98% | rMAE for Validation Set is: 1.18\n",
      "MAE for Test Set is: 34.28 | sMAPE for Test Set is: 38.39% | rMAE for Test Set is: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:15:42,207]\u001b[0m Trial 11 finished with value: 52.09005505322521 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006119398576103992, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.27736532765667854, 'dropout_rate_Layer_2': 0.0014076167391164685, 'dropout_rate_Layer_3': 0.3930941336383762, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.010315213431842734, 'l1_Layer_2': 0.0013046490947950017, 'l1_Layer_3': 0.050462647229350475, 'n_units_Layer_1': 250, 'n_units_Layer_2': 65, 'n_units_Layer_3': 300}. Best is trial 1 with value: 51.56777648055574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.09 | sMAPE for Validation Set is: 29.33% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.35 | sMAPE for Test Set is: 30.15% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:15:42,745]\u001b[0m Trial 21 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:46,239]\u001b[0m Trial 22 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:49,760]\u001b[0m Trial 23 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:51,264]\u001b[0m Trial 24 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:56,433]\u001b[0m Trial 25 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:15:58,042]\u001b[0m Trial 26 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:02,387]\u001b[0m Trial 28 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:03,196]\u001b[0m Trial 6 finished with value: 79.72275847795511 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009824547497489472, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2856609410393065, 'dropout_rate_Layer_2': 0.3242241630683802, 'dropout_rate_Layer_3': 0.08328118968060005, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'sigmoid', 'l1_Layer_1': 0.05224337735879891, 'l1_Layer_2': 1.4128595438506504e-05, 'l1_Layer_3': 0.0010512850085685269, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 160}. Best is trial 1 with value: 51.56777648055574.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 79.72 | sMAPE for Validation Set is: 38.59% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 25.15 | sMAPE for Test Set is: 30.58% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:16:07,230]\u001b[0m Trial 27 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:08,944]\u001b[0m Trial 29 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:12,134]\u001b[0m Trial 30 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:12,665]\u001b[0m Trial 20 finished with value: 42.83385160312389 and parameters: {'n_hidden': 4, 'learning_rate': 0.002614421603115929, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2830201042348289, 'dropout_rate_Layer_2': 0.11565100825854434, 'dropout_rate_Layer_3': 0.07686442520442505, 'dropout_rate_Layer_4': 0.27535479080717806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'activation_Layer_4': 'relu', 'l1_Layer_1': 4.979194091788082e-05, 'l1_Layer_2': 0.00034511544397420886, 'l1_Layer_3': 0.0004627201717316901, 'l1_Layer_4': 2.7135343471917415e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 250, 'n_units_Layer_3': 195, 'n_units_Layer_4': 170}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.83 | sMAPE for Validation Set is: 25.57% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.60 | sMAPE for Test Set is: 27.67% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:16:15,815]\u001b[0m Trial 31 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:18,760]\u001b[0m Trial 34 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:19,262]\u001b[0m Trial 32 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:20,493]\u001b[0m Trial 33 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:25,032]\u001b[0m Trial 36 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:25,306]\u001b[0m Trial 37 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:25,574]\u001b[0m Trial 38 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:25,671]\u001b[0m Trial 35 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:35,502]\u001b[0m Trial 39 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:38,172]\u001b[0m Trial 41 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:38,312]\u001b[0m Trial 42 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:43,239]\u001b[0m Trial 43 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:47,261]\u001b[0m Trial 44 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:51,499]\u001b[0m Trial 47 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:16:54,736]\u001b[0m Trial 48 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:00,302]\u001b[0m Trial 49 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:07,228]\u001b[0m Trial 50 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:15,594]\u001b[0m Trial 51 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:19,523]\u001b[0m Trial 45 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:19,873]\u001b[0m Trial 52 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:24,404]\u001b[0m Trial 53 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:24,798]\u001b[0m Trial 54 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:25,165]\u001b[0m Trial 40 finished with value: 80.54187804773532 and parameters: {'n_hidden': 3, 'learning_rate': 0.004689638740520028, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3389512929954981, 'dropout_rate_Layer_2': 0.32608290066551504, 'dropout_rate_Layer_3': 0.2669730710960589, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00029753799297922587, 'l1_Layer_2': 0.055129345892134626, 'l1_Layer_3': 0.0019563198310966526, 'n_units_Layer_1': 160, 'n_units_Layer_2': 115, 'n_units_Layer_3': 300}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 80.54 | sMAPE for Validation Set is: 39.33% | rMAE for Validation Set is: 0.92\n",
      "MAE for Test Set is: 26.33 | sMAPE for Test Set is: 30.98% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:17:29,442]\u001b[0m Trial 55 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:31,150]\u001b[0m Trial 46 finished with value: 78.61389012318084 and parameters: {'n_hidden': 3, 'learning_rate': 0.004241762083745334, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32540516360429883, 'dropout_rate_Layer_2': 0.015248988891505083, 'dropout_rate_Layer_3': 0.30047760205831225, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002804309090679131, 'l1_Layer_2': 0.05700224315764455, 'l1_Layer_3': 0.0016567766277086865, 'n_units_Layer_1': 165, 'n_units_Layer_2': 110, 'n_units_Layer_3': 125}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 78.61 | sMAPE for Validation Set is: 38.54% | rMAE for Validation Set is: 0.90\n",
      "MAE for Test Set is: 26.32 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:17:36,459]\u001b[0m Trial 57 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:36,647]\u001b[0m Trial 56 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:38,621]\u001b[0m Trial 58 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:43,593]\u001b[0m Trial 60 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:44,885]\u001b[0m Trial 62 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:45,893]\u001b[0m Trial 61 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:50,871]\u001b[0m Trial 63 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:51,151]\u001b[0m Trial 64 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:53,744]\u001b[0m Trial 65 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:57,078]\u001b[0m Trial 66 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:58,079]\u001b[0m Trial 68 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:17:59,242]\u001b[0m Trial 59 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:03,880]\u001b[0m Trial 67 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:04,964]\u001b[0m Trial 71 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:11,777]\u001b[0m Trial 72 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:14,295]\u001b[0m Trial 69 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:17,573]\u001b[0m Trial 74 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:19,851]\u001b[0m Trial 73 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:29,026]\u001b[0m Trial 76 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:30,604]\u001b[0m Trial 77 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:31,192]\u001b[0m Trial 70 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:38,410]\u001b[0m Trial 80 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:41,945]\u001b[0m Trial 79 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:42,301]\u001b[0m Trial 75 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:48,306]\u001b[0m Trial 82 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:54,247]\u001b[0m Trial 84 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:18:56,239]\u001b[0m Trial 83 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:01,459]\u001b[0m Trial 81 finished with value: 52.1384079833903 and parameters: {'n_hidden': 4, 'learning_rate': 0.017229003146207286, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17808697307204038, 'dropout_rate_Layer_2': 0.26348433025355533, 'dropout_rate_Layer_3': 0.0467155924580773, 'dropout_rate_Layer_4': 0.3675143998818813, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.007576862008502948, 'l1_Layer_2': 0.014409981121242713, 'l1_Layer_3': 6.85756171841498e-05, 'l1_Layer_4': 0.00942878515146036, 'n_units_Layer_1': 130, 'n_units_Layer_2': 90, 'n_units_Layer_3': 125, 'n_units_Layer_4': 85}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.14 | sMAPE for Validation Set is: 29.47% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 27.84 | sMAPE for Test Set is: 33.03% | rMAE for Test Set is: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:19:01,692]\u001b[0m Trial 85 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:08,612]\u001b[0m Trial 87 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:08,784]\u001b[0m Trial 88 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:09,189]\u001b[0m Trial 86 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:16,065]\u001b[0m Trial 89 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:16,702]\u001b[0m Trial 91 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:20,489]\u001b[0m Trial 90 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.34 | sMAPE for Validation Set is: 26.75% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.28 | sMAPE for Test Set is: 26.38% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:19:20,943]\u001b[0m Trial 78 finished with value: 45.34268562605704 and parameters: {'n_hidden': 3, 'learning_rate': 0.006184945632605504, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010491653452764677, 'dropout_rate_Layer_2': 0.2367439767471019, 'dropout_rate_Layer_3': 0.32589554536295157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001636035519517982, 'l1_Layer_2': 0.059060329455518173, 'l1_Layer_3': 0.018865932882527126, 'n_units_Layer_1': 165, 'n_units_Layer_2': 185, 'n_units_Layer_3': 150}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:22,685]\u001b[0m Trial 92 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:27,920]\u001b[0m Trial 94 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:30,933]\u001b[0m Trial 96 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:32,230]\u001b[0m Trial 97 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:36,981]\u001b[0m Trial 99 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:47,259]\u001b[0m Trial 95 finished with value: 54.737621162408324 and parameters: {'n_hidden': 3, 'learning_rate': 0.00868570961956224, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039142702090788226, 'dropout_rate_Layer_2': 0.23407572689250145, 'dropout_rate_Layer_3': 0.3449634046269305, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005728402790777323, 'l1_Layer_2': 0.0401890521423475, 'l1_Layer_3': 0.05630977500107875, 'n_units_Layer_1': 115, 'n_units_Layer_2': 240, 'n_units_Layer_3': 110}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.74 | sMAPE for Validation Set is: 30.45% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 25.05 | sMAPE for Test Set is: 32.43% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:19:49,600]\u001b[0m Trial 100 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:55,554]\u001b[0m Trial 102 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:19:57,495]\u001b[0m Trial 98 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:05,876]\u001b[0m Trial 101 finished with value: 52.84762271581415 and parameters: {'n_hidden': 3, 'learning_rate': 0.009398715403734097, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04375640582837553, 'dropout_rate_Layer_2': 0.3551536412419566, 'dropout_rate_Layer_3': 0.33849270487166894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014999935152487133, 'l1_Layer_2': 0.008513604614297968, 'l1_Layer_3': 0.02681478174440572, 'n_units_Layer_1': 85, 'n_units_Layer_2': 240, 'n_units_Layer_3': 160}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.85 | sMAPE for Validation Set is: 29.78% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 24.38 | sMAPE for Test Set is: 31.59% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:20:07,967]\u001b[0m Trial 93 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:08,240]\u001b[0m Trial 104 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:14,050]\u001b[0m Trial 107 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:16,764]\u001b[0m Trial 106 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:21,559]\u001b[0m Trial 109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:25,308]\u001b[0m Trial 110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:31,359]\u001b[0m Trial 111 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:35,449]\u001b[0m Trial 112 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:38,679]\u001b[0m Trial 103 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:41,862]\u001b[0m Trial 113 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:46,262]\u001b[0m Trial 115 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.48 | sMAPE for Validation Set is: 28.67% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.47 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:20:47,828]\u001b[0m Trial 108 finished with value: 50.48390435887004 and parameters: {'n_hidden': 4, 'learning_rate': 0.006403181054039783, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.13160975768229177, 'dropout_rate_Layer_2': 0.24743211722599545, 'dropout_rate_Layer_3': 0.04919223271839605, 'dropout_rate_Layer_4': 0.2245418976934431, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.004236315831985003, 'l1_Layer_2': 1.9573467744801442e-05, 'l1_Layer_3': 0.0033853544409741727, 'l1_Layer_4': 0.0016701204489691164, 'n_units_Layer_1': 300, 'n_units_Layer_2': 95, 'n_units_Layer_3': 115, 'n_units_Layer_4': 300}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:55,119]\u001b[0m Trial 116 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:20:58,211]\u001b[0m Trial 114 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:02,496]\u001b[0m Trial 105 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:06,752]\u001b[0m Trial 117 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:07,881]\u001b[0m Trial 120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:13,196]\u001b[0m Trial 118 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:22,809]\u001b[0m Trial 123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:26,335]\u001b[0m Trial 121 finished with value: 54.95373831536739 and parameters: {'n_hidden': 3, 'learning_rate': 0.00888840155036841, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05627807596977053, 'dropout_rate_Layer_2': 0.3965128846206204, 'dropout_rate_Layer_3': 0.3493526827930655, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0012683756574676825, 'l1_Layer_2': 0.00827597057518418, 'l1_Layer_3': 0.02623568712065866, 'n_units_Layer_1': 90, 'n_units_Layer_2': 250, 'n_units_Layer_3': 160}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.95 | sMAPE for Validation Set is: 30.63% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 26.08 | sMAPE for Test Set is: 33.93% | rMAE for Test Set is: 0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:21:30,453]\u001b[0m Trial 122 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:30,864]\u001b[0m Trial 119 finished with value: 49.21385998302109 and parameters: {'n_hidden': 4, 'learning_rate': 0.011365120836466262, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12947268251756033, 'dropout_rate_Layer_2': 0.2617754028668467, 'dropout_rate_Layer_3': 0.0021750176011059684, 'dropout_rate_Layer_4': 0.052493252027950854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.0023428861490379462, 'l1_Layer_2': 2.8476931475608342e-05, 'l1_Layer_3': 0.0065784046218863084, 'l1_Layer_4': 0.0012893849917999388, 'n_units_Layer_1': 300, 'n_units_Layer_2': 80, 'n_units_Layer_3': 95, 'n_units_Layer_4': 300}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.21 | sMAPE for Validation Set is: 28.26% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.24 | sMAPE for Test Set is: 29.03% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:21:37,458]\u001b[0m Trial 124 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:37,682]\u001b[0m Trial 127 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:37,920]\u001b[0m Trial 126 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:38,127]\u001b[0m Trial 125 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:43,076]\u001b[0m Trial 128 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:49,176]\u001b[0m Trial 129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:49,516]\u001b[0m Trial 130 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:49,670]\u001b[0m Trial 131 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:21:55,759]\u001b[0m Trial 133 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:00,182]\u001b[0m Trial 135 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:03,568]\u001b[0m Trial 132 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:06,148]\u001b[0m Trial 137 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:09,861]\u001b[0m Trial 138 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:13,820]\u001b[0m Trial 140 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:17,122]\u001b[0m Trial 134 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:19,281]\u001b[0m Trial 141 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:19,819]\u001b[0m Trial 139 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:26,342]\u001b[0m Trial 144 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:31,746]\u001b[0m Trial 136 finished with value: 51.1961268190121 and parameters: {'n_hidden': 4, 'learning_rate': 0.008337802489836487, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1330530617623749, 'dropout_rate_Layer_2': 0.2932180262837681, 'dropout_rate_Layer_3': 0.028428050153024572, 'dropout_rate_Layer_4': 0.18408382883109758, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.04904529678302612, 'l1_Layer_2': 0.07884631095206183, 'l1_Layer_3': 0.0013459002860765662, 'l1_Layer_4': 0.004369648712571196, 'n_units_Layer_1': 165, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110, 'n_units_Layer_4': 65}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.20 | sMAPE for Validation Set is: 28.92% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.18 | sMAPE for Test Set is: 29.60% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:22:35,298]\u001b[0m Trial 145 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:35,952]\u001b[0m Trial 143 finished with value: 73.60169485942832 and parameters: {'n_hidden': 3, 'learning_rate': 0.003864701868863258, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2558801053888243, 'dropout_rate_Layer_2': 0.11696132392557664, 'dropout_rate_Layer_3': 0.3177893625680471, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0888770301321336e-05, 'l1_Layer_2': 0.002811193439777564, 'l1_Layer_3': 0.00045682231282974617, 'n_units_Layer_1': 165, 'n_units_Layer_2': 215, 'n_units_Layer_3': 295}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 73.60 | sMAPE for Validation Set is: 36.86% | rMAE for Validation Set is: 0.85\n",
      "MAE for Test Set is: 27.17 | sMAPE for Test Set is: 30.96% | rMAE for Test Set is: 0.79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:22:50,700]\u001b[0m Trial 148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:22:55,150]\u001b[0m Trial 149 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:01,955]\u001b[0m Trial 146 finished with value: 84.77100154201189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0971430792272357, 'batch_size': 35, 'batch_normalization': True, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10076148177402833, 'dropout_rate_Layer_2': 0.17560386652000318, 'dropout_rate_Layer_3': 0.19662742725855648, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'tanh', 'l1_Layer_1': 4.168930570167869e-05, 'l1_Layer_2': 0.00012995129252072837, 'l1_Layer_3': 0.003291259033070409, 'n_units_Layer_1': 285, 'n_units_Layer_2': 95, 'n_units_Layer_3': 295}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 84.77 | sMAPE for Validation Set is: 42.46% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 43.95 | sMAPE for Test Set is: 58.62% | rMAE for Test Set is: 1.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:23:07,752]\u001b[0m Trial 147 finished with value: 53.987458128058925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026999544387798866, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07838570206439714, 'dropout_rate_Layer_2': 0.38004914730964395, 'dropout_rate_Layer_3': 0.30670682639645086, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007722250573125739, 'l1_Layer_2': 0.07516825631733874, 'l1_Layer_3': 0.023543598632168296, 'n_units_Layer_1': 130, 'n_units_Layer_2': 300, 'n_units_Layer_3': 130}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 53.99 | sMAPE for Validation Set is: 30.39% | rMAE for Validation Set is: 0.62\n",
      "MAE for Test Set is: 25.27 | sMAPE for Test Set is: 33.09% | rMAE for Test Set is: 0.74\n",
      "MAE for Validation Set is: 84.09 | sMAPE for Validation Set is: 40.34% | rMAE for Validation Set is: 0.97\n",
      "MAE for Test Set is: 25.02 | sMAPE for Test Set is: 30.99% | rMAE for Test Set is: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:23:10,495]\u001b[0m Trial 142 finished with value: 84.09460840122215 and parameters: {'n_hidden': 3, 'learning_rate': 0.0026603408071703308, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.32381424135925296, 'dropout_rate_Layer_2': 0.1327554633257891, 'dropout_rate_Layer_3': 0.13287153580770683, 'activation_Layer_1': 'sigmoid', 'activation_Layer_2': 'tanh', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.005767973393897431, 'l1_Layer_2': 0.007846681934743825, 'l1_Layer_3': 0.00020335214846371676, 'n_units_Layer_1': 170, 'n_units_Layer_2': 130, 'n_units_Layer_3': 170}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:14,049]\u001b[0m Trial 152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:18,496]\u001b[0m Trial 153 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:19,551]\u001b[0m Trial 150 finished with value: 52.07616219937023 and parameters: {'n_hidden': 4, 'learning_rate': 0.010496511173683777, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0962603600979059, 'dropout_rate_Layer_2': 0.22367980114670907, 'dropout_rate_Layer_3': 0.05986201394008778, 'dropout_rate_Layer_4': 0.13595185832808182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.09710691358688603, 'l1_Layer_2': 2.571619169376968e-05, 'l1_Layer_3': 0.0007490876674594223, 'l1_Layer_4': 0.001338174831897517, 'n_units_Layer_1': 200, 'n_units_Layer_2': 125, 'n_units_Layer_3': 75, 'n_units_Layer_4': 65}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.08 | sMAPE for Validation Set is: 29.26% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 22.92 | sMAPE for Test Set is: 29.95% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:23:21,255]\u001b[0m Trial 151 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:27,767]\u001b[0m Trial 156 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:28,967]\u001b[0m Trial 155 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:33,081]\u001b[0m Trial 158 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:34,340]\u001b[0m Trial 159 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:39,392]\u001b[0m Trial 160 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:39,839]\u001b[0m Trial 161 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:46,908]\u001b[0m Trial 163 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:23:50,042]\u001b[0m Trial 157 finished with value: 54.57302297287591 and parameters: {'n_hidden': 3, 'learning_rate': 0.0029284206783638865, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09345926303867838, 'dropout_rate_Layer_2': 0.39716091263862463, 'dropout_rate_Layer_3': 0.3447749503975695, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0011441589341491991, 'l1_Layer_2': 0.08050472330572488, 'l1_Layer_3': 0.009643364662237438, 'n_units_Layer_1': 65, 'n_units_Layer_2': 290, 'n_units_Layer_3': 140}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 54.57 | sMAPE for Validation Set is: 30.25% | rMAE for Validation Set is: 0.63\n",
      "MAE for Test Set is: 24.36 | sMAPE for Test Set is: 31.92% | rMAE for Test Set is: 0.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:23:54,593]\u001b[0m Trial 154 finished with value: 47.65206747592938 and parameters: {'n_hidden': 3, 'learning_rate': 0.00864885213760477, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11718882986806856, 'dropout_rate_Layer_2': 0.1457551000626939, 'dropout_rate_Layer_3': 0.25961511865862064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0014348243808563123, 'l1_Layer_2': 0.0003693645001364209, 'l1_Layer_3': 0.0036387045976636907, 'n_units_Layer_1': 180, 'n_units_Layer_2': 125, 'n_units_Layer_3': 95}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.65 | sMAPE for Validation Set is: 27.64% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 22.59 | sMAPE for Test Set is: 28.89% | rMAE for Test Set is: 0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:23:58,963]\u001b[0m Trial 162 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:00,190]\u001b[0m Trial 166 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:04,404]\u001b[0m Trial 167 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:07,956]\u001b[0m Trial 165 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:08,175]\u001b[0m Trial 168 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:13,749]\u001b[0m Trial 164 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:17,229]\u001b[0m Trial 171 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:20,168]\u001b[0m Trial 172 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:22,559]\u001b[0m Trial 170 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:24,273]\u001b[0m Trial 174 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:27,214]\u001b[0m Trial 173 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:29,183]\u001b[0m Trial 175 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:31,608]\u001b[0m Trial 176 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:35,993]\u001b[0m Trial 169 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:39,800]\u001b[0m Trial 178 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:42,741]\u001b[0m Trial 179 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:46,798]\u001b[0m Trial 182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:48,900]\u001b[0m Trial 180 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:51,836]\u001b[0m Trial 177 finished with value: 52.495854517769764 and parameters: {'n_hidden': 3, 'learning_rate': 0.005978636341823724, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07292561955068738, 'dropout_rate_Layer_2': 0.3841504732226285, 'dropout_rate_Layer_3': 0.38103007836786545, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00191680883917778, 'l1_Layer_2': 0.005363571413103401, 'l1_Layer_3': 0.029804853930342212, 'n_units_Layer_1': 85, 'n_units_Layer_2': 225, 'n_units_Layer_3': 155}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.50 | sMAPE for Validation Set is: 29.42% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.91 | sMAPE for Test Set is: 32.02% | rMAE for Test Set is: 0.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:24:55,214]\u001b[0m Trial 183 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:24:58,762]\u001b[0m Trial 184 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:01,310]\u001b[0m Trial 181 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:01,716]\u001b[0m Trial 186 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:05,491]\u001b[0m Trial 187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:12,345]\u001b[0m Trial 189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:13,172]\u001b[0m Trial 185 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:14,872]\u001b[0m Trial 188 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:20,661]\u001b[0m Trial 191 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:25,444]\u001b[0m Trial 192 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:30,471]\u001b[0m Trial 195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:36,001]\u001b[0m Trial 194 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:41,910]\u001b[0m Trial 196 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:25:47,168]\u001b[0m Trial 190 finished with value: 51.04010538975397 and parameters: {'n_hidden': 3, 'learning_rate': 0.000707409824368199, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15363633725863, 'dropout_rate_Layer_2': 0.28504078808712746, 'dropout_rate_Layer_3': 0.22832248244346448, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.056970985584820354, 'l1_Layer_2': 0.001929855698039526, 'l1_Layer_3': 0.0033694117974357243, 'n_units_Layer_1': 105, 'n_units_Layer_2': 115, 'n_units_Layer_3': 130}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.04 | sMAPE for Validation Set is: 28.93% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 22.85 | sMAPE for Test Set is: 29.68% | rMAE for Test Set is: 0.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:25:54,575]\u001b[0m Trial 193 finished with value: 43.919634814831106 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006853752541983813, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30444659320027484, 'dropout_rate_Layer_2': 0.2830777509104122, 'dropout_rate_Layer_3': 0.19171849225335952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000830712218049056, 'l1_Layer_2': 0.0005192502923298327, 'l1_Layer_3': 3.526100897161244e-05, 'n_units_Layer_1': 280, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.92 | sMAPE for Validation Set is: 26.33% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 26.71% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:25:56,813]\u001b[0m Trial 199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:01,785]\u001b[0m Trial 198 finished with value: 52.64084743609863 and parameters: {'n_hidden': 4, 'learning_rate': 0.0033298480490180347, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.18615684731934307, 'dropout_rate_Layer_2': 0.06038562531126795, 'dropout_rate_Layer_3': 0.1746818871543492, 'dropout_rate_Layer_4': 0.0008407080318170099, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'linear', 'l1_Layer_1': 0.0853561010439514, 'l1_Layer_2': 0.0008430198883445034, 'l1_Layer_3': 0.067181463832028, 'l1_Layer_4': 0.0007705481261437659, 'n_units_Layer_1': 185, 'n_units_Layer_2': 85, 'n_units_Layer_3': 105, 'n_units_Layer_4': 55}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.64 | sMAPE for Validation Set is: 29.45% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.50 | sMAPE for Test Set is: 30.71% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:26:08,797]\u001b[0m Trial 197 finished with value: 48.37588119870012 and parameters: {'n_hidden': 3, 'learning_rate': 0.003299350651229267, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.00044768316239155587, 'dropout_rate_Layer_2': 0.3066501662817829, 'dropout_rate_Layer_3': 0.31107483187652696, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0024560720162612806, 'l1_Layer_2': 0.012840721701331017, 'l1_Layer_3': 0.008493728531874805, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 85}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 48.38 | sMAPE for Validation Set is: 27.86% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 20.95 | sMAPE for Test Set is: 27.77% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:26:10,509]\u001b[0m Trial 202 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:13,929]\u001b[0m Trial 203 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:14,939]\u001b[0m Trial 200 finished with value: 49.157451341984654 and parameters: {'n_hidden': 3, 'learning_rate': 0.007035008703553856, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11008960718624194, 'dropout_rate_Layer_2': 0.30307768974774024, 'dropout_rate_Layer_3': 0.38918228748907663, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004119504382132362, 'l1_Layer_2': 0.020994921004563554, 'l1_Layer_3': 0.00919182335324258, 'n_units_Layer_1': 195, 'n_units_Layer_2': 200, 'n_units_Layer_3': 125}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.16 | sMAPE for Validation Set is: 28.40% | rMAE for Validation Set is: 0.56\n",
      "MAE for Test Set is: 22.01 | sMAPE for Test Set is: 28.93% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:26:18,835]\u001b[0m Trial 205 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:21,470]\u001b[0m Trial 204 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:23,318]\u001b[0m Trial 207 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:26,200]\u001b[0m Trial 208 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:29,495]\u001b[0m Trial 201 finished with value: 44.42693936027072 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006713406173788018, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3118954030410929, 'dropout_rate_Layer_2': 0.2730355383083311, 'dropout_rate_Layer_3': 0.2368111912373286, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0009147458981675903, 'l1_Layer_2': 0.0002508816473294776, 'l1_Layer_3': 5.9584531952968996e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 115, 'n_units_Layer_3': 140}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:29,633]\u001b[0m Trial 210 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.43 | sMAPE for Validation Set is: 26.64% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.02 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:26:36,077]\u001b[0m Trial 206 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:37,642]\u001b[0m Trial 212 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:43,309]\u001b[0m Trial 213 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:48,121]\u001b[0m Trial 214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:26:48,841]\u001b[0m Trial 209 finished with value: 49.824449222007935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008333963430528666, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038854724386434766, 'dropout_rate_Layer_2': 0.38899669053998437, 'dropout_rate_Layer_3': 0.36452104816007347, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03026136983402105, 'l1_Layer_2': 0.0005673549613217229, 'l1_Layer_3': 2.3884964244092606e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 165, 'n_units_Layer_3': 180}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.82 | sMAPE for Validation Set is: 28.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.82 | sMAPE for Test Set is: 29.28% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:26:56,047]\u001b[0m Trial 216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:27:04,001]\u001b[0m Trial 217 finished with value: 50.37374861432187 and parameters: {'n_hidden': 3, 'learning_rate': 0.00270084660860805, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04287841136750328, 'dropout_rate_Layer_2': 0.3841773288676111, 'dropout_rate_Layer_3': 0.3123783785927021, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.04015732650839401, 'l1_Layer_2': 0.0019851824559726557, 'l1_Layer_3': 0.0005152310856878355, 'n_units_Layer_1': 255, 'n_units_Layer_2': 105, 'n_units_Layer_3': 250}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.37 | sMAPE for Validation Set is: 28.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.81 | sMAPE for Test Set is: 28.62% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:27:07,769]\u001b[0m Trial 211 finished with value: 44.54756882312293 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006526967141394767, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2721510417173873, 'dropout_rate_Layer_2': 0.27353904242434773, 'dropout_rate_Layer_3': 0.26740268527387423, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.001103990187086057, 'l1_Layer_2': 0.00016900157400783413, 'l1_Layer_3': 6.994347250659798e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.55 | sMAPE for Validation Set is: 26.55% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.44 | sMAPE for Test Set is: 27.50% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:27:19,956]\u001b[0m Trial 215 finished with value: 49.6180874128537 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030637499307015867, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.183336909288485, 'dropout_rate_Layer_2': 0.3399339363784576, 'dropout_rate_Layer_3': 0.3162393160757515, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0016639352930735748, 'l1_Layer_2': 0.0717357589166611, 'l1_Layer_3': 0.008656034015878283, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.62 | sMAPE for Validation Set is: 28.31% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.19 | sMAPE for Test Set is: 27.97% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:27:24,264]\u001b[0m Trial 218 finished with value: 47.96935130138858 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031085149336502966, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10768479709134433, 'dropout_rate_Layer_2': 0.3397742147227626, 'dropout_rate_Layer_3': 0.316732240643642, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0017610499122443007, 'l1_Layer_2': 0.02057586218433005, 'l1_Layer_3': 0.009909744547476455, 'n_units_Layer_1': 230, 'n_units_Layer_2': 175, 'n_units_Layer_3': 135}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 47.97 | sMAPE for Validation Set is: 27.83% | rMAE for Validation Set is: 0.55\n",
      "MAE for Test Set is: 20.78 | sMAPE for Test Set is: 28.27% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:27:42,938]\u001b[0m Trial 220 finished with value: 44.0820165682638 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006207134605643543, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.33913842189393933, 'dropout_rate_Layer_2': 0.10442174189993604, 'dropout_rate_Layer_3': 0.2765876950560878, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00195790748303045, 'l1_Layer_2': 0.0002920180658490934, 'l1_Layer_3': 7.934486623349108e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.08 | sMAPE for Validation Set is: 26.48% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 27.32% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:27:45,350]\u001b[0m Trial 219 finished with value: 44.60996082269694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006223664219034786, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3353202505541487, 'dropout_rate_Layer_2': 0.2887055835235034, 'dropout_rate_Layer_3': 0.26730204768014765, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004693937922345324, 'l1_Layer_2': 0.001091987890782431, 'l1_Layer_3': 6.982876173582713e-05, 'n_units_Layer_1': 205, 'n_units_Layer_2': 100, 'n_units_Layer_3': 160}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.61 | sMAPE for Validation Set is: 26.58% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.91 | sMAPE for Test Set is: 26.42% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:27:49,059]\u001b[0m Trial 224 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:27:49,462]\u001b[0m Trial 223 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:27:55,423]\u001b[0m Trial 225 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:27:57,920]\u001b[0m Trial 221 finished with value: 44.211255599886336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006254384891284094, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3269714491784006, 'dropout_rate_Layer_2': 0.2858013480685493, 'dropout_rate_Layer_3': 0.2630745030123583, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008483575554099513, 'l1_Layer_2': 0.00019678074059429699, 'l1_Layer_3': 5.704029518813514e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 115}. Best is trial 20 with value: 42.83385160312389.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.21 | sMAPE for Validation Set is: 26.76% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 27.13% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:11,436]\u001b[0m Trial 222 finished with value: 42.25267268449762 and parameters: {'n_hidden': 3, 'learning_rate': 0.002647249457037518, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05702090921180225, 'dropout_rate_Layer_2': 0.3807548413487279, 'dropout_rate_Layer_3': 0.3103891201727951, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.008884411548712825, 'l1_Layer_2': 0.001686338773731373, 'l1_Layer_3': 4.069940598787332e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.25 | sMAPE for Validation Set is: 25.40% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.11 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:16,807]\u001b[0m Trial 229 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:28:20,186]\u001b[0m Trial 226 finished with value: 46.86935982863107 and parameters: {'n_hidden': 3, 'learning_rate': 0.002541134693164828, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05030578565788704, 'dropout_rate_Layer_2': 0.3813946079070996, 'dropout_rate_Layer_3': 0.3071494035858584, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.03934545716718079, 'l1_Layer_2': 0.002011717904322906, 'l1_Layer_3': 3.116424893098267e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 160, 'n_units_Layer_3': 300}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.87 | sMAPE for Validation Set is: 27.51% | rMAE for Validation Set is: 0.54\n",
      "MAE for Test Set is: 20.33 | sMAPE for Test Set is: 27.51% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:22,204]\u001b[0m Trial 228 finished with value: 52.54139073720856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018511867734215665, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17434091914787936, 'dropout_rate_Layer_2': 0.3036706643920027, 'dropout_rate_Layer_3': 0.28795457909296457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00844250349160275, 'l1_Layer_2': 0.019426592494822315, 'l1_Layer_3': 0.012041115415063917, 'n_units_Layer_1': 185, 'n_units_Layer_2': 175, 'n_units_Layer_3': 90}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.54 | sMAPE for Validation Set is: 29.54% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.53 | sMAPE for Test Set is: 30.13% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:24,160]\u001b[0m Trial 230 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:28:27,886]\u001b[0m Trial 231 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:28:31,601]\u001b[0m Trial 227 finished with value: 42.9833113501139 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006171040529806385, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3295588274319771, 'dropout_rate_Layer_2': 0.3043034773708029, 'dropout_rate_Layer_3': 0.26415831305245446, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014846816962558708, 'l1_Layer_2': 9.5938063091366e-05, 'l1_Layer_3': 7.306399131550554e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 110}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.98 | sMAPE for Validation Set is: 26.18% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.80 | sMAPE for Test Set is: 27.65% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:35,470]\u001b[0m Trial 234 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:28:39,207]\u001b[0m Trial 233 finished with value: 51.22984500294956 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016426788068578198, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17491646745236863, 'dropout_rate_Layer_2': 0.30448370526319274, 'dropout_rate_Layer_3': 0.249093039636329, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09046816300500204, 'l1_Layer_2': 0.020185651793476027, 'l1_Layer_3': 0.0029736362510048844, 'n_units_Layer_1': 255, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.23 | sMAPE for Validation Set is: 29.21% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.43 | sMAPE for Test Set is: 30.24% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:40,609]\u001b[0m Trial 236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:28:44,731]\u001b[0m Trial 232 finished with value: 51.81286238833733 and parameters: {'n_hidden': 3, 'learning_rate': 0.00123145177445788, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17472202831782996, 'dropout_rate_Layer_2': 0.30591214677678474, 'dropout_rate_Layer_3': 0.2711236255504398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03841874945699801, 'l1_Layer_2': 0.019832441195008776, 'l1_Layer_3': 0.0009561354059604235, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 75}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.81 | sMAPE for Validation Set is: 29.37% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.53 | sMAPE for Test Set is: 30.26% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:28:49,774]\u001b[0m Trial 237 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:28:55,905]\u001b[0m Trial 240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:04,139]\u001b[0m Trial 241 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:08,959]\u001b[0m Trial 242 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:11,794]\u001b[0m Trial 238 finished with value: 44.75419876553715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005817250394535301, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.34272998682253203, 'dropout_rate_Layer_2': 0.2903380945810181, 'dropout_rate_Layer_3': 0.2916019371559664, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00039542358664349165, 'l1_Layer_2': 0.00010581309442803727, 'l1_Layer_3': 5.37769046625733e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 90, 'n_units_Layer_3': 115}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.75 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.19 | sMAPE for Test Set is: 28.20% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:29:15,403]\u001b[0m Trial 235 finished with value: 42.83286344531222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009790272583703687, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3399493099407933, 'dropout_rate_Layer_2': 0.3185593818918127, 'dropout_rate_Layer_3': 0.2598452655128677, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0013314842510030547, 'l1_Layer_2': 0.00017815011703295073, 'l1_Layer_3': 3.934123084936782e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 100, 'n_units_Layer_3': 140}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.83 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.51 | sMAPE for Test Set is: 27.66% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:29:20,662]\u001b[0m Trial 239 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:21,310]\u001b[0m Trial 244 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:21,495]\u001b[0m Trial 245 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:28,067]\u001b[0m Trial 247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:31,404]\u001b[0m Trial 243 finished with value: 50.10798834435766 and parameters: {'n_hidden': 3, 'learning_rate': 0.009763331728742865, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06845193572597137, 'dropout_rate_Layer_2': 0.3986873238985832, 'dropout_rate_Layer_3': 0.294540624378823, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.02572610099381587, 'l1_Layer_2': 0.000708533757220652, 'l1_Layer_3': 3.0694199824905864e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 165, 'n_units_Layer_3': 255}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.11 | sMAPE for Validation Set is: 29.02% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 23.39 | sMAPE for Test Set is: 31.18% | rMAE for Test Set is: 0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:29:35,092]\u001b[0m Trial 249 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:38,162]\u001b[0m Trial 246 finished with value: 42.30555608240683 and parameters: {'n_hidden': 3, 'learning_rate': 0.005857132562599707, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12917990555608577, 'dropout_rate_Layer_2': 0.06995041609418536, 'dropout_rate_Layer_3': 0.16829826274626264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011002718359935774, 'l1_Layer_2': 1.4291973671412217e-05, 'l1_Layer_3': 1.4491258711500759e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 165, 'n_units_Layer_3': 275}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.31 | sMAPE for Validation Set is: 25.34% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 17.98 | sMAPE for Test Set is: 26.37% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:29:41,541]\u001b[0m Trial 248 finished with value: 43.73512295180539 and parameters: {'n_hidden': 3, 'learning_rate': 0.002491401297338744, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09428721958869749, 'dropout_rate_Layer_2': 0.3541581363713284, 'dropout_rate_Layer_3': 0.3573706640052486, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00017722301128958158, 'l1_Layer_2': 0.00056165729821171, 'l1_Layer_3': 4.157147917996146e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 245}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.74 | sMAPE for Validation Set is: 25.86% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.98 | sMAPE for Test Set is: 26.27% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:29:52,616]\u001b[0m Trial 253 finished with value: 52.22367576367805 and parameters: {'n_hidden': 3, 'learning_rate': 0.002361594401506939, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1922523643238867, 'dropout_rate_Layer_2': 0.32536884767745855, 'dropout_rate_Layer_3': 0.25641069396691296, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.09665309832413893, 'l1_Layer_2': 0.02936904323935403, 'l1_Layer_3': 0.00045552161560653495, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.22 | sMAPE for Validation Set is: 29.44% | rMAE for Validation Set is: 0.60\n",
      "MAE for Test Set is: 23.74 | sMAPE for Test Set is: 30.78% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:29:56,041]\u001b[0m Trial 254 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:29:58,538]\u001b[0m Trial 250 finished with value: 43.091032610841545 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005131505468098735, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14628330570895415, 'dropout_rate_Layer_2': 0.1302808899335599, 'dropout_rate_Layer_3': 0.05437211882805176, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010087798101484293, 'l1_Layer_2': 1.298306992629361e-05, 'l1_Layer_3': 1.3004673996492201e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 170, 'n_units_Layer_3': 275}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.09 | sMAPE for Validation Set is: 25.59% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.00 | sMAPE for Test Set is: 27.09% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:30:01,065]\u001b[0m Trial 255 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:04,566]\u001b[0m Trial 257 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:08,973]\u001b[0m Trial 258 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:11,515]\u001b[0m Trial 251 finished with value: 42.28464136478967 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007566183021513758, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.30374312571337647, 'dropout_rate_Layer_2': 0.27304641272880914, 'dropout_rate_Layer_3': 0.25146278386111626, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008594527513385168, 'l1_Layer_2': 0.00015131010559390223, 'l1_Layer_3': 5.343476674841081e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 115, 'n_units_Layer_3': 125}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.28 | sMAPE for Validation Set is: 25.82% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.62 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:30:14,443]\u001b[0m Trial 252 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:14,915]\u001b[0m Trial 256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:37,766]\u001b[0m Trial 262 finished with value: 43.0284991345762 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005464810293931496, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14209518683032932, 'dropout_rate_Layer_2': 0.06734410105790582, 'dropout_rate_Layer_3': 0.056046988813907815, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001303843912777804, 'l1_Layer_2': 1.1673712103918072e-05, 'l1_Layer_3': 1.0577924550747234e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 165, 'n_units_Layer_3': 265}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.03 | sMAPE for Validation Set is: 25.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 28.31% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:30:40,090]\u001b[0m Trial 261 finished with value: 43.598451202427704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009034204322583108, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.31921102016093805, 'dropout_rate_Layer_2': 0.26025928255640784, 'dropout_rate_Layer_3': 0.2776495160009975, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010888432477254059, 'l1_Layer_2': 0.00038232356531446636, 'l1_Layer_3': 4.8848421068782e-05, 'n_units_Layer_1': 290, 'n_units_Layer_2': 105, 'n_units_Layer_3': 105}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.60 | sMAPE for Validation Set is: 26.94% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.22 | sMAPE for Test Set is: 29.04% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:30:44,958]\u001b[0m Trial 264 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:45,375]\u001b[0m Trial 260 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:49,568]\u001b[0m Trial 259 finished with value: 42.37903305976861 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007356473199410988, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3271497106932038, 'dropout_rate_Layer_2': 0.2974916817567738, 'dropout_rate_Layer_3': 0.22852714721292033, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006316391267432243, 'l1_Layer_2': 0.0003909775984964392, 'l1_Layer_3': 7.825969596671949e-05, 'n_units_Layer_1': 210, 'n_units_Layer_2': 100, 'n_units_Layer_3': 110}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.38 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.33 | sMAPE for Test Set is: 28.45% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:30:50,639]\u001b[0m Trial 266 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:53,694]\u001b[0m Trial 267 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:54,240]\u001b[0m Trial 265 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:55,953]\u001b[0m Trial 268 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:30:59,808]\u001b[0m Trial 269 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:02,650]\u001b[0m Trial 270 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:07,825]\u001b[0m Trial 272 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:12,646]\u001b[0m Trial 273 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:16,251]\u001b[0m Trial 271 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:20,667]\u001b[0m Trial 275 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:25,287]\u001b[0m Trial 277 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:25,801]\u001b[0m Trial 274 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:28,948]\u001b[0m Trial 263 finished with value: 44.47765751286189 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011591693918245336, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3276635264246406, 'dropout_rate_Layer_2': 0.2614280936129712, 'dropout_rate_Layer_3': 0.22519698083850226, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0010929938172037086, 'l1_Layer_2': 0.00036471099254638067, 'l1_Layer_3': 0.00010783015031249776, 'n_units_Layer_1': 265, 'n_units_Layer_2': 105, 'n_units_Layer_3': 105}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.48 | sMAPE for Validation Set is: 27.16% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.04 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:31:31,775]\u001b[0m Trial 278 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:33,329]\u001b[0m Trial 279 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:36,192]\u001b[0m Trial 281 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:39,426]\u001b[0m Trial 283 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:42,863]\u001b[0m Trial 284 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:46,943]\u001b[0m Trial 280 finished with value: 44.829310839257204 and parameters: {'n_hidden': 3, 'learning_rate': 0.0076265130910651855, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08603470859652121, 'dropout_rate_Layer_2': 0.06455657642563406, 'dropout_rate_Layer_3': 0.1002534118876695, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00017245647543883642, 'l1_Layer_2': 3.7023934429514784e-05, 'l1_Layer_3': 2.5732670450469065e-05, 'n_units_Layer_1': 295, 'n_units_Layer_2': 150, 'n_units_Layer_3': 235}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.83 | sMAPE for Validation Set is: 26.72% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.47 | sMAPE for Test Set is: 27.03% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:31:47,680]\u001b[0m Trial 282 finished with value: 51.6021780796224 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030587803354702034, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.15647208360062287, 'dropout_rate_Layer_2': 0.2804981201991445, 'dropout_rate_Layer_3': 0.3046358294356679, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.03022486831685186, 'l1_Layer_2': 0.01457597016005725, 'l1_Layer_3': 0.00018578762609320015, 'n_units_Layer_1': 255, 'n_units_Layer_2': 160, 'n_units_Layer_3': 50}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 51.60 | sMAPE for Validation Set is: 29.34% | rMAE for Validation Set is: 0.59\n",
      "MAE for Test Set is: 23.56 | sMAPE for Test Set is: 30.57% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:31:48,892]\u001b[0m Trial 285 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:56,427]\u001b[0m Trial 276 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:31:58,974]\u001b[0m Trial 287 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:01,457]\u001b[0m Trial 289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:02,819]\u001b[0m Trial 290 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:06,005]\u001b[0m Trial 288 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:06,319]\u001b[0m Trial 291 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:13,069]\u001b[0m Trial 286 finished with value: 42.735331582610435 and parameters: {'n_hidden': 3, 'learning_rate': 0.001072366720662432, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036699145342728307, 'dropout_rate_Layer_2': 0.3648170725305968, 'dropout_rate_Layer_3': 0.36146538758470437, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.2202101402023308e-05, 'l1_Layer_2': 0.000490463339009981, 'l1_Layer_3': 2.5336827044454933e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 190}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.74 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.27 | sMAPE for Test Set is: 26.83% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:32:16,599]\u001b[0m Trial 295 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:21,845]\u001b[0m Trial 293 finished with value: 43.51889413952356 and parameters: {'n_hidden': 3, 'learning_rate': 0.001959398312986136, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11750685103438505, 'dropout_rate_Layer_2': 0.047158592920044685, 'dropout_rate_Layer_3': 0.16484070240274432, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0005203321987669546, 'l1_Layer_2': 2.3737996942583344e-05, 'l1_Layer_3': 7.46633391158756e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 195, 'n_units_Layer_3': 255}. Best is trial 222 with value: 42.25267268449762.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.52 | sMAPE for Validation Set is: 26.04% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.00 | sMAPE for Test Set is: 29.26% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:32:24,427]\u001b[0m Trial 296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:26,809]\u001b[0m Trial 292 finished with value: 42.22437273028398 and parameters: {'n_hidden': 3, 'learning_rate': 0.002166563898473081, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03588606148149995, 'dropout_rate_Layer_2': 0.3580309572685556, 'dropout_rate_Layer_3': 0.34933092943083227, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1420696925979752e-05, 'l1_Layer_2': 0.00047309619893770105, 'l1_Layer_3': 2.5472750798404726e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 170, 'n_units_Layer_3': 205}. Best is trial 292 with value: 42.22437273028398.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.22 | sMAPE for Validation Set is: 25.59% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.95 | sMAPE for Test Set is: 29.05% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:32:27,668]\u001b[0m Trial 297 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:32,096]\u001b[0m Trial 299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:34,568]\u001b[0m Trial 300 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:37,289]\u001b[0m Trial 301 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:37,763]\u001b[0m Trial 294 finished with value: 40.91169941576166 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010054686329017523, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.025646807031968658, 'dropout_rate_Layer_2': 0.35851597584495215, 'dropout_rate_Layer_3': 0.3491674247292243, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.404509397834027e-05, 'l1_Layer_2': 0.0005281294404303077, 'l1_Layer_3': 2.136181041087904e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 170, 'n_units_Layer_3': 195}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.91 | sMAPE for Validation Set is: 25.14% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 28.02% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:32:38,016]\u001b[0m Trial 302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:43,628]\u001b[0m Trial 303 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:44,462]\u001b[0m Trial 304 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:45,872]\u001b[0m Trial 305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:48,018]\u001b[0m Trial 306 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:52,733]\u001b[0m Trial 309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:54,115]\u001b[0m Trial 307 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:32:57,281]\u001b[0m Trial 310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:00,009]\u001b[0m Trial 298 finished with value: 41.81174891001117 and parameters: {'n_hidden': 3, 'learning_rate': 0.0022358633991593118, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.032037133845845917, 'dropout_rate_Layer_2': 0.31719967063424903, 'dropout_rate_Layer_3': 0.3461739376041178, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0117782139990947e-05, 'l1_Layer_2': 0.001419761057576305, 'l1_Layer_3': 0.00012178336952182305, 'n_units_Layer_1': 270, 'n_units_Layer_2': 175, 'n_units_Layer_3': 210}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 25.26% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 28.17% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:33:02,938]\u001b[0m Trial 311 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:03,492]\u001b[0m Trial 312 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:05,749]\u001b[0m Trial 308 finished with value: 52.85537318906747 and parameters: {'n_hidden': 3, 'learning_rate': 0.0075182979258566875, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.19735913564994162, 'dropout_rate_Layer_2': 0.2633148350120746, 'dropout_rate_Layer_3': 0.23476288838190457, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.052198230093831004, 'l1_Layer_2': 0.014749958601045797, 'l1_Layer_3': 0.004801956589675103, 'n_units_Layer_1': 235, 'n_units_Layer_2': 205, 'n_units_Layer_3': 50}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 52.86 | sMAPE for Validation Set is: 29.87% | rMAE for Validation Set is: 0.61\n",
      "MAE for Test Set is: 23.73 | sMAPE for Test Set is: 30.35% | rMAE for Test Set is: 0.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:33:08,115]\u001b[0m Trial 314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:11,979]\u001b[0m Trial 315 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:15,467]\u001b[0m Trial 316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:19,291]\u001b[0m Trial 319 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:19,480]\u001b[0m Trial 313 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:25,153]\u001b[0m Trial 320 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:29,074]\u001b[0m Trial 322 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:35,653]\u001b[0m Trial 321 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:41,847]\u001b[0m Trial 318 finished with value: 50.38001313824005 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017096005066656818, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02589534066823317, 'dropout_rate_Layer_2': 0.2069841985953694, 'dropout_rate_Layer_3': 0.33363685069608806, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004059926896147073, 'l1_Layer_2': 0.010221585867478006, 'l1_Layer_3': 0.017973665503133014, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 50.38 | sMAPE for Validation Set is: 28.64% | rMAE for Validation Set is: 0.58\n",
      "MAE for Test Set is: 21.34 | sMAPE for Test Set is: 28.48% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:33:42,230]\u001b[0m Trial 323 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:48,195]\u001b[0m Trial 325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:48,491]\u001b[0m Trial 326 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:48,587]\u001b[0m Trial 317 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:56,081]\u001b[0m Trial 328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:33:56,385]\u001b[0m Trial 329 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:00,695]\u001b[0m Trial 327 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:02,562]\u001b[0m Trial 330 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:03,201]\u001b[0m Trial 324 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:03,802]\u001b[0m Trial 331 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:10,677]\u001b[0m Trial 333 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:11,345]\u001b[0m Trial 334 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:11,532]\u001b[0m Trial 335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:19,499]\u001b[0m Trial 337 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:22,717]\u001b[0m Trial 336 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:25,261]\u001b[0m Trial 339 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:28,571]\u001b[0m Trial 340 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:29,206]\u001b[0m Trial 332 finished with value: 43.86113821062821 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008977392234900258, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056765241776905825, 'dropout_rate_Layer_2': 0.08725701755382075, 'dropout_rate_Layer_3': 0.040210997405467686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0018247138990530602, 'l1_Layer_2': 0.0001455237583027894, 'l1_Layer_3': 1.954616393017946e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 160, 'n_units_Layer_3': 225}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.86 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 27.63% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:34:31,923]\u001b[0m Trial 338 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:33,280]\u001b[0m Trial 341 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:36,424]\u001b[0m Trial 342 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:37,526]\u001b[0m Trial 343 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:40,601]\u001b[0m Trial 344 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:43,345]\u001b[0m Trial 345 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:44,033]\u001b[0m Trial 346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:44,059]\u001b[0m Trial 347 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:52,928]\u001b[0m Trial 351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:53,025]\u001b[0m Trial 350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:34:57,129]\u001b[0m Trial 348 finished with value: 100.21384395350098 and parameters: {'n_hidden': 4, 'learning_rate': 0.011950457926658177, 'batch_size': 77, 'batch_normalization': True, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045207696506670114, 'dropout_rate_Layer_2': 0.040606765360483854, 'dropout_rate_Layer_3': 0.1318495704672668, 'dropout_rate_Layer_4': 0.24356049615603104, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'sigmoid', 'activation_Layer_3': 'linear', 'activation_Layer_4': 'relu', 'l1_Layer_1': 0.00016254336748069433, 'l1_Layer_2': 1.1922961308278675e-05, 'l1_Layer_3': 1.0953297008701626e-05, 'l1_Layer_4': 0.0037945548636399615, 'n_units_Layer_1': 190, 'n_units_Layer_2': 190, 'n_units_Layer_3': 275, 'n_units_Layer_4': 115}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 100.21 | sMAPE for Validation Set is: 48.70% | rMAE for Validation Set is: 1.15\n",
      "MAE for Test Set is: 58.42 | sMAPE for Test Set is: 75.65% | rMAE for Test Set is: 1.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:35:01,056]\u001b[0m Trial 354 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:06,064]\u001b[0m Trial 355 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:12,573]\u001b[0m Trial 352 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:16,257]\u001b[0m Trial 357 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:19,367]\u001b[0m Trial 356 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:20,988]\u001b[0m Trial 358 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:25,910]\u001b[0m Trial 359 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:30,272]\u001b[0m Trial 360 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:38,465]\u001b[0m Trial 353 finished with value: 46.157768217751425 and parameters: {'n_hidden': 3, 'learning_rate': 0.002731619710090115, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.16449559245204584, 'dropout_rate_Layer_2': 0.24332247986813144, 'dropout_rate_Layer_3': 0.3230126380907618, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013524688130399742, 'l1_Layer_2': 0.01888790897995224, 'l1_Layer_3': 0.0030915511178593925, 'n_units_Layer_1': 245, 'n_units_Layer_2': 215, 'n_units_Layer_3': 65}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.16 | sMAPE for Validation Set is: 27.29% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.28 | sMAPE for Test Set is: 27.27% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:35:39,580]\u001b[0m Trial 349 finished with value: 45.48457940773368 and parameters: {'n_hidden': 3, 'learning_rate': 0.0024672076389895873, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12894339842901453, 'dropout_rate_Layer_2': 0.19335202720522704, 'dropout_rate_Layer_3': 0.3220027958169138, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0004391759354205801, 'l1_Layer_2': 0.0377204080392508, 'l1_Layer_3': 0.002767166786625622, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 85}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.48 | sMAPE for Validation Set is: 26.94% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.62 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:35:43,552]\u001b[0m Trial 363 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:44,476]\u001b[0m Trial 364 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:46,493]\u001b[0m Trial 361 finished with value: 45.90413343463974 and parameters: {'n_hidden': 3, 'learning_rate': 0.011426824676873374, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2174459519878337, 'dropout_rate_Layer_2': 0.1566017445945443, 'dropout_rate_Layer_3': 0.023336850946678867, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0007595434942195279, 'l1_Layer_2': 0.00029323256326007415, 'l1_Layer_3': 0.000305532319299369, 'n_units_Layer_1': 220, 'n_units_Layer_2': 90, 'n_units_Layer_3': 105}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.90 | sMAPE for Validation Set is: 26.51% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.91 | sMAPE for Test Set is: 27.36% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:35:51,360]\u001b[0m Trial 365 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:51,748]\u001b[0m Trial 366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:54,633]\u001b[0m Trial 367 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:35:59,396]\u001b[0m Trial 368 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:02,004]\u001b[0m Trial 370 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:04,099]\u001b[0m Trial 371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:08,765]\u001b[0m Trial 372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:09,124]\u001b[0m Trial 373 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:14,161]\u001b[0m Trial 375 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:17,092]\u001b[0m Trial 374 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:20,947]\u001b[0m Trial 377 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.64 | sMAPE for Validation Set is: 27.04% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:36:23,471]\u001b[0m Trial 362 finished with value: 45.64283985443399 and parameters: {'n_hidden': 3, 'learning_rate': 0.0028852206075317007, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.011621253482817059, 'dropout_rate_Layer_2': 0.1920085762134564, 'dropout_rate_Layer_3': 0.32354410230794156, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001379683856483082, 'l1_Layer_2': 0.009391447083631656, 'l1_Layer_3': 0.0156943789704201, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 65}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:28,202]\u001b[0m Trial 378 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:28,513]\u001b[0m Trial 379 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:33,614]\u001b[0m Trial 369 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:33,810]\u001b[0m Trial 380 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:34,162]\u001b[0m Trial 381 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:41,750]\u001b[0m Trial 383 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:42,846]\u001b[0m Trial 382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:48,307]\u001b[0m Trial 385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:48,636]\u001b[0m Trial 386 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:54,091]\u001b[0m Trial 387 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:36:57,608]\u001b[0m Trial 389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:00,721]\u001b[0m Trial 388 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:04,535]\u001b[0m Trial 376 finished with value: 43.433057237816854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006785037567302912, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07970682121020813, 'dropout_rate_Layer_2': 0.24385870463533724, 'dropout_rate_Layer_3': 0.04350395068602407, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005058171925564726, 'l1_Layer_2': 0.0001601711821539828, 'l1_Layer_3': 0.0006071106155572615, 'n_units_Layer_1': 290, 'n_units_Layer_2': 135, 'n_units_Layer_3': 115}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.43 | sMAPE for Validation Set is: 26.21% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.99 | sMAPE for Test Set is: 28.22% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:37:06,208]\u001b[0m Trial 391 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.32 | sMAPE for Validation Set is: 25.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.00 | sMAPE for Test Set is: 27.10% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:37:10,207]\u001b[0m Trial 384 finished with value: 42.32010885088817 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005198162089660288, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12820911704888646, 'dropout_rate_Layer_2': 0.13001393506746173, 'dropout_rate_Layer_3': 0.05861798090071657, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.314908155456884e-05, 'l1_Layer_2': 2.257125235604911e-05, 'l1_Layer_3': 1.4384054447724202e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 275}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:11,622]\u001b[0m Trial 392 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:16,017]\u001b[0m Trial 393 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:18,920]\u001b[0m Trial 395 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:19,452]\u001b[0m Trial 396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:19,876]\u001b[0m Trial 394 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:25,744]\u001b[0m Trial 397 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:29,014]\u001b[0m Trial 390 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:30,374]\u001b[0m Trial 400 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:35,204]\u001b[0m Trial 402 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:38,070]\u001b[0m Trial 401 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:41,670]\u001b[0m Trial 403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:37:58,069]\u001b[0m Trial 399 finished with value: 45.12966057309336 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017587806436031993, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.17562173484394097, 'dropout_rate_Layer_2': 0.1860203576116001, 'dropout_rate_Layer_3': 0.3012739796728249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00025937542913936267, 'l1_Layer_2': 0.0001600332769046899, 'l1_Layer_3': 0.010537528930073332, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 55}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.13 | sMAPE for Validation Set is: 26.80% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 20.54 | sMAPE for Test Set is: 28.02% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:38:00,846]\u001b[0m Trial 405 finished with value: 42.0684319610655 and parameters: {'n_hidden': 3, 'learning_rate': 0.0033846916593810953, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05457427782031498, 'dropout_rate_Layer_2': 0.33544775853668074, 'dropout_rate_Layer_3': 0.349998051485587, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0948395274373115e-05, 'l1_Layer_2': 0.00044023842346382127, 'l1_Layer_3': 4.179299661326371e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 135, 'n_units_Layer_3': 195}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.07 | sMAPE for Validation Set is: 25.48% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 27.49% | rMAE for Test Set is: 0.58\n",
      "MAE for Validation Set is: 42.00 | sMAPE for Validation Set is: 25.56% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.37 | sMAPE for Test Set is: 28.49% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:38:01,755]\u001b[0m Trial 404 finished with value: 42.002433675887744 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006701360499503439, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18497439051210576, 'dropout_rate_Layer_2': 0.07181978940118736, 'dropout_rate_Layer_3': 0.05823458251318854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.06832543719622e-05, 'l1_Layer_2': 2.7517159926746102e-05, 'l1_Layer_3': 4.185729581675373e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 270}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:02,024]\u001b[0m Trial 398 finished with value: 43.05910833411783 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007912361767913754, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.056007733696384995, 'dropout_rate_Layer_2': 0.27286300439627353, 'dropout_rate_Layer_3': 0.03443374991831952, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0008039401659352897, 'l1_Layer_2': 0.00024408722864062825, 'l1_Layer_3': 0.0015082404183266922, 'n_units_Layer_1': 280, 'n_units_Layer_2': 270, 'n_units_Layer_3': 120}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.06 | sMAPE for Validation Set is: 26.37% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.72 | sMAPE for Test Set is: 29.46% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:38:02,346]\u001b[0m Trial 406 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:10,451]\u001b[0m Trial 409 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:10,683]\u001b[0m Trial 408 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:15,912]\u001b[0m Trial 411 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:22,531]\u001b[0m Trial 407 finished with value: 43.55294521949144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0034683344922479594, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05810006857240488, 'dropout_rate_Layer_2': 0.3027616707197079, 'dropout_rate_Layer_3': 0.33682426537925025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.0923841413861735e-05, 'l1_Layer_2': 0.0013274012768266295, 'l1_Layer_3': 4.3018085795993364e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 135, 'n_units_Layer_3': 230}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.55 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.19 | sMAPE for Test Set is: 29.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:38:23,053]\u001b[0m Trial 413 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:26,809]\u001b[0m Trial 410 finished with value: 43.227486112230416 and parameters: {'n_hidden': 3, 'learning_rate': 0.000720587854266566, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17884481405778369, 'dropout_rate_Layer_2': 0.10578608325275457, 'dropout_rate_Layer_3': 0.14807970982020888, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.247209496485462e-05, 'l1_Layer_2': 3.148987340315371e-05, 'l1_Layer_3': 0.00012578390546048377, 'n_units_Layer_1': 285, 'n_units_Layer_2': 200, 'n_units_Layer_3': 285}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.23 | sMAPE for Validation Set is: 25.86% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.47 | sMAPE for Test Set is: 28.16% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:38:28,731]\u001b[0m Trial 414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:28,903]\u001b[0m Trial 415 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:31,897]\u001b[0m Trial 416 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:36,539]\u001b[0m Trial 418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:38,646]\u001b[0m Trial 417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:39,012]\u001b[0m Trial 419 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:40,416]\u001b[0m Trial 420 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:46,354]\u001b[0m Trial 421 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:49,995]\u001b[0m Trial 424 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:52,566]\u001b[0m Trial 422 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:53,929]\u001b[0m Trial 423 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:38:59,209]\u001b[0m Trial 412 finished with value: 42.171596216137075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008485315802226412, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03853758829236186, 'dropout_rate_Layer_2': 0.3036622600186981, 'dropout_rate_Layer_3': 0.017886334942002757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0006301966373686575, 'l1_Layer_2': 0.00015702852935008883, 'l1_Layer_3': 0.0011728003278250272, 'n_units_Layer_1': 295, 'n_units_Layer_2': 245, 'n_units_Layer_3': 115}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.17 | sMAPE for Validation Set is: 25.74% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.54 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:38:59,662]\u001b[0m Trial 426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:00,741]\u001b[0m Trial 427 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:08,766]\u001b[0m Trial 428 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:09,466]\u001b[0m Trial 429 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:09,935]\u001b[0m Trial 430 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:14,102]\u001b[0m Trial 431 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:17,753]\u001b[0m Trial 432 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:18,417]\u001b[0m Trial 433 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:19,487]\u001b[0m Trial 434 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:24,986]\u001b[0m Trial 435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:28,265]\u001b[0m Trial 425 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:29,960]\u001b[0m Trial 437 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:31,197]\u001b[0m Trial 438 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:35,787]\u001b[0m Trial 439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:41,016]\u001b[0m Trial 442 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:44,038]\u001b[0m Trial 436 finished with value: 45.01723998162888 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014945119912886532, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11305725303541753, 'dropout_rate_Layer_2': 0.20506236114306017, 'dropout_rate_Layer_3': 0.10997571020470441, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00022502705920829616, 'l1_Layer_2': 6.385540815094256e-05, 'l1_Layer_3': 4.398492219734626e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 180, 'n_units_Layer_3': 300}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.02 | sMAPE for Validation Set is: 26.44% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 20.33 | sMAPE for Test Set is: 28.69% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:39:47,834]\u001b[0m Trial 444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:52,041]\u001b[0m Trial 440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:52,283]\u001b[0m Trial 441 finished with value: 44.288264208904856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013206968666642322, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11007080584506534, 'dropout_rate_Layer_2': 0.19862418255182854, 'dropout_rate_Layer_3': 0.1076251608520789, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021847484765610158, 'l1_Layer_2': 7.045232120823927e-05, 'l1_Layer_3': 4.101709461731469e-05, 'n_units_Layer_1': 300, 'n_units_Layer_2': 140, 'n_units_Layer_3': 285}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.29 | sMAPE for Validation Set is: 26.18% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.19 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:39:52,436]\u001b[0m Trial 445 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:39:59,020]\u001b[0m Trial 447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:07,580]\u001b[0m Trial 443 finished with value: 41.98167565885092 and parameters: {'n_hidden': 3, 'learning_rate': 0.0031621932693772594, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.22587773464487618, 'dropout_rate_Layer_2': 0.2538921727317668, 'dropout_rate_Layer_3': 0.218433407626773, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.6616578992998444e-05, 'l1_Layer_2': 1.6913426073766013e-05, 'l1_Layer_3': 6.550347547599332e-05, 'n_units_Layer_1': 115, 'n_units_Layer_2': 125, 'n_units_Layer_3': 225}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.98 | sMAPE for Validation Set is: 25.51% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 27.41% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:40:08,178]\u001b[0m Trial 449 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:12,660]\u001b[0m Trial 450 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:16,162]\u001b[0m Trial 451 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:19,700]\u001b[0m Trial 453 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:23,506]\u001b[0m Trial 448 finished with value: 46.236420381002574 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014837675087662355, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.2089404108333397, 'dropout_rate_Layer_2': 0.19739375758083125, 'dropout_rate_Layer_3': 0.3136528419259045, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002417143944473603, 'l1_Layer_2': 3.709173495656827e-05, 'l1_Layer_3': 0.013707827670398572, 'n_units_Layer_1': 245, 'n_units_Layer_2': 185, 'n_units_Layer_3': 75}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.24 | sMAPE for Validation Set is: 27.16% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:40:24,428]\u001b[0m Trial 452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:28,605]\u001b[0m Trial 454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:29,149]\u001b[0m Trial 455 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:32,005]\u001b[0m Trial 456 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:35,284]\u001b[0m Trial 457 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:36,567]\u001b[0m Trial 458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:41,341]\u001b[0m Trial 460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:42,304]\u001b[0m Trial 459 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:42,705]\u001b[0m Trial 461 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.39 | sMAPE for Validation Set is: 26.88% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.90 | sMAPE for Test Set is: 26.87% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:40:49,163]\u001b[0m Trial 446 finished with value: 45.3910610698033 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014815687769336664, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10138616848329769, 'dropout_rate_Layer_2': 0.2928506698388285, 'dropout_rate_Layer_3': 0.31795457223086715, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011212964742267417, 'l1_Layer_2': 0.0008298168879107261, 'l1_Layer_3': 0.014035993591347084, 'n_units_Layer_1': 245, 'n_units_Layer_2': 190, 'n_units_Layer_3': 75}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:53,331]\u001b[0m Trial 463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:55,695]\u001b[0m Trial 465 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:40:56,580]\u001b[0m Trial 464 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:01,069]\u001b[0m Trial 462 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:01,217]\u001b[0m Trial 468 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:06,770]\u001b[0m Trial 469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:06,941]\u001b[0m Trial 470 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:09,393]\u001b[0m Trial 466 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:13,649]\u001b[0m Trial 472 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:14,559]\u001b[0m Trial 473 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:17,265]\u001b[0m Trial 471 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:21,159]\u001b[0m Trial 474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:22,845]\u001b[0m Trial 475 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:27,740]\u001b[0m Trial 478 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:30,470]\u001b[0m Trial 477 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:34,178]\u001b[0m Trial 480 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.02 | sMAPE for Validation Set is: 25.97% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.68 | sMAPE for Test Set is: 26.16% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:41:35,791]\u001b[0m Trial 467 finished with value: 44.01672114236505 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015176458308858813, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08664787988227216, 'dropout_rate_Layer_2': 0.1724556136849574, 'dropout_rate_Layer_3': 0.33279065005937686, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014344069942054234, 'l1_Layer_2': 0.00018414438321549036, 'l1_Layer_3': 0.016581783470587537, 'n_units_Layer_1': 235, 'n_units_Layer_2': 190, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:36,310]\u001b[0m Trial 479 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:43,667]\u001b[0m Trial 482 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:46,896]\u001b[0m Trial 476 finished with value: 43.98251794772384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006567108943884387, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.1600557760533315, 'dropout_rate_Layer_2': 0.1485260770674532, 'dropout_rate_Layer_3': 0.041112658608172925, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3512350794532027e-05, 'l1_Layer_2': 0.0004664263348801027, 'l1_Layer_3': 3.373373690329061e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 250, 'n_units_Layer_3': 210}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.98 | sMAPE for Validation Set is: 26.34% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 21.06 | sMAPE for Test Set is: 28.45% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:41:50,850]\u001b[0m Trial 481 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:51,526]\u001b[0m Trial 483 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:53,841]\u001b[0m Trial 484 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:41:56,592]\u001b[0m Trial 486 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:01,400]\u001b[0m Trial 488 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:05,685]\u001b[0m Trial 490 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:08,868]\u001b[0m Trial 489 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:13,907]\u001b[0m Trial 492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:16,640]\u001b[0m Trial 491 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:20,538]\u001b[0m Trial 494 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:24,521]\u001b[0m Trial 485 finished with value: 44.12545095507935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015715643609480637, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08768040103487261, 'dropout_rate_Layer_2': 0.17048344405801116, 'dropout_rate_Layer_3': 0.3405738377582868, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010114585730101115, 'l1_Layer_2': 0.0001583520412011279, 'l1_Layer_3': 0.008576802595977866, 'n_units_Layer_1': 240, 'n_units_Layer_2': 210, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.13 | sMAPE for Validation Set is: 26.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.34 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:42:26,370]\u001b[0m Trial 495 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:29,270]\u001b[0m Trial 487 finished with value: 42.61199134264908 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005387126775873728, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14485744192971348, 'dropout_rate_Layer_2': 0.07020873880122998, 'dropout_rate_Layer_3': 0.0590916332188655, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011577468928801296, 'l1_Layer_2': 1.0390178579899732e-05, 'l1_Layer_3': 1.4900199867159259e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 175, 'n_units_Layer_3': 270}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.61 | sMAPE for Validation Set is: 25.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.87 | sMAPE for Test Set is: 27.74% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:42:32,213]\u001b[0m Trial 496 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:34,706]\u001b[0m Trial 498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:37,121]\u001b[0m Trial 499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:40,142]\u001b[0m Trial 497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:41,665]\u001b[0m Trial 501 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:47,549]\u001b[0m Trial 493 finished with value: 44.02730588703389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015794234125993572, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08370406155762103, 'dropout_rate_Layer_2': 0.1509041629888547, 'dropout_rate_Layer_3': 0.3391033854967573, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010530035792884, 'l1_Layer_2': 0.00015689561810285486, 'l1_Layer_3': 0.008654389517962996, 'n_units_Layer_1': 240, 'n_units_Layer_2': 200, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.03 | sMAPE for Validation Set is: 26.04% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.83 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:42:47,810]\u001b[0m Trial 500 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:50,228]\u001b[0m Trial 502 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:54,784]\u001b[0m Trial 505 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:42:55,243]\u001b[0m Trial 506 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:03,676]\u001b[0m Trial 503 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:06,611]\u001b[0m Trial 507 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:06,821]\u001b[0m Trial 508 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:09,202]\u001b[0m Trial 509 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:14,286]\u001b[0m Trial 510 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:14,548]\u001b[0m Trial 512 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:14,576]\u001b[0m Trial 511 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:20,624]\u001b[0m Trial 513 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:22,432]\u001b[0m Trial 515 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:23,212]\u001b[0m Trial 514 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:24,267]\u001b[0m Trial 504 finished with value: 44.32379121092111 and parameters: {'n_hidden': 3, 'learning_rate': 0.00101755007901546, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08158354194801183, 'dropout_rate_Layer_2': 0.11505535374488156, 'dropout_rate_Layer_3': 0.3682582444618097, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010594960519222138, 'l1_Layer_2': 8.506566126938808e-05, 'l1_Layer_3': 0.004854565952820936, 'n_units_Layer_1': 220, 'n_units_Layer_2': 205, 'n_units_Layer_3': 175}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.32 | sMAPE for Validation Set is: 26.01% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 26.49% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:43:25,391]\u001b[0m Trial 516 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:29,292]\u001b[0m Trial 517 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:34,505]\u001b[0m Trial 519 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:34,577]\u001b[0m Trial 520 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:34,964]\u001b[0m Trial 521 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:35,728]\u001b[0m Trial 518 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:44,649]\u001b[0m Trial 523 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:44,906]\u001b[0m Trial 522 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:45,169]\u001b[0m Trial 524 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:46,431]\u001b[0m Trial 525 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:54,309]\u001b[0m Trial 527 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:54,427]\u001b[0m Trial 526 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:43:55,706]\u001b[0m Trial 529 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:01,278]\u001b[0m Trial 528 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:03,309]\u001b[0m Trial 530 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:04,537]\u001b[0m Trial 531 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:08,629]\u001b[0m Trial 532 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:09,847]\u001b[0m Trial 534 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:11,156]\u001b[0m Trial 535 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:13,104]\u001b[0m Trial 536 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:18,901]\u001b[0m Trial 538 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:19,113]\u001b[0m Trial 537 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:20,323]\u001b[0m Trial 539 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:26,885]\u001b[0m Trial 541 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:30,268]\u001b[0m Trial 543 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:34,635]\u001b[0m Trial 544 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:40,483]\u001b[0m Trial 540 finished with value: 46.23633223284555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018298218906693672, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10170909704259193, 'dropout_rate_Layer_2': 0.18217412324707885, 'dropout_rate_Layer_3': 0.3263920257852406, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.171412263150491e-05, 'l1_Layer_2': 0.00011720234149089147, 'l1_Layer_3': 0.00524447515198159, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 215}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.24 | sMAPE for Validation Set is: 27.21% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 28.18% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:44:44,846]\u001b[0m Trial 533 finished with value: 42.19743442446076 and parameters: {'n_hidden': 3, 'learning_rate': 0.001565408378470437, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07530576135048865, 'dropout_rate_Layer_2': 0.1348541833468979, 'dropout_rate_Layer_3': 0.13199209645553012, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014041274324494077, 'l1_Layer_2': 0.00013458714332709865, 'l1_Layer_3': 0.006589505425188451, 'n_units_Layer_1': 180, 'n_units_Layer_2': 210, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.20 | sMAPE for Validation Set is: 25.32% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.51 | sMAPE for Test Set is: 26.24% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:44:47,910]\u001b[0m Trial 542 finished with value: 49.66207550053489 and parameters: {'n_hidden': 3, 'learning_rate': 0.001862484650146093, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08271502190526284, 'dropout_rate_Layer_2': 0.34929338457003023, 'dropout_rate_Layer_3': 0.14305437133110238, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029401597141035228, 'l1_Layer_2': 0.00012154106071919671, 'l1_Layer_3': 0.012891774924029854, 'n_units_Layer_1': 235, 'n_units_Layer_2': 185, 'n_units_Layer_3': 130}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 49.66 | sMAPE for Validation Set is: 28.47% | rMAE for Validation Set is: 0.57\n",
      "MAE for Test Set is: 21.63 | sMAPE for Test Set is: 28.74% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:44:51,600]\u001b[0m Trial 547 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:52,584]\u001b[0m Trial 548 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:56,565]\u001b[0m Trial 545 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:44:58,751]\u001b[0m Trial 550 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:11,017]\u001b[0m Trial 546 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:11,928]\u001b[0m Trial 552 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:16,406]\u001b[0m Trial 553 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:19,798]\u001b[0m Trial 554 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:20,157]\u001b[0m Trial 549 finished with value: 43.98807479927881 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015025933784654135, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10338950122001939, 'dropout_rate_Layer_2': 0.18297527499773428, 'dropout_rate_Layer_3': 0.06847918212467528, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 6.796976498332906e-05, 'l1_Layer_2': 0.00016941938850154175, 'l1_Layer_3': 0.0049177812214840095, 'n_units_Layer_1': 170, 'n_units_Layer_2': 215, 'n_units_Layer_3': 220}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.99 | sMAPE for Validation Set is: 26.05% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.16 | sMAPE for Test Set is: 26.33% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:45:26,927]\u001b[0m Trial 556 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:27,519]\u001b[0m Trial 557 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:35,830]\u001b[0m Trial 551 finished with value: 42.25676143359039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014109834877506122, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10119378284292917, 'dropout_rate_Layer_2': 0.15386449134636718, 'dropout_rate_Layer_3': 0.16553603094358144, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.9778864381524774e-05, 'l1_Layer_2': 0.00013469788265361082, 'l1_Layer_3': 0.00521691390510278, 'n_units_Layer_1': 170, 'n_units_Layer_2': 205, 'n_units_Layer_3': 255}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.26 | sMAPE for Validation Set is: 25.37% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.35 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:45:42,513]\u001b[0m Trial 555 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:46,667]\u001b[0m Trial 561 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:46,937]\u001b[0m Trial 560 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:52,077]\u001b[0m Trial 562 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:45:52,752]\u001b[0m Trial 559 finished with value: 44.3320063179091 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019530536796874313, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09875273840342363, 'dropout_rate_Layer_2': 0.16886162997491336, 'dropout_rate_Layer_3': 0.11307706878840634, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013736359903825234, 'l1_Layer_2': 0.0001430889860767825, 'l1_Layer_3': 0.004551798655821654, 'n_units_Layer_1': 175, 'n_units_Layer_2': 220, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.33 | sMAPE for Validation Set is: 26.23% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.68 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:45:53,725]\u001b[0m Trial 558 finished with value: 43.27174538906073 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019093274818770313, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09827080319393089, 'dropout_rate_Layer_2': 0.1691413481165156, 'dropout_rate_Layer_3': 0.10360737339227111, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013225555956862666, 'l1_Layer_2': 0.00023067392568105447, 'l1_Layer_3': 0.004884402935913154, 'n_units_Layer_1': 175, 'n_units_Layer_2': 220, 'n_units_Layer_3': 230}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.27 | sMAPE for Validation Set is: 25.74% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.87 | sMAPE for Test Set is: 26.25% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:46:00,074]\u001b[0m Trial 564 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:02,080]\u001b[0m Trial 565 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:07,197]\u001b[0m Trial 567 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:08,616]\u001b[0m Trial 566 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:09,501]\u001b[0m Trial 568 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:17,609]\u001b[0m Trial 569 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:17,876]\u001b[0m Trial 570 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:21,417]\u001b[0m Trial 571 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:24,169]\u001b[0m Trial 572 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:25,011]\u001b[0m Trial 573 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:26,472]\u001b[0m Trial 574 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:33,792]\u001b[0m Trial 575 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:33,999]\u001b[0m Trial 577 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:34,177]\u001b[0m Trial 576 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.03 | sMAPE for Validation Set is: 25.73% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.93 | sMAPE for Test Set is: 26.67% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:46:36,363]\u001b[0m Trial 563 finished with value: 43.032663086310606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011926355311207481, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09288146497156083, 'dropout_rate_Layer_2': 0.14243737258057165, 'dropout_rate_Layer_3': 0.13621707862472898, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.8887475987974834e-05, 'l1_Layer_2': 0.0002285351468514022, 'l1_Layer_3': 0.006774850377943906, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:42,735]\u001b[0m Trial 579 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:42,885]\u001b[0m Trial 580 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:48,595]\u001b[0m Trial 581 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:48,991]\u001b[0m Trial 582 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:49,174]\u001b[0m Trial 583 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:55,426]\u001b[0m Trial 584 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:46:56,166]\u001b[0m Trial 586 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:01,925]\u001b[0m Trial 587 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:06,929]\u001b[0m Trial 588 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:16,617]\u001b[0m Trial 578 finished with value: 42.57205543304559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011549234154260525, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05875865708533198, 'dropout_rate_Layer_2': 0.14425799038563106, 'dropout_rate_Layer_3': 0.11754714460629209, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.50718343481077e-05, 'l1_Layer_2': 0.00010720661174704132, 'l1_Layer_3': 0.0021645826963769136, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.57 | sMAPE for Validation Set is: 25.58% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.72 | sMAPE for Test Set is: 27.08% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:47:27,359]\u001b[0m Trial 585 finished with value: 43.26430833986185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013125565447083124, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10056409974667234, 'dropout_rate_Layer_2': 0.12999618056536694, 'dropout_rate_Layer_3': 0.11645833716584672, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013714111913465206, 'l1_Layer_2': 0.00010393687789594667, 'l1_Layer_3': 0.0060790454126739045, 'n_units_Layer_1': 175, 'n_units_Layer_2': 235, 'n_units_Layer_3': 225}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.26 | sMAPE for Validation Set is: 25.60% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.79 | sMAPE for Test Set is: 26.76% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:47:30,770]\u001b[0m Trial 590 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:35,150]\u001b[0m Trial 593 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:35,330]\u001b[0m Trial 591 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:42,616]\u001b[0m Trial 589 finished with value: 42.271638702471606 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012089678392056553, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10147854531243355, 'dropout_rate_Layer_2': 0.12675400514388122, 'dropout_rate_Layer_3': 0.16366162865751854, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4401233889427928e-05, 'l1_Layer_2': 0.00010302621310392646, 'l1_Layer_3': 0.0023802843924288024, 'n_units_Layer_1': 175, 'n_units_Layer_2': 225, 'n_units_Layer_3': 230}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.27 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.53 | sMAPE for Test Set is: 26.85% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:47:46,818]\u001b[0m Trial 594 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:51,730]\u001b[0m Trial 597 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:47:56,876]\u001b[0m Trial 592 finished with value: 44.40544517656915 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011654920000503854, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.05314150567558091, 'dropout_rate_Layer_2': 0.12564294110092677, 'dropout_rate_Layer_3': 0.11947445088098148, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0982841529026006e-05, 'l1_Layer_2': 0.0002551395722632047, 'l1_Layer_3': 0.0065856033272254245, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 230}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.41 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.26 | sMAPE for Test Set is: 26.77% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:48:01,056]\u001b[0m Trial 595 finished with value: 43.20576284498836 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011084645892548203, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03528717524900422, 'dropout_rate_Layer_2': 0.34918862490154234, 'dropout_rate_Layer_3': 0.3485361484221717, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.9760757916667628e-05, 'l1_Layer_2': 0.00044567493756273965, 'l1_Layer_3': 4.909511731342594e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 155, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.21 | sMAPE for Validation Set is: 25.92% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.17 | sMAPE for Test Set is: 27.77% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:48:01,719]\u001b[0m Trial 599 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:03,141]\u001b[0m Trial 596 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:08,991]\u001b[0m Trial 601 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:12,200]\u001b[0m Trial 602 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:15,006]\u001b[0m Trial 603 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:15,600]\u001b[0m Trial 600 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:17,595]\u001b[0m Trial 604 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:21,747]\u001b[0m Trial 605 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:25,586]\u001b[0m Trial 607 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:25,757]\u001b[0m Trial 608 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:26,372]\u001b[0m Trial 606 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:32,755]\u001b[0m Trial 609 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:33,279]\u001b[0m Trial 610 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:36,857]\u001b[0m Trial 611 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:40,190]\u001b[0m Trial 612 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:45,541]\u001b[0m Trial 613 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:45,911]\u001b[0m Trial 598 finished with value: 46.465135078523396 and parameters: {'n_hidden': 3, 'learning_rate': 0.001247338666431913, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3128335489384796, 'dropout_rate_Layer_2': 0.2542213553062325, 'dropout_rate_Layer_3': 0.20991843519633246, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0007880428915227979, 'l1_Layer_2': 0.0005138217638295519, 'l1_Layer_3': 0.0032249931299763775, 'n_units_Layer_1': 235, 'n_units_Layer_2': 110, 'n_units_Layer_3': 130}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.47 | sMAPE for Validation Set is: 27.09% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.95 | sMAPE for Test Set is: 27.66% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:48:46,201]\u001b[0m Trial 614 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:54,200]\u001b[0m Trial 618 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:48:59,664]\u001b[0m Trial 617 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:17,650]\u001b[0m Trial 616 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:23,039]\u001b[0m Trial 615 finished with value: 42.909423157979326 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011837616431950037, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08762284794628666, 'dropout_rate_Layer_2': 0.10167858803154405, 'dropout_rate_Layer_3': 0.1445156076450056, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3106082570426636e-05, 'l1_Layer_2': 8.761185549381455e-05, 'l1_Layer_3': 0.003611783432670256, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 250}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.91 | sMAPE for Validation Set is: 25.53% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.22 | sMAPE for Test Set is: 25.90% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:49:28,046]\u001b[0m Trial 622 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:29,032]\u001b[0m Trial 621 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:33,595]\u001b[0m Trial 619 finished with value: 43.25627172120872 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011591505020272304, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.28167678410821395, 'dropout_rate_Layer_2': 0.10689623329708034, 'dropout_rate_Layer_3': 0.1062908480140997, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4391407605532666e-05, 'l1_Layer_2': 8.467064925237853e-05, 'l1_Layer_3': 0.0035184459116702773, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 250}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.26 | sMAPE for Validation Set is: 25.86% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.97 | sMAPE for Test Set is: 26.69% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:49:34,671]\u001b[0m Trial 623 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:40,187]\u001b[0m Trial 620 finished with value: 42.516810004831854 and parameters: {'n_hidden': 3, 'learning_rate': 0.001190604010333076, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06244054613541408, 'dropout_rate_Layer_2': 0.09912739156766233, 'dropout_rate_Layer_3': 0.10677922404446993, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1958747288580855e-05, 'l1_Layer_2': 0.00015465892214692678, 'l1_Layer_3': 0.003570652313768404, 'n_units_Layer_1': 180, 'n_units_Layer_2': 235, 'n_units_Layer_3': 245}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.52 | sMAPE for Validation Set is: 25.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.73 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:49:49,425]\u001b[0m Trial 627 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:53,746]\u001b[0m Trial 624 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:54,460]\u001b[0m Trial 628 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:49:59,052]\u001b[0m Trial 629 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:02,631]\u001b[0m Trial 630 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:04,578]\u001b[0m Trial 631 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:05,186]\u001b[0m Trial 625 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:11,752]\u001b[0m Trial 632 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:11,976]\u001b[0m Trial 633 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:18,792]\u001b[0m Trial 626 finished with value: 43.028552370240114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010363137040275256, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0666251022650177, 'dropout_rate_Layer_2': 0.1066590064679869, 'dropout_rate_Layer_3': 0.0909805711028025, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3176401650991318e-05, 'l1_Layer_2': 0.00013571142866800227, 'l1_Layer_3': 0.003467639130480924, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.03 | sMAPE for Validation Set is: 25.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.64 | sMAPE for Test Set is: 26.67% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:50:28,560]\u001b[0m Trial 637 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:32,476]\u001b[0m Trial 638 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:36,499]\u001b[0m Trial 634 finished with value: 44.53245188114639 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010410659436904106, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06521065314878127, 'dropout_rate_Layer_2': 0.08521009026561584, 'dropout_rate_Layer_3': 0.08456537705411282, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2930543917109816e-05, 'l1_Layer_2': 9.635658041039325e-05, 'l1_Layer_3': 0.0017046031728115598, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.53 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.88 | sMAPE for Test Set is: 26.67% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:50:40,365]\u001b[0m Trial 640 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:44,048]\u001b[0m Trial 636 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:45,670]\u001b[0m Trial 641 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:50:48,974]\u001b[0m Trial 642 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:01,778]\u001b[0m Trial 639 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:05,439]\u001b[0m Trial 643 finished with value: 43.58360341026906 and parameters: {'n_hidden': 3, 'learning_rate': 0.002190656643696717, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03504041790256463, 'dropout_rate_Layer_2': 0.3425004560452897, 'dropout_rate_Layer_3': 0.35378916568904833, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.3825535283443326e-05, 'l1_Layer_2': 0.0004604389630129713, 'l1_Layer_3': 4.344784707302828e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 140, 'n_units_Layer_3': 125}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.58 | sMAPE for Validation Set is: 25.97% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.54 | sMAPE for Test Set is: 27.21% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:51:11,098]\u001b[0m Trial 646 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:15,069]\u001b[0m Trial 644 finished with value: 41.698765308853254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010433866817650432, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14498692761675655, 'dropout_rate_Layer_2': 0.10893988776657738, 'dropout_rate_Layer_3': 0.051184401969939446, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00028438422202159316, 'l1_Layer_2': 1.6779822805869303e-05, 'l1_Layer_3': 1.0506606400495682e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 135, 'n_units_Layer_3': 265}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.70 | sMAPE for Validation Set is: 25.45% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.92 | sMAPE for Test Set is: 27.36% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:51:20,381]\u001b[0m Trial 645 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:23,548]\u001b[0m Trial 647 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:24,159]\u001b[0m Trial 649 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:30,164]\u001b[0m Trial 650 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:30,325]\u001b[0m Trial 651 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:36,735]\u001b[0m Trial 653 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:45,026]\u001b[0m Trial 654 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:49,917]\u001b[0m Trial 655 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:54,978]\u001b[0m Trial 652 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:51:58,622]\u001b[0m Trial 648 finished with value: 43.23643153104501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007809879016146407, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07670567083271237, 'dropout_rate_Layer_2': 0.11818836190129854, 'dropout_rate_Layer_3': 0.07193281918685088, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1456280840409412e-05, 'l1_Layer_2': 0.00013316828169670315, 'l1_Layer_3': 0.001197410632999371, 'n_units_Layer_1': 165, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.24 | sMAPE for Validation Set is: 26.03% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.42 | sMAPE for Test Set is: 26.76% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:51:59,067]\u001b[0m Trial 657 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:05,622]\u001b[0m Trial 659 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:06,127]\u001b[0m Trial 658 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:11,374]\u001b[0m Trial 660 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:12,974]\u001b[0m Trial 635 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:14,337]\u001b[0m Trial 656 finished with value: 43.539660239500854 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009660805322814504, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18101606473447035, 'dropout_rate_Layer_2': 0.10661099073605027, 'dropout_rate_Layer_3': 0.19260827247098827, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002877878774508356, 'l1_Layer_2': 1.6872017065006594e-05, 'l1_Layer_3': 1.0282864204082264e-05, 'n_units_Layer_1': 200, 'n_units_Layer_2': 135, 'n_units_Layer_3': 275}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.54 | sMAPE for Validation Set is: 26.06% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.05 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:52:14,491]\u001b[0m Trial 661 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:20,555]\u001b[0m Trial 663 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:21,134]\u001b[0m Trial 664 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:26,477]\u001b[0m Trial 665 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:30,948]\u001b[0m Trial 668 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:32,776]\u001b[0m Trial 667 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:36,887]\u001b[0m Trial 669 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:42,251]\u001b[0m Trial 671 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:43,872]\u001b[0m Trial 670 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:51,789]\u001b[0m Trial 672 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:52:56,852]\u001b[0m Trial 674 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:00,723]\u001b[0m Trial 673 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:03,747]\u001b[0m Trial 666 finished with value: 88.50465473932037 and parameters: {'n_hidden': 3, 'learning_rate': 0.00308924926918014, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.10191460144178574, 'dropout_rate_Layer_2': 0.16444674798309142, 'dropout_rate_Layer_3': 0.046737488193263024, 'activation_Layer_1': 'tanh', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00019005771075183088, 'l1_Layer_2': 4.968387560512658e-05, 'l1_Layer_3': 4.2832748137851826e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 75, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 88.50 | sMAPE for Validation Set is: 42.66% | rMAE for Validation Set is: 1.02\n",
      "MAE for Test Set is: 38.74 | sMAPE for Test Set is: 38.09% | rMAE for Test Set is: 1.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:53:07,565]\u001b[0m Trial 677 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:11,830]\u001b[0m Trial 678 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:14,412]\u001b[0m Trial 675 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:17,441]\u001b[0m Trial 679 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:17,920]\u001b[0m Trial 680 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:22,665]\u001b[0m Trial 681 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:25,726]\u001b[0m Trial 682 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:26,110]\u001b[0m Trial 676 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:29,438]\u001b[0m Trial 683 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.07 | sMAPE for Validation Set is: 26.23% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.33 | sMAPE for Test Set is: 27.24% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:53:33,718]\u001b[0m Trial 662 finished with value: 45.066282729605284 and parameters: {'n_hidden': 3, 'learning_rate': 0.002722101779211703, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09520419913278744, 'dropout_rate_Layer_2': 0.16834513652538013, 'dropout_rate_Layer_3': 0.04605962091662294, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0003114511238669869, 'l1_Layer_2': 1.8112040463403904e-05, 'l1_Layer_3': 4.5730662041825784e-05, 'n_units_Layer_1': 215, 'n_units_Layer_2': 140, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:36,026]\u001b[0m Trial 685 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:39,535]\u001b[0m Trial 686 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:42,217]\u001b[0m Trial 688 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:44,293]\u001b[0m Trial 689 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:45,306]\u001b[0m Trial 687 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:50,225]\u001b[0m Trial 691 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:50,874]\u001b[0m Trial 692 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:55,096]\u001b[0m Trial 693 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:53:58,015]\u001b[0m Trial 684 finished with value: 42.567560975906225 and parameters: {'n_hidden': 3, 'learning_rate': 0.0019130737764385946, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.09190113539249625, 'dropout_rate_Layer_2': 0.3042572384452845, 'dropout_rate_Layer_3': 0.1295089668511604, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.038966537419791e-05, 'l1_Layer_2': 0.0007636548502541993, 'l1_Layer_3': 5.577140478255917e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 180, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.57 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.18 | sMAPE for Test Set is: 29.13% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:53:58,891]\u001b[0m Trial 694 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:00,336]\u001b[0m Trial 695 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:00,532]\u001b[0m Trial 690 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:01,646]\u001b[0m Trial 696 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:10,602]\u001b[0m Trial 697 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:11,451]\u001b[0m Trial 699 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:15,662]\u001b[0m Trial 700 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:15,740]\u001b[0m Trial 702 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:19,789]\u001b[0m Trial 701 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:24,379]\u001b[0m Trial 704 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:27,800]\u001b[0m Trial 705 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:30,156]\u001b[0m Trial 706 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:36,951]\u001b[0m Trial 698 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:42,776]\u001b[0m Trial 709 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:47,844]\u001b[0m Trial 710 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:48,802]\u001b[0m Trial 703 finished with value: 42.95743903615565 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016086805278381678, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.06603491295513433, 'dropout_rate_Layer_2': 0.06698268493883677, 'dropout_rate_Layer_3': 0.08047575615755091, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.284291721039092e-05, 'l1_Layer_2': 7.764425942605168e-05, 'l1_Layer_3': 0.003160223050562683, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 265}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.96 | sMAPE for Validation Set is: 25.71% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 27.39% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:54:53,181]\u001b[0m Trial 708 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:54:53,683]\u001b[0m Trial 712 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:06,258]\u001b[0m Trial 707 finished with value: 42.425086473873925 and parameters: {'n_hidden': 3, 'learning_rate': 0.0016177017317364137, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0602903589062978, 'dropout_rate_Layer_2': 0.06359474889277916, 'dropout_rate_Layer_3': 0.08174512953784661, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1896289416743249e-05, 'l1_Layer_2': 7.794449732910113e-05, 'l1_Layer_3': 0.003022262445156947, 'n_units_Layer_1': 185, 'n_units_Layer_2': 235, 'n_units_Layer_3': 265}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.43 | sMAPE for Validation Set is: 25.41% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.86 | sMAPE for Test Set is: 26.73% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:55:11,606]\u001b[0m Trial 715 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:17,082]\u001b[0m Trial 713 finished with value: 44.32354968425246 and parameters: {'n_hidden': 3, 'learning_rate': 0.001607355793115518, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.09009811940286239, 'dropout_rate_Layer_2': 0.15251430650679268, 'dropout_rate_Layer_3': 0.051120026681393704, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.5879853091279016e-05, 'l1_Layer_2': 7.845637965406637e-05, 'l1_Layer_3': 0.003214035484645554, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 280}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.32 | sMAPE for Validation Set is: 26.10% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 26.11% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:55:17,586]\u001b[0m Trial 711 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:23,619]\u001b[0m Trial 718 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:26,717]\u001b[0m Trial 716 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:30,129]\u001b[0m Trial 719 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:34,844]\u001b[0m Trial 721 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:35,551]\u001b[0m Trial 717 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:35,900]\u001b[0m Trial 714 finished with value: 41.28626090018082 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015989524074452068, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08972606094359085, 'dropout_rate_Layer_2': 0.1329396275345692, 'dropout_rate_Layer_3': 0.07426369880477787, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.962381546096943e-05, 'l1_Layer_2': 7.798330674899433e-05, 'l1_Layer_3': 0.0033472925198863397, 'n_units_Layer_1': 165, 'n_units_Layer_2': 235, 'n_units_Layer_3': 275}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.29 | sMAPE for Validation Set is: 25.27% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.82 | sMAPE for Test Set is: 26.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:55:36,336]\u001b[0m Trial 720 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:40,120]\u001b[0m Trial 722 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:43,519]\u001b[0m Trial 723 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:44,568]\u001b[0m Trial 725 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:45,082]\u001b[0m Trial 724 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:50,050]\u001b[0m Trial 726 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:55,163]\u001b[0m Trial 727 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:55,520]\u001b[0m Trial 729 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:55:55,931]\u001b[0m Trial 728 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:08,938]\u001b[0m Trial 730 finished with value: 43.28727536035925 and parameters: {'n_hidden': 3, 'learning_rate': 0.002240969872952513, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04207687707749965, 'dropout_rate_Layer_2': 0.31753550196969077, 'dropout_rate_Layer_3': 0.10233187851395165, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3669205324684188e-05, 'l1_Layer_2': 0.0007361654275011553, 'l1_Layer_3': 2.6642440687408803e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.29 | sMAPE for Validation Set is: 26.14% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.08 | sMAPE for Test Set is: 28.98% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:56:15,597]\u001b[0m Trial 731 finished with value: 42.76709822475743 and parameters: {'n_hidden': 3, 'learning_rate': 0.002277984466379903, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28342778385560746, 'dropout_rate_Layer_2': 0.32103804700004107, 'dropout_rate_Layer_3': 0.10182198855275909, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.640568032852237e-05, 'l1_Layer_2': 0.0003662145097413109, 'l1_Layer_3': 5.958202502143906e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 180, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:15,689]\u001b[0m Trial 732 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.77 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.16 | sMAPE for Test Set is: 29.50% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:56:22,537]\u001b[0m Trial 736 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:22,889]\u001b[0m Trial 735 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:23,705]\u001b[0m Trial 733 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:30,023]\u001b[0m Trial 738 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:31,128]\u001b[0m Trial 739 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:34,183]\u001b[0m Trial 737 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:56:46,555]\u001b[0m Trial 734 finished with value: 42.80134539561723 and parameters: {'n_hidden': 3, 'learning_rate': 0.001401194978769714, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08316056959749249, 'dropout_rate_Layer_2': 0.06826357431874454, 'dropout_rate_Layer_3': 0.06580073530501744, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.540291846014539e-05, 'l1_Layer_2': 8.255067892302906e-05, 'l1_Layer_3': 0.0039932882044179455, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.80 | sMAPE for Validation Set is: 25.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.47 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:56:54,148]\u001b[0m Trial 741 finished with value: 43.55320629015481 and parameters: {'n_hidden': 3, 'learning_rate': 0.001576810482648153, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10665486629753093, 'dropout_rate_Layer_2': 0.15377650603929757, 'dropout_rate_Layer_3': 0.1314405639564145, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.197047259090421e-05, 'l1_Layer_2': 6.380721682466695e-05, 'l1_Layer_3': 0.0021608237636362524, 'n_units_Layer_1': 155, 'n_units_Layer_2': 230, 'n_units_Layer_3': 280}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.55 | sMAPE for Validation Set is: 25.91% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.46 | sMAPE for Test Set is: 26.07% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:56:56,943]\u001b[0m Trial 740 finished with value: 42.75994413550013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009580058124076464, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1093842084659936, 'dropout_rate_Layer_2': 0.2939716821159222, 'dropout_rate_Layer_3': 0.2367653023581272, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001641138985506781, 'l1_Layer_2': 0.0002110739598196245, 'l1_Layer_3': 4.261036866275095e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 125, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.76 | sMAPE for Validation Set is: 25.76% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.98 | sMAPE for Test Set is: 26.35% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:57:05,152]\u001b[0m Trial 745 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:05,394]\u001b[0m Trial 742 finished with value: 42.34609568788151 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008156081429851039, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3062662796201493, 'dropout_rate_Layer_2': 0.2630776719616444, 'dropout_rate_Layer_3': 0.005075469710952211, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.450678996630797e-05, 'l1_Layer_2': 4.91345294587729e-05, 'l1_Layer_3': 0.0007637781330707848, 'n_units_Layer_1': 195, 'n_units_Layer_2': 100, 'n_units_Layer_3': 130}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.35 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 27.24% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:57:07,310]\u001b[0m Trial 744 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:11,251]\u001b[0m Trial 743 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:16,357]\u001b[0m Trial 747 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:22,388]\u001b[0m Trial 750 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:24,020]\u001b[0m Trial 748 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:27,872]\u001b[0m Trial 752 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:29,112]\u001b[0m Trial 751 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:33,965]\u001b[0m Trial 754 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:36,144]\u001b[0m Trial 753 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:40,236]\u001b[0m Trial 756 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:44,762]\u001b[0m Trial 757 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.30 | sMAPE for Validation Set is: 25.92% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 27.13% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:57:47,237]\u001b[0m Trial 749 finished with value: 43.298568977858906 and parameters: {'n_hidden': 3, 'learning_rate': 0.001405165908327414, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10821779802068526, 'dropout_rate_Layer_2': 0.049749138510465134, 'dropout_rate_Layer_3': 0.06905889166077277, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 7.406369016012363e-05, 'l1_Layer_2': 4.7725393954858496e-05, 'l1_Layer_3': 0.0020161008225728044, 'n_units_Layer_1': 150, 'n_units_Layer_2': 230, 'n_units_Layer_3': 265}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:48,445]\u001b[0m Trial 746 finished with value: 42.35738958729656 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009206275887952463, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3111772881028293, 'dropout_rate_Layer_2': 0.29453529806876805, 'dropout_rate_Layer_3': 0.0003222942851307303, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012787609499401962, 'l1_Layer_2': 5.0969030291552435e-05, 'l1_Layer_3': 2.5890788229517316e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 110, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.36 | sMAPE for Validation Set is: 25.64% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.92 | sMAPE for Test Set is: 27.21% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:57:49,258]\u001b[0m Trial 758 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:51,336]\u001b[0m Trial 755 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:56,795]\u001b[0m Trial 760 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:57:59,237]\u001b[0m Trial 761 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:03,522]\u001b[0m Trial 762 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:07,149]\u001b[0m Trial 764 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:11,037]\u001b[0m Trial 766 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:14,457]\u001b[0m Trial 767 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:18,282]\u001b[0m Trial 763 finished with value: 41.775501497360686 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012054091474898029, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.12577579492497665, 'dropout_rate_Layer_2': 0.07465992410101288, 'dropout_rate_Layer_3': 0.0843755007551187, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014139877018625892, 'l1_Layer_2': 0.00010283612332946772, 'l1_Layer_3': 2.2644706150492168e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.78 | sMAPE for Validation Set is: 25.33% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.21 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:58:20,922]\u001b[0m Trial 759 finished with value: 42.52243321433108 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008114046489378641, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11995166940818316, 'dropout_rate_Layer_2': 0.055165136132834816, 'dropout_rate_Layer_3': 0.08522787571040383, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013752543361682533, 'l1_Layer_2': 9.012535041008983e-05, 'l1_Layer_3': 2.36889150096349e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 190, 'n_units_Layer_3': 255}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.52 | sMAPE for Validation Set is: 25.69% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:58:34,273]\u001b[0m Trial 765 finished with value: 42.70180805807728 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012496767346705773, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.11783870544268413, 'dropout_rate_Layer_2': 0.15552910329670677, 'dropout_rate_Layer_3': 0.1589113717170341, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.080232194358376e-05, 'l1_Layer_2': 3.7975861385203564e-05, 'l1_Layer_3': 0.0020709220938673312, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.70 | sMAPE for Validation Set is: 25.55% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.53 | sMAPE for Test Set is: 26.36% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:58:38,707]\u001b[0m Trial 771 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:42,777]\u001b[0m Trial 768 finished with value: 44.542472239338075 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007699305550500602, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3103450615884472, 'dropout_rate_Layer_2': 0.3207438520723179, 'dropout_rate_Layer_3': 0.25209234114997553, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011531626606216123, 'l1_Layer_2': 3.634802750429371e-05, 'l1_Layer_3': 2.1074705632688414e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 105, 'n_units_Layer_3': 130}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.54 | sMAPE for Validation Set is: 26.63% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.18 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:58:50,774]\u001b[0m Trial 773 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:53,160]\u001b[0m Trial 772 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:58:56,075]\u001b[0m Trial 769 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:00,359]\u001b[0m Trial 770 finished with value: 43.28663245613459 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012268775285808298, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12110109582093244, 'dropout_rate_Layer_2': 0.15869891640720865, 'dropout_rate_Layer_3': 0.08792090811996985, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.27021707521825e-05, 'l1_Layer_2': 4.359970789633787e-05, 'l1_Layer_3': 0.002008651775482846, 'n_units_Layer_1': 160, 'n_units_Layer_2': 220, 'n_units_Layer_3': 280}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:00,373]\u001b[0m Trial 774 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.29 | sMAPE for Validation Set is: 26.12% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 27.80% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:59:07,007]\u001b[0m Trial 777 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:07,197]\u001b[0m Trial 778 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:14,116]\u001b[0m Trial 775 finished with value: 43.416716853061644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013642638934882035, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1294940947982279, 'dropout_rate_Layer_2': 0.05379394752382177, 'dropout_rate_Layer_3': 0.12459142424978613, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014821027432109928, 'l1_Layer_2': 0.00017889940180084352, 'l1_Layer_3': 3.352452932535391e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 210, 'n_units_Layer_3': 280}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.42 | sMAPE for Validation Set is: 26.01% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.01 | sMAPE for Test Set is: 27.50% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:59:17,892]\u001b[0m Trial 776 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:20,861]\u001b[0m Trial 781 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:32,011]\u001b[0m Trial 780 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:36,851]\u001b[0m Trial 779 finished with value: 43.14297144324919 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012108142720918423, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.10995458734381007, 'dropout_rate_Layer_2': 0.16047938698251504, 'dropout_rate_Layer_3': 0.16353971453754051, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.202312583454151e-05, 'l1_Layer_2': 3.432963364079979e-05, 'l1_Layer_3': 0.0020924712712136542, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.14 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.82 | sMAPE for Test Set is: 27.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:59:40,399]\u001b[0m Trial 785 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:45,440]\u001b[0m Trial 782 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.09 | sMAPE for Validation Set is: 26.06% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.66 | sMAPE for Test Set is: 26.24% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 09:59:47,385]\u001b[0m Trial 783 finished with value: 44.08539659961419 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011703584700410315, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12751368429643742, 'dropout_rate_Layer_2': 0.06232150597950278, 'dropout_rate_Layer_3': 0.15626185925401873, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.097338780928271e-05, 'l1_Layer_2': 3.517235541580814e-05, 'l1_Layer_3': 0.002043208082767669, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:51,901]\u001b[0m Trial 786 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:52,490]\u001b[0m Trial 788 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:58,474]\u001b[0m Trial 789 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:58,686]\u001b[0m Trial 790 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 09:59:59,813]\u001b[0m Trial 784 finished with value: 44.362274360567376 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012695060305361213, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.12179775445035372, 'dropout_rate_Layer_2': 0.06035537615830104, 'dropout_rate_Layer_3': 0.15107435503370759, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.639373418966456e-05, 'l1_Layer_2': 3.080415949447913e-05, 'l1_Layer_3': 0.0019765120021002225, 'n_units_Layer_1': 160, 'n_units_Layer_2': 235, 'n_units_Layer_3': 270}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.36 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.99 | sMAPE for Test Set is: 26.29% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:00:04,689]\u001b[0m Trial 791 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:05,800]\u001b[0m Trial 792 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:07,857]\u001b[0m Trial 793 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:12,000]\u001b[0m Trial 794 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:15,261]\u001b[0m Trial 796 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:15,610]\u001b[0m Trial 795 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:16,563]\u001b[0m Trial 797 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:22,879]\u001b[0m Trial 798 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:23,323]\u001b[0m Trial 787 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:23,875]\u001b[0m Trial 799 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:29,301]\u001b[0m Trial 800 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:31,095]\u001b[0m Trial 802 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:32,385]\u001b[0m Trial 803 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:35,070]\u001b[0m Trial 804 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:38,572]\u001b[0m Trial 805 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:39,409]\u001b[0m Trial 801 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:42,108]\u001b[0m Trial 807 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:44,464]\u001b[0m Trial 806 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:48,024]\u001b[0m Trial 809 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:48,624]\u001b[0m Trial 808 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:49,114]\u001b[0m Trial 810 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:55,799]\u001b[0m Trial 811 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:00:58,009]\u001b[0m Trial 812 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:01,826]\u001b[0m Trial 814 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:02,452]\u001b[0m Trial 815 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:06,579]\u001b[0m Trial 816 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:09,390]\u001b[0m Trial 817 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:11,827]\u001b[0m Trial 819 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:15,922]\u001b[0m Trial 818 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:18,511]\u001b[0m Trial 821 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:20,787]\u001b[0m Trial 822 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:21,085]\u001b[0m Trial 820 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:25,375]\u001b[0m Trial 823 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:26,559]\u001b[0m Trial 813 finished with value: 43.40572227414066 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011850207466342928, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2518982062062781, 'dropout_rate_Layer_2': 0.2682079614051911, 'dropout_rate_Layer_3': 0.28399537574926387, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004926851605896581, 'l1_Layer_2': 2.577775483225099e-05, 'l1_Layer_3': 4.0083197840258474e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 120, 'n_units_Layer_3': 100}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.41 | sMAPE for Validation Set is: 26.31% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.55 | sMAPE for Test Set is: 26.91% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:01:27,061]\u001b[0m Trial 825 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:30,922]\u001b[0m Trial 826 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:31,315]\u001b[0m Trial 824 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:34,877]\u001b[0m Trial 828 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:39,136]\u001b[0m Trial 830 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:42,446]\u001b[0m Trial 827 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:43,292]\u001b[0m Trial 832 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:46,001]\u001b[0m Trial 829 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:50,019]\u001b[0m Trial 831 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:50,548]\u001b[0m Trial 834 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:01:55,775]\u001b[0m Trial 837 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:00,519]\u001b[0m Trial 836 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:02,353]\u001b[0m Trial 833 finished with value: 46.394164465121925 and parameters: {'n_hidden': 3, 'learning_rate': 0.004729137907063063, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.14702338871965914, 'dropout_rate_Layer_2': 0.11193483485439557, 'dropout_rate_Layer_3': 0.22047032658308724, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0029820764611754704, 'l1_Layer_2': 0.00031791820382780656, 'l1_Layer_3': 0.0005401091152505922, 'n_units_Layer_1': 150, 'n_units_Layer_2': 190, 'n_units_Layer_3': 160}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 46.39 | sMAPE for Validation Set is: 26.77% | rMAE for Validation Set is: 0.53\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 27.26% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:02:09,764]\u001b[0m Trial 838 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:15,440]\u001b[0m Trial 835 finished with value: 43.765507082827035 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014777296680677328, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.07467740861474739, 'dropout_rate_Layer_2': 0.09646178523897066, 'dropout_rate_Layer_3': 0.07726722029639072, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012251995306842466, 'l1_Layer_2': 6.52937983731147e-05, 'l1_Layer_3': 0.0006557681854978227, 'n_units_Layer_1': 140, 'n_units_Layer_2': 225, 'n_units_Layer_3': 255}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.77 | sMAPE for Validation Set is: 26.40% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.27 | sMAPE for Test Set is: 28.33% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:02:19,353]\u001b[0m Trial 842 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:24,792]\u001b[0m Trial 843 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:29,300]\u001b[0m Trial 840 finished with value: 45.38388329156533 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010373034150687414, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29024104528088446, 'dropout_rate_Layer_2': 0.24182756630087457, 'dropout_rate_Layer_3': 0.309203313170032, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004125342918239051, 'l1_Layer_2': 3.6859137521340894e-05, 'l1_Layer_3': 4.760735471910878e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 110, 'n_units_Layer_3': 100}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 45.38 | sMAPE for Validation Set is: 26.86% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.42 | sMAPE for Test Set is: 27.15% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:02:34,149]\u001b[0m Trial 845 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:34,705]\u001b[0m Trial 839 finished with value: 41.275587424148135 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011205507128302795, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01013913181176309, 'dropout_rate_Layer_2': 0.30710276258573144, 'dropout_rate_Layer_3': 0.07562921487310488, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.8607969442983836e-05, 'l1_Layer_2': 0.0016589735134859502, 'l1_Layer_3': 6.161861981768857e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 185}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.28 | sMAPE for Validation Set is: 25.14% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.37 | sMAPE for Test Set is: 26.46% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:02:37,360]\u001b[0m Trial 844 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:39,493]\u001b[0m Trial 841 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:43,871]\u001b[0m Trial 847 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:46,398]\u001b[0m Trial 846 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:53,450]\u001b[0m Trial 851 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:02:59,489]\u001b[0m Trial 852 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:04,687]\u001b[0m Trial 853 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:08,998]\u001b[0m Trial 850 finished with value: 43.78646093175737 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012745988982654185, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.08591909297764358, 'dropout_rate_Layer_2': 0.10652078217963758, 'dropout_rate_Layer_3': 0.10423052321438325, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012854257850060665, 'l1_Layer_2': 8.642957944044763e-05, 'l1_Layer_3': 0.0006935152974165469, 'n_units_Layer_1': 185, 'n_units_Layer_2': 60, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.79 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.76 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:03:09,741]\u001b[0m Trial 848 finished with value: 43.391021664182006 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012953157513208883, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.058657576848518606, 'dropout_rate_Layer_2': 0.10196169137459106, 'dropout_rate_Layer_3': 0.10189420819053266, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001644656960532474, 'l1_Layer_2': 8.618605629468603e-05, 'l1_Layer_3': 0.0037409075585711563, 'n_units_Layer_1': 185, 'n_units_Layer_2': 220, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.39 | sMAPE for Validation Set is: 25.78% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 26.25% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:03:10,161]\u001b[0m Trial 849 finished with value: 44.094730652849876 and parameters: {'n_hidden': 3, 'learning_rate': 0.001272408803945773, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2903637197567264, 'dropout_rate_Layer_2': 0.2623958594007959, 'dropout_rate_Layer_3': 0.31656047999801845, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0005581465419314022, 'l1_Layer_2': 3.742229426819056e-05, 'l1_Layer_3': 2.913256784373157e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 115, 'n_units_Layer_3': 100}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.09 | sMAPE for Validation Set is: 26.77% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.15 | sMAPE for Test Set is: 28.43% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:03:16,152]\u001b[0m Trial 855 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:16,637]\u001b[0m Trial 856 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:22,026]\u001b[0m Trial 858 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:33,447]\u001b[0m Trial 854 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:35,025]\u001b[0m Trial 860 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:39,508]\u001b[0m Trial 857 finished with value: 43.144749464633094 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012768982047083861, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0557689851469335, 'dropout_rate_Layer_2': 0.10135584037606062, 'dropout_rate_Layer_3': 0.12621108863031455, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00012035463578670453, 'l1_Layer_2': 9.076939524425484e-05, 'l1_Layer_3': 0.0005198080855248666, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.14 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.42 | sMAPE for Test Set is: 26.61% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:03:45,240]\u001b[0m Trial 859 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:45,900]\u001b[0m Trial 861 finished with value: 44.22150243291197 and parameters: {'n_hidden': 3, 'learning_rate': 0.002828040585099966, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1931190028991795, 'dropout_rate_Layer_2': 0.27951993326595903, 'dropout_rate_Layer_3': 0.05564293225800988, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.022742695900117e-05, 'l1_Layer_2': 0.000161409387142463, 'l1_Layer_3': 0.00014189746370502353, 'n_units_Layer_1': 270, 'n_units_Layer_2': 180, 'n_units_Layer_3': 175}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.22 | sMAPE for Validation Set is: 26.53% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 20.65 | sMAPE for Test Set is: 28.04% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:03:53,934]\u001b[0m Trial 864 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:54,017]\u001b[0m Trial 863 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:03:59,977]\u001b[0m Trial 867 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:00,699]\u001b[0m Trial 862 finished with value: 42.490795234626 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012738623793836362, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.056783375609990444, 'dropout_rate_Layer_2': 0.108862637919883, 'dropout_rate_Layer_3': 0.12606603882363965, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001102822407465069, 'l1_Layer_2': 8.70293336690289e-05, 'l1_Layer_3': 0.0007477133816391446, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.49 | sMAPE for Validation Set is: 25.45% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.32 | sMAPE for Test Set is: 26.17% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:04:03,401]\u001b[0m Trial 865 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:08,506]\u001b[0m Trial 868 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:12,942]\u001b[0m Trial 866 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:14,928]\u001b[0m Trial 869 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:18,879]\u001b[0m Trial 871 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:23,888]\u001b[0m Trial 872 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:25,999]\u001b[0m Trial 874 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:32,737]\u001b[0m Trial 875 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:34,911]\u001b[0m Trial 876 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:38,687]\u001b[0m Trial 878 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:43,262]\u001b[0m Trial 870 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:43,415]\u001b[0m Trial 879 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:44,799]\u001b[0m Trial 873 finished with value: 43.825817623793775 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008637221789098812, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3185700084855083, 'dropout_rate_Layer_2': 0.29688457734969587, 'dropout_rate_Layer_3': 0.2733097330670344, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045732560667958473, 'l1_Layer_2': 0.0003321420782476349, 'l1_Layer_3': 4.9700446263743856e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 105, 'n_units_Layer_3': 165}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.83 | sMAPE for Validation Set is: 26.51% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.02 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:04:51,415]\u001b[0m Trial 880 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:52,118]\u001b[0m Trial 882 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:56,371]\u001b[0m Trial 881 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:56,623]\u001b[0m Trial 883 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:04:59,184]\u001b[0m Trial 884 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:05,195]\u001b[0m Trial 887 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:08,103]\u001b[0m Trial 877 finished with value: 42.046037485609226 and parameters: {'n_hidden': 3, 'learning_rate': 0.001085833375436063, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.048317836611904696, 'dropout_rate_Layer_2': 0.1160603008060638, 'dropout_rate_Layer_3': 0.1282860596103701, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001748444024003826, 'l1_Layer_2': 0.0001074327724384998, 'l1_Layer_3': 0.00036062792388922904, 'n_units_Layer_1': 190, 'n_units_Layer_2': 230, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.05 | sMAPE for Validation Set is: 26.01% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.56 | sMAPE for Test Set is: 26.76% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:05:11,469]\u001b[0m Trial 889 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:12,107]\u001b[0m Trial 885 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:12,711]\u001b[0m Trial 888 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:22,036]\u001b[0m Trial 892 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:23,010]\u001b[0m Trial 886 finished with value: 44.77213081944338 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010530360333906742, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.047549816970553445, 'dropout_rate_Layer_2': 0.11741625291094568, 'dropout_rate_Layer_3': 0.12731079941293846, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016057531497244075, 'l1_Layer_2': 0.00010814368351651515, 'l1_Layer_3': 0.00037264473928676466, 'n_units_Layer_1': 190, 'n_units_Layer_2': 230, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.77 | sMAPE for Validation Set is: 26.33% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 18.30 | sMAPE for Test Set is: 25.88% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:05:27,250]\u001b[0m Trial 890 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:30,602]\u001b[0m Trial 893 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:31,578]\u001b[0m Trial 895 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:31,873]\u001b[0m Trial 894 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:39,003]\u001b[0m Trial 897 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:39,104]\u001b[0m Trial 896 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:39,283]\u001b[0m Trial 898 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:47,725]\u001b[0m Trial 900 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:50,251]\u001b[0m Trial 901 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:51,066]\u001b[0m Trial 899 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:56,079]\u001b[0m Trial 902 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:05:59,433]\u001b[0m Trial 891 finished with value: 43.664673875923675 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008118416293568821, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.29152362353113986, 'dropout_rate_Layer_2': 0.27325830218842734, 'dropout_rate_Layer_3': 0.30383546389814314, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00045614796541484074, 'l1_Layer_2': 0.0001954426611514138, 'l1_Layer_3': 0.0001001858311327095, 'n_units_Layer_1': 230, 'n_units_Layer_2': 110, 'n_units_Layer_3': 170}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.66 | sMAPE for Validation Set is: 26.25% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.62 | sMAPE for Test Set is: 26.31% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:06:03,447]\u001b[0m Trial 906 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:06,353]\u001b[0m Trial 904 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:09,130]\u001b[0m Trial 903 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:11,920]\u001b[0m Trial 908 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:14,479]\u001b[0m Trial 909 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:18,564]\u001b[0m Trial 911 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:23,499]\u001b[0m Trial 912 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:27,064]\u001b[0m Trial 913 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:29,775]\u001b[0m Trial 905 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:32,168]\u001b[0m Trial 914 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:36,415]\u001b[0m Trial 916 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:36,695]\u001b[0m Trial 915 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:43,605]\u001b[0m Trial 918 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:43,788]\u001b[0m Trial 917 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:43,991]\u001b[0m Trial 910 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:45,341]\u001b[0m Trial 907 finished with value: 42.35731737666803 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012407035525672425, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.067557749666841, 'dropout_rate_Layer_2': 0.12564171676400526, 'dropout_rate_Layer_3': 0.11234124429743161, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010013442482523712, 'l1_Layer_2': 7.816435424724495e-05, 'l1_Layer_3': 0.00356826688387495, 'n_units_Layer_1': 185, 'n_units_Layer_2': 230, 'n_units_Layer_3': 230}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.36 | sMAPE for Validation Set is: 26.06% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.76 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:06:53,098]\u001b[0m Trial 921 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:06:57,040]\u001b[0m Trial 923 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:01,040]\u001b[0m Trial 924 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:05,067]\u001b[0m Trial 925 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:08,872]\u001b[0m Trial 920 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:09,972]\u001b[0m Trial 926 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:14,705]\u001b[0m Trial 927 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:18,310]\u001b[0m Trial 929 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:22,205]\u001b[0m Trial 930 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:22,226]\u001b[0m Trial 919 finished with value: 41.95168247692592 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011392694030137943, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04830891782103134, 'dropout_rate_Layer_2': 0.14304050021725093, 'dropout_rate_Layer_3': 0.12900016746022308, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001508128103687377, 'l1_Layer_2': 9.510244956097136e-05, 'l1_Layer_3': 0.0026200889338446726, 'n_units_Layer_1': 190, 'n_units_Layer_2': 240, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.95 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.99 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:07:23,199]\u001b[0m Trial 922 finished with value: 40.95226932848271 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010311144697644364, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04635113813463376, 'dropout_rate_Layer_2': 0.12530732922640153, 'dropout_rate_Layer_3': 0.08743656133125752, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015639487513265443, 'l1_Layer_2': 9.338749293329728e-05, 'l1_Layer_3': 0.0008998750273497462, 'n_units_Layer_1': 175, 'n_units_Layer_2': 240, 'n_units_Layer_3': 250}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.95 | sMAPE for Validation Set is: 25.05% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.27 | sMAPE for Test Set is: 26.31% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:07:43,276]\u001b[0m Trial 928 finished with value: 43.9207814641627 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010199303789521082, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.017349020384683347, 'dropout_rate_Layer_2': 0.2959175133902068, 'dropout_rate_Layer_3': 0.268977481316875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.977423774350767e-05, 'l1_Layer_2': 2.9224091293326858e-05, 'l1_Layer_3': 3.692779636585572e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 100, 'n_units_Layer_3': 105}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.92 | sMAPE for Validation Set is: 26.53% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.74 | sMAPE for Test Set is: 29.05% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:07:50,766]\u001b[0m Trial 934 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:07:53,875]\u001b[0m Trial 931 finished with value: 41.807997773188525 and parameters: {'n_hidden': 3, 'learning_rate': 0.001056071710227028, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.0680035090606379, 'dropout_rate_Layer_2': 0.14177802698608946, 'dropout_rate_Layer_3': 0.11761091928421032, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00014944038366285456, 'l1_Layer_2': 0.00010554107776377857, 'l1_Layer_3': 0.0009267286038255177, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 25.74% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 27.31% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:07:59,221]\u001b[0m Trial 933 finished with value: 41.57635650869389 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010075875231248812, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.03438898276298772, 'dropout_rate_Layer_2': 0.12214065573752295, 'dropout_rate_Layer_3': 0.11933063055178966, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1372130668248856e-05, 'l1_Layer_2': 0.00010980789590805339, 'l1_Layer_3': 0.0008544575739014002, 'n_units_Layer_1': 175, 'n_units_Layer_2': 250, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.58 | sMAPE for Validation Set is: 25.85% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 17.83 | sMAPE for Test Set is: 26.49% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:08:02,617]\u001b[0m Trial 932 finished with value: 43.60980993294294 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007966841983141384, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3452847933522564, 'dropout_rate_Layer_2': 0.28191136857825433, 'dropout_rate_Layer_3': 0.2550638810251255, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0004979764624774128, 'l1_Layer_2': 0.00033327722837973075, 'l1_Layer_3': 7.014158606249905e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 105, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.61 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.11 | sMAPE for Test Set is: 27.51% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:08:11,746]\u001b[0m Trial 936 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:15,957]\u001b[0m Trial 939 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:18,054]\u001b[0m Trial 937 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:22,064]\u001b[0m Trial 941 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:25,869]\u001b[0m Trial 942 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:26,343]\u001b[0m Trial 935 finished with value: 42.43856721311086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008804446128599935, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03366060810994258, 'dropout_rate_Layer_2': 0.29695473538822886, 'dropout_rate_Layer_3': 0.2586375338286746, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.277021671314101e-05, 'l1_Layer_2': 2.766932232304077e-05, 'l1_Layer_3': 2.5544737377934152e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 110}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.44 | sMAPE for Validation Set is: 26.14% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 21.59 | sMAPE for Test Set is: 28.88% | rMAE for Test Set is: 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:08:35,229]\u001b[0m Trial 938 finished with value: 41.16780226992231 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009975188746843761, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.031690064946130386, 'dropout_rate_Layer_2': 0.12576341270947847, 'dropout_rate_Layer_3': 0.1271994953387249, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.2370802938354237e-05, 'l1_Layer_2': 0.00010669264329968808, 'l1_Layer_3': 0.0010900483075551675, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 250}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.17 | sMAPE for Validation Set is: 25.52% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.82 | sMAPE for Test Set is: 27.26% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:08:39,873]\u001b[0m Trial 945 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:45,193]\u001b[0m Trial 946 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:08:52,870]\u001b[0m Trial 943 finished with value: 42.79056129373068 and parameters: {'n_hidden': 3, 'learning_rate': 0.001000200199765067, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023380714965974478, 'dropout_rate_Layer_2': 0.3142571250544207, 'dropout_rate_Layer_3': 0.2449063003813085, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.06016764099463e-05, 'l1_Layer_2': 2.9563452768546367e-05, 'l1_Layer_3': 1.6991742366077476e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.79 | sMAPE for Validation Set is: 26.35% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.47 | sMAPE for Test Set is: 28.56% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:08:56,846]\u001b[0m Trial 944 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:00,450]\u001b[0m Trial 949 pruned. Trial was pruned at epoch 3.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.09 | sMAPE for Validation Set is: 25.74% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.63 | sMAPE for Test Set is: 27.91% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:09:02,566]\u001b[0m Trial 940 finished with value: 42.09130697852628 and parameters: {'n_hidden': 3, 'learning_rate': 0.000834487593636871, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010809947970654758, 'dropout_rate_Layer_2': 0.28212672986995024, 'dropout_rate_Layer_3': 0.26304355342001723, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.360889770698849e-05, 'l1_Layer_2': 0.00036831519344774326, 'l1_Layer_3': 9.689191742500759e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 105, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:06,041]\u001b[0m Trial 950 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:13,435]\u001b[0m Trial 948 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:17,255]\u001b[0m Trial 947 finished with value: 42.12462129760089 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009570474841690833, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031144173191629636, 'dropout_rate_Layer_2': 0.3142316606632407, 'dropout_rate_Layer_3': 0.25141855350371023, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.719841099691243e-05, 'l1_Layer_2': 2.296862848233011e-05, 'l1_Layer_3': 1.866083138765258e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.12 | sMAPE for Validation Set is: 25.91% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.35 | sMAPE for Test Set is: 28.44% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:09:20,460]\u001b[0m Trial 953 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:24,357]\u001b[0m Trial 954 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:26,510]\u001b[0m Trial 952 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:29,581]\u001b[0m Trial 955 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:32,480]\u001b[0m Trial 951 finished with value: 42.88527285157746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010585179123518448, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.004997059810047652, 'dropout_rate_Layer_2': 0.3081393117948187, 'dropout_rate_Layer_3': 0.24236073281402382, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.4126008110962155e-05, 'l1_Layer_2': 3.036399655127192e-05, 'l1_Layer_3': 1.813780280571555e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.89 | sMAPE for Validation Set is: 26.34% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.89 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:09:32,874]\u001b[0m Trial 957 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:38,330]\u001b[0m Trial 959 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:38,680]\u001b[0m Trial 960 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:44,270]\u001b[0m Trial 956 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:09:51,795]\u001b[0m Trial 958 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:04,095]\u001b[0m Trial 961 finished with value: 42.693587558276704 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009493490922223221, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030075939838074852, 'dropout_rate_Layer_2': 0.30541892163605483, 'dropout_rate_Layer_3': 0.24706667125472792, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.695252982685146e-05, 'l1_Layer_2': 2.5169293460412365e-05, 'l1_Layer_3': 1.9366639853497342e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.69 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.96 | sMAPE for Test Set is: 26.99% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:10:06,365]\u001b[0m Trial 963 finished with value: 42.400815983034555 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009300370198398808, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.006443939300393168, 'dropout_rate_Layer_2': 0.30437053804576053, 'dropout_rate_Layer_3': 0.24459536991778832, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.567632276073062e-05, 'l1_Layer_2': 1.837905274183254e-05, 'l1_Layer_3': 1.8586928615201175e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.40 | sMAPE for Validation Set is: 25.97% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.48 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:10:07,484]\u001b[0m Trial 962 finished with value: 42.71948752549904 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009760540364690551, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030147958537287682, 'dropout_rate_Layer_2': 0.30680074106177785, 'dropout_rate_Layer_3': 0.24784584166311388, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.281354388807796e-05, 'l1_Layer_2': 2.6298307965133285e-05, 'l1_Layer_3': 1.5886093310979704e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 285, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.72 | sMAPE for Validation Set is: 26.59% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.52 | sMAPE for Test Set is: 27.76% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:10:11,933]\u001b[0m Trial 966 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:15,832]\u001b[0m Trial 964 finished with value: 43.292325207711826 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011454876797856984, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013197949794303873, 'dropout_rate_Layer_2': 0.0020094840817639903, 'dropout_rate_Layer_3': 0.24791691453476183, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.66318845957593e-05, 'l1_Layer_2': 1.7191711873440253e-05, 'l1_Layer_3': 2.1062875523331947e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.29 | sMAPE for Validation Set is: 26.36% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.32 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:10:24,048]\u001b[0m Trial 965 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:28,394]\u001b[0m Trial 970 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:32,612]\u001b[0m Trial 971 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:35,809]\u001b[0m Trial 967 finished with value: 42.874308891718506 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009909082102971356, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.012340981728197342, 'dropout_rate_Layer_2': 0.3056749511036355, 'dropout_rate_Layer_3': 0.24687653717158747, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.379506861151078e-05, 'l1_Layer_2': 1.6149507627910377e-05, 'l1_Layer_3': 1.5455747609771436e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.87 | sMAPE for Validation Set is: 26.57% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.57 | sMAPE for Test Set is: 27.52% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:10:38,573]\u001b[0m Trial 968 finished with value: 42.974143866061524 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011009632808464229, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0003162841392016936, 'dropout_rate_Layer_2': 0.31531468971357446, 'dropout_rate_Layer_3': 0.23580383696911852, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.203011275601443e-05, 'l1_Layer_2': 1.788976300862116e-05, 'l1_Layer_3': 1.8496722688194363e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.97 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.05 | sMAPE for Test Set is: 26.63% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:10:44,215]\u001b[0m Trial 974 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:48,241]\u001b[0m Trial 975 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:10:48,672]\u001b[0m Trial 969 finished with value: 44.0309445364513 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011390248903178418, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007140518627114081, 'dropout_rate_Layer_2': 0.3257942400837301, 'dropout_rate_Layer_3': 0.24030300889480238, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.524362949519548e-05, 'l1_Layer_2': 1.8110038221372835e-05, 'l1_Layer_3': 1.8403731159905258e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 300, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.03 | sMAPE for Validation Set is: 27.57% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.94 | sMAPE for Test Set is: 28.18% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:00,915]\u001b[0m Trial 973 finished with value: 43.47743543225405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010460506456630165, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0008204923242195808, 'dropout_rate_Layer_2': 0.31269794077536606, 'dropout_rate_Layer_3': 0.24080868488648802, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.757356129898789e-05, 'l1_Layer_2': 1.6661190269270325e-05, 'l1_Layer_3': 1.7563207481380314e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 300, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.48 | sMAPE for Validation Set is: 26.76% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.14 | sMAPE for Test Set is: 27.21% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:06,247]\u001b[0m Trial 976 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:07,388]\u001b[0m Trial 972 finished with value: 41.69366039136157 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010891671913492548, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028149219775047283, 'dropout_rate_Layer_2': 0.13730531580387453, 'dropout_rate_Layer_3': 0.1161737807652191, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00011230374001307062, 'l1_Layer_2': 0.00010822996532237802, 'l1_Layer_3': 0.0007640469912621942, 'n_units_Layer_1': 175, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.69 | sMAPE for Validation Set is: 25.40% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.43 | sMAPE for Test Set is: 26.27% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:17,969]\u001b[0m Trial 978 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:18,883]\u001b[0m Trial 977 finished with value: 42.980953450171306 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010311224873963377, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02452676085835741, 'dropout_rate_Layer_2': 0.30917951613107136, 'dropout_rate_Layer_3': 0.24726745983558848, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9070531162122725e-05, 'l1_Layer_2': 1.4011565524042719e-05, 'l1_Layer_3': 1.4122843845163617e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.98 | sMAPE for Validation Set is: 26.74% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 22.29 | sMAPE for Test Set is: 29.19% | rMAE for Test Set is: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:24,367]\u001b[0m Trial 982 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:29,323]\u001b[0m Trial 983 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:32,371]\u001b[0m Trial 979 finished with value: 42.63683144891104 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010367255569907537, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014528494030007949, 'dropout_rate_Layer_2': 0.31408925193244025, 'dropout_rate_Layer_3': 0.23237390424240373, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.576320074058896e-05, 'l1_Layer_2': 1.3704690746683614e-05, 'l1_Layer_3': 1.0799462219583446e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.64 | sMAPE for Validation Set is: 26.05% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.14 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:36,392]\u001b[0m Trial 980 finished with value: 41.72863009135255 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010672592732994318, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.028674370881475914, 'dropout_rate_Layer_2': 0.13294081034983365, 'dropout_rate_Layer_3': 0.1525355112128602, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015822111935623199, 'l1_Layer_2': 0.00011182909766668018, 'l1_Layer_3': 0.0007553729447472916, 'n_units_Layer_1': 175, 'n_units_Layer_2': 240, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.73 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:38,327]\u001b[0m Trial 981 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:43,293]\u001b[0m Trial 987 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:48,655]\u001b[0m Trial 988 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:11:56,258]\u001b[0m Trial 985 finished with value: 43.14791101371026 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012409259126810643, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015056472878996061, 'dropout_rate_Layer_2': 0.3284064061810821, 'dropout_rate_Layer_3': 0.22993409887604324, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.293932703117675e-05, 'l1_Layer_2': 1.1584393514088815e-05, 'l1_Layer_3': 1.4363628334615281e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.15 | sMAPE for Validation Set is: 26.76% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.36 | sMAPE for Test Set is: 28.63% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:11:59,157]\u001b[0m Trial 984 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:12:09,702]\u001b[0m Trial 986 finished with value: 42.11242850994042 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010713193964087004, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.02604508275577094, 'dropout_rate_Layer_2': 0.13838257016636782, 'dropout_rate_Layer_3': 0.15497371492700684, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00016234865466574068, 'l1_Layer_2': 0.0001080540771605482, 'l1_Layer_3': 0.0007490234624436372, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.11 | sMAPE for Validation Set is: 26.04% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.96 | sMAPE for Test Set is: 27.85% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:12:13,237]\u001b[0m Trial 991 finished with value: 43.0206203337022 and parameters: {'n_hidden': 3, 'learning_rate': 0.003352555011792568, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015597083021910391, 'dropout_rate_Layer_2': 0.31637602093772543, 'dropout_rate_Layer_3': 0.1016580537010405, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.3951179403361056e-05, 'l1_Layer_2': 0.001110951090134615, 'l1_Layer_3': 1.8034296200916652e-05, 'n_units_Layer_1': 270, 'n_units_Layer_2': 160, 'n_units_Layer_3': 120}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.02 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 27.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:12:13,721]\u001b[0m Trial 992 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:12:17,118]\u001b[0m Trial 989 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:12:21,820]\u001b[0m Trial 990 finished with value: 44.43549643470575 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012327836460913398, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02456271401515158, 'dropout_rate_Layer_2': 0.3200995526451918, 'dropout_rate_Layer_3': 0.22619358864811132, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.8158166023986134e-05, 'l1_Layer_2': 1.385598677548066e-05, 'l1_Layer_3': 1.476288987735231e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.44 | sMAPE for Validation Set is: 26.89% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.09 | sMAPE for Test Set is: 27.34% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:12:38,632]\u001b[0m Trial 993 finished with value: 43.707497556593815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012271481850721288, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024727554787071046, 'dropout_rate_Layer_2': 0.34165150698395064, 'dropout_rate_Layer_3': 0.2243557933443554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.4757725956503915e-05, 'l1_Layer_2': 1.2922723098622355e-05, 'l1_Layer_3': 1.6295422162233867e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.71 | sMAPE for Validation Set is: 27.09% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.85 | sMAPE for Test Set is: 29.51% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:12:42,625]\u001b[0m Trial 995 finished with value: 43.63067002308352 and parameters: {'n_hidden': 3, 'learning_rate': 0.001201992187634531, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02194060583460393, 'dropout_rate_Layer_2': 0.3358422643474251, 'dropout_rate_Layer_3': 0.223627574458531, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.61747045879001e-05, 'l1_Layer_2': 1.0246814226922363e-05, 'l1_Layer_3': 1.4585083413061958e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.63 | sMAPE for Validation Set is: 26.78% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.25 | sMAPE for Test Set is: 28.54% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:12:45,676]\u001b[0m Trial 994 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:12:47,145]\u001b[0m Trial 996 finished with value: 42.85278187364256 and parameters: {'n_hidden': 3, 'learning_rate': 0.001073950040521649, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021072829586226444, 'dropout_rate_Layer_2': 0.3507128904092545, 'dropout_rate_Layer_3': 0.2316540538603535, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.6061347697583646e-05, 'l1_Layer_2': 1.0295898771000353e-05, 'l1_Layer_3': 1.0443728162361232e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.85 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 27.71% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:12:49,278]\u001b[0m Trial 998 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:12:53,674]\u001b[0m Trial 999 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:12:55,606]\u001b[0m Trial 1000 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:13:07,558]\u001b[0m Trial 997 finished with value: 43.44026540734165 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011019695395794343, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.027329421230029766, 'dropout_rate_Layer_2': 0.13135022863505105, 'dropout_rate_Layer_3': 0.15838111906117516, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00015355299768962265, 'l1_Layer_2': 7.198574724797346e-05, 'l1_Layer_3': 0.00073700541637905, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 220}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.44 | sMAPE for Validation Set is: 26.07% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.36 | sMAPE for Test Set is: 28.52% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:13:16,304]\u001b[0m Trial 1002 finished with value: 42.78762028362858 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011258906185064577, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011671509175745453, 'dropout_rate_Layer_2': 0.3260735658334523, 'dropout_rate_Layer_3': 0.24308047858437729, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.7837572492468324e-05, 'l1_Layer_2': 1.1135818627074815e-05, 'l1_Layer_3': 1.3248972070868704e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.79 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.66 | sMAPE for Test Set is: 27.01% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:13:16,961]\u001b[0m Trial 1001 finished with value: 43.879341493692856 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011003142979960376, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014240556412331531, 'dropout_rate_Layer_2': 0.366548866456961, 'dropout_rate_Layer_3': 0.23801605179439894, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.554372210625018e-05, 'l1_Layer_2': 1.0180100683744439e-05, 'l1_Layer_3': 1.3136974151936308e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 285, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.88 | sMAPE for Validation Set is: 26.97% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.84 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:13:24,186]\u001b[0m Trial 1003 finished with value: 41.59237422045424 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006884945798525287, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17516079672457527, 'dropout_rate_Layer_2': 0.046156571093047064, 'dropout_rate_Layer_3': 0.03653390078402028, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 4.967602768097378e-05, 'l1_Layer_2': 2.1102905321172262e-05, 'l1_Layer_3': 2.4952993634812475e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 160, 'n_units_Layer_3': 290}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.59 | sMAPE for Validation Set is: 25.18% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.60 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:13:31,820]\u001b[0m Trial 1004 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:13:40,992]\u001b[0m Trial 1007 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:13:46,389]\u001b[0m Trial 1006 finished with value: 43.429158710538644 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013974241965433367, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010836743943631214, 'dropout_rate_Layer_2': 0.3338949648964036, 'dropout_rate_Layer_3': 0.24609099623132688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.760376014798683e-05, 'l1_Layer_2': 1.1722147125781063e-05, 'l1_Layer_3': 1.9963019402336852e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.43 | sMAPE for Validation Set is: 26.77% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.85 | sMAPE for Test Set is: 27.53% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:13:47,803]\u001b[0m Trial 1008 finished with value: 43.72603676097048 and parameters: {'n_hidden': 3, 'learning_rate': 0.004276890274060435, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 2.4650050945922153e-05, 'dropout_rate_Layer_2': 0.3020412611930077, 'dropout_rate_Layer_3': 0.1208523280695386, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3008587718686164e-05, 'l1_Layer_2': 0.0009542778457717231, 'l1_Layer_3': 1.8398237216313384e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 125, 'n_units_Layer_3': 120}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:13:47,811]\u001b[0m Trial 1005 finished with value: 42.38826827692363 and parameters: {'n_hidden': 3, 'learning_rate': 0.000975836805847169, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013067429585289028, 'dropout_rate_Layer_2': 0.35920866547350716, 'dropout_rate_Layer_3': 0.24703817980543896, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.579873112325908e-05, 'l1_Layer_2': 1.168059178558748e-05, 'l1_Layer_3': 1.892691640879392e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.39 | sMAPE for Validation Set is: 26.33% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.17 | sMAPE for Test Set is: 27.32% | rMAE for Test Set is: 0.56\n",
      "MAE for Validation Set is: 43.73 | sMAPE for Validation Set is: 26.12% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.00 | sMAPE for Test Set is: 26.28% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:05,444]\u001b[0m Trial 1009 finished with value: 42.94765272958222 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009495697185161038, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.009257540011973056, 'dropout_rate_Layer_2': 0.358731058217394, 'dropout_rate_Layer_3': 0.24118067719054578, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.494701310519387e-05, 'l1_Layer_2': 1.5084707352258252e-05, 'l1_Layer_3': 1.2946032427272135e-05, 'n_units_Layer_1': 265, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.95 | sMAPE for Validation Set is: 26.32% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.27 | sMAPE for Test Set is: 28.03% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:09,988]\u001b[0m Trial 1013 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:10,297]\u001b[0m Trial 1011 finished with value: 42.840405660760155 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009530769474051971, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17551673624680741, 'dropout_rate_Layer_2': 0.04436941788103471, 'dropout_rate_Layer_3': 0.03728064265348913, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.12272598033027e-05, 'l1_Layer_2': 2.2086998195271034e-05, 'l1_Layer_3': 2.63077449601975e-05, 'n_units_Layer_1': 275, 'n_units_Layer_2': 150, 'n_units_Layer_3': 290}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.84 | sMAPE for Validation Set is: 25.84% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.00 | sMAPE for Test Set is: 28.49% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:15,987]\u001b[0m Trial 1014 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:16,520]\u001b[0m Trial 1015 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:20,933]\u001b[0m Trial 1012 finished with value: 42.76738801853546 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009782772161523521, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02266394222963367, 'dropout_rate_Layer_2': 0.3572570718806567, 'dropout_rate_Layer_3': 0.23821984061963616, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.959550538077176e-05, 'l1_Layer_2': 1.5267407960769968e-05, 'l1_Layer_3': 1.0056718394360746e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.77 | sMAPE for Validation Set is: 26.50% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.92 | sMAPE for Test Set is: 28.39% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:23,170]\u001b[0m Trial 1016 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:24,274]\u001b[0m Trial 1010 finished with value: 42.99608267797077 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009828742967859963, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021332806541197534, 'dropout_rate_Layer_2': 0.3274828726659478, 'dropout_rate_Layer_3': 0.23930721549649325, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.74139302193202e-05, 'l1_Layer_2': 1.198846381755818e-05, 'l1_Layer_3': 1.321501997581326e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.00 | sMAPE for Validation Set is: 26.72% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.91 | sMAPE for Test Set is: 27.25% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:24,801]\u001b[0m Trial 1017 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:36,302]\u001b[0m Trial 1020 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:39,070]\u001b[0m Trial 1021 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:41,311]\u001b[0m Trial 1022 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:49,949]\u001b[0m Trial 1023 finished with value: 44.90080385903739 and parameters: {'n_hidden': 3, 'learning_rate': 0.008691889168232225, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': False, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.18995234884300602, 'dropout_rate_Layer_2': 0.08763279796983113, 'dropout_rate_Layer_3': 0.02033752535228947, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.511047496798919e-05, 'l1_Layer_2': 7.64877639709059e-05, 'l1_Layer_3': 1.9916430432799297e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 195, 'n_units_Layer_3': 280}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.90 | sMAPE for Validation Set is: 26.48% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 18.41 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:52,739]\u001b[0m Trial 1018 finished with value: 42.49297610633935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009601757643283874, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.020855108267914157, 'dropout_rate_Layer_2': 0.35802126758879294, 'dropout_rate_Layer_3': 0.24414458764669633, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.021596239020196e-05, 'l1_Layer_2': 1.2556770876383577e-05, 'l1_Layer_3': 1.7026389246279326e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 295, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.49 | sMAPE for Validation Set is: 26.34% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.89 | sMAPE for Test Set is: 27.17% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:14:55,298]\u001b[0m Trial 1019 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:14:59,693]\u001b[0m Trial 1027 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:00,283]\u001b[0m Trial 1026 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:00,605]\u001b[0m Trial 1024 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:08,252]\u001b[0m Trial 1029 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:08,835]\u001b[0m Trial 1028 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:09,022]\u001b[0m Trial 1030 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:11,558]\u001b[0m Trial 1025 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:32,117]\u001b[0m Trial 1033 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:32,398]\u001b[0m Trial 1032 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:35,827]\u001b[0m Trial 1034 finished with value: 41.53307722628154 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014275197101439583, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.15345763325560388, 'dropout_rate_Layer_2': 0.061208568738538374, 'dropout_rate_Layer_3': 0.12104075210358234, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.844507412405646e-05, 'l1_Layer_2': 0.00016250590512883152, 'l1_Layer_3': 0.00010923172367676599, 'n_units_Layer_1': 280, 'n_units_Layer_2': 170, 'n_units_Layer_3': 120}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.53 | sMAPE for Validation Set is: 25.68% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 27.88% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:15:38,066]\u001b[0m Trial 1031 finished with value: 42.321393915109844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008862994825117456, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.00014209849104755007, 'dropout_rate_Layer_2': 0.35313932872550013, 'dropout_rate_Layer_3': 0.23059069429463075, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.7819223017034044e-05, 'l1_Layer_2': 1.4290742070824575e-05, 'l1_Layer_3': 1.2449949236992622e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.32 | sMAPE for Validation Set is: 25.92% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.31 | sMAPE for Test Set is: 25.94% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:15:42,402]\u001b[0m Trial 1035 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:15:47,605]\u001b[0m Trial 1039 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:02,839]\u001b[0m Trial 1038 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:08,472]\u001b[0m Trial 1041 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:09,036]\u001b[0m Trial 1036 finished with value: 43.70329647069577 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009724469427054252, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04289313278048454, 'dropout_rate_Layer_2': 0.35803691340782867, 'dropout_rate_Layer_3': 0.24965391734700945, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.4880688069724268e-05, 'l1_Layer_2': 2.1615258384477638e-05, 'l1_Layer_3': 2.001908291036645e-05, 'n_units_Layer_1': 260, 'n_units_Layer_2': 300, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.70 | sMAPE for Validation Set is: 27.35% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.06 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:16:17,495]\u001b[0m Trial 1040 finished with value: 42.99218195677719 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008846564451339031, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0175626546760551, 'dropout_rate_Layer_2': 0.36209284132123837, 'dropout_rate_Layer_3': 0.22230982382869674, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.498382789589542e-05, 'l1_Layer_2': 1.172451794912744e-05, 'l1_Layer_3': 1.2353253462880675e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.99 | sMAPE for Validation Set is: 26.79% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.33 | sMAPE for Test Set is: 28.65% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:16:18,003]\u001b[0m Trial 1037 finished with value: 41.82071013914501 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009737534196661623, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.04661463685208307, 'dropout_rate_Layer_2': 0.13771747563465436, 'dropout_rate_Layer_3': 0.11368549136738054, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.874658593696013e-05, 'l1_Layer_2': 9.598367856836646e-05, 'l1_Layer_3': 0.0011929037725986272, 'n_units_Layer_1': 180, 'n_units_Layer_2': 240, 'n_units_Layer_3': 225}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.82 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 27.96% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:16:25,413]\u001b[0m Trial 1044 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:27,142]\u001b[0m Trial 1045 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:31,610]\u001b[0m Trial 1046 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:37,859]\u001b[0m Trial 1043 finished with value: 42.7453838493113 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008667435880374521, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018016575502194477, 'dropout_rate_Layer_2': 0.35996057457796504, 'dropout_rate_Layer_3': 0.22416547084272645, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.781772938878382e-05, 'l1_Layer_2': 1.1309004615991239e-05, 'l1_Layer_3': 1.209256815333753e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.75 | sMAPE for Validation Set is: 26.30% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.30 | sMAPE for Test Set is: 27.45% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:16:45,406]\u001b[0m Trial 1042 finished with value: 42.75203822839276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008748167431336937, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015072049469969, 'dropout_rate_Layer_2': 0.3888060277828935, 'dropout_rate_Layer_3': 0.22209786429356973, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.669278148954838e-05, 'l1_Layer_2': 1.167351282172711e-05, 'l1_Layer_3': 1.2648371491423045e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.75 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 26.56% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:16:48,063]\u001b[0m Trial 1047 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:51,046]\u001b[0m Trial 1050 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:16:58,436]\u001b[0m Trial 1052 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:17:01,693]\u001b[0m Trial 1048 finished with value: 42.41865962935012 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008657145408487457, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013671170857180875, 'dropout_rate_Layer_2': 0.3479926772323635, 'dropout_rate_Layer_3': 0.2240602294978095, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.242576673856335e-05, 'l1_Layer_2': 1.666920618875968e-05, 'l1_Layer_3': 1.6857678486254282e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.42 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.28 | sMAPE for Test Set is: 26.85% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:17:06,874]\u001b[0m Trial 1049 finished with value: 42.774367899919405 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008659215814996851, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01749320923199871, 'dropout_rate_Layer_2': 0.3531650893689937, 'dropout_rate_Layer_3': 0.21689661266219343, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.146021865027665e-05, 'l1_Layer_2': 1.1434545513193046e-05, 'l1_Layer_3': 1.2331338952530215e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.77 | sMAPE for Validation Set is: 26.36% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.83 | sMAPE for Test Set is: 27.48% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:17:11,027]\u001b[0m Trial 1054 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:17:14,683]\u001b[0m Trial 1056 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:17:21,858]\u001b[0m Trial 1051 finished with value: 41.84146034514479 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008604890554184078, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019831291348183677, 'dropout_rate_Layer_2': 0.3767665121999584, 'dropout_rate_Layer_3': 0.2167950097344191, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.333230166514762e-05, 'l1_Layer_2': 1.1476605074160177e-05, 'l1_Layer_3': 1.2184437970737457e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.84 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 27.30% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:17:22,878]\u001b[0m Trial 1055 finished with value: 43.494922730345515 and parameters: {'n_hidden': 3, 'learning_rate': 0.002187894880681411, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.019035364912459565, 'dropout_rate_Layer_2': 0.3172175853760438, 'dropout_rate_Layer_3': 0.06536622615643398, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.156123672393969e-05, 'l1_Layer_2': 0.0006767900267106884, 'l1_Layer_3': 2.6200218924218258e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.49 | sMAPE for Validation Set is: 26.20% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.02 | sMAPE for Test Set is: 27.60% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:17:27,498]\u001b[0m Trial 1057 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:17:28,697]\u001b[0m Trial 1053 finished with value: 42.15425018565573 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008801923593596394, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018501082185462925, 'dropout_rate_Layer_2': 0.3930150296685381, 'dropout_rate_Layer_3': 0.22293708734403495, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.206083203744897e-05, 'l1_Layer_2': 1.122337871196796e-05, 'l1_Layer_3': 1.2140267366074822e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.15 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.04 | sMAPE for Test Set is: 26.45% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:17:35,939]\u001b[0m Trial 1059 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:17:48,130]\u001b[0m Trial 1058 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:17:56,285]\u001b[0m Trial 1063 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.64 | sMAPE for Validation Set is: 25.33% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.11 | sMAPE for Test Set is: 27.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:17:58,129]\u001b[0m Trial 1062 finished with value: 41.64204566346796 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010618939152213988, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04520743418944802, 'dropout_rate_Layer_2': 0.14631429115273717, 'dropout_rate_Layer_3': 0.14139175113223373, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00013253542697655584, 'l1_Layer_2': 0.00011042913766444122, 'l1_Layer_3': 0.0006344483453651393, 'n_units_Layer_1': 175, 'n_units_Layer_2': 255, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:03,327]\u001b[0m Trial 1064 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:03,694]\u001b[0m Trial 1061 finished with value: 43.00873364945104 and parameters: {'n_hidden': 3, 'learning_rate': 0.000840599817742244, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03671373904039076, 'dropout_rate_Layer_2': 0.3940726658096012, 'dropout_rate_Layer_3': 0.2108850011270751, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.924927425302104e-05, 'l1_Layer_2': 1.335240008259348e-05, 'l1_Layer_3': 1.2317983070738964e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.01 | sMAPE for Validation Set is: 26.52% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.69 | sMAPE for Test Set is: 28.07% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:18:10,454]\u001b[0m Trial 1065 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:14,943]\u001b[0m Trial 1060 finished with value: 42.817569588391486 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008341279424725607, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.038934193581180256, 'dropout_rate_Layer_2': 0.37777426569860323, 'dropout_rate_Layer_3': 0.21071713483155094, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.995978655719096e-05, 'l1_Layer_2': 1.2297699106339338e-05, 'l1_Layer_3': 1.218471359788481e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.82 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.71 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:18:19,021]\u001b[0m Trial 1069 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:25,400]\u001b[0m Trial 1066 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:29,453]\u001b[0m Trial 1068 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:30,942]\u001b[0m Trial 1067 finished with value: 43.55685011846949 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008597928992071133, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01990572897806036, 'dropout_rate_Layer_2': 0.38103396289328256, 'dropout_rate_Layer_3': 0.21957225915833173, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.284697160819489e-05, 'l1_Layer_2': 1.1805930759063473e-05, 'l1_Layer_3': 1.4937245126508755e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.56 | sMAPE for Validation Set is: 26.22% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.80 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:18:33,772]\u001b[0m Trial 1071 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:39,292]\u001b[0m Trial 1074 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:49,569]\u001b[0m Trial 1070 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:52,196]\u001b[0m Trial 1073 finished with value: 42.697685310216805 and parameters: {'n_hidden': 3, 'learning_rate': 0.0014051933208421804, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.11672834506007253, 'dropout_rate_Layer_2': 0.06954673083419537, 'dropout_rate_Layer_3': 0.07139882400559669, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 5.6083271369334805e-05, 'l1_Layer_2': 0.00014199724389800625, 'l1_Layer_3': 0.00015479639334254396, 'n_units_Layer_1': 300, 'n_units_Layer_2': 145, 'n_units_Layer_3': 110}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.70 | sMAPE for Validation Set is: 25.85% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.00 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:18:55,276]\u001b[0m Trial 1076 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:18:58,038]\u001b[0m Trial 1072 finished with value: 42.994805798795504 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009380313065162516, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.026242754927687965, 'dropout_rate_Layer_2': 0.394840080037717, 'dropout_rate_Layer_3': 0.22303207543571688, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.403491586826311e-05, 'l1_Layer_2': 1.4662591665701248e-05, 'l1_Layer_3': 1.1442911301001776e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 280, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.99 | sMAPE for Validation Set is: 26.54% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 26.84% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:19:04,256]\u001b[0m Trial 1078 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:08,512]\u001b[0m Trial 1079 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:08,891]\u001b[0m Trial 1075 finished with value: 41.31825180305185 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010168107426147034, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03579607956800292, 'dropout_rate_Layer_2': 0.11590431991936373, 'dropout_rate_Layer_3': 0.08679967589440014, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 8.44978442006796e-05, 'l1_Layer_2': 6.610295054656518e-05, 'l1_Layer_3': 0.0007219870322629939, 'n_units_Layer_1': 170, 'n_units_Layer_2': 255, 'n_units_Layer_3': 245}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.32 | sMAPE for Validation Set is: 25.53% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.57 | sMAPE for Test Set is: 27.07% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:19:22,721]\u001b[0m Trial 1080 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:23,289]\u001b[0m Trial 1077 finished with value: 43.62223409976401 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007976173433525828, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030319553011682217, 'dropout_rate_Layer_2': 0.39030948045949976, 'dropout_rate_Layer_3': 0.22401116557868653, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.282605892964549e-05, 'l1_Layer_2': 1.4538578319950883e-05, 'l1_Layer_3': 1.1889203766905065e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 135}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.62 | sMAPE for Validation Set is: 26.34% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.01 | sMAPE for Test Set is: 26.94% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:19:28,340]\u001b[0m Trial 1081 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:29,056]\u001b[0m Trial 1084 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:39,972]\u001b[0m Trial 1085 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:45,136]\u001b[0m Trial 1082 finished with value: 42.637013412822085 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007957249914669829, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04511130573891971, 'dropout_rate_Layer_2': 0.3562526738359624, 'dropout_rate_Layer_3': 0.22625740890983728, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.227308634740169e-05, 'l1_Layer_2': 1.7960335082024374e-05, 'l1_Layer_3': 1.777784290406964e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 290, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.64 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.74 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:19:49,280]\u001b[0m Trial 1088 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:51,116]\u001b[0m Trial 1086 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:19:55,200]\u001b[0m Trial 1083 finished with value: 41.90577523776917 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009409920597404451, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044921111010854026, 'dropout_rate_Layer_2': 0.34480994381941077, 'dropout_rate_Layer_3': 0.19363379996110514, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.546248525839353e-05, 'l1_Layer_2': 1.9954290945675547e-05, 'l1_Layer_3': 2.1085474749390186e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.91 | sMAPE for Validation Set is: 26.11% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.41 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:20:00,049]\u001b[0m Trial 1091 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:04,158]\u001b[0m Trial 1092 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:08,878]\u001b[0m Trial 1087 finished with value: 41.98852940319844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009331681348949994, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': True, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044461510303438354, 'dropout_rate_Layer_2': 0.3693404200290462, 'dropout_rate_Layer_3': 0.20882934808271703, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.903551267369184e-05, 'l1_Layer_2': 1.033449496766654e-05, 'l1_Layer_3': 1.3493362863601162e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 285, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.99 | sMAPE for Validation Set is: 25.74% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 26.91% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:20:12,111]\u001b[0m Trial 1089 finished with value: 43.511391919392196 and parameters: {'n_hidden': 3, 'learning_rate': 0.004941903449315611, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06601677213513658, 'dropout_rate_Layer_2': 0.335621097919689, 'dropout_rate_Layer_3': 0.05048932242733832, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.9539085627774345e-05, 'l1_Layer_2': 0.0012899781768595077, 'l1_Layer_3': 3.528598194042138e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 150, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.51 | sMAPE for Validation Set is: 26.00% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.12 | sMAPE for Test Set is: 29.01% | rMAE for Test Set is: 0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:20:15,656]\u001b[0m Trial 1094 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:18,446]\u001b[0m Trial 1095 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:20,686]\u001b[0m Trial 1096 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:26,476]\u001b[0m Trial 1090 finished with value: 41.96040793910164 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010956001001192117, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': True, 'dropout_rate_Layer_1': 0.01901724111350565, 'dropout_rate_Layer_2': 0.14008055014785434, 'dropout_rate_Layer_3': 0.13863298943116215, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0001338511163071744, 'l1_Layer_2': 0.00010988451071175204, 'l1_Layer_3': 0.0008675205612687166, 'n_units_Layer_1': 200, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.96 | sMAPE for Validation Set is: 25.40% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.65 | sMAPE for Test Set is: 26.56% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:20:27,460]\u001b[0m Trial 1097 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:33,108]\u001b[0m Trial 1100 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:33,767]\u001b[0m Trial 1093 finished with value: 41.686747594244316 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008866313791652654, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044207809661572325, 'dropout_rate_Layer_2': 0.35665504582816115, 'dropout_rate_Layer_3': 0.21615036674259144, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.345337325657052e-05, 'l1_Layer_2': 1.7756273179495342e-05, 'l1_Layer_3': 2.249706865489302e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 130}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.69 | sMAPE for Validation Set is: 25.79% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.28 | sMAPE for Test Set is: 26.64% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:20:40,448]\u001b[0m Trial 1102 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:41,005]\u001b[0m Trial 1101 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:46,106]\u001b[0m Trial 1103 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:20:51,611]\u001b[0m Trial 1098 finished with value: 41.82828818144023 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009041081992685387, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04074341071024393, 'dropout_rate_Layer_2': 0.3734244379078966, 'dropout_rate_Layer_3': 0.20758017855073002, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.874943697457751e-05, 'l1_Layer_2': 1.6182631251647866e-05, 'l1_Layer_3': 2.0991339868599684e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 290, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.83 | sMAPE for Validation Set is: 26.10% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.38 | sMAPE for Test Set is: 26.14% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:20:57,847]\u001b[0m Trial 1099 finished with value: 42.25091049141418 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009167635544186762, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04597840039728959, 'dropout_rate_Layer_2': 0.36428406288677506, 'dropout_rate_Layer_3': 0.20994385452808287, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.245747090212242e-05, 'l1_Layer_2': 1.597225236458909e-05, 'l1_Layer_3': 2.432822657993073e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.25 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.24 | sMAPE for Test Set is: 25.73% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:21:01,459]\u001b[0m Trial 1106 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:05,307]\u001b[0m Trial 1108 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:08,795]\u001b[0m Trial 1107 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:09,136]\u001b[0m Trial 1109 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:14,225]\u001b[0m Trial 1110 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:14,863]\u001b[0m Trial 1111 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:16,566]\u001b[0m Trial 1104 finished with value: 41.202100632218304 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009171785571887967, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031022468711306355, 'dropout_rate_Layer_2': 0.14481247563472607, 'dropout_rate_Layer_3': 0.13193387155770273, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00021990116471753705, 'l1_Layer_2': 0.00011857912855143968, 'l1_Layer_3': 0.0008883771046072957, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 235}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.20 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.42 | sMAPE for Test Set is: 26.80% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:21:22,674]\u001b[0m Trial 1113 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:23,837]\u001b[0m Trial 1114 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:25,203]\u001b[0m Trial 1105 finished with value: 42.54417956726039 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008891009349844454, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05504199673551885, 'dropout_rate_Layer_2': 0.37613181819827424, 'dropout_rate_Layer_3': 0.22285801824424722, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 7.060613584382933e-05, 'l1_Layer_2': 1.3744188307905535e-05, 'l1_Layer_3': 1.8006725366017312e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 290, 'n_units_Layer_3': 130}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.54 | sMAPE for Validation Set is: 26.35% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.74 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:21:28,418]\u001b[0m Trial 1115 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:32,291]\u001b[0m Trial 1116 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:32,842]\u001b[0m Trial 1117 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:38,030]\u001b[0m Trial 1118 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:40,639]\u001b[0m Trial 1119 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:44,710]\u001b[0m Trial 1120 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:49,685]\u001b[0m Trial 1123 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:53,365]\u001b[0m Trial 1124 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:21:57,035]\u001b[0m Trial 1125 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:01,705]\u001b[0m Trial 1112 finished with value: 41.89352870692945 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007643522275752631, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05233854019699616, 'dropout_rate_Layer_2': 0.3443058894031143, 'dropout_rate_Layer_3': 0.18627540055757158, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.338219391836514e-05, 'l1_Layer_2': 1.6890470413383447e-05, 'l1_Layer_3': 2.2851147991804187e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.89 | sMAPE for Validation Set is: 26.10% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.99 | sMAPE for Test Set is: 26.65% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:22:05,870]\u001b[0m Trial 1126 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:07,263]\u001b[0m Trial 1122 finished with value: 42.31128206295173 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008241464639360823, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04916619416874917, 'dropout_rate_Layer_2': 0.34750395823226293, 'dropout_rate_Layer_3': 0.17914916040884807, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.9017507198521594e-05, 'l1_Layer_2': 2.3722054539393744e-05, 'l1_Layer_3': 2.5508720118389324e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.31 | sMAPE for Validation Set is: 25.86% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.94 | sMAPE for Test Set is: 26.40% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:22:11,413]\u001b[0m Trial 1121 finished with value: 41.932230093724456 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008324982519992619, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04843905419854746, 'dropout_rate_Layer_2': 0.34882308567383197, 'dropout_rate_Layer_3': 0.21334045496777737, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.3300889723367975e-05, 'l1_Layer_2': 2.255420734140133e-05, 'l1_Layer_3': 1.7093717425393067e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 290, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.93 | sMAPE for Validation Set is: 26.05% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.38 | sMAPE for Test Set is: 26.78% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:22:15,531]\u001b[0m Trial 1129 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:18,772]\u001b[0m Trial 1130 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:30,839]\u001b[0m Trial 1128 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:42,954]\u001b[0m Trial 1127 finished with value: 42.21308060568693 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007160971530497424, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06519425408919431, 'dropout_rate_Layer_2': 0.3441011006113457, 'dropout_rate_Layer_3': 0.19537322858308157, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.843389501424655e-05, 'l1_Layer_2': 1.3956147567785494e-05, 'l1_Layer_3': 2.000535437508561e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 295, 'n_units_Layer_3': 140}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.21 | sMAPE for Validation Set is: 26.21% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.17 | sMAPE for Test Set is: 26.90% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:22:46,448]\u001b[0m Trial 1132 finished with value: 41.31689743330806 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009963145815970599, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007230679257313844, 'dropout_rate_Layer_2': 0.12423130486081661, 'dropout_rate_Layer_3': 0.11694875919620153, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.00010162054530090932, 'l1_Layer_2': 0.00010195216086533086, 'l1_Layer_3': 0.0006950002161193851, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.32 | sMAPE for Validation Set is: 26.23% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.80 | sMAPE for Test Set is: 27.72% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:22:48,641]\u001b[0m Trial 1134 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:53,349]\u001b[0m Trial 1136 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:22:53,580]\u001b[0m Trial 1131 finished with value: 42.67327842962226 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007226563288890009, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04861801644597391, 'dropout_rate_Layer_2': 0.3489048763787198, 'dropout_rate_Layer_3': 0.19415992362566684, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.921263169746873e-05, 'l1_Layer_2': 2.119626441243082e-05, 'l1_Layer_3': 2.384722654537238e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 300, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.67 | sMAPE for Validation Set is: 26.44% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.99 | sMAPE for Test Set is: 26.38% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:23:00,617]\u001b[0m Trial 1137 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:08,696]\u001b[0m Trial 1139 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:13,392]\u001b[0m Trial 1133 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:16,637]\u001b[0m Trial 1140 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:21,198]\u001b[0m Trial 1142 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:21,808]\u001b[0m Trial 1138 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:24,022]\u001b[0m Trial 1135 finished with value: 42.305253635324995 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009198147866353884, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0024696690356538036, 'dropout_rate_Layer_2': 0.11879019472080139, 'dropout_rate_Layer_3': 0.11404882415096536, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001357338475239862, 'l1_Layer_2': 0.00011867546189991537, 'l1_Layer_3': 0.0006902496688743556, 'n_units_Layer_1': 195, 'n_units_Layer_2': 265, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.31 | sMAPE for Validation Set is: 26.13% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.31 | sMAPE for Test Set is: 26.07% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:23:30,047]\u001b[0m Trial 1145 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:31,096]\u001b[0m Trial 1144 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:38,211]\u001b[0m Trial 1147 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:23:44,882]\u001b[0m Trial 1141 finished with value: 41.99656480028566 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008241081676288234, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008272704776952848, 'dropout_rate_Layer_2': 0.142864462275058, 'dropout_rate_Layer_3': 0.10865137339658242, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002311377357564977, 'l1_Layer_2': 0.00014293086225290687, 'l1_Layer_3': 0.0007612616881051298, 'n_units_Layer_1': 205, 'n_units_Layer_2': 270, 'n_units_Layer_3': 215}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.00 | sMAPE for Validation Set is: 25.81% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.88 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:23:47,137]\u001b[0m Trial 1143 finished with value: 42.03664564822083 and parameters: {'n_hidden': 3, 'learning_rate': 0.002316669284281017, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.023254266295692598, 'dropout_rate_Layer_2': 0.3218472732806839, 'dropout_rate_Layer_3': 0.06032800628330948, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1971866531682139e-05, 'l1_Layer_2': 0.0007147870061906946, 'l1_Layer_3': 2.7441022894158324e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.04 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.93 | sMAPE for Test Set is: 27.75% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:23:53,988]\u001b[0m Trial 1146 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:01,405]\u001b[0m Trial 1148 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:05,227]\u001b[0m Trial 1152 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:08,990]\u001b[0m Trial 1149 finished with value: 42.43963716338001 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021699160390185497, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.021981416632716817, 'dropout_rate_Layer_2': 0.3161219923758007, 'dropout_rate_Layer_3': 0.06502101623656346, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1287551176158473e-05, 'l1_Layer_2': 0.0006972131023372782, 'l1_Layer_3': 3.0242969873955324e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 165, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.44 | sMAPE for Validation Set is: 25.47% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 27.66% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:24:11,279]\u001b[0m Trial 1150 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:15,832]\u001b[0m Trial 1155 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:16,273]\u001b[0m Trial 1153 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:22,959]\u001b[0m Trial 1157 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:26,866]\u001b[0m Trial 1158 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:27,297]\u001b[0m Trial 1151 finished with value: 42.45204325202457 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008574445870862974, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040507662347444, 'dropout_rate_Layer_2': 0.3639285414718376, 'dropout_rate_Layer_3': 0.18995036166018608, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.138325889475199e-05, 'l1_Layer_2': 1.723984719115489e-05, 'l1_Layer_3': 1.772504319316869e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.45 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.43 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:24:27,595]\u001b[0m Trial 1156 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.97 | sMAPE for Validation Set is: 26.22% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.80 | sMAPE for Test Set is: 28.99% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:24:33,407]\u001b[0m Trial 1154 finished with value: 42.96580596208765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0032853885472241954, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.01697585817712209, 'dropout_rate_Layer_2': 0.2916129148215748, 'dropout_rate_Layer_3': 0.04051762922913228, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.6103603147176065e-05, 'l1_Layer_2': 0.0004130698047972814, 'l1_Layer_3': 3.718700436471595e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 180, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:37,771]\u001b[0m Trial 1161 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:42,401]\u001b[0m Trial 1160 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:43,200]\u001b[0m Trial 1159 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:50,477]\u001b[0m Trial 1165 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:24:58,593]\u001b[0m Trial 1166 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:25:01,959]\u001b[0m Trial 1163 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:25:07,097]\u001b[0m Trial 1164 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:25:11,080]\u001b[0m Trial 1169 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:25:19,897]\u001b[0m Trial 1162 finished with value: 41.57778656209425 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007639406679359884, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.036950480734955105, 'dropout_rate_Layer_2': 0.3466230538023738, 'dropout_rate_Layer_3': 0.18962837910801797, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.7901049861479424e-05, 'l1_Layer_2': 1.9053312725676886e-05, 'l1_Layer_3': 1.5351216532309945e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 275, 'n_units_Layer_3': 160}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.58 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.64 | sMAPE for Test Set is: 26.30% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:25:27,670]\u001b[0m Trial 1171 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:25:32,528]\u001b[0m Trial 1172 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:25:32,840]\u001b[0m Trial 1170 finished with value: 43.12256407727131 and parameters: {'n_hidden': 3, 'learning_rate': 0.0025976775026094493, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.024262691095942084, 'dropout_rate_Layer_2': 0.27093115325714207, 'dropout_rate_Layer_3': 0.00021213220280458245, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.1802925331550381e-05, 'l1_Layer_2': 0.001400771859781638, 'l1_Layer_3': 2.025680899584072e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 200, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.12 | sMAPE for Validation Set is: 26.08% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 21.76 | sMAPE for Test Set is: 29.90% | rMAE for Test Set is: 0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:25:34,080]\u001b[0m Trial 1167 finished with value: 42.33823028434144 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007702545596305823, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.044252397740255134, 'dropout_rate_Layer_2': 0.35379263200899164, 'dropout_rate_Layer_3': 0.179490113892604, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.3632154136365324e-05, 'l1_Layer_2': 2.6158202105562283e-05, 'l1_Layer_3': 2.376699952798553e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.34 | sMAPE for Validation Set is: 26.11% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.22 | sMAPE for Test Set is: 26.91% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:25:36,345]\u001b[0m Trial 1168 finished with value: 42.40000677758893 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007973000390399656, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.007280176875817567, 'dropout_rate_Layer_2': 0.1364112069552515, 'dropout_rate_Layer_3': 0.10025039798946547, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00018384534057530575, 'l1_Layer_2': 0.00012190104315988556, 'l1_Layer_3': 0.000517736180002658, 'n_units_Layer_1': 205, 'n_units_Layer_2': 260, 'n_units_Layer_3': 220}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.40 | sMAPE for Validation Set is: 25.79% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.31 | sMAPE for Test Set is: 26.07% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:25:43,725]\u001b[0m Trial 1176 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:01,628]\u001b[0m Trial 1173 finished with value: 41.8058910296788 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009590954327860506, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0006703563153271797, 'dropout_rate_Layer_2': 0.13726039300168466, 'dropout_rate_Layer_3': 0.09654332097742382, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002927067687713973, 'l1_Layer_2': 0.0013693156426412099, 'l1_Layer_3': 0.0005041313246993347, 'n_units_Layer_1': 195, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.81 | sMAPE for Validation Set is: 25.38% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.65 | sMAPE for Test Set is: 27.23% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:26:02,252]\u001b[0m Trial 1175 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:05,109]\u001b[0m Trial 1177 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:13,239]\u001b[0m Trial 1179 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:18,091]\u001b[0m Trial 1174 finished with value: 42.264991259053765 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007827653878760271, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.048447081158603716, 'dropout_rate_Layer_2': 0.3358007210112972, 'dropout_rate_Layer_3': 0.17835937375939814, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.654999555030704e-05, 'l1_Layer_2': 2.8013297810926653e-05, 'l1_Layer_3': 2.70565887999145e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 255, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.26 | sMAPE for Validation Set is: 26.12% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.02 | sMAPE for Test Set is: 26.92% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:26:21,928]\u001b[0m Trial 1182 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:25,190]\u001b[0m Trial 1181 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:26,440]\u001b[0m Trial 1183 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:30,590]\u001b[0m Trial 1184 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:43,045]\u001b[0m Trial 1180 finished with value: 42.945209410780514 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007914050961822251, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03289551162737747, 'dropout_rate_Layer_2': 0.34250771072039315, 'dropout_rate_Layer_3': 0.1970648871982049, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 1.0352799567263466e-05, 'l1_Layer_2': 2.339452853944053e-05, 'l1_Layer_3': 2.1173086391057243e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.95 | sMAPE for Validation Set is: 26.59% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.93 | sMAPE for Test Set is: 28.23% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:26:46,963]\u001b[0m Trial 1187 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:54,610]\u001b[0m Trial 1188 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:26:58,756]\u001b[0m Trial 1178 finished with value: 42.091325196611386 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006772811285935187, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04632060480056144, 'dropout_rate_Layer_2': 0.34140361646778156, 'dropout_rate_Layer_3': 0.1992848157211339, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.671439189601787e-05, 'l1_Layer_2': 2.8228214644319352e-05, 'l1_Layer_3': 2.261485813559146e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 260, 'n_units_Layer_3': 150}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.09 | sMAPE for Validation Set is: 25.96% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.38 | sMAPE for Test Set is: 26.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:26:59,943]\u001b[0m Trial 1189 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:05,181]\u001b[0m Trial 1191 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:08,223]\u001b[0m Trial 1185 finished with value: 42.38775279201261 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006801307677536011, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06968292990156019, 'dropout_rate_Layer_2': 0.3540404565826224, 'dropout_rate_Layer_3': 0.19972524651154902, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.555512024146497e-05, 'l1_Layer_2': 1.0015302344362494e-05, 'l1_Layer_3': 2.8426271404758363e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 250, 'n_units_Layer_3': 145}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.39 | sMAPE for Validation Set is: 26.27% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 27.65% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:27:09,003]\u001b[0m Trial 1192 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:12,069]\u001b[0m Trial 1190 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:13,736]\u001b[0m Trial 1193 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:15,041]\u001b[0m Trial 1186 finished with value: 41.84342619947714 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006711309061339002, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06410002330964479, 'dropout_rate_Layer_2': 0.35467605524702106, 'dropout_rate_Layer_3': 0.19910031161683653, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.755230567088747e-05, 'l1_Layer_2': 1.9805875966863275e-05, 'l1_Layer_3': 1.6764792096867458e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 260, 'n_units_Layer_3': 155}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.84 | sMAPE for Validation Set is: 26.07% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.39 | sMAPE for Test Set is: 26.13% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:27:18,914]\u001b[0m Trial 1194 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:24,157]\u001b[0m Trial 1195 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:24,467]\u001b[0m Trial 1196 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:29,639]\u001b[0m Trial 1198 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:31,579]\u001b[0m Trial 1200 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:38,673]\u001b[0m Trial 1199 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:27:50,291]\u001b[0m Trial 1197 finished with value: 41.205460222592954 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007820759478115788, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.003097389801437065, 'dropout_rate_Layer_2': 0.14687389078301194, 'dropout_rate_Layer_3': 0.09197414397824363, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002622737119646798, 'l1_Layer_2': 0.00010671748166525864, 'l1_Layer_3': 0.000495440104106061, 'n_units_Layer_1': 195, 'n_units_Layer_2': 260, 'n_units_Layer_3': 225}. Best is trial 294 with value: 40.91169941576166.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.21 | sMAPE for Validation Set is: 25.61% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 26.95% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:27:53,016]\u001b[0m Trial 1201 finished with value: 40.714846398516535 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018226348472000116, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.014954250897128207, 'dropout_rate_Layer_2': 0.2941837515645077, 'dropout_rate_Layer_3': 0.042490518545107, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3889084438453185e-05, 'l1_Layer_2': 0.000837536376129359, 'l1_Layer_3': 0.00044332122291193055, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 215}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.71 | sMAPE for Validation Set is: 24.99% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.92 | sMAPE for Test Set is: 26.54% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:27:58,793]\u001b[0m Trial 1203 finished with value: 42.39994375031864 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017963677887555731, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008686098801088418, 'dropout_rate_Layer_2': 0.28600366068648814, 'dropout_rate_Layer_3': 0.038755610417457204, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3460999886953716e-05, 'l1_Layer_2': 0.000997001659954269, 'l1_Layer_3': 2.4236156025048343e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.40 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.98 | sMAPE for Test Set is: 26.73% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:28:03,219]\u001b[0m Trial 1206 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:05,756]\u001b[0m Trial 1202 finished with value: 42.31355678689935 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006150418837527988, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05847959104671123, 'dropout_rate_Layer_2': 0.356649482337389, 'dropout_rate_Layer_3': 0.20532563029169687, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.211448764705067e-05, 'l1_Layer_2': 2.3764715120308258e-05, 'l1_Layer_3': 2.4643682241906396e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 150}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.31 | sMAPE for Validation Set is: 26.08% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.14 | sMAPE for Test Set is: 26.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:28:10,636]\u001b[0m Trial 1207 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:16,382]\u001b[0m Trial 1204 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:18,747]\u001b[0m Trial 1205 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:24,511]\u001b[0m Trial 1209 finished with value: 44.9413089486496 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017665111914013224, 'batch_size': 70, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0012815339116782135, 'dropout_rate_Layer_2': 0.13845792943910284, 'dropout_rate_Layer_3': 0.06094185997136266, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.0044067087427563e-05, 'l1_Layer_2': 0.0018811914290237644, 'l1_Layer_3': 0.0009131628887522565, 'n_units_Layer_1': 215, 'n_units_Layer_2': 195, 'n_units_Layer_3': 215}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.94 | sMAPE for Validation Set is: 26.57% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 20.70 | sMAPE for Test Set is: 27.83% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:28:28,522]\u001b[0m Trial 1212 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:30,765]\u001b[0m Trial 1208 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:39,200]\u001b[0m Trial 1211 finished with value: 42.20349240168013 and parameters: {'n_hidden': 3, 'learning_rate': 0.0021116167605138127, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0058056410093423605, 'dropout_rate_Layer_2': 0.2951922743566069, 'dropout_rate_Layer_3': 0.014203336598265254, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.9060681618814865e-05, 'l1_Layer_2': 0.0006810963759967176, 'l1_Layer_3': 0.00044423635068729017, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 65}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.20 | sMAPE for Validation Set is: 25.50% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.64 | sMAPE for Test Set is: 27.46% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:28:41,148]\u001b[0m Trial 1210 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:45,354]\u001b[0m Trial 1215 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:48,882]\u001b[0m Trial 1216 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:55,003]\u001b[0m Trial 1214 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:28:58,841]\u001b[0m Trial 1219 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:07,362]\u001b[0m Trial 1220 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:08,840]\u001b[0m Trial 1217 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:09,047]\u001b[0m Trial 1213 finished with value: 42.23107239257801 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006169841491763763, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.051588085187439986, 'dropout_rate_Layer_2': 0.3449957094910862, 'dropout_rate_Layer_3': 0.20869200790425804, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.4282717245273605e-05, 'l1_Layer_2': 2.2196156718610686e-05, 'l1_Layer_3': 2.0772956372678815e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.23 | sMAPE for Validation Set is: 26.12% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.78 | sMAPE for Test Set is: 26.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:29:19,352]\u001b[0m Trial 1218 finished with value: 41.099062391723635 and parameters: {'n_hidden': 3, 'learning_rate': 0.002074952396335609, 'batch_size': 63, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03719370407092486, 'dropout_rate_Layer_2': 0.3040516356964797, 'dropout_rate_Layer_3': 0.025801697796911646, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1843505145298708e-05, 'l1_Layer_2': 0.0006247131296925703, 'l1_Layer_3': 0.000698438118956744, 'n_units_Layer_1': 220, 'n_units_Layer_2': 200, 'n_units_Layer_3': 50}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.10 | sMAPE for Validation Set is: 25.16% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.68 | sMAPE for Test Set is: 26.53% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:29:24,546]\u001b[0m Trial 1224 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:31,968]\u001b[0m Trial 1221 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:37,078]\u001b[0m Trial 1226 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:40,344]\u001b[0m Trial 1222 finished with value: 42.15663892251764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008973518026583507, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.010223500321122389, 'dropout_rate_Layer_2': 0.1442312130291069, 'dropout_rate_Layer_3': 0.13877493113402808, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00035567651534481085, 'l1_Layer_2': 0.00020780848096366204, 'l1_Layer_3': 0.0002772198886689501, 'n_units_Layer_1': 195, 'n_units_Layer_2': 255, 'n_units_Layer_3': 220}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.16 | sMAPE for Validation Set is: 25.72% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.48 | sMAPE for Test Set is: 27.03% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:29:43,821]\u001b[0m Trial 1227 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:50,702]\u001b[0m Trial 1228 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:52,729]\u001b[0m Trial 1229 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:29:55,495]\u001b[0m Trial 1223 finished with value: 42.37265476722277 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006238308906737817, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04605486911095144, 'dropout_rate_Layer_2': 0.3426687440836276, 'dropout_rate_Layer_3': 0.2094858286225875, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.927007254603212e-05, 'l1_Layer_2': 3.064091311667024e-05, 'l1_Layer_3': 2.54606719164094e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.37 | sMAPE for Validation Set is: 26.14% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.31 | sMAPE for Test Set is: 27.46% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:30:00,161]\u001b[0m Trial 1230 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:00,921]\u001b[0m Trial 1232 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:05,688]\u001b[0m Trial 1225 finished with value: 42.71297383012052 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006247626723341614, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0567525520537107, 'dropout_rate_Layer_2': 0.34799658443791315, 'dropout_rate_Layer_3': 0.18987774546242991, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.8672798272781393e-05, 'l1_Layer_2': 2.5432459582233286e-05, 'l1_Layer_3': 2.5098611226595077e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 240, 'n_units_Layer_3': 150}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.71 | sMAPE for Validation Set is: 26.03% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.44 | sMAPE for Test Set is: 27.33% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:30:05,992]\u001b[0m Trial 1233 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:06,713]\u001b[0m Trial 1234 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:13,152]\u001b[0m Trial 1235 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:16,485]\u001b[0m Trial 1237 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:18,553]\u001b[0m Trial 1238 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:18,629]\u001b[0m Trial 1236 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:24,819]\u001b[0m Trial 1239 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:25,679]\u001b[0m Trial 1241 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:31,115]\u001b[0m Trial 1243 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:33,226]\u001b[0m Trial 1240 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:37,460]\u001b[0m Trial 1244 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:41,710]\u001b[0m Trial 1246 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:41,765]\u001b[0m Trial 1231 finished with value: 41.844785256128844 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006368785287556906, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040322789111754076, 'dropout_rate_Layer_2': 0.33669690882006775, 'dropout_rate_Layer_3': 0.18998150466351196, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.088229158499422e-05, 'l1_Layer_2': 2.5469895493263004e-05, 'l1_Layer_3': 2.423418829417167e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 245, 'n_units_Layer_3': 150}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.84 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.90 | sMAPE for Test Set is: 26.56% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:30:47,965]\u001b[0m Trial 1247 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:50,553]\u001b[0m Trial 1248 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:56,713]\u001b[0m Trial 1249 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:30:57,964]\u001b[0m Trial 1245 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:03,573]\u001b[0m Trial 1242 finished with value: 41.313232812442756 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017024851059486248, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04476169918520381, 'dropout_rate_Layer_2': 0.2763743425337743, 'dropout_rate_Layer_3': 0.006234024130871603, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.3916732922247378e-05, 'l1_Layer_2': 0.001245359340885048, 'l1_Layer_3': 0.0007779217216529466, 'n_units_Layer_1': 205, 'n_units_Layer_2': 185, 'n_units_Layer_3': 70}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.31 | sMAPE for Validation Set is: 25.03% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.10 | sMAPE for Test Set is: 25.81% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:31:06,895]\u001b[0m Trial 1252 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:13,741]\u001b[0m Trial 1253 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:17,695]\u001b[0m Trial 1250 finished with value: 42.32345989046871 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010858679584243112, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03279880360148591, 'dropout_rate_Layer_2': 0.14292692242056104, 'dropout_rate_Layer_3': 0.21019677341988638, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014983685027159346, 'l1_Layer_2': 9.25697170879621e-05, 'l1_Layer_3': 0.0006761466244084937, 'n_units_Layer_1': 175, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.32 | sMAPE for Validation Set is: 25.93% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.85 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:31:25,424]\u001b[0m Trial 1251 finished with value: 40.9272854854607 and parameters: {'n_hidden': 3, 'learning_rate': 0.001769032353647655, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.045821599690837475, 'dropout_rate_Layer_2': 0.2561247677159004, 'dropout_rate_Layer_3': 0.007122468838584264, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.4576603026045825e-05, 'l1_Layer_2': 0.0013198991096957347, 'l1_Layer_3': 0.0013736705393960187, 'n_units_Layer_1': 220, 'n_units_Layer_2': 190, 'n_units_Layer_3': 50}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 40.93 | sMAPE for Validation Set is: 25.03% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.45 | sMAPE for Test Set is: 25.91% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:31:35,106]\u001b[0m Trial 1257 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:39,181]\u001b[0m Trial 1255 finished with value: 41.54425210239528 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010775757957457034, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.001967953293109341, 'dropout_rate_Layer_2': 0.1451189595205476, 'dropout_rate_Layer_3': 0.1523665375267182, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013671333477028406, 'l1_Layer_2': 9.170359738497821e-05, 'l1_Layer_3': 1.9564853982310026e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 275, 'n_units_Layer_3': 245}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.54 | sMAPE for Validation Set is: 25.81% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.52 | sMAPE for Test Set is: 26.87% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:31:40,077]\u001b[0m Trial 1256 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:45,970]\u001b[0m Trial 1259 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:47,934]\u001b[0m Trial 1260 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:49,571]\u001b[0m Trial 1254 finished with value: 41.88028889219465 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005845601091846055, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049350681379400727, 'dropout_rate_Layer_2': 0.336789230553528, 'dropout_rate_Layer_3': 0.17032221755583554, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.698053176732482e-05, 'l1_Layer_2': 3.487905177001936e-05, 'l1_Layer_3': 1.3946643761942134e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 250, 'n_units_Layer_3': 150}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.88 | sMAPE for Validation Set is: 26.15% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.09 | sMAPE for Test Set is: 26.64% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:31:55,219]\u001b[0m Trial 1263 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:31:56,275]\u001b[0m Trial 1261 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:32:21,825]\u001b[0m Trial 1258 finished with value: 42.14423868901958 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006491578434392446, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.030406133877673935, 'dropout_rate_Layer_2': 0.3380834731460763, 'dropout_rate_Layer_3': 0.2084496992450182, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.858583593943559e-05, 'l1_Layer_2': 3.737768886428694e-05, 'l1_Layer_3': 2.0182979207932127e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 250, 'n_units_Layer_3': 155}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.14 | sMAPE for Validation Set is: 26.43% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.93 | sMAPE for Test Set is: 26.49% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:32:30,312]\u001b[0m Trial 1266 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.06 | sMAPE for Validation Set is: 26.02% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.96 | sMAPE for Test Set is: 26.43% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:32:32,260]\u001b[0m Trial 1262 finished with value: 42.05611230582114 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007110139096205054, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07720504134546495, 'dropout_rate_Layer_2': 0.3408832549096371, 'dropout_rate_Layer_3': 0.21425031181448526, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 8.325546110783451e-05, 'l1_Layer_2': 3.35963636679985e-05, 'l1_Layer_3': 1.2025274036307409e-05, 'n_units_Layer_1': 240, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:32:36,611]\u001b[0m Trial 1267 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:32:41,731]\u001b[0m Trial 1269 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:32:48,010]\u001b[0m Trial 1265 finished with value: 42.46810800196065 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005914719248788829, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04028512773322098, 'dropout_rate_Layer_2': 0.3300400380616287, 'dropout_rate_Layer_3': 0.1955441629785429, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 2.2593413409017582e-05, 'l1_Layer_2': 3.48034031317602e-05, 'l1_Layer_3': 1.1825785098237953e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.47 | sMAPE for Validation Set is: 26.63% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 27.10% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:32:51,878]\u001b[0m Trial 1270 pruned. Trial was pruned at epoch 9.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.25 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.05 | sMAPE for Test Set is: 26.62% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:32:53,748]\u001b[0m Trial 1264 finished with value: 43.247746016478764 and parameters: {'n_hidden': 3, 'learning_rate': 0.0005682232910873532, 'batch_size': 7, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.040524852752916445, 'dropout_rate_Layer_2': 0.34349013904322834, 'dropout_rate_Layer_3': 0.187461977764666, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011394113791818981, 'l1_Layer_2': 1.7459127190839373e-05, 'l1_Layer_3': 1.1994004918790265e-05, 'n_units_Layer_1': 230, 'n_units_Layer_2': 245, 'n_units_Layer_3': 160}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:32:58,477]\u001b[0m Trial 1273 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:32:59,658]\u001b[0m Trial 1271 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:03,926]\u001b[0m Trial 1268 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:07,997]\u001b[0m Trial 1276 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:23,743]\u001b[0m Trial 1274 finished with value: 42.12924048114477 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009531620892845507, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.008194018140683705, 'dropout_rate_Layer_2': 0.16249870853535597, 'dropout_rate_Layer_3': 0.15159831776162064, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012476802477316196, 'l1_Layer_2': 0.00011642094867593883, 'l1_Layer_3': 8.488257197189406e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 270, 'n_units_Layer_3': 245}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.13 | sMAPE for Validation Set is: 25.66% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.03 | sMAPE for Test Set is: 26.99% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:33:24,167]\u001b[0m Trial 1277 finished with value: 44.92044435961716 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010511400867498045, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.011668726794133963, 'dropout_rate_Layer_2': 0.153104491405262, 'dropout_rate_Layer_3': 0.16530765803317735, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00014873542361858768, 'l1_Layer_2': 0.0020490259282556936, 'l1_Layer_3': 4.580514213878515e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 270, 'n_units_Layer_3': 240}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.92 | sMAPE for Validation Set is: 26.49% | rMAE for Validation Set is: 0.52\n",
      "MAE for Test Set is: 19.75 | sMAPE for Test Set is: 28.30% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:33:24,813]\u001b[0m Trial 1272 finished with value: 42.577961750909395 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009539331741961574, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0007704012372207174, 'dropout_rate_Layer_2': 0.1606359374234184, 'dropout_rate_Layer_3': 0.15383233414130082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00013401123235456526, 'l1_Layer_2': 0.002117543593871499, 'l1_Layer_3': 1.6760515189592487e-05, 'n_units_Layer_1': 165, 'n_units_Layer_2': 265, 'n_units_Layer_3': 250}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.58 | sMAPE for Validation Set is: 25.70% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.35 | sMAPE for Test Set is: 26.15% | rMAE for Test Set is: 0.54\n",
      "MAE for Validation Set is: 41.91 | sMAPE for Validation Set is: 25.41% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.55 | sMAPE for Test Set is: 26.08% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:33:31,375]\u001b[0m Trial 1275 finished with value: 41.907389590863964 and parameters: {'n_hidden': 3, 'learning_rate': 0.0017410726233813064, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03710676408695927, 'dropout_rate_Layer_2': 0.2802100603304297, 'dropout_rate_Layer_3': 0.011510431885331508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.8828077625123465e-05, 'l1_Layer_2': 0.0011431569152119203, 'l1_Layer_3': 0.0014379093101998528, 'n_units_Layer_1': 200, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:32,004]\u001b[0m Trial 1278 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:33,267]\u001b[0m Trial 1279 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:40,927]\u001b[0m Trial 1282 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:46,733]\u001b[0m Trial 1284 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:47,029]\u001b[0m Trial 1281 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:52,912]\u001b[0m Trial 1285 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:33:58,165]\u001b[0m Trial 1287 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:01,483]\u001b[0m Trial 1283 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:07,353]\u001b[0m Trial 1289 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:11,628]\u001b[0m Trial 1290 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:14,453]\u001b[0m Trial 1280 finished with value: 41.91337562244559 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006400065054415991, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0511461718508508, 'dropout_rate_Layer_2': 0.33038297290355095, 'dropout_rate_Layer_3': 0.20054057479191445, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.912225190646481e-05, 'l1_Layer_2': 3.111210543350341e-05, 'l1_Layer_3': 1.887039674329693e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 240, 'n_units_Layer_3': 155}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.91 | sMAPE for Validation Set is: 26.18% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.63 | sMAPE for Test Set is: 26.20% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:34:14,729]\u001b[0m Trial 1286 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:32,491]\u001b[0m Trial 1288 finished with value: 42.58422412941603 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006854336359266159, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.049798137079476765, 'dropout_rate_Layer_2': 0.3990324465465003, 'dropout_rate_Layer_3': 0.20384864807760958, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012149923047729056, 'l1_Layer_2': 4.0928163445174284e-05, 'l1_Layer_3': 2.143301230802198e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 255, 'n_units_Layer_3': 160}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.58 | sMAPE for Validation Set is: 26.26% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.46 | sMAPE for Test Set is: 26.73% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:34:40,350]\u001b[0m Trial 1294 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:44,352]\u001b[0m Trial 1292 finished with value: 42.32023734420804 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008411283151484577, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.013793932381372493, 'dropout_rate_Layer_2': 0.16204302193790118, 'dropout_rate_Layer_3': 0.17514310525406743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002704326956585276, 'l1_Layer_2': 0.0002073977186493942, 'l1_Layer_3': 2.949821776321651e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 235}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.32 | sMAPE for Validation Set is: 25.94% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.54 | sMAPE for Test Set is: 27.40% | rMAE for Test Set is: 0.54\n",
      "MAE for Validation Set is: 42.91 | sMAPE for Validation Set is: 25.79% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.13 | sMAPE for Test Set is: 27.59% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:34:44,476]\u001b[0m Trial 1293 finished with value: 42.90697911664815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009646210565122704, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.17054660252511972, 'dropout_rate_Layer_2': 0.062355170621577825, 'dropout_rate_Layer_3': 0.15859516869396129, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 9.315407553709974e-05, 'l1_Layer_2': 1.0056982692529446e-05, 'l1_Layer_3': 3.041564778117734e-05, 'n_units_Layer_1': 285, 'n_units_Layer_2': 155, 'n_units_Layer_3': 255}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:45,000]\u001b[0m Trial 1291 finished with value: 43.435814468172374 and parameters: {'n_hidden': 3, 'learning_rate': 0.0010814370294124442, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': True, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.015680985444352813, 'dropout_rate_Layer_2': 0.1627981993795732, 'dropout_rate_Layer_3': 0.14397139667291403, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002684408956194702, 'l1_Layer_2': 0.0001411894276268723, 'l1_Layer_3': 1.2582628874555918e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 260, 'n_units_Layer_3': 240}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.44 | sMAPE for Validation Set is: 25.83% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 18.16 | sMAPE for Test Set is: 25.85% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:34:50,943]\u001b[0m Trial 1297 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:51,279]\u001b[0m Trial 1296 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:59,076]\u001b[0m Trial 1299 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:34:59,233]\u001b[0m Trial 1300 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:07,185]\u001b[0m Trial 1302 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:11,242]\u001b[0m Trial 1301 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:12,003]\u001b[0m Trial 1303 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:17,049]\u001b[0m Trial 1298 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:17,512]\u001b[0m Trial 1305 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:29,021]\u001b[0m Trial 1295 finished with value: 42.00422298094109 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007052184848235929, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.027921348895922047, 'dropout_rate_Layer_2': 0.3325202144952333, 'dropout_rate_Layer_3': 0.17034342412356107, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 9.292786970116974e-05, 'l1_Layer_2': 3.790930165870518e-05, 'l1_Layer_3': 1.345334447875167e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 270, 'n_units_Layer_3': 165}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.00 | sMAPE for Validation Set is: 26.30% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.63 | sMAPE for Test Set is: 26.65% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:35:36,523]\u001b[0m Trial 1304 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:39,869]\u001b[0m Trial 1308 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:43,509]\u001b[0m Trial 1306 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:44,295]\u001b[0m Trial 1307 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:46,133]\u001b[0m Trial 1309 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:49,943]\u001b[0m Trial 1310 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:52,680]\u001b[0m Trial 1313 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:53,724]\u001b[0m Trial 1311 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:54,199]\u001b[0m Trial 1314 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:35:59,451]\u001b[0m Trial 1315 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:04,906]\u001b[0m Trial 1318 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:05,269]\u001b[0m Trial 1317 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:09,950]\u001b[0m Trial 1316 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:12,689]\u001b[0m Trial 1320 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:15,207]\u001b[0m Trial 1312 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:15,507]\u001b[0m Trial 1321 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:20,038]\u001b[0m Trial 1322 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:22,232]\u001b[0m Trial 1323 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:22,432]\u001b[0m Trial 1324 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:24,888]\u001b[0m Trial 1325 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:31,898]\u001b[0m Trial 1326 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:32,218]\u001b[0m Trial 1328 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:33,181]\u001b[0m Trial 1319 finished with value: 44.1860329626651 and parameters: {'n_hidden': 3, 'learning_rate': 0.0012135487077854187, 'batch_size': 77, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.1321162153698926, 'dropout_rate_Layer_2': 0.10683155711563883, 'dropout_rate_Layer_3': 0.09286435397469452, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'relu', 'l1_Layer_1': 3.8789497083797e-05, 'l1_Layer_2': 0.00014385878171948097, 'l1_Layer_3': 0.0002684945235471001, 'n_units_Layer_1': 170, 'n_units_Layer_2': 150, 'n_units_Layer_3': 75}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.19 | sMAPE for Validation Set is: 26.14% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.61 | sMAPE for Test Set is: 27.16% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:36:39,483]\u001b[0m Trial 1329 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:42,942]\u001b[0m Trial 1331 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:51,784]\u001b[0m Trial 1327 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:36:59,777]\u001b[0m Trial 1330 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:00,470]\u001b[0m Trial 1332 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:04,940]\u001b[0m Trial 1335 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:05,702]\u001b[0m Trial 1333 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:08,056]\u001b[0m Trial 1336 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:15,679]\u001b[0m Trial 1334 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:15,827]\u001b[0m Trial 1337 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:22,208]\u001b[0m Trial 1341 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:22,844]\u001b[0m Trial 1340 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:30,730]\u001b[0m Trial 1343 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:37,071]\u001b[0m Trial 1338 finished with value: 42.250766560508715 and parameters: {'n_hidden': 3, 'learning_rate': 0.0009839346396530741, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02522787360406011, 'dropout_rate_Layer_2': 0.13252436208980176, 'dropout_rate_Layer_3': 0.14033022111558877, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002080569238479232, 'l1_Layer_2': 8.857823435920132e-05, 'l1_Layer_3': 0.0005507948838786718, 'n_units_Layer_1': 185, 'n_units_Layer_2': 245, 'n_units_Layer_3': 235}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.25 | sMAPE for Validation Set is: 26.06% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.18 | sMAPE for Test Set is: 27.78% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:37:43,055]\u001b[0m Trial 1339 finished with value: 41.56305751188604 and parameters: {'n_hidden': 3, 'learning_rate': 0.002789896619450363, 'batch_size': 56, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.022613540282542657, 'dropout_rate_Layer_2': 0.2558848330353151, 'dropout_rate_Layer_3': 0.04536664560318632, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1994105357810756e-05, 'l1_Layer_2': 0.0012604966386462976, 'l1_Layer_3': 0.0007884131020389136, 'n_units_Layer_1': 215, 'n_units_Layer_2': 190, 'n_units_Layer_3': 60}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.56 | sMAPE for Validation Set is: 25.41% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 26.48% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:37:48,542]\u001b[0m Trial 1346 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:48,935]\u001b[0m Trial 1342 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:55,023]\u001b[0m Trial 1347 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:37:55,409]\u001b[0m Trial 1348 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:01,748]\u001b[0m Trial 1345 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:03,699]\u001b[0m Trial 1350 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:07,507]\u001b[0m Trial 1351 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:12,924]\u001b[0m Trial 1344 finished with value: 41.45700020079284 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006755078220533037, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07734602830005238, 'dropout_rate_Layer_2': 0.3436105921331883, 'dropout_rate_Layer_3': 0.17243184055688757, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 6.679309497426631e-05, 'l1_Layer_2': 2.1211341807564583e-05, 'l1_Layer_3': 2.3645593657690892e-05, 'n_units_Layer_1': 245, 'n_units_Layer_2': 245, 'n_units_Layer_3': 165}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.46 | sMAPE for Validation Set is: 26.18% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.59 | sMAPE for Test Set is: 27.17% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:38:13,709]\u001b[0m Trial 1352 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:22,323]\u001b[0m Trial 1354 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:25,689]\u001b[0m Trial 1356 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:26,948]\u001b[0m Trial 1349 finished with value: 42.208646879727276 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008321677790123246, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02436045836167904, 'dropout_rate_Layer_2': 0.14538579386664124, 'dropout_rate_Layer_3': 0.13667259447890082, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00022220271442706298, 'l1_Layer_2': 7.128537703762377e-05, 'l1_Layer_3': 2.2370563831255323e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 245, 'n_units_Layer_3': 255}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.21 | sMAPE for Validation Set is: 25.92% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.07 | sMAPE for Test Set is: 27.80% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:38:32,318]\u001b[0m Trial 1357 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:32,730]\u001b[0m Trial 1358 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:39,869]\u001b[0m Trial 1355 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:43,207]\u001b[0m Trial 1359 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:46,396]\u001b[0m Trial 1361 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:49,912]\u001b[0m Trial 1362 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:53,806]\u001b[0m Trial 1353 finished with value: 42.18791793570699 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007030023191807882, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04633644565148389, 'dropout_rate_Layer_2': 0.14635597491320188, 'dropout_rate_Layer_3': 0.1230329405290551, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001559601015390012, 'l1_Layer_2': 9.098994907432906e-05, 'l1_Layer_3': 0.00046514937464118823, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 245}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.19 | sMAPE for Validation Set is: 25.97% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.68 | sMAPE for Test Set is: 26.65% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:38:56,887]\u001b[0m Trial 1364 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:38:58,128]\u001b[0m Trial 1363 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:02,765]\u001b[0m Trial 1366 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:04,368]\u001b[0m Trial 1367 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:07,038]\u001b[0m Trial 1365 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:08,503]\u001b[0m Trial 1368 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:09,767]\u001b[0m Trial 1360 finished with value: 42.16011190697009 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007224331029051557, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.039984673820804256, 'dropout_rate_Layer_2': 0.14364669130387483, 'dropout_rate_Layer_3': 0.12326655359934814, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00028763717048532804, 'l1_Layer_2': 8.741640734377852e-05, 'l1_Layer_3': 1.7761887948563468e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 250, 'n_units_Layer_3': 235}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.16 | sMAPE for Validation Set is: 26.13% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.40 | sMAPE for Test Set is: 27.50% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:39:16,513]\u001b[0m Trial 1371 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:17,763]\u001b[0m Trial 1372 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:25,798]\u001b[0m Trial 1373 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:27,654]\u001b[0m Trial 1374 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:34,008]\u001b[0m Trial 1375 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:41,957]\u001b[0m Trial 1377 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:47,222]\u001b[0m Trial 1369 finished with value: 41.354840711436786 and parameters: {'n_hidden': 3, 'learning_rate': 0.0018551238068330025, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042656196327692415, 'dropout_rate_Layer_2': 0.2532331997916681, 'dropout_rate_Layer_3': 0.023660575361818453, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.1781894971980873e-05, 'l1_Layer_2': 0.0009008154224727794, 'l1_Layer_3': 0.0015416754219805507, 'n_units_Layer_1': 225, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.35 | sMAPE for Validation Set is: 25.30% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.89 | sMAPE for Test Set is: 26.13% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:39:51,191]\u001b[0m Trial 1376 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:52,940]\u001b[0m Trial 1378 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:54,249]\u001b[0m Trial 1379 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:39:59,197]\u001b[0m Trial 1380 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:02,326]\u001b[0m Trial 1370 finished with value: 42.443682620271595 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008349939638959214, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04868033097576016, 'dropout_rate_Layer_2': 0.3589591531298755, 'dropout_rate_Layer_3': 0.18993926712553522, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00012256108035688768, 'l1_Layer_2': 3.1663409657201226e-05, 'l1_Layer_3': 1.9094140328066374e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 265, 'n_units_Layer_3': 165}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.44 | sMAPE for Validation Set is: 26.42% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.00 | sMAPE for Test Set is: 27.08% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:40:03,006]\u001b[0m Trial 1382 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:07,200]\u001b[0m Trial 1381 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:07,448]\u001b[0m Trial 1383 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:09,652]\u001b[0m Trial 1385 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:16,254]\u001b[0m Trial 1387 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:16,852]\u001b[0m Trial 1384 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:21,137]\u001b[0m Trial 1386 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:22,262]\u001b[0m Trial 1389 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:27,135]\u001b[0m Trial 1392 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:30,946]\u001b[0m Trial 1390 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:34,362]\u001b[0m Trial 1391 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:38,841]\u001b[0m Trial 1395 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:44,401]\u001b[0m Trial 1396 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:45,637]\u001b[0m Trial 1394 pruned. Trial was pruned at epoch 27.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.09 | sMAPE for Validation Set is: 25.22% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.59 | sMAPE for Test Set is: 26.00% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:40:46,761]\u001b[0m Trial 1388 finished with value: 42.08711133258982 and parameters: {'n_hidden': 3, 'learning_rate': 0.002867806184725469, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04374354128464773, 'dropout_rate_Layer_2': 0.24631011810089504, 'dropout_rate_Layer_3': 0.024134987396286157, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0999931295824126e-05, 'l1_Layer_2': 0.0012234049943208479, 'l1_Layer_3': 0.00212486234004703, 'n_units_Layer_1': 210, 'n_units_Layer_2': 210, 'n_units_Layer_3': 85}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:52,953]\u001b[0m Trial 1398 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:53,227]\u001b[0m Trial 1393 finished with value: 43.36703313253806 and parameters: {'n_hidden': 3, 'learning_rate': 0.00285608584983471, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06203862358634102, 'dropout_rate_Layer_2': 0.22226464550285763, 'dropout_rate_Layer_3': 0.035061254629552466, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0680466593063596e-05, 'l1_Layer_2': 0.0009417180176520098, 'l1_Layer_3': 0.001505802576833938, 'n_units_Layer_1': 230, 'n_units_Layer_2': 200, 'n_units_Layer_3': 70}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:40:53,302]\u001b[0m Trial 1399 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.37 | sMAPE for Validation Set is: 25.88% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 19.19 | sMAPE for Test Set is: 26.57% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:41:06,617]\u001b[0m Trial 1401 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:06,833]\u001b[0m Trial 1402 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:14,282]\u001b[0m Trial 1403 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:17,128]\u001b[0m Trial 1404 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:19,670]\u001b[0m Trial 1397 finished with value: 41.78016909786373 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007378452569686734, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.050316254788602126, 'dropout_rate_Layer_2': 0.12905143965805246, 'dropout_rate_Layer_3': 0.11527112976248917, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015823460026063315, 'l1_Layer_2': 9.659601198959651e-05, 'l1_Layer_3': 4.297343243076576e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 265, 'n_units_Layer_3': 235}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.78 | sMAPE for Validation Set is: 25.95% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.90 | sMAPE for Test Set is: 27.30% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:41:22,075]\u001b[0m Trial 1406 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:25,225]\u001b[0m Trial 1400 finished with value: 42.06594379923384 and parameters: {'n_hidden': 3, 'learning_rate': 0.0011128456919978016, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3319239218876467, 'dropout_rate_Layer_2': 0.15564094892069394, 'dropout_rate_Layer_3': 0.1843471047099741, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.0617137754674657e-05, 'l1_Layer_2': 0.0001776845646559634, 'l1_Layer_3': 0.000715706820851735, 'n_units_Layer_1': 300, 'n_units_Layer_2': 170, 'n_units_Layer_3': 265}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.07 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.09 | sMAPE for Test Set is: 27.35% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:41:28,402]\u001b[0m Trial 1405 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:29,388]\u001b[0m Trial 1408 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:35,144]\u001b[0m Trial 1410 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:38,147]\u001b[0m Trial 1411 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:38,224]\u001b[0m Trial 1409 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:45,884]\u001b[0m Trial 1414 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:41:56,058]\u001b[0m Trial 1407 finished with value: 41.98644640511785 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006956922074442143, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03270842412935638, 'dropout_rate_Layer_2': 0.11594897487302733, 'dropout_rate_Layer_3': 0.10998722332916626, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00015875962998668618, 'l1_Layer_2': 0.0006621106483903912, 'l1_Layer_3': 0.0010327076466699954, 'n_units_Layer_1': 185, 'n_units_Layer_2': 270, 'n_units_Layer_3': 230}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.99 | sMAPE for Validation Set is: 25.48% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.60 | sMAPE for Test Set is: 26.91% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:42:02,232]\u001b[0m Trial 1413 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:05,314]\u001b[0m Trial 1412 finished with value: 41.1625676525568 and parameters: {'n_hidden': 3, 'learning_rate': 0.000728280621558306, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0319986600808164, 'dropout_rate_Layer_2': 0.11244013482993018, 'dropout_rate_Layer_3': 0.09488806667496508, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0002010684782386826, 'l1_Layer_2': 9.342361347608791e-05, 'l1_Layer_3': 1.8858368203294427e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 290, 'n_units_Layer_3': 235}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.16 | sMAPE for Validation Set is: 25.59% | rMAE for Validation Set is: 0.47\n",
      "MAE for Test Set is: 18.36 | sMAPE for Test Set is: 26.68% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:42:09,470]\u001b[0m Trial 1418 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:09,681]\u001b[0m Trial 1417 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:16,683]\u001b[0m Trial 1419 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:17,222]\u001b[0m Trial 1420 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:24,718]\u001b[0m Trial 1415 finished with value: 42.226946885520086 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007127121026399895, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.24498158483400823, 'dropout_rate_Layer_2': 0.11374511770399966, 'dropout_rate_Layer_3': 0.10699672286823876, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00011879060490567807, 'l1_Layer_2': 9.261754020074548e-05, 'l1_Layer_3': 2.1551464962992432e-05, 'n_units_Layer_1': 190, 'n_units_Layer_2': 270, 'n_units_Layer_3': 235}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.23 | sMAPE for Validation Set is: 25.95% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.29 | sMAPE for Test Set is: 26.07% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:42:28,493]\u001b[0m Trial 1416 finished with value: 42.064955255459694 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006940092168085051, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.08200745946088446, 'dropout_rate_Layer_2': 0.35464676549306084, 'dropout_rate_Layer_3': 0.21251260642989106, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.029649773160654e-05, 'l1_Layer_2': 3.316689767548873e-05, 'l1_Layer_3': 1.1956211852343038e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 280, 'n_units_Layer_3': 140}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.06 | sMAPE for Validation Set is: 25.96% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.94 | sMAPE for Test Set is: 26.72% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:42:46,365]\u001b[0m Trial 1421 finished with value: 41.60574554022297 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008763295367458667, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.034284127507927725, 'dropout_rate_Layer_2': 0.11286937854463486, 'dropout_rate_Layer_3': 0.09433199391303751, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019078746329219152, 'l1_Layer_2': 0.0006638544155158661, 'l1_Layer_3': 7.87955319408767e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 280, 'n_units_Layer_3': 215}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.61 | sMAPE for Validation Set is: 25.67% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.50 | sMAPE for Test Set is: 26.96% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:42:47,168]\u001b[0m Trial 1422 finished with value: 41.96034386973252 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008462009287754357, 'batch_size': 35, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.033338550267535245, 'dropout_rate_Layer_2': 0.10987247627607964, 'dropout_rate_Layer_3': 0.09554308810936517, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00019380444563949016, 'l1_Layer_2': 0.001125108832196965, 'l1_Layer_3': 6.344540569375553e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 295, 'n_units_Layer_3': 215}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.96 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.13 | sMAPE for Test Set is: 27.33% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:42:53,253]\u001b[0m Trial 1425 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:53,620]\u001b[0m Trial 1426 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:42:53,944]\u001b[0m Trial 1424 finished with value: 42.193031016877214 and parameters: {'n_hidden': 3, 'learning_rate': 0.0008610617859231783, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.0010430582292699983, 'dropout_rate_Layer_2': 0.10944664039907806, 'dropout_rate_Layer_3': 0.09954094287423881, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00020907828705653888, 'l1_Layer_2': 0.0007231257968501583, 'l1_Layer_3': 3.722516754192684e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 225}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.19 | sMAPE for Validation Set is: 25.69% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.75 | sMAPE for Test Set is: 26.62% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:43:02,736]\u001b[0m Trial 1429 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:05,075]\u001b[0m Trial 1423 finished with value: 41.422237338033995 and parameters: {'n_hidden': 3, 'learning_rate': 0.000772926819756532, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05273594925486514, 'dropout_rate_Layer_2': 0.3396754333515185, 'dropout_rate_Layer_3': 0.19150893403334712, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.705779110006356e-05, 'l1_Layer_2': 3.099109502025856e-05, 'l1_Layer_3': 1.675209655158991e-05, 'n_units_Layer_1': 220, 'n_units_Layer_2': 265, 'n_units_Layer_3': 135}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.42 | sMAPE for Validation Set is: 26.05% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.82 | sMAPE for Test Set is: 27.92% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:43:07,558]\u001b[0m Trial 1427 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:17,432]\u001b[0m Trial 1432 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:24,465]\u001b[0m Trial 1428 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:28,808]\u001b[0m Trial 1430 finished with value: 42.33688656164385 and parameters: {'n_hidden': 3, 'learning_rate': 0.0020796814567619845, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': True, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.03219700694633987, 'dropout_rate_Layer_2': 0.27378516158327093, 'dropout_rate_Layer_3': 0.029448546104180375, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.475347536097845e-05, 'l1_Layer_2': 0.0010305331461982266, 'l1_Layer_3': 0.0011306970782689275, 'n_units_Layer_1': 220, 'n_units_Layer_2': 185, 'n_units_Layer_3': 60}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.34 | sMAPE for Validation Set is: 25.43% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.85 | sMAPE for Test Set is: 26.44% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:43:35,206]\u001b[0m Trial 1434 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:39,285]\u001b[0m Trial 1435 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:39,978]\u001b[0m Trial 1431 finished with value: 42.02272632778287 and parameters: {'n_hidden': 3, 'learning_rate': 0.000772628576608058, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.031381414270265494, 'dropout_rate_Layer_2': 0.11678937427016153, 'dropout_rate_Layer_3': 0.08266570134310869, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001861976364306091, 'l1_Layer_2': 0.001112098466177824, 'l1_Layer_3': 5.98703485882056e-05, 'n_units_Layer_1': 175, 'n_units_Layer_2': 295, 'n_units_Layer_3': 210}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.02 | sMAPE for Validation Set is: 25.84% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.39 | sMAPE for Test Set is: 27.56% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:43:40,612]\u001b[0m Trial 1436 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:49,677]\u001b[0m Trial 1438 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:51,860]\u001b[0m Trial 1437 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:54,475]\u001b[0m Trial 1439 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:43:59,692]\u001b[0m Trial 1433 finished with value: 42.41863682289363 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006820368495880198, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.07080625446665052, 'dropout_rate_Layer_2': 0.341880288824451, 'dropout_rate_Layer_3': 0.19001525578494657, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 4.115181856617935e-05, 'l1_Layer_2': 4.187710584687482e-05, 'l1_Layer_3': 1.1847195223276205e-05, 'n_units_Layer_1': 225, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.42 | sMAPE for Validation Set is: 26.31% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 20.50 | sMAPE for Test Set is: 27.86% | rMAE for Test Set is: 0.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:44:00,149]\u001b[0m Trial 1442 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:06,323]\u001b[0m Trial 1441 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:07,193]\u001b[0m Trial 1444 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:14,686]\u001b[0m Trial 1446 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:19,051]\u001b[0m Trial 1447 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:23,387]\u001b[0m Trial 1448 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:28,940]\u001b[0m Trial 1449 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:37,185]\u001b[0m Trial 1440 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:38,339]\u001b[0m Trial 1443 finished with value: 43.425646933209784 and parameters: {'n_hidden': 3, 'learning_rate': 0.000886776815632665, 'batch_size': 49, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3457783372143959, 'dropout_rate_Layer_2': 0.056029158986088776, 'dropout_rate_Layer_3': 0.19847054293222743, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 0.0002706281176283375, 'l1_Layer_2': 1.578919258720487e-05, 'l1_Layer_3': 0.00011031189775348938, 'n_units_Layer_1': 295, 'n_units_Layer_2': 195, 'n_units_Layer_3': 270}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.43 | sMAPE for Validation Set is: 25.86% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 17.95 | sMAPE for Test Set is: 25.22% | rMAE for Test Set is: 0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:44:48,186]\u001b[0m Trial 1452 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:50,531]\u001b[0m Trial 1445 finished with value: 41.716461093247254 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006046450251266494, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.06264143799573164, 'dropout_rate_Layer_2': 0.33099460175578227, 'dropout_rate_Layer_3': 0.20168374189778362, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 5.006072945817155e-05, 'l1_Layer_2': 2.7877042096196227e-05, 'l1_Layer_3': 1.6254125864457888e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 275, 'n_units_Layer_3': 165}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.72 | sMAPE for Validation Set is: 26.28% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.24 | sMAPE for Test Set is: 27.29% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:44:57,229]\u001b[0m Trial 1454 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:44:59,254]\u001b[0m Trial 1453 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:03,461]\u001b[0m Trial 1455 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:06,419]\u001b[0m Trial 1456 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:10,535]\u001b[0m Trial 1450 finished with value: 41.892594153929174 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007916229174832046, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.042418340226104384, 'dropout_rate_Layer_2': 0.09946818299919116, 'dropout_rate_Layer_3': 0.08154777098426438, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.000240310830298802, 'l1_Layer_2': 0.0006602151522780097, 'l1_Layer_3': 0.00012119054307535606, 'n_units_Layer_1': 175, 'n_units_Layer_2': 290, 'n_units_Layer_3': 215}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.89 | sMAPE for Validation Set is: 25.58% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.31 | sMAPE for Test Set is: 26.13% | rMAE for Test Set is: 0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:45:13,086]\u001b[0m Trial 1458 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:17,185]\u001b[0m Trial 1460 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:21,566]\u001b[0m Trial 1451 finished with value: 41.882351290894746 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007922618192763802, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05762206363465225, 'dropout_rate_Layer_2': 0.348577924631428, 'dropout_rate_Layer_3': 0.21678709102100027, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.302282707173533e-05, 'l1_Layer_2': 2.6046432690040408e-05, 'l1_Layer_3': 1.1086199284652447e-05, 'n_units_Layer_1': 235, 'n_units_Layer_2': 275, 'n_units_Layer_3': 140}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 41.88 | sMAPE for Validation Set is: 26.22% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.75 | sMAPE for Test Set is: 26.32% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:45:24,633]\u001b[0m Trial 1461 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:25,249]\u001b[0m Trial 1459 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:32,809]\u001b[0m Trial 1464 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:35,512]\u001b[0m Trial 1463 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:39,283]\u001b[0m Trial 1457 finished with value: 44.428647841390365 and parameters: {'n_hidden': 3, 'learning_rate': 0.0015886246502301255, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.3039117135615436, 'dropout_rate_Layer_2': 0.1851312556751298, 'dropout_rate_Layer_3': 0.1830992934049445, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.1679414365294108e-05, 'l1_Layer_2': 0.00020832633796013747, 'l1_Layer_3': 0.000557196391328595, 'n_units_Layer_1': 270, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 44.43 | sMAPE for Validation Set is: 26.48% | rMAE for Validation Set is: 0.51\n",
      "MAE for Test Set is: 19.67 | sMAPE for Test Set is: 27.79% | rMAE for Test Set is: 0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:45:39,782]\u001b[0m Trial 1465 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:42,704]\u001b[0m Trial 1466 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:46,461]\u001b[0m Trial 1467 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:45:49,021]\u001b[0m Trial 1462 finished with value: 42.50478919563766 and parameters: {'n_hidden': 3, 'learning_rate': 0.001569555530428916, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.28733959527843655, 'dropout_rate_Layer_2': 0.1907891472719031, 'dropout_rate_Layer_3': 0.08224780620983982, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 2.103032683254104e-05, 'l1_Layer_2': 0.0002883339371666616, 'l1_Layer_3': 0.0005262099404217055, 'n_units_Layer_1': 260, 'n_units_Layer_2': 150, 'n_units_Layer_3': 255}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.50 | sMAPE for Validation Set is: 25.90% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.31 | sMAPE for Test Set is: 27.76% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:45:49,531]\u001b[0m Trial 1469 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:08,450]\u001b[0m Trial 1470 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:12,611]\u001b[0m Trial 1472 finished with value: 42.337792447609495 and parameters: {'n_hidden': 3, 'learning_rate': 0.0030402693403735605, 'batch_size': 42, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': False, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 1.541789023843873e-05, 'dropout_rate_Layer_2': 0.2575388062035963, 'dropout_rate_Layer_3': 0.01767677415018651, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.62571106639693e-05, 'l1_Layer_2': 1.751877702833256e-05, 'l1_Layer_3': 0.0035109169483568963, 'n_units_Layer_1': 225, 'n_units_Layer_2': 180, 'n_units_Layer_3': 220}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.34 | sMAPE for Validation Set is: 25.62% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 19.96 | sMAPE for Test Set is: 27.95% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:46:13,800]\u001b[0m Trial 1473 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:16,472]\u001b[0m Trial 1471 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:18,177]\u001b[0m Trial 1468 finished with value: 42.12502069238226 and parameters: {'n_hidden': 3, 'learning_rate': 0.000759510013170836, 'batch_size': 28, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.02999337298160623, 'dropout_rate_Layer_2': 0.10120163880796572, 'dropout_rate_Layer_3': 0.08970738774924922, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.00021241976446650484, 'l1_Layer_2': 0.0005666345114998971, 'l1_Layer_3': 3.709197781063004e-05, 'n_units_Layer_1': 170, 'n_units_Layer_2': 300, 'n_units_Layer_3': 210}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.13 | sMAPE for Validation Set is: 25.97% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.09 | sMAPE for Test Set is: 27.60% | rMAE for Test Set is: 0.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:46:18,650]\u001b[0m Trial 1474 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:26,482]\u001b[0m Trial 1477 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:30,892]\u001b[0m Trial 1478 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:35,940]\u001b[0m Trial 1480 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:41,423]\u001b[0m Trial 1481 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:46,169]\u001b[0m Trial 1482 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:51,926]\u001b[0m Trial 1483 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:55,062]\u001b[0m Trial 1484 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:46:58,794]\u001b[0m Trial 1475 finished with value: 42.09097459132716 and parameters: {'n_hidden': 3, 'learning_rate': 0.000778170702186375, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.05459162075949903, 'dropout_rate_Layer_2': 0.3585640294445163, 'dropout_rate_Layer_3': 0.20445881420341416, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.0371736607948656e-05, 'l1_Layer_2': 2.60496167176685e-05, 'l1_Layer_3': 1.3511979291047842e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 260, 'n_units_Layer_3': 135}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.09 | sMAPE for Validation Set is: 26.75% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 19.86 | sMAPE for Test Set is: 28.06% | rMAE for Test Set is: 0.58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:46:59,048]\u001b[0m Trial 1485 pruned. Trial was pruned at epoch 1.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.16 | sMAPE for Validation Set is: 25.54% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 18.67 | sMAPE for Test Set is: 26.27% | rMAE for Test Set is: 0.55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:47:03,148]\u001b[0m Trial 1479 finished with value: 42.15995567976974 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006798140194526801, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018542750637035324, 'dropout_rate_Layer_2': 0.1227823608047385, 'dropout_rate_Layer_3': 0.07288720103808091, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001388807879589431, 'l1_Layer_2': 0.0006765512473782799, 'l1_Layer_3': 4.2909337371057305e-05, 'n_units_Layer_1': 180, 'n_units_Layer_2': 290, 'n_units_Layer_3': 200}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:05,076]\u001b[0m Trial 1476 finished with value: 42.10901567921943 and parameters: {'n_hidden': 3, 'learning_rate': 0.0007763398356719959, 'batch_size': 14, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': False, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': False, 'use_Won_DA': False, 'use_hour': True, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.04199771399048096, 'dropout_rate_Layer_2': 0.35803907216792485, 'dropout_rate_Layer_3': 0.20431116407722036, 'activation_Layer_1': 'relu', 'activation_Layer_2': 'linear', 'activation_Layer_3': 'linear', 'l1_Layer_1': 3.245755916311701e-05, 'l1_Layer_2': 2.793459403172379e-05, 'l1_Layer_3': 1.377367774669252e-05, 'n_units_Layer_1': 250, 'n_units_Layer_2': 270, 'n_units_Layer_3': 135}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.11 | sMAPE for Validation Set is: 26.80% | rMAE for Validation Set is: 0.48\n",
      "MAE for Test Set is: 20.25 | sMAPE for Test Set is: 27.67% | rMAE for Test Set is: 0.59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:47:14,083]\u001b[0m Trial 1488 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:21,441]\u001b[0m Trial 1486 pruned. Trial was pruned at epoch 81.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:24,693]\u001b[0m Trial 1489 finished with value: 43.20829510831654 and parameters: {'n_hidden': 3, 'learning_rate': 0.0013901832635272347, 'batch_size': 84, 'batch_normalization': False, 'use_hist_2': True, 'use_hist_3': True, 'use_Load_AC': True, 'use_Gen_SC': True, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': False, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.2806316798008292, 'dropout_rate_Layer_2': 0.022298943611381634, 'dropout_rate_Layer_3': 0.09809605639084074, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'relu', 'l1_Layer_1': 1.2921523790733506e-05, 'l1_Layer_2': 0.000289142779855991, 'l1_Layer_3': 1.608338907018172e-05, 'n_units_Layer_1': 255, 'n_units_Layer_2': 175, 'n_units_Layer_3': 265}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 43.21 | sMAPE for Validation Set is: 26.46% | rMAE for Validation Set is: 0.50\n",
      "MAE for Test Set is: 20.89 | sMAPE for Test Set is: 28.66% | rMAE for Test Set is: 0.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:47:29,017]\u001b[0m Trial 1492 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:32,537]\u001b[0m Trial 1491 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:35,063]\u001b[0m Trial 1493 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:38,866]\u001b[0m Trial 1494 pruned. Trial was pruned at epoch 9.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:43,716]\u001b[0m Trial 1496 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:44,053]\u001b[0m Trial 1495 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:50,890]\u001b[0m Trial 1487 finished with value: 42.869096726916815 and parameters: {'n_hidden': 3, 'learning_rate': 0.0006741439122256533, 'batch_size': 21, 'batch_normalization': False, 'use_hist_2': False, 'use_hist_3': True, 'use_Load_AC': False, 'use_Gen_SC': False, 'use_Sol_DA': True, 'use_Won_DA': True, 'use_hour': False, 'use_dow': False, 'use_woy': True, 'use_isweekend': False, 'dropout_rate_Layer_1': 0.018554889467390756, 'dropout_rate_Layer_2': 0.1095135831355068, 'dropout_rate_Layer_3': 0.09624149626761812, 'activation_Layer_1': 'linear', 'activation_Layer_2': 'relu', 'activation_Layer_3': 'linear', 'l1_Layer_1': 0.0001363866213311825, 'l1_Layer_2': 0.0006690920919954524, 'l1_Layer_3': 0.0012275456273790222, 'n_units_Layer_1': 180, 'n_units_Layer_2': 285, 'n_units_Layer_3': 200}. Best is trial 1201 with value: 40.714846398516535.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Validation Set is: 42.87 | sMAPE for Validation Set is: 26.11% | rMAE for Validation Set is: 0.49\n",
      "MAE for Test Set is: 18.62 | sMAPE for Test Set is: 27.47% | rMAE for Test Set is: 0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-08-03 10:47:51,228]\u001b[0m Trial 1498 pruned. Trial was pruned at epoch 3.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:54,485]\u001b[0m Trial 1499 pruned. Trial was pruned at epoch 1.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:47:54,941]\u001b[0m Trial 1497 pruned. Trial was pruned at epoch 27.\u001b[0m\n",
      "\u001b[32m[I 2023-08-03 10:48:03,311]\u001b[0m Trial 1490 pruned. Trial was pruned at epoch 81.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-01-01, MAE is:9.66 & sMAPE is:119.50% & rMAE is:0.11 ||| daily mean of MAE & sMAPE & rMAE till now are :9.66 & 119.50% & 0.11\n",
      "for 2023-01-02, MAE is:72.57 & sMAPE is:78.23% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :41.11 & 98.87% & 0.49\n",
      "for 2023-01-03, MAE is:20.68 & sMAPE is:16.30% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :34.30 & 71.34% & 0.45\n",
      "for 2023-01-04, MAE is:52.08 & sMAPE is:71.50% & rMAE is:2.78 ||| daily mean of MAE & sMAPE & rMAE till now are :38.75 & 71.38% & 1.03\n",
      "for 2023-01-05, MAE is:74.81 & sMAPE is:114.00% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :45.96 & 79.91% & 0.99\n",
      "for 2023-01-06, MAE is:11.95 & sMAPE is:9.95% & rMAE is:0.12 ||| daily mean of MAE & sMAPE & rMAE till now are :40.29 & 68.25% & 0.84\n",
      "for 2023-01-07, MAE is:14.82 & sMAPE is:17.07% & rMAE is:0.17 ||| daily mean of MAE & sMAPE & rMAE till now are :36.65 & 60.94% & 0.75\n",
      "for 2023-01-08, MAE is:29.31 & sMAPE is:62.93% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :35.74 & 61.19% & 0.72\n",
      "for 2023-01-09, MAE is:20.27 & sMAPE is:16.85% & rMAE is:2.11 ||| daily mean of MAE & sMAPE & rMAE till now are :34.02 & 56.26% & 0.87\n",
      "for 2023-01-10, MAE is:18.24 & sMAPE is:16.32% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :32.44 & 52.27% & 0.87\n",
      "for 2023-01-11, MAE is:28.66 & sMAPE is:60.32% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :32.10 & 53.00% & 0.85\n",
      "for 2023-01-12, MAE is:26.52 & sMAPE is:53.54% & rMAE is:0.58 ||| daily mean of MAE & sMAPE & rMAE till now are :31.63 & 53.04% & 0.83\n",
      "for 2023-01-13, MAE is:12.93 & sMAPE is:34.86% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :30.19 & 51.64% & 0.78\n",
      "for 2023-01-14, MAE is:40.57 & sMAPE is:84.77% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :30.93 & 54.01% & 0.78\n",
      "for 2023-01-15, MAE is:24.66 & sMAPE is:134.30% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :30.52 & 59.36% & 0.75\n",
      "for 2023-01-16, MAE is:45.79 & sMAPE is:55.51% & rMAE is:3.95 ||| daily mean of MAE & sMAPE & rMAE till now are :31.47 & 59.12% & 0.95\n",
      "for 2023-01-17, MAE is:18.03 & sMAPE is:13.46% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :30.68 & 56.44% & 0.94\n",
      "for 2023-01-18, MAE is:16.96 & sMAPE is:12.71% & rMAE is:0.28 ||| daily mean of MAE & sMAPE & rMAE till now are :29.92 & 54.01% & 0.90\n",
      "for 2023-01-19, MAE is:32.52 & sMAPE is:23.82% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :30.05 & 52.42% & 0.88\n",
      "for 2023-01-20, MAE is:43.90 & sMAPE is:27.33% & rMAE is:0.38 ||| daily mean of MAE & sMAPE & rMAE till now are :30.75 & 51.16% & 0.85\n",
      "for 2023-01-21, MAE is:18.82 & sMAPE is:13.72% & rMAE is:0.16 ||| daily mean of MAE & sMAPE & rMAE till now are :30.18 & 49.38% & 0.82\n",
      "for 2023-01-22, MAE is:35.61 & sMAPE is:26.35% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :30.43 & 48.33% & 0.79\n",
      "for 2023-01-23, MAE is:16.05 & sMAPE is:8.21% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :29.80 & 46.59% & 0.77\n",
      "for 2023-01-24, MAE is:15.27 & sMAPE is:8.21% & rMAE is:0.22 ||| daily mean of MAE & sMAPE & rMAE till now are :29.20 & 44.99% & 0.74\n",
      "for 2023-01-25, MAE is:14.86 & sMAPE is:8.85% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :28.62 & 43.54% & 0.73\n",
      "for 2023-01-26, MAE is:16.62 & sMAPE is:10.30% & rMAE is:0.60 ||| daily mean of MAE & sMAPE & rMAE till now are :28.16 & 42.27% & 0.73\n",
      "for 2023-01-27, MAE is:11.84 & sMAPE is:7.89% & rMAE is:0.96 ||| daily mean of MAE & sMAPE & rMAE till now are :27.56 & 40.99% & 0.73\n",
      "for 2023-01-28, MAE is:13.35 & sMAPE is:9.87% & rMAE is:1.71 ||| daily mean of MAE & sMAPE & rMAE till now are :27.05 & 39.88% & 0.77\n",
      "for 2023-01-29, MAE is:32.95 & sMAPE is:28.39% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :27.25 & 39.49% & 0.78\n",
      "for 2023-01-30, MAE is:63.16 & sMAPE is:71.65% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.45 & 40.56% & 0.77\n",
      "for 2023-01-31, MAE is:44.12 & sMAPE is:41.47% & rMAE is:0.52 ||| daily mean of MAE & sMAPE & rMAE till now are :28.95 & 40.59% & 0.76\n",
      "for 2023-02-01, MAE is:8.39 & sMAPE is:8.91% & rMAE is:0.09 ||| daily mean of MAE & sMAPE & rMAE till now are :28.31 & 39.60% & 0.74\n",
      "for 2023-02-02, MAE is:43.73 & sMAPE is:35.01% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :28.78 & 39.46% & 0.76\n",
      "for 2023-02-03, MAE is:16.86 & sMAPE is:14.47% & rMAE is:0.25 ||| daily mean of MAE & sMAPE & rMAE till now are :28.43 & 38.72% & 0.74\n",
      "for 2023-02-04, MAE is:53.89 & sMAPE is:44.55% & rMAE is:5.02 ||| daily mean of MAE & sMAPE & rMAE till now are :29.16 & 38.89% & 0.86\n",
      "for 2023-02-05, MAE is:14.71 & sMAPE is:11.43% & rMAE is:0.64 ||| daily mean of MAE & sMAPE & rMAE till now are :28.75 & 38.13% & 0.86\n",
      "for 2023-02-06, MAE is:13.75 & sMAPE is:7.99% & rMAE is:0.14 ||| daily mean of MAE & sMAPE & rMAE till now are :28.35 & 37.31% & 0.84\n",
      "for 2023-02-07, MAE is:20.82 & sMAPE is:11.64% & rMAE is:0.37 ||| daily mean of MAE & sMAPE & rMAE till now are :28.15 & 36.64% & 0.83\n",
      "for 2023-02-08, MAE is:28.79 & sMAPE is:18.22% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :28.17 & 36.16% & 0.82\n",
      "for 2023-02-09, MAE is:24.03 & sMAPE is:17.83% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :28.06 & 35.71% & 0.82\n",
      "for 2023-02-10, MAE is:24.05 & sMAPE is:20.27% & rMAE is:0.77 ||| daily mean of MAE & sMAPE & rMAE till now are :27.97 & 35.33% & 0.81\n",
      "for 2023-02-11, MAE is:24.76 & sMAPE is:24.56% & rMAE is:0.62 ||| daily mean of MAE & sMAPE & rMAE till now are :27.89 & 35.07% & 0.81\n",
      "for 2023-02-12, MAE is:14.08 & sMAPE is:10.88% & rMAE is:1.41 ||| daily mean of MAE & sMAPE & rMAE till now are :27.57 & 34.51% & 0.82\n",
      "for 2023-02-13, MAE is:16.63 & sMAPE is:10.35% & rMAE is:1.53 ||| daily mean of MAE & sMAPE & rMAE till now are :27.32 & 33.96% & 0.84\n",
      "for 2023-02-14, MAE is:18.64 & sMAPE is:11.84% & rMAE is:1.00 ||| daily mean of MAE & sMAPE & rMAE till now are :27.13 & 33.47% & 0.84\n",
      "for 2023-02-15, MAE is:19.37 & sMAPE is:14.37% & rMAE is:1.54 ||| daily mean of MAE & sMAPE & rMAE till now are :26.96 & 33.05% & 0.86\n",
      "for 2023-02-16, MAE is:14.66 & sMAPE is:10.97% & rMAE is:1.14 ||| daily mean of MAE & sMAPE & rMAE till now are :26.70 & 32.58% & 0.86\n",
      "for 2023-02-17, MAE is:40.41 & sMAPE is:44.05% & rMAE is:0.90 ||| daily mean of MAE & sMAPE & rMAE till now are :26.98 & 32.82% & 0.87\n",
      "for 2023-02-18, MAE is:40.46 & sMAPE is:51.02% & rMAE is:2.19 ||| daily mean of MAE & sMAPE & rMAE till now are :27.26 & 33.20% & 0.89\n",
      "for 2023-02-19, MAE is:18.63 & sMAPE is:17.57% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :27.08 & 32.88% & 0.89\n",
      "for 2023-02-20, MAE is:64.46 & sMAPE is:73.17% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :27.82 & 33.67% & 0.89\n",
      "for 2023-02-21, MAE is:25.44 & sMAPE is:22.93% & rMAE is:0.79 ||| daily mean of MAE & sMAPE & rMAE till now are :27.77 & 33.47% & 0.88\n",
      "for 2023-02-22, MAE is:15.13 & sMAPE is:10.83% & rMAE is:1.73 ||| daily mean of MAE & sMAPE & rMAE till now are :27.53 & 33.04% & 0.90\n",
      "for 2023-02-23, MAE is:13.96 & sMAPE is:10.19% & rMAE is:1.29 ||| daily mean of MAE & sMAPE & rMAE till now are :27.28 & 32.62% & 0.91\n",
      "for 2023-02-24, MAE is:22.04 & sMAPE is:18.05% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :27.19 & 32.35% & 0.90\n",
      "for 2023-02-25, MAE is:14.93 & sMAPE is:17.21% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :26.97 & 32.08% & 0.90\n",
      "for 2023-02-26, MAE is:22.84 & sMAPE is:22.38% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :26.90 & 31.91% & 0.91\n",
      "for 2023-02-27, MAE is:16.04 & sMAPE is:10.99% & rMAE is:0.18 ||| daily mean of MAE & sMAPE & rMAE till now are :26.71 & 31.55% & 0.90\n",
      "for 2023-02-28, MAE is:21.79 & sMAPE is:14.03% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :26.63 & 31.25% & 0.89\n",
      "for 2023-03-01, MAE is:19.10 & sMAPE is:13.02% & rMAE is:1.93 ||| daily mean of MAE & sMAPE & rMAE till now are :26.50 & 30.95% & 0.91\n",
      "for 2023-03-02, MAE is:20.35 & sMAPE is:14.54% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :26.40 & 30.68% & 0.92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-03-03, MAE is:18.03 & sMAPE is:12.95% & rMAE is:0.98 ||| daily mean of MAE & sMAPE & rMAE till now are :26.26 & 30.39% & 0.92\n",
      "for 2023-03-04, MAE is:12.91 & sMAPE is:11.92% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :26.05 & 30.10% & 0.92\n",
      "for 2023-03-05, MAE is:23.59 & sMAPE is:20.85% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :26.01 & 29.96% & 0.93\n",
      "for 2023-03-06, MAE is:21.94 & sMAPE is:14.48% & rMAE is:1.48 ||| daily mean of MAE & sMAPE & rMAE till now are :25.95 & 29.72% & 0.94\n",
      "for 2023-03-07, MAE is:26.07 & sMAPE is:22.48% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :25.95 & 29.61% & 0.94\n",
      "for 2023-03-08, MAE is:17.93 & sMAPE is:13.99% & rMAE is:1.06 ||| daily mean of MAE & sMAPE & rMAE till now are :25.83 & 29.38% & 0.94\n",
      "for 2023-03-09, MAE is:8.90 & sMAPE is:6.64% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :25.58 & 29.04% & 0.93\n",
      "for 2023-03-10, MAE is:11.93 & sMAPE is:10.54% & rMAE is:0.54 ||| daily mean of MAE & sMAPE & rMAE till now are :25.39 & 28.77% & 0.93\n",
      "for 2023-03-11, MAE is:16.63 & sMAPE is:17.41% & rMAE is:1.31 ||| daily mean of MAE & sMAPE & rMAE till now are :25.26 & 28.61% & 0.93\n",
      "for 2023-03-12, MAE is:11.06 & sMAPE is:11.70% & rMAE is:0.40 ||| daily mean of MAE & sMAPE & rMAE till now are :25.06 & 28.37% & 0.93\n",
      "for 2023-03-13, MAE is:78.00 & sMAPE is:113.47% & rMAE is:0.69 ||| daily mean of MAE & sMAPE & rMAE till now are :25.80 & 29.55% & 0.92\n",
      "for 2023-03-14, MAE is:29.92 & sMAPE is:61.61% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 29.99% & 0.92\n",
      "for 2023-03-15, MAE is:26.39 & sMAPE is:21.63% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :25.86 & 29.88% & 0.93\n",
      "for 2023-03-16, MAE is:21.61 & sMAPE is:19.08% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :25.80 & 29.74% & 0.93\n",
      "for 2023-03-17, MAE is:19.76 & sMAPE is:22.37% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :25.72 & 29.64% & 0.92\n",
      "for 2023-03-18, MAE is:20.68 & sMAPE is:19.64% & rMAE is:1.64 ||| daily mean of MAE & sMAPE & rMAE till now are :25.66 & 29.51% & 0.93\n",
      "for 2023-03-19, MAE is:12.73 & sMAPE is:12.00% & rMAE is:0.73 ||| daily mean of MAE & sMAPE & rMAE till now are :25.49 & 29.29% & 0.93\n",
      "for 2023-03-20, MAE is:40.51 & sMAPE is:27.24% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :25.68 & 29.26% & 0.93\n",
      "for 2023-03-21, MAE is:22.54 & sMAPE is:18.23% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :25.64 & 29.12% & 0.92\n",
      "for 2023-03-22, MAE is:20.76 & sMAPE is:28.86% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :25.58 & 29.12% & 0.91\n",
      "for 2023-03-23, MAE is:27.58 & sMAPE is:36.70% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :25.61 & 29.21% & 0.91\n",
      "for 2023-03-24, MAE is:33.51 & sMAPE is:63.02% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :25.70 & 29.62% & 0.91\n",
      "for 2023-03-25, MAE is:47.62 & sMAPE is:147.39% & rMAE is:0.50 ||| daily mean of MAE & sMAPE & rMAE till now are :25.96 & 31.02% & 0.91\n",
      "for 2023-03-26, MAE is:35.56 & sMAPE is:65.66% & rMAE is:0.83 ||| daily mean of MAE & sMAPE & rMAE till now are :26.08 & 31.43% & 0.91\n",
      "for 2023-03-27, MAE is:24.61 & sMAPE is:28.35% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :26.06 & 31.39% & 0.90\n",
      "for 2023-03-28, MAE is:24.35 & sMAPE is:22.65% & rMAE is:1.57 ||| daily mean of MAE & sMAPE & rMAE till now are :26.04 & 31.29% & 0.91\n",
      "for 2023-03-29, MAE is:9.31 & sMAPE is:7.76% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :25.85 & 31.02% & 0.90\n",
      "for 2023-03-30, MAE is:20.67 & sMAPE is:31.78% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :25.79 & 31.03% & 0.90\n",
      "for 2023-03-31, MAE is:21.61 & sMAPE is:23.87% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :25.74 & 30.95% & 0.90\n",
      "for 2023-04-01, MAE is:15.83 & sMAPE is:28.73% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :25.64 & 30.93% & 0.89\n",
      "for 2023-04-02, MAE is:18.70 & sMAPE is:30.30% & rMAE is:0.99 ||| daily mean of MAE & sMAPE & rMAE till now are :25.56 & 30.92% & 0.89\n",
      "for 2023-04-03, MAE is:23.11 & sMAPE is:21.43% & rMAE is:1.03 ||| daily mean of MAE & sMAPE & rMAE till now are :25.53 & 30.82% & 0.89\n",
      "for 2023-04-04, MAE is:17.44 & sMAPE is:13.51% & rMAE is:0.92 ||| daily mean of MAE & sMAPE & rMAE till now are :25.45 & 30.64% & 0.89\n",
      "for 2023-04-05, MAE is:20.59 & sMAPE is:14.53% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :25.40 & 30.47% & 0.89\n",
      "for 2023-04-06, MAE is:19.54 & sMAPE is:14.44% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :25.34 & 30.30% & 0.89\n",
      "for 2023-04-07, MAE is:10.92 & sMAPE is:10.18% & rMAE is:0.44 ||| daily mean of MAE & sMAPE & rMAE till now are :25.19 & 30.09% & 0.88\n",
      "for 2023-04-08, MAE is:18.26 & sMAPE is:17.17% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :25.12 & 29.96% & 0.88\n",
      "for 2023-04-09, MAE is:23.05 & sMAPE is:26.29% & rMAE is:0.61 ||| daily mean of MAE & sMAPE & rMAE till now are :25.10 & 29.92% & 0.88\n",
      "for 2023-04-10, MAE is:41.16 & sMAPE is:91.91% & rMAE is:0.55 ||| daily mean of MAE & sMAPE & rMAE till now are :25.26 & 30.54% & 0.87\n",
      "for 2023-04-11, MAE is:42.22 & sMAPE is:108.75% & rMAE is:0.59 ||| daily mean of MAE & sMAPE & rMAE till now are :25.42 & 31.32% & 0.87\n",
      "for 2023-04-12, MAE is:7.93 & sMAPE is:7.48% & rMAE is:0.24 ||| daily mean of MAE & sMAPE & rMAE till now are :25.25 & 31.08% & 0.86\n",
      "for 2023-04-13, MAE is:18.66 & sMAPE is:16.82% & rMAE is:0.68 ||| daily mean of MAE & sMAPE & rMAE till now are :25.19 & 30.94% & 0.86\n",
      "for 2023-04-14, MAE is:9.78 & sMAPE is:7.48% & rMAE is:0.46 ||| daily mean of MAE & sMAPE & rMAE till now are :25.04 & 30.72% & 0.86\n",
      "for 2023-04-15, MAE is:10.19 & sMAPE is:9.99% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :24.90 & 30.52% & 0.86\n",
      "for 2023-04-16, MAE is:13.40 & sMAPE is:14.18% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :24.79 & 30.37% & 0.86\n",
      "for 2023-04-17, MAE is:35.38 & sMAPE is:25.58% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :24.89 & 30.32% & 0.85\n",
      "for 2023-04-18, MAE is:16.27 & sMAPE is:14.57% & rMAE is:0.27 ||| daily mean of MAE & sMAPE & rMAE till now are :24.81 & 30.18% & 0.85\n",
      "for 2023-04-19, MAE is:29.72 & sMAPE is:47.17% & rMAE is:0.93 ||| daily mean of MAE & sMAPE & rMAE till now are :24.85 & 30.33% & 0.85\n",
      "for 2023-04-20, MAE is:14.60 & sMAPE is:14.14% & rMAE is:0.87 ||| daily mean of MAE & sMAPE & rMAE till now are :24.76 & 30.19% & 0.85\n",
      "for 2023-04-21, MAE is:27.88 & sMAPE is:41.52% & rMAE is:0.71 ||| daily mean of MAE & sMAPE & rMAE till now are :24.79 & 30.29% & 0.85\n",
      "for 2023-04-22, MAE is:18.70 & sMAPE is:32.39% & rMAE is:0.84 ||| daily mean of MAE & sMAPE & rMAE till now are :24.74 & 30.31% & 0.85\n",
      "for 2023-04-23, MAE is:19.50 & sMAPE is:32.27% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :24.69 & 30.32% & 0.85\n",
      "for 2023-04-24, MAE is:23.16 & sMAPE is:20.00% & rMAE is:1.18 ||| daily mean of MAE & sMAPE & rMAE till now are :24.68 & 30.23% & 0.85\n",
      "for 2023-04-25, MAE is:12.15 & sMAPE is:12.65% & rMAE is:1.15 ||| daily mean of MAE & sMAPE & rMAE till now are :24.57 & 30.08% & 0.85\n",
      "for 2023-04-26, MAE is:12.18 & sMAPE is:10.96% & rMAE is:0.41 ||| daily mean of MAE & sMAPE & rMAE till now are :24.46 & 29.92% & 0.85\n",
      "for 2023-04-27, MAE is:15.05 & sMAPE is:12.96% & rMAE is:2.61 ||| daily mean of MAE & sMAPE & rMAE till now are :24.38 & 29.77% & 0.86\n",
      "for 2023-04-28, MAE is:7.00 & sMAPE is:6.34% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :24.23 & 29.57% & 0.86\n",
      "for 2023-04-29, MAE is:10.23 & sMAPE is:10.45% & rMAE is:0.49 ||| daily mean of MAE & sMAPE & rMAE till now are :24.11 & 29.41% & 0.86\n",
      "for 2023-04-30, MAE is:24.04 & sMAPE is:56.26% & rMAE is:1.37 ||| daily mean of MAE & sMAPE & rMAE till now are :24.11 & 29.64% & 0.86\n",
      "for 2023-05-01, MAE is:18.08 & sMAPE is:23.74% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :24.06 & 29.59% & 0.86\n",
      "for 2023-05-02, MAE is:19.50 & sMAPE is:16.99% & rMAE is:1.78 ||| daily mean of MAE & sMAPE & rMAE till now are :24.03 & 29.48% & 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for 2023-05-03, MAE is:15.10 & sMAPE is:14.07% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :23.95 & 29.36% & 0.87\n",
      "for 2023-05-04, MAE is:15.27 & sMAPE is:16.11% & rMAE is:1.05 ||| daily mean of MAE & sMAPE & rMAE till now are :23.88 & 29.25% & 0.87\n",
      "for 2023-05-05, MAE is:9.24 & sMAPE is:9.61% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :23.77 & 29.09% & 0.87\n",
      "for 2023-05-06, MAE is:8.47 & sMAPE is:10.04% & rMAE is:0.72 ||| daily mean of MAE & sMAPE & rMAE till now are :23.65 & 28.94% & 0.87\n",
      "for 2023-05-07, MAE is:17.32 & sMAPE is:47.77% & rMAE is:1.85 ||| daily mean of MAE & sMAPE & rMAE till now are :23.60 & 29.09% & 0.88\n",
      "for 2023-05-08, MAE is:19.36 & sMAPE is:18.19% & rMAE is:1.22 ||| daily mean of MAE & sMAPE & rMAE till now are :23.56 & 29.01% & 0.88\n",
      "for 2023-05-09, MAE is:17.19 & sMAPE is:17.27% & rMAE is:1.32 ||| daily mean of MAE & sMAPE & rMAE till now are :23.51 & 28.91% & 0.89\n",
      "for 2023-05-10, MAE is:10.09 & sMAPE is:9.52% & rMAE is:0.78 ||| daily mean of MAE & sMAPE & rMAE till now are :23.41 & 28.77% & 0.89\n",
      "for 2023-05-11, MAE is:15.67 & sMAPE is:14.05% & rMAE is:0.82 ||| daily mean of MAE & sMAPE & rMAE till now are :23.35 & 28.65% & 0.88\n",
      "for 2023-05-12, MAE is:7.91 & sMAPE is:7.82% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :23.23 & 28.50% & 0.88\n",
      "for 2023-05-13, MAE is:20.40 & sMAPE is:41.13% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :23.21 & 28.59% & 0.89\n",
      "for 2023-05-14, MAE is:18.14 & sMAPE is:47.80% & rMAE is:1.68 ||| daily mean of MAE & sMAPE & rMAE till now are :23.17 & 28.73% & 0.89\n",
      "for 2023-05-15, MAE is:21.90 & sMAPE is:17.74% & rMAE is:1.17 ||| daily mean of MAE & sMAPE & rMAE till now are :23.17 & 28.65% & 0.89\n",
      "for 2023-05-16, MAE is:25.95 & sMAPE is:34.12% & rMAE is:1.56 ||| daily mean of MAE & sMAPE & rMAE till now are :23.19 & 28.69% & 0.90\n",
      "for 2023-05-17, MAE is:20.46 & sMAPE is:34.45% & rMAE is:0.70 ||| daily mean of MAE & sMAPE & rMAE till now are :23.17 & 28.73% & 0.90\n",
      "for 2023-05-18, MAE is:15.01 & sMAPE is:19.29% & rMAE is:0.51 ||| daily mean of MAE & sMAPE & rMAE till now are :23.11 & 28.67% & 0.90\n",
      "for 2023-05-19, MAE is:11.73 & sMAPE is:14.03% & rMAE is:0.88 ||| daily mean of MAE & sMAPE & rMAE till now are :23.02 & 28.56% & 0.90\n",
      "for 2023-05-20, MAE is:20.57 & sMAPE is:66.65% & rMAE is:0.65 ||| daily mean of MAE & sMAPE & rMAE till now are :23.01 & 28.83% & 0.89\n",
      "for 2023-05-21, MAE is:18.64 & sMAPE is:88.87% & rMAE is:0.43 ||| daily mean of MAE & sMAPE & rMAE till now are :22.98 & 29.26% & 0.89\n",
      "for 2023-05-22, MAE is:14.24 & sMAPE is:15.31% & rMAE is:0.67 ||| daily mean of MAE & sMAPE & rMAE till now are :22.91 & 29.16% & 0.89\n",
      "for 2023-05-23, MAE is:25.50 & sMAPE is:41.59% & rMAE is:2.54 ||| daily mean of MAE & sMAPE & rMAE till now are :22.93 & 29.25% & 0.90\n",
      "for 2023-05-24, MAE is:29.15 & sMAPE is:31.36% & rMAE is:1.23 ||| daily mean of MAE & sMAPE & rMAE till now are :22.98 & 29.26% & 0.90\n",
      "for 2023-05-25, MAE is:32.17 & sMAPE is:41.94% & rMAE is:2.91 ||| daily mean of MAE & sMAPE & rMAE till now are :23.04 & 29.35% & 0.92\n",
      "for 2023-05-26, MAE is:26.22 & sMAPE is:49.52% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :23.06 & 29.49% & 0.92\n",
      "for 2023-05-27, MAE is:24.56 & sMAPE is:63.03% & rMAE is:1.49 ||| daily mean of MAE & sMAPE & rMAE till now are :23.07 & 29.72% & 0.92\n",
      "for 2023-05-28, MAE is:41.89 & sMAPE is:85.69% & rMAE is:1.26 ||| daily mean of MAE & sMAPE & rMAE till now are :23.20 & 30.09% & 0.93\n",
      "for 2023-05-29, MAE is:43.15 & sMAPE is:92.79% & rMAE is:0.57 ||| daily mean of MAE & sMAPE & rMAE till now are :23.33 & 30.51% & 0.92\n",
      "for 2023-05-30, MAE is:17.11 & sMAPE is:19.04% & rMAE is:0.89 ||| daily mean of MAE & sMAPE & rMAE till now are :23.29 & 30.44% & 0.92\n",
      "for 2023-05-31, MAE is:24.99 & sMAPE is:48.64% & rMAE is:0.76 ||| daily mean of MAE & sMAPE & rMAE till now are :23.30 & 30.56% & 0.92\n",
      "for 2023-06-01, MAE is:14.85 & sMAPE is:30.22% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :23.25 & 30.56% & 0.93\n",
      "for 2023-06-02, MAE is:12.91 & sMAPE is:16.91% & rMAE is:0.85 ||| daily mean of MAE & sMAPE & rMAE till now are :23.18 & 30.47% & 0.92\n",
      "for 2023-06-03, MAE is:16.82 & sMAPE is:56.15% & rMAE is:2.03 ||| daily mean of MAE & sMAPE & rMAE till now are :23.14 & 30.63% & 0.93\n",
      "for 2023-06-04, MAE is:19.84 & sMAPE is:69.54% & rMAE is:0.74 ||| daily mean of MAE & sMAPE & rMAE till now are :23.12 & 30.89% & 0.93\n",
      "for 2023-06-05, MAE is:21.05 & sMAPE is:21.71% & rMAE is:0.30 ||| daily mean of MAE & sMAPE & rMAE till now are :23.10 & 30.83% & 0.93\n",
      "for 2023-06-06, MAE is:20.05 & sMAPE is:19.44% & rMAE is:1.89 ||| daily mean of MAE & sMAPE & rMAE till now are :23.08 & 30.75% & 0.93\n",
      "for 2023-06-07, MAE is:12.10 & sMAPE is:11.38% & rMAE is:0.42 ||| daily mean of MAE & sMAPE & rMAE till now are :23.01 & 30.63% & 0.93\n",
      "for 2023-06-08, MAE is:8.21 & sMAPE is:9.53% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.92 & 30.50% & 0.93\n",
      "for 2023-06-09, MAE is:11.03 & sMAPE is:13.83% & rMAE is:1.13 ||| daily mean of MAE & sMAPE & rMAE till now are :22.85 & 30.39% & 0.93\n",
      "for 2023-06-10, MAE is:26.83 & sMAPE is:60.69% & rMAE is:4.40 ||| daily mean of MAE & sMAPE & rMAE till now are :22.87 & 30.58% & 0.95\n",
      "for 2023-06-11, MAE is:22.89 & sMAPE is:75.67% & rMAE is:2.27 ||| daily mean of MAE & sMAPE & rMAE till now are :22.87 & 30.86% & 0.96\n",
      "for 2023-06-12, MAE is:13.55 & sMAPE is:14.31% & rMAE is:1.30 ||| daily mean of MAE & sMAPE & rMAE till now are :22.81 & 30.76% & 0.96\n",
      "for 2023-06-13, MAE is:14.47 & sMAPE is:16.68% & rMAE is:1.27 ||| daily mean of MAE & sMAPE & rMAE till now are :22.76 & 30.67% & 0.96\n",
      "for 2023-06-14, MAE is:12.03 & sMAPE is:11.50% & rMAE is:2.10 ||| daily mean of MAE & sMAPE & rMAE till now are :22.70 & 30.56% & 0.97\n",
      "for 2023-06-15, MAE is:13.95 & sMAPE is:11.01% & rMAE is:0.39 ||| daily mean of MAE & sMAPE & rMAE till now are :22.65 & 30.44% & 0.97\n",
      "for 2023-06-16, MAE is:10.75 & sMAPE is:8.35% & rMAE is:0.26 ||| daily mean of MAE & sMAPE & rMAE till now are :22.57 & 30.31% & 0.96\n",
      "for 2023-06-17, MAE is:17.14 & sMAPE is:19.19% & rMAE is:0.35 ||| daily mean of MAE & sMAPE & rMAE till now are :22.54 & 30.24% & 0.96\n",
      "for 2023-06-18, MAE is:16.15 & sMAPE is:22.03% & rMAE is:0.31 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 30.19% & 0.95\n",
      "for 2023-06-19, MAE is:18.65 & sMAPE is:15.39% & rMAE is:0.91 ||| daily mean of MAE & sMAPE & rMAE till now are :22.48 & 30.11% & 0.95\n",
      "for 2023-06-20, MAE is:29.43 & sMAPE is:21.87% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :22.52 & 30.06% & 0.95\n",
      "for 2023-06-21, MAE is:11.59 & sMAPE is:8.95% & rMAE is:0.56 ||| daily mean of MAE & sMAPE & rMAE till now are :22.46 & 29.93% & 0.95\n",
      "for 2023-06-22, MAE is:14.04 & sMAPE is:10.44% & rMAE is:0.97 ||| daily mean of MAE & sMAPE & rMAE till now are :22.41 & 29.82% & 0.95\n",
      "for 2023-06-23, MAE is:13.38 & sMAPE is:12.42% & rMAE is:0.63 ||| daily mean of MAE & sMAPE & rMAE till now are :22.36 & 29.72% & 0.95\n",
      "for 2023-06-24, MAE is:22.92 & sMAPE is:44.71% & rMAE is:1.01 ||| daily mean of MAE & sMAPE & rMAE till now are :22.36 & 29.81% & 0.95\n",
      "for 2023-06-25, MAE is:29.30 & sMAPE is:69.26% & rMAE is:1.36 ||| daily mean of MAE & sMAPE & rMAE till now are :22.40 & 30.03% & 0.95\n",
      "for 2023-06-26, MAE is:47.20 & sMAPE is:40.61% & rMAE is:1.95 ||| daily mean of MAE & sMAPE & rMAE till now are :22.54 & 30.09% & 0.96\n",
      "for 2023-06-27, MAE is:15.37 & sMAPE is:14.60% & rMAE is:0.80 ||| daily mean of MAE & sMAPE & rMAE till now are :22.50 & 30.00% & 0.96\n",
      "for 2023-06-28, MAE is:12.48 & sMAPE is:11.03% & rMAE is:1.07 ||| daily mean of MAE & sMAPE & rMAE till now are :22.44 & 29.90% & 0.96\n",
      "for 2023-06-29, MAE is:10.48 & sMAPE is:8.68% & rMAE is:0.95 ||| daily mean of MAE & sMAPE & rMAE till now are :22.38 & 29.78% & 0.96\n",
      "for 2023-06-30, MAE is:10.04 & sMAPE is:8.71% & rMAE is:1.43 ||| daily mean of MAE & sMAPE & rMAE till now are :22.31 & 29.66% & 0.96\n",
      "CPU times: total: 2d 3h 29min 27s\n",
      "Wall time: 1d 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for zone in zones:\n",
    "    large_scale_predictor(zone, first_year=2018, last_year=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
